05/16/2022 14:13:37 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/16/2022 14:13:37 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo
05/16/2022 14:13:38 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/16/2022 14:13:38 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo
05/16/2022 14:13:39 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/16/2022 14:13:39 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/16/2022 14:13:39 - INFO - __main__ - args.device: cuda:0
05/16/2022 14:13:39 - INFO - __main__ - Using 2 gpus
05/16/2022 14:13:39 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/16/2022 14:13:39 - INFO - __main__ - args.device: cuda:1
05/16/2022 14:13:39 - INFO - __main__ - Using 2 gpus
05/16/2022 14:13:39 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/16/2022 14:13:44 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
05/16/2022 14:13:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:13:45 - INFO - __main__ - Printing 3 examples
05/16/2022 14:13:45 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:13:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:13:45 - INFO - __main__ - Printing 3 examples
05/16/2022 14:13:45 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:13:45 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:13:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:13:45 - INFO - __main__ - Printing 3 examples
05/16/2022 14:13:45 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:13:45 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:13:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:13:45 - INFO - __main__ - Printing 3 examples
05/16/2022 14:13:45 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:13:45 - INFO - __main__ - ['others']
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:13:45 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:13:45 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:13:45 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:13:51 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:13:51 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:13:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:13:51 - INFO - __main__ - Starting training!
05/16/2022 14:13:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:13:57 - INFO - __main__ - Starting training!
05/16/2022 14:13:59 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=2
05/16/2022 14:14:00 - INFO - __main__ - Step 20 Global step 20 Train loss 6.44 on epoch=4
05/16/2022 14:14:02 - INFO - __main__ - Step 30 Global step 30 Train loss 6.36 on epoch=7
05/16/2022 14:14:03 - INFO - __main__ - Step 40 Global step 40 Train loss 5.90 on epoch=9
05/16/2022 14:14:05 - INFO - __main__ - Step 50 Global step 50 Train loss 5.57 on epoch=12
05/16/2022 14:14:07 - INFO - __main__ - Global step 50 Train loss 6.19 Classification-F1 0.0 on epoch=12
05/16/2022 14:14:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 14:14:08 - INFO - __main__ - Step 60 Global step 60 Train loss 5.52 on epoch=14
05/16/2022 14:14:10 - INFO - __main__ - Step 70 Global step 70 Train loss 5.19 on epoch=17
05/16/2022 14:14:11 - INFO - __main__ - Step 80 Global step 80 Train loss 4.85 on epoch=19
05/16/2022 14:14:12 - INFO - __main__ - Step 90 Global step 90 Train loss 4.60 on epoch=22
05/16/2022 14:14:14 - INFO - __main__ - Step 100 Global step 100 Train loss 4.31 on epoch=24
05/16/2022 14:14:15 - INFO - __main__ - Global step 100 Train loss 4.90 Classification-F1 0.06015037593984963 on epoch=24
05/16/2022 14:14:15 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06015037593984963 on epoch=24, global_step=100
05/16/2022 14:14:16 - INFO - __main__ - Step 110 Global step 110 Train loss 4.12 on epoch=27
05/16/2022 14:14:17 - INFO - __main__ - Step 120 Global step 120 Train loss 3.90 on epoch=29
05/16/2022 14:14:19 - INFO - __main__ - Step 130 Global step 130 Train loss 3.71 on epoch=32
05/16/2022 14:14:20 - INFO - __main__ - Step 140 Global step 140 Train loss 3.49 on epoch=34
05/16/2022 14:14:22 - INFO - __main__ - Step 150 Global step 150 Train loss 3.28 on epoch=37
05/16/2022 14:14:24 - INFO - __main__ - Global step 150 Train loss 3.70 Classification-F1 0.13660130718954247 on epoch=37
05/16/2022 14:14:24 - INFO - __main__ - Saving model with best Classification-F1: 0.06015037593984963 -> 0.13660130718954247 on epoch=37, global_step=150
05/16/2022 14:14:25 - INFO - __main__ - Step 160 Global step 160 Train loss 3.03 on epoch=39
05/16/2022 14:14:27 - INFO - __main__ - Step 170 Global step 170 Train loss 3.15 on epoch=42
05/16/2022 14:14:28 - INFO - __main__ - Step 180 Global step 180 Train loss 2.93 on epoch=44
05/16/2022 14:14:30 - INFO - __main__ - Step 190 Global step 190 Train loss 3.09 on epoch=47
05/16/2022 14:14:31 - INFO - __main__ - Step 200 Global step 200 Train loss 2.84 on epoch=49
05/16/2022 14:14:31 - INFO - __main__ - Global step 200 Train loss 3.01 Classification-F1 0.1 on epoch=49
05/16/2022 14:14:33 - INFO - __main__ - Step 210 Global step 210 Train loss 2.91 on epoch=52
05/16/2022 14:14:34 - INFO - __main__ - Step 220 Global step 220 Train loss 2.73 on epoch=54
05/16/2022 14:14:35 - INFO - __main__ - Step 230 Global step 230 Train loss 2.77 on epoch=57
05/16/2022 14:14:37 - INFO - __main__ - Step 240 Global step 240 Train loss 2.52 on epoch=59
05/16/2022 14:14:38 - INFO - __main__ - Step 250 Global step 250 Train loss 2.65 on epoch=62
05/16/2022 14:14:39 - INFO - __main__ - Global step 250 Train loss 2.71 Classification-F1 0.12417582417582418 on epoch=62
05/16/2022 14:14:40 - INFO - __main__ - Step 260 Global step 260 Train loss 2.42 on epoch=64
05/16/2022 14:14:41 - INFO - __main__ - Step 270 Global step 270 Train loss 2.36 on epoch=67
05/16/2022 14:14:43 - INFO - __main__ - Step 280 Global step 280 Train loss 2.39 on epoch=69
05/16/2022 14:14:44 - INFO - __main__ - Step 290 Global step 290 Train loss 2.35 on epoch=72
05/16/2022 14:14:46 - INFO - __main__ - Step 300 Global step 300 Train loss 2.16 on epoch=74
05/16/2022 14:14:47 - INFO - __main__ - Global step 300 Train loss 2.34 Classification-F1 0.0974025974025974 on epoch=74
05/16/2022 14:14:48 - INFO - __main__ - Step 310 Global step 310 Train loss 2.39 on epoch=77
05/16/2022 14:14:49 - INFO - __main__ - Step 320 Global step 320 Train loss 2.10 on epoch=79
05/16/2022 14:14:51 - INFO - __main__ - Step 330 Global step 330 Train loss 2.25 on epoch=82
05/16/2022 14:14:52 - INFO - __main__ - Step 340 Global step 340 Train loss 2.02 on epoch=84
05/16/2022 14:14:53 - INFO - __main__ - Step 350 Global step 350 Train loss 2.20 on epoch=87
05/16/2022 14:14:54 - INFO - __main__ - Global step 350 Train loss 2.19 Classification-F1 0.1 on epoch=87
05/16/2022 14:14:55 - INFO - __main__ - Step 360 Global step 360 Train loss 2.10 on epoch=89
05/16/2022 14:14:57 - INFO - __main__ - Step 370 Global step 370 Train loss 2.05 on epoch=92
05/16/2022 14:14:58 - INFO - __main__ - Step 380 Global step 380 Train loss 1.96 on epoch=94
05/16/2022 14:15:00 - INFO - __main__ - Step 390 Global step 390 Train loss 2.09 on epoch=97
05/16/2022 14:15:01 - INFO - __main__ - Step 400 Global step 400 Train loss 1.87 on epoch=99
05/16/2022 14:15:02 - INFO - __main__ - Global step 400 Train loss 2.02 Classification-F1 0.10126582278481013 on epoch=99
05/16/2022 14:15:03 - INFO - __main__ - Step 410 Global step 410 Train loss 1.81 on epoch=102
05/16/2022 14:15:05 - INFO - __main__ - Step 420 Global step 420 Train loss 1.91 on epoch=104
05/16/2022 14:15:06 - INFO - __main__ - Step 430 Global step 430 Train loss 1.91 on epoch=107
05/16/2022 14:15:08 - INFO - __main__ - Step 440 Global step 440 Train loss 1.69 on epoch=109
05/16/2022 14:15:09 - INFO - __main__ - Step 450 Global step 450 Train loss 1.74 on epoch=112
05/16/2022 14:15:10 - INFO - __main__ - Global step 450 Train loss 1.81 Classification-F1 0.10126582278481013 on epoch=112
05/16/2022 14:15:11 - INFO - __main__ - Step 460 Global step 460 Train loss 1.59 on epoch=114
05/16/2022 14:15:13 - INFO - __main__ - Step 470 Global step 470 Train loss 1.95 on epoch=117
05/16/2022 14:15:14 - INFO - __main__ - Step 480 Global step 480 Train loss 1.76 on epoch=119
05/16/2022 14:15:16 - INFO - __main__ - Step 490 Global step 490 Train loss 1.80 on epoch=122
05/16/2022 14:15:18 - INFO - __main__ - Step 500 Global step 500 Train loss 1.84 on epoch=124
05/16/2022 14:15:18 - INFO - __main__ - Global step 500 Train loss 1.79 Classification-F1 0.1 on epoch=124
05/16/2022 14:15:19 - INFO - __main__ - Step 510 Global step 510 Train loss 1.64 on epoch=127
05/16/2022 14:15:21 - INFO - __main__ - Step 520 Global step 520 Train loss 1.49 on epoch=129
05/16/2022 14:15:23 - INFO - __main__ - Step 530 Global step 530 Train loss 1.70 on epoch=132
05/16/2022 14:15:24 - INFO - __main__ - Step 540 Global step 540 Train loss 1.49 on epoch=134
05/16/2022 14:15:25 - INFO - __main__ - Step 550 Global step 550 Train loss 1.51 on epoch=137
05/16/2022 14:15:26 - INFO - __main__ - Global step 550 Train loss 1.56 Classification-F1 0.10126582278481013 on epoch=137
05/16/2022 14:15:27 - INFO - __main__ - Step 560 Global step 560 Train loss 1.48 on epoch=139
05/16/2022 14:15:29 - INFO - __main__ - Step 570 Global step 570 Train loss 1.52 on epoch=142
05/16/2022 14:15:30 - INFO - __main__ - Step 580 Global step 580 Train loss 1.44 on epoch=144
05/16/2022 14:15:32 - INFO - __main__ - Step 590 Global step 590 Train loss 1.45 on epoch=147
05/16/2022 14:15:33 - INFO - __main__ - Step 600 Global step 600 Train loss 1.31 on epoch=149
05/16/2022 14:15:34 - INFO - __main__ - Global step 600 Train loss 1.44 Classification-F1 0.21944444444444447 on epoch=149
05/16/2022 14:15:34 - INFO - __main__ - Saving model with best Classification-F1: 0.13660130718954247 -> 0.21944444444444447 on epoch=149, global_step=600
05/16/2022 14:15:35 - INFO - __main__ - Step 610 Global step 610 Train loss 1.45 on epoch=152
05/16/2022 14:15:36 - INFO - __main__ - Step 620 Global step 620 Train loss 1.43 on epoch=154
05/16/2022 14:15:38 - INFO - __main__ - Step 630 Global step 630 Train loss 1.46 on epoch=157
05/16/2022 14:15:39 - INFO - __main__ - Step 640 Global step 640 Train loss 1.44 on epoch=159
05/16/2022 14:15:41 - INFO - __main__ - Step 650 Global step 650 Train loss 1.39 on epoch=162
05/16/2022 14:15:41 - INFO - __main__ - Global step 650 Train loss 1.43 Classification-F1 0.18284936479128855 on epoch=162
05/16/2022 14:15:43 - INFO - __main__ - Step 660 Global step 660 Train loss 1.50 on epoch=164
05/16/2022 14:15:44 - INFO - __main__ - Step 670 Global step 670 Train loss 1.31 on epoch=167
05/16/2022 14:15:46 - INFO - __main__ - Step 680 Global step 680 Train loss 1.28 on epoch=169
05/16/2022 14:15:47 - INFO - __main__ - Step 690 Global step 690 Train loss 1.42 on epoch=172
05/16/2022 14:15:49 - INFO - __main__ - Step 700 Global step 700 Train loss 1.35 on epoch=174
05/16/2022 14:15:49 - INFO - __main__ - Global step 700 Train loss 1.37 Classification-F1 0.1 on epoch=174
05/16/2022 14:15:51 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=177
05/16/2022 14:15:52 - INFO - __main__ - Step 720 Global step 720 Train loss 1.22 on epoch=179
05/16/2022 14:15:54 - INFO - __main__ - Step 730 Global step 730 Train loss 1.28 on epoch=182
05/16/2022 14:15:55 - INFO - __main__ - Step 740 Global step 740 Train loss 1.32 on epoch=184
05/16/2022 14:15:56 - INFO - __main__ - Step 750 Global step 750 Train loss 1.28 on epoch=187
05/16/2022 14:15:57 - INFO - __main__ - Global step 750 Train loss 1.28 Classification-F1 0.11996779388083736 on epoch=187
05/16/2022 14:15:58 - INFO - __main__ - Step 760 Global step 760 Train loss 1.25 on epoch=189
05/16/2022 14:15:59 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=192
05/16/2022 14:16:01 - INFO - __main__ - Step 780 Global step 780 Train loss 1.29 on epoch=194
05/16/2022 14:16:02 - INFO - __main__ - Step 790 Global step 790 Train loss 1.27 on epoch=197
05/16/2022 14:16:03 - INFO - __main__ - Step 800 Global step 800 Train loss 1.17 on epoch=199
05/16/2022 14:16:04 - INFO - __main__ - Global step 800 Train loss 1.24 Classification-F1 0.19157427937915744 on epoch=199
05/16/2022 14:16:05 - INFO - __main__ - Step 810 Global step 810 Train loss 1.25 on epoch=202
05/16/2022 14:16:07 - INFO - __main__ - Step 820 Global step 820 Train loss 1.12 on epoch=204
05/16/2022 14:16:08 - INFO - __main__ - Step 830 Global step 830 Train loss 1.38 on epoch=207
05/16/2022 14:16:09 - INFO - __main__ - Step 840 Global step 840 Train loss 1.22 on epoch=209
05/16/2022 14:16:11 - INFO - __main__ - Step 850 Global step 850 Train loss 1.18 on epoch=212
05/16/2022 14:16:11 - INFO - __main__ - Global step 850 Train loss 1.23 Classification-F1 0.19267605633802815 on epoch=212
05/16/2022 14:16:13 - INFO - __main__ - Step 860 Global step 860 Train loss 1.25 on epoch=214
05/16/2022 14:16:14 - INFO - __main__ - Step 870 Global step 870 Train loss 1.16 on epoch=217
05/16/2022 14:16:15 - INFO - __main__ - Step 880 Global step 880 Train loss 1.17 on epoch=219
05/16/2022 14:16:16 - INFO - __main__ - Step 890 Global step 890 Train loss 1.12 on epoch=222
05/16/2022 14:16:18 - INFO - __main__ - Step 900 Global step 900 Train loss 1.24 on epoch=224
05/16/2022 14:16:18 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.09090909090909091 on epoch=224
05/16/2022 14:16:20 - INFO - __main__ - Step 910 Global step 910 Train loss 1.11 on epoch=227
05/16/2022 14:16:21 - INFO - __main__ - Step 920 Global step 920 Train loss 1.13 on epoch=229
05/16/2022 14:16:22 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
05/16/2022 14:16:24 - INFO - __main__ - Step 940 Global step 940 Train loss 1.22 on epoch=234
05/16/2022 14:16:25 - INFO - __main__ - Step 950 Global step 950 Train loss 1.12 on epoch=237
05/16/2022 14:16:26 - INFO - __main__ - Global step 950 Train loss 1.20 Classification-F1 0.1 on epoch=237
05/16/2022 14:16:27 - INFO - __main__ - Step 960 Global step 960 Train loss 1.15 on epoch=239
05/16/2022 14:16:28 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=242
05/16/2022 14:16:30 - INFO - __main__ - Step 980 Global step 980 Train loss 1.22 on epoch=244
05/16/2022 14:16:31 - INFO - __main__ - Step 990 Global step 990 Train loss 1.10 on epoch=247
05/16/2022 14:16:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.07 on epoch=249
05/16/2022 14:16:33 - INFO - __main__ - Global step 1000 Train loss 1.13 Classification-F1 0.1 on epoch=249
05/16/2022 14:16:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
05/16/2022 14:16:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.04 on epoch=254
05/16/2022 14:16:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.09 on epoch=257
05/16/2022 14:16:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.09 on epoch=259
05/16/2022 14:16:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=262
05/16/2022 14:16:40 - INFO - __main__ - Global step 1050 Train loss 1.08 Classification-F1 0.1 on epoch=262
05/16/2022 14:16:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=264
05/16/2022 14:16:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.04 on epoch=267
05/16/2022 14:16:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.05 on epoch=269
05/16/2022 14:16:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.16 on epoch=272
05/16/2022 14:16:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.12 on epoch=274
05/16/2022 14:16:47 - INFO - __main__ - Global step 1100 Train loss 1.08 Classification-F1 0.1 on epoch=274
05/16/2022 14:16:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.02 on epoch=277
05/16/2022 14:16:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.10 on epoch=279
05/16/2022 14:16:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.06 on epoch=282
05/16/2022 14:16:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.09 on epoch=284
05/16/2022 14:16:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=287
05/16/2022 14:16:54 - INFO - __main__ - Global step 1150 Train loss 1.08 Classification-F1 0.1 on epoch=287
05/16/2022 14:16:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.05 on epoch=289
05/16/2022 14:16:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.00 on epoch=292
05/16/2022 14:16:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.01 on epoch=294
05/16/2022 14:17:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.93 on epoch=297
05/16/2022 14:17:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.09 on epoch=299
05/16/2022 14:17:01 - INFO - __main__ - Global step 1200 Train loss 1.02 Classification-F1 0.18026315789473685 on epoch=299
05/16/2022 14:17:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.11 on epoch=302
05/16/2022 14:17:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.07 on epoch=304
05/16/2022 14:17:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.97 on epoch=307
05/16/2022 14:17:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.90 on epoch=309
05/16/2022 14:17:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.01 on epoch=312
05/16/2022 14:17:09 - INFO - __main__ - Global step 1250 Train loss 1.01 Classification-F1 0.12407862407862408 on epoch=312
05/16/2022 14:17:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.05 on epoch=314
05/16/2022 14:17:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.10 on epoch=317
05/16/2022 14:17:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.13 on epoch=319
05/16/2022 14:17:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.00 on epoch=322
05/16/2022 14:17:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.00 on epoch=324
05/16/2022 14:17:17 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.12447885646217988 on epoch=324
05/16/2022 14:17:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.92 on epoch=327
05/16/2022 14:17:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.04 on epoch=329
05/16/2022 14:17:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.05 on epoch=332
05/16/2022 14:17:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.06 on epoch=334
05/16/2022 14:17:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.06 on epoch=337
05/16/2022 14:17:24 - INFO - __main__ - Global step 1350 Train loss 1.03 Classification-F1 0.13482414242292662 on epoch=337
05/16/2022 14:17:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/16/2022 14:17:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.00 on epoch=342
05/16/2022 14:17:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/16/2022 14:17:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.11 on epoch=347
05/16/2022 14:17:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.93 on epoch=349
05/16/2022 14:17:32 - INFO - __main__ - Global step 1400 Train loss 1.03 Classification-F1 0.10256410256410256 on epoch=349
05/16/2022 14:17:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.04 on epoch=352
05/16/2022 14:17:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.97 on epoch=354
05/16/2022 14:17:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=357
05/16/2022 14:17:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.95 on epoch=359
05/16/2022 14:17:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.06 on epoch=362
05/16/2022 14:17:39 - INFO - __main__ - Global step 1450 Train loss 1.04 Classification-F1 0.19307400379506642 on epoch=362
05/16/2022 14:17:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.04 on epoch=364
05/16/2022 14:17:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.04 on epoch=367
05/16/2022 14:17:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.08 on epoch=369
05/16/2022 14:17:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=372
05/16/2022 14:17:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.92 on epoch=374
05/16/2022 14:17:47 - INFO - __main__ - Global step 1500 Train loss 1.01 Classification-F1 0.1 on epoch=374
05/16/2022 14:17:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.02 on epoch=377
05/16/2022 14:17:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.01 on epoch=379
05/16/2022 14:17:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/16/2022 14:17:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.99 on epoch=384
05/16/2022 14:17:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.96 on epoch=387
05/16/2022 14:17:54 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.2505484861781483 on epoch=387
05/16/2022 14:17:54 - INFO - __main__ - Saving model with best Classification-F1: 0.21944444444444447 -> 0.2505484861781483 on epoch=387, global_step=1550
05/16/2022 14:17:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.00 on epoch=389
05/16/2022 14:17:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
05/16/2022 14:17:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.96 on epoch=394
05/16/2022 14:18:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=397
05/16/2022 14:18:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.98 on epoch=399
05/16/2022 14:18:02 - INFO - __main__ - Global step 1600 Train loss 0.98 Classification-F1 0.1497584541062802 on epoch=399
05/16/2022 14:18:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.00 on epoch=402
05/16/2022 14:18:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/16/2022 14:18:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.96 on epoch=407
05/16/2022 14:18:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.93 on epoch=409
05/16/2022 14:18:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.01 on epoch=412
05/16/2022 14:18:10 - INFO - __main__ - Global step 1650 Train loss 0.98 Classification-F1 0.13034188034188032 on epoch=412
05/16/2022 14:18:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.02 on epoch=414
05/16/2022 14:18:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/16/2022 14:18:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.95 on epoch=419
05/16/2022 14:18:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/16/2022 14:18:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.04 on epoch=424
05/16/2022 14:18:17 - INFO - __main__ - Global step 1700 Train loss 1.02 Classification-F1 0.17809523809523808 on epoch=424
05/16/2022 14:18:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.97 on epoch=427
05/16/2022 14:18:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.87 on epoch=429
05/16/2022 14:18:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.99 on epoch=432
05/16/2022 14:18:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.98 on epoch=434
05/16/2022 14:18:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.95 on epoch=437
05/16/2022 14:18:25 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.16407982261640797 on epoch=437
05/16/2022 14:18:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=439
05/16/2022 14:18:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.97 on epoch=442
05/16/2022 14:18:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.88 on epoch=444
05/16/2022 14:18:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.98 on epoch=447
05/16/2022 14:18:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.97 on epoch=449
05/16/2022 14:18:33 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.17124542124542122 on epoch=449
05/16/2022 14:18:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.87 on epoch=452
05/16/2022 14:18:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.90 on epoch=454
05/16/2022 14:18:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.00 on epoch=457
05/16/2022 14:18:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.04 on epoch=459
05/16/2022 14:18:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.96 on epoch=462
05/16/2022 14:18:40 - INFO - __main__ - Global step 1850 Train loss 0.95 Classification-F1 0.19165085388994307 on epoch=462
05/16/2022 14:18:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/16/2022 14:18:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=467
05/16/2022 14:18:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.94 on epoch=469
05/16/2022 14:18:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.01 on epoch=472
05/16/2022 14:18:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.83 on epoch=474
05/16/2022 14:18:47 - INFO - __main__ - Global step 1900 Train loss 0.93 Classification-F1 0.11612903225806451 on epoch=474
05/16/2022 14:18:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.92 on epoch=477
05/16/2022 14:18:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
05/16/2022 14:18:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
05/16/2022 14:18:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.96 on epoch=484
05/16/2022 14:18:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.83 on epoch=487
05/16/2022 14:18:55 - INFO - __main__ - Global step 1950 Train loss 0.93 Classification-F1 0.12819829424307036 on epoch=487
05/16/2022 14:18:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.94 on epoch=489
05/16/2022 14:18:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.04 on epoch=492
05/16/2022 14:18:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.94 on epoch=494
05/16/2022 14:19:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.90 on epoch=497
05/16/2022 14:19:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.03 on epoch=499
05/16/2022 14:19:02 - INFO - __main__ - Global step 2000 Train loss 0.97 Classification-F1 0.09999999999999999 on epoch=499
05/16/2022 14:19:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.00 on epoch=502
05/16/2022 14:19:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.88 on epoch=504
05/16/2022 14:19:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.94 on epoch=507
05/16/2022 14:19:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.94 on epoch=509
05/16/2022 14:19:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.92 on epoch=512
05/16/2022 14:19:10 - INFO - __main__ - Global step 2050 Train loss 0.94 Classification-F1 0.14642857142857144 on epoch=512
05/16/2022 14:19:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.05 on epoch=514
05/16/2022 14:19:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.97 on epoch=517
05/16/2022 14:19:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.02 on epoch=519
05/16/2022 14:19:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.87 on epoch=522
05/16/2022 14:19:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.92 on epoch=524
05/16/2022 14:19:18 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.15782608695652173 on epoch=524
05/16/2022 14:19:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
05/16/2022 14:19:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.89 on epoch=529
05/16/2022 14:19:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.94 on epoch=532
05/16/2022 14:19:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.03 on epoch=534
05/16/2022 14:19:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.93 on epoch=537
05/16/2022 14:19:26 - INFO - __main__ - Global step 2150 Train loss 0.94 Classification-F1 0.16795711733174506 on epoch=537
05/16/2022 14:19:27 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.92 on epoch=539
05/16/2022 14:19:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.94 on epoch=542
05/16/2022 14:19:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
05/16/2022 14:19:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.96 on epoch=547
05/16/2022 14:19:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.95 on epoch=549
05/16/2022 14:19:33 - INFO - __main__ - Global step 2200 Train loss 0.95 Classification-F1 0.15306730196545562 on epoch=549
05/16/2022 14:19:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.95 on epoch=552
05/16/2022 14:19:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.95 on epoch=554
05/16/2022 14:19:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.91 on epoch=557
05/16/2022 14:19:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.91 on epoch=559
05/16/2022 14:19:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.91 on epoch=562
05/16/2022 14:19:40 - INFO - __main__ - Global step 2250 Train loss 0.93 Classification-F1 0.1565452091767881 on epoch=562
05/16/2022 14:19:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.94 on epoch=564
05/16/2022 14:19:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
05/16/2022 14:19:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.92 on epoch=569
05/16/2022 14:19:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/16/2022 14:19:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.89 on epoch=574
05/16/2022 14:19:48 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.14304993252361672 on epoch=574
05/16/2022 14:19:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.99 on epoch=577
05/16/2022 14:19:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.87 on epoch=579
05/16/2022 14:19:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/16/2022 14:19:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/16/2022 14:19:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.96 on epoch=587
05/16/2022 14:19:57 - INFO - __main__ - Global step 2350 Train loss 0.95 Classification-F1 0.22751322751322753 on epoch=587
05/16/2022 14:19:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.85 on epoch=589
05/16/2022 14:19:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.87 on epoch=592
05/16/2022 14:20:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/16/2022 14:20:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
05/16/2022 14:20:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.97 on epoch=599
05/16/2022 14:20:04 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.17489919354838712 on epoch=599
05/16/2022 14:20:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/16/2022 14:20:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/16/2022 14:20:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.99 on epoch=607
05/16/2022 14:20:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/16/2022 14:20:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.90 on epoch=612
05/16/2022 14:20:12 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.13067758749069247 on epoch=612
05/16/2022 14:20:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.94 on epoch=614
05/16/2022 14:20:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.85 on epoch=617
05/16/2022 14:20:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/16/2022 14:20:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.92 on epoch=622
05/16/2022 14:20:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.88 on epoch=624
05/16/2022 14:20:20 - INFO - __main__ - Global step 2500 Train loss 0.92 Classification-F1 0.09615384615384615 on epoch=624
05/16/2022 14:20:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.94 on epoch=627
05/16/2022 14:20:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.87 on epoch=629
05/16/2022 14:20:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.87 on epoch=632
05/16/2022 14:20:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/16/2022 14:20:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/16/2022 14:20:27 - INFO - __main__ - Global step 2550 Train loss 0.90 Classification-F1 0.1640625 on epoch=637
05/16/2022 14:20:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.89 on epoch=639
05/16/2022 14:20:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.86 on epoch=642
05/16/2022 14:20:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/16/2022 14:20:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/16/2022 14:20:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/16/2022 14:20:34 - INFO - __main__ - Global step 2600 Train loss 0.91 Classification-F1 0.15833333333333333 on epoch=649
05/16/2022 14:20:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.95 on epoch=652
05/16/2022 14:20:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/16/2022 14:20:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/16/2022 14:20:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.88 on epoch=659
05/16/2022 14:20:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.89 on epoch=662
05/16/2022 14:20:41 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.1 on epoch=662
05/16/2022 14:20:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.85 on epoch=664
05/16/2022 14:20:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
05/16/2022 14:20:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=669
05/16/2022 14:20:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.89 on epoch=672
05/16/2022 14:20:48 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.97 on epoch=674
05/16/2022 14:20:48 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.10126582278481013 on epoch=674
05/16/2022 14:20:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.96 on epoch=677
05/16/2022 14:20:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.95 on epoch=679
05/16/2022 14:20:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.97 on epoch=682
05/16/2022 14:20:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/16/2022 14:20:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.02 on epoch=687
05/16/2022 14:20:56 - INFO - __main__ - Global step 2750 Train loss 0.95 Classification-F1 0.1 on epoch=687
05/16/2022 14:20:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/16/2022 14:20:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.83 on epoch=692
05/16/2022 14:21:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/16/2022 14:21:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.86 on epoch=697
05/16/2022 14:21:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.85 on epoch=699
05/16/2022 14:21:04 - INFO - __main__ - Global step 2800 Train loss 0.89 Classification-F1 0.1 on epoch=699
05/16/2022 14:21:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.93 on epoch=702
05/16/2022 14:21:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/16/2022 14:21:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/16/2022 14:21:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.88 on epoch=709
05/16/2022 14:21:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/16/2022 14:21:11 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.16666666666666666 on epoch=712
05/16/2022 14:21:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.88 on epoch=714
05/16/2022 14:21:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.87 on epoch=717
05/16/2022 14:21:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/16/2022 14:21:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
05/16/2022 14:21:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
05/16/2022 14:21:18 - INFO - __main__ - Global step 2900 Train loss 0.90 Classification-F1 0.09868421052631579 on epoch=724
05/16/2022 14:21:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.93 on epoch=727
05/16/2022 14:21:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.86 on epoch=729
05/16/2022 14:21:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.82 on epoch=732
05/16/2022 14:21:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.87 on epoch=734
05/16/2022 14:21:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.88 on epoch=737
05/16/2022 14:21:26 - INFO - __main__ - Global step 2950 Train loss 0.87 Classification-F1 0.15 on epoch=737
05/16/2022 14:21:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.81 on epoch=739
05/16/2022 14:21:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.90 on epoch=742
05/16/2022 14:21:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.90 on epoch=744
05/16/2022 14:21:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.92 on epoch=747
05/16/2022 14:21:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.87 on epoch=749
05/16/2022 14:21:33 - INFO - __main__ - Global step 3000 Train loss 0.88 Classification-F1 0.17569930069930068 on epoch=749
05/16/2022 14:21:33 - INFO - __main__ - save last model!
05/16/2022 14:21:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 14:21:33 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 14:21:33 - INFO - __main__ - Printing 3 examples
05/16/2022 14:21:33 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 14:21:33 - INFO - __main__ - ['others']
05/16/2022 14:21:33 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 14:21:33 - INFO - __main__ - ['others']
05/16/2022 14:21:33 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 14:21:33 - INFO - __main__ - ['others']
05/16/2022 14:21:33 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:21:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:21:34 - INFO - __main__ - Printing 3 examples
05/16/2022 14:21:34 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:21:34 - INFO - __main__ - ['others']
05/16/2022 14:21:34 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:21:34 - INFO - __main__ - ['others']
05/16/2022 14:21:34 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:21:34 - INFO - __main__ - ['others']
05/16/2022 14:21:34 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:21:34 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:21:34 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:21:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:21:34 - INFO - __main__ - Printing 3 examples
05/16/2022 14:21:34 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:21:34 - INFO - __main__ - ['others']
05/16/2022 14:21:34 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:21:34 - INFO - __main__ - ['others']
05/16/2022 14:21:34 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:21:34 - INFO - __main__ - ['others']
05/16/2022 14:21:34 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:21:34 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:21:34 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:21:36 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:21:41 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:21:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:21:41 - INFO - __main__ - Starting training!
05/16/2022 14:21:41 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 14:22:28 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.5_8_predictions.txt
05/16/2022 14:22:28 - INFO - __main__ - Classification-F1 on test data: 0.0473
05/16/2022 14:22:28 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.2505484861781483, test_performance=0.04729741568112133
05/16/2022 14:22:28 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
05/16/2022 14:22:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:22:29 - INFO - __main__ - Printing 3 examples
05/16/2022 14:22:29 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:22:29 - INFO - __main__ - ['others']
05/16/2022 14:22:29 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:22:29 - INFO - __main__ - ['others']
05/16/2022 14:22:29 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:22:29 - INFO - __main__ - ['others']
05/16/2022 14:22:29 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:22:29 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:22:29 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:22:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:22:29 - INFO - __main__ - Printing 3 examples
05/16/2022 14:22:29 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:22:29 - INFO - __main__ - ['others']
05/16/2022 14:22:29 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:22:29 - INFO - __main__ - ['others']
05/16/2022 14:22:29 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:22:29 - INFO - __main__ - ['others']
05/16/2022 14:22:29 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:22:29 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:22:29 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:22:36 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:22:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:22:36 - INFO - __main__ - Starting training!
05/16/2022 14:22:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.76 on epoch=2
05/16/2022 14:22:39 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/16/2022 14:22:40 - INFO - __main__ - Step 30 Global step 30 Train loss 6.22 on epoch=7
05/16/2022 14:22:42 - INFO - __main__ - Step 40 Global step 40 Train loss 6.03 on epoch=9
05/16/2022 14:22:43 - INFO - __main__ - Step 50 Global step 50 Train loss 5.81 on epoch=12
05/16/2022 14:22:56 - INFO - __main__ - Global step 50 Train loss 6.28 Classification-F1 0.0 on epoch=12
05/16/2022 14:22:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 14:22:58 - INFO - __main__ - Step 60 Global step 60 Train loss 5.64 on epoch=14
05/16/2022 14:22:59 - INFO - __main__ - Step 70 Global step 70 Train loss 5.56 on epoch=17
05/16/2022 14:23:01 - INFO - __main__ - Step 80 Global step 80 Train loss 5.44 on epoch=19
05/16/2022 14:23:02 - INFO - __main__ - Step 90 Global step 90 Train loss 5.10 on epoch=22
05/16/2022 14:23:04 - INFO - __main__ - Step 100 Global step 100 Train loss 4.90 on epoch=24
05/16/2022 14:23:05 - INFO - __main__ - Global step 100 Train loss 5.33 Classification-F1 0.009049773755656108 on epoch=24
05/16/2022 14:23:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009049773755656108 on epoch=24, global_step=100
05/16/2022 14:23:06 - INFO - __main__ - Step 110 Global step 110 Train loss 4.73 on epoch=27
05/16/2022 14:23:07 - INFO - __main__ - Step 120 Global step 120 Train loss 4.50 on epoch=29
05/16/2022 14:23:09 - INFO - __main__ - Step 130 Global step 130 Train loss 4.27 on epoch=32
05/16/2022 14:23:10 - INFO - __main__ - Step 140 Global step 140 Train loss 4.05 on epoch=34
05/16/2022 14:23:12 - INFO - __main__ - Step 150 Global step 150 Train loss 3.85 on epoch=37
05/16/2022 14:23:12 - INFO - __main__ - Global step 150 Train loss 4.28 Classification-F1 0.08421052631578949 on epoch=37
05/16/2022 14:23:12 - INFO - __main__ - Saving model with best Classification-F1: 0.009049773755656108 -> 0.08421052631578949 on epoch=37, global_step=150
05/16/2022 14:23:13 - INFO - __main__ - Step 160 Global step 160 Train loss 3.71 on epoch=39
05/16/2022 14:23:15 - INFO - __main__ - Step 170 Global step 170 Train loss 3.72 on epoch=42
05/16/2022 14:23:16 - INFO - __main__ - Step 180 Global step 180 Train loss 3.40 on epoch=44
05/16/2022 14:23:18 - INFO - __main__ - Step 190 Global step 190 Train loss 3.07 on epoch=47
05/16/2022 14:23:19 - INFO - __main__ - Step 200 Global step 200 Train loss 3.10 on epoch=49
05/16/2022 14:23:20 - INFO - __main__ - Global step 200 Train loss 3.40 Classification-F1 0.1237183868762816 on epoch=49
05/16/2022 14:23:20 - INFO - __main__ - Saving model with best Classification-F1: 0.08421052631578949 -> 0.1237183868762816 on epoch=49, global_step=200
05/16/2022 14:23:21 - INFO - __main__ - Step 210 Global step 210 Train loss 2.93 on epoch=52
05/16/2022 14:23:23 - INFO - __main__ - Step 220 Global step 220 Train loss 2.85 on epoch=54
05/16/2022 14:23:24 - INFO - __main__ - Step 230 Global step 230 Train loss 2.78 on epoch=57
05/16/2022 14:23:26 - INFO - __main__ - Step 240 Global step 240 Train loss 2.58 on epoch=59
05/16/2022 14:23:27 - INFO - __main__ - Step 250 Global step 250 Train loss 2.58 on epoch=62
05/16/2022 14:23:28 - INFO - __main__ - Global step 250 Train loss 2.75 Classification-F1 0.09210526315789473 on epoch=62
05/16/2022 14:23:29 - INFO - __main__ - Step 260 Global step 260 Train loss 2.54 on epoch=64
05/16/2022 14:23:30 - INFO - __main__ - Step 270 Global step 270 Train loss 2.51 on epoch=67
05/16/2022 14:23:32 - INFO - __main__ - Step 280 Global step 280 Train loss 2.28 on epoch=69
05/16/2022 14:23:33 - INFO - __main__ - Step 290 Global step 290 Train loss 2.32 on epoch=72
05/16/2022 14:23:35 - INFO - __main__ - Step 300 Global step 300 Train loss 2.19 on epoch=74
05/16/2022 14:23:35 - INFO - __main__ - Global step 300 Train loss 2.37 Classification-F1 0.1527777777777778 on epoch=74
05/16/2022 14:23:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1237183868762816 -> 0.1527777777777778 on epoch=74, global_step=300
05/16/2022 14:23:36 - INFO - __main__ - Step 310 Global step 310 Train loss 2.51 on epoch=77
05/16/2022 14:23:38 - INFO - __main__ - Step 320 Global step 320 Train loss 2.28 on epoch=79
05/16/2022 14:23:39 - INFO - __main__ - Step 330 Global step 330 Train loss 2.18 on epoch=82
05/16/2022 14:23:41 - INFO - __main__ - Step 340 Global step 340 Train loss 2.01 on epoch=84
05/16/2022 14:23:42 - INFO - __main__ - Step 350 Global step 350 Train loss 2.17 on epoch=87
05/16/2022 14:23:43 - INFO - __main__ - Global step 350 Train loss 2.23 Classification-F1 0.1565276828434723 on epoch=87
05/16/2022 14:23:43 - INFO - __main__ - Saving model with best Classification-F1: 0.1527777777777778 -> 0.1565276828434723 on epoch=87, global_step=350
05/16/2022 14:23:44 - INFO - __main__ - Step 360 Global step 360 Train loss 2.00 on epoch=89
05/16/2022 14:23:46 - INFO - __main__ - Step 370 Global step 370 Train loss 1.95 on epoch=92
05/16/2022 14:23:47 - INFO - __main__ - Step 380 Global step 380 Train loss 1.95 on epoch=94
05/16/2022 14:23:49 - INFO - __main__ - Step 390 Global step 390 Train loss 1.97 on epoch=97
05/16/2022 14:23:50 - INFO - __main__ - Step 400 Global step 400 Train loss 1.79 on epoch=99
05/16/2022 14:23:51 - INFO - __main__ - Global step 400 Train loss 1.93 Classification-F1 0.10234192037470727 on epoch=99
05/16/2022 14:23:52 - INFO - __main__ - Step 410 Global step 410 Train loss 1.96 on epoch=102
05/16/2022 14:23:54 - INFO - __main__ - Step 420 Global step 420 Train loss 1.77 on epoch=104
05/16/2022 14:23:55 - INFO - __main__ - Step 430 Global step 430 Train loss 1.88 on epoch=107
05/16/2022 14:23:56 - INFO - __main__ - Step 440 Global step 440 Train loss 1.66 on epoch=109
05/16/2022 14:23:58 - INFO - __main__ - Step 450 Global step 450 Train loss 1.73 on epoch=112
05/16/2022 14:23:58 - INFO - __main__ - Global step 450 Train loss 1.80 Classification-F1 0.16969147005444646 on epoch=112
05/16/2022 14:23:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.16969147005444646 on epoch=112, global_step=450
05/16/2022 14:24:00 - INFO - __main__ - Step 460 Global step 460 Train loss 1.53 on epoch=114
05/16/2022 14:24:01 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=117
05/16/2022 14:24:02 - INFO - __main__ - Step 480 Global step 480 Train loss 1.63 on epoch=119
05/16/2022 14:24:04 - INFO - __main__ - Step 490 Global step 490 Train loss 1.67 on epoch=122
05/16/2022 14:24:05 - INFO - __main__ - Step 500 Global step 500 Train loss 1.67 on epoch=124
05/16/2022 14:24:06 - INFO - __main__ - Global step 500 Train loss 1.64 Classification-F1 0.1 on epoch=124
05/16/2022 14:24:07 - INFO - __main__ - Step 510 Global step 510 Train loss 1.60 on epoch=127
05/16/2022 14:24:08 - INFO - __main__ - Step 520 Global step 520 Train loss 1.44 on epoch=129
05/16/2022 14:24:10 - INFO - __main__ - Step 530 Global step 530 Train loss 1.67 on epoch=132
05/16/2022 14:24:11 - INFO - __main__ - Step 540 Global step 540 Train loss 1.56 on epoch=134
05/16/2022 14:24:13 - INFO - __main__ - Step 550 Global step 550 Train loss 1.42 on epoch=137
05/16/2022 14:24:13 - INFO - __main__ - Global step 550 Train loss 1.54 Classification-F1 0.18643263757115752 on epoch=137
05/16/2022 14:24:13 - INFO - __main__ - Saving model with best Classification-F1: 0.16969147005444646 -> 0.18643263757115752 on epoch=137, global_step=550
05/16/2022 14:24:15 - INFO - __main__ - Step 560 Global step 560 Train loss 1.46 on epoch=139
05/16/2022 14:24:16 - INFO - __main__ - Step 570 Global step 570 Train loss 1.45 on epoch=142
05/16/2022 14:24:18 - INFO - __main__ - Step 580 Global step 580 Train loss 1.40 on epoch=144
05/16/2022 14:24:19 - INFO - __main__ - Step 590 Global step 590 Train loss 1.39 on epoch=147
05/16/2022 14:24:21 - INFO - __main__ - Step 600 Global step 600 Train loss 1.39 on epoch=149
05/16/2022 14:24:21 - INFO - __main__ - Global step 600 Train loss 1.42 Classification-F1 0.1 on epoch=149
05/16/2022 14:24:23 - INFO - __main__ - Step 610 Global step 610 Train loss 1.44 on epoch=152
05/16/2022 14:24:24 - INFO - __main__ - Step 620 Global step 620 Train loss 1.27 on epoch=154
05/16/2022 14:24:26 - INFO - __main__ - Step 630 Global step 630 Train loss 1.33 on epoch=157
05/16/2022 14:24:27 - INFO - __main__ - Step 640 Global step 640 Train loss 1.23 on epoch=159
05/16/2022 14:24:29 - INFO - __main__ - Step 650 Global step 650 Train loss 1.38 on epoch=162
05/16/2022 14:24:29 - INFO - __main__ - Global step 650 Train loss 1.33 Classification-F1 0.10126582278481013 on epoch=162
05/16/2022 14:24:30 - INFO - __main__ - Step 660 Global step 660 Train loss 1.32 on epoch=164
05/16/2022 14:24:32 - INFO - __main__ - Step 670 Global step 670 Train loss 1.29 on epoch=167
05/16/2022 14:24:33 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=169
05/16/2022 14:24:34 - INFO - __main__ - Step 690 Global step 690 Train loss 1.29 on epoch=172
05/16/2022 14:24:36 - INFO - __main__ - Step 700 Global step 700 Train loss 1.29 on epoch=174
05/16/2022 14:24:36 - INFO - __main__ - Global step 700 Train loss 1.29 Classification-F1 0.12399355877616748 on epoch=174
05/16/2022 14:24:38 - INFO - __main__ - Step 710 Global step 710 Train loss 1.35 on epoch=177
05/16/2022 14:24:39 - INFO - __main__ - Step 720 Global step 720 Train loss 1.23 on epoch=179
05/16/2022 14:24:40 - INFO - __main__ - Step 730 Global step 730 Train loss 1.19 on epoch=182
05/16/2022 14:24:42 - INFO - __main__ - Step 740 Global step 740 Train loss 1.20 on epoch=184
05/16/2022 14:24:43 - INFO - __main__ - Step 750 Global step 750 Train loss 1.22 on epoch=187
05/16/2022 14:24:44 - INFO - __main__ - Global step 750 Train loss 1.24 Classification-F1 0.177928916191312 on epoch=187
05/16/2022 14:24:45 - INFO - __main__ - Step 760 Global step 760 Train loss 1.27 on epoch=189
05/16/2022 14:24:46 - INFO - __main__ - Step 770 Global step 770 Train loss 1.29 on epoch=192
05/16/2022 14:24:48 - INFO - __main__ - Step 780 Global step 780 Train loss 1.16 on epoch=194
05/16/2022 14:24:50 - INFO - __main__ - Step 790 Global step 790 Train loss 1.06 on epoch=197
05/16/2022 14:24:51 - INFO - __main__ - Step 800 Global step 800 Train loss 1.19 on epoch=199
05/16/2022 14:24:52 - INFO - __main__ - Global step 800 Train loss 1.19 Classification-F1 0.09999999999999999 on epoch=199
05/16/2022 14:24:53 - INFO - __main__ - Step 810 Global step 810 Train loss 1.18 on epoch=202
05/16/2022 14:24:55 - INFO - __main__ - Step 820 Global step 820 Train loss 1.18 on epoch=204
05/16/2022 14:24:56 - INFO - __main__ - Step 830 Global step 830 Train loss 1.11 on epoch=207
05/16/2022 14:24:57 - INFO - __main__ - Step 840 Global step 840 Train loss 1.14 on epoch=209
05/16/2022 14:24:59 - INFO - __main__ - Step 850 Global step 850 Train loss 1.17 on epoch=212
05/16/2022 14:24:59 - INFO - __main__ - Global step 850 Train loss 1.16 Classification-F1 0.08571428571428572 on epoch=212
05/16/2022 14:25:01 - INFO - __main__ - Step 860 Global step 860 Train loss 1.02 on epoch=214
05/16/2022 14:25:02 - INFO - __main__ - Step 870 Global step 870 Train loss 1.36 on epoch=217
05/16/2022 14:25:03 - INFO - __main__ - Step 880 Global step 880 Train loss 1.14 on epoch=219
05/16/2022 14:25:05 - INFO - __main__ - Step 890 Global step 890 Train loss 1.23 on epoch=222
05/16/2022 14:25:06 - INFO - __main__ - Step 900 Global step 900 Train loss 1.16 on epoch=224
05/16/2022 14:25:07 - INFO - __main__ - Global step 900 Train loss 1.18 Classification-F1 0.13333333333333333 on epoch=224
05/16/2022 14:25:08 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/16/2022 14:25:09 - INFO - __main__ - Step 920 Global step 920 Train loss 1.10 on epoch=229
05/16/2022 14:25:11 - INFO - __main__ - Step 930 Global step 930 Train loss 1.17 on epoch=232
05/16/2022 14:25:12 - INFO - __main__ - Step 940 Global step 940 Train loss 1.17 on epoch=234
05/16/2022 14:25:14 - INFO - __main__ - Step 950 Global step 950 Train loss 1.25 on epoch=237
05/16/2022 14:25:14 - INFO - __main__ - Global step 950 Train loss 1.18 Classification-F1 0.2277777777777778 on epoch=237
05/16/2022 14:25:15 - INFO - __main__ - Saving model with best Classification-F1: 0.18643263757115752 -> 0.2277777777777778 on epoch=237, global_step=950
05/16/2022 14:25:16 - INFO - __main__ - Step 960 Global step 960 Train loss 1.08 on epoch=239
05/16/2022 14:25:18 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=242
05/16/2022 14:25:19 - INFO - __main__ - Step 980 Global step 980 Train loss 1.21 on epoch=244
05/16/2022 14:25:20 - INFO - __main__ - Step 990 Global step 990 Train loss 1.04 on epoch=247
05/16/2022 14:25:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.06 on epoch=249
05/16/2022 14:25:22 - INFO - __main__ - Global step 1000 Train loss 1.11 Classification-F1 0.09493670886075949 on epoch=249
05/16/2022 14:25:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.07 on epoch=252
05/16/2022 14:25:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.10 on epoch=254
05/16/2022 14:25:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/16/2022 14:25:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=259
05/16/2022 14:25:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.10 on epoch=262
05/16/2022 14:25:30 - INFO - __main__ - Global step 1050 Train loss 1.09 Classification-F1 0.1575757575757576 on epoch=262
05/16/2022 14:25:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.10 on epoch=264
05/16/2022 14:25:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=267
05/16/2022 14:25:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/16/2022 14:25:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.21 on epoch=272
05/16/2022 14:25:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
05/16/2022 14:25:38 - INFO - __main__ - Global step 1100 Train loss 1.14 Classification-F1 0.12447885646217988 on epoch=274
05/16/2022 14:25:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.12 on epoch=277
05/16/2022 14:25:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.98 on epoch=279
05/16/2022 14:25:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=282
05/16/2022 14:25:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.10 on epoch=284
05/16/2022 14:25:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.09 on epoch=287
05/16/2022 14:25:46 - INFO - __main__ - Global step 1150 Train loss 1.06 Classification-F1 0.13427800269905532 on epoch=287
05/16/2022 14:25:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.11 on epoch=289
05/16/2022 14:25:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.20 on epoch=292
05/16/2022 14:25:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/16/2022 14:25:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.12 on epoch=297
05/16/2022 14:25:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.05 on epoch=299
05/16/2022 14:25:54 - INFO - __main__ - Global step 1200 Train loss 1.13 Classification-F1 0.1 on epoch=299
05/16/2022 14:25:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.18 on epoch=302
05/16/2022 14:25:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.05 on epoch=304
05/16/2022 14:25:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.10 on epoch=307
05/16/2022 14:26:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
05/16/2022 14:26:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=312
05/16/2022 14:26:02 - INFO - __main__ - Global step 1250 Train loss 1.10 Classification-F1 0.1 on epoch=312
05/16/2022 14:26:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.11 on epoch=314
05/16/2022 14:26:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.17 on epoch=317
05/16/2022 14:26:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.01 on epoch=319
05/16/2022 14:26:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.01 on epoch=322
05/16/2022 14:26:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.14 on epoch=324
05/16/2022 14:26:09 - INFO - __main__ - Global step 1300 Train loss 1.09 Classification-F1 0.13154929577464788 on epoch=324
05/16/2022 14:26:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
05/16/2022 14:26:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.12 on epoch=329
05/16/2022 14:26:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.08 on epoch=332
05/16/2022 14:26:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.95 on epoch=334
05/16/2022 14:26:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.08 on epoch=337
05/16/2022 14:26:17 - INFO - __main__ - Global step 1350 Train loss 1.05 Classification-F1 0.19821428571428573 on epoch=337
05/16/2022 14:26:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.10 on epoch=339
05/16/2022 14:26:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.07 on epoch=342
05/16/2022 14:26:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.02 on epoch=344
05/16/2022 14:26:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
05/16/2022 14:26:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.90 on epoch=349
05/16/2022 14:26:24 - INFO - __main__ - Global step 1400 Train loss 1.05 Classification-F1 0.1774628879892038 on epoch=349
05/16/2022 14:26:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.13 on epoch=352
05/16/2022 14:26:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.94 on epoch=354
05/16/2022 14:26:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.97 on epoch=357
05/16/2022 14:26:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.05 on epoch=359
05/16/2022 14:26:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.07 on epoch=362
05/16/2022 14:26:32 - INFO - __main__ - Global step 1450 Train loss 1.03 Classification-F1 0.14913151364764268 on epoch=362
05/16/2022 14:26:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=364
05/16/2022 14:26:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.98 on epoch=367
05/16/2022 14:26:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
05/16/2022 14:26:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.96 on epoch=372
05/16/2022 14:26:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.06 on epoch=374
05/16/2022 14:26:39 - INFO - __main__ - Global step 1500 Train loss 1.01 Classification-F1 0.13123993558776167 on epoch=374
05/16/2022 14:26:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
05/16/2022 14:26:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/16/2022 14:26:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.04 on epoch=382
05/16/2022 14:26:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.97 on epoch=384
05/16/2022 14:26:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.99 on epoch=387
05/16/2022 14:26:48 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.13482414242292662 on epoch=387
05/16/2022 14:26:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.07 on epoch=389
05/16/2022 14:26:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.01 on epoch=392
05/16/2022 14:26:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.06 on epoch=394
05/16/2022 14:26:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.01 on epoch=397
05/16/2022 14:26:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.97 on epoch=399
05/16/2022 14:26:56 - INFO - __main__ - Global step 1600 Train loss 1.02 Classification-F1 0.16563380281690143 on epoch=399
05/16/2022 14:26:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=402
05/16/2022 14:26:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.89 on epoch=404
05/16/2022 14:27:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.12 on epoch=407
05/16/2022 14:27:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.00 on epoch=409
05/16/2022 14:27:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.03 on epoch=412
05/16/2022 14:27:04 - INFO - __main__ - Global step 1650 Train loss 1.01 Classification-F1 0.17712418300653593 on epoch=412
05/16/2022 14:27:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.89 on epoch=414
05/16/2022 14:27:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.91 on epoch=417
05/16/2022 14:27:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.10 on epoch=419
05/16/2022 14:27:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.94 on epoch=422
05/16/2022 14:27:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.06 on epoch=424
05/16/2022 14:27:11 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.14600840336134455 on epoch=424
05/16/2022 14:27:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.02 on epoch=427
05/16/2022 14:27:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.85 on epoch=429
05/16/2022 14:27:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.03 on epoch=432
05/16/2022 14:27:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.97 on epoch=434
05/16/2022 14:27:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.98 on epoch=437
05/16/2022 14:27:19 - INFO - __main__ - Global step 1750 Train loss 0.97 Classification-F1 0.16137566137566137 on epoch=437
05/16/2022 14:27:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.99 on epoch=439
05/16/2022 14:27:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/16/2022 14:27:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.86 on epoch=444
05/16/2022 14:27:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.93 on epoch=447
05/16/2022 14:27:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
05/16/2022 14:27:27 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.15587044534412953 on epoch=449
05/16/2022 14:27:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.02 on epoch=452
05/16/2022 14:27:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.02 on epoch=454
05/16/2022 14:27:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.98 on epoch=457
05/16/2022 14:27:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=459
05/16/2022 14:27:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/16/2022 14:27:34 - INFO - __main__ - Global step 1850 Train loss 1.02 Classification-F1 0.15682382133995038 on epoch=462
05/16/2022 14:27:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/16/2022 14:27:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=467
05/16/2022 14:27:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
05/16/2022 14:27:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/16/2022 14:27:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.95 on epoch=474
05/16/2022 14:27:42 - INFO - __main__ - Global step 1900 Train loss 0.95 Classification-F1 0.12447885646217988 on epoch=474
05/16/2022 14:27:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/16/2022 14:27:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.08 on epoch=479
05/16/2022 14:27:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.95 on epoch=482
05/16/2022 14:27:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/16/2022 14:27:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.09 on epoch=487
05/16/2022 14:27:49 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.20833333333333331 on epoch=487
05/16/2022 14:27:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.89 on epoch=489
05/16/2022 14:27:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=492
05/16/2022 14:27:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.96 on epoch=494
05/16/2022 14:27:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.01 on epoch=497
05/16/2022 14:27:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.91 on epoch=499
05/16/2022 14:27:56 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.13034188034188032 on epoch=499
05/16/2022 14:27:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.90 on epoch=502
05/16/2022 14:27:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.99 on epoch=504
05/16/2022 14:28:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.08 on epoch=507
05/16/2022 14:28:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.92 on epoch=509
05/16/2022 14:28:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.09 on epoch=512
05/16/2022 14:28:04 - INFO - __main__ - Global step 2050 Train loss 1.00 Classification-F1 0.09333333333333334 on epoch=512
05/16/2022 14:28:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.04 on epoch=514
05/16/2022 14:28:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.98 on epoch=517
05/16/2022 14:28:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.94 on epoch=519
05/16/2022 14:28:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.92 on epoch=522
05/16/2022 14:28:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/16/2022 14:28:11 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.09482363719651855 on epoch=524
05/16/2022 14:28:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.86 on epoch=527
05/16/2022 14:28:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
05/16/2022 14:28:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/16/2022 14:28:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.90 on epoch=534
05/16/2022 14:28:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.95 on epoch=537
05/16/2022 14:28:19 - INFO - __main__ - Global step 2150 Train loss 0.94 Classification-F1 0.10126582278481013 on epoch=537
05/16/2022 14:28:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
05/16/2022 14:28:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.87 on epoch=542
05/16/2022 14:28:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.92 on epoch=544
05/16/2022 14:28:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.95 on epoch=547
05/16/2022 14:28:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.03 on epoch=549
05/16/2022 14:28:27 - INFO - __main__ - Global step 2200 Train loss 0.94 Classification-F1 0.09615384615384615 on epoch=549
05/16/2022 14:28:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.04 on epoch=552
05/16/2022 14:28:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.89 on epoch=554
05/16/2022 14:28:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=557
05/16/2022 14:28:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.95 on epoch=559
05/16/2022 14:28:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.04 on epoch=562
05/16/2022 14:28:34 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.13251935675997617 on epoch=562
05/16/2022 14:28:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.86 on epoch=564
05/16/2022 14:28:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.91 on epoch=567
05/16/2022 14:28:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/16/2022 14:28:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
05/16/2022 14:28:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.03 on epoch=574
05/16/2022 14:28:41 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.09391534391534392 on epoch=574
05/16/2022 14:28:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/16/2022 14:28:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.92 on epoch=579
05/16/2022 14:28:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.04 on epoch=582
05/16/2022 14:28:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/16/2022 14:28:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.05 on epoch=587
05/16/2022 14:28:48 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.18614718614718614 on epoch=587
05/16/2022 14:28:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.91 on epoch=589
05/16/2022 14:28:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/16/2022 14:28:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.93 on epoch=594
05/16/2022 14:28:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.01 on epoch=597
05/16/2022 14:28:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.84 on epoch=599
05/16/2022 14:28:55 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.15188470066518847 on epoch=599
05/16/2022 14:28:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/16/2022 14:28:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/16/2022 14:28:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.98 on epoch=607
05/16/2022 14:29:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.94 on epoch=609
05/16/2022 14:29:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.95 on epoch=612
05/16/2022 14:29:02 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.15306730196545562 on epoch=612
05/16/2022 14:29:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.90 on epoch=614
05/16/2022 14:29:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/16/2022 14:29:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.91 on epoch=619
05/16/2022 14:29:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.91 on epoch=622
05/16/2022 14:29:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.90 on epoch=624
05/16/2022 14:29:10 - INFO - __main__ - Global step 2500 Train loss 0.93 Classification-F1 0.09493670886075949 on epoch=624
05/16/2022 14:29:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=627
05/16/2022 14:29:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.93 on epoch=629
05/16/2022 14:29:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.92 on epoch=632
05/16/2022 14:29:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.90 on epoch=634
05/16/2022 14:29:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
05/16/2022 14:29:17 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.1486842105263158 on epoch=637
05/16/2022 14:29:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.86 on epoch=639
05/16/2022 14:29:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.84 on epoch=642
05/16/2022 14:29:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.86 on epoch=644
05/16/2022 14:29:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/16/2022 14:29:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.88 on epoch=649
05/16/2022 14:29:24 - INFO - __main__ - Global step 2600 Train loss 0.89 Classification-F1 0.09285714285714285 on epoch=649
05/16/2022 14:29:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.07 on epoch=652
05/16/2022 14:29:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.87 on epoch=654
05/16/2022 14:29:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.87 on epoch=657
05/16/2022 14:29:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
05/16/2022 14:29:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/16/2022 14:29:31 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.15306730196545562 on epoch=662
05/16/2022 14:29:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.08 on epoch=664
05/16/2022 14:29:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/16/2022 14:29:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
05/16/2022 14:29:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.99 on epoch=672
05/16/2022 14:29:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/16/2022 14:29:39 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.1458966565349544 on epoch=674
05/16/2022 14:29:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/16/2022 14:29:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.86 on epoch=679
05/16/2022 14:29:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/16/2022 14:29:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.91 on epoch=684
05/16/2022 14:29:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.92 on epoch=687
05/16/2022 14:29:46 - INFO - __main__ - Global step 2750 Train loss 0.91 Classification-F1 0.18623481781376516 on epoch=687
05/16/2022 14:29:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
05/16/2022 14:29:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
05/16/2022 14:29:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.86 on epoch=694
05/16/2022 14:29:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
05/16/2022 14:29:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.86 on epoch=699
05/16/2022 14:29:53 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.10023419203747073 on epoch=699
05/16/2022 14:29:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.86 on epoch=702
05/16/2022 14:29:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/16/2022 14:29:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.05 on epoch=707
05/16/2022 14:29:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.84 on epoch=709
05/16/2022 14:30:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=712
05/16/2022 14:30:01 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.13859154929577466 on epoch=712
05/16/2022 14:30:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.92 on epoch=714
05/16/2022 14:30:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.97 on epoch=717
05/16/2022 14:30:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/16/2022 14:30:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.91 on epoch=722
05/16/2022 14:30:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
05/16/2022 14:30:08 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.16923774954627951 on epoch=724
05/16/2022 14:30:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.96 on epoch=727
05/16/2022 14:30:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.97 on epoch=729
05/16/2022 14:30:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
05/16/2022 14:30:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.00 on epoch=734
05/16/2022 14:30:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.79 on epoch=737
05/16/2022 14:30:16 - INFO - __main__ - Global step 2950 Train loss 0.92 Classification-F1 0.11805555555555555 on epoch=737
05/16/2022 14:30:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.06 on epoch=739
05/16/2022 14:30:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.85 on epoch=742
05/16/2022 14:30:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.92 on epoch=744
05/16/2022 14:30:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.87 on epoch=747
05/16/2022 14:30:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.81 on epoch=749
05/16/2022 14:30:23 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.12521739130434784 on epoch=749
05/16/2022 14:30:23 - INFO - __main__ - save last model!
05/16/2022 14:30:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 14:30:24 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 14:30:24 - INFO - __main__ - Printing 3 examples
05/16/2022 14:30:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:30:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:30:24 - INFO - __main__ - Printing 3 examples
05/16/2022 14:30:24 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:30:24 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:30:24 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:30:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:30:24 - INFO - __main__ - Printing 3 examples
05/16/2022 14:30:24 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:30:24 - INFO - __main__ - ['others']
05/16/2022 14:30:24 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:30:24 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:30:24 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:30:26 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:30:30 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:30:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:30:30 - INFO - __main__ - Starting training!
05/16/2022 14:30:31 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 14:31:16 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.4_8_predictions.txt
05/16/2022 14:31:16 - INFO - __main__ - Classification-F1 on test data: 0.0438
05/16/2022 14:31:17 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.2277777777777778, test_performance=0.043761291883696464
05/16/2022 14:31:17 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
05/16/2022 14:31:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:31:18 - INFO - __main__ - Printing 3 examples
05/16/2022 14:31:18 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:31:18 - INFO - __main__ - ['others']
05/16/2022 14:31:18 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:31:18 - INFO - __main__ - ['others']
05/16/2022 14:31:18 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:31:18 - INFO - __main__ - ['others']
05/16/2022 14:31:18 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:31:18 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:31:18 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:31:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:31:18 - INFO - __main__ - Printing 3 examples
05/16/2022 14:31:18 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:31:18 - INFO - __main__ - ['others']
05/16/2022 14:31:18 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:31:18 - INFO - __main__ - ['others']
05/16/2022 14:31:18 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:31:18 - INFO - __main__ - ['others']
05/16/2022 14:31:18 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:31:18 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:31:18 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:31:24 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:31:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:31:24 - INFO - __main__ - Starting training!
05/16/2022 14:31:26 - INFO - __main__ - Step 10 Global step 10 Train loss 6.95 on epoch=2
05/16/2022 14:31:27 - INFO - __main__ - Step 20 Global step 20 Train loss 6.55 on epoch=4
05/16/2022 14:31:29 - INFO - __main__ - Step 30 Global step 30 Train loss 6.14 on epoch=7
05/16/2022 14:31:30 - INFO - __main__ - Step 40 Global step 40 Train loss 6.17 on epoch=9
05/16/2022 14:31:31 - INFO - __main__ - Step 50 Global step 50 Train loss 5.94 on epoch=12
05/16/2022 14:31:33 - INFO - __main__ - Global step 50 Train loss 6.35 Classification-F1 0.0 on epoch=12
05/16/2022 14:31:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 14:31:35 - INFO - __main__ - Step 60 Global step 60 Train loss 5.78 on epoch=14
05/16/2022 14:31:36 - INFO - __main__ - Step 70 Global step 70 Train loss 5.65 on epoch=17
05/16/2022 14:31:37 - INFO - __main__ - Step 80 Global step 80 Train loss 5.50 on epoch=19
05/16/2022 14:31:39 - INFO - __main__ - Step 90 Global step 90 Train loss 5.36 on epoch=22
05/16/2022 14:31:40 - INFO - __main__ - Step 100 Global step 100 Train loss 5.17 on epoch=24
05/16/2022 14:31:42 - INFO - __main__ - Global step 100 Train loss 5.49 Classification-F1 0.0 on epoch=24
05/16/2022 14:31:44 - INFO - __main__ - Step 110 Global step 110 Train loss 5.02 on epoch=27
05/16/2022 14:31:45 - INFO - __main__ - Step 120 Global step 120 Train loss 5.06 on epoch=29
05/16/2022 14:31:46 - INFO - __main__ - Step 130 Global step 130 Train loss 4.80 on epoch=32
05/16/2022 14:31:48 - INFO - __main__ - Step 140 Global step 140 Train loss 4.65 on epoch=34
05/16/2022 14:31:49 - INFO - __main__ - Step 150 Global step 150 Train loss 4.62 on epoch=37
05/16/2022 14:31:50 - INFO - __main__ - Global step 150 Train loss 4.83 Classification-F1 0.03214285714285714 on epoch=37
05/16/2022 14:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03214285714285714 on epoch=37, global_step=150
05/16/2022 14:31:52 - INFO - __main__ - Step 160 Global step 160 Train loss 4.34 on epoch=39
05/16/2022 14:31:53 - INFO - __main__ - Step 170 Global step 170 Train loss 4.31 on epoch=42
05/16/2022 14:31:55 - INFO - __main__ - Step 180 Global step 180 Train loss 4.13 on epoch=44
05/16/2022 14:31:56 - INFO - __main__ - Step 190 Global step 190 Train loss 4.19 on epoch=47
05/16/2022 14:31:58 - INFO - __main__ - Step 200 Global step 200 Train loss 4.07 on epoch=49
05/16/2022 14:31:58 - INFO - __main__ - Global step 200 Train loss 4.21 Classification-F1 0.16666666666666666 on epoch=49
05/16/2022 14:31:58 - INFO - __main__ - Saving model with best Classification-F1: 0.03214285714285714 -> 0.16666666666666666 on epoch=49, global_step=200
05/16/2022 14:31:59 - INFO - __main__ - Step 210 Global step 210 Train loss 4.01 on epoch=52
05/16/2022 14:32:01 - INFO - __main__ - Step 220 Global step 220 Train loss 3.76 on epoch=54
05/16/2022 14:32:02 - INFO - __main__ - Step 230 Global step 230 Train loss 3.65 on epoch=57
05/16/2022 14:32:03 - INFO - __main__ - Step 240 Global step 240 Train loss 3.55 on epoch=59
05/16/2022 14:32:05 - INFO - __main__ - Step 250 Global step 250 Train loss 3.40 on epoch=62
05/16/2022 14:32:05 - INFO - __main__ - Global step 250 Train loss 3.67 Classification-F1 0.09333333333333334 on epoch=62
05/16/2022 14:32:07 - INFO - __main__ - Step 260 Global step 260 Train loss 3.50 on epoch=64
05/16/2022 14:32:08 - INFO - __main__ - Step 270 Global step 270 Train loss 3.47 on epoch=67
05/16/2022 14:32:09 - INFO - __main__ - Step 280 Global step 280 Train loss 3.13 on epoch=69
05/16/2022 14:32:11 - INFO - __main__ - Step 290 Global step 290 Train loss 3.28 on epoch=72
05/16/2022 14:32:12 - INFO - __main__ - Step 300 Global step 300 Train loss 3.00 on epoch=74
05/16/2022 14:32:13 - INFO - __main__ - Global step 300 Train loss 3.28 Classification-F1 0.11507936507936507 on epoch=74
05/16/2022 14:32:14 - INFO - __main__ - Step 310 Global step 310 Train loss 3.09 on epoch=77
05/16/2022 14:32:15 - INFO - __main__ - Step 320 Global step 320 Train loss 2.96 on epoch=79
05/16/2022 14:32:17 - INFO - __main__ - Step 330 Global step 330 Train loss 3.06 on epoch=82
05/16/2022 14:32:18 - INFO - __main__ - Step 340 Global step 340 Train loss 2.88 on epoch=84
05/16/2022 14:32:19 - INFO - __main__ - Step 350 Global step 350 Train loss 2.76 on epoch=87
05/16/2022 14:32:20 - INFO - __main__ - Global step 350 Train loss 2.95 Classification-F1 0.14383875400824553 on epoch=87
05/16/2022 14:32:21 - INFO - __main__ - Step 360 Global step 360 Train loss 2.76 on epoch=89
05/16/2022 14:32:22 - INFO - __main__ - Step 370 Global step 370 Train loss 2.83 on epoch=92
05/16/2022 14:32:24 - INFO - __main__ - Step 380 Global step 380 Train loss 2.71 on epoch=94
05/16/2022 14:32:25 - INFO - __main__ - Step 390 Global step 390 Train loss 2.70 on epoch=97
05/16/2022 14:32:26 - INFO - __main__ - Step 400 Global step 400 Train loss 2.60 on epoch=99
05/16/2022 14:32:27 - INFO - __main__ - Global step 400 Train loss 2.72 Classification-F1 0.1 on epoch=99
05/16/2022 14:32:28 - INFO - __main__ - Step 410 Global step 410 Train loss 2.69 on epoch=102
05/16/2022 14:32:30 - INFO - __main__ - Step 420 Global step 420 Train loss 2.57 on epoch=104
05/16/2022 14:32:31 - INFO - __main__ - Step 430 Global step 430 Train loss 2.54 on epoch=107
05/16/2022 14:32:32 - INFO - __main__ - Step 440 Global step 440 Train loss 2.25 on epoch=109
05/16/2022 14:32:34 - INFO - __main__ - Step 450 Global step 450 Train loss 2.34 on epoch=112
05/16/2022 14:32:34 - INFO - __main__ - Global step 450 Train loss 2.48 Classification-F1 0.1 on epoch=112
05/16/2022 14:32:35 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=114
05/16/2022 14:32:37 - INFO - __main__ - Step 470 Global step 470 Train loss 2.38 on epoch=117
05/16/2022 14:32:38 - INFO - __main__ - Step 480 Global step 480 Train loss 2.24 on epoch=119
05/16/2022 14:32:40 - INFO - __main__ - Step 490 Global step 490 Train loss 2.23 on epoch=122
05/16/2022 14:32:41 - INFO - __main__ - Step 500 Global step 500 Train loss 2.16 on epoch=124
05/16/2022 14:32:41 - INFO - __main__ - Global step 500 Train loss 2.27 Classification-F1 0.1238095238095238 on epoch=124
05/16/2022 14:32:43 - INFO - __main__ - Step 510 Global step 510 Train loss 2.07 on epoch=127
05/16/2022 14:32:44 - INFO - __main__ - Step 520 Global step 520 Train loss 2.16 on epoch=129
05/16/2022 14:32:45 - INFO - __main__ - Step 530 Global step 530 Train loss 2.05 on epoch=132
05/16/2022 14:32:47 - INFO - __main__ - Step 540 Global step 540 Train loss 2.00 on epoch=134
05/16/2022 14:32:48 - INFO - __main__ - Step 550 Global step 550 Train loss 2.13 on epoch=137
05/16/2022 14:32:49 - INFO - __main__ - Global step 550 Train loss 2.08 Classification-F1 0.18614718614718614 on epoch=137
05/16/2022 14:32:49 - INFO - __main__ - Saving model with best Classification-F1: 0.16666666666666666 -> 0.18614718614718614 on epoch=137, global_step=550
05/16/2022 14:32:50 - INFO - __main__ - Step 560 Global step 560 Train loss 1.98 on epoch=139
05/16/2022 14:32:52 - INFO - __main__ - Step 570 Global step 570 Train loss 1.98 on epoch=142
05/16/2022 14:32:53 - INFO - __main__ - Step 580 Global step 580 Train loss 1.89 on epoch=144
05/16/2022 14:32:54 - INFO - __main__ - Step 590 Global step 590 Train loss 1.89 on epoch=147
05/16/2022 14:32:56 - INFO - __main__ - Step 600 Global step 600 Train loss 1.86 on epoch=149
05/16/2022 14:32:56 - INFO - __main__ - Global step 600 Train loss 1.92 Classification-F1 0.1 on epoch=149
05/16/2022 14:32:57 - INFO - __main__ - Step 610 Global step 610 Train loss 2.11 on epoch=152
05/16/2022 14:32:59 - INFO - __main__ - Step 620 Global step 620 Train loss 1.94 on epoch=154
05/16/2022 14:33:00 - INFO - __main__ - Step 630 Global step 630 Train loss 1.99 on epoch=157
05/16/2022 14:33:02 - INFO - __main__ - Step 640 Global step 640 Train loss 1.79 on epoch=159
05/16/2022 14:33:03 - INFO - __main__ - Step 650 Global step 650 Train loss 1.75 on epoch=162
05/16/2022 14:33:04 - INFO - __main__ - Global step 650 Train loss 1.91 Classification-F1 0.189010989010989 on epoch=162
05/16/2022 14:33:04 - INFO - __main__ - Saving model with best Classification-F1: 0.18614718614718614 -> 0.189010989010989 on epoch=162, global_step=650
05/16/2022 14:33:05 - INFO - __main__ - Step 660 Global step 660 Train loss 1.75 on epoch=164
05/16/2022 14:33:06 - INFO - __main__ - Step 670 Global step 670 Train loss 1.67 on epoch=167
05/16/2022 14:33:07 - INFO - __main__ - Step 680 Global step 680 Train loss 1.65 on epoch=169
05/16/2022 14:33:09 - INFO - __main__ - Step 690 Global step 690 Train loss 1.77 on epoch=172
05/16/2022 14:33:10 - INFO - __main__ - Step 700 Global step 700 Train loss 1.75 on epoch=174
05/16/2022 14:33:11 - INFO - __main__ - Global step 700 Train loss 1.72 Classification-F1 0.09493670886075949 on epoch=174
05/16/2022 14:33:12 - INFO - __main__ - Step 710 Global step 710 Train loss 1.71 on epoch=177
05/16/2022 14:33:14 - INFO - __main__ - Step 720 Global step 720 Train loss 1.50 on epoch=179
05/16/2022 14:33:15 - INFO - __main__ - Step 730 Global step 730 Train loss 1.57 on epoch=182
05/16/2022 14:33:17 - INFO - __main__ - Step 740 Global step 740 Train loss 1.64 on epoch=184
05/16/2022 14:33:18 - INFO - __main__ - Step 750 Global step 750 Train loss 1.60 on epoch=187
05/16/2022 14:33:19 - INFO - __main__ - Global step 750 Train loss 1.60 Classification-F1 0.16223908918406071 on epoch=187
05/16/2022 14:33:20 - INFO - __main__ - Step 760 Global step 760 Train loss 1.51 on epoch=189
05/16/2022 14:33:22 - INFO - __main__ - Step 770 Global step 770 Train loss 1.46 on epoch=192
05/16/2022 14:33:23 - INFO - __main__ - Step 780 Global step 780 Train loss 1.47 on epoch=194
05/16/2022 14:33:24 - INFO - __main__ - Step 790 Global step 790 Train loss 1.57 on epoch=197
05/16/2022 14:33:26 - INFO - __main__ - Step 800 Global step 800 Train loss 1.50 on epoch=199
05/16/2022 14:33:26 - INFO - __main__ - Global step 800 Train loss 1.50 Classification-F1 0.20714285714285713 on epoch=199
05/16/2022 14:33:26 - INFO - __main__ - Saving model with best Classification-F1: 0.189010989010989 -> 0.20714285714285713 on epoch=199, global_step=800
05/16/2022 14:33:28 - INFO - __main__ - Step 810 Global step 810 Train loss 1.48 on epoch=202
05/16/2022 14:33:29 - INFO - __main__ - Step 820 Global step 820 Train loss 1.52 on epoch=204
05/16/2022 14:33:30 - INFO - __main__ - Step 830 Global step 830 Train loss 1.43 on epoch=207
05/16/2022 14:33:31 - INFO - __main__ - Step 840 Global step 840 Train loss 1.39 on epoch=209
05/16/2022 14:33:33 - INFO - __main__ - Step 850 Global step 850 Train loss 1.47 on epoch=212
05/16/2022 14:33:33 - INFO - __main__ - Global step 850 Train loss 1.46 Classification-F1 0.19270833333333334 on epoch=212
05/16/2022 14:33:35 - INFO - __main__ - Step 860 Global step 860 Train loss 1.25 on epoch=214
05/16/2022 14:33:36 - INFO - __main__ - Step 870 Global step 870 Train loss 1.53 on epoch=217
05/16/2022 14:33:38 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
05/16/2022 14:33:39 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
05/16/2022 14:33:41 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
05/16/2022 14:33:42 - INFO - __main__ - Global step 900 Train loss 1.39 Classification-F1 0.13067758749069247 on epoch=224
05/16/2022 14:33:43 - INFO - __main__ - Step 910 Global step 910 Train loss 1.41 on epoch=227
05/16/2022 14:33:45 - INFO - __main__ - Step 920 Global step 920 Train loss 1.32 on epoch=229
05/16/2022 14:33:46 - INFO - __main__ - Step 930 Global step 930 Train loss 1.30 on epoch=232
05/16/2022 14:33:47 - INFO - __main__ - Step 940 Global step 940 Train loss 1.23 on epoch=234
05/16/2022 14:33:49 - INFO - __main__ - Step 950 Global step 950 Train loss 1.39 on epoch=237
05/16/2022 14:33:49 - INFO - __main__ - Global step 950 Train loss 1.33 Classification-F1 0.1 on epoch=237
05/16/2022 14:33:51 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/16/2022 14:33:52 - INFO - __main__ - Step 970 Global step 970 Train loss 1.39 on epoch=242
05/16/2022 14:33:54 - INFO - __main__ - Step 980 Global step 980 Train loss 1.37 on epoch=244
05/16/2022 14:33:55 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=247
05/16/2022 14:33:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.30 on epoch=249
05/16/2022 14:33:57 - INFO - __main__ - Global step 1000 Train loss 1.33 Classification-F1 0.18318622882517405 on epoch=249
05/16/2022 14:33:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.44 on epoch=252
05/16/2022 14:34:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.44 on epoch=254
05/16/2022 14:34:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.33 on epoch=257
05/16/2022 14:34:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.32 on epoch=259
05/16/2022 14:34:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.31 on epoch=262
05/16/2022 14:34:05 - INFO - __main__ - Global step 1050 Train loss 1.36 Classification-F1 0.13936867182846935 on epoch=262
05/16/2022 14:34:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.23 on epoch=264
05/16/2022 14:34:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.19 on epoch=267
05/16/2022 14:34:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.33 on epoch=269
05/16/2022 14:34:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.30 on epoch=272
05/16/2022 14:34:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.24 on epoch=274
05/16/2022 14:34:12 - INFO - __main__ - Global step 1100 Train loss 1.26 Classification-F1 0.1 on epoch=274
05/16/2022 14:34:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/16/2022 14:34:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.37 on epoch=279
05/16/2022 14:34:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.29 on epoch=282
05/16/2022 14:34:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.34 on epoch=284
05/16/2022 14:34:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.27 on epoch=287
05/16/2022 14:34:20 - INFO - __main__ - Global step 1150 Train loss 1.30 Classification-F1 0.1 on epoch=287
05/16/2022 14:34:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.32 on epoch=289
05/16/2022 14:34:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.18 on epoch=292
05/16/2022 14:34:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.17 on epoch=294
05/16/2022 14:34:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.20 on epoch=297
05/16/2022 14:34:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.25 on epoch=299
05/16/2022 14:34:27 - INFO - __main__ - Global step 1200 Train loss 1.22 Classification-F1 0.1 on epoch=299
05/16/2022 14:34:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.19 on epoch=302
05/16/2022 14:34:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.22 on epoch=304
05/16/2022 14:34:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.23 on epoch=307
05/16/2022 14:34:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/16/2022 14:34:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.13 on epoch=312
05/16/2022 14:34:35 - INFO - __main__ - Global step 1250 Train loss 1.19 Classification-F1 0.1 on epoch=312
05/16/2022 14:34:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.22 on epoch=314
05/16/2022 14:34:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.12 on epoch=317
05/16/2022 14:34:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.02 on epoch=319
05/16/2022 14:34:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.37 on epoch=322
05/16/2022 14:34:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.14 on epoch=324
05/16/2022 14:34:42 - INFO - __main__ - Global step 1300 Train loss 1.17 Classification-F1 0.1 on epoch=324
05/16/2022 14:34:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.09 on epoch=327
05/16/2022 14:34:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=329
05/16/2022 14:34:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=332
05/16/2022 14:34:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.12 on epoch=334
05/16/2022 14:34:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.18 on epoch=337
05/16/2022 14:34:50 - INFO - __main__ - Global step 1350 Train loss 1.16 Classification-F1 0.1 on epoch=337
05/16/2022 14:34:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.09 on epoch=339
05/16/2022 14:34:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.23 on epoch=342
05/16/2022 14:34:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/16/2022 14:34:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.05 on epoch=347
05/16/2022 14:34:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.10 on epoch=349
05/16/2022 14:34:57 - INFO - __main__ - Global step 1400 Train loss 1.11 Classification-F1 0.1 on epoch=349
05/16/2022 14:34:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.08 on epoch=352
05/16/2022 14:35:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.12 on epoch=354
05/16/2022 14:35:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.30 on epoch=357
05/16/2022 14:35:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.14 on epoch=359
05/16/2022 14:35:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.20 on epoch=362
05/16/2022 14:35:05 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.13034188034188032 on epoch=362
05/16/2022 14:35:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.03 on epoch=364
05/16/2022 14:35:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.12 on epoch=367
05/16/2022 14:35:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
05/16/2022 14:35:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.21 on epoch=372
05/16/2022 14:35:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.11 on epoch=374
05/16/2022 14:35:12 - INFO - __main__ - Global step 1500 Train loss 1.09 Classification-F1 0.13197586726998492 on epoch=374
05/16/2022 14:35:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.18 on epoch=377
05/16/2022 14:35:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
05/16/2022 14:35:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
05/16/2022 14:35:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
05/16/2022 14:35:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=387
05/16/2022 14:35:19 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.1581196581196581 on epoch=387
05/16/2022 14:35:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.10 on epoch=389
05/16/2022 14:35:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=392
05/16/2022 14:35:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.05 on epoch=394
05/16/2022 14:35:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
05/16/2022 14:35:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.11 on epoch=399
05/16/2022 14:35:27 - INFO - __main__ - Global step 1600 Train loss 1.11 Classification-F1 0.23552022689953725 on epoch=399
05/16/2022 14:35:27 - INFO - __main__ - Saving model with best Classification-F1: 0.20714285714285713 -> 0.23552022689953725 on epoch=399, global_step=1600
05/16/2022 14:35:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=402
05/16/2022 14:35:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/16/2022 14:35:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.12 on epoch=407
05/16/2022 14:35:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.21 on epoch=409
05/16/2022 14:35:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/16/2022 14:35:35 - INFO - __main__ - Global step 1650 Train loss 1.10 Classification-F1 0.1 on epoch=412
05/16/2022 14:35:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.06 on epoch=414
05/16/2022 14:35:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.16 on epoch=417
05/16/2022 14:35:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
05/16/2022 14:35:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/16/2022 14:35:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.00 on epoch=424
05/16/2022 14:35:42 - INFO - __main__ - Global step 1700 Train loss 1.06 Classification-F1 0.08783783783783784 on epoch=424
05/16/2022 14:35:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.13 on epoch=427
05/16/2022 14:35:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
05/16/2022 14:35:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.13 on epoch=432
05/16/2022 14:35:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=434
05/16/2022 14:35:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.14 on epoch=437
05/16/2022 14:35:50 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.07857142857142856 on epoch=437
05/16/2022 14:35:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.98 on epoch=439
05/16/2022 14:35:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.05 on epoch=442
05/16/2022 14:35:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.05 on epoch=444
05/16/2022 14:35:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/16/2022 14:35:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.95 on epoch=449
05/16/2022 14:35:57 - INFO - __main__ - Global step 1800 Train loss 1.02 Classification-F1 0.14304519526107942 on epoch=449
05/16/2022 14:35:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.08 on epoch=452
05/16/2022 14:36:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.10 on epoch=454
05/16/2022 14:36:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.09 on epoch=457
05/16/2022 14:36:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.01 on epoch=459
05/16/2022 14:36:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=462
05/16/2022 14:36:05 - INFO - __main__ - Global step 1850 Train loss 1.05 Classification-F1 0.1575934721714773 on epoch=462
05/16/2022 14:36:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.02 on epoch=464
05/16/2022 14:36:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.18 on epoch=467
05/16/2022 14:36:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.08 on epoch=469
05/16/2022 14:36:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.03 on epoch=472
05/16/2022 14:36:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.06 on epoch=474
05/16/2022 14:36:12 - INFO - __main__ - Global step 1900 Train loss 1.07 Classification-F1 0.10126582278481013 on epoch=474
05/16/2022 14:36:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.04 on epoch=477
05/16/2022 14:36:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.00 on epoch=479
05/16/2022 14:36:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.03 on epoch=482
05/16/2022 14:36:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/16/2022 14:36:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.96 on epoch=487
05/16/2022 14:36:20 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.1 on epoch=487
05/16/2022 14:36:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=489
05/16/2022 14:36:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=492
05/16/2022 14:36:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.93 on epoch=494
05/16/2022 14:36:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
05/16/2022 14:36:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.99 on epoch=499
05/16/2022 14:36:27 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.1 on epoch=499
05/16/2022 14:36:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.09 on epoch=502
05/16/2022 14:36:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.96 on epoch=504
05/16/2022 14:36:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
05/16/2022 14:36:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/16/2022 14:36:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.05 on epoch=512
05/16/2022 14:36:35 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.1 on epoch=512
05/16/2022 14:36:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/16/2022 14:36:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/16/2022 14:36:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.08 on epoch=519
05/16/2022 14:36:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
05/16/2022 14:36:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.02 on epoch=524
05/16/2022 14:36:42 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.1 on epoch=524
05/16/2022 14:36:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.99 on epoch=527
05/16/2022 14:36:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
05/16/2022 14:36:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.09 on epoch=532
05/16/2022 14:36:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=534
05/16/2022 14:36:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.02 on epoch=537
05/16/2022 14:36:49 - INFO - __main__ - Global step 2150 Train loss 1.03 Classification-F1 0.14621798689696247 on epoch=537
05/16/2022 14:36:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.97 on epoch=539
05/16/2022 14:36:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.98 on epoch=542
05/16/2022 14:36:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.98 on epoch=544
05/16/2022 14:36:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/16/2022 14:36:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.01 on epoch=549
05/16/2022 14:36:57 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.1595890410958904 on epoch=549
05/16/2022 14:36:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/16/2022 14:37:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.93 on epoch=554
05/16/2022 14:37:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/16/2022 14:37:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/16/2022 14:37:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.94 on epoch=562
05/16/2022 14:37:04 - INFO - __main__ - Global step 2250 Train loss 0.97 Classification-F1 0.15328054298642532 on epoch=562
05/16/2022 14:37:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.97 on epoch=564
05/16/2022 14:37:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.92 on epoch=567
05/16/2022 14:37:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.08 on epoch=569
05/16/2022 14:37:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
05/16/2022 14:37:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/16/2022 14:37:12 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.12393162393162392 on epoch=574
05/16/2022 14:37:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
05/16/2022 14:37:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/16/2022 14:37:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.96 on epoch=582
05/16/2022 14:37:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/16/2022 14:37:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/16/2022 14:37:21 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=587
05/16/2022 14:37:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.99 on epoch=589
05/16/2022 14:37:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/16/2022 14:37:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
05/16/2022 14:37:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.05 on epoch=597
05/16/2022 14:37:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.06 on epoch=599
05/16/2022 14:37:28 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.11710526315789474 on epoch=599
05/16/2022 14:37:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/16/2022 14:37:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.01 on epoch=604
05/16/2022 14:37:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
05/16/2022 14:37:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/16/2022 14:37:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.02 on epoch=612
05/16/2022 14:37:36 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=612
05/16/2022 14:37:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.04 on epoch=614
05/16/2022 14:37:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=617
05/16/2022 14:37:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/16/2022 14:37:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.06 on epoch=622
05/16/2022 14:37:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.92 on epoch=624
05/16/2022 14:37:43 - INFO - __main__ - Global step 2500 Train loss 1.01 Classification-F1 0.1238095238095238 on epoch=624
05/16/2022 14:37:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.20 on epoch=627
05/16/2022 14:37:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.87 on epoch=629
05/16/2022 14:37:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.04 on epoch=632
05/16/2022 14:37:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/16/2022 14:37:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
05/16/2022 14:37:51 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.13047619047619047 on epoch=637
05/16/2022 14:37:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
05/16/2022 14:37:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
05/16/2022 14:37:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/16/2022 14:37:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
05/16/2022 14:37:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
05/16/2022 14:37:58 - INFO - __main__ - Global step 2600 Train loss 1.00 Classification-F1 0.1554709658157934 on epoch=649
05/16/2022 14:37:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/16/2022 14:38:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
05/16/2022 14:38:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/16/2022 14:38:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/16/2022 14:38:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
05/16/2022 14:38:06 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.17220843672456576 on epoch=662
05/16/2022 14:38:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.97 on epoch=664
05/16/2022 14:38:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.92 on epoch=667
05/16/2022 14:38:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
05/16/2022 14:38:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=672
05/16/2022 14:38:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/16/2022 14:38:14 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.1255656108597285 on epoch=674
05/16/2022 14:38:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.95 on epoch=677
05/16/2022 14:38:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.02 on epoch=679
05/16/2022 14:38:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/16/2022 14:38:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=684
05/16/2022 14:38:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=687
05/16/2022 14:38:21 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.13067758749069247 on epoch=687
05/16/2022 14:38:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.96 on epoch=689
05/16/2022 14:38:24 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.88 on epoch=692
05/16/2022 14:38:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.03 on epoch=694
05/16/2022 14:38:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.04 on epoch=697
05/16/2022 14:38:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.99 on epoch=699
05/16/2022 14:38:29 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.1468058968058968 on epoch=699
05/16/2022 14:38:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.02 on epoch=702
05/16/2022 14:38:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/16/2022 14:38:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.96 on epoch=707
05/16/2022 14:38:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.91 on epoch=709
05/16/2022 14:38:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
05/16/2022 14:38:37 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.1 on epoch=712
05/16/2022 14:38:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.95 on epoch=714
05/16/2022 14:38:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.05 on epoch=717
05/16/2022 14:38:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/16/2022 14:38:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.92 on epoch=722
05/16/2022 14:38:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/16/2022 14:38:45 - INFO - __main__ - Global step 2900 Train loss 0.96 Classification-F1 0.16795711733174506 on epoch=724
05/16/2022 14:38:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.02 on epoch=727
05/16/2022 14:38:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.92 on epoch=729
05/16/2022 14:38:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.93 on epoch=732
05/16/2022 14:38:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/16/2022 14:38:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.96 on epoch=737
05/16/2022 14:38:52 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.1 on epoch=737
05/16/2022 14:38:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.89 on epoch=739
05/16/2022 14:38:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.92 on epoch=742
05/16/2022 14:38:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.02 on epoch=744
05/16/2022 14:38:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/16/2022 14:38:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.82 on epoch=749
05/16/2022 14:39:00 - INFO - __main__ - Global step 3000 Train loss 0.93 Classification-F1 0.13067758749069247 on epoch=749
05/16/2022 14:39:00 - INFO - __main__ - save last model!
05/16/2022 14:39:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 14:39:00 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 14:39:00 - INFO - __main__ - Printing 3 examples
05/16/2022 14:39:00 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 14:39:00 - INFO - __main__ - ['others']
05/16/2022 14:39:00 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 14:39:00 - INFO - __main__ - ['others']
05/16/2022 14:39:00 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 14:39:00 - INFO - __main__ - ['others']
05/16/2022 14:39:00 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:39:01 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:39:01 - INFO - __main__ - Printing 3 examples
05/16/2022 14:39:01 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:39:01 - INFO - __main__ - ['others']
05/16/2022 14:39:01 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:39:01 - INFO - __main__ - ['others']
05/16/2022 14:39:01 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:39:01 - INFO - __main__ - ['others']
05/16/2022 14:39:01 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:39:01 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:39:01 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:39:01 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:39:01 - INFO - __main__ - Printing 3 examples
05/16/2022 14:39:01 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:39:01 - INFO - __main__ - ['others']
05/16/2022 14:39:01 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:39:01 - INFO - __main__ - ['others']
05/16/2022 14:39:01 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:39:01 - INFO - __main__ - ['others']
05/16/2022 14:39:01 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:39:01 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:39:01 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:39:03 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:39:06 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:39:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:39:07 - INFO - __main__ - Starting training!
05/16/2022 14:39:09 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 14:39:54 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.3_8_predictions.txt
05/16/2022 14:39:54 - INFO - __main__ - Classification-F1 on test data: 0.0343
05/16/2022 14:39:54 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.23552022689953725, test_performance=0.03427363395026725
05/16/2022 14:39:54 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
05/16/2022 14:39:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:39:55 - INFO - __main__ - Printing 3 examples
05/16/2022 14:39:55 - INFO - __main__ -  [emo] how cause yes am listening
05/16/2022 14:39:55 - INFO - __main__ - ['others']
05/16/2022 14:39:55 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/16/2022 14:39:55 - INFO - __main__ - ['others']
05/16/2022 14:39:55 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/16/2022 14:39:55 - INFO - __main__ - ['others']
05/16/2022 14:39:55 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:39:55 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:39:55 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:39:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:39:55 - INFO - __main__ - Printing 3 examples
05/16/2022 14:39:55 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/16/2022 14:39:55 - INFO - __main__ - ['others']
05/16/2022 14:39:55 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/16/2022 14:39:55 - INFO - __main__ - ['others']
05/16/2022 14:39:55 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/16/2022 14:39:55 - INFO - __main__ - ['others']
05/16/2022 14:39:55 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:39:55 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:39:55 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:40:01 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:40:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:40:01 - INFO - __main__ - Starting training!
05/16/2022 14:40:03 - INFO - __main__ - Step 10 Global step 10 Train loss 6.77 on epoch=2
05/16/2022 14:40:04 - INFO - __main__ - Step 20 Global step 20 Train loss 6.71 on epoch=4
05/16/2022 14:40:05 - INFO - __main__ - Step 30 Global step 30 Train loss 6.51 on epoch=7
05/16/2022 14:40:07 - INFO - __main__ - Step 40 Global step 40 Train loss 6.45 on epoch=9
05/16/2022 14:40:08 - INFO - __main__ - Step 50 Global step 50 Train loss 6.20 on epoch=12
05/16/2022 14:40:12 - INFO - __main__ - Global step 50 Train loss 6.53 Classification-F1 0.0 on epoch=12
05/16/2022 14:40:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 14:40:14 - INFO - __main__ - Step 60 Global step 60 Train loss 6.13 on epoch=14
05/16/2022 14:40:15 - INFO - __main__ - Step 70 Global step 70 Train loss 6.18 on epoch=17
05/16/2022 14:40:16 - INFO - __main__ - Step 80 Global step 80 Train loss 6.06 on epoch=19
05/16/2022 14:40:17 - INFO - __main__ - Step 90 Global step 90 Train loss 5.79 on epoch=22
05/16/2022 14:40:19 - INFO - __main__ - Step 100 Global step 100 Train loss 5.63 on epoch=24
05/16/2022 14:40:21 - INFO - __main__ - Global step 100 Train loss 5.96 Classification-F1 0.0 on epoch=24
05/16/2022 14:40:22 - INFO - __main__ - Step 110 Global step 110 Train loss 5.50 on epoch=27
05/16/2022 14:40:24 - INFO - __main__ - Step 120 Global step 120 Train loss 5.51 on epoch=29
05/16/2022 14:40:25 - INFO - __main__ - Step 130 Global step 130 Train loss 5.35 on epoch=32
05/16/2022 14:40:27 - INFO - __main__ - Step 140 Global step 140 Train loss 5.23 on epoch=34
05/16/2022 14:40:28 - INFO - __main__ - Step 150 Global step 150 Train loss 5.16 on epoch=37
05/16/2022 14:40:30 - INFO - __main__ - Global step 150 Train loss 5.35 Classification-F1 0.0 on epoch=37
05/16/2022 14:40:31 - INFO - __main__ - Step 160 Global step 160 Train loss 4.96 on epoch=39
05/16/2022 14:40:32 - INFO - __main__ - Step 170 Global step 170 Train loss 4.82 on epoch=42
05/16/2022 14:40:34 - INFO - __main__ - Step 180 Global step 180 Train loss 4.84 on epoch=44
05/16/2022 14:40:35 - INFO - __main__ - Step 190 Global step 190 Train loss 4.62 on epoch=47
05/16/2022 14:40:37 - INFO - __main__ - Step 200 Global step 200 Train loss 4.73 on epoch=49
05/16/2022 14:40:40 - INFO - __main__ - Global step 200 Train loss 4.79 Classification-F1 0.0 on epoch=49
05/16/2022 14:40:41 - INFO - __main__ - Step 210 Global step 210 Train loss 4.56 on epoch=52
05/16/2022 14:40:43 - INFO - __main__ - Step 220 Global step 220 Train loss 4.47 on epoch=54
05/16/2022 14:40:44 - INFO - __main__ - Step 230 Global step 230 Train loss 4.43 on epoch=57
05/16/2022 14:40:45 - INFO - __main__ - Step 240 Global step 240 Train loss 4.29 on epoch=59
05/16/2022 14:40:47 - INFO - __main__ - Step 250 Global step 250 Train loss 4.30 on epoch=62
05/16/2022 14:40:47 - INFO - __main__ - Global step 250 Train loss 4.41 Classification-F1 0.06111801242236026 on epoch=62
05/16/2022 14:40:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06111801242236026 on epoch=62, global_step=250
05/16/2022 14:40:49 - INFO - __main__ - Step 260 Global step 260 Train loss 4.22 on epoch=64
05/16/2022 14:40:50 - INFO - __main__ - Step 270 Global step 270 Train loss 4.17 on epoch=67
05/16/2022 14:40:52 - INFO - __main__ - Step 280 Global step 280 Train loss 4.00 on epoch=69
05/16/2022 14:40:53 - INFO - __main__ - Step 290 Global step 290 Train loss 4.01 on epoch=72
05/16/2022 14:40:55 - INFO - __main__ - Step 300 Global step 300 Train loss 4.05 on epoch=74
05/16/2022 14:40:55 - INFO - __main__ - Global step 300 Train loss 4.09 Classification-F1 0.08206896551724137 on epoch=74
05/16/2022 14:40:55 - INFO - __main__ - Saving model with best Classification-F1: 0.06111801242236026 -> 0.08206896551724137 on epoch=74, global_step=300
05/16/2022 14:40:57 - INFO - __main__ - Step 310 Global step 310 Train loss 3.81 on epoch=77
05/16/2022 14:40:58 - INFO - __main__ - Step 320 Global step 320 Train loss 3.74 on epoch=79
05/16/2022 14:40:59 - INFO - __main__ - Step 330 Global step 330 Train loss 3.89 on epoch=82
05/16/2022 14:41:01 - INFO - __main__ - Step 340 Global step 340 Train loss 3.60 on epoch=84
05/16/2022 14:41:02 - INFO - __main__ - Step 350 Global step 350 Train loss 3.72 on epoch=87
05/16/2022 14:41:03 - INFO - __main__ - Global step 350 Train loss 3.75 Classification-F1 0.1081904761904762 on epoch=87
05/16/2022 14:41:03 - INFO - __main__ - Saving model with best Classification-F1: 0.08206896551724137 -> 0.1081904761904762 on epoch=87, global_step=350
05/16/2022 14:41:04 - INFO - __main__ - Step 360 Global step 360 Train loss 3.51 on epoch=89
05/16/2022 14:41:06 - INFO - __main__ - Step 370 Global step 370 Train loss 3.51 on epoch=92
05/16/2022 14:41:08 - INFO - __main__ - Step 380 Global step 380 Train loss 3.49 on epoch=94
05/16/2022 14:41:09 - INFO - __main__ - Step 390 Global step 390 Train loss 3.69 on epoch=97
05/16/2022 14:41:11 - INFO - __main__ - Step 400 Global step 400 Train loss 3.47 on epoch=99
05/16/2022 14:41:12 - INFO - __main__ - Global step 400 Train loss 3.53 Classification-F1 0.07344632768361581 on epoch=99
05/16/2022 14:41:13 - INFO - __main__ - Step 410 Global step 410 Train loss 3.42 on epoch=102
05/16/2022 14:41:15 - INFO - __main__ - Step 420 Global step 420 Train loss 3.36 on epoch=104
05/16/2022 14:41:16 - INFO - __main__ - Step 430 Global step 430 Train loss 3.29 on epoch=107
05/16/2022 14:41:18 - INFO - __main__ - Step 440 Global step 440 Train loss 2.97 on epoch=109
05/16/2022 14:41:19 - INFO - __main__ - Step 450 Global step 450 Train loss 3.31 on epoch=112
05/16/2022 14:41:20 - INFO - __main__ - Global step 450 Train loss 3.27 Classification-F1 0.05555555555555556 on epoch=112
05/16/2022 14:41:21 - INFO - __main__ - Step 460 Global step 460 Train loss 3.15 on epoch=114
05/16/2022 14:41:22 - INFO - __main__ - Step 470 Global step 470 Train loss 3.19 on epoch=117
05/16/2022 14:41:24 - INFO - __main__ - Step 480 Global step 480 Train loss 3.02 on epoch=119
05/16/2022 14:41:25 - INFO - __main__ - Step 490 Global step 490 Train loss 3.00 on epoch=122
05/16/2022 14:41:26 - INFO - __main__ - Step 500 Global step 500 Train loss 2.94 on epoch=124
05/16/2022 14:41:27 - INFO - __main__ - Global step 500 Train loss 3.06 Classification-F1 0.1 on epoch=124
05/16/2022 14:41:28 - INFO - __main__ - Step 510 Global step 510 Train loss 3.08 on epoch=127
05/16/2022 14:41:30 - INFO - __main__ - Step 520 Global step 520 Train loss 3.01 on epoch=129
05/16/2022 14:41:32 - INFO - __main__ - Step 530 Global step 530 Train loss 2.99 on epoch=132
05/16/2022 14:41:33 - INFO - __main__ - Step 540 Global step 540 Train loss 2.85 on epoch=134
05/16/2022 14:41:34 - INFO - __main__ - Step 550 Global step 550 Train loss 2.99 on epoch=137
05/16/2022 14:41:35 - INFO - __main__ - Global step 550 Train loss 2.98 Classification-F1 0.13026315789473686 on epoch=137
05/16/2022 14:41:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1081904761904762 -> 0.13026315789473686 on epoch=137, global_step=550
05/16/2022 14:41:36 - INFO - __main__ - Step 560 Global step 560 Train loss 2.76 on epoch=139
05/16/2022 14:41:38 - INFO - __main__ - Step 570 Global step 570 Train loss 2.90 on epoch=142
05/16/2022 14:41:39 - INFO - __main__ - Step 580 Global step 580 Train loss 2.78 on epoch=144
05/16/2022 14:41:40 - INFO - __main__ - Step 590 Global step 590 Train loss 2.66 on epoch=147
05/16/2022 14:41:42 - INFO - __main__ - Step 600 Global step 600 Train loss 2.80 on epoch=149
05/16/2022 14:41:42 - INFO - __main__ - Global step 600 Train loss 2.78 Classification-F1 0.1 on epoch=149
05/16/2022 14:41:44 - INFO - __main__ - Step 610 Global step 610 Train loss 2.74 on epoch=152
05/16/2022 14:41:45 - INFO - __main__ - Step 620 Global step 620 Train loss 2.49 on epoch=154
05/16/2022 14:41:47 - INFO - __main__ - Step 630 Global step 630 Train loss 2.53 on epoch=157
05/16/2022 14:41:49 - INFO - __main__ - Step 640 Global step 640 Train loss 2.58 on epoch=159
05/16/2022 14:41:50 - INFO - __main__ - Step 650 Global step 650 Train loss 2.59 on epoch=162
05/16/2022 14:41:51 - INFO - __main__ - Global step 650 Train loss 2.59 Classification-F1 0.13034188034188032 on epoch=162
05/16/2022 14:41:51 - INFO - __main__ - Saving model with best Classification-F1: 0.13026315789473686 -> 0.13034188034188032 on epoch=162, global_step=650
05/16/2022 14:41:52 - INFO - __main__ - Step 660 Global step 660 Train loss 2.47 on epoch=164
05/16/2022 14:41:54 - INFO - __main__ - Step 670 Global step 670 Train loss 2.79 on epoch=167
05/16/2022 14:41:56 - INFO - __main__ - Step 680 Global step 680 Train loss 2.38 on epoch=169
05/16/2022 14:41:57 - INFO - __main__ - Step 690 Global step 690 Train loss 2.66 on epoch=172
05/16/2022 14:41:59 - INFO - __main__ - Step 700 Global step 700 Train loss 2.45 on epoch=174
05/16/2022 14:41:59 - INFO - __main__ - Global step 700 Train loss 2.55 Classification-F1 0.1 on epoch=174
05/16/2022 14:42:01 - INFO - __main__ - Step 710 Global step 710 Train loss 2.56 on epoch=177
05/16/2022 14:42:02 - INFO - __main__ - Step 720 Global step 720 Train loss 2.49 on epoch=179
05/16/2022 14:42:04 - INFO - __main__ - Step 730 Global step 730 Train loss 2.46 on epoch=182
05/16/2022 14:42:05 - INFO - __main__ - Step 740 Global step 740 Train loss 2.25 on epoch=184
05/16/2022 14:42:07 - INFO - __main__ - Step 750 Global step 750 Train loss 2.37 on epoch=187
05/16/2022 14:42:07 - INFO - __main__ - Global step 750 Train loss 2.43 Classification-F1 0.10256410256410256 on epoch=187
05/16/2022 14:42:09 - INFO - __main__ - Step 760 Global step 760 Train loss 2.43 on epoch=189
05/16/2022 14:42:10 - INFO - __main__ - Step 770 Global step 770 Train loss 2.34 on epoch=192
05/16/2022 14:42:12 - INFO - __main__ - Step 780 Global step 780 Train loss 2.30 on epoch=194
05/16/2022 14:42:13 - INFO - __main__ - Step 790 Global step 790 Train loss 2.35 on epoch=197
05/16/2022 14:42:15 - INFO - __main__ - Step 800 Global step 800 Train loss 2.28 on epoch=199
05/16/2022 14:42:15 - INFO - __main__ - Global step 800 Train loss 2.34 Classification-F1 0.16695652173913045 on epoch=199
05/16/2022 14:42:15 - INFO - __main__ - Saving model with best Classification-F1: 0.13034188034188032 -> 0.16695652173913045 on epoch=199, global_step=800
05/16/2022 14:42:16 - INFO - __main__ - Step 810 Global step 810 Train loss 2.09 on epoch=202
05/16/2022 14:42:18 - INFO - __main__ - Step 820 Global step 820 Train loss 2.19 on epoch=204
05/16/2022 14:42:19 - INFO - __main__ - Step 830 Global step 830 Train loss 2.27 on epoch=207
05/16/2022 14:42:20 - INFO - __main__ - Step 840 Global step 840 Train loss 2.23 on epoch=209
05/16/2022 14:42:22 - INFO - __main__ - Step 850 Global step 850 Train loss 2.28 on epoch=212
05/16/2022 14:42:22 - INFO - __main__ - Global step 850 Train loss 2.21 Classification-F1 0.15339578454332553 on epoch=212
05/16/2022 14:42:24 - INFO - __main__ - Step 860 Global step 860 Train loss 2.08 on epoch=214
05/16/2022 14:42:25 - INFO - __main__ - Step 870 Global step 870 Train loss 2.21 on epoch=217
05/16/2022 14:42:27 - INFO - __main__ - Step 880 Global step 880 Train loss 2.05 on epoch=219
05/16/2022 14:42:28 - INFO - __main__ - Step 890 Global step 890 Train loss 2.09 on epoch=222
05/16/2022 14:42:30 - INFO - __main__ - Step 900 Global step 900 Train loss 2.08 on epoch=224
05/16/2022 14:42:30 - INFO - __main__ - Global step 900 Train loss 2.10 Classification-F1 0.18623481781376516 on epoch=224
05/16/2022 14:42:30 - INFO - __main__ - Saving model with best Classification-F1: 0.16695652173913045 -> 0.18623481781376516 on epoch=224, global_step=900
05/16/2022 14:42:32 - INFO - __main__ - Step 910 Global step 910 Train loss 2.09 on epoch=227
05/16/2022 14:42:33 - INFO - __main__ - Step 920 Global step 920 Train loss 2.04 on epoch=229
05/16/2022 14:42:35 - INFO - __main__ - Step 930 Global step 930 Train loss 2.14 on epoch=232
05/16/2022 14:42:36 - INFO - __main__ - Step 940 Global step 940 Train loss 2.06 on epoch=234
05/16/2022 14:42:37 - INFO - __main__ - Step 950 Global step 950 Train loss 2.12 on epoch=237
05/16/2022 14:42:38 - INFO - __main__ - Global step 950 Train loss 2.09 Classification-F1 0.217858709960509 on epoch=237
05/16/2022 14:42:38 - INFO - __main__ - Saving model with best Classification-F1: 0.18623481781376516 -> 0.217858709960509 on epoch=237, global_step=950
05/16/2022 14:42:39 - INFO - __main__ - Step 960 Global step 960 Train loss 2.09 on epoch=239
05/16/2022 14:42:41 - INFO - __main__ - Step 970 Global step 970 Train loss 2.11 on epoch=242
05/16/2022 14:42:42 - INFO - __main__ - Step 980 Global step 980 Train loss 1.91 on epoch=244
05/16/2022 14:42:44 - INFO - __main__ - Step 990 Global step 990 Train loss 1.83 on epoch=247
05/16/2022 14:42:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.96 on epoch=249
05/16/2022 14:42:46 - INFO - __main__ - Global step 1000 Train loss 1.98 Classification-F1 0.16464237516869096 on epoch=249
05/16/2022 14:42:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.83 on epoch=252
05/16/2022 14:42:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.84 on epoch=254
05/16/2022 14:42:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.93 on epoch=257
05/16/2022 14:42:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.88 on epoch=259
05/16/2022 14:42:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.82 on epoch=262
05/16/2022 14:42:54 - INFO - __main__ - Global step 1050 Train loss 1.86 Classification-F1 0.17267605633802818 on epoch=262
05/16/2022 14:42:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.73 on epoch=264
05/16/2022 14:42:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.95 on epoch=267
05/16/2022 14:42:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.77 on epoch=269
05/16/2022 14:43:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.94 on epoch=272
05/16/2022 14:43:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.71 on epoch=274
05/16/2022 14:43:01 - INFO - __main__ - Global step 1100 Train loss 1.82 Classification-F1 0.13225806451612904 on epoch=274
05/16/2022 14:43:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.81 on epoch=277
05/16/2022 14:43:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.78 on epoch=279
05/16/2022 14:43:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.88 on epoch=282
05/16/2022 14:43:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.72 on epoch=284
05/16/2022 14:43:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.72 on epoch=287
05/16/2022 14:43:09 - INFO - __main__ - Global step 1150 Train loss 1.78 Classification-F1 0.1302118933697881 on epoch=287
05/16/2022 14:43:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.51 on epoch=289
05/16/2022 14:43:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.64 on epoch=292
05/16/2022 14:43:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.47 on epoch=294
05/16/2022 14:43:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.58 on epoch=297
05/16/2022 14:43:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.59 on epoch=299
05/16/2022 14:43:16 - INFO - __main__ - Global step 1200 Train loss 1.56 Classification-F1 0.2000907441016334 on epoch=299
05/16/2022 14:43:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.82 on epoch=302
05/16/2022 14:43:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.66 on epoch=304
05/16/2022 14:43:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.63 on epoch=307
05/16/2022 14:43:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.68 on epoch=309
05/16/2022 14:43:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.52 on epoch=312
05/16/2022 14:43:24 - INFO - __main__ - Global step 1250 Train loss 1.66 Classification-F1 0.171875 on epoch=312
05/16/2022 14:43:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.49 on epoch=314
05/16/2022 14:43:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.57 on epoch=317
05/16/2022 14:43:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.51 on epoch=319
05/16/2022 14:43:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.58 on epoch=322
05/16/2022 14:43:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.52 on epoch=324
05/16/2022 14:43:32 - INFO - __main__ - Global step 1300 Train loss 1.53 Classification-F1 0.1523109243697479 on epoch=324
05/16/2022 14:43:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.57 on epoch=327
05/16/2022 14:43:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.65 on epoch=329
05/16/2022 14:43:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.43 on epoch=332
05/16/2022 14:43:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.51 on epoch=334
05/16/2022 14:43:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.48 on epoch=337
05/16/2022 14:43:39 - INFO - __main__ - Global step 1350 Train loss 1.53 Classification-F1 0.17377495462794917 on epoch=337
05/16/2022 14:43:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.37 on epoch=339
05/16/2022 14:43:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.53 on epoch=342
05/16/2022 14:43:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.43 on epoch=344
05/16/2022 14:43:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.54 on epoch=347
05/16/2022 14:43:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.38 on epoch=349
05/16/2022 14:43:47 - INFO - __main__ - Global step 1400 Train loss 1.45 Classification-F1 0.16078790655061842 on epoch=349
05/16/2022 14:43:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.35 on epoch=352
05/16/2022 14:43:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.42 on epoch=354
05/16/2022 14:43:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.43 on epoch=357
05/16/2022 14:43:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.29 on epoch=359
05/16/2022 14:43:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.38 on epoch=362
05/16/2022 14:43:54 - INFO - __main__ - Global step 1450 Train loss 1.37 Classification-F1 0.14563380281690141 on epoch=362
05/16/2022 14:43:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.26 on epoch=364
05/16/2022 14:43:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.50 on epoch=367
05/16/2022 14:43:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.39 on epoch=369
05/16/2022 14:44:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.51 on epoch=372
05/16/2022 14:44:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.28 on epoch=374
05/16/2022 14:44:02 - INFO - __main__ - Global step 1500 Train loss 1.39 Classification-F1 0.1 on epoch=374
05/16/2022 14:44:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.45 on epoch=377
05/16/2022 14:44:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.44 on epoch=379
05/16/2022 14:44:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.49 on epoch=382
05/16/2022 14:44:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.33 on epoch=384
05/16/2022 14:44:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
05/16/2022 14:44:10 - INFO - __main__ - Global step 1550 Train loss 1.42 Classification-F1 0.1869328493647913 on epoch=387
05/16/2022 14:44:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.44 on epoch=389
05/16/2022 14:44:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.37 on epoch=392
05/16/2022 14:44:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.29 on epoch=394
05/16/2022 14:44:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.29 on epoch=397
05/16/2022 14:44:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.32 on epoch=399
05/16/2022 14:44:17 - INFO - __main__ - Global step 1600 Train loss 1.34 Classification-F1 0.1 on epoch=399
05/16/2022 14:44:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.35 on epoch=402
05/16/2022 14:44:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.22 on epoch=404
05/16/2022 14:44:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.30 on epoch=407
05/16/2022 14:44:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.38 on epoch=409
05/16/2022 14:44:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.35 on epoch=412
05/16/2022 14:44:25 - INFO - __main__ - Global step 1650 Train loss 1.32 Classification-F1 0.1875814155449414 on epoch=412
05/16/2022 14:44:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.33 on epoch=414
05/16/2022 14:44:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.32 on epoch=417
05/16/2022 14:44:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.32 on epoch=419
05/16/2022 14:44:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.19 on epoch=422
05/16/2022 14:44:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.16 on epoch=424
05/16/2022 14:44:33 - INFO - __main__ - Global step 1700 Train loss 1.26 Classification-F1 0.12403499742665978 on epoch=424
05/16/2022 14:44:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.15 on epoch=427
05/16/2022 14:44:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.15 on epoch=429
05/16/2022 14:44:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.23 on epoch=432
05/16/2022 14:44:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.24 on epoch=434
05/16/2022 14:44:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=437
05/16/2022 14:44:40 - INFO - __main__ - Global step 1750 Train loss 1.20 Classification-F1 0.10126582278481013 on epoch=437
05/16/2022 14:44:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.22 on epoch=439
05/16/2022 14:44:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.36 on epoch=442
05/16/2022 14:44:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.37 on epoch=444
05/16/2022 14:44:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.29 on epoch=447
05/16/2022 14:44:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.21 on epoch=449
05/16/2022 14:44:48 - INFO - __main__ - Global step 1800 Train loss 1.29 Classification-F1 0.1 on epoch=449
05/16/2022 14:44:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.29 on epoch=452
05/16/2022 14:44:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.14 on epoch=454
05/16/2022 14:44:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.25 on epoch=457
05/16/2022 14:44:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.14 on epoch=459
05/16/2022 14:44:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.19 on epoch=462
05/16/2022 14:44:56 - INFO - __main__ - Global step 1850 Train loss 1.20 Classification-F1 0.11762954139368673 on epoch=462
05/16/2022 14:44:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.22 on epoch=464
05/16/2022 14:44:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.24 on epoch=467
05/16/2022 14:45:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.25 on epoch=469
05/16/2022 14:45:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.26 on epoch=472
05/16/2022 14:45:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.21 on epoch=474
05/16/2022 14:45:03 - INFO - __main__ - Global step 1900 Train loss 1.24 Classification-F1 0.16608695652173913 on epoch=474
05/16/2022 14:45:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.29 on epoch=477
05/16/2022 14:45:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.27 on epoch=479
05/16/2022 14:45:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.23 on epoch=482
05/16/2022 14:45:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.12 on epoch=484
05/16/2022 14:45:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.26 on epoch=487
05/16/2022 14:45:11 - INFO - __main__ - Global step 1950 Train loss 1.23 Classification-F1 0.1 on epoch=487
05/16/2022 14:45:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.24 on epoch=489
05/16/2022 14:45:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.30 on epoch=492
05/16/2022 14:45:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.18 on epoch=494
05/16/2022 14:45:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.30 on epoch=497
05/16/2022 14:45:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.17 on epoch=499
05/16/2022 14:45:19 - INFO - __main__ - Global step 2000 Train loss 1.24 Classification-F1 0.17809523809523808 on epoch=499
05/16/2022 14:45:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.20 on epoch=502
05/16/2022 14:45:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.09 on epoch=504
05/16/2022 14:45:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.19 on epoch=507
05/16/2022 14:45:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.22 on epoch=509
05/16/2022 14:45:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.24 on epoch=512
05/16/2022 14:45:26 - INFO - __main__ - Global step 2050 Train loss 1.19 Classification-F1 0.17573497147871872 on epoch=512
05/16/2022 14:45:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.19 on epoch=514
05/16/2022 14:45:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.25 on epoch=517
05/16/2022 14:45:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.13 on epoch=519
05/16/2022 14:45:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.23 on epoch=522
05/16/2022 14:45:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.16 on epoch=524
05/16/2022 14:45:34 - INFO - __main__ - Global step 2100 Train loss 1.19 Classification-F1 0.1 on epoch=524
05/16/2022 14:45:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.17 on epoch=527
05/16/2022 14:45:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.24 on epoch=529
05/16/2022 14:45:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.18 on epoch=532
05/16/2022 14:45:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.17 on epoch=534
05/16/2022 14:45:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.16 on epoch=537
05/16/2022 14:45:41 - INFO - __main__ - Global step 2150 Train loss 1.18 Classification-F1 0.12393162393162392 on epoch=537
05/16/2022 14:45:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.19 on epoch=539
05/16/2022 14:45:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.16 on epoch=542
05/16/2022 14:45:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.21 on epoch=544
05/16/2022 14:45:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.20 on epoch=547
05/16/2022 14:45:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.20 on epoch=549
05/16/2022 14:45:49 - INFO - __main__ - Global step 2200 Train loss 1.19 Classification-F1 0.1 on epoch=549
05/16/2022 14:45:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.08 on epoch=552
05/16/2022 14:45:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.09 on epoch=554
05/16/2022 14:45:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.23 on epoch=557
05/16/2022 14:45:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.01 on epoch=559
05/16/2022 14:45:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.08 on epoch=562
05/16/2022 14:45:57 - INFO - __main__ - Global step 2250 Train loss 1.10 Classification-F1 0.1 on epoch=562
05/16/2022 14:45:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.08 on epoch=564
05/16/2022 14:46:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.15 on epoch=567
05/16/2022 14:46:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.11 on epoch=569
05/16/2022 14:46:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.15 on epoch=572
05/16/2022 14:46:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.24 on epoch=574
05/16/2022 14:46:05 - INFO - __main__ - Global step 2300 Train loss 1.15 Classification-F1 0.13067758749069247 on epoch=574
05/16/2022 14:46:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.27 on epoch=577
05/16/2022 14:46:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
05/16/2022 14:46:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.20 on epoch=582
05/16/2022 14:46:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.13 on epoch=584
05/16/2022 14:46:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.16 on epoch=587
05/16/2022 14:46:12 - INFO - __main__ - Global step 2350 Train loss 1.18 Classification-F1 0.1283068783068783 on epoch=587
05/16/2022 14:46:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.12 on epoch=589
05/16/2022 14:46:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.10 on epoch=592
05/16/2022 14:46:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
05/16/2022 14:46:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
05/16/2022 14:46:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.14 on epoch=599
05/16/2022 14:46:20 - INFO - __main__ - Global step 2400 Train loss 1.10 Classification-F1 0.14450704225352112 on epoch=599
05/16/2022 14:46:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.30 on epoch=602
05/16/2022 14:46:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.12 on epoch=604
05/16/2022 14:46:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.10 on epoch=607
05/16/2022 14:46:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
05/16/2022 14:46:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.10 on epoch=612
05/16/2022 14:46:28 - INFO - __main__ - Global step 2450 Train loss 1.12 Classification-F1 0.09493670886075949 on epoch=612
05/16/2022 14:46:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.24 on epoch=614
05/16/2022 14:46:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.10 on epoch=617
05/16/2022 14:46:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.05 on epoch=619
05/16/2022 14:46:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
05/16/2022 14:46:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.20 on epoch=624
05/16/2022 14:46:36 - INFO - __main__ - Global step 2500 Train loss 1.12 Classification-F1 0.1 on epoch=624
05/16/2022 14:46:37 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.15 on epoch=627
05/16/2022 14:46:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
05/16/2022 14:46:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.17 on epoch=632
05/16/2022 14:46:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.07 on epoch=634
05/16/2022 14:46:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.08 on epoch=637
05/16/2022 14:46:44 - INFO - __main__ - Global step 2550 Train loss 1.11 Classification-F1 0.1 on epoch=637
05/16/2022 14:46:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.03 on epoch=639
05/16/2022 14:46:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.05 on epoch=642
05/16/2022 14:46:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.11 on epoch=644
05/16/2022 14:46:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.07 on epoch=647
05/16/2022 14:46:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.07 on epoch=649
05/16/2022 14:46:51 - INFO - __main__ - Global step 2600 Train loss 1.07 Classification-F1 0.1 on epoch=649
05/16/2022 14:46:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/16/2022 14:46:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.15 on epoch=654
05/16/2022 14:46:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.04 on epoch=657
05/16/2022 14:46:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.18 on epoch=659
05/16/2022 14:46:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.12 on epoch=662
05/16/2022 14:46:58 - INFO - __main__ - Global step 2650 Train loss 1.09 Classification-F1 0.1434065934065934 on epoch=662
05/16/2022 14:47:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.05 on epoch=664
05/16/2022 14:47:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.04 on epoch=667
05/16/2022 14:47:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.06 on epoch=669
05/16/2022 14:47:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/16/2022 14:47:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.07 on epoch=674
05/16/2022 14:47:06 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.16515151515151516 on epoch=674
05/16/2022 14:47:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.07 on epoch=677
05/16/2022 14:47:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
05/16/2022 14:47:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.09 on epoch=682
05/16/2022 14:47:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.01 on epoch=684
05/16/2022 14:47:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.11 on epoch=687
05/16/2022 14:47:14 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.18679549114331723 on epoch=687
05/16/2022 14:47:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.16 on epoch=689
05/16/2022 14:47:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.09 on epoch=692
05/16/2022 14:47:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/16/2022 14:47:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
05/16/2022 14:47:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.08 on epoch=699
05/16/2022 14:47:22 - INFO - __main__ - Global step 2800 Train loss 1.05 Classification-F1 0.14180672268907563 on epoch=699
05/16/2022 14:47:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
05/16/2022 14:47:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.19 on epoch=704
05/16/2022 14:47:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.05 on epoch=707
05/16/2022 14:47:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/16/2022 14:47:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
05/16/2022 14:47:29 - INFO - __main__ - Global step 2850 Train loss 1.07 Classification-F1 0.10526315789473685 on epoch=712
05/16/2022 14:47:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.93 on epoch=714
05/16/2022 14:47:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.14 on epoch=717
05/16/2022 14:47:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.20 on epoch=719
05/16/2022 14:47:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.11 on epoch=722
05/16/2022 14:47:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.21 on epoch=724
05/16/2022 14:47:38 - INFO - __main__ - Global step 2900 Train loss 1.12 Classification-F1 0.14509803921568626 on epoch=724
05/16/2022 14:47:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.06 on epoch=727
05/16/2022 14:47:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.13 on epoch=729
05/16/2022 14:47:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.96 on epoch=732
05/16/2022 14:47:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.05 on epoch=734
05/16/2022 14:47:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.99 on epoch=737
05/16/2022 14:47:45 - INFO - __main__ - Global step 2950 Train loss 1.04 Classification-F1 0.1517857142857143 on epoch=737
05/16/2022 14:47:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/16/2022 14:47:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.09 on epoch=742
05/16/2022 14:47:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.15 on epoch=744
05/16/2022 14:47:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.03 on epoch=747
05/16/2022 14:47:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.00 on epoch=749
05/16/2022 14:47:52 - INFO - __main__ - Global step 3000 Train loss 1.05 Classification-F1 0.13034188034188032 on epoch=749
05/16/2022 14:47:52 - INFO - __main__ - save last model!
05/16/2022 14:47:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 14:47:52 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 14:47:52 - INFO - __main__ - Printing 3 examples
05/16/2022 14:47:52 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 14:47:52 - INFO - __main__ - ['others']
05/16/2022 14:47:52 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 14:47:52 - INFO - __main__ - ['others']
05/16/2022 14:47:52 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 14:47:52 - INFO - __main__ - ['others']
05/16/2022 14:47:52 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:47:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:47:53 - INFO - __main__ - Printing 3 examples
05/16/2022 14:47:53 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 14:47:53 - INFO - __main__ - ['others']
05/16/2022 14:47:53 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 14:47:53 - INFO - __main__ - ['others']
05/16/2022 14:47:53 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 14:47:53 - INFO - __main__ - ['others']
05/16/2022 14:47:53 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:47:53 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:47:53 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:47:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:47:53 - INFO - __main__ - Printing 3 examples
05/16/2022 14:47:53 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 14:47:53 - INFO - __main__ - ['others']
05/16/2022 14:47:53 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 14:47:53 - INFO - __main__ - ['others']
05/16/2022 14:47:53 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 14:47:53 - INFO - __main__ - ['others']
05/16/2022 14:47:53 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:47:53 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:47:53 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:47:54 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:47:59 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:48:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:48:00 - INFO - __main__ - Starting training!
05/16/2022 14:48:00 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 14:48:50 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.2_8_predictions.txt
05/16/2022 14:48:50 - INFO - __main__ - Classification-F1 on test data: 0.0339
05/16/2022 14:48:51 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.217858709960509, test_performance=0.03393767675257918
05/16/2022 14:48:51 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
05/16/2022 14:48:52 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:48:52 - INFO - __main__ - Printing 3 examples
05/16/2022 14:48:52 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 14:48:52 - INFO - __main__ - ['others']
05/16/2022 14:48:52 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 14:48:52 - INFO - __main__ - ['others']
05/16/2022 14:48:52 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 14:48:52 - INFO - __main__ - ['others']
05/16/2022 14:48:52 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:48:52 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:48:52 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:48:52 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:48:52 - INFO - __main__ - Printing 3 examples
05/16/2022 14:48:52 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 14:48:52 - INFO - __main__ - ['others']
05/16/2022 14:48:52 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 14:48:52 - INFO - __main__ - ['others']
05/16/2022 14:48:52 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 14:48:52 - INFO - __main__ - ['others']
05/16/2022 14:48:52 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:48:52 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:48:52 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:48:58 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:48:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:48:58 - INFO - __main__ - Starting training!
05/16/2022 14:49:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.71 on epoch=2
05/16/2022 14:49:01 - INFO - __main__ - Step 20 Global step 20 Train loss 6.49 on epoch=4
05/16/2022 14:49:02 - INFO - __main__ - Step 30 Global step 30 Train loss 5.99 on epoch=7
05/16/2022 14:49:04 - INFO - __main__ - Step 40 Global step 40 Train loss 5.80 on epoch=9
05/16/2022 14:49:05 - INFO - __main__ - Step 50 Global step 50 Train loss 5.51 on epoch=12
05/16/2022 14:49:08 - INFO - __main__ - Global step 50 Train loss 6.10 Classification-F1 0.0 on epoch=12
05/16/2022 14:49:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 14:49:09 - INFO - __main__ - Step 60 Global step 60 Train loss 5.18 on epoch=14
05/16/2022 14:49:11 - INFO - __main__ - Step 70 Global step 70 Train loss 5.09 on epoch=17
05/16/2022 14:49:12 - INFO - __main__ - Step 80 Global step 80 Train loss 4.72 on epoch=19
05/16/2022 14:49:14 - INFO - __main__ - Step 90 Global step 90 Train loss 4.43 on epoch=22
05/16/2022 14:49:15 - INFO - __main__ - Step 100 Global step 100 Train loss 4.13 on epoch=24
05/16/2022 14:49:16 - INFO - __main__ - Global step 100 Train loss 4.71 Classification-F1 0.17584541062801934 on epoch=24
05/16/2022 14:49:16 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.17584541062801934 on epoch=24, global_step=100
05/16/2022 14:49:17 - INFO - __main__ - Step 110 Global step 110 Train loss 3.87 on epoch=27
05/16/2022 14:49:19 - INFO - __main__ - Step 120 Global step 120 Train loss 3.74 on epoch=29
05/16/2022 14:49:20 - INFO - __main__ - Step 130 Global step 130 Train loss 3.86 on epoch=32
05/16/2022 14:49:21 - INFO - __main__ - Step 140 Global step 140 Train loss 3.44 on epoch=34
05/16/2022 14:49:23 - INFO - __main__ - Step 150 Global step 150 Train loss 3.45 on epoch=37
05/16/2022 14:49:23 - INFO - __main__ - Global step 150 Train loss 3.67 Classification-F1 0.10404761904761906 on epoch=37
05/16/2022 14:49:24 - INFO - __main__ - Step 160 Global step 160 Train loss 3.24 on epoch=39
05/16/2022 14:49:26 - INFO - __main__ - Step 170 Global step 170 Train loss 3.20 on epoch=42
05/16/2022 14:49:27 - INFO - __main__ - Step 180 Global step 180 Train loss 3.09 on epoch=44
05/16/2022 14:49:28 - INFO - __main__ - Step 190 Global step 190 Train loss 3.04 on epoch=47
05/16/2022 14:49:29 - INFO - __main__ - Step 200 Global step 200 Train loss 2.95 on epoch=49
05/16/2022 14:49:30 - INFO - __main__ - Global step 200 Train loss 3.10 Classification-F1 0.08450704225352113 on epoch=49
05/16/2022 14:49:31 - INFO - __main__ - Step 210 Global step 210 Train loss 2.72 on epoch=52
05/16/2022 14:49:33 - INFO - __main__ - Step 220 Global step 220 Train loss 2.76 on epoch=54
05/16/2022 14:49:34 - INFO - __main__ - Step 230 Global step 230 Train loss 2.73 on epoch=57
05/16/2022 14:49:35 - INFO - __main__ - Step 240 Global step 240 Train loss 2.40 on epoch=59
05/16/2022 14:49:37 - INFO - __main__ - Step 250 Global step 250 Train loss 2.52 on epoch=62
05/16/2022 14:49:37 - INFO - __main__ - Global step 250 Train loss 2.63 Classification-F1 0.12368421052631579 on epoch=62
05/16/2022 14:49:38 - INFO - __main__ - Step 260 Global step 260 Train loss 2.59 on epoch=64
05/16/2022 14:49:40 - INFO - __main__ - Step 270 Global step 270 Train loss 2.39 on epoch=67
05/16/2022 14:49:41 - INFO - __main__ - Step 280 Global step 280 Train loss 2.14 on epoch=69
05/16/2022 14:49:42 - INFO - __main__ - Step 290 Global step 290 Train loss 2.26 on epoch=72
05/16/2022 14:49:44 - INFO - __main__ - Step 300 Global step 300 Train loss 2.05 on epoch=74
05/16/2022 14:49:44 - INFO - __main__ - Global step 300 Train loss 2.29 Classification-F1 0.1970899470899471 on epoch=74
05/16/2022 14:49:44 - INFO - __main__ - Saving model with best Classification-F1: 0.17584541062801934 -> 0.1970899470899471 on epoch=74, global_step=300
05/16/2022 14:49:46 - INFO - __main__ - Step 310 Global step 310 Train loss 2.12 on epoch=77
05/16/2022 14:49:47 - INFO - __main__ - Step 320 Global step 320 Train loss 2.14 on epoch=79
05/16/2022 14:49:49 - INFO - __main__ - Step 330 Global step 330 Train loss 1.99 on epoch=82
05/16/2022 14:49:50 - INFO - __main__ - Step 340 Global step 340 Train loss 1.88 on epoch=84
05/16/2022 14:49:51 - INFO - __main__ - Step 350 Global step 350 Train loss 1.90 on epoch=87
05/16/2022 14:49:52 - INFO - __main__ - Global step 350 Train loss 2.01 Classification-F1 0.18029871977240397 on epoch=87
05/16/2022 14:49:54 - INFO - __main__ - Step 360 Global step 360 Train loss 1.86 on epoch=89
05/16/2022 14:49:55 - INFO - __main__ - Step 370 Global step 370 Train loss 1.88 on epoch=92
05/16/2022 14:49:56 - INFO - __main__ - Step 380 Global step 380 Train loss 1.65 on epoch=94
05/16/2022 14:49:58 - INFO - __main__ - Step 390 Global step 390 Train loss 1.78 on epoch=97
05/16/2022 14:49:59 - INFO - __main__ - Step 400 Global step 400 Train loss 1.59 on epoch=99
05/16/2022 14:49:59 - INFO - __main__ - Global step 400 Train loss 1.75 Classification-F1 0.19542483660130716 on epoch=99
05/16/2022 14:50:01 - INFO - __main__ - Step 410 Global step 410 Train loss 1.66 on epoch=102
05/16/2022 14:50:02 - INFO - __main__ - Step 420 Global step 420 Train loss 1.70 on epoch=104
05/16/2022 14:50:04 - INFO - __main__ - Step 430 Global step 430 Train loss 1.73 on epoch=107
05/16/2022 14:50:05 - INFO - __main__ - Step 440 Global step 440 Train loss 1.54 on epoch=109
05/16/2022 14:50:07 - INFO - __main__ - Step 450 Global step 450 Train loss 1.57 on epoch=112
05/16/2022 14:50:07 - INFO - __main__ - Global step 450 Train loss 1.64 Classification-F1 0.142512077294686 on epoch=112
05/16/2022 14:50:09 - INFO - __main__ - Step 460 Global step 460 Train loss 1.51 on epoch=114
05/16/2022 14:50:10 - INFO - __main__ - Step 470 Global step 470 Train loss 1.51 on epoch=117
05/16/2022 14:50:12 - INFO - __main__ - Step 480 Global step 480 Train loss 1.43 on epoch=119
05/16/2022 14:50:14 - INFO - __main__ - Step 490 Global step 490 Train loss 1.36 on epoch=122
05/16/2022 14:50:15 - INFO - __main__ - Step 500 Global step 500 Train loss 1.47 on epoch=124
05/16/2022 14:50:16 - INFO - __main__ - Global step 500 Train loss 1.46 Classification-F1 0.1853146853146853 on epoch=124
05/16/2022 14:50:17 - INFO - __main__ - Step 510 Global step 510 Train loss 1.45 on epoch=127
05/16/2022 14:50:19 - INFO - __main__ - Step 520 Global step 520 Train loss 1.32 on epoch=129
05/16/2022 14:50:20 - INFO - __main__ - Step 530 Global step 530 Train loss 1.29 on epoch=132
05/16/2022 14:50:21 - INFO - __main__ - Step 540 Global step 540 Train loss 1.39 on epoch=134
05/16/2022 14:50:23 - INFO - __main__ - Step 550 Global step 550 Train loss 1.34 on epoch=137
05/16/2022 14:50:24 - INFO - __main__ - Global step 550 Train loss 1.36 Classification-F1 0.1576923076923077 on epoch=137
05/16/2022 14:50:25 - INFO - __main__ - Step 560 Global step 560 Train loss 1.32 on epoch=139
05/16/2022 14:50:27 - INFO - __main__ - Step 570 Global step 570 Train loss 1.41 on epoch=142
05/16/2022 14:50:28 - INFO - __main__ - Step 580 Global step 580 Train loss 1.25 on epoch=144
05/16/2022 14:50:30 - INFO - __main__ - Step 590 Global step 590 Train loss 1.30 on epoch=147
05/16/2022 14:50:31 - INFO - __main__ - Step 600 Global step 600 Train loss 1.22 on epoch=149
05/16/2022 14:50:32 - INFO - __main__ - Global step 600 Train loss 1.30 Classification-F1 0.09868421052631579 on epoch=149
05/16/2022 14:50:33 - INFO - __main__ - Step 610 Global step 610 Train loss 1.28 on epoch=152
05/16/2022 14:50:35 - INFO - __main__ - Step 620 Global step 620 Train loss 1.29 on epoch=154
05/16/2022 14:50:36 - INFO - __main__ - Step 630 Global step 630 Train loss 1.31 on epoch=157
05/16/2022 14:50:37 - INFO - __main__ - Step 640 Global step 640 Train loss 1.30 on epoch=159
05/16/2022 14:50:39 - INFO - __main__ - Step 650 Global step 650 Train loss 1.17 on epoch=162
05/16/2022 14:50:39 - INFO - __main__ - Global step 650 Train loss 1.27 Classification-F1 0.1 on epoch=162
05/16/2022 14:50:41 - INFO - __main__ - Step 660 Global step 660 Train loss 1.20 on epoch=164
05/16/2022 14:50:42 - INFO - __main__ - Step 670 Global step 670 Train loss 1.21 on epoch=167
05/16/2022 14:50:43 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=169
05/16/2022 14:50:45 - INFO - __main__ - Step 690 Global step 690 Train loss 1.23 on epoch=172
05/16/2022 14:50:46 - INFO - __main__ - Step 700 Global step 700 Train loss 1.21 on epoch=174
05/16/2022 14:50:47 - INFO - __main__ - Global step 700 Train loss 1.22 Classification-F1 0.15682382133995038 on epoch=174
05/16/2022 14:50:48 - INFO - __main__ - Step 710 Global step 710 Train loss 1.24 on epoch=177
05/16/2022 14:50:49 - INFO - __main__ - Step 720 Global step 720 Train loss 1.23 on epoch=179
05/16/2022 14:50:51 - INFO - __main__ - Step 730 Global step 730 Train loss 1.17 on epoch=182
05/16/2022 14:50:52 - INFO - __main__ - Step 740 Global step 740 Train loss 1.28 on epoch=184
05/16/2022 14:50:53 - INFO - __main__ - Step 750 Global step 750 Train loss 1.14 on epoch=187
05/16/2022 14:50:54 - INFO - __main__ - Global step 750 Train loss 1.21 Classification-F1 0.20277777777777778 on epoch=187
05/16/2022 14:50:54 - INFO - __main__ - Saving model with best Classification-F1: 0.1970899470899471 -> 0.20277777777777778 on epoch=187, global_step=750
05/16/2022 14:50:55 - INFO - __main__ - Step 760 Global step 760 Train loss 1.15 on epoch=189
05/16/2022 14:50:57 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=192
05/16/2022 14:50:58 - INFO - __main__ - Step 780 Global step 780 Train loss 1.19 on epoch=194
05/16/2022 14:50:59 - INFO - __main__ - Step 790 Global step 790 Train loss 1.11 on epoch=197
05/16/2022 14:51:01 - INFO - __main__ - Step 800 Global step 800 Train loss 1.29 on epoch=199
05/16/2022 14:51:01 - INFO - __main__ - Global step 800 Train loss 1.19 Classification-F1 0.0974025974025974 on epoch=199
05/16/2022 14:51:02 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=202
05/16/2022 14:51:04 - INFO - __main__ - Step 820 Global step 820 Train loss 1.16 on epoch=204
05/16/2022 14:51:05 - INFO - __main__ - Step 830 Global step 830 Train loss 1.22 on epoch=207
05/16/2022 14:51:07 - INFO - __main__ - Step 840 Global step 840 Train loss 1.14 on epoch=209
05/16/2022 14:51:08 - INFO - __main__ - Step 850 Global step 850 Train loss 1.24 on epoch=212
05/16/2022 14:51:08 - INFO - __main__ - Global step 850 Train loss 1.17 Classification-F1 0.23076923076923078 on epoch=212
05/16/2022 14:51:09 - INFO - __main__ - Saving model with best Classification-F1: 0.20277777777777778 -> 0.23076923076923078 on epoch=212, global_step=850
05/16/2022 14:51:10 - INFO - __main__ - Step 860 Global step 860 Train loss 1.10 on epoch=214
05/16/2022 14:51:11 - INFO - __main__ - Step 870 Global step 870 Train loss 1.17 on epoch=217
05/16/2022 14:51:13 - INFO - __main__ - Step 880 Global step 880 Train loss 1.19 on epoch=219
05/16/2022 14:51:14 - INFO - __main__ - Step 890 Global step 890 Train loss 1.18 on epoch=222
05/16/2022 14:51:16 - INFO - __main__ - Step 900 Global step 900 Train loss 1.18 on epoch=224
05/16/2022 14:51:16 - INFO - __main__ - Global step 900 Train loss 1.17 Classification-F1 0.1256338028169014 on epoch=224
05/16/2022 14:51:18 - INFO - __main__ - Step 910 Global step 910 Train loss 1.18 on epoch=227
05/16/2022 14:51:19 - INFO - __main__ - Step 920 Global step 920 Train loss 1.18 on epoch=229
05/16/2022 14:51:20 - INFO - __main__ - Step 930 Global step 930 Train loss 1.20 on epoch=232
05/16/2022 14:51:22 - INFO - __main__ - Step 940 Global step 940 Train loss 1.06 on epoch=234
05/16/2022 14:51:23 - INFO - __main__ - Step 950 Global step 950 Train loss 1.10 on epoch=237
05/16/2022 14:51:24 - INFO - __main__ - Global step 950 Train loss 1.14 Classification-F1 0.22059553349875932 on epoch=237
05/16/2022 14:51:25 - INFO - __main__ - Step 960 Global step 960 Train loss 1.12 on epoch=239
05/16/2022 14:51:26 - INFO - __main__ - Step 970 Global step 970 Train loss 1.06 on epoch=242
05/16/2022 14:51:28 - INFO - __main__ - Step 980 Global step 980 Train loss 1.04 on epoch=244
05/16/2022 14:51:29 - INFO - __main__ - Step 990 Global step 990 Train loss 1.12 on epoch=247
05/16/2022 14:51:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.04 on epoch=249
05/16/2022 14:51:31 - INFO - __main__ - Global step 1000 Train loss 1.08 Classification-F1 0.16666666666666666 on epoch=249
05/16/2022 14:51:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.16 on epoch=252
05/16/2022 14:51:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.03 on epoch=254
05/16/2022 14:51:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/16/2022 14:51:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.91 on epoch=259
05/16/2022 14:51:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.12 on epoch=262
05/16/2022 14:51:39 - INFO - __main__ - Global step 1050 Train loss 1.06 Classification-F1 0.21743697478991597 on epoch=262
05/16/2022 14:51:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=264
05/16/2022 14:51:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.99 on epoch=267
05/16/2022 14:51:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=269
05/16/2022 14:51:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.12 on epoch=272
05/16/2022 14:51:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.10 on epoch=274
05/16/2022 14:51:47 - INFO - __main__ - Global step 1100 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=274
05/16/2022 14:51:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.10 on epoch=277
05/16/2022 14:51:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.04 on epoch=279
05/16/2022 14:51:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.10 on epoch=282
05/16/2022 14:51:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.07 on epoch=284
05/16/2022 14:51:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.98 on epoch=287
05/16/2022 14:51:55 - INFO - __main__ - Global step 1150 Train loss 1.06 Classification-F1 0.11762954139368673 on epoch=287
05/16/2022 14:51:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.04 on epoch=289
05/16/2022 14:51:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.10 on epoch=292
05/16/2022 14:51:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.06 on epoch=294
05/16/2022 14:52:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.17 on epoch=297
05/16/2022 14:52:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.04 on epoch=299
05/16/2022 14:52:02 - INFO - __main__ - Global step 1200 Train loss 1.08 Classification-F1 0.16785714285714287 on epoch=299
05/16/2022 14:52:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.07 on epoch=302
05/16/2022 14:52:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.16 on epoch=304
05/16/2022 14:52:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.07 on epoch=307
05/16/2022 14:52:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
05/16/2022 14:52:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.16 on epoch=312
05/16/2022 14:52:10 - INFO - __main__ - Global step 1250 Train loss 1.11 Classification-F1 0.11714285714285715 on epoch=312
05/16/2022 14:52:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.05 on epoch=314
05/16/2022 14:52:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.08 on epoch=317
05/16/2022 14:52:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.99 on epoch=319
05/16/2022 14:52:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.04 on epoch=322
05/16/2022 14:52:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.11 on epoch=324
05/16/2022 14:52:18 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.22026143790849673 on epoch=324
05/16/2022 14:52:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.04 on epoch=327
05/16/2022 14:52:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.03 on epoch=329
05/16/2022 14:52:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.95 on epoch=332
05/16/2022 14:52:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.99 on epoch=334
05/16/2022 14:52:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.02 on epoch=337
05/16/2022 14:52:26 - INFO - __main__ - Global step 1350 Train loss 1.01 Classification-F1 0.1527777777777778 on epoch=337
05/16/2022 14:52:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.02 on epoch=339
05/16/2022 14:52:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/16/2022 14:52:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.13 on epoch=344
05/16/2022 14:52:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.24 on epoch=347
05/16/2022 14:52:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.13 on epoch=349
05/16/2022 14:52:34 - INFO - __main__ - Global step 1400 Train loss 1.12 Classification-F1 0.13067758749069247 on epoch=349
05/16/2022 14:52:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.15 on epoch=352
05/16/2022 14:52:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.21 on epoch=354
05/16/2022 14:52:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.05 on epoch=357
05/16/2022 14:52:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.21 on epoch=359
05/16/2022 14:52:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=362
05/16/2022 14:52:41 - INFO - __main__ - Global step 1450 Train loss 1.14 Classification-F1 0.21827759963353183 on epoch=362
05/16/2022 14:52:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.11 on epoch=364
05/16/2022 14:52:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.17 on epoch=367
05/16/2022 14:52:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.13 on epoch=369
05/16/2022 14:52:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.10 on epoch=372
05/16/2022 14:52:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.16 on epoch=374
05/16/2022 14:52:49 - INFO - __main__ - Global step 1500 Train loss 1.13 Classification-F1 0.1873628784554629 on epoch=374
05/16/2022 14:52:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.09 on epoch=377
05/16/2022 14:52:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
05/16/2022 14:52:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
05/16/2022 14:52:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.18 on epoch=384
05/16/2022 14:52:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.02 on epoch=387
05/16/2022 14:52:57 - INFO - __main__ - Global step 1550 Train loss 1.08 Classification-F1 0.1732142857142857 on epoch=387
05/16/2022 14:52:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.00 on epoch=389
05/16/2022 14:52:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.12 on epoch=392
05/16/2022 14:53:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.02 on epoch=394
05/16/2022 14:53:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=397
05/16/2022 14:53:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
05/16/2022 14:53:04 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.15625 on epoch=399
05/16/2022 14:53:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.09 on epoch=402
05/16/2022 14:53:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/16/2022 14:53:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.04 on epoch=407
05/16/2022 14:53:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.90 on epoch=409
05/16/2022 14:53:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.16 on epoch=412
05/16/2022 14:53:12 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.14583333333333334 on epoch=412
05/16/2022 14:53:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.05 on epoch=414
05/16/2022 14:53:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.03 on epoch=417
05/16/2022 14:53:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.09 on epoch=419
05/16/2022 14:53:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.13 on epoch=422
05/16/2022 14:53:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=424
05/16/2022 14:53:19 - INFO - __main__ - Global step 1700 Train loss 1.07 Classification-F1 0.13067758749069247 on epoch=424
05/16/2022 14:53:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.98 on epoch=427
05/16/2022 14:53:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.03 on epoch=429
05/16/2022 14:53:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.06 on epoch=432
05/16/2022 14:53:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
05/16/2022 14:53:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.19 on epoch=437
05/16/2022 14:53:26 - INFO - __main__ - Global step 1750 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=437
05/16/2022 14:53:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
05/16/2022 14:53:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
05/16/2022 14:53:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/16/2022 14:53:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.98 on epoch=447
05/16/2022 14:53:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=449
05/16/2022 14:53:33 - INFO - __main__ - Global step 1800 Train loss 1.04 Classification-F1 0.1 on epoch=449
05/16/2022 14:53:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/16/2022 14:53:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.08 on epoch=454
05/16/2022 14:53:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.07 on epoch=457
05/16/2022 14:53:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.24 on epoch=459
05/16/2022 14:53:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.15 on epoch=462
05/16/2022 14:53:41 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.16666666666666666 on epoch=462
05/16/2022 14:53:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.05 on epoch=464
05/16/2022 14:53:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.97 on epoch=467
05/16/2022 14:53:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.08 on epoch=469
05/16/2022 14:53:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.97 on epoch=472
05/16/2022 14:53:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.00 on epoch=474
05/16/2022 14:53:49 - INFO - __main__ - Global step 1900 Train loss 1.01 Classification-F1 0.11714285714285715 on epoch=474
05/16/2022 14:53:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
05/16/2022 14:53:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
05/16/2022 14:53:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.93 on epoch=482
05/16/2022 14:53:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
05/16/2022 14:53:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.95 on epoch=487
05/16/2022 14:53:57 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.1 on epoch=487
05/16/2022 14:53:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.03 on epoch=489
05/16/2022 14:54:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/16/2022 14:54:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.92 on epoch=494
05/16/2022 14:54:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.11 on epoch=497
05/16/2022 14:54:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.94 on epoch=499
05/16/2022 14:54:05 - INFO - __main__ - Global step 2000 Train loss 1.00 Classification-F1 0.10256410256410256 on epoch=499
05/16/2022 14:54:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.09 on epoch=502
05/16/2022 14:54:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.93 on epoch=504
05/16/2022 14:54:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.07 on epoch=507
05/16/2022 14:54:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.04 on epoch=509
05/16/2022 14:54:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.98 on epoch=512
05/16/2022 14:54:13 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.1 on epoch=512
05/16/2022 14:54:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.08 on epoch=514
05/16/2022 14:54:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
05/16/2022 14:54:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.06 on epoch=519
05/16/2022 14:54:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.98 on epoch=522
05/16/2022 14:54:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.01 on epoch=524
05/16/2022 14:54:21 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.09493670886075949 on epoch=524
05/16/2022 14:54:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.10 on epoch=527
05/16/2022 14:54:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
05/16/2022 14:54:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
05/16/2022 14:54:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.89 on epoch=534
05/16/2022 14:54:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
05/16/2022 14:54:28 - INFO - __main__ - Global step 2150 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=537
05/16/2022 14:54:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.95 on epoch=539
05/16/2022 14:54:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.89 on epoch=542
05/16/2022 14:54:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/16/2022 14:54:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/16/2022 14:54:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
05/16/2022 14:54:36 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.1 on epoch=549
05/16/2022 14:54:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/16/2022 14:54:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.05 on epoch=554
05/16/2022 14:54:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=557
05/16/2022 14:54:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.92 on epoch=559
05/16/2022 14:54:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/16/2022 14:54:44 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.1796875 on epoch=562
05/16/2022 14:54:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.02 on epoch=564
05/16/2022 14:54:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.04 on epoch=567
05/16/2022 14:54:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.98 on epoch=569
05/16/2022 14:54:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
05/16/2022 14:54:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/16/2022 14:54:52 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.14304993252361672 on epoch=574
05/16/2022 14:54:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.97 on epoch=577
05/16/2022 14:54:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/16/2022 14:54:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.91 on epoch=582
05/16/2022 14:54:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.90 on epoch=584
05/16/2022 14:54:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.92 on epoch=587
05/16/2022 14:54:59 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.1576923076923077 on epoch=587
05/16/2022 14:55:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.95 on epoch=589
05/16/2022 14:55:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.96 on epoch=592
05/16/2022 14:55:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.97 on epoch=594
05/16/2022 14:55:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.07 on epoch=597
05/16/2022 14:55:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.91 on epoch=599
05/16/2022 14:55:06 - INFO - __main__ - Global step 2400 Train loss 0.97 Classification-F1 0.1 on epoch=599
05/16/2022 14:55:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.95 on epoch=602
05/16/2022 14:55:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.92 on epoch=604
05/16/2022 14:55:11 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.02 on epoch=607
05/16/2022 14:55:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.86 on epoch=609
05/16/2022 14:55:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.93 on epoch=612
05/16/2022 14:55:14 - INFO - __main__ - Global step 2450 Train loss 0.94 Classification-F1 0.1 on epoch=612
05/16/2022 14:55:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.01 on epoch=614
05/16/2022 14:55:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/16/2022 14:55:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.93 on epoch=619
05/16/2022 14:55:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
05/16/2022 14:55:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.99 on epoch=624
05/16/2022 14:55:22 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.1682769726247987 on epoch=624
05/16/2022 14:55:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/16/2022 14:55:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.03 on epoch=629
05/16/2022 14:55:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.01 on epoch=632
05/16/2022 14:55:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/16/2022 14:55:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.00 on epoch=637
05/16/2022 14:55:29 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=637
05/16/2022 14:55:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.07 on epoch=639
05/16/2022 14:55:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.97 on epoch=642
05/16/2022 14:55:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.86 on epoch=644
05/16/2022 14:55:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/16/2022 14:55:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.93 on epoch=649
05/16/2022 14:55:37 - INFO - __main__ - Global step 2600 Train loss 0.95 Classification-F1 0.15625 on epoch=649
05/16/2022 14:55:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/16/2022 14:55:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
05/16/2022 14:55:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.02 on epoch=657
05/16/2022 14:55:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.09 on epoch=659
05/16/2022 14:55:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
05/16/2022 14:55:44 - INFO - __main__ - Global step 2650 Train loss 1.02 Classification-F1 0.1354895104895105 on epoch=662
05/16/2022 14:55:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.96 on epoch=664
05/16/2022 14:55:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/16/2022 14:55:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
05/16/2022 14:55:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.07 on epoch=672
05/16/2022 14:55:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/16/2022 14:55:52 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.20980302336234538 on epoch=674
05/16/2022 14:55:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/16/2022 14:55:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.98 on epoch=679
05/16/2022 14:55:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.02 on epoch=682
05/16/2022 14:55:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.93 on epoch=684
05/16/2022 14:55:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=687
05/16/2022 14:56:00 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.1767857142857143 on epoch=687
05/16/2022 14:56:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.03 on epoch=689
05/16/2022 14:56:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
05/16/2022 14:56:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/16/2022 14:56:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
05/16/2022 14:56:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=699
05/16/2022 14:56:07 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.10126582278481013 on epoch=699
05/16/2022 14:56:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.99 on epoch=702
05/16/2022 14:56:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.03 on epoch=704
05/16/2022 14:56:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.97 on epoch=707
05/16/2022 14:56:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/16/2022 14:56:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
05/16/2022 14:56:15 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.10126582278481013 on epoch=712
05/16/2022 14:56:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.03 on epoch=714
05/16/2022 14:56:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.82 on epoch=717
05/16/2022 14:56:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.90 on epoch=719
05/16/2022 14:56:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/16/2022 14:56:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
05/16/2022 14:56:22 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.14383875400824553 on epoch=724
05/16/2022 14:56:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.93 on epoch=727
05/16/2022 14:56:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/16/2022 14:56:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.02 on epoch=732
05/16/2022 14:56:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
05/16/2022 14:56:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/16/2022 14:56:30 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.1171875 on epoch=737
05/16/2022 14:56:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/16/2022 14:56:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/16/2022 14:56:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
05/16/2022 14:56:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/16/2022 14:56:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.00 on epoch=749
05/16/2022 14:56:38 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.14583333333333331 on epoch=749
05/16/2022 14:56:38 - INFO - __main__ - save last model!
05/16/2022 14:56:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 14:56:38 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 14:56:38 - INFO - __main__ - Printing 3 examples
05/16/2022 14:56:38 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 14:56:38 - INFO - __main__ - ['others']
05/16/2022 14:56:38 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 14:56:38 - INFO - __main__ - ['others']
05/16/2022 14:56:38 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 14:56:38 - INFO - __main__ - ['others']
05/16/2022 14:56:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:56:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:56:39 - INFO - __main__ - Printing 3 examples
05/16/2022 14:56:39 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 14:56:39 - INFO - __main__ - ['others']
05/16/2022 14:56:39 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 14:56:39 - INFO - __main__ - ['others']
05/16/2022 14:56:39 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 14:56:39 - INFO - __main__ - ['others']
05/16/2022 14:56:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:56:39 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:56:39 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:56:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:56:39 - INFO - __main__ - Printing 3 examples
05/16/2022 14:56:39 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 14:56:39 - INFO - __main__ - ['others']
05/16/2022 14:56:39 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 14:56:39 - INFO - __main__ - ['others']
05/16/2022 14:56:39 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 14:56:39 - INFO - __main__ - ['others']
05/16/2022 14:56:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:56:39 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:56:39 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:56:40 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:56:45 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:56:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:56:45 - INFO - __main__ - Starting training!
05/16/2022 14:56:46 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 14:57:32 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.5_8_predictions.txt
05/16/2022 14:57:32 - INFO - __main__ - Classification-F1 on test data: 0.0401
05/16/2022 14:57:32 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.23076923076923078, test_performance=0.04012249342932043
05/16/2022 14:57:32 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
05/16/2022 14:57:33 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:57:33 - INFO - __main__ - Printing 3 examples
05/16/2022 14:57:33 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 14:57:33 - INFO - __main__ - ['others']
05/16/2022 14:57:33 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 14:57:33 - INFO - __main__ - ['others']
05/16/2022 14:57:33 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 14:57:33 - INFO - __main__ - ['others']
05/16/2022 14:57:33 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:57:33 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:57:33 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 14:57:33 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 14:57:33 - INFO - __main__ - Printing 3 examples
05/16/2022 14:57:33 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 14:57:33 - INFO - __main__ - ['others']
05/16/2022 14:57:33 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 14:57:33 - INFO - __main__ - ['others']
05/16/2022 14:57:33 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 14:57:33 - INFO - __main__ - ['others']
05/16/2022 14:57:33 - INFO - __main__ - Tokenizing Input ...
05/16/2022 14:57:33 - INFO - __main__ - Tokenizing Output ...
05/16/2022 14:57:33 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 14:57:39 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 14:57:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 14:57:39 - INFO - __main__ - Starting training!
05/16/2022 14:57:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=2
05/16/2022 14:57:42 - INFO - __main__ - Step 20 Global step 20 Train loss 6.37 on epoch=4
05/16/2022 14:57:43 - INFO - __main__ - Step 30 Global step 30 Train loss 5.99 on epoch=7
05/16/2022 14:57:45 - INFO - __main__ - Step 40 Global step 40 Train loss 5.61 on epoch=9
05/16/2022 14:57:46 - INFO - __main__ - Step 50 Global step 50 Train loss 5.46 on epoch=12
05/16/2022 14:57:50 - INFO - __main__ - Global step 50 Train loss 6.03 Classification-F1 0.0 on epoch=12
05/16/2022 14:57:50 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 14:57:51 - INFO - __main__ - Step 60 Global step 60 Train loss 5.21 on epoch=14
05/16/2022 14:57:52 - INFO - __main__ - Step 70 Global step 70 Train loss 5.05 on epoch=17
05/16/2022 14:57:53 - INFO - __main__ - Step 80 Global step 80 Train loss 4.74 on epoch=19
05/16/2022 14:57:55 - INFO - __main__ - Step 90 Global step 90 Train loss 4.67 on epoch=22
05/16/2022 14:57:56 - INFO - __main__ - Step 100 Global step 100 Train loss 4.65 on epoch=24
05/16/2022 14:58:01 - INFO - __main__ - Global step 100 Train loss 4.86 Classification-F1 0.0101010101010101 on epoch=24
05/16/2022 14:58:01 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0101010101010101 on epoch=24, global_step=100
05/16/2022 14:58:02 - INFO - __main__ - Step 110 Global step 110 Train loss 4.50 on epoch=27
05/16/2022 14:58:03 - INFO - __main__ - Step 120 Global step 120 Train loss 4.44 on epoch=29
05/16/2022 14:58:05 - INFO - __main__ - Step 130 Global step 130 Train loss 4.29 on epoch=32
05/16/2022 14:58:06 - INFO - __main__ - Step 140 Global step 140 Train loss 3.96 on epoch=34
05/16/2022 14:58:07 - INFO - __main__ - Step 150 Global step 150 Train loss 4.11 on epoch=37
05/16/2022 14:58:08 - INFO - __main__ - Global step 150 Train loss 4.26 Classification-F1 0.1 on epoch=37
05/16/2022 14:58:08 - INFO - __main__ - Saving model with best Classification-F1: 0.0101010101010101 -> 0.1 on epoch=37, global_step=150
05/16/2022 14:58:09 - INFO - __main__ - Step 160 Global step 160 Train loss 3.78 on epoch=39
05/16/2022 14:58:11 - INFO - __main__ - Step 170 Global step 170 Train loss 3.77 on epoch=42
05/16/2022 14:58:12 - INFO - __main__ - Step 180 Global step 180 Train loss 3.47 on epoch=44
05/16/2022 14:58:13 - INFO - __main__ - Step 190 Global step 190 Train loss 3.63 on epoch=47
05/16/2022 14:58:14 - INFO - __main__ - Step 200 Global step 200 Train loss 3.36 on epoch=49
05/16/2022 14:58:15 - INFO - __main__ - Global step 200 Train loss 3.60 Classification-F1 0.1 on epoch=49
05/16/2022 14:58:16 - INFO - __main__ - Step 210 Global step 210 Train loss 3.43 on epoch=52
05/16/2022 14:58:18 - INFO - __main__ - Step 220 Global step 220 Train loss 3.09 on epoch=54
05/16/2022 14:58:19 - INFO - __main__ - Step 230 Global step 230 Train loss 3.27 on epoch=57
05/16/2022 14:58:20 - INFO - __main__ - Step 240 Global step 240 Train loss 3.16 on epoch=59
05/16/2022 14:58:22 - INFO - __main__ - Step 250 Global step 250 Train loss 3.16 on epoch=62
05/16/2022 14:58:22 - INFO - __main__ - Global step 250 Train loss 3.22 Classification-F1 0.08108108108108109 on epoch=62
05/16/2022 14:58:23 - INFO - __main__ - Step 260 Global step 260 Train loss 3.05 on epoch=64
05/16/2022 14:58:25 - INFO - __main__ - Step 270 Global step 270 Train loss 3.19 on epoch=67
05/16/2022 14:58:26 - INFO - __main__ - Step 280 Global step 280 Train loss 2.76 on epoch=69
05/16/2022 14:58:27 - INFO - __main__ - Step 290 Global step 290 Train loss 2.76 on epoch=72
05/16/2022 14:58:29 - INFO - __main__ - Step 300 Global step 300 Train loss 2.83 on epoch=74
05/16/2022 14:58:29 - INFO - __main__ - Global step 300 Train loss 2.92 Classification-F1 0.10256410256410256 on epoch=74
05/16/2022 14:58:29 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10256410256410256 on epoch=74, global_step=300
05/16/2022 14:58:30 - INFO - __main__ - Step 310 Global step 310 Train loss 2.76 on epoch=77
05/16/2022 14:58:32 - INFO - __main__ - Step 320 Global step 320 Train loss 2.60 on epoch=79
05/16/2022 14:58:33 - INFO - __main__ - Step 330 Global step 330 Train loss 2.85 on epoch=82
05/16/2022 14:58:34 - INFO - __main__ - Step 340 Global step 340 Train loss 2.52 on epoch=84
05/16/2022 14:58:35 - INFO - __main__ - Step 350 Global step 350 Train loss 2.61 on epoch=87
05/16/2022 14:58:36 - INFO - __main__ - Global step 350 Train loss 2.67 Classification-F1 0.23911070780399274 on epoch=87
05/16/2022 14:58:36 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.23911070780399274 on epoch=87, global_step=350
05/16/2022 14:58:37 - INFO - __main__ - Step 360 Global step 360 Train loss 2.34 on epoch=89
05/16/2022 14:58:39 - INFO - __main__ - Step 370 Global step 370 Train loss 2.56 on epoch=92
05/16/2022 14:58:40 - INFO - __main__ - Step 380 Global step 380 Train loss 2.29 on epoch=94
05/16/2022 14:58:42 - INFO - __main__ - Step 390 Global step 390 Train loss 2.43 on epoch=97
05/16/2022 14:58:43 - INFO - __main__ - Step 400 Global step 400 Train loss 2.16 on epoch=99
05/16/2022 14:58:44 - INFO - __main__ - Global step 400 Train loss 2.35 Classification-F1 0.1 on epoch=99
05/16/2022 14:58:45 - INFO - __main__ - Step 410 Global step 410 Train loss 2.30 on epoch=102
05/16/2022 14:58:46 - INFO - __main__ - Step 420 Global step 420 Train loss 2.06 on epoch=104
05/16/2022 14:58:48 - INFO - __main__ - Step 430 Global step 430 Train loss 2.19 on epoch=107
05/16/2022 14:58:49 - INFO - __main__ - Step 440 Global step 440 Train loss 2.25 on epoch=109
05/16/2022 14:58:50 - INFO - __main__ - Step 450 Global step 450 Train loss 2.13 on epoch=112
05/16/2022 14:58:51 - INFO - __main__ - Global step 450 Train loss 2.19 Classification-F1 0.1237183868762816 on epoch=112
05/16/2022 14:58:52 - INFO - __main__ - Step 460 Global step 460 Train loss 2.16 on epoch=114
05/16/2022 14:58:53 - INFO - __main__ - Step 470 Global step 470 Train loss 2.08 on epoch=117
05/16/2022 14:58:55 - INFO - __main__ - Step 480 Global step 480 Train loss 2.00 on epoch=119
05/16/2022 14:58:56 - INFO - __main__ - Step 490 Global step 490 Train loss 2.12 on epoch=122
05/16/2022 14:58:57 - INFO - __main__ - Step 500 Global step 500 Train loss 1.92 on epoch=124
05/16/2022 14:58:58 - INFO - __main__ - Global step 500 Train loss 2.05 Classification-F1 0.1 on epoch=124
05/16/2022 14:58:59 - INFO - __main__ - Step 510 Global step 510 Train loss 1.92 on epoch=127
05/16/2022 14:59:01 - INFO - __main__ - Step 520 Global step 520 Train loss 1.85 on epoch=129
05/16/2022 14:59:02 - INFO - __main__ - Step 530 Global step 530 Train loss 1.89 on epoch=132
05/16/2022 14:59:04 - INFO - __main__ - Step 540 Global step 540 Train loss 1.92 on epoch=134
05/16/2022 14:59:05 - INFO - __main__ - Step 550 Global step 550 Train loss 1.72 on epoch=137
05/16/2022 14:59:06 - INFO - __main__ - Global step 550 Train loss 1.86 Classification-F1 0.16666666666666666 on epoch=137
05/16/2022 14:59:07 - INFO - __main__ - Step 560 Global step 560 Train loss 1.68 on epoch=139
05/16/2022 14:59:08 - INFO - __main__ - Step 570 Global step 570 Train loss 1.83 on epoch=142
05/16/2022 14:59:10 - INFO - __main__ - Step 580 Global step 580 Train loss 1.83 on epoch=144
05/16/2022 14:59:11 - INFO - __main__ - Step 590 Global step 590 Train loss 1.77 on epoch=147
05/16/2022 14:59:13 - INFO - __main__ - Step 600 Global step 600 Train loss 1.57 on epoch=149
05/16/2022 14:59:14 - INFO - __main__ - Global step 600 Train loss 1.74 Classification-F1 0.16407982261640797 on epoch=149
05/16/2022 14:59:15 - INFO - __main__ - Step 610 Global step 610 Train loss 1.62 on epoch=152
05/16/2022 14:59:16 - INFO - __main__ - Step 620 Global step 620 Train loss 1.66 on epoch=154
05/16/2022 14:59:18 - INFO - __main__ - Step 630 Global step 630 Train loss 1.77 on epoch=157
05/16/2022 14:59:19 - INFO - __main__ - Step 640 Global step 640 Train loss 1.61 on epoch=159
05/16/2022 14:59:20 - INFO - __main__ - Step 650 Global step 650 Train loss 1.67 on epoch=162
05/16/2022 14:59:21 - INFO - __main__ - Global step 650 Train loss 1.67 Classification-F1 0.14107142857142857 on epoch=162
05/16/2022 14:59:22 - INFO - __main__ - Step 660 Global step 660 Train loss 1.63 on epoch=164
05/16/2022 14:59:24 - INFO - __main__ - Step 670 Global step 670 Train loss 1.51 on epoch=167
05/16/2022 14:59:25 - INFO - __main__ - Step 680 Global step 680 Train loss 1.46 on epoch=169
05/16/2022 14:59:26 - INFO - __main__ - Step 690 Global step 690 Train loss 1.62 on epoch=172
05/16/2022 14:59:28 - INFO - __main__ - Step 700 Global step 700 Train loss 1.48 on epoch=174
05/16/2022 14:59:28 - INFO - __main__ - Global step 700 Train loss 1.54 Classification-F1 0.08863636363636362 on epoch=174
05/16/2022 14:59:30 - INFO - __main__ - Step 710 Global step 710 Train loss 1.63 on epoch=177
05/16/2022 14:59:31 - INFO - __main__ - Step 720 Global step 720 Train loss 1.44 on epoch=179
05/16/2022 14:59:33 - INFO - __main__ - Step 730 Global step 730 Train loss 1.45 on epoch=182
05/16/2022 14:59:34 - INFO - __main__ - Step 740 Global step 740 Train loss 1.43 on epoch=184
05/16/2022 14:59:36 - INFO - __main__ - Step 750 Global step 750 Train loss 1.31 on epoch=187
05/16/2022 14:59:36 - INFO - __main__ - Global step 750 Train loss 1.45 Classification-F1 0.19149305555555554 on epoch=187
05/16/2022 14:59:37 - INFO - __main__ - Step 760 Global step 760 Train loss 1.61 on epoch=189
05/16/2022 14:59:39 - INFO - __main__ - Step 770 Global step 770 Train loss 1.30 on epoch=192
05/16/2022 14:59:40 - INFO - __main__ - Step 780 Global step 780 Train loss 1.35 on epoch=194
05/16/2022 14:59:42 - INFO - __main__ - Step 790 Global step 790 Train loss 1.46 on epoch=197
05/16/2022 14:59:43 - INFO - __main__ - Step 800 Global step 800 Train loss 1.33 on epoch=199
05/16/2022 14:59:44 - INFO - __main__ - Global step 800 Train loss 1.41 Classification-F1 0.13525835866261396 on epoch=199
05/16/2022 14:59:45 - INFO - __main__ - Step 810 Global step 810 Train loss 1.38 on epoch=202
05/16/2022 14:59:46 - INFO - __main__ - Step 820 Global step 820 Train loss 1.43 on epoch=204
05/16/2022 14:59:48 - INFO - __main__ - Step 830 Global step 830 Train loss 1.31 on epoch=207
05/16/2022 14:59:49 - INFO - __main__ - Step 840 Global step 840 Train loss 1.43 on epoch=209
05/16/2022 14:59:50 - INFO - __main__ - Step 850 Global step 850 Train loss 1.30 on epoch=212
05/16/2022 14:59:51 - INFO - __main__ - Global step 850 Train loss 1.37 Classification-F1 0.13475499092558985 on epoch=212
05/16/2022 14:59:52 - INFO - __main__ - Step 860 Global step 860 Train loss 1.23 on epoch=214
05/16/2022 14:59:54 - INFO - __main__ - Step 870 Global step 870 Train loss 1.24 on epoch=217
05/16/2022 14:59:55 - INFO - __main__ - Step 880 Global step 880 Train loss 1.38 on epoch=219
05/16/2022 14:59:57 - INFO - __main__ - Step 890 Global step 890 Train loss 1.25 on epoch=222
05/16/2022 14:59:58 - INFO - __main__ - Step 900 Global step 900 Train loss 1.24 on epoch=224
05/16/2022 14:59:59 - INFO - __main__ - Global step 900 Train loss 1.27 Classification-F1 0.13026315789473686 on epoch=224
05/16/2022 15:00:00 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/16/2022 15:00:02 - INFO - __main__ - Step 920 Global step 920 Train loss 1.27 on epoch=229
05/16/2022 15:00:03 - INFO - __main__ - Step 930 Global step 930 Train loss 1.27 on epoch=232
05/16/2022 15:00:04 - INFO - __main__ - Step 940 Global step 940 Train loss 1.15 on epoch=234
05/16/2022 15:00:06 - INFO - __main__ - Step 950 Global step 950 Train loss 1.30 on epoch=237
05/16/2022 15:00:06 - INFO - __main__ - Global step 950 Train loss 1.24 Classification-F1 0.10666666666666667 on epoch=237
05/16/2022 15:00:07 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
05/16/2022 15:00:09 - INFO - __main__ - Step 970 Global step 970 Train loss 1.27 on epoch=242
05/16/2022 15:00:10 - INFO - __main__ - Step 980 Global step 980 Train loss 1.21 on epoch=244
05/16/2022 15:00:12 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=247
05/16/2022 15:00:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.24 on epoch=249
05/16/2022 15:00:14 - INFO - __main__ - Global step 1000 Train loss 1.28 Classification-F1 0.13067758749069247 on epoch=249
05/16/2022 15:00:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.20 on epoch=252
05/16/2022 15:00:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.36 on epoch=254
05/16/2022 15:00:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.21 on epoch=257
05/16/2022 15:00:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.23 on epoch=259
05/16/2022 15:00:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.16 on epoch=262
05/16/2022 15:00:21 - INFO - __main__ - Global step 1050 Train loss 1.23 Classification-F1 0.18920361247947456 on epoch=262
05/16/2022 15:00:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.21 on epoch=264
05/16/2022 15:00:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.24 on epoch=267
05/16/2022 15:00:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
05/16/2022 15:00:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.20 on epoch=272
05/16/2022 15:00:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.07 on epoch=274
05/16/2022 15:00:29 - INFO - __main__ - Global step 1100 Train loss 1.18 Classification-F1 0.15208955223880596 on epoch=274
05/16/2022 15:00:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.00 on epoch=277
05/16/2022 15:00:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.05 on epoch=279
05/16/2022 15:00:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.21 on epoch=282
05/16/2022 15:00:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.98 on epoch=284
05/16/2022 15:00:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.27 on epoch=287
05/16/2022 15:00:37 - INFO - __main__ - Global step 1150 Train loss 1.10 Classification-F1 0.178243195475433 on epoch=287
05/16/2022 15:00:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.15 on epoch=289
05/16/2022 15:00:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.14 on epoch=292
05/16/2022 15:00:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.07 on epoch=294
05/16/2022 15:00:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.17 on epoch=297
05/16/2022 15:00:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.26 on epoch=299
05/16/2022 15:00:44 - INFO - __main__ - Global step 1200 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=299
05/16/2022 15:00:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
05/16/2022 15:00:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.08 on epoch=304
05/16/2022 15:00:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.19 on epoch=307
05/16/2022 15:00:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.16 on epoch=309
05/16/2022 15:00:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.02 on epoch=312
05/16/2022 15:00:52 - INFO - __main__ - Global step 1250 Train loss 1.12 Classification-F1 0.18860472005529771 on epoch=312
05/16/2022 15:00:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.01 on epoch=314
05/16/2022 15:00:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.07 on epoch=317
05/16/2022 15:00:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
05/16/2022 15:00:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.17 on epoch=322
05/16/2022 15:00:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.10 on epoch=324
05/16/2022 15:00:59 - INFO - __main__ - Global step 1300 Train loss 1.10 Classification-F1 0.14210526315789473 on epoch=324
05/16/2022 15:01:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.17 on epoch=327
05/16/2022 15:01:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.08 on epoch=329
05/16/2022 15:01:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=332
05/16/2022 15:01:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.10 on epoch=334
05/16/2022 15:01:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.13 on epoch=337
05/16/2022 15:01:06 - INFO - __main__ - Global step 1350 Train loss 1.14 Classification-F1 0.12407862407862408 on epoch=337
05/16/2022 15:01:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/16/2022 15:01:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/16/2022 15:01:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.07 on epoch=344
05/16/2022 15:01:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.17 on epoch=347
05/16/2022 15:01:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=349
05/16/2022 15:01:13 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.10666666666666667 on epoch=349
05/16/2022 15:01:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.08 on epoch=352
05/16/2022 15:01:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.04 on epoch=354
05/16/2022 15:01:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/16/2022 15:01:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.05 on epoch=359
05/16/2022 15:01:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.05 on epoch=362
05/16/2022 15:01:20 - INFO - __main__ - Global step 1450 Train loss 1.07 Classification-F1 0.15838509316770188 on epoch=362
05/16/2022 15:01:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/16/2022 15:01:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.07 on epoch=367
05/16/2022 15:01:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.08 on epoch=369
05/16/2022 15:01:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.94 on epoch=372
05/16/2022 15:01:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.01 on epoch=374
05/16/2022 15:01:27 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.1497584541062802 on epoch=374
05/16/2022 15:01:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.15 on epoch=377
05/16/2022 15:01:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=379
05/16/2022 15:01:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.19 on epoch=382
05/16/2022 15:01:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=384
05/16/2022 15:01:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
05/16/2022 15:01:35 - INFO - __main__ - Global step 1550 Train loss 1.09 Classification-F1 0.10389610389610389 on epoch=387
05/16/2022 15:01:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.02 on epoch=389
05/16/2022 15:01:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.11 on epoch=392
05/16/2022 15:01:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.10 on epoch=394
05/16/2022 15:01:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.02 on epoch=397
05/16/2022 15:01:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.95 on epoch=399
05/16/2022 15:01:43 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.11157407407407408 on epoch=399
05/16/2022 15:01:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
05/16/2022 15:01:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/16/2022 15:01:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.07 on epoch=407
05/16/2022 15:01:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/16/2022 15:01:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/16/2022 15:01:50 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.20924825940892933 on epoch=412
05/16/2022 15:01:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.96 on epoch=414
05/16/2022 15:01:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.93 on epoch=417
05/16/2022 15:01:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.97 on epoch=419
05/16/2022 15:01:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.02 on epoch=422
05/16/2022 15:01:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.02 on epoch=424
05/16/2022 15:01:58 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.2109375 on epoch=424
05/16/2022 15:01:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.07 on epoch=427
05/16/2022 15:02:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.97 on epoch=429
05/16/2022 15:02:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.04 on epoch=432
05/16/2022 15:02:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
05/16/2022 15:02:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.97 on epoch=437
05/16/2022 15:02:05 - INFO - __main__ - Global step 1750 Train loss 1.03 Classification-F1 0.1 on epoch=437
05/16/2022 15:02:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
05/16/2022 15:02:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.03 on epoch=442
05/16/2022 15:02:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/16/2022 15:02:11 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.00 on epoch=447
05/16/2022 15:02:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
05/16/2022 15:02:13 - INFO - __main__ - Global step 1800 Train loss 1.03 Classification-F1 0.1 on epoch=449
05/16/2022 15:02:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.95 on epoch=452
05/16/2022 15:02:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.91 on epoch=454
05/16/2022 15:02:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.12 on epoch=457
05/16/2022 15:02:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.02 on epoch=459
05/16/2022 15:02:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.00 on epoch=462
05/16/2022 15:02:21 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.20614919354838712 on epoch=462
05/16/2022 15:02:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/16/2022 15:02:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.00 on epoch=467
05/16/2022 15:02:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.90 on epoch=469
05/16/2022 15:02:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.94 on epoch=472
05/16/2022 15:02:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.13 on epoch=474
05/16/2022 15:02:29 - INFO - __main__ - Global step 1900 Train loss 0.99 Classification-F1 0.13026315789473686 on epoch=474
05/16/2022 15:02:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
05/16/2022 15:02:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.07 on epoch=479
05/16/2022 15:02:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.99 on epoch=482
05/16/2022 15:02:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.98 on epoch=484
05/16/2022 15:02:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.04 on epoch=487
05/16/2022 15:02:36 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.13194444444444445 on epoch=487
05/16/2022 15:02:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.97 on epoch=489
05/16/2022 15:02:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=492
05/16/2022 15:02:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.05 on epoch=494
05/16/2022 15:02:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=497
05/16/2022 15:02:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.98 on epoch=499
05/16/2022 15:02:44 - INFO - __main__ - Global step 2000 Train loss 1.01 Classification-F1 0.13034188034188032 on epoch=499
05/16/2022 15:02:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/16/2022 15:02:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.06 on epoch=504
05/16/2022 15:02:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
05/16/2022 15:02:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.01 on epoch=509
05/16/2022 15:02:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.99 on epoch=512
05/16/2022 15:02:51 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.18948412698412698 on epoch=512
05/16/2022 15:02:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.02 on epoch=514
05/16/2022 15:02:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/16/2022 15:02:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.98 on epoch=519
05/16/2022 15:02:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.05 on epoch=522
05/16/2022 15:02:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
05/16/2022 15:02:59 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.16666666666666669 on epoch=524
05/16/2022 15:03:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.06 on epoch=527
05/16/2022 15:03:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.05 on epoch=529
05/16/2022 15:03:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/16/2022 15:03:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.92 on epoch=534
05/16/2022 15:03:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.97 on epoch=537
05/16/2022 15:03:06 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=537
05/16/2022 15:03:08 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/16/2022 15:03:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
05/16/2022 15:03:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.96 on epoch=544
05/16/2022 15:03:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/16/2022 15:03:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=549
05/16/2022 15:03:14 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.13430127041742287 on epoch=549
05/16/2022 15:03:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.91 on epoch=552
05/16/2022 15:03:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.98 on epoch=554
05/16/2022 15:03:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.98 on epoch=557
05/16/2022 15:03:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.05 on epoch=559
05/16/2022 15:03:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.02 on epoch=562
05/16/2022 15:03:21 - INFO - __main__ - Global step 2250 Train loss 0.99 Classification-F1 0.2897623608830505 on epoch=562
05/16/2022 15:03:21 - INFO - __main__ - Saving model with best Classification-F1: 0.23911070780399274 -> 0.2897623608830505 on epoch=562, global_step=2250
05/16/2022 15:03:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.09 on epoch=564
05/16/2022 15:03:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.92 on epoch=567
05/16/2022 15:03:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.93 on epoch=569
05/16/2022 15:03:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.97 on epoch=572
05/16/2022 15:03:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
05/16/2022 15:03:28 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.15718418514946964 on epoch=574
05/16/2022 15:03:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
05/16/2022 15:03:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
05/16/2022 15:03:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/16/2022 15:03:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.91 on epoch=584
05/16/2022 15:03:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.03 on epoch=587
05/16/2022 15:03:36 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.12091038406827881 on epoch=587
05/16/2022 15:03:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.92 on epoch=589
05/16/2022 15:03:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/16/2022 15:03:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.95 on epoch=594
05/16/2022 15:03:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.99 on epoch=597
05/16/2022 15:03:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.98 on epoch=599
05/16/2022 15:03:43 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.17075892857142858 on epoch=599
05/16/2022 15:03:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/16/2022 15:03:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
05/16/2022 15:03:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.94 on epoch=607
05/16/2022 15:03:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.98 on epoch=609
05/16/2022 15:03:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.92 on epoch=612
05/16/2022 15:03:51 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.19285387081997252 on epoch=612
05/16/2022 15:03:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.97 on epoch=614
05/16/2022 15:03:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.89 on epoch=617
05/16/2022 15:03:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.03 on epoch=619
05/16/2022 15:03:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.93 on epoch=622
05/16/2022 15:03:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/16/2022 15:03:58 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.09589041095890412 on epoch=624
05/16/2022 15:04:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.00 on epoch=627
05/16/2022 15:04:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=629
05/16/2022 15:04:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.88 on epoch=632
05/16/2022 15:04:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/16/2022 15:04:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
05/16/2022 15:04:06 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.16666666666666666 on epoch=637
05/16/2022 15:04:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.04 on epoch=639
05/16/2022 15:04:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.89 on epoch=642
05/16/2022 15:04:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.01 on epoch=644
05/16/2022 15:04:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.97 on epoch=647
05/16/2022 15:04:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.90 on epoch=649
05/16/2022 15:04:13 - INFO - __main__ - Global step 2600 Train loss 0.96 Classification-F1 0.23394278135657448 on epoch=649
05/16/2022 15:04:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.91 on epoch=652
05/16/2022 15:04:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
05/16/2022 15:04:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.90 on epoch=657
05/16/2022 15:04:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.99 on epoch=659
05/16/2022 15:04:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/16/2022 15:04:20 - INFO - __main__ - Global step 2650 Train loss 0.93 Classification-F1 0.09333333333333334 on epoch=662
05/16/2022 15:04:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.02 on epoch=664
05/16/2022 15:04:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
05/16/2022 15:04:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.90 on epoch=669
05/16/2022 15:04:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=672
05/16/2022 15:04:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.00 on epoch=674
05/16/2022 15:04:28 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.20380692599620492 on epoch=674
05/16/2022 15:04:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/16/2022 15:04:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.91 on epoch=679
05/16/2022 15:04:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.88 on epoch=682
05/16/2022 15:04:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/16/2022 15:04:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.89 on epoch=687
05/16/2022 15:04:35 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.1015625 on epoch=687
05/16/2022 15:04:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.11 on epoch=689
05/16/2022 15:04:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.96 on epoch=692
05/16/2022 15:04:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.03 on epoch=694
05/16/2022 15:04:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.90 on epoch=697
05/16/2022 15:04:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.00 on epoch=699
05/16/2022 15:04:43 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.12400635930047696 on epoch=699
05/16/2022 15:04:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.95 on epoch=702
05/16/2022 15:04:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.05 on epoch=704
05/16/2022 15:04:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.94 on epoch=707
05/16/2022 15:04:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/16/2022 15:04:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.92 on epoch=712
05/16/2022 15:04:50 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=712
05/16/2022 15:04:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.93 on epoch=714
05/16/2022 15:04:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.00 on epoch=717
05/16/2022 15:04:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.00 on epoch=719
05/16/2022 15:04:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/16/2022 15:04:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/16/2022 15:04:58 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.15521739130434786 on epoch=724
05/16/2022 15:05:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.92 on epoch=727
05/16/2022 15:05:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.99 on epoch=729
05/16/2022 15:05:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
05/16/2022 15:05:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/16/2022 15:05:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
05/16/2022 15:05:06 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.12228260869565218 on epoch=737
05/16/2022 15:05:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.08 on epoch=739
05/16/2022 15:05:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.96 on epoch=742
05/16/2022 15:05:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/16/2022 15:05:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.90 on epoch=747
05/16/2022 15:05:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.91 on epoch=749
05/16/2022 15:05:13 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1 on epoch=749
05/16/2022 15:05:13 - INFO - __main__ - save last model!
05/16/2022 15:05:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 15:05:13 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 15:05:13 - INFO - __main__ - Printing 3 examples
05/16/2022 15:05:13 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 15:05:13 - INFO - __main__ - ['others']
05/16/2022 15:05:13 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 15:05:13 - INFO - __main__ - ['others']
05/16/2022 15:05:13 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 15:05:13 - INFO - __main__ - ['others']
05/16/2022 15:05:13 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:05:14 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:05:14 - INFO - __main__ - Printing 3 examples
05/16/2022 15:05:14 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 15:05:14 - INFO - __main__ - ['others']
05/16/2022 15:05:14 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 15:05:14 - INFO - __main__ - ['others']
05/16/2022 15:05:14 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 15:05:14 - INFO - __main__ - ['others']
05/16/2022 15:05:14 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:05:14 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:05:14 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:05:14 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:05:14 - INFO - __main__ - Printing 3 examples
05/16/2022 15:05:14 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 15:05:14 - INFO - __main__ - ['others']
05/16/2022 15:05:14 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 15:05:14 - INFO - __main__ - ['others']
05/16/2022 15:05:14 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 15:05:14 - INFO - __main__ - ['others']
05/16/2022 15:05:14 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:05:14 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:05:14 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:05:16 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:05:20 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:05:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:05:21 - INFO - __main__ - Starting training!
05/16/2022 15:05:21 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 15:06:05 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.4_8_predictions.txt
05/16/2022 15:06:05 - INFO - __main__ - Classification-F1 on test data: 0.0315
05/16/2022 15:06:05 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.2897623608830505, test_performance=0.03154834166311928
05/16/2022 15:06:05 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
05/16/2022 15:06:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:06:06 - INFO - __main__ - Printing 3 examples
05/16/2022 15:06:06 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 15:06:06 - INFO - __main__ - ['others']
05/16/2022 15:06:06 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 15:06:06 - INFO - __main__ - ['others']
05/16/2022 15:06:06 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 15:06:06 - INFO - __main__ - ['others']
05/16/2022 15:06:06 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:06:06 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:06:06 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:06:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:06:06 - INFO - __main__ - Printing 3 examples
05/16/2022 15:06:06 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 15:06:06 - INFO - __main__ - ['others']
05/16/2022 15:06:06 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 15:06:06 - INFO - __main__ - ['others']
05/16/2022 15:06:06 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 15:06:06 - INFO - __main__ - ['others']
05/16/2022 15:06:06 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:06:06 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:06:06 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:06:12 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:06:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:06:12 - INFO - __main__ - Starting training!
05/16/2022 15:06:14 - INFO - __main__ - Step 10 Global step 10 Train loss 6.67 on epoch=2
05/16/2022 15:06:16 - INFO - __main__ - Step 20 Global step 20 Train loss 6.58 on epoch=4
05/16/2022 15:06:17 - INFO - __main__ - Step 30 Global step 30 Train loss 6.29 on epoch=7
05/16/2022 15:06:19 - INFO - __main__ - Step 40 Global step 40 Train loss 6.15 on epoch=9
05/16/2022 15:06:20 - INFO - __main__ - Step 50 Global step 50 Train loss 5.94 on epoch=12
05/16/2022 15:06:29 - INFO - __main__ - Global step 50 Train loss 6.32 Classification-F1 0.0 on epoch=12
05/16/2022 15:06:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 15:06:30 - INFO - __main__ - Step 60 Global step 60 Train loss 5.72 on epoch=14
05/16/2022 15:06:32 - INFO - __main__ - Step 70 Global step 70 Train loss 5.55 on epoch=17
05/16/2022 15:06:33 - INFO - __main__ - Step 80 Global step 80 Train loss 5.44 on epoch=19
05/16/2022 15:06:35 - INFO - __main__ - Step 90 Global step 90 Train loss 5.28 on epoch=22
05/16/2022 15:06:36 - INFO - __main__ - Step 100 Global step 100 Train loss 5.08 on epoch=24
05/16/2022 15:06:38 - INFO - __main__ - Global step 100 Train loss 5.41 Classification-F1 0.0 on epoch=24
05/16/2022 15:06:39 - INFO - __main__ - Step 110 Global step 110 Train loss 4.88 on epoch=27
05/16/2022 15:06:41 - INFO - __main__ - Step 120 Global step 120 Train loss 4.79 on epoch=29
05/16/2022 15:06:42 - INFO - __main__ - Step 130 Global step 130 Train loss 4.51 on epoch=32
05/16/2022 15:06:43 - INFO - __main__ - Step 140 Global step 140 Train loss 4.47 on epoch=34
05/16/2022 15:06:44 - INFO - __main__ - Step 150 Global step 150 Train loss 4.41 on epoch=37
05/16/2022 15:06:45 - INFO - __main__ - Global step 150 Train loss 4.61 Classification-F1 0.07915893630179342 on epoch=37
05/16/2022 15:06:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07915893630179342 on epoch=37, global_step=150
05/16/2022 15:06:47 - INFO - __main__ - Step 160 Global step 160 Train loss 4.15 on epoch=39
05/16/2022 15:06:48 - INFO - __main__ - Step 170 Global step 170 Train loss 4.13 on epoch=42
05/16/2022 15:06:49 - INFO - __main__ - Step 180 Global step 180 Train loss 3.93 on epoch=44
05/16/2022 15:06:51 - INFO - __main__ - Step 190 Global step 190 Train loss 3.80 on epoch=47
05/16/2022 15:06:52 - INFO - __main__ - Step 200 Global step 200 Train loss 3.82 on epoch=49
05/16/2022 15:06:53 - INFO - __main__ - Global step 200 Train loss 3.96 Classification-F1 0.09477124183006536 on epoch=49
05/16/2022 15:06:53 - INFO - __main__ - Saving model with best Classification-F1: 0.07915893630179342 -> 0.09477124183006536 on epoch=49, global_step=200
05/16/2022 15:06:54 - INFO - __main__ - Step 210 Global step 210 Train loss 3.67 on epoch=52
05/16/2022 15:06:55 - INFO - __main__ - Step 220 Global step 220 Train loss 3.40 on epoch=54
05/16/2022 15:06:57 - INFO - __main__ - Step 230 Global step 230 Train loss 3.49 on epoch=57
05/16/2022 15:06:58 - INFO - __main__ - Step 240 Global step 240 Train loss 3.20 on epoch=59
05/16/2022 15:06:59 - INFO - __main__ - Step 250 Global step 250 Train loss 3.30 on epoch=62
05/16/2022 15:07:00 - INFO - __main__ - Global step 250 Train loss 3.41 Classification-F1 0.16084656084656085 on epoch=62
05/16/2022 15:07:00 - INFO - __main__ - Saving model with best Classification-F1: 0.09477124183006536 -> 0.16084656084656085 on epoch=62, global_step=250
05/16/2022 15:07:01 - INFO - __main__ - Step 260 Global step 260 Train loss 3.37 on epoch=64
05/16/2022 15:07:03 - INFO - __main__ - Step 270 Global step 270 Train loss 3.17 on epoch=67
05/16/2022 15:07:04 - INFO - __main__ - Step 280 Global step 280 Train loss 3.02 on epoch=69
05/16/2022 15:07:06 - INFO - __main__ - Step 290 Global step 290 Train loss 3.09 on epoch=72
05/16/2022 15:07:07 - INFO - __main__ - Step 300 Global step 300 Train loss 2.82 on epoch=74
05/16/2022 15:07:07 - INFO - __main__ - Global step 300 Train loss 3.09 Classification-F1 0.13198653198653199 on epoch=74
05/16/2022 15:07:09 - INFO - __main__ - Step 310 Global step 310 Train loss 3.05 on epoch=77
05/16/2022 15:07:10 - INFO - __main__ - Step 320 Global step 320 Train loss 2.66 on epoch=79
05/16/2022 15:07:11 - INFO - __main__ - Step 330 Global step 330 Train loss 2.89 on epoch=82
05/16/2022 15:07:13 - INFO - __main__ - Step 340 Global step 340 Train loss 2.62 on epoch=84
05/16/2022 15:07:14 - INFO - __main__ - Step 350 Global step 350 Train loss 2.79 on epoch=87
05/16/2022 15:07:15 - INFO - __main__ - Global step 350 Train loss 2.80 Classification-F1 0.13034188034188032 on epoch=87
05/16/2022 15:07:16 - INFO - __main__ - Step 360 Global step 360 Train loss 2.62 on epoch=89
05/16/2022 15:07:17 - INFO - __main__ - Step 370 Global step 370 Train loss 2.69 on epoch=92
05/16/2022 15:07:19 - INFO - __main__ - Step 380 Global step 380 Train loss 2.48 on epoch=94
05/16/2022 15:07:20 - INFO - __main__ - Step 390 Global step 390 Train loss 2.57 on epoch=97
05/16/2022 15:07:21 - INFO - __main__ - Step 400 Global step 400 Train loss 2.47 on epoch=99
05/16/2022 15:07:22 - INFO - __main__ - Global step 400 Train loss 2.57 Classification-F1 0.20804195804195807 on epoch=99
05/16/2022 15:07:22 - INFO - __main__ - Saving model with best Classification-F1: 0.16084656084656085 -> 0.20804195804195807 on epoch=99, global_step=400
05/16/2022 15:07:23 - INFO - __main__ - Step 410 Global step 410 Train loss 2.71 on epoch=102
05/16/2022 15:07:25 - INFO - __main__ - Step 420 Global step 420 Train loss 2.31 on epoch=104
05/16/2022 15:07:26 - INFO - __main__ - Step 430 Global step 430 Train loss 2.44 on epoch=107
05/16/2022 15:07:27 - INFO - __main__ - Step 440 Global step 440 Train loss 2.37 on epoch=109
05/16/2022 15:07:29 - INFO - __main__ - Step 450 Global step 450 Train loss 2.66 on epoch=112
05/16/2022 15:07:29 - INFO - __main__ - Global step 450 Train loss 2.50 Classification-F1 0.14242424242424243 on epoch=112
05/16/2022 15:07:30 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=114
05/16/2022 15:07:32 - INFO - __main__ - Step 470 Global step 470 Train loss 2.43 on epoch=117
05/16/2022 15:07:33 - INFO - __main__ - Step 480 Global step 480 Train loss 2.24 on epoch=119
05/16/2022 15:07:35 - INFO - __main__ - Step 490 Global step 490 Train loss 2.50 on epoch=122
05/16/2022 15:07:36 - INFO - __main__ - Step 500 Global step 500 Train loss 2.10 on epoch=124
05/16/2022 15:07:37 - INFO - __main__ - Global step 500 Train loss 2.32 Classification-F1 0.1565276828434723 on epoch=124
05/16/2022 15:07:38 - INFO - __main__ - Step 510 Global step 510 Train loss 2.22 on epoch=127
05/16/2022 15:07:40 - INFO - __main__ - Step 520 Global step 520 Train loss 2.08 on epoch=129
05/16/2022 15:07:42 - INFO - __main__ - Step 530 Global step 530 Train loss 2.27 on epoch=132
05/16/2022 15:07:43 - INFO - __main__ - Step 540 Global step 540 Train loss 2.01 on epoch=134
05/16/2022 15:07:45 - INFO - __main__ - Step 550 Global step 550 Train loss 2.14 on epoch=137
05/16/2022 15:07:45 - INFO - __main__ - Global step 550 Train loss 2.14 Classification-F1 0.1105263157894737 on epoch=137
05/16/2022 15:07:46 - INFO - __main__ - Step 560 Global step 560 Train loss 2.22 on epoch=139
05/16/2022 15:07:48 - INFO - __main__ - Step 570 Global step 570 Train loss 2.04 on epoch=142
05/16/2022 15:07:49 - INFO - __main__ - Step 580 Global step 580 Train loss 1.98 on epoch=144
05/16/2022 15:07:50 - INFO - __main__ - Step 590 Global step 590 Train loss 2.13 on epoch=147
05/16/2022 15:07:52 - INFO - __main__ - Step 600 Global step 600 Train loss 1.92 on epoch=149
05/16/2022 15:07:52 - INFO - __main__ - Global step 600 Train loss 2.06 Classification-F1 0.16666666666666666 on epoch=149
05/16/2022 15:07:54 - INFO - __main__ - Step 610 Global step 610 Train loss 1.98 on epoch=152
05/16/2022 15:07:55 - INFO - __main__ - Step 620 Global step 620 Train loss 1.95 on epoch=154
05/16/2022 15:07:56 - INFO - __main__ - Step 630 Global step 630 Train loss 2.00 on epoch=157
05/16/2022 15:07:58 - INFO - __main__ - Step 640 Global step 640 Train loss 1.95 on epoch=159
05/16/2022 15:07:59 - INFO - __main__ - Step 650 Global step 650 Train loss 1.96 on epoch=162
05/16/2022 15:08:00 - INFO - __main__ - Global step 650 Train loss 1.97 Classification-F1 0.18614718614718614 on epoch=162
05/16/2022 15:08:01 - INFO - __main__ - Step 660 Global step 660 Train loss 1.67 on epoch=164
05/16/2022 15:08:02 - INFO - __main__ - Step 670 Global step 670 Train loss 1.86 on epoch=167
05/16/2022 15:08:04 - INFO - __main__ - Step 680 Global step 680 Train loss 1.83 on epoch=169
05/16/2022 15:08:05 - INFO - __main__ - Step 690 Global step 690 Train loss 1.74 on epoch=172
05/16/2022 15:08:06 - INFO - __main__ - Step 700 Global step 700 Train loss 1.84 on epoch=174
05/16/2022 15:08:07 - INFO - __main__ - Global step 700 Train loss 1.79 Classification-F1 0.11710526315789474 on epoch=174
05/16/2022 15:08:08 - INFO - __main__ - Step 710 Global step 710 Train loss 1.93 on epoch=177
05/16/2022 15:08:10 - INFO - __main__ - Step 720 Global step 720 Train loss 1.64 on epoch=179
05/16/2022 15:08:11 - INFO - __main__ - Step 730 Global step 730 Train loss 1.72 on epoch=182
05/16/2022 15:08:12 - INFO - __main__ - Step 740 Global step 740 Train loss 1.83 on epoch=184
05/16/2022 15:08:14 - INFO - __main__ - Step 750 Global step 750 Train loss 1.69 on epoch=187
05/16/2022 15:08:14 - INFO - __main__ - Global step 750 Train loss 1.76 Classification-F1 0.09493670886075949 on epoch=187
05/16/2022 15:08:16 - INFO - __main__ - Step 760 Global step 760 Train loss 1.82 on epoch=189
05/16/2022 15:08:17 - INFO - __main__ - Step 770 Global step 770 Train loss 1.57 on epoch=192
05/16/2022 15:08:18 - INFO - __main__ - Step 780 Global step 780 Train loss 1.67 on epoch=194
05/16/2022 15:08:20 - INFO - __main__ - Step 790 Global step 790 Train loss 1.74 on epoch=197
05/16/2022 15:08:21 - INFO - __main__ - Step 800 Global step 800 Train loss 1.51 on epoch=199
05/16/2022 15:08:22 - INFO - __main__ - Global step 800 Train loss 1.66 Classification-F1 0.13936867182846935 on epoch=199
05/16/2022 15:08:23 - INFO - __main__ - Step 810 Global step 810 Train loss 1.65 on epoch=202
05/16/2022 15:08:24 - INFO - __main__ - Step 820 Global step 820 Train loss 1.61 on epoch=204
05/16/2022 15:08:26 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/16/2022 15:08:27 - INFO - __main__ - Step 840 Global step 840 Train loss 1.48 on epoch=209
05/16/2022 15:08:28 - INFO - __main__ - Step 850 Global step 850 Train loss 1.59 on epoch=212
05/16/2022 15:08:29 - INFO - __main__ - Global step 850 Train loss 1.60 Classification-F1 0.13624338624338622 on epoch=212
05/16/2022 15:08:30 - INFO - __main__ - Step 860 Global step 860 Train loss 1.57 on epoch=214
05/16/2022 15:08:32 - INFO - __main__ - Step 870 Global step 870 Train loss 1.42 on epoch=217
05/16/2022 15:08:33 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
05/16/2022 15:08:35 - INFO - __main__ - Step 890 Global step 890 Train loss 1.49 on epoch=222
05/16/2022 15:08:36 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
05/16/2022 15:08:37 - INFO - __main__ - Global step 900 Train loss 1.46 Classification-F1 0.19016393442622948 on epoch=224
05/16/2022 15:08:38 - INFO - __main__ - Step 910 Global step 910 Train loss 1.58 on epoch=227
05/16/2022 15:08:40 - INFO - __main__ - Step 920 Global step 920 Train loss 1.27 on epoch=229
05/16/2022 15:08:41 - INFO - __main__ - Step 930 Global step 930 Train loss 1.41 on epoch=232
05/16/2022 15:08:43 - INFO - __main__ - Step 940 Global step 940 Train loss 1.42 on epoch=234
05/16/2022 15:08:44 - INFO - __main__ - Step 950 Global step 950 Train loss 1.54 on epoch=237
05/16/2022 15:08:45 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.1576923076923077 on epoch=237
05/16/2022 15:08:46 - INFO - __main__ - Step 960 Global step 960 Train loss 1.30 on epoch=239
05/16/2022 15:08:48 - INFO - __main__ - Step 970 Global step 970 Train loss 1.56 on epoch=242
05/16/2022 15:08:49 - INFO - __main__ - Step 980 Global step 980 Train loss 1.32 on epoch=244
05/16/2022 15:08:51 - INFO - __main__ - Step 990 Global step 990 Train loss 1.37 on epoch=247
05/16/2022 15:08:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.36 on epoch=249
05/16/2022 15:08:53 - INFO - __main__ - Global step 1000 Train loss 1.38 Classification-F1 0.1302118933697881 on epoch=249
05/16/2022 15:08:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.43 on epoch=252
05/16/2022 15:08:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
05/16/2022 15:08:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.24 on epoch=257
05/16/2022 15:08:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.36 on epoch=259
05/16/2022 15:08:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.57 on epoch=262
05/16/2022 15:09:00 - INFO - __main__ - Global step 1050 Train loss 1.39 Classification-F1 0.08333333333333333 on epoch=262
05/16/2022 15:09:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.32 on epoch=264
05/16/2022 15:09:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.58 on epoch=267
05/16/2022 15:09:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.35 on epoch=269
05/16/2022 15:09:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.46 on epoch=272
05/16/2022 15:09:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
05/16/2022 15:09:07 - INFO - __main__ - Global step 1100 Train loss 1.38 Classification-F1 0.09333333333333334 on epoch=274
05/16/2022 15:09:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/16/2022 15:09:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.32 on epoch=279
05/16/2022 15:09:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.22 on epoch=282
05/16/2022 15:09:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.39 on epoch=284
05/16/2022 15:09:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.17 on epoch=287
05/16/2022 15:09:15 - INFO - __main__ - Global step 1150 Train loss 1.27 Classification-F1 0.1 on epoch=287
05/16/2022 15:09:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.21 on epoch=289
05/16/2022 15:09:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.28 on epoch=292
05/16/2022 15:09:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.20 on epoch=294
05/16/2022 15:09:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.37 on epoch=297
05/16/2022 15:09:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.27 on epoch=299
05/16/2022 15:09:22 - INFO - __main__ - Global step 1200 Train loss 1.26 Classification-F1 0.1 on epoch=299
05/16/2022 15:09:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.35 on epoch=302
05/16/2022 15:09:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.22 on epoch=304
05/16/2022 15:09:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=307
05/16/2022 15:09:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.30 on epoch=309
05/16/2022 15:09:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.24 on epoch=312
05/16/2022 15:09:29 - INFO - __main__ - Global step 1250 Train loss 1.28 Classification-F1 0.10256410256410256 on epoch=312
05/16/2022 15:09:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
05/16/2022 15:09:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.38 on epoch=317
05/16/2022 15:09:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.23 on epoch=319
05/16/2022 15:09:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.15 on epoch=322
05/16/2022 15:09:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.13 on epoch=324
05/16/2022 15:09:37 - INFO - __main__ - Global step 1300 Train loss 1.24 Classification-F1 0.1611111111111111 on epoch=324
05/16/2022 15:09:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.24 on epoch=327
05/16/2022 15:09:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.18 on epoch=329
05/16/2022 15:09:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.11 on epoch=332
05/16/2022 15:09:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.27 on epoch=334
05/16/2022 15:09:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.21 on epoch=337
05/16/2022 15:09:44 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.1658268437929455 on epoch=337
05/16/2022 15:09:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/16/2022 15:09:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.20 on epoch=342
05/16/2022 15:09:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.29 on epoch=344
05/16/2022 15:09:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.16 on epoch=347
05/16/2022 15:09:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
05/16/2022 15:09:51 - INFO - __main__ - Global step 1400 Train loss 1.21 Classification-F1 0.10126582278481013 on epoch=349
05/16/2022 15:09:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.24 on epoch=352
05/16/2022 15:09:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.28 on epoch=354
05/16/2022 15:09:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.15 on epoch=357
05/16/2022 15:09:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.21 on epoch=359
05/16/2022 15:09:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.21 on epoch=362
05/16/2022 15:09:58 - INFO - __main__ - Global step 1450 Train loss 1.22 Classification-F1 0.13034188034188032 on epoch=362
05/16/2022 15:09:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.21 on epoch=364
05/16/2022 15:10:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.26 on epoch=367
05/16/2022 15:10:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
05/16/2022 15:10:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/16/2022 15:10:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.18 on epoch=374
05/16/2022 15:10:05 - INFO - __main__ - Global step 1500 Train loss 1.19 Classification-F1 0.10126582278481013 on epoch=374
05/16/2022 15:10:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.16 on epoch=377
05/16/2022 15:10:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.18 on epoch=379
05/16/2022 15:10:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.14 on epoch=382
05/16/2022 15:10:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.14 on epoch=384
05/16/2022 15:10:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=387
05/16/2022 15:10:13 - INFO - __main__ - Global step 1550 Train loss 1.16 Classification-F1 0.0901639344262295 on epoch=387
05/16/2022 15:10:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.15 on epoch=389
05/16/2022 15:10:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.22 on epoch=392
05/16/2022 15:10:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.11 on epoch=394
05/16/2022 15:10:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
05/16/2022 15:10:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
05/16/2022 15:10:20 - INFO - __main__ - Global step 1600 Train loss 1.14 Classification-F1 0.13846153846153847 on epoch=399
05/16/2022 15:10:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.11 on epoch=402
05/16/2022 15:10:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.24 on epoch=404
05/16/2022 15:10:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.15 on epoch=407
05/16/2022 15:10:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.07 on epoch=409
05/16/2022 15:10:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.10 on epoch=412
05/16/2022 15:10:27 - INFO - __main__ - Global step 1650 Train loss 1.13 Classification-F1 0.20555555555555555 on epoch=412
05/16/2022 15:10:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.13 on epoch=414
05/16/2022 15:10:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.25 on epoch=417
05/16/2022 15:10:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.19 on epoch=419
05/16/2022 15:10:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.18 on epoch=422
05/16/2022 15:10:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
05/16/2022 15:10:34 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.20853462157809982 on epoch=424
05/16/2022 15:10:34 - INFO - __main__ - Saving model with best Classification-F1: 0.20804195804195807 -> 0.20853462157809982 on epoch=424, global_step=1700
05/16/2022 15:10:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.23 on epoch=427
05/16/2022 15:10:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=429
05/16/2022 15:10:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.17 on epoch=432
05/16/2022 15:10:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.07 on epoch=434
05/16/2022 15:10:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.13 on epoch=437
05/16/2022 15:10:41 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.18055555555555555 on epoch=437
05/16/2022 15:10:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
05/16/2022 15:10:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.05 on epoch=442
05/16/2022 15:10:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.99 on epoch=444
05/16/2022 15:10:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/16/2022 15:10:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.11 on epoch=449
05/16/2022 15:10:48 - INFO - __main__ - Global step 1800 Train loss 1.04 Classification-F1 0.13427800269905532 on epoch=449
05/16/2022 15:10:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.12 on epoch=452
05/16/2022 15:10:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.03 on epoch=454
05/16/2022 15:10:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.17 on epoch=457
05/16/2022 15:10:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.03 on epoch=459
05/16/2022 15:10:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.22 on epoch=462
05/16/2022 15:10:55 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.09493670886075949 on epoch=462
05/16/2022 15:10:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=464
05/16/2022 15:10:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.05 on epoch=467
05/16/2022 15:10:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.09 on epoch=469
05/16/2022 15:11:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.20 on epoch=472
05/16/2022 15:11:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/16/2022 15:11:03 - INFO - __main__ - Global step 1900 Train loss 1.11 Classification-F1 0.12575757575757576 on epoch=474
05/16/2022 15:11:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.09 on epoch=477
05/16/2022 15:11:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
05/16/2022 15:11:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
05/16/2022 15:11:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.18 on epoch=484
05/16/2022 15:11:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.17 on epoch=487
05/16/2022 15:11:10 - INFO - __main__ - Global step 1950 Train loss 1.11 Classification-F1 0.09999999999999999 on epoch=487
05/16/2022 15:11:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=489
05/16/2022 15:11:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.07 on epoch=492
05/16/2022 15:11:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.15 on epoch=494
05/16/2022 15:11:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.03 on epoch=497
05/16/2022 15:11:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.18 on epoch=499
05/16/2022 15:11:17 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.07638888888888888 on epoch=499
05/16/2022 15:11:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.21 on epoch=502
05/16/2022 15:11:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.01 on epoch=504
05/16/2022 15:11:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.96 on epoch=507
05/16/2022 15:11:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.20 on epoch=509
05/16/2022 15:11:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.11 on epoch=512
05/16/2022 15:11:24 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.07258064516129033 on epoch=512
05/16/2022 15:11:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/16/2022 15:11:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.12 on epoch=517
05/16/2022 15:11:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.18 on epoch=519
05/16/2022 15:11:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.16 on epoch=522
05/16/2022 15:11:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.01 on epoch=524
05/16/2022 15:11:31 - INFO - __main__ - Global step 2100 Train loss 1.10 Classification-F1 0.12417582417582418 on epoch=524
05/16/2022 15:11:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.12 on epoch=527
05/16/2022 15:11:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.10 on epoch=529
05/16/2022 15:11:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.09 on epoch=532
05/16/2022 15:11:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.97 on epoch=534
05/16/2022 15:11:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.08 on epoch=537
05/16/2022 15:11:38 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.09615384615384615 on epoch=537
05/16/2022 15:11:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/16/2022 15:11:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.09 on epoch=542
05/16/2022 15:11:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.96 on epoch=544
05/16/2022 15:11:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/16/2022 15:11:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.99 on epoch=549
05/16/2022 15:11:46 - INFO - __main__ - Global step 2200 Train loss 1.02 Classification-F1 0.09615384615384615 on epoch=549
05/16/2022 15:11:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.09 on epoch=552
05/16/2022 15:11:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.17 on epoch=554
05/16/2022 15:11:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/16/2022 15:11:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.03 on epoch=559
05/16/2022 15:11:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/16/2022 15:11:53 - INFO - __main__ - Global step 2250 Train loss 1.08 Classification-F1 0.11996779388083736 on epoch=562
05/16/2022 15:11:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.16 on epoch=564
05/16/2022 15:11:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.14 on epoch=567
05/16/2022 15:11:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/16/2022 15:11:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/16/2022 15:12:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.05 on epoch=574
05/16/2022 15:12:00 - INFO - __main__ - Global step 2300 Train loss 1.08 Classification-F1 0.13154929577464788 on epoch=574
05/16/2022 15:12:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.96 on epoch=577
05/16/2022 15:12:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=579
05/16/2022 15:12:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.11 on epoch=582
05/16/2022 15:12:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.01 on epoch=584
05/16/2022 15:12:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.12 on epoch=587
05/16/2022 15:12:07 - INFO - __main__ - Global step 2350 Train loss 1.06 Classification-F1 0.1 on epoch=587
05/16/2022 15:12:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
05/16/2022 15:12:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.98 on epoch=592
05/16/2022 15:12:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/16/2022 15:12:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.03 on epoch=597
05/16/2022 15:12:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.09 on epoch=599
05/16/2022 15:12:15 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.1 on epoch=599
05/16/2022 15:12:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.06 on epoch=602
05/16/2022 15:12:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/16/2022 15:12:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.15 on epoch=607
05/16/2022 15:12:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.09 on epoch=609
05/16/2022 15:12:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.04 on epoch=612
05/16/2022 15:12:22 - INFO - __main__ - Global step 2450 Train loss 1.08 Classification-F1 0.09868421052631579 on epoch=612
05/16/2022 15:12:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.12 on epoch=614
05/16/2022 15:12:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.11 on epoch=617
05/16/2022 15:12:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.13 on epoch=619
05/16/2022 15:12:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/16/2022 15:12:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.04 on epoch=624
05/16/2022 15:12:29 - INFO - __main__ - Global step 2500 Train loss 1.09 Classification-F1 0.15490196078431373 on epoch=624
05/16/2022 15:12:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/16/2022 15:12:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
05/16/2022 15:12:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.10 on epoch=632
05/16/2022 15:12:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
05/16/2022 15:12:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.92 on epoch=637
05/16/2022 15:12:36 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.1 on epoch=637
05/16/2022 15:12:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.92 on epoch=639
05/16/2022 15:12:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
05/16/2022 15:12:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.03 on epoch=644
05/16/2022 15:12:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
05/16/2022 15:12:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.18 on epoch=649
05/16/2022 15:12:43 - INFO - __main__ - Global step 2600 Train loss 1.04 Classification-F1 0.17368421052631577 on epoch=649
05/16/2022 15:12:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.10 on epoch=652
05/16/2022 15:12:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.08 on epoch=654
05/16/2022 15:12:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.06 on epoch=657
05/16/2022 15:12:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.98 on epoch=659
05/16/2022 15:12:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/16/2022 15:12:50 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.1717171717171717 on epoch=662
05/16/2022 15:12:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.07 on epoch=664
05/16/2022 15:12:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.03 on epoch=667
05/16/2022 15:12:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.01 on epoch=669
05/16/2022 15:12:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.11 on epoch=672
05/16/2022 15:12:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.04 on epoch=674
05/16/2022 15:12:57 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.1581196581196581 on epoch=674
05/16/2022 15:12:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.08 on epoch=677
05/16/2022 15:12:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.09 on epoch=679
05/16/2022 15:13:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/16/2022 15:13:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
05/16/2022 15:13:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/16/2022 15:13:04 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.11666666666666667 on epoch=687
05/16/2022 15:13:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.04 on epoch=689
05/16/2022 15:13:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/16/2022 15:13:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/16/2022 15:13:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.12 on epoch=697
05/16/2022 15:13:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=699
05/16/2022 15:13:11 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=699
05/16/2022 15:13:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.05 on epoch=702
05/16/2022 15:13:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/16/2022 15:13:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.14 on epoch=707
05/16/2022 15:13:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/16/2022 15:13:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
05/16/2022 15:13:18 - INFO - __main__ - Global step 2850 Train loss 1.01 Classification-F1 0.1 on epoch=712
05/16/2022 15:13:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.04 on epoch=714
05/16/2022 15:13:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/16/2022 15:13:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.05 on epoch=719
05/16/2022 15:13:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.07 on epoch=722
05/16/2022 15:13:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.14 on epoch=724
05/16/2022 15:13:25 - INFO - __main__ - Global step 2900 Train loss 1.06 Classification-F1 0.09589041095890412 on epoch=724
05/16/2022 15:13:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.95 on epoch=727
05/16/2022 15:13:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/16/2022 15:13:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.94 on epoch=732
05/16/2022 15:13:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.93 on epoch=734
05/16/2022 15:13:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.93 on epoch=737
05/16/2022 15:13:32 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.17687747035573123 on epoch=737
05/16/2022 15:13:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/16/2022 15:13:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/16/2022 15:13:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.16 on epoch=744
05/16/2022 15:13:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.94 on epoch=747
05/16/2022 15:13:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/16/2022 15:13:39 - INFO - __main__ - Global step 3000 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=749
05/16/2022 15:13:39 - INFO - __main__ - save last model!
05/16/2022 15:13:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 15:13:39 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 15:13:39 - INFO - __main__ - Printing 3 examples
05/16/2022 15:13:39 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 15:13:39 - INFO - __main__ - ['others']
05/16/2022 15:13:39 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 15:13:39 - INFO - __main__ - ['others']
05/16/2022 15:13:39 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 15:13:39 - INFO - __main__ - ['others']
05/16/2022 15:13:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:13:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:13:40 - INFO - __main__ - Printing 3 examples
05/16/2022 15:13:40 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 15:13:40 - INFO - __main__ - ['others']
05/16/2022 15:13:40 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 15:13:40 - INFO - __main__ - ['others']
05/16/2022 15:13:40 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 15:13:40 - INFO - __main__ - ['others']
05/16/2022 15:13:40 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:13:40 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:13:40 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:13:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:13:40 - INFO - __main__ - Printing 3 examples
05/16/2022 15:13:40 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 15:13:40 - INFO - __main__ - ['others']
05/16/2022 15:13:40 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 15:13:40 - INFO - __main__ - ['others']
05/16/2022 15:13:40 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 15:13:40 - INFO - __main__ - ['others']
05/16/2022 15:13:40 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:13:40 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:13:40 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:13:41 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:13:46 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:13:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:13:46 - INFO - __main__ - Starting training!
05/16/2022 15:13:47 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 15:14:30 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.3_8_predictions.txt
05/16/2022 15:14:30 - INFO - __main__ - Classification-F1 on test data: 0.0317
05/16/2022 15:14:30 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.20853462157809982, test_performance=0.03167854221146765
05/16/2022 15:14:30 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
05/16/2022 15:14:31 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:14:31 - INFO - __main__ - Printing 3 examples
05/16/2022 15:14:31 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/16/2022 15:14:31 - INFO - __main__ - ['others']
05/16/2022 15:14:31 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/16/2022 15:14:31 - INFO - __main__ - ['others']
05/16/2022 15:14:31 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/16/2022 15:14:31 - INFO - __main__ - ['others']
05/16/2022 15:14:31 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:14:31 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:14:31 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:14:31 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:14:31 - INFO - __main__ - Printing 3 examples
05/16/2022 15:14:31 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/16/2022 15:14:31 - INFO - __main__ - ['others']
05/16/2022 15:14:31 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/16/2022 15:14:31 - INFO - __main__ - ['others']
05/16/2022 15:14:31 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/16/2022 15:14:31 - INFO - __main__ - ['others']
05/16/2022 15:14:31 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:14:31 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:14:31 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:14:37 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:14:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:14:37 - INFO - __main__ - Starting training!
05/16/2022 15:14:39 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=2
05/16/2022 15:14:40 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/16/2022 15:14:41 - INFO - __main__ - Step 30 Global step 30 Train loss 6.43 on epoch=7
05/16/2022 15:14:43 - INFO - __main__ - Step 40 Global step 40 Train loss 6.24 on epoch=9
05/16/2022 15:14:44 - INFO - __main__ - Step 50 Global step 50 Train loss 6.25 on epoch=12
05/16/2022 15:14:48 - INFO - __main__ - Global step 50 Train loss 6.45 Classification-F1 0.0 on epoch=12
05/16/2022 15:14:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 15:14:50 - INFO - __main__ - Step 60 Global step 60 Train loss 6.00 on epoch=14
05/16/2022 15:14:51 - INFO - __main__ - Step 70 Global step 70 Train loss 5.97 on epoch=17
05/16/2022 15:14:52 - INFO - __main__ - Step 80 Global step 80 Train loss 5.78 on epoch=19
05/16/2022 15:14:54 - INFO - __main__ - Step 90 Global step 90 Train loss 5.75 on epoch=22
05/16/2022 15:14:55 - INFO - __main__ - Step 100 Global step 100 Train loss 5.58 on epoch=24
05/16/2022 15:14:57 - INFO - __main__ - Global step 100 Train loss 5.82 Classification-F1 0.0 on epoch=24
05/16/2022 15:14:58 - INFO - __main__ - Step 110 Global step 110 Train loss 5.67 on epoch=27
05/16/2022 15:15:00 - INFO - __main__ - Step 120 Global step 120 Train loss 5.40 on epoch=29
05/16/2022 15:15:01 - INFO - __main__ - Step 130 Global step 130 Train loss 5.37 on epoch=32
05/16/2022 15:15:02 - INFO - __main__ - Step 140 Global step 140 Train loss 5.33 on epoch=34
05/16/2022 15:15:04 - INFO - __main__ - Step 150 Global step 150 Train loss 5.14 on epoch=37
05/16/2022 15:15:05 - INFO - __main__ - Global step 150 Train loss 5.38 Classification-F1 0.0 on epoch=37
05/16/2022 15:15:07 - INFO - __main__ - Step 160 Global step 160 Train loss 4.96 on epoch=39
05/16/2022 15:15:08 - INFO - __main__ - Step 170 Global step 170 Train loss 4.96 on epoch=42
05/16/2022 15:15:09 - INFO - __main__ - Step 180 Global step 180 Train loss 4.91 on epoch=44
05/16/2022 15:15:10 - INFO - __main__ - Step 190 Global step 190 Train loss 4.84 on epoch=47
05/16/2022 15:15:12 - INFO - __main__ - Step 200 Global step 200 Train loss 4.63 on epoch=49
05/16/2022 15:15:14 - INFO - __main__ - Global step 200 Train loss 4.86 Classification-F1 0.009523809523809525 on epoch=49
05/16/2022 15:15:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009523809523809525 on epoch=49, global_step=200
05/16/2022 15:15:15 - INFO - __main__ - Step 210 Global step 210 Train loss 4.58 on epoch=52
05/16/2022 15:15:16 - INFO - __main__ - Step 220 Global step 220 Train loss 4.59 on epoch=54
05/16/2022 15:15:17 - INFO - __main__ - Step 230 Global step 230 Train loss 4.45 on epoch=57
05/16/2022 15:15:19 - INFO - __main__ - Step 240 Global step 240 Train loss 4.25 on epoch=59
05/16/2022 15:15:20 - INFO - __main__ - Step 250 Global step 250 Train loss 4.13 on epoch=62
05/16/2022 15:15:21 - INFO - __main__ - Global step 250 Train loss 4.40 Classification-F1 0.15789473684210525 on epoch=62
05/16/2022 15:15:21 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809525 -> 0.15789473684210525 on epoch=62, global_step=250
05/16/2022 15:15:22 - INFO - __main__ - Step 260 Global step 260 Train loss 4.14 on epoch=64
05/16/2022 15:15:23 - INFO - __main__ - Step 270 Global step 270 Train loss 4.06 on epoch=67
05/16/2022 15:15:25 - INFO - __main__ - Step 280 Global step 280 Train loss 3.92 on epoch=69
05/16/2022 15:15:26 - INFO - __main__ - Step 290 Global step 290 Train loss 3.83 on epoch=72
05/16/2022 15:15:27 - INFO - __main__ - Step 300 Global step 300 Train loss 3.86 on epoch=74
05/16/2022 15:15:28 - INFO - __main__ - Global step 300 Train loss 3.96 Classification-F1 0.15339578454332553 on epoch=74
05/16/2022 15:15:29 - INFO - __main__ - Step 310 Global step 310 Train loss 3.81 on epoch=77
05/16/2022 15:15:31 - INFO - __main__ - Step 320 Global step 320 Train loss 3.89 on epoch=79
05/16/2022 15:15:32 - INFO - __main__ - Step 330 Global step 330 Train loss 3.81 on epoch=82
05/16/2022 15:15:33 - INFO - __main__ - Step 340 Global step 340 Train loss 3.67 on epoch=84
05/16/2022 15:15:35 - INFO - __main__ - Step 350 Global step 350 Train loss 3.62 on epoch=87
05/16/2022 15:15:35 - INFO - __main__ - Global step 350 Train loss 3.76 Classification-F1 0.11019607843137255 on epoch=87
05/16/2022 15:15:36 - INFO - __main__ - Step 360 Global step 360 Train loss 3.36 on epoch=89
05/16/2022 15:15:38 - INFO - __main__ - Step 370 Global step 370 Train loss 3.44 on epoch=92
05/16/2022 15:15:39 - INFO - __main__ - Step 380 Global step 380 Train loss 3.23 on epoch=94
05/16/2022 15:15:40 - INFO - __main__ - Step 390 Global step 390 Train loss 3.30 on epoch=97
05/16/2022 15:15:42 - INFO - __main__ - Step 400 Global step 400 Train loss 3.09 on epoch=99
05/16/2022 15:15:42 - INFO - __main__ - Global step 400 Train loss 3.28 Classification-F1 0.1570048309178744 on epoch=99
05/16/2022 15:15:43 - INFO - __main__ - Step 410 Global step 410 Train loss 3.26 on epoch=102
05/16/2022 15:15:45 - INFO - __main__ - Step 420 Global step 420 Train loss 3.12 on epoch=104
05/16/2022 15:15:46 - INFO - __main__ - Step 430 Global step 430 Train loss 3.06 on epoch=107
05/16/2022 15:15:47 - INFO - __main__ - Step 440 Global step 440 Train loss 3.00 on epoch=109
05/16/2022 15:15:49 - INFO - __main__ - Step 450 Global step 450 Train loss 3.04 on epoch=112
05/16/2022 15:15:49 - INFO - __main__ - Global step 450 Train loss 3.09 Classification-F1 0.10126582278481013 on epoch=112
05/16/2022 15:15:51 - INFO - __main__ - Step 460 Global step 460 Train loss 2.97 on epoch=114
05/16/2022 15:15:52 - INFO - __main__ - Step 470 Global step 470 Train loss 2.93 on epoch=117
05/16/2022 15:15:53 - INFO - __main__ - Step 480 Global step 480 Train loss 2.87 on epoch=119
05/16/2022 15:15:55 - INFO - __main__ - Step 490 Global step 490 Train loss 3.10 on epoch=122
05/16/2022 15:15:56 - INFO - __main__ - Step 500 Global step 500 Train loss 2.79 on epoch=124
05/16/2022 15:15:56 - INFO - __main__ - Global step 500 Train loss 2.93 Classification-F1 0.1 on epoch=124
05/16/2022 15:15:58 - INFO - __main__ - Step 510 Global step 510 Train loss 2.96 on epoch=127
05/16/2022 15:15:59 - INFO - __main__ - Step 520 Global step 520 Train loss 2.79 on epoch=129
05/16/2022 15:16:00 - INFO - __main__ - Step 530 Global step 530 Train loss 2.59 on epoch=132
05/16/2022 15:16:02 - INFO - __main__ - Step 540 Global step 540 Train loss 2.84 on epoch=134
05/16/2022 15:16:03 - INFO - __main__ - Step 550 Global step 550 Train loss 2.81 on epoch=137
05/16/2022 15:16:03 - INFO - __main__ - Global step 550 Train loss 2.80 Classification-F1 0.1 on epoch=137
05/16/2022 15:16:05 - INFO - __main__ - Step 560 Global step 560 Train loss 2.53 on epoch=139
05/16/2022 15:16:06 - INFO - __main__ - Step 570 Global step 570 Train loss 2.57 on epoch=142
05/16/2022 15:16:07 - INFO - __main__ - Step 580 Global step 580 Train loss 2.57 on epoch=144
05/16/2022 15:16:09 - INFO - __main__ - Step 590 Global step 590 Train loss 2.67 on epoch=147
05/16/2022 15:16:10 - INFO - __main__ - Step 600 Global step 600 Train loss 2.62 on epoch=149
05/16/2022 15:16:11 - INFO - __main__ - Global step 600 Train loss 2.59 Classification-F1 0.1 on epoch=149
05/16/2022 15:16:12 - INFO - __main__ - Step 610 Global step 610 Train loss 2.53 on epoch=152
05/16/2022 15:16:13 - INFO - __main__ - Step 620 Global step 620 Train loss 2.54 on epoch=154
05/16/2022 15:16:14 - INFO - __main__ - Step 630 Global step 630 Train loss 2.69 on epoch=157
05/16/2022 15:16:16 - INFO - __main__ - Step 640 Global step 640 Train loss 2.39 on epoch=159
05/16/2022 15:16:17 - INFO - __main__ - Step 650 Global step 650 Train loss 2.41 on epoch=162
05/16/2022 15:16:18 - INFO - __main__ - Global step 650 Train loss 2.51 Classification-F1 0.10256410256410256 on epoch=162
05/16/2022 15:16:19 - INFO - __main__ - Step 660 Global step 660 Train loss 2.33 on epoch=164
05/16/2022 15:16:20 - INFO - __main__ - Step 670 Global step 670 Train loss 2.54 on epoch=167
05/16/2022 15:16:22 - INFO - __main__ - Step 680 Global step 680 Train loss 2.31 on epoch=169
05/16/2022 15:16:23 - INFO - __main__ - Step 690 Global step 690 Train loss 2.33 on epoch=172
05/16/2022 15:16:24 - INFO - __main__ - Step 700 Global step 700 Train loss 2.17 on epoch=174
05/16/2022 15:16:25 - INFO - __main__ - Global step 700 Train loss 2.34 Classification-F1 0.10126582278481013 on epoch=174
05/16/2022 15:16:26 - INFO - __main__ - Step 710 Global step 710 Train loss 2.28 on epoch=177
05/16/2022 15:16:27 - INFO - __main__ - Step 720 Global step 720 Train loss 2.32 on epoch=179
05/16/2022 15:16:29 - INFO - __main__ - Step 730 Global step 730 Train loss 2.31 on epoch=182
05/16/2022 15:16:30 - INFO - __main__ - Step 740 Global step 740 Train loss 2.28 on epoch=184
05/16/2022 15:16:32 - INFO - __main__ - Step 750 Global step 750 Train loss 2.35 on epoch=187
05/16/2022 15:16:32 - INFO - __main__ - Global step 750 Train loss 2.31 Classification-F1 0.09615384615384615 on epoch=187
05/16/2022 15:16:33 - INFO - __main__ - Step 760 Global step 760 Train loss 2.13 on epoch=189
05/16/2022 15:16:35 - INFO - __main__ - Step 770 Global step 770 Train loss 2.25 on epoch=192
05/16/2022 15:16:36 - INFO - __main__ - Step 780 Global step 780 Train loss 2.11 on epoch=194
05/16/2022 15:16:37 - INFO - __main__ - Step 790 Global step 790 Train loss 2.28 on epoch=197
05/16/2022 15:16:39 - INFO - __main__ - Step 800 Global step 800 Train loss 2.12 on epoch=199
05/16/2022 15:16:39 - INFO - __main__ - Global step 800 Train loss 2.18 Classification-F1 0.1111111111111111 on epoch=199
05/16/2022 15:16:41 - INFO - __main__ - Step 810 Global step 810 Train loss 2.28 on epoch=202
05/16/2022 15:16:42 - INFO - __main__ - Step 820 Global step 820 Train loss 2.13 on epoch=204
05/16/2022 15:16:43 - INFO - __main__ - Step 830 Global step 830 Train loss 2.23 on epoch=207
05/16/2022 15:16:44 - INFO - __main__ - Step 840 Global step 840 Train loss 2.03 on epoch=209
05/16/2022 15:16:46 - INFO - __main__ - Step 850 Global step 850 Train loss 2.19 on epoch=212
05/16/2022 15:16:46 - INFO - __main__ - Global step 850 Train loss 2.17 Classification-F1 0.1476190476190476 on epoch=212
05/16/2022 15:16:48 - INFO - __main__ - Step 860 Global step 860 Train loss 1.95 on epoch=214
05/16/2022 15:16:49 - INFO - __main__ - Step 870 Global step 870 Train loss 2.08 on epoch=217
05/16/2022 15:16:50 - INFO - __main__ - Step 880 Global step 880 Train loss 1.91 on epoch=219
05/16/2022 15:16:51 - INFO - __main__ - Step 890 Global step 890 Train loss 2.01 on epoch=222
05/16/2022 15:16:53 - INFO - __main__ - Step 900 Global step 900 Train loss 1.82 on epoch=224
05/16/2022 15:16:53 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.17480643240023822 on epoch=224
05/16/2022 15:16:53 - INFO - __main__ - Saving model with best Classification-F1: 0.15789473684210525 -> 0.17480643240023822 on epoch=224, global_step=900
05/16/2022 15:16:55 - INFO - __main__ - Step 910 Global step 910 Train loss 1.94 on epoch=227
05/16/2022 15:16:56 - INFO - __main__ - Step 920 Global step 920 Train loss 1.81 on epoch=229
05/16/2022 15:16:57 - INFO - __main__ - Step 930 Global step 930 Train loss 1.96 on epoch=232
05/16/2022 15:16:58 - INFO - __main__ - Step 940 Global step 940 Train loss 1.78 on epoch=234
05/16/2022 15:17:00 - INFO - __main__ - Step 950 Global step 950 Train loss 1.96 on epoch=237
05/16/2022 15:17:00 - INFO - __main__ - Global step 950 Train loss 1.89 Classification-F1 0.18276972624798712 on epoch=237
05/16/2022 15:17:00 - INFO - __main__ - Saving model with best Classification-F1: 0.17480643240023822 -> 0.18276972624798712 on epoch=237, global_step=950
05/16/2022 15:17:02 - INFO - __main__ - Step 960 Global step 960 Train loss 1.94 on epoch=239
05/16/2022 15:17:03 - INFO - __main__ - Step 970 Global step 970 Train loss 1.95 on epoch=242
05/16/2022 15:17:04 - INFO - __main__ - Step 980 Global step 980 Train loss 1.80 on epoch=244
05/16/2022 15:17:06 - INFO - __main__ - Step 990 Global step 990 Train loss 1.86 on epoch=247
05/16/2022 15:17:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.63 on epoch=249
05/16/2022 15:17:08 - INFO - __main__ - Global step 1000 Train loss 1.84 Classification-F1 0.14563380281690141 on epoch=249
05/16/2022 15:17:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.81 on epoch=252
05/16/2022 15:17:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.61 on epoch=254
05/16/2022 15:17:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.72 on epoch=257
05/16/2022 15:17:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.78 on epoch=259
05/16/2022 15:17:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.81 on epoch=262
05/16/2022 15:17:15 - INFO - __main__ - Global step 1050 Train loss 1.75 Classification-F1 0.21743697478991597 on epoch=262
05/16/2022 15:17:15 - INFO - __main__ - Saving model with best Classification-F1: 0.18276972624798712 -> 0.21743697478991597 on epoch=262, global_step=1050
05/16/2022 15:17:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.67 on epoch=264
05/16/2022 15:17:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.63 on epoch=267
05/16/2022 15:17:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.80 on epoch=269
05/16/2022 15:17:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.65 on epoch=272
05/16/2022 15:17:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.51 on epoch=274
05/16/2022 15:17:22 - INFO - __main__ - Global step 1100 Train loss 1.65 Classification-F1 0.17552334943639292 on epoch=274
05/16/2022 15:17:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.62 on epoch=277
05/16/2022 15:17:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.60 on epoch=279
05/16/2022 15:17:26 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.66 on epoch=282
05/16/2022 15:17:27 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.60 on epoch=284
05/16/2022 15:17:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.60 on epoch=287
05/16/2022 15:17:29 - INFO - __main__ - Global step 1150 Train loss 1.61 Classification-F1 0.1302118933697881 on epoch=287
05/16/2022 15:17:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.62 on epoch=289
05/16/2022 15:17:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.69 on epoch=292
05/16/2022 15:17:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.60 on epoch=294
05/16/2022 15:17:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.61 on epoch=297
05/16/2022 15:17:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.63 on epoch=299
05/16/2022 15:17:36 - INFO - __main__ - Global step 1200 Train loss 1.63 Classification-F1 0.11746478873239438 on epoch=299
05/16/2022 15:17:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.51 on epoch=302
05/16/2022 15:17:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.57 on epoch=304
05/16/2022 15:17:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.53 on epoch=307
05/16/2022 15:17:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.51 on epoch=309
05/16/2022 15:17:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.63 on epoch=312
05/16/2022 15:17:43 - INFO - __main__ - Global step 1250 Train loss 1.55 Classification-F1 0.13154929577464788 on epoch=312
05/16/2022 15:17:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.59 on epoch=314
05/16/2022 15:17:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.53 on epoch=317
05/16/2022 15:17:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.43 on epoch=319
05/16/2022 15:17:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.47 on epoch=322
05/16/2022 15:17:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.34 on epoch=324
05/16/2022 15:17:50 - INFO - __main__ - Global step 1300 Train loss 1.47 Classification-F1 0.1640625 on epoch=324
05/16/2022 15:17:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.49 on epoch=327
05/16/2022 15:17:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.46 on epoch=329
05/16/2022 15:17:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.47 on epoch=332
05/16/2022 15:17:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.41 on epoch=334
05/16/2022 15:17:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.37 on epoch=337
05/16/2022 15:17:58 - INFO - __main__ - Global step 1350 Train loss 1.44 Classification-F1 0.1597222222222222 on epoch=337
05/16/2022 15:17:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.57 on epoch=339
05/16/2022 15:18:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.38 on epoch=342
05/16/2022 15:18:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.51 on epoch=344
05/16/2022 15:18:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.47 on epoch=347
05/16/2022 15:18:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.27 on epoch=349
05/16/2022 15:18:05 - INFO - __main__ - Global step 1400 Train loss 1.44 Classification-F1 0.16470588235294115 on epoch=349
05/16/2022 15:18:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.39 on epoch=352
05/16/2022 15:18:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.31 on epoch=354
05/16/2022 15:18:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.49 on epoch=357
05/16/2022 15:18:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.45 on epoch=359
05/16/2022 15:18:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.37 on epoch=362
05/16/2022 15:18:12 - INFO - __main__ - Global step 1450 Train loss 1.40 Classification-F1 0.1875 on epoch=362
05/16/2022 15:18:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.38 on epoch=364
05/16/2022 15:18:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.35 on epoch=367
05/16/2022 15:18:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.44 on epoch=369
05/16/2022 15:18:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.35 on epoch=372
05/16/2022 15:18:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.49 on epoch=374
05/16/2022 15:18:19 - INFO - __main__ - Global step 1500 Train loss 1.40 Classification-F1 0.1457326892109501 on epoch=374
05/16/2022 15:18:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.35 on epoch=377
05/16/2022 15:18:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.23 on epoch=379
05/16/2022 15:18:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.31 on epoch=382
05/16/2022 15:18:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=384
05/16/2022 15:18:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.32 on epoch=387
05/16/2022 15:18:26 - INFO - __main__ - Global step 1550 Train loss 1.29 Classification-F1 0.11485019539730784 on epoch=387
05/16/2022 15:18:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.23 on epoch=389
05/16/2022 15:18:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.26 on epoch=392
05/16/2022 15:18:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=394
05/16/2022 15:18:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.27 on epoch=397
05/16/2022 15:18:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.33 on epoch=399
05/16/2022 15:18:34 - INFO - __main__ - Global step 1600 Train loss 1.26 Classification-F1 0.13154929577464788 on epoch=399
05/16/2022 15:18:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.25 on epoch=402
05/16/2022 15:18:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.27 on epoch=404
05/16/2022 15:18:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.35 on epoch=407
05/16/2022 15:18:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.29 on epoch=409
05/16/2022 15:18:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.39 on epoch=412
05/16/2022 15:18:41 - INFO - __main__ - Global step 1650 Train loss 1.31 Classification-F1 0.13047619047619047 on epoch=412
05/16/2022 15:18:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.27 on epoch=414
05/16/2022 15:18:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.32 on epoch=417
05/16/2022 15:18:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.30 on epoch=419
05/16/2022 15:18:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.33 on epoch=422
05/16/2022 15:18:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.26 on epoch=424
05/16/2022 15:18:48 - INFO - __main__ - Global step 1700 Train loss 1.30 Classification-F1 0.15359477124183005 on epoch=424
05/16/2022 15:18:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.28 on epoch=427
05/16/2022 15:18:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.24 on epoch=429
05/16/2022 15:18:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
05/16/2022 15:18:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.27 on epoch=434
05/16/2022 15:18:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=437
05/16/2022 15:18:56 - INFO - __main__ - Global step 1750 Train loss 1.24 Classification-F1 0.09065934065934066 on epoch=437
05/16/2022 15:18:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.19 on epoch=439
05/16/2022 15:18:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.17 on epoch=442
05/16/2022 15:19:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.18 on epoch=444
05/16/2022 15:19:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.19 on epoch=447
05/16/2022 15:19:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.24 on epoch=449
05/16/2022 15:19:03 - INFO - __main__ - Global step 1800 Train loss 1.19 Classification-F1 0.09109311740890687 on epoch=449
05/16/2022 15:19:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.30 on epoch=452
05/16/2022 15:19:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.22 on epoch=454
05/16/2022 15:19:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.24 on epoch=457
05/16/2022 15:19:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.29 on epoch=459
05/16/2022 15:19:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.26 on epoch=462
05/16/2022 15:19:10 - INFO - __main__ - Global step 1850 Train loss 1.26 Classification-F1 0.15071003206596426 on epoch=462
05/16/2022 15:19:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=464
05/16/2022 15:19:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.17 on epoch=467
05/16/2022 15:19:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.27 on epoch=469
05/16/2022 15:19:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.45 on epoch=472
05/16/2022 15:19:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.24 on epoch=474
05/16/2022 15:19:17 - INFO - __main__ - Global step 1900 Train loss 1.25 Classification-F1 0.1774628879892038 on epoch=474
05/16/2022 15:19:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.25 on epoch=477
05/16/2022 15:19:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.20 on epoch=479
05/16/2022 15:19:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.17 on epoch=482
05/16/2022 15:19:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.12 on epoch=484
05/16/2022 15:19:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.27 on epoch=487
05/16/2022 15:19:24 - INFO - __main__ - Global step 1950 Train loss 1.20 Classification-F1 0.09414519906323185 on epoch=487
05/16/2022 15:19:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.11 on epoch=489
05/16/2022 15:19:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.28 on epoch=492
05/16/2022 15:19:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.24 on epoch=494
05/16/2022 15:19:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
05/16/2022 15:19:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.20 on epoch=499
05/16/2022 15:19:32 - INFO - __main__ - Global step 2000 Train loss 1.18 Classification-F1 0.11781609195402298 on epoch=499
05/16/2022 15:19:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.25 on epoch=502
05/16/2022 15:19:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.14 on epoch=504
05/16/2022 15:19:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.20 on epoch=507
05/16/2022 15:19:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.15 on epoch=509
05/16/2022 15:19:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.18 on epoch=512
05/16/2022 15:19:39 - INFO - __main__ - Global step 2050 Train loss 1.18 Classification-F1 0.16451612903225807 on epoch=512
05/16/2022 15:19:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.16 on epoch=514
05/16/2022 15:19:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.22 on epoch=517
05/16/2022 15:19:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.10 on epoch=519
05/16/2022 15:19:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.11 on epoch=522
05/16/2022 15:19:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.08 on epoch=524
05/16/2022 15:19:46 - INFO - __main__ - Global step 2100 Train loss 1.14 Classification-F1 0.14962702939885913 on epoch=524
05/16/2022 15:19:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.15 on epoch=527
05/16/2022 15:19:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.24 on epoch=529
05/16/2022 15:19:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.30 on epoch=532
05/16/2022 15:19:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.22 on epoch=534
05/16/2022 15:19:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.18 on epoch=537
05/16/2022 15:19:53 - INFO - __main__ - Global step 2150 Train loss 1.22 Classification-F1 0.17946136788048553 on epoch=537
05/16/2022 15:19:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.16 on epoch=539
05/16/2022 15:19:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=542
05/16/2022 15:19:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.17 on epoch=544
05/16/2022 15:19:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.25 on epoch=547
05/16/2022 15:20:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.14 on epoch=549
05/16/2022 15:20:01 - INFO - __main__ - Global step 2200 Train loss 1.17 Classification-F1 0.15682382133995038 on epoch=549
05/16/2022 15:20:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.10 on epoch=552
05/16/2022 15:20:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.15 on epoch=554
05/16/2022 15:20:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/16/2022 15:20:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/16/2022 15:20:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/16/2022 15:20:08 - INFO - __main__ - Global step 2250 Train loss 1.12 Classification-F1 0.09210526315789473 on epoch=562
05/16/2022 15:20:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/16/2022 15:20:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.33 on epoch=567
05/16/2022 15:20:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/16/2022 15:20:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.15 on epoch=572
05/16/2022 15:20:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
05/16/2022 15:20:15 - INFO - __main__ - Global step 2300 Train loss 1.15 Classification-F1 0.13626373626373625 on epoch=574
05/16/2022 15:20:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.09 on epoch=577
05/16/2022 15:20:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.13 on epoch=579
05/16/2022 15:20:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.18 on epoch=582
05/16/2022 15:20:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.29 on epoch=584
05/16/2022 15:20:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.11 on epoch=587
05/16/2022 15:20:22 - INFO - __main__ - Global step 2350 Train loss 1.16 Classification-F1 0.1412177985948478 on epoch=587
05/16/2022 15:20:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.07 on epoch=589
05/16/2022 15:20:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.15 on epoch=592
05/16/2022 15:20:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/16/2022 15:20:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.13 on epoch=597
05/16/2022 15:20:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.14 on epoch=599
05/16/2022 15:20:30 - INFO - __main__ - Global step 2400 Train loss 1.11 Classification-F1 0.20634920634920634 on epoch=599
05/16/2022 15:20:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.13 on epoch=602
05/16/2022 15:20:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.11 on epoch=604
05/16/2022 15:20:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.17 on epoch=607
05/16/2022 15:20:35 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.17 on epoch=609
05/16/2022 15:20:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.03 on epoch=612
05/16/2022 15:20:37 - INFO - __main__ - Global step 2450 Train loss 1.12 Classification-F1 0.13047619047619047 on epoch=612
05/16/2022 15:20:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.09 on epoch=614
05/16/2022 15:20:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.05 on epoch=617
05/16/2022 15:20:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.13 on epoch=619
05/16/2022 15:20:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/16/2022 15:20:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
05/16/2022 15:20:44 - INFO - __main__ - Global step 2500 Train loss 1.08 Classification-F1 0.1497584541062802 on epoch=624
05/16/2022 15:20:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.01 on epoch=627
05/16/2022 15:20:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
05/16/2022 15:20:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.20 on epoch=632
05/16/2022 15:20:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.13 on epoch=634
05/16/2022 15:20:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.21 on epoch=637
05/16/2022 15:20:52 - INFO - __main__ - Global step 2550 Train loss 1.14 Classification-F1 0.15434782608695652 on epoch=637
05/16/2022 15:20:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.12 on epoch=639
05/16/2022 15:20:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.18 on epoch=642
05/16/2022 15:20:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.12 on epoch=644
05/16/2022 15:20:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/16/2022 15:20:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/16/2022 15:20:59 - INFO - __main__ - Global step 2600 Train loss 1.10 Classification-F1 0.15587044534412953 on epoch=649
05/16/2022 15:21:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.06 on epoch=652
05/16/2022 15:21:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.16 on epoch=654
05/16/2022 15:21:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
05/16/2022 15:21:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.24 on epoch=659
05/16/2022 15:21:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.18 on epoch=662
05/16/2022 15:21:06 - INFO - __main__ - Global step 2650 Train loss 1.12 Classification-F1 0.14095238095238094 on epoch=662
05/16/2022 15:21:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.20 on epoch=664
05/16/2022 15:21:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.16 on epoch=667
05/16/2022 15:21:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.08 on epoch=669
05/16/2022 15:21:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.02 on epoch=672
05/16/2022 15:21:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/16/2022 15:21:15 - INFO - __main__ - Global step 2700 Train loss 1.10 Classification-F1 0.12541806020066892 on epoch=674
05/16/2022 15:21:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.06 on epoch=677
05/16/2022 15:21:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.13 on epoch=679
05/16/2022 15:21:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.10 on epoch=682
05/16/2022 15:21:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.08 on epoch=684
05/16/2022 15:21:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.07 on epoch=687
05/16/2022 15:21:22 - INFO - __main__ - Global step 2750 Train loss 1.09 Classification-F1 0.12564102564102564 on epoch=687
05/16/2022 15:21:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.10 on epoch=689
05/16/2022 15:21:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.13 on epoch=692
05/16/2022 15:21:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.10 on epoch=694
05/16/2022 15:21:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
05/16/2022 15:21:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.11 on epoch=699
05/16/2022 15:21:29 - INFO - __main__ - Global step 2800 Train loss 1.09 Classification-F1 0.15260416666666665 on epoch=699
05/16/2022 15:21:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.02 on epoch=702
05/16/2022 15:21:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.09 on epoch=704
05/16/2022 15:21:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.28 on epoch=707
05/16/2022 15:21:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.04 on epoch=709
05/16/2022 15:21:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.11 on epoch=712
05/16/2022 15:21:37 - INFO - __main__ - Global step 2850 Train loss 1.11 Classification-F1 0.12407862407862408 on epoch=712
05/16/2022 15:21:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.15 on epoch=714
05/16/2022 15:21:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.09 on epoch=717
05/16/2022 15:21:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/16/2022 15:21:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.20 on epoch=722
05/16/2022 15:21:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.11 on epoch=724
05/16/2022 15:21:44 - INFO - __main__ - Global step 2900 Train loss 1.11 Classification-F1 0.13430127041742287 on epoch=724
05/16/2022 15:21:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.17 on epoch=727
05/16/2022 15:21:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.20 on epoch=729
05/16/2022 15:21:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.05 on epoch=732
05/16/2022 15:21:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.06 on epoch=734
05/16/2022 15:21:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.05 on epoch=737
05/16/2022 15:21:52 - INFO - __main__ - Global step 2950 Train loss 1.10 Classification-F1 0.1875 on epoch=737
05/16/2022 15:21:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.04 on epoch=739
05/16/2022 15:21:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.10 on epoch=742
05/16/2022 15:21:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.10 on epoch=744
05/16/2022 15:21:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.09 on epoch=747
05/16/2022 15:21:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.18 on epoch=749
05/16/2022 15:21:59 - INFO - __main__ - Global step 3000 Train loss 1.10 Classification-F1 0.13251935675997617 on epoch=749
05/16/2022 15:21:59 - INFO - __main__ - save last model!
05/16/2022 15:21:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 15:21:59 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 15:21:59 - INFO - __main__ - Printing 3 examples
05/16/2022 15:21:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 15:21:59 - INFO - __main__ - ['others']
05/16/2022 15:21:59 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 15:21:59 - INFO - __main__ - ['others']
05/16/2022 15:21:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 15:21:59 - INFO - __main__ - ['others']
05/16/2022 15:21:59 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:22:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:22:00 - INFO - __main__ - Printing 3 examples
05/16/2022 15:22:00 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:22:00 - INFO - __main__ - ['sad']
05/16/2022 15:22:00 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:22:00 - INFO - __main__ - ['sad']
05/16/2022 15:22:00 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:22:00 - INFO - __main__ - ['sad']
05/16/2022 15:22:00 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:22:00 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:22:00 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:22:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:22:00 - INFO - __main__ - Printing 3 examples
05/16/2022 15:22:00 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:22:00 - INFO - __main__ - ['sad']
05/16/2022 15:22:00 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:22:00 - INFO - __main__ - ['sad']
05/16/2022 15:22:00 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:22:00 - INFO - __main__ - ['sad']
05/16/2022 15:22:00 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:22:00 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:22:00 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:22:01 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:22:06 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:22:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:22:06 - INFO - __main__ - Starting training!
05/16/2022 15:22:08 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 15:22:53 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.2_8_predictions.txt
05/16/2022 15:22:53 - INFO - __main__ - Classification-F1 on test data: 0.0383
05/16/2022 15:22:53 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.21743697478991597, test_performance=0.03826613080547574
05/16/2022 15:22:53 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
05/16/2022 15:22:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:22:54 - INFO - __main__ - Printing 3 examples
05/16/2022 15:22:54 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:22:54 - INFO - __main__ - ['sad']
05/16/2022 15:22:54 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:22:54 - INFO - __main__ - ['sad']
05/16/2022 15:22:54 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:22:54 - INFO - __main__ - ['sad']
05/16/2022 15:22:54 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:22:54 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:22:54 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:22:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:22:54 - INFO - __main__ - Printing 3 examples
05/16/2022 15:22:54 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:22:54 - INFO - __main__ - ['sad']
05/16/2022 15:22:54 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:22:54 - INFO - __main__ - ['sad']
05/16/2022 15:22:54 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:22:54 - INFO - __main__ - ['sad']
05/16/2022 15:22:54 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:22:54 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:22:54 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:23:00 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:23:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:23:00 - INFO - __main__ - Starting training!
05/16/2022 15:23:02 - INFO - __main__ - Step 10 Global step 10 Train loss 6.57 on epoch=2
05/16/2022 15:23:03 - INFO - __main__ - Step 20 Global step 20 Train loss 6.45 on epoch=4
05/16/2022 15:23:04 - INFO - __main__ - Step 30 Global step 30 Train loss 6.23 on epoch=7
05/16/2022 15:23:06 - INFO - __main__ - Step 40 Global step 40 Train loss 5.99 on epoch=9
05/16/2022 15:23:07 - INFO - __main__ - Step 50 Global step 50 Train loss 5.78 on epoch=12
05/16/2022 15:23:10 - INFO - __main__ - Global step 50 Train loss 6.21 Classification-F1 0.0 on epoch=12
05/16/2022 15:23:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 15:23:11 - INFO - __main__ - Step 60 Global step 60 Train loss 5.59 on epoch=14
05/16/2022 15:23:12 - INFO - __main__ - Step 70 Global step 70 Train loss 5.28 on epoch=17
05/16/2022 15:23:14 - INFO - __main__ - Step 80 Global step 80 Train loss 4.97 on epoch=19
05/16/2022 15:23:15 - INFO - __main__ - Step 90 Global step 90 Train loss 4.85 on epoch=22
05/16/2022 15:23:16 - INFO - __main__ - Step 100 Global step 100 Train loss 4.55 on epoch=24
05/16/2022 15:23:17 - INFO - __main__ - Global step 100 Train loss 5.05 Classification-F1 0.06862745098039216 on epoch=24
05/16/2022 15:23:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06862745098039216 on epoch=24, global_step=100
05/16/2022 15:23:18 - INFO - __main__ - Step 110 Global step 110 Train loss 4.41 on epoch=27
05/16/2022 15:23:20 - INFO - __main__ - Step 120 Global step 120 Train loss 4.15 on epoch=29
05/16/2022 15:23:21 - INFO - __main__ - Step 130 Global step 130 Train loss 3.94 on epoch=32
05/16/2022 15:23:22 - INFO - __main__ - Step 140 Global step 140 Train loss 3.64 on epoch=34
05/16/2022 15:23:24 - INFO - __main__ - Step 150 Global step 150 Train loss 3.77 on epoch=37
05/16/2022 15:23:24 - INFO - __main__ - Global step 150 Train loss 3.98 Classification-F1 0.12393162393162392 on epoch=37
05/16/2022 15:23:24 - INFO - __main__ - Saving model with best Classification-F1: 0.06862745098039216 -> 0.12393162393162392 on epoch=37, global_step=150
05/16/2022 15:23:25 - INFO - __main__ - Step 160 Global step 160 Train loss 3.26 on epoch=39
05/16/2022 15:23:27 - INFO - __main__ - Step 170 Global step 170 Train loss 3.44 on epoch=42
05/16/2022 15:23:28 - INFO - __main__ - Step 180 Global step 180 Train loss 3.16 on epoch=44
05/16/2022 15:23:30 - INFO - __main__ - Step 190 Global step 190 Train loss 3.14 on epoch=47
05/16/2022 15:23:31 - INFO - __main__ - Step 200 Global step 200 Train loss 2.96 on epoch=49
05/16/2022 15:23:32 - INFO - __main__ - Global step 200 Train loss 3.19 Classification-F1 0.12145748987854252 on epoch=49
05/16/2022 15:23:33 - INFO - __main__ - Step 210 Global step 210 Train loss 3.09 on epoch=52
05/16/2022 15:23:35 - INFO - __main__ - Step 220 Global step 220 Train loss 2.88 on epoch=54
05/16/2022 15:23:36 - INFO - __main__ - Step 230 Global step 230 Train loss 3.04 on epoch=57
05/16/2022 15:23:38 - INFO - __main__ - Step 240 Global step 240 Train loss 2.77 on epoch=59
05/16/2022 15:23:39 - INFO - __main__ - Step 250 Global step 250 Train loss 2.84 on epoch=62
05/16/2022 15:23:40 - INFO - __main__ - Global step 250 Train loss 2.92 Classification-F1 0.1682769726247987 on epoch=62
05/16/2022 15:23:40 - INFO - __main__ - Saving model with best Classification-F1: 0.12393162393162392 -> 0.1682769726247987 on epoch=62, global_step=250
05/16/2022 15:23:41 - INFO - __main__ - Step 260 Global step 260 Train loss 2.77 on epoch=64
05/16/2022 15:23:43 - INFO - __main__ - Step 270 Global step 270 Train loss 2.87 on epoch=67
05/16/2022 15:23:44 - INFO - __main__ - Step 280 Global step 280 Train loss 2.46 on epoch=69
05/16/2022 15:23:45 - INFO - __main__ - Step 290 Global step 290 Train loss 2.74 on epoch=72
05/16/2022 15:23:46 - INFO - __main__ - Step 300 Global step 300 Train loss 2.60 on epoch=74
05/16/2022 15:23:47 - INFO - __main__ - Global step 300 Train loss 2.69 Classification-F1 0.1 on epoch=74
05/16/2022 15:23:48 - INFO - __main__ - Step 310 Global step 310 Train loss 2.70 on epoch=77
05/16/2022 15:23:49 - INFO - __main__ - Step 320 Global step 320 Train loss 2.42 on epoch=79
05/16/2022 15:23:51 - INFO - __main__ - Step 330 Global step 330 Train loss 2.60 on epoch=82
05/16/2022 15:23:52 - INFO - __main__ - Step 340 Global step 340 Train loss 2.40 on epoch=84
05/16/2022 15:23:53 - INFO - __main__ - Step 350 Global step 350 Train loss 2.45 on epoch=87
05/16/2022 15:23:54 - INFO - __main__ - Global step 350 Train loss 2.51 Classification-F1 0.1 on epoch=87
05/16/2022 15:23:55 - INFO - __main__ - Step 360 Global step 360 Train loss 2.09 on epoch=89
05/16/2022 15:23:56 - INFO - __main__ - Step 370 Global step 370 Train loss 2.32 on epoch=92
05/16/2022 15:23:58 - INFO - __main__ - Step 380 Global step 380 Train loss 2.28 on epoch=94
05/16/2022 15:23:59 - INFO - __main__ - Step 390 Global step 390 Train loss 2.28 on epoch=97
05/16/2022 15:24:00 - INFO - __main__ - Step 400 Global step 400 Train loss 2.20 on epoch=99
05/16/2022 15:24:01 - INFO - __main__ - Global step 400 Train loss 2.24 Classification-F1 0.09615384615384615 on epoch=99
05/16/2022 15:24:02 - INFO - __main__ - Step 410 Global step 410 Train loss 2.12 on epoch=102
05/16/2022 15:24:03 - INFO - __main__ - Step 420 Global step 420 Train loss 2.13 on epoch=104
05/16/2022 15:24:05 - INFO - __main__ - Step 430 Global step 430 Train loss 2.12 on epoch=107
05/16/2022 15:24:06 - INFO - __main__ - Step 440 Global step 440 Train loss 1.94 on epoch=109
05/16/2022 15:24:07 - INFO - __main__ - Step 450 Global step 450 Train loss 1.93 on epoch=112
05/16/2022 15:24:08 - INFO - __main__ - Global step 450 Train loss 2.05 Classification-F1 0.14915966386554622 on epoch=112
05/16/2022 15:24:09 - INFO - __main__ - Step 460 Global step 460 Train loss 1.96 on epoch=114
05/16/2022 15:24:10 - INFO - __main__ - Step 470 Global step 470 Train loss 1.91 on epoch=117
05/16/2022 15:24:11 - INFO - __main__ - Step 480 Global step 480 Train loss 1.83 on epoch=119
05/16/2022 15:24:13 - INFO - __main__ - Step 490 Global step 490 Train loss 1.76 on epoch=122
05/16/2022 15:24:14 - INFO - __main__ - Step 500 Global step 500 Train loss 1.68 on epoch=124
05/16/2022 15:24:15 - INFO - __main__ - Global step 500 Train loss 1.83 Classification-F1 0.13968957871396895 on epoch=124
05/16/2022 15:24:16 - INFO - __main__ - Step 510 Global step 510 Train loss 1.77 on epoch=127
05/16/2022 15:24:17 - INFO - __main__ - Step 520 Global step 520 Train loss 1.69 on epoch=129
05/16/2022 15:24:19 - INFO - __main__ - Step 530 Global step 530 Train loss 1.75 on epoch=132
05/16/2022 15:24:20 - INFO - __main__ - Step 540 Global step 540 Train loss 1.73 on epoch=134
05/16/2022 15:24:21 - INFO - __main__ - Step 550 Global step 550 Train loss 1.70 on epoch=137
05/16/2022 15:24:22 - INFO - __main__ - Global step 550 Train loss 1.73 Classification-F1 0.170995670995671 on epoch=137
05/16/2022 15:24:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1682769726247987 -> 0.170995670995671 on epoch=137, global_step=550
05/16/2022 15:24:23 - INFO - __main__ - Step 560 Global step 560 Train loss 1.55 on epoch=139
05/16/2022 15:24:24 - INFO - __main__ - Step 570 Global step 570 Train loss 1.57 on epoch=142
05/16/2022 15:24:26 - INFO - __main__ - Step 580 Global step 580 Train loss 1.66 on epoch=144
05/16/2022 15:24:27 - INFO - __main__ - Step 590 Global step 590 Train loss 1.61 on epoch=147
05/16/2022 15:24:28 - INFO - __main__ - Step 600 Global step 600 Train loss 1.55 on epoch=149
05/16/2022 15:24:29 - INFO - __main__ - Global step 600 Train loss 1.59 Classification-F1 0.1 on epoch=149
05/16/2022 15:24:30 - INFO - __main__ - Step 610 Global step 610 Train loss 1.51 on epoch=152
05/16/2022 15:24:31 - INFO - __main__ - Step 620 Global step 620 Train loss 1.34 on epoch=154
05/16/2022 15:24:32 - INFO - __main__ - Step 630 Global step 630 Train loss 1.44 on epoch=157
05/16/2022 15:24:34 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=159
05/16/2022 15:24:35 - INFO - __main__ - Step 650 Global step 650 Train loss 1.32 on epoch=162
05/16/2022 15:24:36 - INFO - __main__ - Global step 650 Train loss 1.41 Classification-F1 0.09493670886075949 on epoch=162
05/16/2022 15:24:37 - INFO - __main__ - Step 660 Global step 660 Train loss 1.40 on epoch=164
05/16/2022 15:24:38 - INFO - __main__ - Step 670 Global step 670 Train loss 1.46 on epoch=167
05/16/2022 15:24:40 - INFO - __main__ - Step 680 Global step 680 Train loss 1.32 on epoch=169
05/16/2022 15:24:41 - INFO - __main__ - Step 690 Global step 690 Train loss 1.43 on epoch=172
05/16/2022 15:24:42 - INFO - __main__ - Step 700 Global step 700 Train loss 1.44 on epoch=174
05/16/2022 15:24:43 - INFO - __main__ - Global step 700 Train loss 1.41 Classification-F1 0.1 on epoch=174
05/16/2022 15:24:44 - INFO - __main__ - Step 710 Global step 710 Train loss 1.45 on epoch=177
05/16/2022 15:24:45 - INFO - __main__ - Step 720 Global step 720 Train loss 1.39 on epoch=179
05/16/2022 15:24:47 - INFO - __main__ - Step 730 Global step 730 Train loss 1.31 on epoch=182
05/16/2022 15:24:48 - INFO - __main__ - Step 740 Global step 740 Train loss 1.29 on epoch=184
05/16/2022 15:24:49 - INFO - __main__ - Step 750 Global step 750 Train loss 1.34 on epoch=187
05/16/2022 15:24:50 - INFO - __main__ - Global step 750 Train loss 1.36 Classification-F1 0.09493670886075949 on epoch=187
05/16/2022 15:24:51 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=189
05/16/2022 15:24:52 - INFO - __main__ - Step 770 Global step 770 Train loss 1.30 on epoch=192
05/16/2022 15:24:54 - INFO - __main__ - Step 780 Global step 780 Train loss 1.29 on epoch=194
05/16/2022 15:24:55 - INFO - __main__ - Step 790 Global step 790 Train loss 1.26 on epoch=197
05/16/2022 15:24:56 - INFO - __main__ - Step 800 Global step 800 Train loss 1.31 on epoch=199
05/16/2022 15:24:57 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.1 on epoch=199
05/16/2022 15:24:58 - INFO - __main__ - Step 810 Global step 810 Train loss 1.44 on epoch=202
05/16/2022 15:24:59 - INFO - __main__ - Step 820 Global step 820 Train loss 1.17 on epoch=204
05/16/2022 15:25:00 - INFO - __main__ - Step 830 Global step 830 Train loss 1.25 on epoch=207
05/16/2022 15:25:02 - INFO - __main__ - Step 840 Global step 840 Train loss 1.26 on epoch=209
05/16/2022 15:25:03 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=212
05/16/2022 15:25:04 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.11732186732186733 on epoch=212
05/16/2022 15:25:05 - INFO - __main__ - Step 860 Global step 860 Train loss 1.22 on epoch=214
05/16/2022 15:25:06 - INFO - __main__ - Step 870 Global step 870 Train loss 1.21 on epoch=217
05/16/2022 15:25:07 - INFO - __main__ - Step 880 Global step 880 Train loss 1.23 on epoch=219
05/16/2022 15:25:09 - INFO - __main__ - Step 890 Global step 890 Train loss 1.14 on epoch=222
05/16/2022 15:25:10 - INFO - __main__ - Step 900 Global step 900 Train loss 1.23 on epoch=224
05/16/2022 15:25:10 - INFO - __main__ - Global step 900 Train loss 1.21 Classification-F1 0.13611111111111113 on epoch=224
05/16/2022 15:25:12 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=227
05/16/2022 15:25:13 - INFO - __main__ - Step 920 Global step 920 Train loss 1.28 on epoch=229
05/16/2022 15:25:15 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=232
05/16/2022 15:25:16 - INFO - __main__ - Step 940 Global step 940 Train loss 1.32 on epoch=234
05/16/2022 15:25:17 - INFO - __main__ - Step 950 Global step 950 Train loss 1.16 on epoch=237
05/16/2022 15:25:18 - INFO - __main__ - Global step 950 Train loss 1.26 Classification-F1 0.14915966386554622 on epoch=237
05/16/2022 15:25:19 - INFO - __main__ - Step 960 Global step 960 Train loss 1.18 on epoch=239
05/16/2022 15:25:20 - INFO - __main__ - Step 970 Global step 970 Train loss 1.04 on epoch=242
05/16/2022 15:25:22 - INFO - __main__ - Step 980 Global step 980 Train loss 1.27 on epoch=244
05/16/2022 15:25:23 - INFO - __main__ - Step 990 Global step 990 Train loss 1.06 on epoch=247
05/16/2022 15:25:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.27 on epoch=249
05/16/2022 15:25:25 - INFO - __main__ - Global step 1000 Train loss 1.16 Classification-F1 0.11762954139368673 on epoch=249
05/16/2022 15:25:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.12 on epoch=252
05/16/2022 15:25:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.16 on epoch=254
05/16/2022 15:25:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.25 on epoch=257
05/16/2022 15:25:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.21 on epoch=259
05/16/2022 15:25:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.16 on epoch=262
05/16/2022 15:25:32 - INFO - __main__ - Global step 1050 Train loss 1.18 Classification-F1 0.09615384615384615 on epoch=262
05/16/2022 15:25:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.19 on epoch=264
05/16/2022 15:25:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=267
05/16/2022 15:25:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
05/16/2022 15:25:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.18 on epoch=272
05/16/2022 15:25:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
05/16/2022 15:25:40 - INFO - __main__ - Global step 1100 Train loss 1.15 Classification-F1 0.11177278973889145 on epoch=274
05/16/2022 15:25:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/16/2022 15:25:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.22 on epoch=279
05/16/2022 15:25:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.19 on epoch=282
05/16/2022 15:25:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.20 on epoch=284
05/16/2022 15:25:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=287
05/16/2022 15:25:47 - INFO - __main__ - Global step 1150 Train loss 1.20 Classification-F1 0.14753320683111953 on epoch=287
05/16/2022 15:25:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.12 on epoch=289
05/16/2022 15:25:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.12 on epoch=292
05/16/2022 15:25:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.12 on epoch=294
05/16/2022 15:25:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.06 on epoch=297
05/16/2022 15:25:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.21 on epoch=299
05/16/2022 15:25:54 - INFO - __main__ - Global step 1200 Train loss 1.12 Classification-F1 0.14771241830065357 on epoch=299
05/16/2022 15:25:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.12 on epoch=302
05/16/2022 15:25:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.18 on epoch=304
05/16/2022 15:25:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=307
05/16/2022 15:25:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/16/2022 15:26:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=312
05/16/2022 15:26:01 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.140625 on epoch=312
05/16/2022 15:26:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.01 on epoch=314
05/16/2022 15:26:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.98 on epoch=317
05/16/2022 15:26:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.21 on epoch=319
05/16/2022 15:26:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.09 on epoch=322
05/16/2022 15:26:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.09 on epoch=324
05/16/2022 15:26:08 - INFO - __main__ - Global step 1300 Train loss 1.08 Classification-F1 0.15356265356265356 on epoch=324
05/16/2022 15:26:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.12 on epoch=327
05/16/2022 15:26:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.19 on epoch=329
05/16/2022 15:26:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.10 on epoch=332
05/16/2022 15:26:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.13 on epoch=334
05/16/2022 15:26:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.12 on epoch=337
05/16/2022 15:26:15 - INFO - __main__ - Global step 1350 Train loss 1.13 Classification-F1 0.10126582278481013 on epoch=337
05/16/2022 15:26:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.09 on epoch=339
05/16/2022 15:26:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=342
05/16/2022 15:26:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=344
05/16/2022 15:26:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.00 on epoch=347
05/16/2022 15:26:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=349
05/16/2022 15:26:22 - INFO - __main__ - Global step 1400 Train loss 1.03 Classification-F1 0.1611111111111111 on epoch=349
05/16/2022 15:26:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.02 on epoch=352
05/16/2022 15:26:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.10 on epoch=354
05/16/2022 15:26:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.09 on epoch=357
05/16/2022 15:26:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.12 on epoch=359
05/16/2022 15:26:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
05/16/2022 15:26:29 - INFO - __main__ - Global step 1450 Train loss 1.09 Classification-F1 0.10126582278481013 on epoch=362
05/16/2022 15:26:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=364
05/16/2022 15:26:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.05 on epoch=367
05/16/2022 15:26:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.93 on epoch=369
05/16/2022 15:26:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.05 on epoch=372
05/16/2022 15:26:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.13 on epoch=374
05/16/2022 15:26:37 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.1796875 on epoch=374
05/16/2022 15:26:37 - INFO - __main__ - Saving model with best Classification-F1: 0.170995670995671 -> 0.1796875 on epoch=374, global_step=1500
05/16/2022 15:26:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.11 on epoch=377
05/16/2022 15:26:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.93 on epoch=379
05/16/2022 15:26:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.01 on epoch=382
05/16/2022 15:26:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.95 on epoch=384
05/16/2022 15:26:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.07 on epoch=387
05/16/2022 15:26:44 - INFO - __main__ - Global step 1550 Train loss 1.01 Classification-F1 0.0974025974025974 on epoch=387
05/16/2022 15:26:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.94 on epoch=389
05/16/2022 15:26:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.05 on epoch=392
05/16/2022 15:26:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.01 on epoch=394
05/16/2022 15:26:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.05 on epoch=397
05/16/2022 15:26:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.03 on epoch=399
05/16/2022 15:26:51 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.12646198830409355 on epoch=399
05/16/2022 15:26:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.06 on epoch=402
05/16/2022 15:26:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/16/2022 15:26:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.13 on epoch=407
05/16/2022 15:26:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.92 on epoch=409
05/16/2022 15:26:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.95 on epoch=412
05/16/2022 15:26:59 - INFO - __main__ - Global step 1650 Train loss 1.01 Classification-F1 0.11722488038277512 on epoch=412
05/16/2022 15:27:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.97 on epoch=414
05/16/2022 15:27:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.09 on epoch=417
05/16/2022 15:27:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.03 on epoch=419
05/16/2022 15:27:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.92 on epoch=422
05/16/2022 15:27:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.99 on epoch=424
05/16/2022 15:27:06 - INFO - __main__ - Global step 1700 Train loss 1.00 Classification-F1 0.12710084033613445 on epoch=424
05/16/2022 15:27:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
05/16/2022 15:27:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.86 on epoch=429
05/16/2022 15:27:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.96 on epoch=432
05/16/2022 15:27:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.00 on epoch=434
05/16/2022 15:27:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.04 on epoch=437
05/16/2022 15:27:13 - INFO - __main__ - Global step 1750 Train loss 0.98 Classification-F1 0.17369852369852368 on epoch=437
05/16/2022 15:27:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
05/16/2022 15:27:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.09 on epoch=442
05/16/2022 15:27:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.06 on epoch=444
05/16/2022 15:27:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.11 on epoch=447
05/16/2022 15:27:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.19 on epoch=449
05/16/2022 15:27:20 - INFO - __main__ - Global step 1800 Train loss 1.09 Classification-F1 0.21286031042128603 on epoch=449
05/16/2022 15:27:20 - INFO - __main__ - Saving model with best Classification-F1: 0.1796875 -> 0.21286031042128603 on epoch=449, global_step=1800
05/16/2022 15:27:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/16/2022 15:27:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.99 on epoch=454
05/16/2022 15:27:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.12 on epoch=457
05/16/2022 15:27:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.00 on epoch=459
05/16/2022 15:27:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/16/2022 15:27:27 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.2034090909090909 on epoch=462
05/16/2022 15:27:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.00 on epoch=464
05/16/2022 15:27:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.98 on epoch=467
05/16/2022 15:27:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.99 on epoch=469
05/16/2022 15:27:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.95 on epoch=472
05/16/2022 15:27:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.93 on epoch=474
05/16/2022 15:27:35 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.1 on epoch=474
05/16/2022 15:27:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.00 on epoch=477
05/16/2022 15:27:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.05 on epoch=479
05/16/2022 15:27:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=482
05/16/2022 15:27:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.01 on epoch=484
05/16/2022 15:27:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.04 on epoch=487
05/16/2022 15:27:42 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.12393162393162392 on epoch=487
05/16/2022 15:27:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.08 on epoch=489
05/16/2022 15:27:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.10 on epoch=492
05/16/2022 15:27:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.03 on epoch=494
05/16/2022 15:27:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.06 on epoch=497
05/16/2022 15:27:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.05 on epoch=499
05/16/2022 15:27:50 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.1 on epoch=499
05/16/2022 15:27:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/16/2022 15:27:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.11 on epoch=504
05/16/2022 15:27:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=507
05/16/2022 15:27:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.06 on epoch=509
05/16/2022 15:27:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.04 on epoch=512
05/16/2022 15:27:57 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.15498891352549887 on epoch=512
05/16/2022 15:27:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=514
05/16/2022 15:28:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.99 on epoch=517
05/16/2022 15:28:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
05/16/2022 15:28:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.88 on epoch=522
05/16/2022 15:28:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.96 on epoch=524
05/16/2022 15:28:04 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.10256410256410256 on epoch=524
05/16/2022 15:28:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/16/2022 15:28:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.95 on epoch=529
05/16/2022 15:28:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
05/16/2022 15:28:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.00 on epoch=534
05/16/2022 15:28:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.09 on epoch=537
05/16/2022 15:28:11 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.1660839160839161 on epoch=537
05/16/2022 15:28:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.05 on epoch=539
05/16/2022 15:28:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.92 on epoch=542
05/16/2022 15:28:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/16/2022 15:28:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.99 on epoch=547
05/16/2022 15:28:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.96 on epoch=549
05/16/2022 15:28:19 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.16963260619977039 on epoch=549
05/16/2022 15:28:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.89 on epoch=552
05/16/2022 15:28:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.00 on epoch=554
05/16/2022 15:28:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.91 on epoch=557
05/16/2022 15:28:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.01 on epoch=559
05/16/2022 15:28:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=562
05/16/2022 15:28:26 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.12407862407862408 on epoch=562
05/16/2022 15:28:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/16/2022 15:28:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=567
05/16/2022 15:28:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.00 on epoch=569
05/16/2022 15:28:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/16/2022 15:28:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/16/2022 15:28:33 - INFO - __main__ - Global step 2300 Train loss 1.01 Classification-F1 0.13067758749069247 on epoch=574
05/16/2022 15:28:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/16/2022 15:28:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.97 on epoch=579
05/16/2022 15:28:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/16/2022 15:28:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.88 on epoch=584
05/16/2022 15:28:40 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=587
05/16/2022 15:28:40 - INFO - __main__ - Global step 2350 Train loss 0.94 Classification-F1 0.1437908496732026 on epoch=587
05/16/2022 15:28:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.91 on epoch=589
05/16/2022 15:28:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
05/16/2022 15:28:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.95 on epoch=594
05/16/2022 15:28:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/16/2022 15:28:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.96 on epoch=599
05/16/2022 15:28:48 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.13067758749069247 on epoch=599
05/16/2022 15:28:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.02 on epoch=602
05/16/2022 15:28:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/16/2022 15:28:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.92 on epoch=607
05/16/2022 15:28:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
05/16/2022 15:28:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
05/16/2022 15:28:55 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.23392857142857143 on epoch=612
05/16/2022 15:28:55 - INFO - __main__ - Saving model with best Classification-F1: 0.21286031042128603 -> 0.23392857142857143 on epoch=612, global_step=2450
05/16/2022 15:28:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.89 on epoch=614
05/16/2022 15:28:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=617
05/16/2022 15:28:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
05/16/2022 15:29:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
05/16/2022 15:29:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
05/16/2022 15:29:02 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.10126582278481013 on epoch=624
05/16/2022 15:29:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/16/2022 15:29:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.99 on epoch=629
05/16/2022 15:29:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.85 on epoch=632
05/16/2022 15:29:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/16/2022 15:29:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.01 on epoch=637
05/16/2022 15:29:09 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.21869565217391307 on epoch=637
05/16/2022 15:29:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.92 on epoch=639
05/16/2022 15:29:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.84 on epoch=642
05/16/2022 15:29:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.87 on epoch=644
05/16/2022 15:29:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/16/2022 15:29:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/16/2022 15:29:16 - INFO - __main__ - Global step 2600 Train loss 0.92 Classification-F1 0.17694311767260096 on epoch=649
05/16/2022 15:29:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.08 on epoch=652
05/16/2022 15:29:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
05/16/2022 15:29:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=657
05/16/2022 15:29:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
05/16/2022 15:29:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.94 on epoch=662
05/16/2022 15:29:24 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.0974025974025974 on epoch=662
05/16/2022 15:29:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.87 on epoch=664
05/16/2022 15:29:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.99 on epoch=667
05/16/2022 15:29:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.98 on epoch=669
05/16/2022 15:29:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.95 on epoch=672
05/16/2022 15:29:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.96 on epoch=674
05/16/2022 15:29:31 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.1738412346070504 on epoch=674
05/16/2022 15:29:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.90 on epoch=677
05/16/2022 15:29:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.87 on epoch=679
05/16/2022 15:29:35 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.95 on epoch=682
05/16/2022 15:29:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.01 on epoch=684
05/16/2022 15:29:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.96 on epoch=687
05/16/2022 15:29:39 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.13333333333333333 on epoch=687
05/16/2022 15:29:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.89 on epoch=689
05/16/2022 15:29:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.84 on epoch=692
05/16/2022 15:29:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.94 on epoch=694
05/16/2022 15:29:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
05/16/2022 15:29:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.87 on epoch=699
05/16/2022 15:29:47 - INFO - __main__ - Global step 2800 Train loss 0.90 Classification-F1 0.13566098081023453 on epoch=699
05/16/2022 15:29:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.94 on epoch=702
05/16/2022 15:29:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/16/2022 15:29:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.99 on epoch=707
05/16/2022 15:29:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.86 on epoch=709
05/16/2022 15:29:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.83 on epoch=712
05/16/2022 15:29:54 - INFO - __main__ - Global step 2850 Train loss 0.91 Classification-F1 0.15 on epoch=712
05/16/2022 15:29:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
05/16/2022 15:29:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.87 on epoch=717
05/16/2022 15:29:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.93 on epoch=719
05/16/2022 15:30:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.98 on epoch=722
05/16/2022 15:30:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.85 on epoch=724
05/16/2022 15:30:02 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.1 on epoch=724
05/16/2022 15:30:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.94 on epoch=727
05/16/2022 15:30:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.07 on epoch=729
05/16/2022 15:30:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
05/16/2022 15:30:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.92 on epoch=734
05/16/2022 15:30:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.89 on epoch=737
05/16/2022 15:30:09 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.148970398970399 on epoch=737
05/16/2022 15:30:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=739
05/16/2022 15:30:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.88 on epoch=742
05/16/2022 15:30:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.88 on epoch=744
05/16/2022 15:30:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.91 on epoch=747
05/16/2022 15:30:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.88 on epoch=749
05/16/2022 15:30:16 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.13047619047619047 on epoch=749
05/16/2022 15:30:16 - INFO - __main__ - save last model!
05/16/2022 15:30:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 15:30:16 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 15:30:16 - INFO - __main__ - Printing 3 examples
05/16/2022 15:30:16 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 15:30:16 - INFO - __main__ - ['others']
05/16/2022 15:30:16 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 15:30:16 - INFO - __main__ - ['others']
05/16/2022 15:30:16 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 15:30:16 - INFO - __main__ - ['others']
05/16/2022 15:30:16 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:30:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:30:17 - INFO - __main__ - Printing 3 examples
05/16/2022 15:30:17 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:30:17 - INFO - __main__ - ['sad']
05/16/2022 15:30:17 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:30:17 - INFO - __main__ - ['sad']
05/16/2022 15:30:17 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:30:17 - INFO - __main__ - ['sad']
05/16/2022 15:30:17 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:30:17 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:30:17 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:30:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:30:17 - INFO - __main__ - Printing 3 examples
05/16/2022 15:30:17 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:30:17 - INFO - __main__ - ['sad']
05/16/2022 15:30:17 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:30:17 - INFO - __main__ - ['sad']
05/16/2022 15:30:17 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:30:17 - INFO - __main__ - ['sad']
05/16/2022 15:30:17 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:30:17 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:30:17 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:30:18 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:30:23 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:30:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:30:23 - INFO - __main__ - Starting training!
05/16/2022 15:30:24 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 15:31:08 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.5_8_predictions.txt
05/16/2022 15:31:08 - INFO - __main__ - Classification-F1 on test data: 0.0474
05/16/2022 15:31:08 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.23392857142857143, test_performance=0.04740650656882946
05/16/2022 15:31:08 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
05/16/2022 15:31:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:31:09 - INFO - __main__ - Printing 3 examples
05/16/2022 15:31:09 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:31:09 - INFO - __main__ - ['sad']
05/16/2022 15:31:09 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:31:09 - INFO - __main__ - ['sad']
05/16/2022 15:31:09 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:31:09 - INFO - __main__ - ['sad']
05/16/2022 15:31:09 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:31:09 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:31:09 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:31:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:31:09 - INFO - __main__ - Printing 3 examples
05/16/2022 15:31:09 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:31:09 - INFO - __main__ - ['sad']
05/16/2022 15:31:09 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:31:09 - INFO - __main__ - ['sad']
05/16/2022 15:31:09 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:31:09 - INFO - __main__ - ['sad']
05/16/2022 15:31:09 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:31:09 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:31:09 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:31:15 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:31:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:31:15 - INFO - __main__ - Starting training!
05/16/2022 15:31:17 - INFO - __main__ - Step 10 Global step 10 Train loss 6.72 on epoch=2
05/16/2022 15:31:18 - INFO - __main__ - Step 20 Global step 20 Train loss 6.47 on epoch=4
05/16/2022 15:31:20 - INFO - __main__ - Step 30 Global step 30 Train loss 6.25 on epoch=7
05/16/2022 15:31:21 - INFO - __main__ - Step 40 Global step 40 Train loss 6.07 on epoch=9
05/16/2022 15:31:22 - INFO - __main__ - Step 50 Global step 50 Train loss 5.90 on epoch=12
05/16/2022 15:31:25 - INFO - __main__ - Global step 50 Train loss 6.28 Classification-F1 0.0 on epoch=12
05/16/2022 15:31:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 15:31:27 - INFO - __main__ - Step 60 Global step 60 Train loss 5.66 on epoch=14
05/16/2022 15:31:28 - INFO - __main__ - Step 70 Global step 70 Train loss 5.64 on epoch=17
05/16/2022 15:31:29 - INFO - __main__ - Step 80 Global step 80 Train loss 5.40 on epoch=19
05/16/2022 15:31:31 - INFO - __main__ - Step 90 Global step 90 Train loss 5.30 on epoch=22
05/16/2022 15:31:32 - INFO - __main__ - Step 100 Global step 100 Train loss 5.06 on epoch=24
05/16/2022 15:31:33 - INFO - __main__ - Global step 100 Train loss 5.41 Classification-F1 0.0 on epoch=24
05/16/2022 15:31:35 - INFO - __main__ - Step 110 Global step 110 Train loss 5.02 on epoch=27
05/16/2022 15:31:36 - INFO - __main__ - Step 120 Global step 120 Train loss 4.77 on epoch=29
05/16/2022 15:31:38 - INFO - __main__ - Step 130 Global step 130 Train loss 4.71 on epoch=32
05/16/2022 15:31:39 - INFO - __main__ - Step 140 Global step 140 Train loss 4.55 on epoch=34
05/16/2022 15:31:41 - INFO - __main__ - Step 150 Global step 150 Train loss 4.48 on epoch=37
05/16/2022 15:31:42 - INFO - __main__ - Global step 150 Train loss 4.71 Classification-F1 0.03571428571428571 on epoch=37
05/16/2022 15:31:42 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03571428571428571 on epoch=37, global_step=150
05/16/2022 15:31:43 - INFO - __main__ - Step 160 Global step 160 Train loss 4.19 on epoch=39
05/16/2022 15:31:45 - INFO - __main__ - Step 170 Global step 170 Train loss 4.17 on epoch=42
05/16/2022 15:31:46 - INFO - __main__ - Step 180 Global step 180 Train loss 4.12 on epoch=44
05/16/2022 15:31:47 - INFO - __main__ - Step 190 Global step 190 Train loss 4.15 on epoch=47
05/16/2022 15:31:49 - INFO - __main__ - Step 200 Global step 200 Train loss 4.03 on epoch=49
05/16/2022 15:31:50 - INFO - __main__ - Global step 200 Train loss 4.13 Classification-F1 0.11805555555555555 on epoch=49
05/16/2022 15:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.03571428571428571 -> 0.11805555555555555 on epoch=49, global_step=200
05/16/2022 15:31:51 - INFO - __main__ - Step 210 Global step 210 Train loss 4.00 on epoch=52
05/16/2022 15:31:53 - INFO - __main__ - Step 220 Global step 220 Train loss 3.85 on epoch=54
05/16/2022 15:31:54 - INFO - __main__ - Step 230 Global step 230 Train loss 3.83 on epoch=57
05/16/2022 15:31:55 - INFO - __main__ - Step 240 Global step 240 Train loss 3.64 on epoch=59
05/16/2022 15:31:57 - INFO - __main__ - Step 250 Global step 250 Train loss 3.60 on epoch=62
05/16/2022 15:31:57 - INFO - __main__ - Global step 250 Train loss 3.78 Classification-F1 0.1283068783068783 on epoch=62
05/16/2022 15:31:57 - INFO - __main__ - Saving model with best Classification-F1: 0.11805555555555555 -> 0.1283068783068783 on epoch=62, global_step=250
05/16/2022 15:31:59 - INFO - __main__ - Step 260 Global step 260 Train loss 3.46 on epoch=64
05/16/2022 15:32:00 - INFO - __main__ - Step 270 Global step 270 Train loss 3.47 on epoch=67
05/16/2022 15:32:01 - INFO - __main__ - Step 280 Global step 280 Train loss 3.26 on epoch=69
05/16/2022 15:32:03 - INFO - __main__ - Step 290 Global step 290 Train loss 3.24 on epoch=72
05/16/2022 15:32:04 - INFO - __main__ - Step 300 Global step 300 Train loss 3.06 on epoch=74
05/16/2022 15:32:05 - INFO - __main__ - Global step 300 Train loss 3.30 Classification-F1 0.15526315789473685 on epoch=74
05/16/2022 15:32:05 - INFO - __main__ - Saving model with best Classification-F1: 0.1283068783068783 -> 0.15526315789473685 on epoch=74, global_step=300
05/16/2022 15:32:06 - INFO - __main__ - Step 310 Global step 310 Train loss 3.04 on epoch=77
05/16/2022 15:32:07 - INFO - __main__ - Step 320 Global step 320 Train loss 3.00 on epoch=79
05/16/2022 15:32:09 - INFO - __main__ - Step 330 Global step 330 Train loss 3.10 on epoch=82
05/16/2022 15:32:10 - INFO - __main__ - Step 340 Global step 340 Train loss 3.02 on epoch=84
05/16/2022 15:32:11 - INFO - __main__ - Step 350 Global step 350 Train loss 3.04 on epoch=87
05/16/2022 15:32:12 - INFO - __main__ - Global step 350 Train loss 3.04 Classification-F1 0.1869328493647913 on epoch=87
05/16/2022 15:32:12 - INFO - __main__ - Saving model with best Classification-F1: 0.15526315789473685 -> 0.1869328493647913 on epoch=87, global_step=350
05/16/2022 15:32:13 - INFO - __main__ - Step 360 Global step 360 Train loss 2.83 on epoch=89
05/16/2022 15:32:15 - INFO - __main__ - Step 370 Global step 370 Train loss 2.81 on epoch=92
05/16/2022 15:32:16 - INFO - __main__ - Step 380 Global step 380 Train loss 2.69 on epoch=94
05/16/2022 15:32:17 - INFO - __main__ - Step 390 Global step 390 Train loss 2.77 on epoch=97
05/16/2022 15:32:19 - INFO - __main__ - Step 400 Global step 400 Train loss 2.53 on epoch=99
05/16/2022 15:32:19 - INFO - __main__ - Global step 400 Train loss 2.73 Classification-F1 0.18888888888888888 on epoch=99
05/16/2022 15:32:19 - INFO - __main__ - Saving model with best Classification-F1: 0.1869328493647913 -> 0.18888888888888888 on epoch=99, global_step=400
05/16/2022 15:32:20 - INFO - __main__ - Step 410 Global step 410 Train loss 2.50 on epoch=102
05/16/2022 15:32:22 - INFO - __main__ - Step 420 Global step 420 Train loss 2.47 on epoch=104
05/16/2022 15:32:23 - INFO - __main__ - Step 430 Global step 430 Train loss 2.51 on epoch=107
05/16/2022 15:32:24 - INFO - __main__ - Step 440 Global step 440 Train loss 2.37 on epoch=109
05/16/2022 15:32:26 - INFO - __main__ - Step 450 Global step 450 Train loss 2.45 on epoch=112
05/16/2022 15:32:26 - INFO - __main__ - Global step 450 Train loss 2.46 Classification-F1 0.10294117647058824 on epoch=112
05/16/2022 15:32:28 - INFO - __main__ - Step 460 Global step 460 Train loss 2.45 on epoch=114
05/16/2022 15:32:29 - INFO - __main__ - Step 470 Global step 470 Train loss 2.44 on epoch=117
05/16/2022 15:32:30 - INFO - __main__ - Step 480 Global step 480 Train loss 2.41 on epoch=119
05/16/2022 15:32:32 - INFO - __main__ - Step 490 Global step 490 Train loss 2.24 on epoch=122
05/16/2022 15:32:34 - INFO - __main__ - Step 500 Global step 500 Train loss 2.29 on epoch=124
05/16/2022 15:32:34 - INFO - __main__ - Global step 500 Train loss 2.37 Classification-F1 0.1237183868762816 on epoch=124
05/16/2022 15:32:36 - INFO - __main__ - Step 510 Global step 510 Train loss 2.29 on epoch=127
05/16/2022 15:32:37 - INFO - __main__ - Step 520 Global step 520 Train loss 2.12 on epoch=129
05/16/2022 15:32:39 - INFO - __main__ - Step 530 Global step 530 Train loss 2.14 on epoch=132
05/16/2022 15:32:41 - INFO - __main__ - Step 540 Global step 540 Train loss 1.98 on epoch=134
05/16/2022 15:32:42 - INFO - __main__ - Step 550 Global step 550 Train loss 2.12 on epoch=137
05/16/2022 15:32:43 - INFO - __main__ - Global step 550 Train loss 2.13 Classification-F1 0.1 on epoch=137
05/16/2022 15:32:44 - INFO - __main__ - Step 560 Global step 560 Train loss 1.86 on epoch=139
05/16/2022 15:32:46 - INFO - __main__ - Step 570 Global step 570 Train loss 2.00 on epoch=142
05/16/2022 15:32:47 - INFO - __main__ - Step 580 Global step 580 Train loss 1.88 on epoch=144
05/16/2022 15:32:48 - INFO - __main__ - Step 590 Global step 590 Train loss 1.81 on epoch=147
05/16/2022 15:32:50 - INFO - __main__ - Step 600 Global step 600 Train loss 1.84 on epoch=149
05/16/2022 15:32:50 - INFO - __main__ - Global step 600 Train loss 1.88 Classification-F1 0.12393162393162392 on epoch=149
05/16/2022 15:32:52 - INFO - __main__ - Step 610 Global step 610 Train loss 1.89 on epoch=152
05/16/2022 15:32:53 - INFO - __main__ - Step 620 Global step 620 Train loss 1.82 on epoch=154
05/16/2022 15:32:54 - INFO - __main__ - Step 630 Global step 630 Train loss 1.91 on epoch=157
05/16/2022 15:32:56 - INFO - __main__ - Step 640 Global step 640 Train loss 1.66 on epoch=159
05/16/2022 15:32:57 - INFO - __main__ - Step 650 Global step 650 Train loss 1.80 on epoch=162
05/16/2022 15:32:58 - INFO - __main__ - Global step 650 Train loss 1.81 Classification-F1 0.11714285714285715 on epoch=162
05/16/2022 15:32:59 - INFO - __main__ - Step 660 Global step 660 Train loss 1.68 on epoch=164
05/16/2022 15:33:01 - INFO - __main__ - Step 670 Global step 670 Train loss 1.67 on epoch=167
05/16/2022 15:33:02 - INFO - __main__ - Step 680 Global step 680 Train loss 1.59 on epoch=169
05/16/2022 15:33:04 - INFO - __main__ - Step 690 Global step 690 Train loss 1.78 on epoch=172
05/16/2022 15:33:05 - INFO - __main__ - Step 700 Global step 700 Train loss 1.66 on epoch=174
05/16/2022 15:33:06 - INFO - __main__ - Global step 700 Train loss 1.67 Classification-F1 0.19016393442622948 on epoch=174
05/16/2022 15:33:06 - INFO - __main__ - Saving model with best Classification-F1: 0.18888888888888888 -> 0.19016393442622948 on epoch=174, global_step=700
05/16/2022 15:33:07 - INFO - __main__ - Step 710 Global step 710 Train loss 1.69 on epoch=177
05/16/2022 15:33:09 - INFO - __main__ - Step 720 Global step 720 Train loss 1.55 on epoch=179
05/16/2022 15:33:10 - INFO - __main__ - Step 730 Global step 730 Train loss 1.69 on epoch=182
05/16/2022 15:33:12 - INFO - __main__ - Step 740 Global step 740 Train loss 1.58 on epoch=184
05/16/2022 15:33:13 - INFO - __main__ - Step 750 Global step 750 Train loss 1.69 on epoch=187
05/16/2022 15:33:14 - INFO - __main__ - Global step 750 Train loss 1.64 Classification-F1 0.12407862407862408 on epoch=187
05/16/2022 15:33:15 - INFO - __main__ - Step 760 Global step 760 Train loss 1.50 on epoch=189
05/16/2022 15:33:17 - INFO - __main__ - Step 770 Global step 770 Train loss 1.58 on epoch=192
05/16/2022 15:33:18 - INFO - __main__ - Step 780 Global step 780 Train loss 1.49 on epoch=194
05/16/2022 15:33:20 - INFO - __main__ - Step 790 Global step 790 Train loss 1.56 on epoch=197
05/16/2022 15:33:21 - INFO - __main__ - Step 800 Global step 800 Train loss 1.46 on epoch=199
05/16/2022 15:33:22 - INFO - __main__ - Global step 800 Train loss 1.52 Classification-F1 0.13026315789473686 on epoch=199
05/16/2022 15:33:23 - INFO - __main__ - Step 810 Global step 810 Train loss 1.42 on epoch=202
05/16/2022 15:33:25 - INFO - __main__ - Step 820 Global step 820 Train loss 1.45 on epoch=204
05/16/2022 15:33:26 - INFO - __main__ - Step 830 Global step 830 Train loss 1.49 on epoch=207
05/16/2022 15:33:28 - INFO - __main__ - Step 840 Global step 840 Train loss 1.50 on epoch=209
05/16/2022 15:33:29 - INFO - __main__ - Step 850 Global step 850 Train loss 1.46 on epoch=212
05/16/2022 15:33:30 - INFO - __main__ - Global step 850 Train loss 1.46 Classification-F1 0.09333333333333334 on epoch=212
05/16/2022 15:33:31 - INFO - __main__ - Step 860 Global step 860 Train loss 1.41 on epoch=214
05/16/2022 15:33:33 - INFO - __main__ - Step 870 Global step 870 Train loss 1.40 on epoch=217
05/16/2022 15:33:34 - INFO - __main__ - Step 880 Global step 880 Train loss 1.51 on epoch=219
05/16/2022 15:33:36 - INFO - __main__ - Step 890 Global step 890 Train loss 1.37 on epoch=222
05/16/2022 15:33:37 - INFO - __main__ - Step 900 Global step 900 Train loss 1.53 on epoch=224
05/16/2022 15:33:38 - INFO - __main__ - Global step 900 Train loss 1.44 Classification-F1 0.1 on epoch=224
05/16/2022 15:33:40 - INFO - __main__ - Step 910 Global step 910 Train loss 1.41 on epoch=227
05/16/2022 15:33:41 - INFO - __main__ - Step 920 Global step 920 Train loss 1.38 on epoch=229
05/16/2022 15:33:42 - INFO - __main__ - Step 930 Global step 930 Train loss 1.35 on epoch=232
05/16/2022 15:33:44 - INFO - __main__ - Step 940 Global step 940 Train loss 1.41 on epoch=234
05/16/2022 15:33:45 - INFO - __main__ - Step 950 Global step 950 Train loss 1.43 on epoch=237
05/16/2022 15:33:46 - INFO - __main__ - Global step 950 Train loss 1.40 Classification-F1 0.12171899125064337 on epoch=237
05/16/2022 15:33:47 - INFO - __main__ - Step 960 Global step 960 Train loss 1.33 on epoch=239
05/16/2022 15:33:48 - INFO - __main__ - Step 970 Global step 970 Train loss 1.28 on epoch=242
05/16/2022 15:33:50 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
05/16/2022 15:33:51 - INFO - __main__ - Step 990 Global step 990 Train loss 1.28 on epoch=247
05/16/2022 15:33:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.29 on epoch=249
05/16/2022 15:33:53 - INFO - __main__ - Global step 1000 Train loss 1.30 Classification-F1 0.17344312918167784 on epoch=249
05/16/2022 15:33:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/16/2022 15:33:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.21 on epoch=254
05/16/2022 15:33:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.34 on epoch=257
05/16/2022 15:33:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.22 on epoch=259
05/16/2022 15:34:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.23 on epoch=262
05/16/2022 15:34:01 - INFO - __main__ - Global step 1050 Train loss 1.27 Classification-F1 0.1625874125874126 on epoch=262
05/16/2022 15:34:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.34 on epoch=264
05/16/2022 15:34:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.36 on epoch=267
05/16/2022 15:34:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.29 on epoch=269
05/16/2022 15:34:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.25 on epoch=272
05/16/2022 15:34:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.29 on epoch=274
05/16/2022 15:34:08 - INFO - __main__ - Global step 1100 Train loss 1.31 Classification-F1 0.14583333333333331 on epoch=274
05/16/2022 15:34:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.34 on epoch=277
05/16/2022 15:34:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.32 on epoch=279
05/16/2022 15:34:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.34 on epoch=282
05/16/2022 15:34:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.27 on epoch=284
05/16/2022 15:34:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.34 on epoch=287
05/16/2022 15:34:15 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.13034188034188032 on epoch=287
05/16/2022 15:34:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.27 on epoch=289
05/16/2022 15:34:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.21 on epoch=292
05/16/2022 15:34:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/16/2022 15:34:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.13 on epoch=297
05/16/2022 15:34:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.24 on epoch=299
05/16/2022 15:34:22 - INFO - __main__ - Global step 1200 Train loss 1.20 Classification-F1 0.1565276828434723 on epoch=299
05/16/2022 15:34:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.21 on epoch=302
05/16/2022 15:34:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.17 on epoch=304
05/16/2022 15:34:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.12 on epoch=307
05/16/2022 15:34:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/16/2022 15:34:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.09 on epoch=312
05/16/2022 15:34:30 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.12407862407862408 on epoch=312
05/16/2022 15:34:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.22 on epoch=314
05/16/2022 15:34:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.32 on epoch=317
05/16/2022 15:34:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.28 on epoch=319
05/16/2022 15:34:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.12 on epoch=322
05/16/2022 15:34:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.12 on epoch=324
05/16/2022 15:34:37 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.1486842105263158 on epoch=324
05/16/2022 15:34:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.08 on epoch=327
05/16/2022 15:34:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.17 on epoch=329
05/16/2022 15:34:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.23 on epoch=332
05/16/2022 15:34:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.21 on epoch=334
05/16/2022 15:34:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=337
05/16/2022 15:34:44 - INFO - __main__ - Global step 1350 Train loss 1.18 Classification-F1 0.2109375 on epoch=337
05/16/2022 15:34:44 - INFO - __main__ - Saving model with best Classification-F1: 0.19016393442622948 -> 0.2109375 on epoch=337, global_step=1350
05/16/2022 15:34:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/16/2022 15:34:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
05/16/2022 15:34:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.17 on epoch=344
05/16/2022 15:34:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.23 on epoch=347
05/16/2022 15:34:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/16/2022 15:34:52 - INFO - __main__ - Global step 1400 Train loss 1.17 Classification-F1 0.131328171530673 on epoch=349
05/16/2022 15:34:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/16/2022 15:34:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.16 on epoch=354
05/16/2022 15:34:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.18 on epoch=357
05/16/2022 15:34:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.19 on epoch=359
05/16/2022 15:34:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.12 on epoch=362
05/16/2022 15:34:59 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.2144212523719165 on epoch=362
05/16/2022 15:34:59 - INFO - __main__ - Saving model with best Classification-F1: 0.2109375 -> 0.2144212523719165 on epoch=362, global_step=1450
05/16/2022 15:35:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.14 on epoch=364
05/16/2022 15:35:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.21 on epoch=367
05/16/2022 15:35:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/16/2022 15:35:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=372
05/16/2022 15:35:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.27 on epoch=374
05/16/2022 15:35:07 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.1 on epoch=374
05/16/2022 15:35:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.06 on epoch=377
05/16/2022 15:35:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/16/2022 15:35:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.15 on epoch=382
05/16/2022 15:35:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
05/16/2022 15:35:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.12 on epoch=387
05/16/2022 15:35:14 - INFO - __main__ - Global step 1550 Train loss 1.09 Classification-F1 0.18356643356643357 on epoch=387
05/16/2022 15:35:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.11 on epoch=389
05/16/2022 15:35:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
05/16/2022 15:35:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.15 on epoch=394
05/16/2022 15:35:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.07 on epoch=397
05/16/2022 15:35:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.99 on epoch=399
05/16/2022 15:35:21 - INFO - __main__ - Global step 1600 Train loss 1.07 Classification-F1 0.17450980392156862 on epoch=399
05/16/2022 15:35:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.13 on epoch=402
05/16/2022 15:35:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.13 on epoch=404
05/16/2022 15:35:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.18 on epoch=407
05/16/2022 15:35:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.13 on epoch=409
05/16/2022 15:35:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.16 on epoch=412
05/16/2022 15:35:28 - INFO - __main__ - Global step 1650 Train loss 1.15 Classification-F1 0.21827759963353183 on epoch=412
05/16/2022 15:35:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2144212523719165 -> 0.21827759963353183 on epoch=412, global_step=1650
05/16/2022 15:35:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.17 on epoch=414
05/16/2022 15:35:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.08 on epoch=417
05/16/2022 15:35:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.23 on epoch=419
05/16/2022 15:35:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.24 on epoch=422
05/16/2022 15:35:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.14 on epoch=424
05/16/2022 15:35:36 - INFO - __main__ - Global step 1700 Train loss 1.17 Classification-F1 0.18869565217391304 on epoch=424
05/16/2022 15:35:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.09 on epoch=427
05/16/2022 15:35:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/16/2022 15:35:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.19 on epoch=432
05/16/2022 15:35:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.11 on epoch=434
05/16/2022 15:35:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.02 on epoch=437
05/16/2022 15:35:43 - INFO - __main__ - Global step 1750 Train loss 1.08 Classification-F1 0.22832890218234186 on epoch=437
05/16/2022 15:35:43 - INFO - __main__ - Saving model with best Classification-F1: 0.21827759963353183 -> 0.22832890218234186 on epoch=437, global_step=1750
05/16/2022 15:35:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.03 on epoch=439
05/16/2022 15:35:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
05/16/2022 15:35:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/16/2022 15:35:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.97 on epoch=447
05/16/2022 15:35:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/16/2022 15:35:51 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.23446115288220554 on epoch=449
05/16/2022 15:35:51 - INFO - __main__ - Saving model with best Classification-F1: 0.22832890218234186 -> 0.23446115288220554 on epoch=449, global_step=1800
05/16/2022 15:35:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.10 on epoch=452
05/16/2022 15:35:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.05 on epoch=454
05/16/2022 15:35:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.15 on epoch=457
05/16/2022 15:35:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.10 on epoch=459
05/16/2022 15:35:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.07 on epoch=462
05/16/2022 15:35:58 - INFO - __main__ - Global step 1850 Train loss 1.10 Classification-F1 0.10606060606060605 on epoch=462
05/16/2022 15:36:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.17 on epoch=464
05/16/2022 15:36:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.12 on epoch=467
05/16/2022 15:36:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.18 on epoch=469
05/16/2022 15:36:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.12 on epoch=472
05/16/2022 15:36:05 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.09 on epoch=474
05/16/2022 15:36:06 - INFO - __main__ - Global step 1900 Train loss 1.14 Classification-F1 0.18928571428571428 on epoch=474
05/16/2022 15:36:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
05/16/2022 15:36:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
05/16/2022 15:36:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.07 on epoch=482
05/16/2022 15:36:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=484
05/16/2022 15:36:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.97 on epoch=487
05/16/2022 15:36:13 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.17075672111933193 on epoch=487
05/16/2022 15:36:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.06 on epoch=489
05/16/2022 15:36:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.10 on epoch=492
05/16/2022 15:36:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.97 on epoch=494
05/16/2022 15:36:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.94 on epoch=497
05/16/2022 15:36:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.06 on epoch=499
05/16/2022 15:36:21 - INFO - __main__ - Global step 2000 Train loss 1.02 Classification-F1 0.11512749142601521 on epoch=499
05/16/2022 15:36:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.00 on epoch=502
05/16/2022 15:36:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.12 on epoch=504
05/16/2022 15:36:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
05/16/2022 15:36:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.10 on epoch=509
05/16/2022 15:36:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.03 on epoch=512
05/16/2022 15:36:28 - INFO - __main__ - Global step 2050 Train loss 1.06 Classification-F1 0.16953316953316955 on epoch=512
05/16/2022 15:36:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=514
05/16/2022 15:36:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.01 on epoch=517
05/16/2022 15:36:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.08 on epoch=519
05/16/2022 15:36:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.12 on epoch=522
05/16/2022 15:36:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.07 on epoch=524
05/16/2022 15:36:36 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.18714719930525403 on epoch=524
05/16/2022 15:36:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.13 on epoch=527
05/16/2022 15:36:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.04 on epoch=529
05/16/2022 15:36:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.05 on epoch=532
05/16/2022 15:36:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/16/2022 15:36:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.98 on epoch=537
05/16/2022 15:36:43 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.11840411840411841 on epoch=537
05/16/2022 15:36:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.06 on epoch=539
05/16/2022 15:36:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.01 on epoch=542
05/16/2022 15:36:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.09 on epoch=544
05/16/2022 15:36:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=547
05/16/2022 15:36:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
05/16/2022 15:36:50 - INFO - __main__ - Global step 2200 Train loss 1.03 Classification-F1 0.10256410256410256 on epoch=549
05/16/2022 15:36:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.96 on epoch=552
05/16/2022 15:36:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.07 on epoch=554
05/16/2022 15:36:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/16/2022 15:36:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/16/2022 15:36:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=562
05/16/2022 15:36:58 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.1 on epoch=562
05/16/2022 15:36:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/16/2022 15:37:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.03 on epoch=567
05/16/2022 15:37:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.04 on epoch=569
05/16/2022 15:37:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/16/2022 15:37:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.10 on epoch=574
05/16/2022 15:37:05 - INFO - __main__ - Global step 2300 Train loss 1.03 Classification-F1 0.1697802197802198 on epoch=574
05/16/2022 15:37:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/16/2022 15:37:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/16/2022 15:37:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=582
05/16/2022 15:37:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/16/2022 15:37:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.11 on epoch=587
05/16/2022 15:37:12 - INFO - __main__ - Global step 2350 Train loss 1.00 Classification-F1 0.20053238686779057 on epoch=587
05/16/2022 15:37:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.98 on epoch=589
05/16/2022 15:37:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.01 on epoch=592
05/16/2022 15:37:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.01 on epoch=594
05/16/2022 15:37:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.13 on epoch=597
05/16/2022 15:37:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.05 on epoch=599
05/16/2022 15:37:20 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.17343358395989975 on epoch=599
05/16/2022 15:37:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.04 on epoch=602
05/16/2022 15:37:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/16/2022 15:37:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.06 on epoch=607
05/16/2022 15:37:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.07 on epoch=609
05/16/2022 15:37:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/16/2022 15:37:27 - INFO - __main__ - Global step 2450 Train loss 1.02 Classification-F1 0.11762954139368673 on epoch=612
05/16/2022 15:37:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.03 on epoch=614
05/16/2022 15:37:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.00 on epoch=617
05/16/2022 15:37:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.01 on epoch=619
05/16/2022 15:37:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/16/2022 15:37:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.13 on epoch=624
05/16/2022 15:37:35 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.18969624776652771 on epoch=624
05/16/2022 15:37:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.09 on epoch=627
05/16/2022 15:37:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.05 on epoch=629
05/16/2022 15:37:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.00 on epoch=632
05/16/2022 15:37:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/16/2022 15:37:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.02 on epoch=637
05/16/2022 15:37:43 - INFO - __main__ - Global step 2550 Train loss 1.03 Classification-F1 0.16451612903225807 on epoch=637
05/16/2022 15:37:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/16/2022 15:37:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
05/16/2022 15:37:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.93 on epoch=644
05/16/2022 15:37:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.04 on epoch=647
05/16/2022 15:37:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/16/2022 15:37:51 - INFO - __main__ - Global step 2600 Train loss 0.99 Classification-F1 0.17694311767260096 on epoch=649
05/16/2022 15:37:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/16/2022 15:37:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=654
05/16/2022 15:37:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
05/16/2022 15:37:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.99 on epoch=659
05/16/2022 15:37:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.97 on epoch=662
05/16/2022 15:37:59 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.20714285714285713 on epoch=662
05/16/2022 15:38:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.05 on epoch=664
05/16/2022 15:38:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.08 on epoch=667
05/16/2022 15:38:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.01 on epoch=669
05/16/2022 15:38:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.98 on epoch=672
05/16/2022 15:38:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.94 on epoch=674
05/16/2022 15:38:07 - INFO - __main__ - Global step 2700 Train loss 1.01 Classification-F1 0.10273972602739727 on epoch=674
05/16/2022 15:38:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/16/2022 15:38:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.10 on epoch=679
05/16/2022 15:38:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/16/2022 15:38:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.06 on epoch=684
05/16/2022 15:38:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.97 on epoch=687
05/16/2022 15:38:14 - INFO - __main__ - Global step 2750 Train loss 1.04 Classification-F1 0.10389610389610389 on epoch=687
05/16/2022 15:38:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.94 on epoch=689
05/16/2022 15:38:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.95 on epoch=692
05/16/2022 15:38:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.89 on epoch=694
05/16/2022 15:38:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=697
05/16/2022 15:38:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.99 on epoch=699
05/16/2022 15:38:21 - INFO - __main__ - Global step 2800 Train loss 0.94 Classification-F1 0.12393162393162392 on epoch=699
05/16/2022 15:38:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.01 on epoch=702
05/16/2022 15:38:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.00 on epoch=704
05/16/2022 15:38:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.03 on epoch=707
05/16/2022 15:38:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/16/2022 15:38:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/16/2022 15:38:29 - INFO - __main__ - Global step 2850 Train loss 0.99 Classification-F1 0.1 on epoch=712
05/16/2022 15:38:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.94 on epoch=714
05/16/2022 15:38:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
05/16/2022 15:38:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.02 on epoch=719
05/16/2022 15:38:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.06 on epoch=722
05/16/2022 15:38:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/16/2022 15:38:38 - INFO - __main__ - Global step 2900 Train loss 1.00 Classification-F1 0.1576923076923077 on epoch=724
05/16/2022 15:38:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.97 on epoch=727
05/16/2022 15:38:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.00 on epoch=729
05/16/2022 15:38:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.99 on epoch=732
05/16/2022 15:38:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.03 on epoch=734
05/16/2022 15:38:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.96 on epoch=737
05/16/2022 15:38:46 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.13865730583589295 on epoch=737
05/16/2022 15:38:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/16/2022 15:38:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.99 on epoch=742
05/16/2022 15:38:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/16/2022 15:38:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/16/2022 15:38:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.84 on epoch=749
05/16/2022 15:38:53 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=749
05/16/2022 15:38:53 - INFO - __main__ - save last model!
05/16/2022 15:38:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 15:38:53 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 15:38:53 - INFO - __main__ - Printing 3 examples
05/16/2022 15:38:53 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 15:38:53 - INFO - __main__ - ['others']
05/16/2022 15:38:53 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 15:38:53 - INFO - __main__ - ['others']
05/16/2022 15:38:53 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 15:38:53 - INFO - __main__ - ['others']
05/16/2022 15:38:53 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:38:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:38:54 - INFO - __main__ - Printing 3 examples
05/16/2022 15:38:54 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:38:54 - INFO - __main__ - ['sad']
05/16/2022 15:38:54 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:38:54 - INFO - __main__ - ['sad']
05/16/2022 15:38:54 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:38:54 - INFO - __main__ - ['sad']
05/16/2022 15:38:54 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:38:54 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:38:54 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:38:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:38:54 - INFO - __main__ - Printing 3 examples
05/16/2022 15:38:54 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:38:54 - INFO - __main__ - ['sad']
05/16/2022 15:38:54 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:38:54 - INFO - __main__ - ['sad']
05/16/2022 15:38:54 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:38:54 - INFO - __main__ - ['sad']
05/16/2022 15:38:54 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:38:54 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:38:54 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:38:56 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:39:00 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:39:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:39:01 - INFO - __main__ - Starting training!
05/16/2022 15:39:02 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 15:39:47 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.4_8_predictions.txt
05/16/2022 15:39:47 - INFO - __main__ - Classification-F1 on test data: 0.0337
05/16/2022 15:39:48 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.23446115288220554, test_performance=0.0337088983910494
05/16/2022 15:39:48 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
05/16/2022 15:39:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:39:49 - INFO - __main__ - Printing 3 examples
05/16/2022 15:39:49 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:39:49 - INFO - __main__ - ['sad']
05/16/2022 15:39:49 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:39:49 - INFO - __main__ - ['sad']
05/16/2022 15:39:49 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:39:49 - INFO - __main__ - ['sad']
05/16/2022 15:39:49 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:39:49 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:39:49 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:39:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:39:49 - INFO - __main__ - Printing 3 examples
05/16/2022 15:39:49 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:39:49 - INFO - __main__ - ['sad']
05/16/2022 15:39:49 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:39:49 - INFO - __main__ - ['sad']
05/16/2022 15:39:49 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:39:49 - INFO - __main__ - ['sad']
05/16/2022 15:39:49 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:39:49 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:39:49 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:39:55 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:39:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:39:55 - INFO - __main__ - Starting training!
05/16/2022 15:39:57 - INFO - __main__ - Step 10 Global step 10 Train loss 6.61 on epoch=2
05/16/2022 15:39:58 - INFO - __main__ - Step 20 Global step 20 Train loss 6.48 on epoch=4
05/16/2022 15:40:00 - INFO - __main__ - Step 30 Global step 30 Train loss 6.42 on epoch=7
05/16/2022 15:40:01 - INFO - __main__ - Step 40 Global step 40 Train loss 6.05 on epoch=9
05/16/2022 15:40:02 - INFO - __main__ - Step 50 Global step 50 Train loss 5.98 on epoch=12
05/16/2022 15:40:05 - INFO - __main__ - Global step 50 Train loss 6.31 Classification-F1 0.0 on epoch=12
05/16/2022 15:40:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 15:40:07 - INFO - __main__ - Step 60 Global step 60 Train loss 6.02 on epoch=14
05/16/2022 15:40:08 - INFO - __main__ - Step 70 Global step 70 Train loss 5.82 on epoch=17
05/16/2022 15:40:09 - INFO - __main__ - Step 80 Global step 80 Train loss 5.73 on epoch=19
05/16/2022 15:40:11 - INFO - __main__ - Step 90 Global step 90 Train loss 5.63 on epoch=22
05/16/2022 15:40:12 - INFO - __main__ - Step 100 Global step 100 Train loss 5.56 on epoch=24
05/16/2022 15:40:14 - INFO - __main__ - Global step 100 Train loss 5.75 Classification-F1 0.0 on epoch=24
05/16/2022 15:40:15 - INFO - __main__ - Step 110 Global step 110 Train loss 5.49 on epoch=27
05/16/2022 15:40:17 - INFO - __main__ - Step 120 Global step 120 Train loss 5.30 on epoch=29
05/16/2022 15:40:18 - INFO - __main__ - Step 130 Global step 130 Train loss 5.17 on epoch=32
05/16/2022 15:40:19 - INFO - __main__ - Step 140 Global step 140 Train loss 5.05 on epoch=34
05/16/2022 15:40:21 - INFO - __main__ - Step 150 Global step 150 Train loss 5.09 on epoch=37
05/16/2022 15:40:22 - INFO - __main__ - Global step 150 Train loss 5.22 Classification-F1 0.0 on epoch=37
05/16/2022 15:40:24 - INFO - __main__ - Step 160 Global step 160 Train loss 4.78 on epoch=39
05/16/2022 15:40:25 - INFO - __main__ - Step 170 Global step 170 Train loss 4.75 on epoch=42
05/16/2022 15:40:26 - INFO - __main__ - Step 180 Global step 180 Train loss 4.64 on epoch=44
05/16/2022 15:40:27 - INFO - __main__ - Step 190 Global step 190 Train loss 4.70 on epoch=47
05/16/2022 15:40:29 - INFO - __main__ - Step 200 Global step 200 Train loss 4.39 on epoch=49
05/16/2022 15:40:30 - INFO - __main__ - Global step 200 Train loss 4.65 Classification-F1 0.0 on epoch=49
05/16/2022 15:40:32 - INFO - __main__ - Step 210 Global step 210 Train loss 4.32 on epoch=52
05/16/2022 15:40:33 - INFO - __main__ - Step 220 Global step 220 Train loss 4.16 on epoch=54
05/16/2022 15:40:35 - INFO - __main__ - Step 230 Global step 230 Train loss 4.15 on epoch=57
05/16/2022 15:40:36 - INFO - __main__ - Step 240 Global step 240 Train loss 4.09 on epoch=59
05/16/2022 15:40:37 - INFO - __main__ - Step 250 Global step 250 Train loss 3.98 on epoch=62
05/16/2022 15:40:38 - INFO - __main__ - Global step 250 Train loss 4.14 Classification-F1 0.19408369408369408 on epoch=62
05/16/2022 15:40:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.19408369408369408 on epoch=62, global_step=250
05/16/2022 15:40:39 - INFO - __main__ - Step 260 Global step 260 Train loss 3.87 on epoch=64
05/16/2022 15:40:41 - INFO - __main__ - Step 270 Global step 270 Train loss 3.81 on epoch=67
05/16/2022 15:40:42 - INFO - __main__ - Step 280 Global step 280 Train loss 3.62 on epoch=69
05/16/2022 15:40:43 - INFO - __main__ - Step 290 Global step 290 Train loss 3.67 on epoch=72
05/16/2022 15:40:45 - INFO - __main__ - Step 300 Global step 300 Train loss 3.40 on epoch=74
05/16/2022 15:40:45 - INFO - __main__ - Global step 300 Train loss 3.67 Classification-F1 0.15859154929577468 on epoch=74
05/16/2022 15:40:47 - INFO - __main__ - Step 310 Global step 310 Train loss 3.58 on epoch=77
05/16/2022 15:40:48 - INFO - __main__ - Step 320 Global step 320 Train loss 3.28 on epoch=79
05/16/2022 15:40:49 - INFO - __main__ - Step 330 Global step 330 Train loss 3.37 on epoch=82
05/16/2022 15:40:51 - INFO - __main__ - Step 340 Global step 340 Train loss 3.36 on epoch=84
05/16/2022 15:40:52 - INFO - __main__ - Step 350 Global step 350 Train loss 3.37 on epoch=87
05/16/2022 15:40:53 - INFO - __main__ - Global step 350 Train loss 3.39 Classification-F1 0.20606060606060606 on epoch=87
05/16/2022 15:40:53 - INFO - __main__ - Saving model with best Classification-F1: 0.19408369408369408 -> 0.20606060606060606 on epoch=87, global_step=350
05/16/2022 15:40:54 - INFO - __main__ - Step 360 Global step 360 Train loss 3.14 on epoch=89
05/16/2022 15:40:55 - INFO - __main__ - Step 370 Global step 370 Train loss 3.24 on epoch=92
05/16/2022 15:40:57 - INFO - __main__ - Step 380 Global step 380 Train loss 3.08 on epoch=94
05/16/2022 15:40:58 - INFO - __main__ - Step 390 Global step 390 Train loss 3.07 on epoch=97
05/16/2022 15:40:59 - INFO - __main__ - Step 400 Global step 400 Train loss 2.91 on epoch=99
05/16/2022 15:41:00 - INFO - __main__ - Global step 400 Train loss 3.09 Classification-F1 0.10126582278481013 on epoch=99
05/16/2022 15:41:01 - INFO - __main__ - Step 410 Global step 410 Train loss 3.06 on epoch=102
05/16/2022 15:41:03 - INFO - __main__ - Step 420 Global step 420 Train loss 3.05 on epoch=104
05/16/2022 15:41:04 - INFO - __main__ - Step 430 Global step 430 Train loss 2.94 on epoch=107
05/16/2022 15:41:05 - INFO - __main__ - Step 440 Global step 440 Train loss 2.66 on epoch=109
05/16/2022 15:41:06 - INFO - __main__ - Step 450 Global step 450 Train loss 2.83 on epoch=112
05/16/2022 15:41:07 - INFO - __main__ - Global step 450 Train loss 2.91 Classification-F1 0.12447885646217988 on epoch=112
05/16/2022 15:41:08 - INFO - __main__ - Step 460 Global step 460 Train loss 2.68 on epoch=114
05/16/2022 15:41:10 - INFO - __main__ - Step 470 Global step 470 Train loss 2.75 on epoch=117
05/16/2022 15:41:11 - INFO - __main__ - Step 480 Global step 480 Train loss 2.54 on epoch=119
05/16/2022 15:41:12 - INFO - __main__ - Step 490 Global step 490 Train loss 2.73 on epoch=122
05/16/2022 15:41:14 - INFO - __main__ - Step 500 Global step 500 Train loss 2.51 on epoch=124
05/16/2022 15:41:14 - INFO - __main__ - Global step 500 Train loss 2.64 Classification-F1 0.1 on epoch=124
05/16/2022 15:41:15 - INFO - __main__ - Step 510 Global step 510 Train loss 2.47 on epoch=127
05/16/2022 15:41:17 - INFO - __main__ - Step 520 Global step 520 Train loss 2.57 on epoch=129
05/16/2022 15:41:18 - INFO - __main__ - Step 530 Global step 530 Train loss 2.47 on epoch=132
05/16/2022 15:41:19 - INFO - __main__ - Step 540 Global step 540 Train loss 2.34 on epoch=134
05/16/2022 15:41:21 - INFO - __main__ - Step 550 Global step 550 Train loss 2.45 on epoch=137
05/16/2022 15:41:21 - INFO - __main__ - Global step 550 Train loss 2.46 Classification-F1 0.12368421052631579 on epoch=137
05/16/2022 15:41:23 - INFO - __main__ - Step 560 Global step 560 Train loss 2.28 on epoch=139
05/16/2022 15:41:24 - INFO - __main__ - Step 570 Global step 570 Train loss 2.35 on epoch=142
05/16/2022 15:41:25 - INFO - __main__ - Step 580 Global step 580 Train loss 2.23 on epoch=144
05/16/2022 15:41:27 - INFO - __main__ - Step 590 Global step 590 Train loss 2.30 on epoch=147
05/16/2022 15:41:28 - INFO - __main__ - Step 600 Global step 600 Train loss 2.18 on epoch=149
05/16/2022 15:41:28 - INFO - __main__ - Global step 600 Train loss 2.27 Classification-F1 0.10126582278481013 on epoch=149
05/16/2022 15:41:30 - INFO - __main__ - Step 610 Global step 610 Train loss 2.21 on epoch=152
05/16/2022 15:41:31 - INFO - __main__ - Step 620 Global step 620 Train loss 2.03 on epoch=154
05/16/2022 15:41:32 - INFO - __main__ - Step 630 Global step 630 Train loss 2.17 on epoch=157
05/16/2022 15:41:34 - INFO - __main__ - Step 640 Global step 640 Train loss 1.90 on epoch=159
05/16/2022 15:41:35 - INFO - __main__ - Step 650 Global step 650 Train loss 1.91 on epoch=162
05/16/2022 15:41:35 - INFO - __main__ - Global step 650 Train loss 2.05 Classification-F1 0.1402116402116402 on epoch=162
05/16/2022 15:41:37 - INFO - __main__ - Step 660 Global step 660 Train loss 1.83 on epoch=164
05/16/2022 15:41:38 - INFO - __main__ - Step 670 Global step 670 Train loss 1.91 on epoch=167
05/16/2022 15:41:39 - INFO - __main__ - Step 680 Global step 680 Train loss 1.77 on epoch=169
05/16/2022 15:41:41 - INFO - __main__ - Step 690 Global step 690 Train loss 1.84 on epoch=172
05/16/2022 15:41:42 - INFO - __main__ - Step 700 Global step 700 Train loss 1.77 on epoch=174
05/16/2022 15:41:43 - INFO - __main__ - Global step 700 Train loss 1.82 Classification-F1 0.10126582278481013 on epoch=174
05/16/2022 15:41:44 - INFO - __main__ - Step 710 Global step 710 Train loss 1.65 on epoch=177
05/16/2022 15:41:45 - INFO - __main__ - Step 720 Global step 720 Train loss 1.68 on epoch=179
05/16/2022 15:41:47 - INFO - __main__ - Step 730 Global step 730 Train loss 1.73 on epoch=182
05/16/2022 15:41:48 - INFO - __main__ - Step 740 Global step 740 Train loss 1.72 on epoch=184
05/16/2022 15:41:49 - INFO - __main__ - Step 750 Global step 750 Train loss 1.71 on epoch=187
05/16/2022 15:41:50 - INFO - __main__ - Global step 750 Train loss 1.70 Classification-F1 0.16666666666666666 on epoch=187
05/16/2022 15:41:51 - INFO - __main__ - Step 760 Global step 760 Train loss 1.69 on epoch=189
05/16/2022 15:41:53 - INFO - __main__ - Step 770 Global step 770 Train loss 1.65 on epoch=192
05/16/2022 15:41:54 - INFO - __main__ - Step 780 Global step 780 Train loss 1.70 on epoch=194
05/16/2022 15:41:55 - INFO - __main__ - Step 790 Global step 790 Train loss 1.62 on epoch=197
05/16/2022 15:41:57 - INFO - __main__ - Step 800 Global step 800 Train loss 1.44 on epoch=199
05/16/2022 15:41:57 - INFO - __main__ - Global step 800 Train loss 1.62 Classification-F1 0.17979127134724857 on epoch=199
05/16/2022 15:41:59 - INFO - __main__ - Step 810 Global step 810 Train loss 1.67 on epoch=202
05/16/2022 15:42:00 - INFO - __main__ - Step 820 Global step 820 Train loss 1.53 on epoch=204
05/16/2022 15:42:01 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/16/2022 15:42:03 - INFO - __main__ - Step 840 Global step 840 Train loss 1.41 on epoch=209
05/16/2022 15:42:04 - INFO - __main__ - Step 850 Global step 850 Train loss 1.58 on epoch=212
05/16/2022 15:42:05 - INFO - __main__ - Global step 850 Train loss 1.57 Classification-F1 0.20833333333333334 on epoch=212
05/16/2022 15:42:05 - INFO - __main__ - Saving model with best Classification-F1: 0.20606060606060606 -> 0.20833333333333334 on epoch=212, global_step=850
05/16/2022 15:42:06 - INFO - __main__ - Step 860 Global step 860 Train loss 1.51 on epoch=214
05/16/2022 15:42:07 - INFO - __main__ - Step 870 Global step 870 Train loss 1.54 on epoch=217
05/16/2022 15:42:09 - INFO - __main__ - Step 880 Global step 880 Train loss 1.55 on epoch=219
05/16/2022 15:42:10 - INFO - __main__ - Step 890 Global step 890 Train loss 1.51 on epoch=222
05/16/2022 15:42:11 - INFO - __main__ - Step 900 Global step 900 Train loss 1.40 on epoch=224
05/16/2022 15:42:12 - INFO - __main__ - Global step 900 Train loss 1.50 Classification-F1 0.1 on epoch=224
05/16/2022 15:42:13 - INFO - __main__ - Step 910 Global step 910 Train loss 1.50 on epoch=227
05/16/2022 15:42:15 - INFO - __main__ - Step 920 Global step 920 Train loss 1.46 on epoch=229
05/16/2022 15:42:16 - INFO - __main__ - Step 930 Global step 930 Train loss 1.43 on epoch=232
05/16/2022 15:42:17 - INFO - __main__ - Step 940 Global step 940 Train loss 1.40 on epoch=234
05/16/2022 15:42:19 - INFO - __main__ - Step 950 Global step 950 Train loss 1.42 on epoch=237
05/16/2022 15:42:19 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.16953316953316955 on epoch=237
05/16/2022 15:42:20 - INFO - __main__ - Step 960 Global step 960 Train loss 1.48 on epoch=239
05/16/2022 15:42:22 - INFO - __main__ - Step 970 Global step 970 Train loss 1.27 on epoch=242
05/16/2022 15:42:23 - INFO - __main__ - Step 980 Global step 980 Train loss 1.39 on epoch=244
05/16/2022 15:42:24 - INFO - __main__ - Step 990 Global step 990 Train loss 1.49 on epoch=247
05/16/2022 15:42:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.36 on epoch=249
05/16/2022 15:42:26 - INFO - __main__ - Global step 1000 Train loss 1.40 Classification-F1 0.17809523809523808 on epoch=249
05/16/2022 15:42:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=252
05/16/2022 15:42:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
05/16/2022 15:42:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.39 on epoch=257
05/16/2022 15:42:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.39 on epoch=259
05/16/2022 15:42:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.29 on epoch=262
05/16/2022 15:42:33 - INFO - __main__ - Global step 1050 Train loss 1.37 Classification-F1 0.17752100840336132 on epoch=262
05/16/2022 15:42:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.18 on epoch=264
05/16/2022 15:42:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.51 on epoch=267
05/16/2022 15:42:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/16/2022 15:42:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.39 on epoch=272
05/16/2022 15:42:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.22 on epoch=274
05/16/2022 15:42:39 - INFO - __main__ - Global step 1100 Train loss 1.30 Classification-F1 0.13859154929577466 on epoch=274
05/16/2022 15:42:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.20 on epoch=277
05/16/2022 15:42:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.35 on epoch=279
05/16/2022 15:42:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.24 on epoch=282
05/16/2022 15:42:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=284
05/16/2022 15:42:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.26 on epoch=287
05/16/2022 15:42:46 - INFO - __main__ - Global step 1150 Train loss 1.26 Classification-F1 0.16110780226325194 on epoch=287
05/16/2022 15:42:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.33 on epoch=289
05/16/2022 15:42:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.24 on epoch=292
05/16/2022 15:42:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.14 on epoch=294
05/16/2022 15:42:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.24 on epoch=297
05/16/2022 15:42:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.41 on epoch=299
05/16/2022 15:42:53 - INFO - __main__ - Global step 1200 Train loss 1.27 Classification-F1 0.11208791208791208 on epoch=299
05/16/2022 15:42:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.24 on epoch=302
05/16/2022 15:42:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.21 on epoch=304
05/16/2022 15:42:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.41 on epoch=307
05/16/2022 15:42:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.08 on epoch=309
05/16/2022 15:43:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.33 on epoch=312
05/16/2022 15:43:00 - INFO - __main__ - Global step 1250 Train loss 1.25 Classification-F1 0.13130252100840337 on epoch=312
05/16/2022 15:43:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.29 on epoch=314
05/16/2022 15:43:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=317
05/16/2022 15:43:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.37 on epoch=319
05/16/2022 15:43:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.11 on epoch=322
05/16/2022 15:43:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.09 on epoch=324
05/16/2022 15:43:07 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.14560439560439564 on epoch=324
05/16/2022 15:43:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.11 on epoch=327
05/16/2022 15:43:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.12 on epoch=329
05/16/2022 15:43:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.25 on epoch=332
05/16/2022 15:43:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.31 on epoch=334
05/16/2022 15:43:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.18 on epoch=337
05/16/2022 15:43:14 - INFO - __main__ - Global step 1350 Train loss 1.19 Classification-F1 0.14107142857142857 on epoch=337
05/16/2022 15:43:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/16/2022 15:43:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.13 on epoch=342
05/16/2022 15:43:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.14 on epoch=344
05/16/2022 15:43:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.26 on epoch=347
05/16/2022 15:43:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/16/2022 15:43:21 - INFO - __main__ - Global step 1400 Train loss 1.18 Classification-F1 0.1 on epoch=349
05/16/2022 15:43:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.18 on epoch=352
05/16/2022 15:43:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.19 on epoch=354
05/16/2022 15:43:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.18 on epoch=357
05/16/2022 15:43:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.22 on epoch=359
05/16/2022 15:43:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
05/16/2022 15:43:28 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.1581196581196581 on epoch=362
05/16/2022 15:43:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.08 on epoch=364
05/16/2022 15:43:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.23 on epoch=367
05/16/2022 15:43:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
05/16/2022 15:43:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.18 on epoch=372
05/16/2022 15:43:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.28 on epoch=374
05/16/2022 15:43:35 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=374
05/16/2022 15:43:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.14 on epoch=377
05/16/2022 15:43:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.25 on epoch=379
05/16/2022 15:43:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.21 on epoch=382
05/16/2022 15:43:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.26 on epoch=384
05/16/2022 15:43:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
05/16/2022 15:43:42 - INFO - __main__ - Global step 1550 Train loss 1.22 Classification-F1 0.1318181818181818 on epoch=387
05/16/2022 15:43:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.05 on epoch=389
05/16/2022 15:43:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.25 on epoch=392
05/16/2022 15:43:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.27 on epoch=394
05/16/2022 15:43:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.07 on epoch=397
05/16/2022 15:43:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.22 on epoch=399
05/16/2022 15:43:49 - INFO - __main__ - Global step 1600 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=399
05/16/2022 15:43:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.11 on epoch=402
05/16/2022 15:43:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.05 on epoch=404
05/16/2022 15:43:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.20 on epoch=407
05/16/2022 15:43:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.03 on epoch=409
05/16/2022 15:43:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.13 on epoch=412
05/16/2022 15:43:55 - INFO - __main__ - Global step 1650 Train loss 1.10 Classification-F1 0.1 on epoch=412
05/16/2022 15:43:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.10 on epoch=414
05/16/2022 15:43:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.19 on epoch=417
05/16/2022 15:43:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.12 on epoch=419
05/16/2022 15:44:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.22 on epoch=422
05/16/2022 15:44:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
05/16/2022 15:44:02 - INFO - __main__ - Global step 1700 Train loss 1.16 Classification-F1 0.1 on epoch=424
05/16/2022 15:44:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.06 on epoch=427
05/16/2022 15:44:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.02 on epoch=429
05/16/2022 15:44:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.02 on epoch=432
05/16/2022 15:44:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.13 on epoch=434
05/16/2022 15:44:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.08 on epoch=437
05/16/2022 15:44:09 - INFO - __main__ - Global step 1750 Train loss 1.06 Classification-F1 0.10126582278481013 on epoch=437
05/16/2022 15:44:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.04 on epoch=439
05/16/2022 15:44:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.14 on epoch=442
05/16/2022 15:44:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.31 on epoch=444
05/16/2022 15:44:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.17 on epoch=447
05/16/2022 15:44:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=449
05/16/2022 15:44:16 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.1 on epoch=449
05/16/2022 15:44:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.07 on epoch=452
05/16/2022 15:44:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.06 on epoch=454
05/16/2022 15:44:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.11 on epoch=457
05/16/2022 15:44:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.18 on epoch=459
05/16/2022 15:44:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.00 on epoch=462
05/16/2022 15:44:23 - INFO - __main__ - Global step 1850 Train loss 1.08 Classification-F1 0.1 on epoch=462
05/16/2022 15:44:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.07 on epoch=464
05/16/2022 15:44:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.13 on epoch=467
05/16/2022 15:44:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.04 on epoch=469
05/16/2022 15:44:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
05/16/2022 15:44:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/16/2022 15:44:29 - INFO - __main__ - Global step 1900 Train loss 1.08 Classification-F1 0.203125 on epoch=474
05/16/2022 15:44:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/16/2022 15:44:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.03 on epoch=479
05/16/2022 15:44:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
05/16/2022 15:44:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=484
05/16/2022 15:44:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.09 on epoch=487
05/16/2022 15:44:36 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.18847006651884698 on epoch=487
05/16/2022 15:44:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.07 on epoch=489
05/16/2022 15:44:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/16/2022 15:44:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.03 on epoch=494
05/16/2022 15:44:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.10 on epoch=497
05/16/2022 15:44:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.97 on epoch=499
05/16/2022 15:44:43 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.16433566433566432 on epoch=499
05/16/2022 15:44:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/16/2022 15:44:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.10 on epoch=504
05/16/2022 15:44:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
05/16/2022 15:44:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.97 on epoch=509
05/16/2022 15:44:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.00 on epoch=512
05/16/2022 15:44:50 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.12407862407862408 on epoch=512
05/16/2022 15:44:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
05/16/2022 15:44:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
05/16/2022 15:44:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.03 on epoch=519
05/16/2022 15:44:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
05/16/2022 15:44:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/16/2022 15:44:57 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.18172268907563027 on epoch=524
05/16/2022 15:44:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.09 on epoch=527
05/16/2022 15:45:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.01 on epoch=529
05/16/2022 15:45:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/16/2022 15:45:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.95 on epoch=534
05/16/2022 15:45:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.93 on epoch=537
05/16/2022 15:45:04 - INFO - __main__ - Global step 2150 Train loss 0.99 Classification-F1 0.21596452328159646 on epoch=537
05/16/2022 15:45:04 - INFO - __main__ - Saving model with best Classification-F1: 0.20833333333333334 -> 0.21596452328159646 on epoch=537, global_step=2150
05/16/2022 15:45:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.11 on epoch=539
05/16/2022 15:45:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.14 on epoch=542
05/16/2022 15:45:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/16/2022 15:45:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.11 on epoch=547
05/16/2022 15:45:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.08 on epoch=549
05/16/2022 15:45:11 - INFO - __main__ - Global step 2200 Train loss 1.09 Classification-F1 0.1642512077294686 on epoch=549
05/16/2022 15:45:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.06 on epoch=552
05/16/2022 15:45:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/16/2022 15:45:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.09 on epoch=557
05/16/2022 15:45:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.04 on epoch=559
05/16/2022 15:45:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/16/2022 15:45:18 - INFO - __main__ - Global step 2250 Train loss 1.06 Classification-F1 0.21323866239120476 on epoch=562
05/16/2022 15:45:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.06 on epoch=564
05/16/2022 15:45:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.02 on epoch=567
05/16/2022 15:45:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.06 on epoch=569
05/16/2022 15:45:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.01 on epoch=572
05/16/2022 15:45:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/16/2022 15:45:26 - INFO - __main__ - Global step 2300 Train loss 1.02 Classification-F1 0.11923076923076922 on epoch=574
05/16/2022 15:45:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.03 on epoch=577
05/16/2022 15:45:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
05/16/2022 15:45:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=582
05/16/2022 15:45:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/16/2022 15:45:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=587
05/16/2022 15:45:33 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.15735226752175901 on epoch=587
05/16/2022 15:45:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
05/16/2022 15:45:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.04 on epoch=592
05/16/2022 15:45:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.00 on epoch=594
05/16/2022 15:45:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
05/16/2022 15:45:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/16/2022 15:45:40 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.16608695652173913 on epoch=599
05/16/2022 15:45:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/16/2022 15:45:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.99 on epoch=604
05/16/2022 15:45:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/16/2022 15:45:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
05/16/2022 15:45:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.11 on epoch=612
05/16/2022 15:45:47 - INFO - __main__ - Global step 2450 Train loss 1.04 Classification-F1 0.10256410256410256 on epoch=612
05/16/2022 15:45:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.08 on epoch=614
05/16/2022 15:45:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.05 on epoch=617
05/16/2022 15:45:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/16/2022 15:45:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.02 on epoch=622
05/16/2022 15:45:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.02 on epoch=624
05/16/2022 15:45:54 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=624
05/16/2022 15:45:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.00 on epoch=627
05/16/2022 15:45:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.98 on epoch=629
05/16/2022 15:45:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
05/16/2022 15:46:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.99 on epoch=634
05/16/2022 15:46:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.07 on epoch=637
05/16/2022 15:46:02 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.14947089947089948 on epoch=637
05/16/2022 15:46:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
05/16/2022 15:46:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.96 on epoch=642
05/16/2022 15:46:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/16/2022 15:46:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/16/2022 15:46:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.85 on epoch=649
05/16/2022 15:46:09 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.22916666666666669 on epoch=649
05/16/2022 15:46:09 - INFO - __main__ - Saving model with best Classification-F1: 0.21596452328159646 -> 0.22916666666666669 on epoch=649, global_step=2600
05/16/2022 15:46:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.11 on epoch=652
05/16/2022 15:46:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.95 on epoch=654
05/16/2022 15:46:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
05/16/2022 15:46:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/16/2022 15:46:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.09 on epoch=662
05/16/2022 15:46:16 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.14242424242424243 on epoch=662
05/16/2022 15:46:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.95 on epoch=664
05/16/2022 15:46:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.97 on epoch=667
05/16/2022 15:46:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.92 on epoch=669
05/16/2022 15:46:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.97 on epoch=672
05/16/2022 15:46:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/16/2022 15:46:23 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.1851689337428697 on epoch=674
05/16/2022 15:46:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/16/2022 15:46:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.99 on epoch=679
05/16/2022 15:46:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.92 on epoch=682
05/16/2022 15:46:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
05/16/2022 15:46:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.01 on epoch=687
05/16/2022 15:46:31 - INFO - __main__ - Global step 2750 Train loss 0.97 Classification-F1 0.19869565217391305 on epoch=687
05/16/2022 15:46:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=689
05/16/2022 15:46:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.00 on epoch=692
05/16/2022 15:46:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/16/2022 15:46:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.99 on epoch=697
05/16/2022 15:46:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.98 on epoch=699
05/16/2022 15:46:39 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.2300653594771242 on epoch=699
05/16/2022 15:46:39 - INFO - __main__ - Saving model with best Classification-F1: 0.22916666666666669 -> 0.2300653594771242 on epoch=699, global_step=2800
05/16/2022 15:46:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.88 on epoch=702
05/16/2022 15:46:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
05/16/2022 15:46:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.00 on epoch=707
05/16/2022 15:46:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/16/2022 15:46:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/16/2022 15:46:46 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.140625 on epoch=712
05/16/2022 15:46:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/16/2022 15:46:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.92 on epoch=717
05/16/2022 15:46:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.97 on epoch=719
05/16/2022 15:46:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.03 on epoch=722
05/16/2022 15:46:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.99 on epoch=724
05/16/2022 15:46:53 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.19735128093790708 on epoch=724
05/16/2022 15:46:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.91 on epoch=727
05/16/2022 15:46:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.99 on epoch=729
05/16/2022 15:46:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.05 on epoch=732
05/16/2022 15:46:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
05/16/2022 15:46:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.06 on epoch=737
05/16/2022 15:47:00 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.1056338028169014 on epoch=737
05/16/2022 15:47:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/16/2022 15:47:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/16/2022 15:47:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
05/16/2022 15:47:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.94 on epoch=747
05/16/2022 15:47:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
05/16/2022 15:47:07 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.17344312918167784 on epoch=749
05/16/2022 15:47:07 - INFO - __main__ - save last model!
05/16/2022 15:47:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 15:47:07 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 15:47:07 - INFO - __main__ - Printing 3 examples
05/16/2022 15:47:07 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 15:47:07 - INFO - __main__ - ['others']
05/16/2022 15:47:07 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 15:47:07 - INFO - __main__ - ['others']
05/16/2022 15:47:07 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 15:47:07 - INFO - __main__ - ['others']
05/16/2022 15:47:07 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:47:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:47:07 - INFO - __main__ - Printing 3 examples
05/16/2022 15:47:07 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:47:07 - INFO - __main__ - ['sad']
05/16/2022 15:47:07 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:47:07 - INFO - __main__ - ['sad']
05/16/2022 15:47:07 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:47:07 - INFO - __main__ - ['sad']
05/16/2022 15:47:07 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:47:07 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:47:07 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:47:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:47:07 - INFO - __main__ - Printing 3 examples
05/16/2022 15:47:07 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:47:07 - INFO - __main__ - ['sad']
05/16/2022 15:47:07 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:47:07 - INFO - __main__ - ['sad']
05/16/2022 15:47:07 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:47:07 - INFO - __main__ - ['sad']
05/16/2022 15:47:07 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:47:07 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:47:07 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:47:09 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:47:14 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:47:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:47:14 - INFO - __main__ - Starting training!
05/16/2022 15:47:16 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 15:47:59 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.3_8_predictions.txt
05/16/2022 15:47:59 - INFO - __main__ - Classification-F1 on test data: 0.0488
05/16/2022 15:47:59 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.2300653594771242, test_performance=0.048775773564390404
05/16/2022 15:47:59 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
05/16/2022 15:48:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:48:00 - INFO - __main__ - Printing 3 examples
05/16/2022 15:48:00 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/16/2022 15:48:00 - INFO - __main__ - ['sad']
05/16/2022 15:48:00 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/16/2022 15:48:00 - INFO - __main__ - ['sad']
05/16/2022 15:48:00 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/16/2022 15:48:00 - INFO - __main__ - ['sad']
05/16/2022 15:48:00 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:48:00 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:48:00 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:48:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:48:00 - INFO - __main__ - Printing 3 examples
05/16/2022 15:48:00 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/16/2022 15:48:00 - INFO - __main__ - ['sad']
05/16/2022 15:48:00 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/16/2022 15:48:00 - INFO - __main__ - ['sad']
05/16/2022 15:48:00 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/16/2022 15:48:00 - INFO - __main__ - ['sad']
05/16/2022 15:48:00 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:48:00 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:48:01 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:48:06 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:48:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:48:07 - INFO - __main__ - Starting training!
05/16/2022 15:48:08 - INFO - __main__ - Step 10 Global step 10 Train loss 6.63 on epoch=2
05/16/2022 15:48:09 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/16/2022 15:48:11 - INFO - __main__ - Step 30 Global step 30 Train loss 6.47 on epoch=7
05/16/2022 15:48:12 - INFO - __main__ - Step 40 Global step 40 Train loss 6.37 on epoch=9
05/16/2022 15:48:13 - INFO - __main__ - Step 50 Global step 50 Train loss 6.39 on epoch=12
05/16/2022 15:48:22 - INFO - __main__ - Global step 50 Train loss 6.49 Classification-F1 0.0 on epoch=12
05/16/2022 15:48:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 15:48:23 - INFO - __main__ - Step 60 Global step 60 Train loss 6.23 on epoch=14
05/16/2022 15:48:24 - INFO - __main__ - Step 70 Global step 70 Train loss 6.18 on epoch=17
05/16/2022 15:48:26 - INFO - __main__ - Step 80 Global step 80 Train loss 6.03 on epoch=19
05/16/2022 15:48:27 - INFO - __main__ - Step 90 Global step 90 Train loss 5.92 on epoch=22
05/16/2022 15:48:28 - INFO - __main__ - Step 100 Global step 100 Train loss 5.77 on epoch=24
05/16/2022 15:48:32 - INFO - __main__ - Global step 100 Train loss 6.03 Classification-F1 0.0 on epoch=24
05/16/2022 15:48:33 - INFO - __main__ - Step 110 Global step 110 Train loss 5.71 on epoch=27
05/16/2022 15:48:34 - INFO - __main__ - Step 120 Global step 120 Train loss 5.59 on epoch=29
05/16/2022 15:48:35 - INFO - __main__ - Step 130 Global step 130 Train loss 5.60 on epoch=32
05/16/2022 15:48:37 - INFO - __main__ - Step 140 Global step 140 Train loss 5.30 on epoch=34
05/16/2022 15:48:38 - INFO - __main__ - Step 150 Global step 150 Train loss 5.41 on epoch=37
05/16/2022 15:48:41 - INFO - __main__ - Global step 150 Train loss 5.52 Classification-F1 0.0 on epoch=37
05/16/2022 15:48:42 - INFO - __main__ - Step 160 Global step 160 Train loss 5.11 on epoch=39
05/16/2022 15:48:43 - INFO - __main__ - Step 170 Global step 170 Train loss 5.18 on epoch=42
05/16/2022 15:48:45 - INFO - __main__ - Step 180 Global step 180 Train loss 4.92 on epoch=44
05/16/2022 15:48:46 - INFO - __main__ - Step 190 Global step 190 Train loss 4.86 on epoch=47
05/16/2022 15:48:47 - INFO - __main__ - Step 200 Global step 200 Train loss 4.88 on epoch=49
05/16/2022 15:48:49 - INFO - __main__ - Global step 200 Train loss 4.99 Classification-F1 0.0 on epoch=49
05/16/2022 15:48:50 - INFO - __main__ - Step 210 Global step 210 Train loss 4.57 on epoch=52
05/16/2022 15:48:52 - INFO - __main__ - Step 220 Global step 220 Train loss 4.41 on epoch=54
05/16/2022 15:48:53 - INFO - __main__ - Step 230 Global step 230 Train loss 4.41 on epoch=57
05/16/2022 15:48:54 - INFO - __main__ - Step 240 Global step 240 Train loss 4.40 on epoch=59
05/16/2022 15:48:56 - INFO - __main__ - Step 250 Global step 250 Train loss 4.29 on epoch=62
05/16/2022 15:48:57 - INFO - __main__ - Global step 250 Train loss 4.41 Classification-F1 0.10126582278481013 on epoch=62
05/16/2022 15:48:57 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.10126582278481013 on epoch=62, global_step=250
05/16/2022 15:48:58 - INFO - __main__ - Step 260 Global step 260 Train loss 4.02 on epoch=64
05/16/2022 15:49:00 - INFO - __main__ - Step 270 Global step 270 Train loss 4.14 on epoch=67
05/16/2022 15:49:01 - INFO - __main__ - Step 280 Global step 280 Train loss 3.83 on epoch=69
05/16/2022 15:49:02 - INFO - __main__ - Step 290 Global step 290 Train loss 3.90 on epoch=72
05/16/2022 15:49:04 - INFO - __main__ - Step 300 Global step 300 Train loss 3.79 on epoch=74
05/16/2022 15:49:04 - INFO - __main__ - Global step 300 Train loss 3.94 Classification-F1 0.11710526315789474 on epoch=74
05/16/2022 15:49:04 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.11710526315789474 on epoch=74, global_step=300
05/16/2022 15:49:06 - INFO - __main__ - Step 310 Global step 310 Train loss 3.87 on epoch=77
05/16/2022 15:49:07 - INFO - __main__ - Step 320 Global step 320 Train loss 3.65 on epoch=79
05/16/2022 15:49:09 - INFO - __main__ - Step 330 Global step 330 Train loss 3.66 on epoch=82
05/16/2022 15:49:10 - INFO - __main__ - Step 340 Global step 340 Train loss 3.60 on epoch=84
05/16/2022 15:49:11 - INFO - __main__ - Step 350 Global step 350 Train loss 3.44 on epoch=87
05/16/2022 15:49:12 - INFO - __main__ - Global step 350 Train loss 3.64 Classification-F1 0.16277641277641278 on epoch=87
05/16/2022 15:49:12 - INFO - __main__ - Saving model with best Classification-F1: 0.11710526315789474 -> 0.16277641277641278 on epoch=87, global_step=350
05/16/2022 15:49:14 - INFO - __main__ - Step 360 Global step 360 Train loss 3.42 on epoch=89
05/16/2022 15:49:15 - INFO - __main__ - Step 370 Global step 370 Train loss 3.49 on epoch=92
05/16/2022 15:49:16 - INFO - __main__ - Step 380 Global step 380 Train loss 3.31 on epoch=94
05/16/2022 15:49:18 - INFO - __main__ - Step 390 Global step 390 Train loss 3.42 on epoch=97
05/16/2022 15:49:19 - INFO - __main__ - Step 400 Global step 400 Train loss 3.17 on epoch=99
05/16/2022 15:49:20 - INFO - __main__ - Global step 400 Train loss 3.36 Classification-F1 0.15498891352549887 on epoch=99
05/16/2022 15:49:21 - INFO - __main__ - Step 410 Global step 410 Train loss 3.33 on epoch=102
05/16/2022 15:49:22 - INFO - __main__ - Step 420 Global step 420 Train loss 3.19 on epoch=104
05/16/2022 15:49:24 - INFO - __main__ - Step 430 Global step 430 Train loss 3.25 on epoch=107
05/16/2022 15:49:25 - INFO - __main__ - Step 440 Global step 440 Train loss 3.13 on epoch=109
05/16/2022 15:49:26 - INFO - __main__ - Step 450 Global step 450 Train loss 3.04 on epoch=112
05/16/2022 15:49:27 - INFO - __main__ - Global step 450 Train loss 3.19 Classification-F1 0.1 on epoch=112
05/16/2022 15:49:28 - INFO - __main__ - Step 460 Global step 460 Train loss 2.99 on epoch=114
05/16/2022 15:49:29 - INFO - __main__ - Step 470 Global step 470 Train loss 3.13 on epoch=117
05/16/2022 15:49:31 - INFO - __main__ - Step 480 Global step 480 Train loss 2.92 on epoch=119
05/16/2022 15:49:32 - INFO - __main__ - Step 490 Global step 490 Train loss 3.01 on epoch=122
05/16/2022 15:49:34 - INFO - __main__ - Step 500 Global step 500 Train loss 2.85 on epoch=124
05/16/2022 15:49:34 - INFO - __main__ - Global step 500 Train loss 2.98 Classification-F1 0.10126582278481013 on epoch=124
05/16/2022 15:49:35 - INFO - __main__ - Step 510 Global step 510 Train loss 2.89 on epoch=127
05/16/2022 15:49:37 - INFO - __main__ - Step 520 Global step 520 Train loss 2.62 on epoch=129
05/16/2022 15:49:38 - INFO - __main__ - Step 530 Global step 530 Train loss 2.80 on epoch=132
05/16/2022 15:49:39 - INFO - __main__ - Step 540 Global step 540 Train loss 2.81 on epoch=134
05/16/2022 15:49:41 - INFO - __main__ - Step 550 Global step 550 Train loss 2.61 on epoch=137
05/16/2022 15:49:41 - INFO - __main__ - Global step 550 Train loss 2.75 Classification-F1 0.1 on epoch=137
05/16/2022 15:49:43 - INFO - __main__ - Step 560 Global step 560 Train loss 2.60 on epoch=139
05/16/2022 15:49:44 - INFO - __main__ - Step 570 Global step 570 Train loss 2.73 on epoch=142
05/16/2022 15:49:45 - INFO - __main__ - Step 580 Global step 580 Train loss 2.42 on epoch=144
05/16/2022 15:49:47 - INFO - __main__ - Step 590 Global step 590 Train loss 2.67 on epoch=147
05/16/2022 15:49:48 - INFO - __main__ - Step 600 Global step 600 Train loss 2.49 on epoch=149
05/16/2022 15:49:49 - INFO - __main__ - Global step 600 Train loss 2.58 Classification-F1 0.1 on epoch=149
05/16/2022 15:49:50 - INFO - __main__ - Step 610 Global step 610 Train loss 2.47 on epoch=152
05/16/2022 15:49:52 - INFO - __main__ - Step 620 Global step 620 Train loss 2.51 on epoch=154
05/16/2022 15:49:53 - INFO - __main__ - Step 630 Global step 630 Train loss 2.62 on epoch=157
05/16/2022 15:49:55 - INFO - __main__ - Step 640 Global step 640 Train loss 2.37 on epoch=159
05/16/2022 15:49:56 - INFO - __main__ - Step 650 Global step 650 Train loss 2.42 on epoch=162
05/16/2022 15:49:57 - INFO - __main__ - Global step 650 Train loss 2.48 Classification-F1 0.09493670886075949 on epoch=162
05/16/2022 15:49:58 - INFO - __main__ - Step 660 Global step 660 Train loss 2.38 on epoch=164
05/16/2022 15:49:59 - INFO - __main__ - Step 670 Global step 670 Train loss 2.42 on epoch=167
05/16/2022 15:50:01 - INFO - __main__ - Step 680 Global step 680 Train loss 2.33 on epoch=169
05/16/2022 15:50:02 - INFO - __main__ - Step 690 Global step 690 Train loss 2.39 on epoch=172
05/16/2022 15:50:03 - INFO - __main__ - Step 700 Global step 700 Train loss 2.19 on epoch=174
05/16/2022 15:50:04 - INFO - __main__ - Global step 700 Train loss 2.34 Classification-F1 0.10126582278481013 on epoch=174
05/16/2022 15:50:05 - INFO - __main__ - Step 710 Global step 710 Train loss 2.30 on epoch=177
05/16/2022 15:50:06 - INFO - __main__ - Step 720 Global step 720 Train loss 2.07 on epoch=179
05/16/2022 15:50:08 - INFO - __main__ - Step 730 Global step 730 Train loss 2.34 on epoch=182
05/16/2022 15:50:09 - INFO - __main__ - Step 740 Global step 740 Train loss 2.20 on epoch=184
05/16/2022 15:50:10 - INFO - __main__ - Step 750 Global step 750 Train loss 2.29 on epoch=187
05/16/2022 15:50:11 - INFO - __main__ - Global step 750 Train loss 2.24 Classification-F1 0.11078022632519356 on epoch=187
05/16/2022 15:50:12 - INFO - __main__ - Step 760 Global step 760 Train loss 2.04 on epoch=189
05/16/2022 15:50:14 - INFO - __main__ - Step 770 Global step 770 Train loss 2.31 on epoch=192
05/16/2022 15:50:15 - INFO - __main__ - Step 780 Global step 780 Train loss 1.99 on epoch=194
05/16/2022 15:50:16 - INFO - __main__ - Step 790 Global step 790 Train loss 2.14 on epoch=197
05/16/2022 15:50:18 - INFO - __main__ - Step 800 Global step 800 Train loss 1.93 on epoch=199
05/16/2022 15:50:19 - INFO - __main__ - Global step 800 Train loss 2.08 Classification-F1 0.13123993558776167 on epoch=199
05/16/2022 15:50:20 - INFO - __main__ - Step 810 Global step 810 Train loss 1.98 on epoch=202
05/16/2022 15:50:21 - INFO - __main__ - Step 820 Global step 820 Train loss 2.02 on epoch=204
05/16/2022 15:50:23 - INFO - __main__ - Step 830 Global step 830 Train loss 2.06 on epoch=207
05/16/2022 15:50:24 - INFO - __main__ - Step 840 Global step 840 Train loss 1.93 on epoch=209
05/16/2022 15:50:25 - INFO - __main__ - Step 850 Global step 850 Train loss 1.86 on epoch=212
05/16/2022 15:50:26 - INFO - __main__ - Global step 850 Train loss 1.97 Classification-F1 0.08440555841482245 on epoch=212
05/16/2022 15:50:27 - INFO - __main__ - Step 860 Global step 860 Train loss 1.94 on epoch=214
05/16/2022 15:50:28 - INFO - __main__ - Step 870 Global step 870 Train loss 1.90 on epoch=217
05/16/2022 15:50:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.93 on epoch=219
05/16/2022 15:50:31 - INFO - __main__ - Step 890 Global step 890 Train loss 2.00 on epoch=222
05/16/2022 15:50:33 - INFO - __main__ - Step 900 Global step 900 Train loss 1.96 on epoch=224
05/16/2022 15:50:33 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.09210526315789473 on epoch=224
05/16/2022 15:50:35 - INFO - __main__ - Step 910 Global step 910 Train loss 1.94 on epoch=227
05/16/2022 15:50:36 - INFO - __main__ - Step 920 Global step 920 Train loss 1.82 on epoch=229
05/16/2022 15:50:37 - INFO - __main__ - Step 930 Global step 930 Train loss 1.80 on epoch=232
05/16/2022 15:50:38 - INFO - __main__ - Step 940 Global step 940 Train loss 1.77 on epoch=234
05/16/2022 15:50:40 - INFO - __main__ - Step 950 Global step 950 Train loss 1.92 on epoch=237
05/16/2022 15:50:40 - INFO - __main__ - Global step 950 Train loss 1.85 Classification-F1 0.11607142857142856 on epoch=237
05/16/2022 15:50:42 - INFO - __main__ - Step 960 Global step 960 Train loss 1.80 on epoch=239
05/16/2022 15:50:43 - INFO - __main__ - Step 970 Global step 970 Train loss 1.71 on epoch=242
05/16/2022 15:50:44 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
05/16/2022 15:50:46 - INFO - __main__ - Step 990 Global step 990 Train loss 1.84 on epoch=247
05/16/2022 15:50:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.70 on epoch=249
05/16/2022 15:50:48 - INFO - __main__ - Global step 1000 Train loss 1.75 Classification-F1 0.10969141755062681 on epoch=249
05/16/2022 15:50:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.69 on epoch=252
05/16/2022 15:50:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.71 on epoch=254
05/16/2022 15:50:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.76 on epoch=257
05/16/2022 15:50:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.63 on epoch=259
05/16/2022 15:50:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.73 on epoch=262
05/16/2022 15:50:55 - INFO - __main__ - Global step 1050 Train loss 1.70 Classification-F1 0.15535714285714286 on epoch=262
05/16/2022 15:50:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.68 on epoch=264
05/16/2022 15:50:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.65 on epoch=267
05/16/2022 15:50:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.49 on epoch=269
05/16/2022 15:51:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.64 on epoch=272
05/16/2022 15:51:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.52 on epoch=274
05/16/2022 15:51:02 - INFO - __main__ - Global step 1100 Train loss 1.60 Classification-F1 0.09822866344605476 on epoch=274
05/16/2022 15:51:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.67 on epoch=277
05/16/2022 15:51:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.57 on epoch=279
05/16/2022 15:51:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.79 on epoch=282
05/16/2022 15:51:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.57 on epoch=284
05/16/2022 15:51:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.53 on epoch=287
05/16/2022 15:51:09 - INFO - __main__ - Global step 1150 Train loss 1.63 Classification-F1 0.09615384615384615 on epoch=287
05/16/2022 15:51:11 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.62 on epoch=289
05/16/2022 15:51:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.61 on epoch=292
05/16/2022 15:51:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.32 on epoch=294
05/16/2022 15:51:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.53 on epoch=297
05/16/2022 15:51:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.57 on epoch=299
05/16/2022 15:51:17 - INFO - __main__ - Global step 1200 Train loss 1.53 Classification-F1 0.12819829424307036 on epoch=299
05/16/2022 15:51:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.45 on epoch=302
05/16/2022 15:51:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.43 on epoch=304
05/16/2022 15:51:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.41 on epoch=307
05/16/2022 15:51:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.45 on epoch=309
05/16/2022 15:51:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.44 on epoch=312
05/16/2022 15:51:24 - INFO - __main__ - Global step 1250 Train loss 1.43 Classification-F1 0.14222873900293254 on epoch=312
05/16/2022 15:51:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.28 on epoch=314
05/16/2022 15:51:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.45 on epoch=317
05/16/2022 15:51:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.34 on epoch=319
05/16/2022 15:51:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.39 on epoch=322
05/16/2022 15:51:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.35 on epoch=324
05/16/2022 15:51:31 - INFO - __main__ - Global step 1300 Train loss 1.36 Classification-F1 0.08904109589041095 on epoch=324
05/16/2022 15:51:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.42 on epoch=327
05/16/2022 15:51:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.37 on epoch=329
05/16/2022 15:51:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.41 on epoch=332
05/16/2022 15:51:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.43 on epoch=334
05/16/2022 15:51:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.28 on epoch=337
05/16/2022 15:51:39 - INFO - __main__ - Global step 1350 Train loss 1.38 Classification-F1 0.1468058968058968 on epoch=337
05/16/2022 15:51:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.27 on epoch=339
05/16/2022 15:51:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.32 on epoch=342
05/16/2022 15:51:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.31 on epoch=344
05/16/2022 15:51:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.33 on epoch=347
05/16/2022 15:51:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
05/16/2022 15:51:46 - INFO - __main__ - Global step 1400 Train loss 1.29 Classification-F1 0.1406926406926407 on epoch=349
05/16/2022 15:51:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/16/2022 15:51:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.33 on epoch=354
05/16/2022 15:51:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.28 on epoch=357
05/16/2022 15:51:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.36 on epoch=359
05/16/2022 15:51:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.30 on epoch=362
05/16/2022 15:51:53 - INFO - __main__ - Global step 1450 Train loss 1.30 Classification-F1 0.08783783783783784 on epoch=362
05/16/2022 15:51:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.29 on epoch=364
05/16/2022 15:51:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.29 on epoch=367
05/16/2022 15:51:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.16 on epoch=369
05/16/2022 15:51:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/16/2022 15:52:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=374
05/16/2022 15:52:00 - INFO - __main__ - Global step 1500 Train loss 1.24 Classification-F1 0.08904109589041095 on epoch=374
05/16/2022 15:52:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.14 on epoch=377
05/16/2022 15:52:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.28 on epoch=379
05/16/2022 15:52:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.35 on epoch=382
05/16/2022 15:52:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.21 on epoch=384
05/16/2022 15:52:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
05/16/2022 15:52:08 - INFO - __main__ - Global step 1550 Train loss 1.24 Classification-F1 0.10389610389610389 on epoch=387
05/16/2022 15:52:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.21 on epoch=389
05/16/2022 15:52:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=392
05/16/2022 15:52:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
05/16/2022 15:52:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.15 on epoch=397
05/16/2022 15:52:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.26 on epoch=399
05/16/2022 15:52:15 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.1487390633041688 on epoch=399
05/16/2022 15:52:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
05/16/2022 15:52:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.19 on epoch=404
05/16/2022 15:52:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.25 on epoch=407
05/16/2022 15:52:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.20 on epoch=409
05/16/2022 15:52:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.15 on epoch=412
05/16/2022 15:52:22 - INFO - __main__ - Global step 1650 Train loss 1.18 Classification-F1 0.1 on epoch=412
05/16/2022 15:52:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.20 on epoch=414
05/16/2022 15:52:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
05/16/2022 15:52:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.99 on epoch=419
05/16/2022 15:52:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.26 on epoch=422
05/16/2022 15:52:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.18 on epoch=424
05/16/2022 15:52:30 - INFO - __main__ - Global step 1700 Train loss 1.17 Classification-F1 0.1785345717234262 on epoch=424
05/16/2022 15:52:30 - INFO - __main__ - Saving model with best Classification-F1: 0.16277641277641278 -> 0.1785345717234262 on epoch=424, global_step=1700
05/16/2022 15:52:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.18 on epoch=427
05/16/2022 15:52:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.07 on epoch=429
05/16/2022 15:52:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.24 on epoch=432
05/16/2022 15:52:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.10 on epoch=434
05/16/2022 15:52:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.12 on epoch=437
05/16/2022 15:52:39 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.13430127041742287 on epoch=437
05/16/2022 15:52:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.23 on epoch=439
05/16/2022 15:52:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.18 on epoch=442
05/16/2022 15:52:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.18 on epoch=444
05/16/2022 15:52:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.19 on epoch=447
05/16/2022 15:52:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/16/2022 15:52:47 - INFO - __main__ - Global step 1800 Train loss 1.18 Classification-F1 0.13482414242292662 on epoch=449
05/16/2022 15:52:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.28 on epoch=452
05/16/2022 15:52:50 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/16/2022 15:52:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.22 on epoch=457
05/16/2022 15:52:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.22 on epoch=459
05/16/2022 15:52:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.18 on epoch=462
05/16/2022 15:52:55 - INFO - __main__ - Global step 1850 Train loss 1.21 Classification-F1 0.11616161616161616 on epoch=462
05/16/2022 15:52:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.06 on epoch=464
05/16/2022 15:52:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.26 on epoch=467
05/16/2022 15:52:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
05/16/2022 15:53:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.01 on epoch=472
05/16/2022 15:53:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/16/2022 15:53:02 - INFO - __main__ - Global step 1900 Train loss 1.14 Classification-F1 0.09999999999999999 on epoch=474
05/16/2022 15:53:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.14 on epoch=477
05/16/2022 15:53:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.00 on epoch=479
05/16/2022 15:53:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
05/16/2022 15:53:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.18 on epoch=484
05/16/2022 15:53:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.16 on epoch=487
05/16/2022 15:53:09 - INFO - __main__ - Global step 1950 Train loss 1.12 Classification-F1 0.18847006651884698 on epoch=487
05/16/2022 15:53:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1785345717234262 -> 0.18847006651884698 on epoch=487, global_step=1950
05/16/2022 15:53:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.08 on epoch=489
05/16/2022 15:53:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.17 on epoch=492
05/16/2022 15:53:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.10 on epoch=494
05/16/2022 15:53:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.18 on epoch=497
05/16/2022 15:53:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.01 on epoch=499
05/16/2022 15:53:17 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.1769449715370019 on epoch=499
05/16/2022 15:53:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.20 on epoch=502
05/16/2022 15:53:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.22 on epoch=504
05/16/2022 15:53:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.10 on epoch=507
05/16/2022 15:53:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.06 on epoch=509
05/16/2022 15:53:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.22 on epoch=512
05/16/2022 15:53:24 - INFO - __main__ - Global step 2050 Train loss 1.16 Classification-F1 0.21964285714285714 on epoch=512
05/16/2022 15:53:24 - INFO - __main__ - Saving model with best Classification-F1: 0.18847006651884698 -> 0.21964285714285714 on epoch=512, global_step=2050
05/16/2022 15:53:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.01 on epoch=514
05/16/2022 15:53:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.21 on epoch=517
05/16/2022 15:53:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.15 on epoch=519
05/16/2022 15:53:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
05/16/2022 15:53:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.14 on epoch=524
05/16/2022 15:53:31 - INFO - __main__ - Global step 2100 Train loss 1.12 Classification-F1 0.1 on epoch=524
05/16/2022 15:53:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.09 on epoch=527
05/16/2022 15:53:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.18 on epoch=529
05/16/2022 15:53:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.11 on epoch=532
05/16/2022 15:53:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.08 on epoch=534
05/16/2022 15:53:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.17 on epoch=537
05/16/2022 15:53:39 - INFO - __main__ - Global step 2150 Train loss 1.12 Classification-F1 0.1 on epoch=537
05/16/2022 15:53:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.14 on epoch=539
05/16/2022 15:53:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=542
05/16/2022 15:53:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.11 on epoch=544
05/16/2022 15:53:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.06 on epoch=547
05/16/2022 15:53:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.11 on epoch=549
05/16/2022 15:53:46 - INFO - __main__ - Global step 2200 Train loss 1.11 Classification-F1 0.18172268907563027 on epoch=549
05/16/2022 15:53:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/16/2022 15:53:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.08 on epoch=554
05/16/2022 15:53:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.10 on epoch=557
05/16/2022 15:53:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/16/2022 15:53:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.03 on epoch=562
05/16/2022 15:53:54 - INFO - __main__ - Global step 2250 Train loss 1.05 Classification-F1 0.11859154929577466 on epoch=562
05/16/2022 15:53:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/16/2022 15:53:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=567
05/16/2022 15:53:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.14 on epoch=569
05/16/2022 15:53:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.10 on epoch=572
05/16/2022 15:54:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.02 on epoch=574
05/16/2022 15:54:01 - INFO - __main__ - Global step 2300 Train loss 1.08 Classification-F1 0.16563380281690143 on epoch=574
05/16/2022 15:54:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/16/2022 15:54:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.00 on epoch=579
05/16/2022 15:54:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/16/2022 15:54:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.07 on epoch=584
05/16/2022 15:54:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=587
05/16/2022 15:54:09 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.18055555555555552 on epoch=587
05/16/2022 15:54:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.06 on epoch=589
05/16/2022 15:54:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.07 on epoch=592
05/16/2022 15:54:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.99 on epoch=594
05/16/2022 15:54:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
05/16/2022 15:54:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=599
05/16/2022 15:54:16 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.19807311222361285 on epoch=599
05/16/2022 15:54:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.04 on epoch=602
05/16/2022 15:54:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/16/2022 15:54:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.05 on epoch=607
05/16/2022 15:54:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
05/16/2022 15:54:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.94 on epoch=612
05/16/2022 15:54:23 - INFO - __main__ - Global step 2450 Train loss 0.99 Classification-F1 0.18783068783068785 on epoch=612
05/16/2022 15:54:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.08 on epoch=614
05/16/2022 15:54:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=617
05/16/2022 15:54:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
05/16/2022 15:54:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.09 on epoch=622
05/16/2022 15:54:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
05/16/2022 15:54:30 - INFO - __main__ - Global step 2500 Train loss 1.06 Classification-F1 0.109375 on epoch=624
05/16/2022 15:54:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.05 on epoch=627
05/16/2022 15:54:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.97 on epoch=629
05/16/2022 15:54:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
05/16/2022 15:54:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.01 on epoch=634
05/16/2022 15:54:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/16/2022 15:54:38 - INFO - __main__ - Global step 2550 Train loss 1.02 Classification-F1 0.1527777777777778 on epoch=637
05/16/2022 15:54:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.10 on epoch=639
05/16/2022 15:54:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.02 on epoch=642
05/16/2022 15:54:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.04 on epoch=644
05/16/2022 15:54:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/16/2022 15:54:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.10 on epoch=649
05/16/2022 15:54:45 - INFO - __main__ - Global step 2600 Train loss 1.06 Classification-F1 0.19836065573770492 on epoch=649
05/16/2022 15:54:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.13 on epoch=652
05/16/2022 15:54:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.15 on epoch=654
05/16/2022 15:54:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
05/16/2022 15:54:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/16/2022 15:54:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.07 on epoch=662
05/16/2022 15:54:52 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.13067758749069247 on epoch=662
05/16/2022 15:54:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.00 on epoch=664
05/16/2022 15:54:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.05 on epoch=667
05/16/2022 15:54:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.03 on epoch=669
05/16/2022 15:54:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.14 on epoch=672
05/16/2022 15:54:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.03 on epoch=674
05/16/2022 15:55:00 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.1 on epoch=674
05/16/2022 15:55:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.13 on epoch=677
05/16/2022 15:55:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.00 on epoch=679
05/16/2022 15:55:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.87 on epoch=682
05/16/2022 15:55:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/16/2022 15:55:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.05 on epoch=687
05/16/2022 15:55:07 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=687
05/16/2022 15:55:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.11 on epoch=689
05/16/2022 15:55:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.04 on epoch=692
05/16/2022 15:55:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/16/2022 15:55:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.02 on epoch=697
05/16/2022 15:55:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.02 on epoch=699
05/16/2022 15:55:15 - INFO - __main__ - Global step 2800 Train loss 1.02 Classification-F1 0.22478991596638653 on epoch=699
05/16/2022 15:55:15 - INFO - __main__ - Saving model with best Classification-F1: 0.21964285714285714 -> 0.22478991596638653 on epoch=699, global_step=2800
05/16/2022 15:55:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.08 on epoch=702
05/16/2022 15:55:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.19 on epoch=704
05/16/2022 15:55:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.08 on epoch=707
05/16/2022 15:55:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/16/2022 15:55:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
05/16/2022 15:55:22 - INFO - __main__ - Global step 2850 Train loss 1.09 Classification-F1 0.1 on epoch=712
05/16/2022 15:55:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.89 on epoch=714
05/16/2022 15:55:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.02 on epoch=717
05/16/2022 15:55:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/16/2022 15:55:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.00 on epoch=722
05/16/2022 15:55:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/16/2022 15:55:29 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.11065943992773261 on epoch=724
05/16/2022 15:55:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.09 on epoch=727
05/16/2022 15:55:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.95 on epoch=729
05/16/2022 15:55:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.97 on epoch=732
05/16/2022 15:55:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
05/16/2022 15:55:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.88 on epoch=737
05/16/2022 15:55:37 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.19310511089681776 on epoch=737
05/16/2022 15:55:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.92 on epoch=739
05/16/2022 15:55:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.03 on epoch=742
05/16/2022 15:55:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.00 on epoch=744
05/16/2022 15:55:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/16/2022 15:55:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.04 on epoch=749
05/16/2022 15:55:44 - INFO - __main__ - Global step 3000 Train loss 1.00 Classification-F1 0.1488095238095238 on epoch=749
05/16/2022 15:55:44 - INFO - __main__ - save last model!
05/16/2022 15:55:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 15:55:44 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 15:55:44 - INFO - __main__ - Printing 3 examples
05/16/2022 15:55:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 15:55:44 - INFO - __main__ - ['others']
05/16/2022 15:55:44 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 15:55:44 - INFO - __main__ - ['others']
05/16/2022 15:55:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 15:55:44 - INFO - __main__ - ['others']
05/16/2022 15:55:44 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:55:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:55:45 - INFO - __main__ - Printing 3 examples
05/16/2022 15:55:45 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 15:55:45 - INFO - __main__ - ['happy']
05/16/2022 15:55:45 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 15:55:45 - INFO - __main__ - ['happy']
05/16/2022 15:55:45 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 15:55:45 - INFO - __main__ - ['happy']
05/16/2022 15:55:45 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:55:45 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:55:45 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:55:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:55:45 - INFO - __main__ - Printing 3 examples
05/16/2022 15:55:45 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 15:55:45 - INFO - __main__ - ['happy']
05/16/2022 15:55:45 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 15:55:45 - INFO - __main__ - ['happy']
05/16/2022 15:55:45 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 15:55:45 - INFO - __main__ - ['happy']
05/16/2022 15:55:45 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:55:45 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:55:45 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:55:47 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:55:51 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:55:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:55:51 - INFO - __main__ - Starting training!
05/16/2022 15:55:53 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 15:56:37 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.2_8_predictions.txt
05/16/2022 15:56:38 - INFO - __main__ - Classification-F1 on test data: 0.0428
05/16/2022 15:56:38 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.22478991596638653, test_performance=0.0428240268843188
05/16/2022 15:56:38 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
05/16/2022 15:56:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:56:39 - INFO - __main__ - Printing 3 examples
05/16/2022 15:56:39 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 15:56:39 - INFO - __main__ - ['happy']
05/16/2022 15:56:39 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 15:56:39 - INFO - __main__ - ['happy']
05/16/2022 15:56:39 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 15:56:39 - INFO - __main__ - ['happy']
05/16/2022 15:56:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:56:39 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:56:39 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 15:56:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 15:56:39 - INFO - __main__ - Printing 3 examples
05/16/2022 15:56:39 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 15:56:39 - INFO - __main__ - ['happy']
05/16/2022 15:56:39 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 15:56:39 - INFO - __main__ - ['happy']
05/16/2022 15:56:39 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 15:56:39 - INFO - __main__ - ['happy']
05/16/2022 15:56:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 15:56:39 - INFO - __main__ - Tokenizing Output ...
05/16/2022 15:56:39 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 15:56:44 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 15:56:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 15:56:45 - INFO - __main__ - Starting training!
05/16/2022 15:56:47 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=2
05/16/2022 15:56:48 - INFO - __main__ - Step 20 Global step 20 Train loss 6.48 on epoch=4
05/16/2022 15:56:50 - INFO - __main__ - Step 30 Global step 30 Train loss 6.08 on epoch=7
05/16/2022 15:56:51 - INFO - __main__ - Step 40 Global step 40 Train loss 5.84 on epoch=9
05/16/2022 15:56:53 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=12
05/16/2022 15:56:57 - INFO - __main__ - Global step 50 Train loss 6.13 Classification-F1 0.0 on epoch=12
05/16/2022 15:56:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 15:56:59 - INFO - __main__ - Step 60 Global step 60 Train loss 5.38 on epoch=14
05/16/2022 15:57:00 - INFO - __main__ - Step 70 Global step 70 Train loss 5.24 on epoch=17
05/16/2022 15:57:02 - INFO - __main__ - Step 80 Global step 80 Train loss 5.02 on epoch=19
05/16/2022 15:57:03 - INFO - __main__ - Step 90 Global step 90 Train loss 4.63 on epoch=22
05/16/2022 15:57:05 - INFO - __main__ - Step 100 Global step 100 Train loss 4.76 on epoch=24
05/16/2022 15:57:06 - INFO - __main__ - Global step 100 Train loss 5.01 Classification-F1 0.03240740740740741 on epoch=24
05/16/2022 15:57:06 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03240740740740741 on epoch=24, global_step=100
05/16/2022 15:57:07 - INFO - __main__ - Step 110 Global step 110 Train loss 4.42 on epoch=27
05/16/2022 15:57:09 - INFO - __main__ - Step 120 Global step 120 Train loss 4.43 on epoch=29
05/16/2022 15:57:10 - INFO - __main__ - Step 130 Global step 130 Train loss 4.34 on epoch=32
05/16/2022 15:57:11 - INFO - __main__ - Step 140 Global step 140 Train loss 4.21 on epoch=34
05/16/2022 15:57:13 - INFO - __main__ - Step 150 Global step 150 Train loss 4.07 on epoch=37
05/16/2022 15:57:14 - INFO - __main__ - Global step 150 Train loss 4.29 Classification-F1 0.0810126582278481 on epoch=37
05/16/2022 15:57:14 - INFO - __main__ - Saving model with best Classification-F1: 0.03240740740740741 -> 0.0810126582278481 on epoch=37, global_step=150
05/16/2022 15:57:15 - INFO - __main__ - Step 160 Global step 160 Train loss 4.01 on epoch=39
05/16/2022 15:57:16 - INFO - __main__ - Step 170 Global step 170 Train loss 3.60 on epoch=42
05/16/2022 15:57:18 - INFO - __main__ - Step 180 Global step 180 Train loss 3.72 on epoch=44
05/16/2022 15:57:19 - INFO - __main__ - Step 190 Global step 190 Train loss 3.54 on epoch=47
05/16/2022 15:57:20 - INFO - __main__ - Step 200 Global step 200 Train loss 3.49 on epoch=49
05/16/2022 15:57:21 - INFO - __main__ - Global step 200 Train loss 3.68 Classification-F1 0.09615384615384615 on epoch=49
05/16/2022 15:57:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.09615384615384615 on epoch=49, global_step=200
05/16/2022 15:57:22 - INFO - __main__ - Step 210 Global step 210 Train loss 3.38 on epoch=52
05/16/2022 15:57:24 - INFO - __main__ - Step 220 Global step 220 Train loss 3.22 on epoch=54
05/16/2022 15:57:25 - INFO - __main__ - Step 230 Global step 230 Train loss 2.98 on epoch=57
05/16/2022 15:57:26 - INFO - __main__ - Step 240 Global step 240 Train loss 3.02 on epoch=59
05/16/2022 15:57:28 - INFO - __main__ - Step 250 Global step 250 Train loss 2.91 on epoch=62
05/16/2022 15:57:28 - INFO - __main__ - Global step 250 Train loss 3.10 Classification-F1 0.07594936708860758 on epoch=62
05/16/2022 15:57:29 - INFO - __main__ - Step 260 Global step 260 Train loss 2.92 on epoch=64
05/16/2022 15:57:31 - INFO - __main__ - Step 270 Global step 270 Train loss 2.86 on epoch=67
05/16/2022 15:57:32 - INFO - __main__ - Step 280 Global step 280 Train loss 2.92 on epoch=69
05/16/2022 15:57:33 - INFO - __main__ - Step 290 Global step 290 Train loss 2.66 on epoch=72
05/16/2022 15:57:35 - INFO - __main__ - Step 300 Global step 300 Train loss 2.77 on epoch=74
05/16/2022 15:57:35 - INFO - __main__ - Global step 300 Train loss 2.83 Classification-F1 0.1 on epoch=74
05/16/2022 15:57:35 - INFO - __main__ - Saving model with best Classification-F1: 0.09615384615384615 -> 0.1 on epoch=74, global_step=300
05/16/2022 15:57:37 - INFO - __main__ - Step 310 Global step 310 Train loss 2.63 on epoch=77
05/16/2022 15:57:38 - INFO - __main__ - Step 320 Global step 320 Train loss 2.64 on epoch=79
05/16/2022 15:57:39 - INFO - __main__ - Step 330 Global step 330 Train loss 2.38 on epoch=82
05/16/2022 15:57:40 - INFO - __main__ - Step 340 Global step 340 Train loss 2.53 on epoch=84
05/16/2022 15:57:42 - INFO - __main__ - Step 350 Global step 350 Train loss 2.43 on epoch=87
05/16/2022 15:57:42 - INFO - __main__ - Global step 350 Train loss 2.52 Classification-F1 0.1118421052631579 on epoch=87
05/16/2022 15:57:42 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1118421052631579 on epoch=87, global_step=350
05/16/2022 15:57:43 - INFO - __main__ - Step 360 Global step 360 Train loss 2.44 on epoch=89
05/16/2022 15:57:45 - INFO - __main__ - Step 370 Global step 370 Train loss 2.32 on epoch=92
05/16/2022 15:57:46 - INFO - __main__ - Step 380 Global step 380 Train loss 2.39 on epoch=94
05/16/2022 15:57:47 - INFO - __main__ - Step 390 Global step 390 Train loss 2.27 on epoch=97
05/16/2022 15:57:49 - INFO - __main__ - Step 400 Global step 400 Train loss 2.31 on epoch=99
05/16/2022 15:57:49 - INFO - __main__ - Global step 400 Train loss 2.35 Classification-F1 0.11714285714285715 on epoch=99
05/16/2022 15:57:49 - INFO - __main__ - Saving model with best Classification-F1: 0.1118421052631579 -> 0.11714285714285715 on epoch=99, global_step=400
05/16/2022 15:57:50 - INFO - __main__ - Step 410 Global step 410 Train loss 2.25 on epoch=102
05/16/2022 15:57:52 - INFO - __main__ - Step 420 Global step 420 Train loss 2.12 on epoch=104
05/16/2022 15:57:53 - INFO - __main__ - Step 430 Global step 430 Train loss 2.30 on epoch=107
05/16/2022 15:57:54 - INFO - __main__ - Step 440 Global step 440 Train loss 2.07 on epoch=109
05/16/2022 15:57:56 - INFO - __main__ - Step 450 Global step 450 Train loss 2.13 on epoch=112
05/16/2022 15:57:56 - INFO - __main__ - Global step 450 Train loss 2.17 Classification-F1 0.1646076146076146 on epoch=112
05/16/2022 15:57:56 - INFO - __main__ - Saving model with best Classification-F1: 0.11714285714285715 -> 0.1646076146076146 on epoch=112, global_step=450
05/16/2022 15:57:57 - INFO - __main__ - Step 460 Global step 460 Train loss 1.98 on epoch=114
05/16/2022 15:57:59 - INFO - __main__ - Step 470 Global step 470 Train loss 1.92 on epoch=117
05/16/2022 15:58:00 - INFO - __main__ - Step 480 Global step 480 Train loss 2.01 on epoch=119
05/16/2022 15:58:01 - INFO - __main__ - Step 490 Global step 490 Train loss 1.65 on epoch=122
05/16/2022 15:58:03 - INFO - __main__ - Step 500 Global step 500 Train loss 1.68 on epoch=124
05/16/2022 15:58:03 - INFO - __main__ - Global step 500 Train loss 1.85 Classification-F1 0.17436974789915968 on epoch=124
05/16/2022 15:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.1646076146076146 -> 0.17436974789915968 on epoch=124, global_step=500
05/16/2022 15:58:05 - INFO - __main__ - Step 510 Global step 510 Train loss 1.80 on epoch=127
05/16/2022 15:58:06 - INFO - __main__ - Step 520 Global step 520 Train loss 1.71 on epoch=129
05/16/2022 15:58:07 - INFO - __main__ - Step 530 Global step 530 Train loss 1.77 on epoch=132
05/16/2022 15:58:09 - INFO - __main__ - Step 540 Global step 540 Train loss 1.67 on epoch=134
05/16/2022 15:58:10 - INFO - __main__ - Step 550 Global step 550 Train loss 1.77 on epoch=137
05/16/2022 15:58:10 - INFO - __main__ - Global step 550 Train loss 1.74 Classification-F1 0.16785714285714287 on epoch=137
05/16/2022 15:58:12 - INFO - __main__ - Step 560 Global step 560 Train loss 1.63 on epoch=139
05/16/2022 15:58:13 - INFO - __main__ - Step 570 Global step 570 Train loss 1.56 on epoch=142
05/16/2022 15:58:14 - INFO - __main__ - Step 580 Global step 580 Train loss 1.51 on epoch=144
05/16/2022 15:58:16 - INFO - __main__ - Step 590 Global step 590 Train loss 1.51 on epoch=147
05/16/2022 15:58:17 - INFO - __main__ - Step 600 Global step 600 Train loss 1.47 on epoch=149
05/16/2022 15:58:17 - INFO - __main__ - Global step 600 Train loss 1.53 Classification-F1 0.17368421052631577 on epoch=149
05/16/2022 15:58:19 - INFO - __main__ - Step 610 Global step 610 Train loss 1.63 on epoch=152
05/16/2022 15:58:20 - INFO - __main__ - Step 620 Global step 620 Train loss 1.65 on epoch=154
05/16/2022 15:58:21 - INFO - __main__ - Step 630 Global step 630 Train loss 1.34 on epoch=157
05/16/2022 15:58:23 - INFO - __main__ - Step 640 Global step 640 Train loss 1.45 on epoch=159
05/16/2022 15:58:24 - INFO - __main__ - Step 650 Global step 650 Train loss 1.36 on epoch=162
05/16/2022 15:58:25 - INFO - __main__ - Global step 650 Train loss 1.49 Classification-F1 0.1 on epoch=162
05/16/2022 15:58:26 - INFO - __main__ - Step 660 Global step 660 Train loss 1.49 on epoch=164
05/16/2022 15:58:27 - INFO - __main__ - Step 670 Global step 670 Train loss 1.48 on epoch=167
05/16/2022 15:58:29 - INFO - __main__ - Step 680 Global step 680 Train loss 1.48 on epoch=169
05/16/2022 15:58:30 - INFO - __main__ - Step 690 Global step 690 Train loss 1.34 on epoch=172
05/16/2022 15:58:31 - INFO - __main__ - Step 700 Global step 700 Train loss 1.50 on epoch=174
05/16/2022 15:58:32 - INFO - __main__ - Global step 700 Train loss 1.46 Classification-F1 0.1 on epoch=174
05/16/2022 15:58:33 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=177
05/16/2022 15:58:35 - INFO - __main__ - Step 720 Global step 720 Train loss 1.33 on epoch=179
05/16/2022 15:58:36 - INFO - __main__ - Step 730 Global step 730 Train loss 1.33 on epoch=182
05/16/2022 15:58:37 - INFO - __main__ - Step 740 Global step 740 Train loss 1.20 on epoch=184
05/16/2022 15:58:39 - INFO - __main__ - Step 750 Global step 750 Train loss 1.23 on epoch=187
05/16/2022 15:58:39 - INFO - __main__ - Global step 750 Train loss 1.28 Classification-F1 0.1 on epoch=187
05/16/2022 15:58:40 - INFO - __main__ - Step 760 Global step 760 Train loss 1.35 on epoch=189
05/16/2022 15:58:42 - INFO - __main__ - Step 770 Global step 770 Train loss 1.32 on epoch=192
05/16/2022 15:58:43 - INFO - __main__ - Step 780 Global step 780 Train loss 1.23 on epoch=194
05/16/2022 15:58:44 - INFO - __main__ - Step 790 Global step 790 Train loss 1.25 on epoch=197
05/16/2022 15:58:46 - INFO - __main__ - Step 800 Global step 800 Train loss 1.27 on epoch=199
05/16/2022 15:58:46 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.1 on epoch=199
05/16/2022 15:58:47 - INFO - __main__ - Step 810 Global step 810 Train loss 1.35 on epoch=202
05/16/2022 15:58:49 - INFO - __main__ - Step 820 Global step 820 Train loss 1.34 on epoch=204
05/16/2022 15:58:50 - INFO - __main__ - Step 830 Global step 830 Train loss 1.13 on epoch=207
05/16/2022 15:58:52 - INFO - __main__ - Step 840 Global step 840 Train loss 1.30 on epoch=209
05/16/2022 15:58:53 - INFO - __main__ - Step 850 Global step 850 Train loss 1.25 on epoch=212
05/16/2022 15:58:54 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.16666666666666666 on epoch=212
05/16/2022 15:58:55 - INFO - __main__ - Step 860 Global step 860 Train loss 1.30 on epoch=214
05/16/2022 15:58:57 - INFO - __main__ - Step 870 Global step 870 Train loss 1.29 on epoch=217
05/16/2022 15:58:58 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
05/16/2022 15:58:59 - INFO - __main__ - Step 890 Global step 890 Train loss 1.29 on epoch=222
05/16/2022 15:59:01 - INFO - __main__ - Step 900 Global step 900 Train loss 1.21 on epoch=224
05/16/2022 15:59:01 - INFO - __main__ - Global step 900 Train loss 1.28 Classification-F1 0.1 on epoch=224
05/16/2022 15:59:03 - INFO - __main__ - Step 910 Global step 910 Train loss 1.34 on epoch=227
05/16/2022 15:59:04 - INFO - __main__ - Step 920 Global step 920 Train loss 1.19 on epoch=229
05/16/2022 15:59:05 - INFO - __main__ - Step 930 Global step 930 Train loss 1.21 on epoch=232
05/16/2022 15:59:07 - INFO - __main__ - Step 940 Global step 940 Train loss 1.36 on epoch=234
05/16/2022 15:59:08 - INFO - __main__ - Step 950 Global step 950 Train loss 1.29 on epoch=237
05/16/2022 15:59:09 - INFO - __main__ - Global step 950 Train loss 1.28 Classification-F1 0.13034188034188032 on epoch=237
05/16/2022 15:59:10 - INFO - __main__ - Step 960 Global step 960 Train loss 1.04 on epoch=239
05/16/2022 15:59:12 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=242
05/16/2022 15:59:13 - INFO - __main__ - Step 980 Global step 980 Train loss 1.20 on epoch=244
05/16/2022 15:59:14 - INFO - __main__ - Step 990 Global step 990 Train loss 1.20 on epoch=247
05/16/2022 15:59:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.11 on epoch=249
05/16/2022 15:59:16 - INFO - __main__ - Global step 1000 Train loss 1.15 Classification-F1 0.2097902097902098 on epoch=249
05/16/2022 15:59:16 - INFO - __main__ - Saving model with best Classification-F1: 0.17436974789915968 -> 0.2097902097902098 on epoch=249, global_step=1000
05/16/2022 15:59:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.08 on epoch=252
05/16/2022 15:59:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.17 on epoch=254
05/16/2022 15:59:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/16/2022 15:59:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.23 on epoch=259
05/16/2022 15:59:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.04 on epoch=262
05/16/2022 15:59:24 - INFO - __main__ - Global step 1050 Train loss 1.12 Classification-F1 0.21717171717171715 on epoch=262
05/16/2022 15:59:24 - INFO - __main__ - Saving model with best Classification-F1: 0.2097902097902098 -> 0.21717171717171715 on epoch=262, global_step=1050
05/16/2022 15:59:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
05/16/2022 15:59:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.99 on epoch=267
05/16/2022 15:59:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.95 on epoch=269
05/16/2022 15:59:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.14 on epoch=272
05/16/2022 15:59:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.15 on epoch=274
05/16/2022 15:59:31 - INFO - __main__ - Global step 1100 Train loss 1.06 Classification-F1 0.1638655462184874 on epoch=274
05/16/2022 15:59:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.23 on epoch=277
05/16/2022 15:59:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.20 on epoch=279
05/16/2022 15:59:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
05/16/2022 15:59:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.17 on epoch=284
05/16/2022 15:59:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.94 on epoch=287
05/16/2022 15:59:38 - INFO - __main__ - Global step 1150 Train loss 1.14 Classification-F1 0.12912912912912913 on epoch=287
05/16/2022 15:59:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
05/16/2022 15:59:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.04 on epoch=292
05/16/2022 15:59:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.08 on epoch=294
05/16/2022 15:59:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.07 on epoch=297
05/16/2022 15:59:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.15 on epoch=299
05/16/2022 15:59:46 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.1 on epoch=299
05/16/2022 15:59:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.06 on epoch=302
05/16/2022 15:59:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=304
05/16/2022 15:59:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.99 on epoch=307
05/16/2022 15:59:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/16/2022 15:59:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.03 on epoch=312
05/16/2022 15:59:53 - INFO - __main__ - Global step 1250 Train loss 1.05 Classification-F1 0.197603121516165 on epoch=312
05/16/2022 15:59:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.11 on epoch=314
05/16/2022 15:59:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=317
05/16/2022 15:59:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.12 on epoch=319
05/16/2022 15:59:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.13 on epoch=322
05/16/2022 15:59:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.05 on epoch=324
05/16/2022 16:00:00 - INFO - __main__ - Global step 1300 Train loss 1.12 Classification-F1 0.17811480585078396 on epoch=324
05/16/2022 16:00:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.06 on epoch=327
05/16/2022 16:00:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.97 on epoch=329
05/16/2022 16:00:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.00 on epoch=332
05/16/2022 16:00:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.01 on epoch=334
05/16/2022 16:00:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.14 on epoch=337
05/16/2022 16:00:07 - INFO - __main__ - Global step 1350 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=337
05/16/2022 16:00:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.18 on epoch=339
05/16/2022 16:00:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=342
05/16/2022 16:00:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=344
05/16/2022 16:00:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.01 on epoch=347
05/16/2022 16:00:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.13 on epoch=349
05/16/2022 16:00:14 - INFO - __main__ - Global step 1400 Train loss 1.10 Classification-F1 0.1527777777777778 on epoch=349
05/16/2022 16:00:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.17 on epoch=352
05/16/2022 16:00:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.09 on epoch=354
05/16/2022 16:00:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.14 on epoch=357
05/16/2022 16:00:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.06 on epoch=359
05/16/2022 16:00:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.05 on epoch=362
05/16/2022 16:00:21 - INFO - __main__ - Global step 1450 Train loss 1.10 Classification-F1 0.10966810966810966 on epoch=362
05/16/2022 16:00:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.10 on epoch=364
05/16/2022 16:00:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.16 on epoch=367
05/16/2022 16:00:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.10 on epoch=369
05/16/2022 16:00:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=372
05/16/2022 16:00:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.02 on epoch=374
05/16/2022 16:00:29 - INFO - __main__ - Global step 1500 Train loss 1.07 Classification-F1 0.15606060606060607 on epoch=374
05/16/2022 16:00:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.96 on epoch=377
05/16/2022 16:00:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/16/2022 16:00:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.04 on epoch=382
05/16/2022 16:00:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
05/16/2022 16:00:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.97 on epoch=387
05/16/2022 16:00:36 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.09868421052631579 on epoch=387
05/16/2022 16:00:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.04 on epoch=389
05/16/2022 16:00:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.09 on epoch=392
05/16/2022 16:00:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.98 on epoch=394
05/16/2022 16:00:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.02 on epoch=397
05/16/2022 16:00:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
05/16/2022 16:00:43 - INFO - __main__ - Global step 1600 Train loss 1.05 Classification-F1 0.0974025974025974 on epoch=399
05/16/2022 16:00:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.04 on epoch=402
05/16/2022 16:00:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=404
05/16/2022 16:00:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.03 on epoch=407
05/16/2022 16:00:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
05/16/2022 16:00:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.99 on epoch=412
05/16/2022 16:00:50 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.2011385199240987 on epoch=412
05/16/2022 16:00:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.95 on epoch=414
05/16/2022 16:00:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.96 on epoch=417
05/16/2022 16:00:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.95 on epoch=419
05/16/2022 16:00:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/16/2022 16:00:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.01 on epoch=424
05/16/2022 16:00:57 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.2011926367643246 on epoch=424
05/16/2022 16:00:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.09 on epoch=427
05/16/2022 16:01:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.88 on epoch=429
05/16/2022 16:01:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.05 on epoch=432
05/16/2022 16:01:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.04 on epoch=434
05/16/2022 16:01:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.02 on epoch=437
05/16/2022 16:01:04 - INFO - __main__ - Global step 1750 Train loss 1.02 Classification-F1 0.10126582278481013 on epoch=437
05/16/2022 16:01:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
05/16/2022 16:01:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/16/2022 16:01:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.98 on epoch=444
05/16/2022 16:01:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.01 on epoch=447
05/16/2022 16:01:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
05/16/2022 16:01:11 - INFO - __main__ - Global step 1800 Train loss 1.00 Classification-F1 0.1767857142857143 on epoch=449
05/16/2022 16:01:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.00 on epoch=452
05/16/2022 16:01:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
05/16/2022 16:01:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.02 on epoch=457
05/16/2022 16:01:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=459
05/16/2022 16:01:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.97 on epoch=462
05/16/2022 16:01:19 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.13157894736842107 on epoch=462
05/16/2022 16:01:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.00 on epoch=464
05/16/2022 16:01:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.96 on epoch=467
05/16/2022 16:01:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.93 on epoch=469
05/16/2022 16:01:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/16/2022 16:01:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=474
05/16/2022 16:01:26 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.1 on epoch=474
05/16/2022 16:01:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.98 on epoch=477
05/16/2022 16:01:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.94 on epoch=479
05/16/2022 16:01:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.93 on epoch=482
05/16/2022 16:01:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.00 on epoch=484
05/16/2022 16:01:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.99 on epoch=487
05/16/2022 16:01:33 - INFO - __main__ - Global step 1950 Train loss 0.97 Classification-F1 0.19537815126050417 on epoch=487
05/16/2022 16:01:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.02 on epoch=489
05/16/2022 16:01:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.91 on epoch=492
05/16/2022 16:01:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.08 on epoch=494
05/16/2022 16:01:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.99 on epoch=497
05/16/2022 16:01:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/16/2022 16:01:40 - INFO - __main__ - Global step 2000 Train loss 0.99 Classification-F1 0.27645590314598795 on epoch=499
05/16/2022 16:01:40 - INFO - __main__ - Saving model with best Classification-F1: 0.21717171717171715 -> 0.27645590314598795 on epoch=499, global_step=2000
05/16/2022 16:01:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/16/2022 16:01:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
05/16/2022 16:01:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.00 on epoch=507
05/16/2022 16:01:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.96 on epoch=509
05/16/2022 16:01:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.10 on epoch=512
05/16/2022 16:01:47 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.1388888888888889 on epoch=512
05/16/2022 16:01:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.00 on epoch=514
05/16/2022 16:01:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/16/2022 16:01:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.95 on epoch=519
05/16/2022 16:01:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.02 on epoch=522
05/16/2022 16:01:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.04 on epoch=524
05/16/2022 16:01:54 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.3629129129129129 on epoch=524
05/16/2022 16:01:54 - INFO - __main__ - Saving model with best Classification-F1: 0.27645590314598795 -> 0.3629129129129129 on epoch=524, global_step=2100
05/16/2022 16:01:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/16/2022 16:01:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.05 on epoch=529
05/16/2022 16:01:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.97 on epoch=532
05/16/2022 16:02:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.92 on epoch=534
05/16/2022 16:02:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.07 on epoch=537
05/16/2022 16:02:02 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.25918367346938775 on epoch=537
05/16/2022 16:02:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.04 on epoch=539
05/16/2022 16:02:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.02 on epoch=542
05/16/2022 16:02:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/16/2022 16:02:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/16/2022 16:02:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.96 on epoch=549
05/16/2022 16:02:09 - INFO - __main__ - Global step 2200 Train loss 1.01 Classification-F1 0.11732186732186733 on epoch=549
05/16/2022 16:02:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/16/2022 16:02:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.99 on epoch=554
05/16/2022 16:02:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.11 on epoch=557
05/16/2022 16:02:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.09 on epoch=559
05/16/2022 16:02:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
05/16/2022 16:02:16 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.2032315020119898 on epoch=562
05/16/2022 16:02:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/16/2022 16:02:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.00 on epoch=567
05/16/2022 16:02:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.96 on epoch=569
05/16/2022 16:02:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/16/2022 16:02:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/16/2022 16:02:23 - INFO - __main__ - Global step 2300 Train loss 0.98 Classification-F1 0.27036679536679536 on epoch=574
05/16/2022 16:02:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/16/2022 16:02:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.00 on epoch=579
05/16/2022 16:02:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
05/16/2022 16:02:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.04 on epoch=584
05/16/2022 16:02:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/16/2022 16:02:30 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.15587044534412953 on epoch=587
05/16/2022 16:02:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/16/2022 16:02:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.11 on epoch=592
05/16/2022 16:02:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/16/2022 16:02:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
05/16/2022 16:02:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.04 on epoch=599
05/16/2022 16:02:37 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.09528130671506352 on epoch=599
05/16/2022 16:02:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/16/2022 16:02:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/16/2022 16:02:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/16/2022 16:02:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.88 on epoch=609
05/16/2022 16:02:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.98 on epoch=612
05/16/2022 16:02:45 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.15714285714285717 on epoch=612
05/16/2022 16:02:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.93 on epoch=614
05/16/2022 16:02:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.90 on epoch=617
05/16/2022 16:02:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/16/2022 16:02:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/16/2022 16:02:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.94 on epoch=624
05/16/2022 16:02:52 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.1774628879892038 on epoch=624
05/16/2022 16:02:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/16/2022 16:02:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.04 on epoch=629
05/16/2022 16:02:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.99 on epoch=632
05/16/2022 16:02:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.05 on epoch=634
05/16/2022 16:02:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.97 on epoch=637
05/16/2022 16:03:00 - INFO - __main__ - Global step 2550 Train loss 1.01 Classification-F1 0.18385416666666665 on epoch=637
05/16/2022 16:03:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
05/16/2022 16:03:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.98 on epoch=642
05/16/2022 16:03:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.99 on epoch=644
05/16/2022 16:03:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/16/2022 16:03:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.98 on epoch=649
05/16/2022 16:03:07 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.17813655142422266 on epoch=649
05/16/2022 16:03:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.87 on epoch=652
05/16/2022 16:03:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
05/16/2022 16:03:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.91 on epoch=657
05/16/2022 16:03:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.90 on epoch=659
05/16/2022 16:03:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/16/2022 16:03:14 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.1698691172375383 on epoch=662
05/16/2022 16:03:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.92 on epoch=664
05/16/2022 16:03:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.00 on epoch=667
05/16/2022 16:03:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/16/2022 16:03:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.05 on epoch=672
05/16/2022 16:03:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/16/2022 16:03:21 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.14583504477121498 on epoch=674
05/16/2022 16:03:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.05 on epoch=677
05/16/2022 16:03:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.89 on epoch=679
05/16/2022 16:03:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/16/2022 16:03:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/16/2022 16:03:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.97 on epoch=687
05/16/2022 16:03:28 - INFO - __main__ - Global step 2750 Train loss 0.96 Classification-F1 0.19811563763176665 on epoch=687
05/16/2022 16:03:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.01 on epoch=689
05/16/2022 16:03:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
05/16/2022 16:03:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.92 on epoch=694
05/16/2022 16:03:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.02 on epoch=697
05/16/2022 16:03:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.90 on epoch=699
05/16/2022 16:03:36 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.07971014492753624 on epoch=699
05/16/2022 16:03:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.91 on epoch=702
05/16/2022 16:03:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.09 on epoch=704
05/16/2022 16:03:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.95 on epoch=707
05/16/2022 16:03:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/16/2022 16:03:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
05/16/2022 16:03:43 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.1865079365079365 on epoch=712
05/16/2022 16:03:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/16/2022 16:03:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
05/16/2022 16:03:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.02 on epoch=719
05/16/2022 16:03:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/16/2022 16:03:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/16/2022 16:03:50 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.16091269841269842 on epoch=724
05/16/2022 16:03:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/16/2022 16:03:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
05/16/2022 16:03:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.93 on epoch=732
05/16/2022 16:03:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/16/2022 16:03:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.91 on epoch=737
05/16/2022 16:03:58 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.22316451664277753 on epoch=737
05/16/2022 16:03:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/16/2022 16:04:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.99 on epoch=742
05/16/2022 16:04:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/16/2022 16:04:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.92 on epoch=747
05/16/2022 16:04:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
05/16/2022 16:04:05 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.20094080338266385 on epoch=749
05/16/2022 16:04:05 - INFO - __main__ - save last model!
05/16/2022 16:04:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 16:04:05 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 16:04:05 - INFO - __main__ - Printing 3 examples
05/16/2022 16:04:05 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 16:04:05 - INFO - __main__ - ['others']
05/16/2022 16:04:05 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 16:04:05 - INFO - __main__ - ['others']
05/16/2022 16:04:05 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 16:04:05 - INFO - __main__ - ['others']
05/16/2022 16:04:05 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:04:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:04:06 - INFO - __main__ - Printing 3 examples
05/16/2022 16:04:06 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 16:04:06 - INFO - __main__ - ['happy']
05/16/2022 16:04:06 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 16:04:06 - INFO - __main__ - ['happy']
05/16/2022 16:04:06 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 16:04:06 - INFO - __main__ - ['happy']
05/16/2022 16:04:06 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:04:06 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:04:06 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:04:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:04:06 - INFO - __main__ - Printing 3 examples
05/16/2022 16:04:06 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 16:04:06 - INFO - __main__ - ['happy']
05/16/2022 16:04:06 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 16:04:06 - INFO - __main__ - ['happy']
05/16/2022 16:04:06 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 16:04:06 - INFO - __main__ - ['happy']
05/16/2022 16:04:06 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:04:06 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:04:06 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:04:08 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:04:12 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:04:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:04:12 - INFO - __main__ - Starting training!
05/16/2022 16:04:14 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 16:05:02 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.5_8_predictions.txt
05/16/2022 16:05:02 - INFO - __main__ - Classification-F1 on test data: 0.0681
05/16/2022 16:05:03 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.3629129129129129, test_performance=0.06813091170116173
05/16/2022 16:05:03 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
05/16/2022 16:05:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:05:03 - INFO - __main__ - Printing 3 examples
05/16/2022 16:05:03 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 16:05:03 - INFO - __main__ - ['happy']
05/16/2022 16:05:03 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 16:05:03 - INFO - __main__ - ['happy']
05/16/2022 16:05:03 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 16:05:03 - INFO - __main__ - ['happy']
05/16/2022 16:05:03 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:05:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:05:04 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:05:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:05:04 - INFO - __main__ - Printing 3 examples
05/16/2022 16:05:04 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 16:05:04 - INFO - __main__ - ['happy']
05/16/2022 16:05:04 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 16:05:04 - INFO - __main__ - ['happy']
05/16/2022 16:05:04 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 16:05:04 - INFO - __main__ - ['happy']
05/16/2022 16:05:04 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:05:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:05:04 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:05:09 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:05:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:05:10 - INFO - __main__ - Starting training!
05/16/2022 16:05:11 - INFO - __main__ - Step 10 Global step 10 Train loss 6.66 on epoch=2
05/16/2022 16:05:12 - INFO - __main__ - Step 20 Global step 20 Train loss 6.37 on epoch=4
05/16/2022 16:05:14 - INFO - __main__ - Step 30 Global step 30 Train loss 6.08 on epoch=7
05/16/2022 16:05:15 - INFO - __main__ - Step 40 Global step 40 Train loss 5.91 on epoch=9
05/16/2022 16:05:16 - INFO - __main__ - Step 50 Global step 50 Train loss 5.70 on epoch=12
05/16/2022 16:05:18 - INFO - __main__ - Global step 50 Train loss 6.14 Classification-F1 0.0 on epoch=12
05/16/2022 16:05:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 16:05:20 - INFO - __main__ - Step 60 Global step 60 Train loss 5.34 on epoch=14
05/16/2022 16:05:21 - INFO - __main__ - Step 70 Global step 70 Train loss 5.08 on epoch=17
05/16/2022 16:05:22 - INFO - __main__ - Step 80 Global step 80 Train loss 4.97 on epoch=19
05/16/2022 16:05:23 - INFO - __main__ - Step 90 Global step 90 Train loss 4.78 on epoch=22
05/16/2022 16:05:25 - INFO - __main__ - Step 100 Global step 100 Train loss 4.71 on epoch=24
05/16/2022 16:05:27 - INFO - __main__ - Global step 100 Train loss 4.98 Classification-F1 0.0 on epoch=24
05/16/2022 16:05:29 - INFO - __main__ - Step 110 Global step 110 Train loss 4.32 on epoch=27
05/16/2022 16:05:30 - INFO - __main__ - Step 120 Global step 120 Train loss 4.31 on epoch=29
05/16/2022 16:05:31 - INFO - __main__ - Step 130 Global step 130 Train loss 4.12 on epoch=32
05/16/2022 16:05:33 - INFO - __main__ - Step 140 Global step 140 Train loss 4.08 on epoch=34
05/16/2022 16:05:34 - INFO - __main__ - Step 150 Global step 150 Train loss 3.97 on epoch=37
05/16/2022 16:05:35 - INFO - __main__ - Global step 150 Train loss 4.16 Classification-F1 0.13624338624338622 on epoch=37
05/16/2022 16:05:35 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.13624338624338622 on epoch=37, global_step=150
05/16/2022 16:05:36 - INFO - __main__ - Step 160 Global step 160 Train loss 3.87 on epoch=39
05/16/2022 16:05:37 - INFO - __main__ - Step 170 Global step 170 Train loss 3.62 on epoch=42
05/16/2022 16:05:39 - INFO - __main__ - Step 180 Global step 180 Train loss 3.45 on epoch=44
05/16/2022 16:05:40 - INFO - __main__ - Step 190 Global step 190 Train loss 3.36 on epoch=47
05/16/2022 16:05:41 - INFO - __main__ - Step 200 Global step 200 Train loss 3.45 on epoch=49
05/16/2022 16:05:42 - INFO - __main__ - Global step 200 Train loss 3.55 Classification-F1 0.1565276828434723 on epoch=49
05/16/2022 16:05:42 - INFO - __main__ - Saving model with best Classification-F1: 0.13624338624338622 -> 0.1565276828434723 on epoch=49, global_step=200
05/16/2022 16:05:43 - INFO - __main__ - Step 210 Global step 210 Train loss 3.20 on epoch=52
05/16/2022 16:05:45 - INFO - __main__ - Step 220 Global step 220 Train loss 3.27 on epoch=54
05/16/2022 16:05:46 - INFO - __main__ - Step 230 Global step 230 Train loss 2.92 on epoch=57
05/16/2022 16:05:48 - INFO - __main__ - Step 240 Global step 240 Train loss 3.12 on epoch=59
05/16/2022 16:05:49 - INFO - __main__ - Step 250 Global step 250 Train loss 2.99 on epoch=62
05/16/2022 16:05:50 - INFO - __main__ - Global step 250 Train loss 3.10 Classification-F1 0.12568058076225044 on epoch=62
05/16/2022 16:05:51 - INFO - __main__ - Step 260 Global step 260 Train loss 3.07 on epoch=64
05/16/2022 16:05:53 - INFO - __main__ - Step 270 Global step 270 Train loss 2.78 on epoch=67
05/16/2022 16:05:54 - INFO - __main__ - Step 280 Global step 280 Train loss 2.87 on epoch=69
05/16/2022 16:05:55 - INFO - __main__ - Step 290 Global step 290 Train loss 2.64 on epoch=72
05/16/2022 16:05:57 - INFO - __main__ - Step 300 Global step 300 Train loss 2.77 on epoch=74
05/16/2022 16:05:57 - INFO - __main__ - Global step 300 Train loss 2.83 Classification-F1 0.13347763347763347 on epoch=74
05/16/2022 16:05:59 - INFO - __main__ - Step 310 Global step 310 Train loss 2.53 on epoch=77
05/16/2022 16:06:00 - INFO - __main__ - Step 320 Global step 320 Train loss 2.54 on epoch=79
05/16/2022 16:06:01 - INFO - __main__ - Step 330 Global step 330 Train loss 2.50 on epoch=82
05/16/2022 16:06:02 - INFO - __main__ - Step 340 Global step 340 Train loss 2.28 on epoch=84
05/16/2022 16:06:04 - INFO - __main__ - Step 350 Global step 350 Train loss 2.42 on epoch=87
05/16/2022 16:06:04 - INFO - __main__ - Global step 350 Train loss 2.45 Classification-F1 0.1659804426145136 on epoch=87
05/16/2022 16:06:04 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.1659804426145136 on epoch=87, global_step=350
05/16/2022 16:06:06 - INFO - __main__ - Step 360 Global step 360 Train loss 2.36 on epoch=89
05/16/2022 16:06:07 - INFO - __main__ - Step 370 Global step 370 Train loss 2.36 on epoch=92
05/16/2022 16:06:08 - INFO - __main__ - Step 380 Global step 380 Train loss 2.44 on epoch=94
05/16/2022 16:06:10 - INFO - __main__ - Step 390 Global step 390 Train loss 2.11 on epoch=97
05/16/2022 16:06:11 - INFO - __main__ - Step 400 Global step 400 Train loss 2.42 on epoch=99
05/16/2022 16:06:12 - INFO - __main__ - Global step 400 Train loss 2.34 Classification-F1 0.13034188034188032 on epoch=99
05/16/2022 16:06:13 - INFO - __main__ - Step 410 Global step 410 Train loss 2.21 on epoch=102
05/16/2022 16:06:14 - INFO - __main__ - Step 420 Global step 420 Train loss 2.29 on epoch=104
05/16/2022 16:06:16 - INFO - __main__ - Step 430 Global step 430 Train loss 2.11 on epoch=107
05/16/2022 16:06:17 - INFO - __main__ - Step 440 Global step 440 Train loss 2.18 on epoch=109
05/16/2022 16:06:19 - INFO - __main__ - Step 450 Global step 450 Train loss 1.90 on epoch=112
05/16/2022 16:06:19 - INFO - __main__ - Global step 450 Train loss 2.14 Classification-F1 0.1576923076923077 on epoch=112
05/16/2022 16:06:21 - INFO - __main__ - Step 460 Global step 460 Train loss 2.14 on epoch=114
05/16/2022 16:06:22 - INFO - __main__ - Step 470 Global step 470 Train loss 1.90 on epoch=117
05/16/2022 16:06:23 - INFO - __main__ - Step 480 Global step 480 Train loss 1.96 on epoch=119
05/16/2022 16:06:25 - INFO - __main__ - Step 490 Global step 490 Train loss 1.71 on epoch=122
05/16/2022 16:06:26 - INFO - __main__ - Step 500 Global step 500 Train loss 1.92 on epoch=124
05/16/2022 16:06:27 - INFO - __main__ - Global step 500 Train loss 1.93 Classification-F1 0.13067758749069247 on epoch=124
05/16/2022 16:06:28 - INFO - __main__ - Step 510 Global step 510 Train loss 1.66 on epoch=127
05/16/2022 16:06:29 - INFO - __main__ - Step 520 Global step 520 Train loss 1.67 on epoch=129
05/16/2022 16:06:31 - INFO - __main__ - Step 530 Global step 530 Train loss 1.61 on epoch=132
05/16/2022 16:06:32 - INFO - __main__ - Step 540 Global step 540 Train loss 1.78 on epoch=134
05/16/2022 16:06:33 - INFO - __main__ - Step 550 Global step 550 Train loss 1.53 on epoch=137
05/16/2022 16:06:34 - INFO - __main__ - Global step 550 Train loss 1.65 Classification-F1 0.14915966386554622 on epoch=137
05/16/2022 16:06:35 - INFO - __main__ - Step 560 Global step 560 Train loss 1.57 on epoch=139
05/16/2022 16:06:36 - INFO - __main__ - Step 570 Global step 570 Train loss 1.67 on epoch=142
05/16/2022 16:06:38 - INFO - __main__ - Step 580 Global step 580 Train loss 1.52 on epoch=144
05/16/2022 16:06:39 - INFO - __main__ - Step 590 Global step 590 Train loss 1.51 on epoch=147
05/16/2022 16:06:40 - INFO - __main__ - Step 600 Global step 600 Train loss 1.46 on epoch=149
05/16/2022 16:06:41 - INFO - __main__ - Global step 600 Train loss 1.55 Classification-F1 0.16377171215880895 on epoch=149
05/16/2022 16:06:42 - INFO - __main__ - Step 610 Global step 610 Train loss 1.51 on epoch=152
05/16/2022 16:06:44 - INFO - __main__ - Step 620 Global step 620 Train loss 1.49 on epoch=154
05/16/2022 16:06:45 - INFO - __main__ - Step 630 Global step 630 Train loss 1.63 on epoch=157
05/16/2022 16:06:47 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=159
05/16/2022 16:06:48 - INFO - __main__ - Step 650 Global step 650 Train loss 1.55 on epoch=162
05/16/2022 16:06:49 - INFO - __main__ - Global step 650 Train loss 1.52 Classification-F1 0.13275613275613274 on epoch=162
05/16/2022 16:06:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.56 on epoch=164
05/16/2022 16:06:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.48 on epoch=167
05/16/2022 16:06:53 - INFO - __main__ - Step 680 Global step 680 Train loss 1.50 on epoch=169
05/16/2022 16:06:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.49 on epoch=172
05/16/2022 16:06:55 - INFO - __main__ - Step 700 Global step 700 Train loss 1.45 on epoch=174
05/16/2022 16:06:56 - INFO - __main__ - Global step 700 Train loss 1.50 Classification-F1 0.13936867182846935 on epoch=174
05/16/2022 16:06:57 - INFO - __main__ - Step 710 Global step 710 Train loss 1.37 on epoch=177
05/16/2022 16:06:59 - INFO - __main__ - Step 720 Global step 720 Train loss 1.45 on epoch=179
05/16/2022 16:07:00 - INFO - __main__ - Step 730 Global step 730 Train loss 1.50 on epoch=182
05/16/2022 16:07:02 - INFO - __main__ - Step 740 Global step 740 Train loss 1.48 on epoch=184
05/16/2022 16:07:03 - INFO - __main__ - Step 750 Global step 750 Train loss 1.46 on epoch=187
05/16/2022 16:07:04 - INFO - __main__ - Global step 750 Train loss 1.45 Classification-F1 0.1 on epoch=187
05/16/2022 16:07:05 - INFO - __main__ - Step 760 Global step 760 Train loss 1.44 on epoch=189
05/16/2022 16:07:06 - INFO - __main__ - Step 770 Global step 770 Train loss 1.62 on epoch=192
05/16/2022 16:07:07 - INFO - __main__ - Step 780 Global step 780 Train loss 1.52 on epoch=194
05/16/2022 16:07:09 - INFO - __main__ - Step 790 Global step 790 Train loss 1.41 on epoch=197
05/16/2022 16:07:10 - INFO - __main__ - Step 800 Global step 800 Train loss 1.38 on epoch=199
05/16/2022 16:07:11 - INFO - __main__ - Global step 800 Train loss 1.47 Classification-F1 0.15607940446650126 on epoch=199
05/16/2022 16:07:12 - INFO - __main__ - Step 810 Global step 810 Train loss 1.44 on epoch=202
05/16/2022 16:07:13 - INFO - __main__ - Step 820 Global step 820 Train loss 1.48 on epoch=204
05/16/2022 16:07:14 - INFO - __main__ - Step 830 Global step 830 Train loss 1.39 on epoch=207
05/16/2022 16:07:16 - INFO - __main__ - Step 840 Global step 840 Train loss 1.37 on epoch=209
05/16/2022 16:07:17 - INFO - __main__ - Step 850 Global step 850 Train loss 1.23 on epoch=212
05/16/2022 16:07:18 - INFO - __main__ - Global step 850 Train loss 1.38 Classification-F1 0.12194223401119952 on epoch=212
05/16/2022 16:07:19 - INFO - __main__ - Step 860 Global step 860 Train loss 1.27 on epoch=214
05/16/2022 16:07:20 - INFO - __main__ - Step 870 Global step 870 Train loss 1.34 on epoch=217
05/16/2022 16:07:22 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
05/16/2022 16:07:23 - INFO - __main__ - Step 890 Global step 890 Train loss 1.31 on epoch=222
05/16/2022 16:07:24 - INFO - __main__ - Step 900 Global step 900 Train loss 1.45 on epoch=224
05/16/2022 16:07:25 - INFO - __main__ - Global step 900 Train loss 1.34 Classification-F1 0.14179439381386358 on epoch=224
05/16/2022 16:07:26 - INFO - __main__ - Step 910 Global step 910 Train loss 1.30 on epoch=227
05/16/2022 16:07:28 - INFO - __main__ - Step 920 Global step 920 Train loss 1.29 on epoch=229
05/16/2022 16:07:29 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
05/16/2022 16:07:30 - INFO - __main__ - Step 940 Global step 940 Train loss 1.23 on epoch=234
05/16/2022 16:07:32 - INFO - __main__ - Step 950 Global step 950 Train loss 1.26 on epoch=237
05/16/2022 16:07:32 - INFO - __main__ - Global step 950 Train loss 1.29 Classification-F1 0.18161263800798685 on epoch=237
05/16/2022 16:07:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1659804426145136 -> 0.18161263800798685 on epoch=237, global_step=950
05/16/2022 16:07:34 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/16/2022 16:07:35 - INFO - __main__ - Step 970 Global step 970 Train loss 1.17 on epoch=242
05/16/2022 16:07:36 - INFO - __main__ - Step 980 Global step 980 Train loss 1.37 on epoch=244
05/16/2022 16:07:38 - INFO - __main__ - Step 990 Global step 990 Train loss 1.29 on epoch=247
05/16/2022 16:07:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.33 on epoch=249
05/16/2022 16:07:40 - INFO - __main__ - Global step 1000 Train loss 1.29 Classification-F1 0.13034188034188032 on epoch=249
05/16/2022 16:07:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.31 on epoch=252
05/16/2022 16:07:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.26 on epoch=254
05/16/2022 16:07:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.30 on epoch=257
05/16/2022 16:07:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.30 on epoch=259
05/16/2022 16:07:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.15 on epoch=262
05/16/2022 16:07:47 - INFO - __main__ - Global step 1050 Train loss 1.26 Classification-F1 0.1715492957746479 on epoch=262
05/16/2022 16:07:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.27 on epoch=264
05/16/2022 16:07:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.13 on epoch=267
05/16/2022 16:07:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=269
05/16/2022 16:07:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.15 on epoch=272
05/16/2022 16:07:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
05/16/2022 16:07:55 - INFO - __main__ - Global step 1100 Train loss 1.17 Classification-F1 0.18166666666666667 on epoch=274
05/16/2022 16:07:55 - INFO - __main__ - Saving model with best Classification-F1: 0.18161263800798685 -> 0.18166666666666667 on epoch=274, global_step=1100
05/16/2022 16:07:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.22 on epoch=277
05/16/2022 16:07:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.30 on epoch=279
05/16/2022 16:07:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
05/16/2022 16:08:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.25 on epoch=284
05/16/2022 16:08:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.25 on epoch=287
05/16/2022 16:08:02 - INFO - __main__ - Global step 1150 Train loss 1.23 Classification-F1 0.1970899470899471 on epoch=287
05/16/2022 16:08:02 - INFO - __main__ - Saving model with best Classification-F1: 0.18166666666666667 -> 0.1970899470899471 on epoch=287, global_step=1150
05/16/2022 16:08:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.21 on epoch=289
05/16/2022 16:08:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.13 on epoch=292
05/16/2022 16:08:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.23 on epoch=294
05/16/2022 16:08:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.08 on epoch=297
05/16/2022 16:08:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.27 on epoch=299
05/16/2022 16:08:09 - INFO - __main__ - Global step 1200 Train loss 1.19 Classification-F1 0.15625 on epoch=299
05/16/2022 16:08:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.23 on epoch=302
05/16/2022 16:08:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.20 on epoch=304
05/16/2022 16:08:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.13 on epoch=307
05/16/2022 16:08:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.14 on epoch=309
05/16/2022 16:08:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.22 on epoch=312
05/16/2022 16:08:17 - INFO - __main__ - Global step 1250 Train loss 1.18 Classification-F1 0.1527777777777778 on epoch=312
05/16/2022 16:08:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.23 on epoch=314
05/16/2022 16:08:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.26 on epoch=317
05/16/2022 16:08:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
05/16/2022 16:08:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.16 on epoch=322
05/16/2022 16:08:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.05 on epoch=324
05/16/2022 16:08:24 - INFO - __main__ - Global step 1300 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=324
05/16/2022 16:08:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
05/16/2022 16:08:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.11 on epoch=329
05/16/2022 16:08:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.19 on epoch=332
05/16/2022 16:08:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.22 on epoch=334
05/16/2022 16:08:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.24 on epoch=337
05/16/2022 16:08:32 - INFO - __main__ - Global step 1350 Train loss 1.16 Classification-F1 0.1 on epoch=337
05/16/2022 16:08:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.13 on epoch=339
05/16/2022 16:08:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.19 on epoch=342
05/16/2022 16:08:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.24 on epoch=344
05/16/2022 16:08:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.26 on epoch=347
05/16/2022 16:08:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.99 on epoch=349
05/16/2022 16:08:39 - INFO - __main__ - Global step 1400 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=349
05/16/2022 16:08:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.06 on epoch=352
05/16/2022 16:08:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/16/2022 16:08:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/16/2022 16:08:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=359
05/16/2022 16:08:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=362
05/16/2022 16:08:46 - INFO - __main__ - Global step 1450 Train loss 1.06 Classification-F1 0.10256410256410256 on epoch=362
05/16/2022 16:08:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/16/2022 16:08:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
05/16/2022 16:08:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.16 on epoch=369
05/16/2022 16:08:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=372
05/16/2022 16:08:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=374
05/16/2022 16:08:53 - INFO - __main__ - Global step 1500 Train loss 1.15 Classification-F1 0.20842474769635805 on epoch=374
05/16/2022 16:08:53 - INFO - __main__ - Saving model with best Classification-F1: 0.1970899470899471 -> 0.20842474769635805 on epoch=374, global_step=1500
05/16/2022 16:08:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.03 on epoch=377
05/16/2022 16:08:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.13 on epoch=379
05/16/2022 16:08:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.10 on epoch=382
05/16/2022 16:08:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.02 on epoch=384
05/16/2022 16:09:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.00 on epoch=387
05/16/2022 16:09:01 - INFO - __main__ - Global step 1550 Train loss 1.06 Classification-F1 0.1875 on epoch=387
05/16/2022 16:09:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.11 on epoch=389
05/16/2022 16:09:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.08 on epoch=392
05/16/2022 16:09:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.02 on epoch=394
05/16/2022 16:09:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.06 on epoch=397
05/16/2022 16:09:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.01 on epoch=399
05/16/2022 16:09:08 - INFO - __main__ - Global step 1600 Train loss 1.06 Classification-F1 0.17341430499325233 on epoch=399
05/16/2022 16:09:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.07 on epoch=402
05/16/2022 16:09:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.10 on epoch=404
05/16/2022 16:09:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.88 on epoch=407
05/16/2022 16:09:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
05/16/2022 16:09:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.05 on epoch=412
05/16/2022 16:09:16 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.21765734265734268 on epoch=412
05/16/2022 16:09:16 - INFO - __main__ - Saving model with best Classification-F1: 0.20842474769635805 -> 0.21765734265734268 on epoch=412, global_step=1650
05/16/2022 16:09:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.16 on epoch=414
05/16/2022 16:09:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/16/2022 16:09:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.01 on epoch=419
05/16/2022 16:09:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.09 on epoch=422
05/16/2022 16:09:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.09 on epoch=424
05/16/2022 16:09:23 - INFO - __main__ - Global step 1700 Train loss 1.08 Classification-F1 0.11710526315789474 on epoch=424
05/16/2022 16:09:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
05/16/2022 16:09:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.10 on epoch=429
05/16/2022 16:09:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.10 on epoch=432
05/16/2022 16:09:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.02 on epoch=434
05/16/2022 16:09:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.03 on epoch=437
05/16/2022 16:09:31 - INFO - __main__ - Global step 1750 Train loss 1.06 Classification-F1 0.1 on epoch=437
05/16/2022 16:09:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.07 on epoch=439
05/16/2022 16:09:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
05/16/2022 16:09:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/16/2022 16:09:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.01 on epoch=447
05/16/2022 16:09:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
05/16/2022 16:09:38 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.1 on epoch=449
05/16/2022 16:09:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
05/16/2022 16:09:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/16/2022 16:09:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.89 on epoch=457
05/16/2022 16:09:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.06 on epoch=459
05/16/2022 16:09:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.08 on epoch=462
05/16/2022 16:09:46 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.14004914004914004 on epoch=462
05/16/2022 16:09:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.07 on epoch=464
05/16/2022 16:09:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.99 on epoch=467
05/16/2022 16:09:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.95 on epoch=469
05/16/2022 16:09:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/16/2022 16:09:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.02 on epoch=474
05/16/2022 16:09:54 - INFO - __main__ - Global step 1900 Train loss 1.00 Classification-F1 0.1 on epoch=474
05/16/2022 16:09:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/16/2022 16:09:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
05/16/2022 16:09:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=482
05/16/2022 16:10:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.15 on epoch=484
05/16/2022 16:10:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.14 on epoch=487
05/16/2022 16:10:02 - INFO - __main__ - Global step 1950 Train loss 1.07 Classification-F1 0.1843681917211329 on epoch=487
05/16/2022 16:10:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.99 on epoch=489
05/16/2022 16:10:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.98 on epoch=492
05/16/2022 16:10:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.92 on epoch=494
05/16/2022 16:10:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.05 on epoch=497
05/16/2022 16:10:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.97 on epoch=499
05/16/2022 16:10:09 - INFO - __main__ - Global step 2000 Train loss 0.98 Classification-F1 0.13047619047619047 on epoch=499
05/16/2022 16:10:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.05 on epoch=502
05/16/2022 16:10:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.04 on epoch=504
05/16/2022 16:10:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
05/16/2022 16:10:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.92 on epoch=509
05/16/2022 16:10:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.20 on epoch=512
05/16/2022 16:10:16 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.1 on epoch=512
05/16/2022 16:10:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
05/16/2022 16:10:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/16/2022 16:10:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.92 on epoch=519
05/16/2022 16:10:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.06 on epoch=522
05/16/2022 16:10:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.97 on epoch=524
05/16/2022 16:10:23 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.15054945054945054 on epoch=524
05/16/2022 16:10:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
05/16/2022 16:10:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.08 on epoch=529
05/16/2022 16:10:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.04 on epoch=532
05/16/2022 16:10:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.94 on epoch=534
05/16/2022 16:10:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.05 on epoch=537
05/16/2022 16:10:31 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.14621798689696247 on epoch=537
05/16/2022 16:10:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.94 on epoch=539
05/16/2022 16:10:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.20 on epoch=542
05/16/2022 16:10:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
05/16/2022 16:10:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.08 on epoch=547
05/16/2022 16:10:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
05/16/2022 16:10:38 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.16061705989110708 on epoch=549
05/16/2022 16:10:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/16/2022 16:10:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=554
05/16/2022 16:10:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/16/2022 16:10:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/16/2022 16:10:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/16/2022 16:10:45 - INFO - __main__ - Global step 2250 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=562
05/16/2022 16:10:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/16/2022 16:10:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.96 on epoch=567
05/16/2022 16:10:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.04 on epoch=569
05/16/2022 16:10:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.03 on epoch=572
05/16/2022 16:10:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/16/2022 16:10:53 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=574
05/16/2022 16:10:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.04 on epoch=577
05/16/2022 16:10:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=579
05/16/2022 16:10:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.01 on epoch=582
05/16/2022 16:10:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.91 on epoch=584
05/16/2022 16:11:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/16/2022 16:11:00 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.14791288566243194 on epoch=587
05/16/2022 16:11:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.89 on epoch=589
05/16/2022 16:11:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.90 on epoch=592
05/16/2022 16:11:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.92 on epoch=594
05/16/2022 16:11:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.09 on epoch=597
05/16/2022 16:11:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/16/2022 16:11:08 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.1 on epoch=599
05/16/2022 16:11:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.92 on epoch=602
05/16/2022 16:11:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/16/2022 16:11:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.95 on epoch=607
05/16/2022 16:11:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/16/2022 16:11:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/16/2022 16:11:15 - INFO - __main__ - Global step 2450 Train loss 0.99 Classification-F1 0.10135135135135136 on epoch=612
05/16/2022 16:11:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=614
05/16/2022 16:11:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.99 on epoch=617
05/16/2022 16:11:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/16/2022 16:11:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/16/2022 16:11:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.01 on epoch=624
05/16/2022 16:11:22 - INFO - __main__ - Global step 2500 Train loss 1.00 Classification-F1 0.18407494145199066 on epoch=624
05/16/2022 16:11:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.97 on epoch=627
05/16/2022 16:11:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.96 on epoch=629
05/16/2022 16:11:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.99 on epoch=632
05/16/2022 16:11:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.87 on epoch=634
05/16/2022 16:11:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.90 on epoch=637
05/16/2022 16:11:29 - INFO - __main__ - Global step 2550 Train loss 0.94 Classification-F1 0.1774628879892038 on epoch=637
05/16/2022 16:11:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.08 on epoch=639
05/16/2022 16:11:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.99 on epoch=642
05/16/2022 16:11:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.98 on epoch=644
05/16/2022 16:11:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
05/16/2022 16:11:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/16/2022 16:11:38 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.1 on epoch=649
05/16/2022 16:11:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.93 on epoch=652
05/16/2022 16:11:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
05/16/2022 16:11:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
05/16/2022 16:11:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/16/2022 16:11:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.85 on epoch=662
05/16/2022 16:11:45 - INFO - __main__ - Global step 2650 Train loss 0.94 Classification-F1 0.1 on epoch=662
05/16/2022 16:11:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.99 on epoch=664
05/16/2022 16:11:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.99 on epoch=667
05/16/2022 16:11:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.95 on epoch=669
05/16/2022 16:11:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.94 on epoch=672
05/16/2022 16:11:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
05/16/2022 16:11:53 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
05/16/2022 16:11:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/16/2022 16:11:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.96 on epoch=679
05/16/2022 16:11:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/16/2022 16:11:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=684
05/16/2022 16:11:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.94 on epoch=687
05/16/2022 16:12:00 - INFO - __main__ - Global step 2750 Train loss 0.96 Classification-F1 0.09090909090909091 on epoch=687
05/16/2022 16:12:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.04 on epoch=689
05/16/2022 16:12:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
05/16/2022 16:12:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.04 on epoch=694
05/16/2022 16:12:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.01 on epoch=697
05/16/2022 16:12:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
05/16/2022 16:12:07 - INFO - __main__ - Global step 2800 Train loss 1.02 Classification-F1 0.12368421052631579 on epoch=699
05/16/2022 16:12:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.06 on epoch=702
05/16/2022 16:12:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/16/2022 16:12:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.86 on epoch=707
05/16/2022 16:12:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/16/2022 16:12:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.03 on epoch=712
05/16/2022 16:12:15 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.10389610389610389 on epoch=712
05/16/2022 16:12:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/16/2022 16:12:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.94 on epoch=717
05/16/2022 16:12:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/16/2022 16:12:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.99 on epoch=722
05/16/2022 16:12:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/16/2022 16:12:22 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.09493670886075949 on epoch=724
05/16/2022 16:12:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.85 on epoch=727
05/16/2022 16:12:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/16/2022 16:12:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
05/16/2022 16:12:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/16/2022 16:12:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/16/2022 16:12:30 - INFO - __main__ - Global step 2950 Train loss 0.93 Classification-F1 0.1 on epoch=737
05/16/2022 16:12:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.90 on epoch=739
05/16/2022 16:12:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.94 on epoch=742
05/16/2022 16:12:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.00 on epoch=744
05/16/2022 16:12:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/16/2022 16:12:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/16/2022 16:12:37 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.1 on epoch=749
05/16/2022 16:12:37 - INFO - __main__ - save last model!
05/16/2022 16:12:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 16:12:37 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 16:12:37 - INFO - __main__ - Printing 3 examples
05/16/2022 16:12:37 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 16:12:37 - INFO - __main__ - ['others']
05/16/2022 16:12:37 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 16:12:37 - INFO - __main__ - ['others']
05/16/2022 16:12:37 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 16:12:37 - INFO - __main__ - ['others']
05/16/2022 16:12:37 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:12:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:12:38 - INFO - __main__ - Printing 3 examples
05/16/2022 16:12:38 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 16:12:38 - INFO - __main__ - ['happy']
05/16/2022 16:12:38 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 16:12:38 - INFO - __main__ - ['happy']
05/16/2022 16:12:38 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 16:12:38 - INFO - __main__ - ['happy']
05/16/2022 16:12:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:12:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:12:38 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:12:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:12:38 - INFO - __main__ - Printing 3 examples
05/16/2022 16:12:38 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 16:12:38 - INFO - __main__ - ['happy']
05/16/2022 16:12:38 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 16:12:38 - INFO - __main__ - ['happy']
05/16/2022 16:12:38 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 16:12:38 - INFO - __main__ - ['happy']
05/16/2022 16:12:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:12:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:12:38 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:12:40 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:12:44 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:12:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:12:45 - INFO - __main__ - Starting training!
05/16/2022 16:12:45 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 16:13:29 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.4_8_predictions.txt
05/16/2022 16:13:29 - INFO - __main__ - Classification-F1 on test data: 0.0332
05/16/2022 16:13:29 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.21765734265734268, test_performance=0.03324837737583468
05/16/2022 16:13:29 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
05/16/2022 16:13:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:13:30 - INFO - __main__ - Printing 3 examples
05/16/2022 16:13:30 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 16:13:30 - INFO - __main__ - ['happy']
05/16/2022 16:13:30 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 16:13:30 - INFO - __main__ - ['happy']
05/16/2022 16:13:30 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 16:13:30 - INFO - __main__ - ['happy']
05/16/2022 16:13:30 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:13:30 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:13:30 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:13:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:13:30 - INFO - __main__ - Printing 3 examples
05/16/2022 16:13:30 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 16:13:30 - INFO - __main__ - ['happy']
05/16/2022 16:13:30 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 16:13:30 - INFO - __main__ - ['happy']
05/16/2022 16:13:30 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 16:13:30 - INFO - __main__ - ['happy']
05/16/2022 16:13:30 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:13:30 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:13:30 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:13:36 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:13:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:13:36 - INFO - __main__ - Starting training!
05/16/2022 16:13:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=2
05/16/2022 16:13:39 - INFO - __main__ - Step 20 Global step 20 Train loss 6.42 on epoch=4
05/16/2022 16:13:41 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=7
05/16/2022 16:13:42 - INFO - __main__ - Step 40 Global step 40 Train loss 6.17 on epoch=9
05/16/2022 16:13:44 - INFO - __main__ - Step 50 Global step 50 Train loss 6.12 on epoch=12
05/16/2022 16:13:48 - INFO - __main__ - Global step 50 Train loss 6.37 Classification-F1 0.0 on epoch=12
05/16/2022 16:13:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 16:13:49 - INFO - __main__ - Step 60 Global step 60 Train loss 5.97 on epoch=14
05/16/2022 16:13:51 - INFO - __main__ - Step 70 Global step 70 Train loss 5.74 on epoch=17
05/16/2022 16:13:52 - INFO - __main__ - Step 80 Global step 80 Train loss 5.52 on epoch=19
05/16/2022 16:13:53 - INFO - __main__ - Step 90 Global step 90 Train loss 5.44 on epoch=22
05/16/2022 16:13:55 - INFO - __main__ - Step 100 Global step 100 Train loss 5.18 on epoch=24
05/16/2022 16:13:56 - INFO - __main__ - Global step 100 Train loss 5.57 Classification-F1 0.0 on epoch=24
05/16/2022 16:13:57 - INFO - __main__ - Step 110 Global step 110 Train loss 5.20 on epoch=27
05/16/2022 16:13:59 - INFO - __main__ - Step 120 Global step 120 Train loss 4.90 on epoch=29
05/16/2022 16:14:00 - INFO - __main__ - Step 130 Global step 130 Train loss 4.80 on epoch=32
05/16/2022 16:14:01 - INFO - __main__ - Step 140 Global step 140 Train loss 4.58 on epoch=34
05/16/2022 16:14:03 - INFO - __main__ - Step 150 Global step 150 Train loss 4.52 on epoch=37
05/16/2022 16:14:04 - INFO - __main__ - Global step 150 Train loss 4.80 Classification-F1 0.02886002886002886 on epoch=37
05/16/2022 16:14:04 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.02886002886002886 on epoch=37, global_step=150
05/16/2022 16:14:05 - INFO - __main__ - Step 160 Global step 160 Train loss 4.26 on epoch=39
05/16/2022 16:14:07 - INFO - __main__ - Step 170 Global step 170 Train loss 4.23 on epoch=42
05/16/2022 16:14:08 - INFO - __main__ - Step 180 Global step 180 Train loss 4.15 on epoch=44
05/16/2022 16:14:09 - INFO - __main__ - Step 190 Global step 190 Train loss 4.00 on epoch=47
05/16/2022 16:14:11 - INFO - __main__ - Step 200 Global step 200 Train loss 3.90 on epoch=49
05/16/2022 16:14:11 - INFO - __main__ - Global step 200 Train loss 4.11 Classification-F1 0.07792207792207792 on epoch=49
05/16/2022 16:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.02886002886002886 -> 0.07792207792207792 on epoch=49, global_step=200
05/16/2022 16:14:13 - INFO - __main__ - Step 210 Global step 210 Train loss 3.61 on epoch=52
05/16/2022 16:14:14 - INFO - __main__ - Step 220 Global step 220 Train loss 3.62 on epoch=54
05/16/2022 16:14:15 - INFO - __main__ - Step 230 Global step 230 Train loss 3.43 on epoch=57
05/16/2022 16:14:17 - INFO - __main__ - Step 240 Global step 240 Train loss 3.45 on epoch=59
05/16/2022 16:14:18 - INFO - __main__ - Step 250 Global step 250 Train loss 3.14 on epoch=62
05/16/2022 16:14:19 - INFO - __main__ - Global step 250 Train loss 3.45 Classification-F1 0.17344312918167784 on epoch=62
05/16/2022 16:14:19 - INFO - __main__ - Saving model with best Classification-F1: 0.07792207792207792 -> 0.17344312918167784 on epoch=62, global_step=250
05/16/2022 16:14:20 - INFO - __main__ - Step 260 Global step 260 Train loss 3.21 on epoch=64
05/16/2022 16:14:21 - INFO - __main__ - Step 270 Global step 270 Train loss 3.26 on epoch=67
05/16/2022 16:14:23 - INFO - __main__ - Step 280 Global step 280 Train loss 3.07 on epoch=69
05/16/2022 16:14:24 - INFO - __main__ - Step 290 Global step 290 Train loss 3.02 on epoch=72
05/16/2022 16:14:26 - INFO - __main__ - Step 300 Global step 300 Train loss 3.02 on epoch=74
05/16/2022 16:14:26 - INFO - __main__ - Global step 300 Train loss 3.11 Classification-F1 0.1 on epoch=74
05/16/2022 16:14:28 - INFO - __main__ - Step 310 Global step 310 Train loss 2.81 on epoch=77
05/16/2022 16:14:29 - INFO - __main__ - Step 320 Global step 320 Train loss 2.90 on epoch=79
05/16/2022 16:14:30 - INFO - __main__ - Step 330 Global step 330 Train loss 2.69 on epoch=82
05/16/2022 16:14:32 - INFO - __main__ - Step 340 Global step 340 Train loss 2.80 on epoch=84
05/16/2022 16:14:33 - INFO - __main__ - Step 350 Global step 350 Train loss 2.67 on epoch=87
05/16/2022 16:14:34 - INFO - __main__ - Global step 350 Train loss 2.77 Classification-F1 0.1468058968058968 on epoch=87
05/16/2022 16:14:35 - INFO - __main__ - Step 360 Global step 360 Train loss 2.69 on epoch=89
05/16/2022 16:14:36 - INFO - __main__ - Step 370 Global step 370 Train loss 2.63 on epoch=92
05/16/2022 16:14:38 - INFO - __main__ - Step 380 Global step 380 Train loss 2.80 on epoch=94
05/16/2022 16:14:39 - INFO - __main__ - Step 390 Global step 390 Train loss 2.21 on epoch=97
05/16/2022 16:14:40 - INFO - __main__ - Step 400 Global step 400 Train loss 2.62 on epoch=99
05/16/2022 16:14:41 - INFO - __main__ - Global step 400 Train loss 2.59 Classification-F1 0.16483516483516486 on epoch=99
05/16/2022 16:14:42 - INFO - __main__ - Step 410 Global step 410 Train loss 2.41 on epoch=102
05/16/2022 16:14:44 - INFO - __main__ - Step 420 Global step 420 Train loss 2.40 on epoch=104
05/16/2022 16:14:45 - INFO - __main__ - Step 430 Global step 430 Train loss 2.27 on epoch=107
05/16/2022 16:14:46 - INFO - __main__ - Step 440 Global step 440 Train loss 2.39 on epoch=109
05/16/2022 16:14:48 - INFO - __main__ - Step 450 Global step 450 Train loss 2.44 on epoch=112
05/16/2022 16:14:48 - INFO - __main__ - Global step 450 Train loss 2.38 Classification-F1 0.15682382133995038 on epoch=112
05/16/2022 16:14:50 - INFO - __main__ - Step 460 Global step 460 Train loss 2.49 on epoch=114
05/16/2022 16:14:51 - INFO - __main__ - Step 470 Global step 470 Train loss 2.40 on epoch=117
05/16/2022 16:14:52 - INFO - __main__ - Step 480 Global step 480 Train loss 2.34 on epoch=119
05/16/2022 16:14:54 - INFO - __main__ - Step 490 Global step 490 Train loss 2.20 on epoch=122
05/16/2022 16:14:55 - INFO - __main__ - Step 500 Global step 500 Train loss 2.17 on epoch=124
05/16/2022 16:14:56 - INFO - __main__ - Global step 500 Train loss 2.32 Classification-F1 0.17317073170731706 on epoch=124
05/16/2022 16:14:57 - INFO - __main__ - Step 510 Global step 510 Train loss 2.39 on epoch=127
05/16/2022 16:14:58 - INFO - __main__ - Step 520 Global step 520 Train loss 2.21 on epoch=129
05/16/2022 16:15:00 - INFO - __main__ - Step 530 Global step 530 Train loss 2.10 on epoch=132
05/16/2022 16:15:01 - INFO - __main__ - Step 540 Global step 540 Train loss 2.25 on epoch=134
05/16/2022 16:15:02 - INFO - __main__ - Step 550 Global step 550 Train loss 1.81 on epoch=137
05/16/2022 16:15:03 - INFO - __main__ - Global step 550 Train loss 2.15 Classification-F1 0.15559772296015179 on epoch=137
05/16/2022 16:15:04 - INFO - __main__ - Step 560 Global step 560 Train loss 2.09 on epoch=139
05/16/2022 16:15:05 - INFO - __main__ - Step 570 Global step 570 Train loss 2.03 on epoch=142
05/16/2022 16:15:07 - INFO - __main__ - Step 580 Global step 580 Train loss 2.17 on epoch=144
05/16/2022 16:15:08 - INFO - __main__ - Step 590 Global step 590 Train loss 2.10 on epoch=147
05/16/2022 16:15:09 - INFO - __main__ - Step 600 Global step 600 Train loss 2.06 on epoch=149
05/16/2022 16:15:10 - INFO - __main__ - Global step 600 Train loss 2.09 Classification-F1 0.17372070779531323 on epoch=149
05/16/2022 16:15:10 - INFO - __main__ - Saving model with best Classification-F1: 0.17344312918167784 -> 0.17372070779531323 on epoch=149, global_step=600
05/16/2022 16:15:11 - INFO - __main__ - Step 610 Global step 610 Train loss 2.01 on epoch=152
05/16/2022 16:15:13 - INFO - __main__ - Step 620 Global step 620 Train loss 2.13 on epoch=154
05/16/2022 16:15:14 - INFO - __main__ - Step 630 Global step 630 Train loss 1.87 on epoch=157
05/16/2022 16:15:15 - INFO - __main__ - Step 640 Global step 640 Train loss 2.07 on epoch=159
05/16/2022 16:15:17 - INFO - __main__ - Step 650 Global step 650 Train loss 1.93 on epoch=162
05/16/2022 16:15:17 - INFO - __main__ - Global step 650 Train loss 2.00 Classification-F1 0.18026315789473685 on epoch=162
05/16/2022 16:15:17 - INFO - __main__ - Saving model with best Classification-F1: 0.17372070779531323 -> 0.18026315789473685 on epoch=162, global_step=650
05/16/2022 16:15:19 - INFO - __main__ - Step 660 Global step 660 Train loss 1.93 on epoch=164
05/16/2022 16:15:20 - INFO - __main__ - Step 670 Global step 670 Train loss 1.94 on epoch=167
05/16/2022 16:15:21 - INFO - __main__ - Step 680 Global step 680 Train loss 2.06 on epoch=169
05/16/2022 16:15:23 - INFO - __main__ - Step 690 Global step 690 Train loss 1.77 on epoch=172
05/16/2022 16:15:24 - INFO - __main__ - Step 700 Global step 700 Train loss 1.81 on epoch=174
05/16/2022 16:15:24 - INFO - __main__ - Global step 700 Train loss 1.90 Classification-F1 0.15339578454332553 on epoch=174
05/16/2022 16:15:26 - INFO - __main__ - Step 710 Global step 710 Train loss 1.67 on epoch=177
05/16/2022 16:15:27 - INFO - __main__ - Step 720 Global step 720 Train loss 1.73 on epoch=179
05/16/2022 16:15:28 - INFO - __main__ - Step 730 Global step 730 Train loss 1.70 on epoch=182
05/16/2022 16:15:30 - INFO - __main__ - Step 740 Global step 740 Train loss 1.76 on epoch=184
05/16/2022 16:15:31 - INFO - __main__ - Step 750 Global step 750 Train loss 1.60 on epoch=187
05/16/2022 16:15:32 - INFO - __main__ - Global step 750 Train loss 1.69 Classification-F1 0.1 on epoch=187
05/16/2022 16:15:33 - INFO - __main__ - Step 760 Global step 760 Train loss 1.73 on epoch=189
05/16/2022 16:15:34 - INFO - __main__ - Step 770 Global step 770 Train loss 1.61 on epoch=192
05/16/2022 16:15:36 - INFO - __main__ - Step 780 Global step 780 Train loss 1.60 on epoch=194
05/16/2022 16:15:37 - INFO - __main__ - Step 790 Global step 790 Train loss 1.39 on epoch=197
05/16/2022 16:15:39 - INFO - __main__ - Step 800 Global step 800 Train loss 1.55 on epoch=199
05/16/2022 16:15:39 - INFO - __main__ - Global step 800 Train loss 1.58 Classification-F1 0.1237183868762816 on epoch=199
05/16/2022 16:15:40 - INFO - __main__ - Step 810 Global step 810 Train loss 1.38 on epoch=202
05/16/2022 16:15:42 - INFO - __main__ - Step 820 Global step 820 Train loss 1.63 on epoch=204
05/16/2022 16:15:43 - INFO - __main__ - Step 830 Global step 830 Train loss 1.60 on epoch=207
05/16/2022 16:15:44 - INFO - __main__ - Step 840 Global step 840 Train loss 1.49 on epoch=209
05/16/2022 16:15:46 - INFO - __main__ - Step 850 Global step 850 Train loss 1.41 on epoch=212
05/16/2022 16:15:46 - INFO - __main__ - Global step 850 Train loss 1.50 Classification-F1 0.10126582278481013 on epoch=212
05/16/2022 16:15:48 - INFO - __main__ - Step 860 Global step 860 Train loss 1.57 on epoch=214
05/16/2022 16:15:49 - INFO - __main__ - Step 870 Global step 870 Train loss 1.52 on epoch=217
05/16/2022 16:15:51 - INFO - __main__ - Step 880 Global step 880 Train loss 1.38 on epoch=219
05/16/2022 16:15:52 - INFO - __main__ - Step 890 Global step 890 Train loss 1.32 on epoch=222
05/16/2022 16:15:53 - INFO - __main__ - Step 900 Global step 900 Train loss 1.32 on epoch=224
05/16/2022 16:15:54 - INFO - __main__ - Global step 900 Train loss 1.42 Classification-F1 0.0974025974025974 on epoch=224
05/16/2022 16:15:55 - INFO - __main__ - Step 910 Global step 910 Train loss 1.31 on epoch=227
05/16/2022 16:15:57 - INFO - __main__ - Step 920 Global step 920 Train loss 1.47 on epoch=229
05/16/2022 16:15:58 - INFO - __main__ - Step 930 Global step 930 Train loss 1.34 on epoch=232
05/16/2022 16:15:59 - INFO - __main__ - Step 940 Global step 940 Train loss 1.47 on epoch=234
05/16/2022 16:16:01 - INFO - __main__ - Step 950 Global step 950 Train loss 1.34 on epoch=237
05/16/2022 16:16:01 - INFO - __main__ - Global step 950 Train loss 1.39 Classification-F1 0.11425630468347914 on epoch=237
05/16/2022 16:16:03 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
05/16/2022 16:16:04 - INFO - __main__ - Step 970 Global step 970 Train loss 1.41 on epoch=242
05/16/2022 16:16:06 - INFO - __main__ - Step 980 Global step 980 Train loss 1.60 on epoch=244
05/16/2022 16:16:07 - INFO - __main__ - Step 990 Global step 990 Train loss 1.22 on epoch=247
05/16/2022 16:16:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.29 on epoch=249
05/16/2022 16:16:09 - INFO - __main__ - Global step 1000 Train loss 1.38 Classification-F1 0.1 on epoch=249
05/16/2022 16:16:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/16/2022 16:16:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.17 on epoch=254
05/16/2022 16:16:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.26 on epoch=257
05/16/2022 16:16:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.24 on epoch=259
05/16/2022 16:16:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.41 on epoch=262
05/16/2022 16:16:16 - INFO - __main__ - Global step 1050 Train loss 1.29 Classification-F1 0.1856338028169014 on epoch=262
05/16/2022 16:16:16 - INFO - __main__ - Saving model with best Classification-F1: 0.18026315789473685 -> 0.1856338028169014 on epoch=262, global_step=1050
05/16/2022 16:16:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.47 on epoch=264
05/16/2022 16:16:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.27 on epoch=267
05/16/2022 16:16:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/16/2022 16:16:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.26 on epoch=272
05/16/2022 16:16:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.31 on epoch=274
05/16/2022 16:16:23 - INFO - __main__ - Global step 1100 Train loss 1.31 Classification-F1 0.1081081081081081 on epoch=274
05/16/2022 16:16:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.38 on epoch=277
05/16/2022 16:16:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.25 on epoch=279
05/16/2022 16:16:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.30 on epoch=282
05/16/2022 16:16:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.51 on epoch=284
05/16/2022 16:16:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.19 on epoch=287
05/16/2022 16:16:31 - INFO - __main__ - Global step 1150 Train loss 1.33 Classification-F1 0.1 on epoch=287
05/16/2022 16:16:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.16 on epoch=289
05/16/2022 16:16:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.24 on epoch=292
05/16/2022 16:16:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.24 on epoch=294
05/16/2022 16:16:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.41 on epoch=297
05/16/2022 16:16:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.44 on epoch=299
05/16/2022 16:16:38 - INFO - __main__ - Global step 1200 Train loss 1.30 Classification-F1 0.10126582278481013 on epoch=299
05/16/2022 16:16:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.27 on epoch=302
05/16/2022 16:16:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.35 on epoch=304
05/16/2022 16:16:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.27 on epoch=307
05/16/2022 16:16:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.16 on epoch=309
05/16/2022 16:16:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.27 on epoch=312
05/16/2022 16:16:46 - INFO - __main__ - Global step 1250 Train loss 1.26 Classification-F1 0.16110780226325194 on epoch=312
05/16/2022 16:16:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
05/16/2022 16:16:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.28 on epoch=317
05/16/2022 16:16:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.27 on epoch=319
05/16/2022 16:16:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.30 on epoch=322
05/16/2022 16:16:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.20 on epoch=324
05/16/2022 16:16:53 - INFO - __main__ - Global step 1300 Train loss 1.27 Classification-F1 0.1 on epoch=324
05/16/2022 16:16:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.13 on epoch=327
05/16/2022 16:16:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.16 on epoch=329
05/16/2022 16:16:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=332
05/16/2022 16:16:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.29 on epoch=334
05/16/2022 16:17:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.21 on epoch=337
05/16/2022 16:17:00 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.1 on epoch=337
05/16/2022 16:17:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/16/2022 16:17:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
05/16/2022 16:17:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=344
05/16/2022 16:17:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
05/16/2022 16:17:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/16/2022 16:17:07 - INFO - __main__ - Global step 1400 Train loss 1.13 Classification-F1 0.14560439560439564 on epoch=349
05/16/2022 16:17:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.25 on epoch=352
05/16/2022 16:17:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.22 on epoch=354
05/16/2022 16:17:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.13 on epoch=357
05/16/2022 16:17:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.10 on epoch=359
05/16/2022 16:17:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.18 on epoch=362
05/16/2022 16:17:14 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.1 on epoch=362
05/16/2022 16:17:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.11 on epoch=364
05/16/2022 16:17:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.31 on epoch=367
05/16/2022 16:17:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/16/2022 16:17:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.03 on epoch=372
05/16/2022 16:17:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.20 on epoch=374
05/16/2022 16:17:22 - INFO - __main__ - Global step 1500 Train loss 1.16 Classification-F1 0.1 on epoch=374
05/16/2022 16:17:23 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.09 on epoch=377
05/16/2022 16:17:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.21 on epoch=379
05/16/2022 16:17:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.10 on epoch=382
05/16/2022 16:17:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.09 on epoch=384
05/16/2022 16:17:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.09 on epoch=387
05/16/2022 16:17:29 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.13067758749069247 on epoch=387
05/16/2022 16:17:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.03 on epoch=389
05/16/2022 16:17:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.06 on epoch=392
05/16/2022 16:17:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
05/16/2022 16:17:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.17 on epoch=397
05/16/2022 16:17:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=399
05/16/2022 16:17:37 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.10126582278481013 on epoch=399
05/16/2022 16:17:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.07 on epoch=402
05/16/2022 16:17:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.06 on epoch=404
05/16/2022 16:17:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.21 on epoch=407
05/16/2022 16:17:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/16/2022 16:17:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.04 on epoch=412
05/16/2022 16:17:44 - INFO - __main__ - Global step 1650 Train loss 1.08 Classification-F1 0.1 on epoch=412
05/16/2022 16:17:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.08 on epoch=414
05/16/2022 16:17:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.99 on epoch=417
05/16/2022 16:17:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.07 on epoch=419
05/16/2022 16:17:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.15 on epoch=422
05/16/2022 16:17:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.99 on epoch=424
05/16/2022 16:17:51 - INFO - __main__ - Global step 1700 Train loss 1.05 Classification-F1 0.15306730196545562 on epoch=424
05/16/2022 16:17:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.16 on epoch=427
05/16/2022 16:17:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.96 on epoch=429
05/16/2022 16:17:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.98 on epoch=432
05/16/2022 16:17:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.97 on epoch=434
05/16/2022 16:17:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.18 on epoch=437
05/16/2022 16:17:58 - INFO - __main__ - Global step 1750 Train loss 1.05 Classification-F1 0.1 on epoch=437
05/16/2022 16:17:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.14 on epoch=439
05/16/2022 16:18:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.10 on epoch=442
05/16/2022 16:18:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
05/16/2022 16:18:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.24 on epoch=447
05/16/2022 16:18:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
05/16/2022 16:18:06 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.17737733391228833 on epoch=449
05/16/2022 16:18:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
05/16/2022 16:18:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/16/2022 16:18:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.05 on epoch=457
05/16/2022 16:18:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.24 on epoch=459
05/16/2022 16:18:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.11 on epoch=462
05/16/2022 16:18:13 - INFO - __main__ - Global step 1850 Train loss 1.11 Classification-F1 0.1782106782106782 on epoch=462
05/16/2022 16:18:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.14 on epoch=464
05/16/2022 16:18:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.19 on epoch=467
05/16/2022 16:18:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.10 on epoch=469
05/16/2022 16:18:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
05/16/2022 16:18:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=474
05/16/2022 16:18:20 - INFO - __main__ - Global step 1900 Train loss 1.10 Classification-F1 0.1762899262899263 on epoch=474
05/16/2022 16:18:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.02 on epoch=477
05/16/2022 16:18:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.09 on epoch=479
05/16/2022 16:18:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.02 on epoch=482
05/16/2022 16:18:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.19 on epoch=484
05/16/2022 16:18:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.13 on epoch=487
05/16/2022 16:18:27 - INFO - __main__ - Global step 1950 Train loss 1.09 Classification-F1 0.13333333333333333 on epoch=487
05/16/2022 16:18:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.07 on epoch=489
05/16/2022 16:18:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=492
05/16/2022 16:18:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.09 on epoch=494
05/16/2022 16:18:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
05/16/2022 16:18:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.99 on epoch=499
05/16/2022 16:18:34 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.1 on epoch=499
05/16/2022 16:18:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.07 on epoch=502
05/16/2022 16:18:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.07 on epoch=504
05/16/2022 16:18:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
05/16/2022 16:18:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.16 on epoch=509
05/16/2022 16:18:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.98 on epoch=512
05/16/2022 16:18:42 - INFO - __main__ - Global step 2050 Train loss 1.06 Classification-F1 0.14004914004914004 on epoch=512
05/16/2022 16:18:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.07 on epoch=514
05/16/2022 16:18:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/16/2022 16:18:46 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.12 on epoch=519
05/16/2022 16:18:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.07 on epoch=522
05/16/2022 16:18:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
05/16/2022 16:18:49 - INFO - __main__ - Global step 2100 Train loss 1.08 Classification-F1 0.1527777777777778 on epoch=524
05/16/2022 16:18:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.96 on epoch=527
05/16/2022 16:18:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.06 on epoch=529
05/16/2022 16:18:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.14 on epoch=532
05/16/2022 16:18:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.07 on epoch=534
05/16/2022 16:18:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.11 on epoch=537
05/16/2022 16:18:56 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.1576923076923077 on epoch=537
05/16/2022 16:18:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.01 on epoch=539
05/16/2022 16:18:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.02 on epoch=542
05/16/2022 16:19:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.97 on epoch=544
05/16/2022 16:19:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=547
05/16/2022 16:19:02 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.99 on epoch=549
05/16/2022 16:19:03 - INFO - __main__ - Global step 2200 Train loss 1.00 Classification-F1 0.1402116402116402 on epoch=549
05/16/2022 16:19:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/16/2022 16:19:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/16/2022 16:19:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.07 on epoch=557
05/16/2022 16:19:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
05/16/2022 16:19:09 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
05/16/2022 16:19:10 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.20219168748580513 on epoch=562
05/16/2022 16:19:10 - INFO - __main__ - Saving model with best Classification-F1: 0.1856338028169014 -> 0.20219168748580513 on epoch=562, global_step=2250
05/16/2022 16:19:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/16/2022 16:19:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.98 on epoch=567
05/16/2022 16:19:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/16/2022 16:19:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/16/2022 16:19:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.00 on epoch=574
05/16/2022 16:19:17 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.12077294685990338 on epoch=574
05/16/2022 16:19:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/16/2022 16:19:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/16/2022 16:19:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.92 on epoch=582
05/16/2022 16:19:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/16/2022 16:19:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/16/2022 16:19:24 - INFO - __main__ - Global step 2350 Train loss 0.96 Classification-F1 0.13445378151260504 on epoch=587
05/16/2022 16:19:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.98 on epoch=589
05/16/2022 16:19:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=592
05/16/2022 16:19:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.05 on epoch=594
05/16/2022 16:19:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/16/2022 16:19:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=599
05/16/2022 16:19:32 - INFO - __main__ - Global step 2400 Train loss 0.99 Classification-F1 0.06060606060606061 on epoch=599
05/16/2022 16:19:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
05/16/2022 16:19:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/16/2022 16:19:36 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
05/16/2022 16:19:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.02 on epoch=609
05/16/2022 16:19:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.05 on epoch=612
05/16/2022 16:19:39 - INFO - __main__ - Global step 2450 Train loss 1.01 Classification-F1 0.22004608294930872 on epoch=612
05/16/2022 16:19:39 - INFO - __main__ - Saving model with best Classification-F1: 0.20219168748580513 -> 0.22004608294930872 on epoch=612, global_step=2450
05/16/2022 16:19:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
05/16/2022 16:19:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.04 on epoch=617
05/16/2022 16:19:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/16/2022 16:19:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/16/2022 16:19:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
05/16/2022 16:19:46 - INFO - __main__ - Global step 2500 Train loss 1.07 Classification-F1 0.10256410256410256 on epoch=624
05/16/2022 16:19:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.05 on epoch=627
05/16/2022 16:19:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.12 on epoch=629
05/16/2022 16:19:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.07 on epoch=632
05/16/2022 16:19:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.94 on epoch=634
05/16/2022 16:19:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/16/2022 16:19:54 - INFO - __main__ - Global step 2550 Train loss 1.04 Classification-F1 0.1 on epoch=637
05/16/2022 16:19:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.05 on epoch=639
05/16/2022 16:19:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.92 on epoch=642
05/16/2022 16:19:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.11 on epoch=644
05/16/2022 16:19:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.05 on epoch=647
05/16/2022 16:20:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/16/2022 16:20:00 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.12681436210847974 on epoch=649
05/16/2022 16:20:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.07 on epoch=652
05/16/2022 16:20:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.01 on epoch=654
05/16/2022 16:20:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
05/16/2022 16:20:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.02 on epoch=659
05/16/2022 16:20:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.06 on epoch=662
05/16/2022 16:20:08 - INFO - __main__ - Global step 2650 Train loss 1.04 Classification-F1 0.1 on epoch=662
05/16/2022 16:20:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.00 on epoch=664
05/16/2022 16:20:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
05/16/2022 16:20:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
05/16/2022 16:20:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.90 on epoch=672
05/16/2022 16:20:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
05/16/2022 16:20:15 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
05/16/2022 16:20:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/16/2022 16:20:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.07 on epoch=679
05/16/2022 16:20:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.98 on epoch=682
05/16/2022 16:20:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.90 on epoch=684
05/16/2022 16:20:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/16/2022 16:20:23 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.09493670886075949 on epoch=687
05/16/2022 16:20:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.05 on epoch=689
05/16/2022 16:20:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/16/2022 16:20:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.07 on epoch=694
05/16/2022 16:20:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
05/16/2022 16:20:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.05 on epoch=699
05/16/2022 16:20:30 - INFO - __main__ - Global step 2800 Train loss 1.03 Classification-F1 0.17028824833702882 on epoch=699
05/16/2022 16:20:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.97 on epoch=702
05/16/2022 16:20:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.11 on epoch=704
05/16/2022 16:20:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/16/2022 16:20:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/16/2022 16:20:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
05/16/2022 16:20:37 - INFO - __main__ - Global step 2850 Train loss 0.99 Classification-F1 0.17798594847775173 on epoch=712
05/16/2022 16:20:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
05/16/2022 16:20:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.93 on epoch=717
05/16/2022 16:20:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/16/2022 16:20:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.99 on epoch=722
05/16/2022 16:20:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/16/2022 16:20:44 - INFO - __main__ - Global step 2900 Train loss 0.96 Classification-F1 0.11094819159335288 on epoch=724
05/16/2022 16:20:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/16/2022 16:20:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.96 on epoch=729
05/16/2022 16:20:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
05/16/2022 16:20:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
05/16/2022 16:20:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.02 on epoch=737
05/16/2022 16:20:51 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.14915966386554622 on epoch=737
05/16/2022 16:20:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/16/2022 16:20:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.05 on epoch=742
05/16/2022 16:20:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
05/16/2022 16:20:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
05/16/2022 16:20:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.01 on epoch=749
05/16/2022 16:20:58 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.11732186732186733 on epoch=749
05/16/2022 16:20:58 - INFO - __main__ - save last model!
05/16/2022 16:20:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 16:20:58 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 16:20:58 - INFO - __main__ - Printing 3 examples
05/16/2022 16:20:58 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 16:20:58 - INFO - __main__ - ['others']
05/16/2022 16:20:58 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 16:20:58 - INFO - __main__ - ['others']
05/16/2022 16:20:58 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 16:20:58 - INFO - __main__ - ['others']
05/16/2022 16:20:58 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:20:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:20:59 - INFO - __main__ - Printing 3 examples
05/16/2022 16:20:59 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 16:20:59 - INFO - __main__ - ['happy']
05/16/2022 16:20:59 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 16:20:59 - INFO - __main__ - ['happy']
05/16/2022 16:20:59 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 16:20:59 - INFO - __main__ - ['happy']
05/16/2022 16:20:59 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:20:59 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:20:59 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:20:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:20:59 - INFO - __main__ - Printing 3 examples
05/16/2022 16:20:59 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 16:20:59 - INFO - __main__ - ['happy']
05/16/2022 16:20:59 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 16:20:59 - INFO - __main__ - ['happy']
05/16/2022 16:20:59 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 16:20:59 - INFO - __main__ - ['happy']
05/16/2022 16:20:59 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:20:59 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:20:59 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:21:00 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:21:05 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:21:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:21:05 - INFO - __main__ - Starting training!
05/16/2022 16:21:07 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 16:21:52 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.3_8_predictions.txt
05/16/2022 16:21:52 - INFO - __main__ - Classification-F1 on test data: 0.0404
05/16/2022 16:21:52 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.22004608294930872, test_performance=0.04041940527737243
05/16/2022 16:21:52 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
05/16/2022 16:21:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:21:53 - INFO - __main__ - Printing 3 examples
05/16/2022 16:21:53 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/16/2022 16:21:53 - INFO - __main__ - ['happy']
05/16/2022 16:21:53 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/16/2022 16:21:53 - INFO - __main__ - ['happy']
05/16/2022 16:21:53 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/16/2022 16:21:53 - INFO - __main__ - ['happy']
05/16/2022 16:21:53 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:21:53 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:21:53 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:21:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:21:53 - INFO - __main__ - Printing 3 examples
05/16/2022 16:21:53 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/16/2022 16:21:53 - INFO - __main__ - ['happy']
05/16/2022 16:21:53 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/16/2022 16:21:53 - INFO - __main__ - ['happy']
05/16/2022 16:21:53 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/16/2022 16:21:53 - INFO - __main__ - ['happy']
05/16/2022 16:21:53 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:21:53 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:21:53 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:21:59 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:21:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:21:59 - INFO - __main__ - Starting training!
05/16/2022 16:22:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.63 on epoch=2
05/16/2022 16:22:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/16/2022 16:22:04 - INFO - __main__ - Step 30 Global step 30 Train loss 6.55 on epoch=7
05/16/2022 16:22:05 - INFO - __main__ - Step 40 Global step 40 Train loss 6.37 on epoch=9
05/16/2022 16:22:06 - INFO - __main__ - Step 50 Global step 50 Train loss 6.17 on epoch=12
05/16/2022 16:22:14 - INFO - __main__ - Global step 50 Train loss 6.46 Classification-F1 0.0 on epoch=12
05/16/2022 16:22:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 16:22:16 - INFO - __main__ - Step 60 Global step 60 Train loss 6.25 on epoch=14
05/16/2022 16:22:17 - INFO - __main__ - Step 70 Global step 70 Train loss 6.01 on epoch=17
05/16/2022 16:22:18 - INFO - __main__ - Step 80 Global step 80 Train loss 5.95 on epoch=19
05/16/2022 16:22:20 - INFO - __main__ - Step 90 Global step 90 Train loss 5.85 on epoch=22
05/16/2022 16:22:21 - INFO - __main__ - Step 100 Global step 100 Train loss 5.68 on epoch=24
05/16/2022 16:22:23 - INFO - __main__ - Global step 100 Train loss 5.95 Classification-F1 0.0 on epoch=24
05/16/2022 16:22:24 - INFO - __main__ - Step 110 Global step 110 Train loss 5.65 on epoch=27
05/16/2022 16:22:25 - INFO - __main__ - Step 120 Global step 120 Train loss 5.60 on epoch=29
05/16/2022 16:22:27 - INFO - __main__ - Step 130 Global step 130 Train loss 5.51 on epoch=32
05/16/2022 16:22:28 - INFO - __main__ - Step 140 Global step 140 Train loss 5.45 on epoch=34
05/16/2022 16:22:29 - INFO - __main__ - Step 150 Global step 150 Train loss 5.33 on epoch=37
05/16/2022 16:22:31 - INFO - __main__ - Global step 150 Train loss 5.51 Classification-F1 0.0 on epoch=37
05/16/2022 16:22:32 - INFO - __main__ - Step 160 Global step 160 Train loss 5.24 on epoch=39
05/16/2022 16:22:33 - INFO - __main__ - Step 170 Global step 170 Train loss 5.27 on epoch=42
05/16/2022 16:22:35 - INFO - __main__ - Step 180 Global step 180 Train loss 4.89 on epoch=44
05/16/2022 16:22:36 - INFO - __main__ - Step 190 Global step 190 Train loss 4.88 on epoch=47
05/16/2022 16:22:37 - INFO - __main__ - Step 200 Global step 200 Train loss 4.81 on epoch=49
05/16/2022 16:22:39 - INFO - __main__ - Global step 200 Train loss 5.02 Classification-F1 0.0 on epoch=49
05/16/2022 16:22:41 - INFO - __main__ - Step 210 Global step 210 Train loss 4.58 on epoch=52
05/16/2022 16:22:42 - INFO - __main__ - Step 220 Global step 220 Train loss 4.68 on epoch=54
05/16/2022 16:22:43 - INFO - __main__ - Step 230 Global step 230 Train loss 4.25 on epoch=57
05/16/2022 16:22:44 - INFO - __main__ - Step 240 Global step 240 Train loss 4.46 on epoch=59
05/16/2022 16:22:46 - INFO - __main__ - Step 250 Global step 250 Train loss 4.29 on epoch=62
05/16/2022 16:22:46 - INFO - __main__ - Global step 250 Train loss 4.45 Classification-F1 0.0810126582278481 on epoch=62
05/16/2022 16:22:46 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0810126582278481 on epoch=62, global_step=250
05/16/2022 16:22:48 - INFO - __main__ - Step 260 Global step 260 Train loss 4.21 on epoch=64
05/16/2022 16:22:49 - INFO - __main__ - Step 270 Global step 270 Train loss 4.04 on epoch=67
05/16/2022 16:22:51 - INFO - __main__ - Step 280 Global step 280 Train loss 4.07 on epoch=69
05/16/2022 16:22:52 - INFO - __main__ - Step 290 Global step 290 Train loss 3.94 on epoch=72
05/16/2022 16:22:53 - INFO - __main__ - Step 300 Global step 300 Train loss 3.88 on epoch=74
05/16/2022 16:22:54 - INFO - __main__ - Global step 300 Train loss 4.03 Classification-F1 0.10199240986717267 on epoch=74
05/16/2022 16:22:54 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.10199240986717267 on epoch=74, global_step=300
05/16/2022 16:22:55 - INFO - __main__ - Step 310 Global step 310 Train loss 3.59 on epoch=77
05/16/2022 16:22:56 - INFO - __main__ - Step 320 Global step 320 Train loss 3.75 on epoch=79
05/16/2022 16:22:58 - INFO - __main__ - Step 330 Global step 330 Train loss 3.76 on epoch=82
05/16/2022 16:22:59 - INFO - __main__ - Step 340 Global step 340 Train loss 3.76 on epoch=84
05/16/2022 16:23:00 - INFO - __main__ - Step 350 Global step 350 Train loss 3.48 on epoch=87
05/16/2022 16:23:01 - INFO - __main__ - Global step 350 Train loss 3.67 Classification-F1 0.11300097751710654 on epoch=87
05/16/2022 16:23:01 - INFO - __main__ - Saving model with best Classification-F1: 0.10199240986717267 -> 0.11300097751710654 on epoch=87, global_step=350
05/16/2022 16:23:02 - INFO - __main__ - Step 360 Global step 360 Train loss 3.56 on epoch=89
05/16/2022 16:23:04 - INFO - __main__ - Step 370 Global step 370 Train loss 3.37 on epoch=92
05/16/2022 16:23:05 - INFO - __main__ - Step 380 Global step 380 Train loss 3.41 on epoch=94
05/16/2022 16:23:06 - INFO - __main__ - Step 390 Global step 390 Train loss 3.23 on epoch=97
05/16/2022 16:23:08 - INFO - __main__ - Step 400 Global step 400 Train loss 3.38 on epoch=99
05/16/2022 16:23:08 - INFO - __main__ - Global step 400 Train loss 3.39 Classification-F1 0.07733847637415622 on epoch=99
05/16/2022 16:23:09 - INFO - __main__ - Step 410 Global step 410 Train loss 3.25 on epoch=102
05/16/2022 16:23:11 - INFO - __main__ - Step 420 Global step 420 Train loss 3.24 on epoch=104
05/16/2022 16:23:12 - INFO - __main__ - Step 430 Global step 430 Train loss 3.06 on epoch=107
05/16/2022 16:23:13 - INFO - __main__ - Step 440 Global step 440 Train loss 3.18 on epoch=109
05/16/2022 16:23:15 - INFO - __main__ - Step 450 Global step 450 Train loss 2.97 on epoch=112
05/16/2022 16:23:15 - INFO - __main__ - Global step 450 Train loss 3.14 Classification-F1 0.14505347593582887 on epoch=112
05/16/2022 16:23:15 - INFO - __main__ - Saving model with best Classification-F1: 0.11300097751710654 -> 0.14505347593582887 on epoch=112, global_step=450
05/16/2022 16:23:17 - INFO - __main__ - Step 460 Global step 460 Train loss 3.10 on epoch=114
05/16/2022 16:23:18 - INFO - __main__ - Step 470 Global step 470 Train loss 2.85 on epoch=117
05/16/2022 16:23:20 - INFO - __main__ - Step 480 Global step 480 Train loss 2.89 on epoch=119
05/16/2022 16:23:21 - INFO - __main__ - Step 490 Global step 490 Train loss 2.67 on epoch=122
05/16/2022 16:23:22 - INFO - __main__ - Step 500 Global step 500 Train loss 2.87 on epoch=124
05/16/2022 16:23:23 - INFO - __main__ - Global step 500 Train loss 2.88 Classification-F1 0.10483870967741937 on epoch=124
05/16/2022 16:23:24 - INFO - __main__ - Step 510 Global step 510 Train loss 2.67 on epoch=127
05/16/2022 16:23:25 - INFO - __main__ - Step 520 Global step 520 Train loss 2.71 on epoch=129
05/16/2022 16:23:27 - INFO - __main__ - Step 530 Global step 530 Train loss 2.72 on epoch=132
05/16/2022 16:23:28 - INFO - __main__ - Step 540 Global step 540 Train loss 2.72 on epoch=134
05/16/2022 16:23:29 - INFO - __main__ - Step 550 Global step 550 Train loss 2.59 on epoch=137
05/16/2022 16:23:30 - INFO - __main__ - Global step 550 Train loss 2.68 Classification-F1 0.1 on epoch=137
05/16/2022 16:23:31 - INFO - __main__ - Step 560 Global step 560 Train loss 2.64 on epoch=139
05/16/2022 16:23:32 - INFO - __main__ - Step 570 Global step 570 Train loss 2.57 on epoch=142
05/16/2022 16:23:34 - INFO - __main__ - Step 580 Global step 580 Train loss 2.51 on epoch=144
05/16/2022 16:23:35 - INFO - __main__ - Step 590 Global step 590 Train loss 2.39 on epoch=147
05/16/2022 16:23:36 - INFO - __main__ - Step 600 Global step 600 Train loss 2.55 on epoch=149
05/16/2022 16:23:37 - INFO - __main__ - Global step 600 Train loss 2.53 Classification-F1 0.1 on epoch=149
05/16/2022 16:23:38 - INFO - __main__ - Step 610 Global step 610 Train loss 2.27 on epoch=152
05/16/2022 16:23:40 - INFO - __main__ - Step 620 Global step 620 Train loss 2.51 on epoch=154
05/16/2022 16:23:41 - INFO - __main__ - Step 630 Global step 630 Train loss 2.29 on epoch=157
05/16/2022 16:23:42 - INFO - __main__ - Step 640 Global step 640 Train loss 2.34 on epoch=159
05/16/2022 16:23:44 - INFO - __main__ - Step 650 Global step 650 Train loss 2.20 on epoch=162
05/16/2022 16:23:44 - INFO - __main__ - Global step 650 Train loss 2.32 Classification-F1 0.1 on epoch=162
05/16/2022 16:23:45 - INFO - __main__ - Step 660 Global step 660 Train loss 2.53 on epoch=164
05/16/2022 16:23:47 - INFO - __main__ - Step 670 Global step 670 Train loss 2.15 on epoch=167
05/16/2022 16:23:48 - INFO - __main__ - Step 680 Global step 680 Train loss 2.27 on epoch=169
05/16/2022 16:23:49 - INFO - __main__ - Step 690 Global step 690 Train loss 2.10 on epoch=172
05/16/2022 16:23:51 - INFO - __main__ - Step 700 Global step 700 Train loss 2.08 on epoch=174
05/16/2022 16:23:51 - INFO - __main__ - Global step 700 Train loss 2.23 Classification-F1 0.1 on epoch=174
05/16/2022 16:23:53 - INFO - __main__ - Step 710 Global step 710 Train loss 2.07 on epoch=177
05/16/2022 16:23:54 - INFO - __main__ - Step 720 Global step 720 Train loss 2.18 on epoch=179
05/16/2022 16:23:55 - INFO - __main__ - Step 730 Global step 730 Train loss 2.05 on epoch=182
05/16/2022 16:23:57 - INFO - __main__ - Step 740 Global step 740 Train loss 2.17 on epoch=184
05/16/2022 16:23:58 - INFO - __main__ - Step 750 Global step 750 Train loss 2.07 on epoch=187
05/16/2022 16:23:59 - INFO - __main__ - Global step 750 Train loss 2.11 Classification-F1 0.1 on epoch=187
05/16/2022 16:24:00 - INFO - __main__ - Step 760 Global step 760 Train loss 2.09 on epoch=189
05/16/2022 16:24:01 - INFO - __main__ - Step 770 Global step 770 Train loss 2.25 on epoch=192
05/16/2022 16:24:03 - INFO - __main__ - Step 780 Global step 780 Train loss 2.14 on epoch=194
05/16/2022 16:24:04 - INFO - __main__ - Step 790 Global step 790 Train loss 2.08 on epoch=197
05/16/2022 16:24:05 - INFO - __main__ - Step 800 Global step 800 Train loss 2.22 on epoch=199
05/16/2022 16:24:06 - INFO - __main__ - Global step 800 Train loss 2.16 Classification-F1 0.1 on epoch=199
05/16/2022 16:24:07 - INFO - __main__ - Step 810 Global step 810 Train loss 1.92 on epoch=202
05/16/2022 16:24:08 - INFO - __main__ - Step 820 Global step 820 Train loss 2.04 on epoch=204
05/16/2022 16:24:10 - INFO - __main__ - Step 830 Global step 830 Train loss 1.96 on epoch=207
05/16/2022 16:24:11 - INFO - __main__ - Step 840 Global step 840 Train loss 2.01 on epoch=209
05/16/2022 16:24:12 - INFO - __main__ - Step 850 Global step 850 Train loss 1.82 on epoch=212
05/16/2022 16:24:13 - INFO - __main__ - Global step 850 Train loss 1.95 Classification-F1 0.1 on epoch=212
05/16/2022 16:24:14 - INFO - __main__ - Step 860 Global step 860 Train loss 1.86 on epoch=214
05/16/2022 16:24:16 - INFO - __main__ - Step 870 Global step 870 Train loss 1.94 on epoch=217
05/16/2022 16:24:17 - INFO - __main__ - Step 880 Global step 880 Train loss 1.99 on epoch=219
05/16/2022 16:24:18 - INFO - __main__ - Step 890 Global step 890 Train loss 1.84 on epoch=222
05/16/2022 16:24:20 - INFO - __main__ - Step 900 Global step 900 Train loss 1.82 on epoch=224
05/16/2022 16:24:20 - INFO - __main__ - Global step 900 Train loss 1.89 Classification-F1 0.1 on epoch=224
05/16/2022 16:24:21 - INFO - __main__ - Step 910 Global step 910 Train loss 1.83 on epoch=227
05/16/2022 16:24:23 - INFO - __main__ - Step 920 Global step 920 Train loss 1.99 on epoch=229
05/16/2022 16:24:24 - INFO - __main__ - Step 930 Global step 930 Train loss 1.74 on epoch=232
05/16/2022 16:24:25 - INFO - __main__ - Step 940 Global step 940 Train loss 1.91 on epoch=234
05/16/2022 16:24:27 - INFO - __main__ - Step 950 Global step 950 Train loss 1.81 on epoch=237
05/16/2022 16:24:27 - INFO - __main__ - Global step 950 Train loss 1.85 Classification-F1 0.1 on epoch=237
05/16/2022 16:24:29 - INFO - __main__ - Step 960 Global step 960 Train loss 1.73 on epoch=239
05/16/2022 16:24:30 - INFO - __main__ - Step 970 Global step 970 Train loss 1.88 on epoch=242
05/16/2022 16:24:31 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
05/16/2022 16:24:33 - INFO - __main__ - Step 990 Global step 990 Train loss 1.84 on epoch=247
05/16/2022 16:24:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.78 on epoch=249
05/16/2022 16:24:35 - INFO - __main__ - Global step 1000 Train loss 1.79 Classification-F1 0.1 on epoch=249
05/16/2022 16:24:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.74 on epoch=252
05/16/2022 16:24:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.84 on epoch=254
05/16/2022 16:24:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.66 on epoch=257
05/16/2022 16:24:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.68 on epoch=259
05/16/2022 16:24:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.84 on epoch=262
05/16/2022 16:24:42 - INFO - __main__ - Global step 1050 Train loss 1.75 Classification-F1 0.1 on epoch=262
05/16/2022 16:24:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.78 on epoch=264
05/16/2022 16:24:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.76 on epoch=267
05/16/2022 16:24:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.68 on epoch=269
05/16/2022 16:24:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.66 on epoch=272
05/16/2022 16:24:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.67 on epoch=274
05/16/2022 16:24:49 - INFO - __main__ - Global step 1100 Train loss 1.71 Classification-F1 0.1 on epoch=274
05/16/2022 16:24:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.63 on epoch=277
05/16/2022 16:24:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.69 on epoch=279
05/16/2022 16:24:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.58 on epoch=282
05/16/2022 16:24:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.59 on epoch=284
05/16/2022 16:24:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.62 on epoch=287
05/16/2022 16:24:56 - INFO - __main__ - Global step 1150 Train loss 1.62 Classification-F1 0.1 on epoch=287
05/16/2022 16:24:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.66 on epoch=289
05/16/2022 16:24:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.64 on epoch=292
05/16/2022 16:25:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.40 on epoch=294
05/16/2022 16:25:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.60 on epoch=297
05/16/2022 16:25:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.58 on epoch=299
05/16/2022 16:25:04 - INFO - __main__ - Global step 1200 Train loss 1.57 Classification-F1 0.1 on epoch=299
05/16/2022 16:25:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.60 on epoch=302
05/16/2022 16:25:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.39 on epoch=304
05/16/2022 16:25:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.47 on epoch=307
05/16/2022 16:25:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.54 on epoch=309
05/16/2022 16:25:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.53 on epoch=312
05/16/2022 16:25:11 - INFO - __main__ - Global step 1250 Train loss 1.51 Classification-F1 0.1 on epoch=312
05/16/2022 16:25:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.55 on epoch=314
05/16/2022 16:25:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.35 on epoch=317
05/16/2022 16:25:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.56 on epoch=319
05/16/2022 16:25:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.56 on epoch=322
05/16/2022 16:25:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.49 on epoch=324
05/16/2022 16:25:18 - INFO - __main__ - Global step 1300 Train loss 1.50 Classification-F1 0.1 on epoch=324
05/16/2022 16:25:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.49 on epoch=327
05/16/2022 16:25:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.50 on epoch=329
05/16/2022 16:25:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.45 on epoch=332
05/16/2022 16:25:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.55 on epoch=334
05/16/2022 16:25:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.50 on epoch=337
05/16/2022 16:25:25 - INFO - __main__ - Global step 1350 Train loss 1.50 Classification-F1 0.1 on epoch=337
05/16/2022 16:25:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.28 on epoch=339
05/16/2022 16:25:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.51 on epoch=342
05/16/2022 16:25:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.44 on epoch=344
05/16/2022 16:25:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.30 on epoch=347
05/16/2022 16:25:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.42 on epoch=349
05/16/2022 16:25:33 - INFO - __main__ - Global step 1400 Train loss 1.39 Classification-F1 0.1 on epoch=349
05/16/2022 16:25:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.34 on epoch=352
05/16/2022 16:25:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.45 on epoch=354
05/16/2022 16:25:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.50 on epoch=357
05/16/2022 16:25:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.43 on epoch=359
05/16/2022 16:25:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.47 on epoch=362
05/16/2022 16:25:40 - INFO - __main__ - Global step 1450 Train loss 1.44 Classification-F1 0.1 on epoch=362
05/16/2022 16:25:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.42 on epoch=364
05/16/2022 16:25:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.50 on epoch=367
05/16/2022 16:25:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.40 on epoch=369
05/16/2022 16:25:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.39 on epoch=372
05/16/2022 16:25:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.35 on epoch=374
05/16/2022 16:25:47 - INFO - __main__ - Global step 1500 Train loss 1.41 Classification-F1 0.1 on epoch=374
05/16/2022 16:25:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.26 on epoch=377
05/16/2022 16:25:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.43 on epoch=379
05/16/2022 16:25:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.44 on epoch=382
05/16/2022 16:25:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.36 on epoch=384
05/16/2022 16:25:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
05/16/2022 16:25:55 - INFO - __main__ - Global step 1550 Train loss 1.37 Classification-F1 0.1 on epoch=387
05/16/2022 16:25:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=389
05/16/2022 16:25:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.41 on epoch=392
05/16/2022 16:25:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=394
05/16/2022 16:26:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.28 on epoch=397
05/16/2022 16:26:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.30 on epoch=399
05/16/2022 16:26:02 - INFO - __main__ - Global step 1600 Train loss 1.28 Classification-F1 0.1 on epoch=399
05/16/2022 16:26:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.45 on epoch=402
05/16/2022 16:26:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.34 on epoch=404
05/16/2022 16:26:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.33 on epoch=407
05/16/2022 16:26:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.40 on epoch=409
05/16/2022 16:26:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.33 on epoch=412
05/16/2022 16:26:09 - INFO - __main__ - Global step 1650 Train loss 1.37 Classification-F1 0.1 on epoch=412
05/16/2022 16:26:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.43 on epoch=414
05/16/2022 16:26:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
05/16/2022 16:26:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.22 on epoch=419
05/16/2022 16:26:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.36 on epoch=422
05/16/2022 16:26:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.38 on epoch=424
05/16/2022 16:26:17 - INFO - __main__ - Global step 1700 Train loss 1.33 Classification-F1 0.1 on epoch=424
05/16/2022 16:26:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=427
05/16/2022 16:26:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.34 on epoch=429
05/16/2022 16:26:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.30 on epoch=432
05/16/2022 16:26:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.23 on epoch=434
05/16/2022 16:26:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.37 on epoch=437
05/16/2022 16:26:24 - INFO - __main__ - Global step 1750 Train loss 1.30 Classification-F1 0.1 on epoch=437
05/16/2022 16:26:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.23 on epoch=439
05/16/2022 16:26:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.16 on epoch=442
05/16/2022 16:26:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.16 on epoch=444
05/16/2022 16:26:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.34 on epoch=447
05/16/2022 16:26:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.31 on epoch=449
05/16/2022 16:26:31 - INFO - __main__ - Global step 1800 Train loss 1.24 Classification-F1 0.1 on epoch=449
05/16/2022 16:26:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.21 on epoch=452
05/16/2022 16:26:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.29 on epoch=454
05/16/2022 16:26:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.16 on epoch=457
05/16/2022 16:26:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.10 on epoch=459
05/16/2022 16:26:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.34 on epoch=462
05/16/2022 16:26:38 - INFO - __main__ - Global step 1850 Train loss 1.22 Classification-F1 0.1 on epoch=462
05/16/2022 16:26:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.09 on epoch=464
05/16/2022 16:26:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.14 on epoch=467
05/16/2022 16:26:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
05/16/2022 16:26:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.37 on epoch=472
05/16/2022 16:26:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/16/2022 16:26:45 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.1 on epoch=474
05/16/2022 16:26:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.16 on epoch=477
05/16/2022 16:26:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.16 on epoch=479
05/16/2022 16:26:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.29 on epoch=482
05/16/2022 16:26:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.22 on epoch=484
05/16/2022 16:26:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.24 on epoch=487
05/16/2022 16:26:52 - INFO - __main__ - Global step 1950 Train loss 1.21 Classification-F1 0.1 on epoch=487
05/16/2022 16:26:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.33 on epoch=489
05/16/2022 16:26:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.25 on epoch=492
05/16/2022 16:26:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.14 on epoch=494
05/16/2022 16:26:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.29 on epoch=497
05/16/2022 16:26:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.00 on epoch=499
05/16/2022 16:27:00 - INFO - __main__ - Global step 2000 Train loss 1.20 Classification-F1 0.1 on epoch=499
05/16/2022 16:27:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.08 on epoch=502
05/16/2022 16:27:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.20 on epoch=504
05/16/2022 16:27:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.07 on epoch=507
05/16/2022 16:27:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.28 on epoch=509
05/16/2022 16:27:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.20 on epoch=512
05/16/2022 16:27:07 - INFO - __main__ - Global step 2050 Train loss 1.17 Classification-F1 0.09493670886075949 on epoch=512
05/16/2022 16:27:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.32 on epoch=514
05/16/2022 16:27:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.18 on epoch=517
05/16/2022 16:27:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.25 on epoch=519
05/16/2022 16:27:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.01 on epoch=522
05/16/2022 16:27:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.22 on epoch=524
05/16/2022 16:27:15 - INFO - __main__ - Global step 2100 Train loss 1.19 Classification-F1 0.13034188034188032 on epoch=524
05/16/2022 16:27:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.10 on epoch=527
05/16/2022 16:27:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.21 on epoch=529
05/16/2022 16:27:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.18 on epoch=532
05/16/2022 16:27:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.19 on epoch=534
05/16/2022 16:27:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.27 on epoch=537
05/16/2022 16:27:22 - INFO - __main__ - Global step 2150 Train loss 1.19 Classification-F1 0.1 on epoch=537
05/16/2022 16:27:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.18 on epoch=539
05/16/2022 16:27:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.21 on epoch=542
05/16/2022 16:27:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.14 on epoch=544
05/16/2022 16:27:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.12 on epoch=547
05/16/2022 16:27:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.06 on epoch=549
05/16/2022 16:27:30 - INFO - __main__ - Global step 2200 Train loss 1.14 Classification-F1 0.1468058968058968 on epoch=549
05/16/2022 16:27:30 - INFO - __main__ - Saving model with best Classification-F1: 0.14505347593582887 -> 0.1468058968058968 on epoch=549, global_step=2200
05/16/2022 16:27:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.07 on epoch=552
05/16/2022 16:27:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.07 on epoch=554
05/16/2022 16:27:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.25 on epoch=557
05/16/2022 16:27:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.14 on epoch=559
05/16/2022 16:27:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.20 on epoch=562
05/16/2022 16:27:37 - INFO - __main__ - Global step 2250 Train loss 1.15 Classification-F1 0.10256410256410256 on epoch=562
05/16/2022 16:27:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.15 on epoch=564
05/16/2022 16:27:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.05 on epoch=567
05/16/2022 16:27:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.19 on epoch=569
05/16/2022 16:27:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.00 on epoch=572
05/16/2022 16:27:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.12 on epoch=574
05/16/2022 16:27:45 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.1 on epoch=574
05/16/2022 16:27:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/16/2022 16:27:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
05/16/2022 16:27:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.08 on epoch=582
05/16/2022 16:27:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.16 on epoch=584
05/16/2022 16:27:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.02 on epoch=587
05/16/2022 16:27:52 - INFO - __main__ - Global step 2350 Train loss 1.09 Classification-F1 0.1 on epoch=587
05/16/2022 16:27:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/16/2022 16:27:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/16/2022 16:27:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/16/2022 16:27:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.10 on epoch=597
05/16/2022 16:27:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.08 on epoch=599
05/16/2022 16:28:00 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.1 on epoch=599
05/16/2022 16:28:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.10 on epoch=602
05/16/2022 16:28:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/16/2022 16:28:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.15 on epoch=607
05/16/2022 16:28:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
05/16/2022 16:28:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.17 on epoch=612
05/16/2022 16:28:07 - INFO - __main__ - Global step 2450 Train loss 1.07 Classification-F1 0.1 on epoch=612
05/16/2022 16:28:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
05/16/2022 16:28:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.15 on epoch=617
05/16/2022 16:28:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.24 on epoch=619
05/16/2022 16:28:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.18 on epoch=622
05/16/2022 16:28:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.05 on epoch=624
05/16/2022 16:28:14 - INFO - __main__ - Global step 2500 Train loss 1.14 Classification-F1 0.1 on epoch=624
05/16/2022 16:28:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.12 on epoch=627
05/16/2022 16:28:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
05/16/2022 16:28:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.21 on epoch=632
05/16/2022 16:28:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.18 on epoch=634
05/16/2022 16:28:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
05/16/2022 16:28:21 - INFO - __main__ - Global step 2550 Train loss 1.14 Classification-F1 0.1 on epoch=637
05/16/2022 16:28:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.15 on epoch=639
05/16/2022 16:28:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
05/16/2022 16:28:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.16 on epoch=644
05/16/2022 16:28:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.11 on epoch=647
05/16/2022 16:28:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
05/16/2022 16:28:30 - INFO - __main__ - Global step 2600 Train loss 1.09 Classification-F1 0.1 on epoch=649
05/16/2022 16:28:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
05/16/2022 16:28:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.07 on epoch=654
05/16/2022 16:28:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.10 on epoch=657
05/16/2022 16:28:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.10 on epoch=659
05/16/2022 16:28:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.21 on epoch=662
05/16/2022 16:28:37 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.1 on epoch=662
05/16/2022 16:28:38 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.10 on epoch=664
05/16/2022 16:28:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.06 on epoch=667
05/16/2022 16:28:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.18 on epoch=669
05/16/2022 16:28:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.11 on epoch=672
05/16/2022 16:28:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.08 on epoch=674
05/16/2022 16:28:44 - INFO - __main__ - Global step 2700 Train loss 1.11 Classification-F1 0.1 on epoch=674
05/16/2022 16:28:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.94 on epoch=677
05/16/2022 16:28:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
05/16/2022 16:28:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.05 on epoch=682
05/16/2022 16:28:49 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.08 on epoch=684
05/16/2022 16:28:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.05 on epoch=687
05/16/2022 16:28:51 - INFO - __main__ - Global step 2750 Train loss 1.03 Classification-F1 0.1 on epoch=687
05/16/2022 16:28:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.18 on epoch=689
05/16/2022 16:28:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
05/16/2022 16:28:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.17 on epoch=694
05/16/2022 16:28:56 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.04 on epoch=697
05/16/2022 16:28:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.15 on epoch=699
05/16/2022 16:28:58 - INFO - __main__ - Global step 2800 Train loss 1.10 Classification-F1 0.1 on epoch=699
05/16/2022 16:28:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.11 on epoch=702
05/16/2022 16:29:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.08 on epoch=704
05/16/2022 16:29:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.02 on epoch=707
05/16/2022 16:29:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/16/2022 16:29:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.01 on epoch=712
05/16/2022 16:29:05 - INFO - __main__ - Global step 2850 Train loss 1.04 Classification-F1 0.1 on epoch=712
05/16/2022 16:29:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.05 on epoch=714
05/16/2022 16:29:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/16/2022 16:29:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.03 on epoch=719
05/16/2022 16:29:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.07 on epoch=722
05/16/2022 16:29:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/16/2022 16:29:12 - INFO - __main__ - Global step 2900 Train loss 1.04 Classification-F1 0.1 on epoch=724
05/16/2022 16:29:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.04 on epoch=727
05/16/2022 16:29:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.09 on epoch=729
05/16/2022 16:29:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.04 on epoch=732
05/16/2022 16:29:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.18 on epoch=734
05/16/2022 16:29:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.09 on epoch=737
05/16/2022 16:29:20 - INFO - __main__ - Global step 2950 Train loss 1.09 Classification-F1 0.1 on epoch=737
05/16/2022 16:29:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.05 on epoch=739
05/16/2022 16:29:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.04 on epoch=742
05/16/2022 16:29:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.18 on epoch=744
05/16/2022 16:29:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=747
05/16/2022 16:29:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.15 on epoch=749
05/16/2022 16:29:27 - INFO - __main__ - Global step 3000 Train loss 1.08 Classification-F1 0.1 on epoch=749
05/16/2022 16:29:27 - INFO - __main__ - save last model!
05/16/2022 16:29:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 16:29:27 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 16:29:27 - INFO - __main__ - Printing 3 examples
05/16/2022 16:29:27 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 16:29:27 - INFO - __main__ - ['others']
05/16/2022 16:29:27 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 16:29:27 - INFO - __main__ - ['others']
05/16/2022 16:29:27 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 16:29:27 - INFO - __main__ - ['others']
05/16/2022 16:29:27 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:29:28 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:29:28 - INFO - __main__ - Printing 3 examples
05/16/2022 16:29:28 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:29:28 - INFO - __main__ - ['others']
05/16/2022 16:29:28 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:29:28 - INFO - __main__ - ['others']
05/16/2022 16:29:28 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:29:28 - INFO - __main__ - ['others']
05/16/2022 16:29:28 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:29:28 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:29:28 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:29:28 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:29:28 - INFO - __main__ - Printing 3 examples
05/16/2022 16:29:28 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:29:28 - INFO - __main__ - ['others']
05/16/2022 16:29:28 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:29:28 - INFO - __main__ - ['others']
05/16/2022 16:29:28 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:29:28 - INFO - __main__ - ['others']
05/16/2022 16:29:28 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:29:28 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:29:28 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:29:29 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:29:34 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:29:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:29:34 - INFO - __main__ - Starting training!
05/16/2022 16:29:35 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 16:30:18 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.2_8_predictions.txt
05/16/2022 16:30:18 - INFO - __main__ - Classification-F1 on test data: 0.0257
05/16/2022 16:30:19 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.1468058968058968, test_performance=0.025658687790597552
05/16/2022 16:30:19 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
05/16/2022 16:30:20 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:30:20 - INFO - __main__ - Printing 3 examples
05/16/2022 16:30:20 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:30:20 - INFO - __main__ - ['others']
05/16/2022 16:30:20 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:30:20 - INFO - __main__ - ['others']
05/16/2022 16:30:20 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:30:20 - INFO - __main__ - ['others']
05/16/2022 16:30:20 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:30:20 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:30:20 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:30:20 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:30:20 - INFO - __main__ - Printing 3 examples
05/16/2022 16:30:20 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:30:20 - INFO - __main__ - ['others']
05/16/2022 16:30:20 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:30:20 - INFO - __main__ - ['others']
05/16/2022 16:30:20 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:30:20 - INFO - __main__ - ['others']
05/16/2022 16:30:20 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:30:20 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:30:20 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:30:26 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:30:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:30:26 - INFO - __main__ - Starting training!
05/16/2022 16:30:27 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=2
05/16/2022 16:30:29 - INFO - __main__ - Step 20 Global step 20 Train loss 6.61 on epoch=4
05/16/2022 16:30:30 - INFO - __main__ - Step 30 Global step 30 Train loss 6.22 on epoch=7
05/16/2022 16:30:32 - INFO - __main__ - Step 40 Global step 40 Train loss 5.81 on epoch=9
05/16/2022 16:30:33 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=12
05/16/2022 16:30:37 - INFO - __main__ - Global step 50 Train loss 6.18 Classification-F1 0.0 on epoch=12
05/16/2022 16:30:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 16:30:38 - INFO - __main__ - Step 60 Global step 60 Train loss 5.17 on epoch=14
05/16/2022 16:30:40 - INFO - __main__ - Step 70 Global step 70 Train loss 4.83 on epoch=17
05/16/2022 16:30:41 - INFO - __main__ - Step 80 Global step 80 Train loss 4.36 on epoch=19
05/16/2022 16:30:42 - INFO - __main__ - Step 90 Global step 90 Train loss 4.15 on epoch=22
05/16/2022 16:30:44 - INFO - __main__ - Step 100 Global step 100 Train loss 3.93 on epoch=24
05/16/2022 16:30:44 - INFO - __main__ - Global step 100 Train loss 4.49 Classification-F1 0.22426438296003515 on epoch=24
05/16/2022 16:30:44 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.22426438296003515 on epoch=24, global_step=100
05/16/2022 16:30:46 - INFO - __main__ - Step 110 Global step 110 Train loss 3.93 on epoch=27
05/16/2022 16:30:47 - INFO - __main__ - Step 120 Global step 120 Train loss 3.38 on epoch=29
05/16/2022 16:30:48 - INFO - __main__ - Step 130 Global step 130 Train loss 3.35 on epoch=32
05/16/2022 16:30:50 - INFO - __main__ - Step 140 Global step 140 Train loss 3.24 on epoch=34
05/16/2022 16:30:51 - INFO - __main__ - Step 150 Global step 150 Train loss 3.27 on epoch=37
05/16/2022 16:30:52 - INFO - __main__ - Global step 150 Train loss 3.44 Classification-F1 0.06507515473032714 on epoch=37
05/16/2022 16:30:53 - INFO - __main__ - Step 160 Global step 160 Train loss 2.89 on epoch=39
05/16/2022 16:30:55 - INFO - __main__ - Step 170 Global step 170 Train loss 3.02 on epoch=42
05/16/2022 16:30:56 - INFO - __main__ - Step 180 Global step 180 Train loss 2.78 on epoch=44
05/16/2022 16:30:57 - INFO - __main__ - Step 190 Global step 190 Train loss 2.83 on epoch=47
05/16/2022 16:30:59 - INFO - __main__ - Step 200 Global step 200 Train loss 2.75 on epoch=49
05/16/2022 16:30:59 - INFO - __main__ - Global step 200 Train loss 2.85 Classification-F1 0.15587044534412953 on epoch=49
05/16/2022 16:31:01 - INFO - __main__ - Step 210 Global step 210 Train loss 2.83 on epoch=52
05/16/2022 16:31:02 - INFO - __main__ - Step 220 Global step 220 Train loss 2.55 on epoch=54
05/16/2022 16:31:03 - INFO - __main__ - Step 230 Global step 230 Train loss 2.54 on epoch=57
05/16/2022 16:31:05 - INFO - __main__ - Step 240 Global step 240 Train loss 2.40 on epoch=59
05/16/2022 16:31:06 - INFO - __main__ - Step 250 Global step 250 Train loss 2.76 on epoch=62
05/16/2022 16:31:07 - INFO - __main__ - Global step 250 Train loss 2.61 Classification-F1 0.19654556283502084 on epoch=62
05/16/2022 16:31:08 - INFO - __main__ - Step 260 Global step 260 Train loss 2.53 on epoch=64
05/16/2022 16:31:09 - INFO - __main__ - Step 270 Global step 270 Train loss 2.59 on epoch=67
05/16/2022 16:31:11 - INFO - __main__ - Step 280 Global step 280 Train loss 2.35 on epoch=69
05/16/2022 16:31:12 - INFO - __main__ - Step 290 Global step 290 Train loss 2.38 on epoch=72
05/16/2022 16:31:13 - INFO - __main__ - Step 300 Global step 300 Train loss 2.10 on epoch=74
05/16/2022 16:31:14 - INFO - __main__ - Global step 300 Train loss 2.39 Classification-F1 0.13067758749069247 on epoch=74
05/16/2022 16:31:15 - INFO - __main__ - Step 310 Global step 310 Train loss 2.10 on epoch=77
05/16/2022 16:31:17 - INFO - __main__ - Step 320 Global step 320 Train loss 2.04 on epoch=79
05/16/2022 16:31:18 - INFO - __main__ - Step 330 Global step 330 Train loss 2.21 on epoch=82
05/16/2022 16:31:19 - INFO - __main__ - Step 340 Global step 340 Train loss 2.01 on epoch=84
05/16/2022 16:31:21 - INFO - __main__ - Step 350 Global step 350 Train loss 2.00 on epoch=87
05/16/2022 16:31:21 - INFO - __main__ - Global step 350 Train loss 2.07 Classification-F1 0.11722488038277512 on epoch=87
05/16/2022 16:31:23 - INFO - __main__ - Step 360 Global step 360 Train loss 1.87 on epoch=89
05/16/2022 16:31:24 - INFO - __main__ - Step 370 Global step 370 Train loss 1.90 on epoch=92
05/16/2022 16:31:25 - INFO - __main__ - Step 380 Global step 380 Train loss 1.77 on epoch=94
05/16/2022 16:31:27 - INFO - __main__ - Step 390 Global step 390 Train loss 1.89 on epoch=97
05/16/2022 16:31:28 - INFO - __main__ - Step 400 Global step 400 Train loss 1.82 on epoch=99
05/16/2022 16:31:29 - INFO - __main__ - Global step 400 Train loss 1.85 Classification-F1 0.2011385199240987 on epoch=99
05/16/2022 16:31:30 - INFO - __main__ - Step 410 Global step 410 Train loss 1.74 on epoch=102
05/16/2022 16:31:31 - INFO - __main__ - Step 420 Global step 420 Train loss 1.62 on epoch=104
05/16/2022 16:31:33 - INFO - __main__ - Step 430 Global step 430 Train loss 1.73 on epoch=107
05/16/2022 16:31:34 - INFO - __main__ - Step 440 Global step 440 Train loss 1.67 on epoch=109
05/16/2022 16:31:35 - INFO - __main__ - Step 450 Global step 450 Train loss 1.74 on epoch=112
05/16/2022 16:31:36 - INFO - __main__ - Global step 450 Train loss 1.70 Classification-F1 0.09615384615384615 on epoch=112
05/16/2022 16:31:37 - INFO - __main__ - Step 460 Global step 460 Train loss 1.55 on epoch=114
05/16/2022 16:31:39 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=117
05/16/2022 16:31:40 - INFO - __main__ - Step 480 Global step 480 Train loss 1.46 on epoch=119
05/16/2022 16:31:41 - INFO - __main__ - Step 490 Global step 490 Train loss 1.53 on epoch=122
05/16/2022 16:31:43 - INFO - __main__ - Step 500 Global step 500 Train loss 1.41 on epoch=124
05/16/2022 16:31:43 - INFO - __main__ - Global step 500 Train loss 1.54 Classification-F1 0.15526315789473685 on epoch=124
05/16/2022 16:31:44 - INFO - __main__ - Step 510 Global step 510 Train loss 1.52 on epoch=127
05/16/2022 16:31:46 - INFO - __main__ - Step 520 Global step 520 Train loss 1.44 on epoch=129
05/16/2022 16:31:47 - INFO - __main__ - Step 530 Global step 530 Train loss 1.49 on epoch=132
05/16/2022 16:31:48 - INFO - __main__ - Step 540 Global step 540 Train loss 1.50 on epoch=134
05/16/2022 16:31:50 - INFO - __main__ - Step 550 Global step 550 Train loss 1.40 on epoch=137
05/16/2022 16:31:50 - INFO - __main__ - Global step 550 Train loss 1.47 Classification-F1 0.13026315789473686 on epoch=137
05/16/2022 16:31:52 - INFO - __main__ - Step 560 Global step 560 Train loss 1.33 on epoch=139
05/16/2022 16:31:53 - INFO - __main__ - Step 570 Global step 570 Train loss 1.35 on epoch=142
05/16/2022 16:31:54 - INFO - __main__ - Step 580 Global step 580 Train loss 1.29 on epoch=144
05/16/2022 16:31:56 - INFO - __main__ - Step 590 Global step 590 Train loss 1.46 on epoch=147
05/16/2022 16:31:57 - INFO - __main__ - Step 600 Global step 600 Train loss 1.38 on epoch=149
05/16/2022 16:31:58 - INFO - __main__ - Global step 600 Train loss 1.36 Classification-F1 0.13034188034188032 on epoch=149
05/16/2022 16:31:59 - INFO - __main__ - Step 610 Global step 610 Train loss 1.27 on epoch=152
05/16/2022 16:32:01 - INFO - __main__ - Step 620 Global step 620 Train loss 1.26 on epoch=154
05/16/2022 16:32:02 - INFO - __main__ - Step 630 Global step 630 Train loss 1.23 on epoch=157
05/16/2022 16:32:04 - INFO - __main__ - Step 640 Global step 640 Train loss 1.32 on epoch=159
05/16/2022 16:32:05 - INFO - __main__ - Step 650 Global step 650 Train loss 1.19 on epoch=162
05/16/2022 16:32:05 - INFO - __main__ - Global step 650 Train loss 1.25 Classification-F1 0.16926248282180484 on epoch=162
05/16/2022 16:32:07 - INFO - __main__ - Step 660 Global step 660 Train loss 1.26 on epoch=164
05/16/2022 16:32:08 - INFO - __main__ - Step 670 Global step 670 Train loss 1.36 on epoch=167
05/16/2022 16:32:09 - INFO - __main__ - Step 680 Global step 680 Train loss 1.22 on epoch=169
05/16/2022 16:32:11 - INFO - __main__ - Step 690 Global step 690 Train loss 1.10 on epoch=172
05/16/2022 16:32:12 - INFO - __main__ - Step 700 Global step 700 Train loss 1.16 on epoch=174
05/16/2022 16:32:13 - INFO - __main__ - Global step 700 Train loss 1.22 Classification-F1 0.10126582278481013 on epoch=174
05/16/2022 16:32:14 - INFO - __main__ - Step 710 Global step 710 Train loss 1.10 on epoch=177
05/16/2022 16:32:16 - INFO - __main__ - Step 720 Global step 720 Train loss 1.17 on epoch=179
05/16/2022 16:32:17 - INFO - __main__ - Step 730 Global step 730 Train loss 1.10 on epoch=182
05/16/2022 16:32:19 - INFO - __main__ - Step 740 Global step 740 Train loss 1.02 on epoch=184
05/16/2022 16:32:21 - INFO - __main__ - Step 750 Global step 750 Train loss 1.14 on epoch=187
05/16/2022 16:32:21 - INFO - __main__ - Global step 750 Train loss 1.11 Classification-F1 0.1 on epoch=187
05/16/2022 16:32:23 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=189
05/16/2022 16:32:25 - INFO - __main__ - Step 770 Global step 770 Train loss 1.19 on epoch=192
05/16/2022 16:32:26 - INFO - __main__ - Step 780 Global step 780 Train loss 1.15 on epoch=194
05/16/2022 16:32:28 - INFO - __main__ - Step 790 Global step 790 Train loss 1.15 on epoch=197
05/16/2022 16:32:29 - INFO - __main__ - Step 800 Global step 800 Train loss 1.04 on epoch=199
05/16/2022 16:32:30 - INFO - __main__ - Global step 800 Train loss 1.15 Classification-F1 0.13541666666666669 on epoch=199
05/16/2022 16:32:31 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=202
05/16/2022 16:32:33 - INFO - __main__ - Step 820 Global step 820 Train loss 1.14 on epoch=204
05/16/2022 16:32:34 - INFO - __main__ - Step 830 Global step 830 Train loss 1.09 on epoch=207
05/16/2022 16:32:35 - INFO - __main__ - Step 840 Global step 840 Train loss 1.01 on epoch=209
05/16/2022 16:32:37 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=212
05/16/2022 16:32:37 - INFO - __main__ - Global step 850 Train loss 1.11 Classification-F1 0.15535714285714286 on epoch=212
05/16/2022 16:32:39 - INFO - __main__ - Step 860 Global step 860 Train loss 1.21 on epoch=214
05/16/2022 16:32:40 - INFO - __main__ - Step 870 Global step 870 Train loss 1.13 on epoch=217
05/16/2022 16:32:41 - INFO - __main__ - Step 880 Global step 880 Train loss 1.18 on epoch=219
05/16/2022 16:32:42 - INFO - __main__ - Step 890 Global step 890 Train loss 1.28 on epoch=222
05/16/2022 16:32:44 - INFO - __main__ - Step 900 Global step 900 Train loss 1.21 on epoch=224
05/16/2022 16:32:44 - INFO - __main__ - Global step 900 Train loss 1.20 Classification-F1 0.18014375561545376 on epoch=224
05/16/2022 16:32:46 - INFO - __main__ - Step 910 Global step 910 Train loss 1.19 on epoch=227
05/16/2022 16:32:47 - INFO - __main__ - Step 920 Global step 920 Train loss 1.09 on epoch=229
05/16/2022 16:32:48 - INFO - __main__ - Step 930 Global step 930 Train loss 1.08 on epoch=232
05/16/2022 16:32:50 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=234
05/16/2022 16:32:51 - INFO - __main__ - Step 950 Global step 950 Train loss 1.04 on epoch=237
05/16/2022 16:32:52 - INFO - __main__ - Global step 950 Train loss 1.11 Classification-F1 0.1484375 on epoch=237
05/16/2022 16:32:53 - INFO - __main__ - Step 960 Global step 960 Train loss 1.05 on epoch=239
05/16/2022 16:32:54 - INFO - __main__ - Step 970 Global step 970 Train loss 1.12 on epoch=242
05/16/2022 16:32:56 - INFO - __main__ - Step 980 Global step 980 Train loss 1.08 on epoch=244
05/16/2022 16:32:57 - INFO - __main__ - Step 990 Global step 990 Train loss 1.04 on epoch=247
05/16/2022 16:32:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.03 on epoch=249
05/16/2022 16:32:59 - INFO - __main__ - Global step 1000 Train loss 1.07 Classification-F1 0.12333965844402277 on epoch=249
05/16/2022 16:33:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
05/16/2022 16:33:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.15 on epoch=254
05/16/2022 16:33:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/16/2022 16:33:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.10 on epoch=259
05/16/2022 16:33:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=262
05/16/2022 16:33:06 - INFO - __main__ - Global step 1050 Train loss 1.10 Classification-F1 0.1875 on epoch=262
05/16/2022 16:33:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
05/16/2022 16:33:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.02 on epoch=267
05/16/2022 16:33:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.97 on epoch=269
05/16/2022 16:33:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.04 on epoch=272
05/16/2022 16:33:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.02 on epoch=274
05/16/2022 16:33:13 - INFO - __main__ - Global step 1100 Train loss 1.02 Classification-F1 0.15607940446650126 on epoch=274
05/16/2022 16:33:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.00 on epoch=277
05/16/2022 16:33:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.07 on epoch=279
05/16/2022 16:33:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=282
05/16/2022 16:33:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.02 on epoch=284
05/16/2022 16:33:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.08 on epoch=287
05/16/2022 16:33:20 - INFO - __main__ - Global step 1150 Train loss 1.03 Classification-F1 0.12368421052631579 on epoch=287
05/16/2022 16:33:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.05 on epoch=289
05/16/2022 16:33:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=292
05/16/2022 16:33:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.08 on epoch=294
05/16/2022 16:33:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.19 on epoch=297
05/16/2022 16:33:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.13 on epoch=299
05/16/2022 16:33:28 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.1565349544072948 on epoch=299
05/16/2022 16:33:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.03 on epoch=302
05/16/2022 16:33:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.10 on epoch=304
05/16/2022 16:33:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.16 on epoch=307
05/16/2022 16:33:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.01 on epoch=309
05/16/2022 16:33:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.04 on epoch=312
05/16/2022 16:33:35 - INFO - __main__ - Global step 1250 Train loss 1.07 Classification-F1 0.1 on epoch=312
05/16/2022 16:33:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=314
05/16/2022 16:33:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.02 on epoch=317
05/16/2022 16:33:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.08 on epoch=319
05/16/2022 16:33:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.06 on epoch=322
05/16/2022 16:33:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.08 on epoch=324
05/16/2022 16:33:42 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.20417422867513613 on epoch=324
05/16/2022 16:33:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.13 on epoch=327
05/16/2022 16:33:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.06 on epoch=329
05/16/2022 16:33:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.99 on epoch=332
05/16/2022 16:33:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.06 on epoch=334
05/16/2022 16:33:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.98 on epoch=337
05/16/2022 16:33:49 - INFO - __main__ - Global step 1350 Train loss 1.04 Classification-F1 0.09090909090909091 on epoch=337
05/16/2022 16:33:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/16/2022 16:33:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.96 on epoch=342
05/16/2022 16:33:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/16/2022 16:33:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.98 on epoch=347
05/16/2022 16:33:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.95 on epoch=349
05/16/2022 16:33:57 - INFO - __main__ - Global step 1400 Train loss 1.00 Classification-F1 0.09305210918114144 on epoch=349
05/16/2022 16:33:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.97 on epoch=352
05/16/2022 16:34:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/16/2022 16:34:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.95 on epoch=357
05/16/2022 16:34:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.96 on epoch=359
05/16/2022 16:34:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.93 on epoch=362
05/16/2022 16:34:04 - INFO - __main__ - Global step 1450 Train loss 0.96 Classification-F1 0.11687344913151365 on epoch=362
05/16/2022 16:34:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.90 on epoch=364
05/16/2022 16:34:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.02 on epoch=367
05/16/2022 16:34:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/16/2022 16:34:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.93 on epoch=372
05/16/2022 16:34:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.88 on epoch=374
05/16/2022 16:34:11 - INFO - __main__ - Global step 1500 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=374
05/16/2022 16:34:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
05/16/2022 16:34:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=379
05/16/2022 16:34:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.89 on epoch=382
05/16/2022 16:34:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.86 on epoch=384
05/16/2022 16:34:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.01 on epoch=387
05/16/2022 16:34:19 - INFO - __main__ - Global step 1550 Train loss 0.97 Classification-F1 0.1 on epoch=387
05/16/2022 16:34:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.89 on epoch=389
05/16/2022 16:34:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.95 on epoch=392
05/16/2022 16:34:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.00 on epoch=394
05/16/2022 16:34:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.88 on epoch=397
05/16/2022 16:34:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
05/16/2022 16:34:27 - INFO - __main__ - Global step 1600 Train loss 0.94 Classification-F1 0.1 on epoch=399
05/16/2022 16:34:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.05 on epoch=402
05/16/2022 16:34:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.93 on epoch=404
05/16/2022 16:34:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.92 on epoch=407
05/16/2022 16:34:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.00 on epoch=409
05/16/2022 16:34:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.99 on epoch=412
05/16/2022 16:34:35 - INFO - __main__ - Global step 1650 Train loss 0.98 Classification-F1 0.17408906882591094 on epoch=412
05/16/2022 16:34:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.00 on epoch=414
05/16/2022 16:34:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/16/2022 16:34:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.98 on epoch=419
05/16/2022 16:34:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.96 on epoch=422
05/16/2022 16:34:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.94 on epoch=424
05/16/2022 16:34:43 - INFO - __main__ - Global step 1700 Train loss 0.99 Classification-F1 0.1 on epoch=424
05/16/2022 16:34:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.95 on epoch=427
05/16/2022 16:34:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/16/2022 16:34:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.97 on epoch=432
05/16/2022 16:34:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.90 on epoch=434
05/16/2022 16:34:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.94 on epoch=437
05/16/2022 16:34:50 - INFO - __main__ - Global step 1750 Train loss 0.95 Classification-F1 0.1 on epoch=437
05/16/2022 16:34:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.96 on epoch=439
05/16/2022 16:34:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/16/2022 16:34:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=444
05/16/2022 16:34:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.95 on epoch=447
05/16/2022 16:34:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=449
05/16/2022 16:34:58 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.1 on epoch=449
05/16/2022 16:35:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.06 on epoch=452
05/16/2022 16:35:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.10 on epoch=454
05/16/2022 16:35:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.90 on epoch=457
05/16/2022 16:35:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.92 on epoch=459
05/16/2022 16:35:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.91 on epoch=462
05/16/2022 16:35:06 - INFO - __main__ - Global step 1850 Train loss 0.98 Classification-F1 0.1488888888888889 on epoch=462
05/16/2022 16:35:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.93 on epoch=464
05/16/2022 16:35:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.86 on epoch=467
05/16/2022 16:35:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.96 on epoch=469
05/16/2022 16:35:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.87 on epoch=472
05/16/2022 16:35:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.89 on epoch=474
05/16/2022 16:35:13 - INFO - __main__ - Global step 1900 Train loss 0.90 Classification-F1 0.1238095238095238 on epoch=474
05/16/2022 16:35:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.06 on epoch=477
05/16/2022 16:35:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.95 on epoch=479
05/16/2022 16:35:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
05/16/2022 16:35:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=484
05/16/2022 16:35:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.00 on epoch=487
05/16/2022 16:35:21 - INFO - __main__ - Global step 1950 Train loss 0.98 Classification-F1 0.13067758749069247 on epoch=487
05/16/2022 16:35:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=489
05/16/2022 16:35:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=492
05/16/2022 16:35:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.98 on epoch=494
05/16/2022 16:35:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.98 on epoch=497
05/16/2022 16:35:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/16/2022 16:35:28 - INFO - __main__ - Global step 2000 Train loss 0.96 Classification-F1 0.1980392156862745 on epoch=499
05/16/2022 16:35:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.88 on epoch=502
05/16/2022 16:35:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.89 on epoch=504
05/16/2022 16:35:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=507
05/16/2022 16:35:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.86 on epoch=509
05/16/2022 16:35:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.94 on epoch=512
05/16/2022 16:35:35 - INFO - __main__ - Global step 2050 Train loss 0.91 Classification-F1 0.12447885646217988 on epoch=512
05/16/2022 16:35:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.94 on epoch=514
05/16/2022 16:35:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.91 on epoch=517
05/16/2022 16:35:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
05/16/2022 16:35:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.87 on epoch=522
05/16/2022 16:35:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.93 on epoch=524
05/16/2022 16:35:43 - INFO - __main__ - Global step 2100 Train loss 0.92 Classification-F1 0.12391774891774893 on epoch=524
05/16/2022 16:35:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.88 on epoch=527
05/16/2022 16:35:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
05/16/2022 16:35:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/16/2022 16:35:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/16/2022 16:35:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.03 on epoch=537
05/16/2022 16:35:50 - INFO - __main__ - Global step 2150 Train loss 0.99 Classification-F1 0.13034188034188032 on epoch=537
05/16/2022 16:35:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.93 on epoch=539
05/16/2022 16:35:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.03 on epoch=542
05/16/2022 16:35:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.86 on epoch=544
05/16/2022 16:35:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.03 on epoch=547
05/16/2022 16:35:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.94 on epoch=549
05/16/2022 16:35:57 - INFO - __main__ - Global step 2200 Train loss 0.96 Classification-F1 0.12439024390243902 on epoch=549
05/16/2022 16:35:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.93 on epoch=552
05/16/2022 16:36:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.90 on epoch=554
05/16/2022 16:36:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/16/2022 16:36:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.91 on epoch=559
05/16/2022 16:36:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
05/16/2022 16:36:04 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.18674449412154331 on epoch=562
05/16/2022 16:36:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.89 on epoch=564
05/16/2022 16:36:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.07 on epoch=567
05/16/2022 16:36:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.99 on epoch=569
05/16/2022 16:36:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
05/16/2022 16:36:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.96 on epoch=574
05/16/2022 16:36:12 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.10987903225806452 on epoch=574
05/16/2022 16:36:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.90 on epoch=577
05/16/2022 16:36:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.03 on epoch=579
05/16/2022 16:36:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/16/2022 16:36:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.97 on epoch=584
05/16/2022 16:36:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.99 on epoch=587
05/16/2022 16:36:19 - INFO - __main__ - Global step 2350 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=587
05/16/2022 16:36:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.93 on epoch=589
05/16/2022 16:36:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.98 on epoch=592
05/16/2022 16:36:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.98 on epoch=594
05/16/2022 16:36:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.93 on epoch=597
05/16/2022 16:36:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.06 on epoch=599
05/16/2022 16:36:27 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.13865546218487396 on epoch=599
05/16/2022 16:36:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.03 on epoch=602
05/16/2022 16:36:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.90 on epoch=604
05/16/2022 16:36:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.01 on epoch=607
05/16/2022 16:36:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
05/16/2022 16:36:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.93 on epoch=612
05/16/2022 16:36:34 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.2440667318162781 on epoch=612
05/16/2022 16:36:34 - INFO - __main__ - Saving model with best Classification-F1: 0.22426438296003515 -> 0.2440667318162781 on epoch=612, global_step=2450
05/16/2022 16:36:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.85 on epoch=614
05/16/2022 16:36:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.92 on epoch=617
05/16/2022 16:36:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/16/2022 16:36:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
05/16/2022 16:36:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/16/2022 16:36:42 - INFO - __main__ - Global step 2500 Train loss 0.94 Classification-F1 0.1 on epoch=624
05/16/2022 16:36:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/16/2022 16:36:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.96 on epoch=629
05/16/2022 16:36:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
05/16/2022 16:36:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
05/16/2022 16:36:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.96 on epoch=637
05/16/2022 16:36:49 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.17893217893217894 on epoch=637
05/16/2022 16:36:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.84 on epoch=639
05/16/2022 16:36:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
05/16/2022 16:36:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.05 on epoch=644
05/16/2022 16:36:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.02 on epoch=647
05/16/2022 16:36:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.96 on epoch=649
05/16/2022 16:36:57 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.10666666666666667 on epoch=649
05/16/2022 16:36:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.84 on epoch=652
05/16/2022 16:36:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.86 on epoch=654
05/16/2022 16:37:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/16/2022 16:37:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.98 on epoch=659
05/16/2022 16:37:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.94 on epoch=662
05/16/2022 16:37:04 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.10677083333333333 on epoch=662
05/16/2022 16:37:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.87 on epoch=664
05/16/2022 16:37:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/16/2022 16:37:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/16/2022 16:37:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.92 on epoch=672
05/16/2022 16:37:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=674
05/16/2022 16:37:12 - INFO - __main__ - Global step 2700 Train loss 0.91 Classification-F1 0.1 on epoch=674
05/16/2022 16:37:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/16/2022 16:37:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
05/16/2022 16:37:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
05/16/2022 16:37:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/16/2022 16:37:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/16/2022 16:37:19 - INFO - __main__ - Global step 2750 Train loss 0.91 Classification-F1 0.09333333333333334 on epoch=687
05/16/2022 16:37:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/16/2022 16:37:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/16/2022 16:37:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.96 on epoch=694
05/16/2022 16:37:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
05/16/2022 16:37:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
05/16/2022 16:37:27 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.13167388167388167 on epoch=699
05/16/2022 16:37:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=702
05/16/2022 16:37:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/16/2022 16:37:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
05/16/2022 16:37:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.84 on epoch=709
05/16/2022 16:37:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=712
05/16/2022 16:37:34 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.18276972624798712 on epoch=712
05/16/2022 16:37:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/16/2022 16:37:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.91 on epoch=717
05/16/2022 16:37:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.78 on epoch=719
05/16/2022 16:37:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.86 on epoch=722
05/16/2022 16:37:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.88 on epoch=724
05/16/2022 16:37:42 - INFO - __main__ - Global step 2900 Train loss 0.88 Classification-F1 0.202020202020202 on epoch=724
05/16/2022 16:37:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.90 on epoch=727
05/16/2022 16:37:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.88 on epoch=729
05/16/2022 16:37:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.99 on epoch=732
05/16/2022 16:37:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.88 on epoch=734
05/16/2022 16:37:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
05/16/2022 16:37:49 - INFO - __main__ - Global step 2950 Train loss 0.92 Classification-F1 0.16071428571428573 on epoch=737
05/16/2022 16:37:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.95 on epoch=739
05/16/2022 16:37:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.93 on epoch=742
05/16/2022 16:37:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.86 on epoch=744
05/16/2022 16:37:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/16/2022 16:37:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/16/2022 16:37:57 - INFO - __main__ - Global step 3000 Train loss 0.93 Classification-F1 0.21354166666666669 on epoch=749
05/16/2022 16:37:57 - INFO - __main__ - save last model!
05/16/2022 16:37:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 16:37:57 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 16:37:57 - INFO - __main__ - Printing 3 examples
05/16/2022 16:37:57 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:37:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:37:57 - INFO - __main__ - Printing 3 examples
05/16/2022 16:37:57 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:37:57 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:37:57 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:37:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:37:57 - INFO - __main__ - Printing 3 examples
05/16/2022 16:37:57 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:37:57 - INFO - __main__ - ['others']
05/16/2022 16:37:57 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:37:57 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:37:57 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:37:59 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:38:03 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:38:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:38:03 - INFO - __main__ - Starting training!
05/16/2022 16:38:06 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 16:38:49 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.5_8_predictions.txt
05/16/2022 16:38:49 - INFO - __main__ - Classification-F1 on test data: 0.0580
05/16/2022 16:38:50 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.2440667318162781, test_performance=0.057998635256980235
05/16/2022 16:38:50 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
05/16/2022 16:38:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:38:51 - INFO - __main__ - Printing 3 examples
05/16/2022 16:38:51 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:38:51 - INFO - __main__ - ['others']
05/16/2022 16:38:51 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:38:51 - INFO - __main__ - ['others']
05/16/2022 16:38:51 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:38:51 - INFO - __main__ - ['others']
05/16/2022 16:38:51 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:38:51 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:38:51 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:38:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:38:51 - INFO - __main__ - Printing 3 examples
05/16/2022 16:38:51 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:38:51 - INFO - __main__ - ['others']
05/16/2022 16:38:51 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:38:51 - INFO - __main__ - ['others']
05/16/2022 16:38:51 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:38:51 - INFO - __main__ - ['others']
05/16/2022 16:38:51 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:38:51 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:38:51 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:38:57 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:38:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:38:57 - INFO - __main__ - Starting training!
05/16/2022 16:38:59 - INFO - __main__ - Step 10 Global step 10 Train loss 6.82 on epoch=2
05/16/2022 16:39:00 - INFO - __main__ - Step 20 Global step 20 Train loss 6.60 on epoch=4
05/16/2022 16:39:01 - INFO - __main__ - Step 30 Global step 30 Train loss 6.18 on epoch=7
05/16/2022 16:39:02 - INFO - __main__ - Step 40 Global step 40 Train loss 6.08 on epoch=9
05/16/2022 16:39:04 - INFO - __main__ - Step 50 Global step 50 Train loss 5.78 on epoch=12
05/16/2022 16:39:05 - INFO - __main__ - Global step 50 Train loss 6.29 Classification-F1 0.0 on epoch=12
05/16/2022 16:39:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 16:39:06 - INFO - __main__ - Step 60 Global step 60 Train loss 5.61 on epoch=14
05/16/2022 16:39:08 - INFO - __main__ - Step 70 Global step 70 Train loss 5.57 on epoch=17
05/16/2022 16:39:09 - INFO - __main__ - Step 80 Global step 80 Train loss 5.11 on epoch=19
05/16/2022 16:39:10 - INFO - __main__ - Step 90 Global step 90 Train loss 5.12 on epoch=22
05/16/2022 16:39:11 - INFO - __main__ - Step 100 Global step 100 Train loss 4.93 on epoch=24
05/16/2022 16:39:13 - INFO - __main__ - Global step 100 Train loss 5.27 Classification-F1 0.0 on epoch=24
05/16/2022 16:39:14 - INFO - __main__ - Step 110 Global step 110 Train loss 4.90 on epoch=27
05/16/2022 16:39:15 - INFO - __main__ - Step 120 Global step 120 Train loss 4.72 on epoch=29
05/16/2022 16:39:16 - INFO - __main__ - Step 130 Global step 130 Train loss 4.67 on epoch=32
05/16/2022 16:39:17 - INFO - __main__ - Step 140 Global step 140 Train loss 4.26 on epoch=34
05/16/2022 16:39:19 - INFO - __main__ - Step 150 Global step 150 Train loss 4.33 on epoch=37
05/16/2022 16:39:19 - INFO - __main__ - Global step 150 Train loss 4.58 Classification-F1 0.1 on epoch=37
05/16/2022 16:39:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.1 on epoch=37, global_step=150
05/16/2022 16:39:21 - INFO - __main__ - Step 160 Global step 160 Train loss 4.06 on epoch=39
05/16/2022 16:39:22 - INFO - __main__ - Step 170 Global step 170 Train loss 4.02 on epoch=42
05/16/2022 16:39:23 - INFO - __main__ - Step 180 Global step 180 Train loss 3.65 on epoch=44
05/16/2022 16:39:24 - INFO - __main__ - Step 190 Global step 190 Train loss 3.83 on epoch=47
05/16/2022 16:39:26 - INFO - __main__ - Step 200 Global step 200 Train loss 3.45 on epoch=49
05/16/2022 16:39:26 - INFO - __main__ - Global step 200 Train loss 3.80 Classification-F1 0.1778115501519757 on epoch=49
05/16/2022 16:39:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1778115501519757 on epoch=49, global_step=200
05/16/2022 16:39:27 - INFO - __main__ - Step 210 Global step 210 Train loss 3.38 on epoch=52
05/16/2022 16:39:29 - INFO - __main__ - Step 220 Global step 220 Train loss 3.39 on epoch=54
05/16/2022 16:39:31 - INFO - __main__ - Step 230 Global step 230 Train loss 3.31 on epoch=57
05/16/2022 16:39:32 - INFO - __main__ - Step 240 Global step 240 Train loss 3.15 on epoch=59
05/16/2022 16:39:34 - INFO - __main__ - Step 250 Global step 250 Train loss 3.27 on epoch=62
05/16/2022 16:39:34 - INFO - __main__ - Global step 250 Train loss 3.30 Classification-F1 0.09154929577464789 on epoch=62
05/16/2022 16:39:36 - INFO - __main__ - Step 260 Global step 260 Train loss 2.91 on epoch=64
05/16/2022 16:39:37 - INFO - __main__ - Step 270 Global step 270 Train loss 2.81 on epoch=67
05/16/2022 16:39:38 - INFO - __main__ - Step 280 Global step 280 Train loss 2.67 on epoch=69
05/16/2022 16:39:39 - INFO - __main__ - Step 290 Global step 290 Train loss 2.74 on epoch=72
05/16/2022 16:39:41 - INFO - __main__ - Step 300 Global step 300 Train loss 2.58 on epoch=74
05/16/2022 16:39:41 - INFO - __main__ - Global step 300 Train loss 2.74 Classification-F1 0.13123993558776167 on epoch=74
05/16/2022 16:39:42 - INFO - __main__ - Step 310 Global step 310 Train loss 2.78 on epoch=77
05/16/2022 16:39:44 - INFO - __main__ - Step 320 Global step 320 Train loss 2.45 on epoch=79
05/16/2022 16:39:45 - INFO - __main__ - Step 330 Global step 330 Train loss 2.46 on epoch=82
05/16/2022 16:39:46 - INFO - __main__ - Step 340 Global step 340 Train loss 2.44 on epoch=84
05/16/2022 16:39:48 - INFO - __main__ - Step 350 Global step 350 Train loss 2.39 on epoch=87
05/16/2022 16:39:48 - INFO - __main__ - Global step 350 Train loss 2.50 Classification-F1 0.14509803921568626 on epoch=87
05/16/2022 16:39:50 - INFO - __main__ - Step 360 Global step 360 Train loss 2.24 on epoch=89
05/16/2022 16:39:51 - INFO - __main__ - Step 370 Global step 370 Train loss 2.31 on epoch=92
05/16/2022 16:39:52 - INFO - __main__ - Step 380 Global step 380 Train loss 2.29 on epoch=94
05/16/2022 16:39:54 - INFO - __main__ - Step 390 Global step 390 Train loss 2.29 on epoch=97
05/16/2022 16:39:55 - INFO - __main__ - Step 400 Global step 400 Train loss 2.15 on epoch=99
05/16/2022 16:39:56 - INFO - __main__ - Global step 400 Train loss 2.26 Classification-F1 0.1486842105263158 on epoch=99
05/16/2022 16:39:57 - INFO - __main__ - Step 410 Global step 410 Train loss 2.10 on epoch=102
05/16/2022 16:39:58 - INFO - __main__ - Step 420 Global step 420 Train loss 2.10 on epoch=104
05/16/2022 16:40:00 - INFO - __main__ - Step 430 Global step 430 Train loss 2.00 on epoch=107
05/16/2022 16:40:01 - INFO - __main__ - Step 440 Global step 440 Train loss 1.97 on epoch=109
05/16/2022 16:40:02 - INFO - __main__ - Step 450 Global step 450 Train loss 2.04 on epoch=112
05/16/2022 16:40:03 - INFO - __main__ - Global step 450 Train loss 2.04 Classification-F1 0.1 on epoch=112
05/16/2022 16:40:04 - INFO - __main__ - Step 460 Global step 460 Train loss 2.01 on epoch=114
05/16/2022 16:40:05 - INFO - __main__ - Step 470 Global step 470 Train loss 1.99 on epoch=117
05/16/2022 16:40:06 - INFO - __main__ - Step 480 Global step 480 Train loss 1.97 on epoch=119
05/16/2022 16:40:08 - INFO - __main__ - Step 490 Global step 490 Train loss 1.92 on epoch=122
05/16/2022 16:40:09 - INFO - __main__ - Step 500 Global step 500 Train loss 1.84 on epoch=124
05/16/2022 16:40:09 - INFO - __main__ - Global step 500 Train loss 1.95 Classification-F1 0.1 on epoch=124
05/16/2022 16:40:11 - INFO - __main__ - Step 510 Global step 510 Train loss 1.93 on epoch=127
05/16/2022 16:40:12 - INFO - __main__ - Step 520 Global step 520 Train loss 1.64 on epoch=129
05/16/2022 16:40:13 - INFO - __main__ - Step 530 Global step 530 Train loss 1.88 on epoch=132
05/16/2022 16:40:14 - INFO - __main__ - Step 540 Global step 540 Train loss 1.63 on epoch=134
05/16/2022 16:40:16 - INFO - __main__ - Step 550 Global step 550 Train loss 1.72 on epoch=137
05/16/2022 16:40:16 - INFO - __main__ - Global step 550 Train loss 1.76 Classification-F1 0.1 on epoch=137
05/16/2022 16:40:18 - INFO - __main__ - Step 560 Global step 560 Train loss 1.75 on epoch=139
05/16/2022 16:40:19 - INFO - __main__ - Step 570 Global step 570 Train loss 1.79 on epoch=142
05/16/2022 16:40:20 - INFO - __main__ - Step 580 Global step 580 Train loss 1.78 on epoch=144
05/16/2022 16:40:21 - INFO - __main__ - Step 590 Global step 590 Train loss 1.65 on epoch=147
05/16/2022 16:40:22 - INFO - __main__ - Step 600 Global step 600 Train loss 1.59 on epoch=149
05/16/2022 16:40:23 - INFO - __main__ - Global step 600 Train loss 1.71 Classification-F1 0.15782608695652173 on epoch=149
05/16/2022 16:40:24 - INFO - __main__ - Step 610 Global step 610 Train loss 1.63 on epoch=152
05/16/2022 16:40:26 - INFO - __main__ - Step 620 Global step 620 Train loss 1.61 on epoch=154
05/16/2022 16:40:27 - INFO - __main__ - Step 630 Global step 630 Train loss 1.57 on epoch=157
05/16/2022 16:40:28 - INFO - __main__ - Step 640 Global step 640 Train loss 1.60 on epoch=159
05/16/2022 16:40:29 - INFO - __main__ - Step 650 Global step 650 Train loss 1.53 on epoch=162
05/16/2022 16:40:30 - INFO - __main__ - Global step 650 Train loss 1.59 Classification-F1 0.13067758749069247 on epoch=162
05/16/2022 16:40:31 - INFO - __main__ - Step 660 Global step 660 Train loss 1.48 on epoch=164
05/16/2022 16:40:32 - INFO - __main__ - Step 670 Global step 670 Train loss 1.57 on epoch=167
05/16/2022 16:40:33 - INFO - __main__ - Step 680 Global step 680 Train loss 1.46 on epoch=169
05/16/2022 16:40:35 - INFO - __main__ - Step 690 Global step 690 Train loss 1.50 on epoch=172
05/16/2022 16:40:36 - INFO - __main__ - Step 700 Global step 700 Train loss 1.30 on epoch=174
05/16/2022 16:40:36 - INFO - __main__ - Global step 700 Train loss 1.46 Classification-F1 0.1 on epoch=174
05/16/2022 16:40:38 - INFO - __main__ - Step 710 Global step 710 Train loss 1.37 on epoch=177
05/16/2022 16:40:39 - INFO - __main__ - Step 720 Global step 720 Train loss 1.31 on epoch=179
05/16/2022 16:40:40 - INFO - __main__ - Step 730 Global step 730 Train loss 1.37 on epoch=182
05/16/2022 16:40:41 - INFO - __main__ - Step 740 Global step 740 Train loss 1.35 on epoch=184
05/16/2022 16:40:43 - INFO - __main__ - Step 750 Global step 750 Train loss 1.47 on epoch=187
05/16/2022 16:40:43 - INFO - __main__ - Global step 750 Train loss 1.38 Classification-F1 0.1 on epoch=187
05/16/2022 16:40:45 - INFO - __main__ - Step 760 Global step 760 Train loss 1.32 on epoch=189
05/16/2022 16:40:46 - INFO - __main__ - Step 770 Global step 770 Train loss 1.41 on epoch=192
05/16/2022 16:40:47 - INFO - __main__ - Step 780 Global step 780 Train loss 1.34 on epoch=194
05/16/2022 16:40:48 - INFO - __main__ - Step 790 Global step 790 Train loss 1.43 on epoch=197
05/16/2022 16:40:50 - INFO - __main__ - Step 800 Global step 800 Train loss 1.29 on epoch=199
05/16/2022 16:40:50 - INFO - __main__ - Global step 800 Train loss 1.36 Classification-F1 0.1 on epoch=199
05/16/2022 16:40:52 - INFO - __main__ - Step 810 Global step 810 Train loss 1.31 on epoch=202
05/16/2022 16:40:53 - INFO - __main__ - Step 820 Global step 820 Train loss 1.37 on epoch=204
05/16/2022 16:40:54 - INFO - __main__ - Step 830 Global step 830 Train loss 1.23 on epoch=207
05/16/2022 16:40:56 - INFO - __main__ - Step 840 Global step 840 Train loss 1.31 on epoch=209
05/16/2022 16:40:57 - INFO - __main__ - Step 850 Global step 850 Train loss 1.20 on epoch=212
05/16/2022 16:40:57 - INFO - __main__ - Global step 850 Train loss 1.28 Classification-F1 0.1 on epoch=212
05/16/2022 16:40:59 - INFO - __main__ - Step 860 Global step 860 Train loss 1.19 on epoch=214
05/16/2022 16:41:00 - INFO - __main__ - Step 870 Global step 870 Train loss 1.11 on epoch=217
05/16/2022 16:41:01 - INFO - __main__ - Step 880 Global step 880 Train loss 1.09 on epoch=219
05/16/2022 16:41:02 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
05/16/2022 16:41:04 - INFO - __main__ - Step 900 Global step 900 Train loss 1.23 on epoch=224
05/16/2022 16:41:04 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.1 on epoch=224
05/16/2022 16:41:05 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/16/2022 16:41:07 - INFO - __main__ - Step 920 Global step 920 Train loss 1.14 on epoch=229
05/16/2022 16:41:08 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=232
05/16/2022 16:41:09 - INFO - __main__ - Step 940 Global step 940 Train loss 1.13 on epoch=234
05/16/2022 16:41:10 - INFO - __main__ - Step 950 Global step 950 Train loss 1.12 on epoch=237
05/16/2022 16:41:11 - INFO - __main__ - Global step 950 Train loss 1.17 Classification-F1 0.1 on epoch=237
05/16/2022 16:41:12 - INFO - __main__ - Step 960 Global step 960 Train loss 1.27 on epoch=239
05/16/2022 16:41:13 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=242
05/16/2022 16:41:15 - INFO - __main__ - Step 980 Global step 980 Train loss 1.14 on epoch=244
05/16/2022 16:41:16 - INFO - __main__ - Step 990 Global step 990 Train loss 1.21 on epoch=247
05/16/2022 16:41:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.22 on epoch=249
05/16/2022 16:41:18 - INFO - __main__ - Global step 1000 Train loss 1.20 Classification-F1 0.1 on epoch=249
05/16/2022 16:41:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.10 on epoch=252
05/16/2022 16:41:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.98 on epoch=254
05/16/2022 16:41:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.29 on epoch=257
05/16/2022 16:41:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.19 on epoch=259
05/16/2022 16:41:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.20 on epoch=262
05/16/2022 16:41:25 - INFO - __main__ - Global step 1050 Train loss 1.15 Classification-F1 0.09493670886075949 on epoch=262
05/16/2022 16:41:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.09 on epoch=264
05/16/2022 16:41:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.00 on epoch=267
05/16/2022 16:41:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.06 on epoch=269
05/16/2022 16:41:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.22 on epoch=272
05/16/2022 16:41:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.98 on epoch=274
05/16/2022 16:41:32 - INFO - __main__ - Global step 1100 Train loss 1.07 Classification-F1 0.1 on epoch=274
05/16/2022 16:41:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.04 on epoch=277
05/16/2022 16:41:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.08 on epoch=279
05/16/2022 16:41:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.04 on epoch=282
05/16/2022 16:41:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.08 on epoch=284
05/16/2022 16:41:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.02 on epoch=287
05/16/2022 16:41:39 - INFO - __main__ - Global step 1150 Train loss 1.05 Classification-F1 0.1 on epoch=287
05/16/2022 16:41:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.07 on epoch=289
05/16/2022 16:41:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.14 on epoch=292
05/16/2022 16:41:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.10 on epoch=294
05/16/2022 16:41:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.07 on epoch=297
05/16/2022 16:41:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.07 on epoch=299
05/16/2022 16:41:46 - INFO - __main__ - Global step 1200 Train loss 1.09 Classification-F1 0.1 on epoch=299
05/16/2022 16:41:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
05/16/2022 16:41:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.91 on epoch=304
05/16/2022 16:41:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.10 on epoch=307
05/16/2022 16:41:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/16/2022 16:41:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
05/16/2022 16:41:53 - INFO - __main__ - Global step 1250 Train loss 1.09 Classification-F1 0.1 on epoch=312
05/16/2022 16:41:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=314
05/16/2022 16:41:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.07 on epoch=317
05/16/2022 16:41:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.01 on epoch=319
05/16/2022 16:41:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.94 on epoch=322
05/16/2022 16:41:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.99 on epoch=324
05/16/2022 16:41:59 - INFO - __main__ - Global step 1300 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=324
05/16/2022 16:42:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.12 on epoch=327
05/16/2022 16:42:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.96 on epoch=329
05/16/2022 16:42:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.05 on epoch=332
05/16/2022 16:42:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.02 on epoch=334
05/16/2022 16:42:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.11 on epoch=337
05/16/2022 16:42:06 - INFO - __main__ - Global step 1350 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=337
05/16/2022 16:42:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.06 on epoch=339
05/16/2022 16:42:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/16/2022 16:42:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.99 on epoch=344
05/16/2022 16:42:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.12 on epoch=347
05/16/2022 16:42:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
05/16/2022 16:42:13 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.15441176470588236 on epoch=349
05/16/2022 16:42:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.03 on epoch=352
05/16/2022 16:42:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/16/2022 16:42:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.99 on epoch=357
05/16/2022 16:42:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.93 on epoch=359
05/16/2022 16:42:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.02 on epoch=362
05/16/2022 16:42:20 - INFO - __main__ - Global step 1450 Train loss 1.00 Classification-F1 0.1 on epoch=362
05/16/2022 16:42:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.05 on epoch=364
05/16/2022 16:42:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.99 on epoch=367
05/16/2022 16:42:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.11 on epoch=369
05/16/2022 16:42:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.04 on epoch=372
05/16/2022 16:42:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.04 on epoch=374
05/16/2022 16:42:27 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=374
05/16/2022 16:42:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.00 on epoch=377
05/16/2022 16:42:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.01 on epoch=379
05/16/2022 16:42:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.91 on epoch=382
05/16/2022 16:42:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
05/16/2022 16:42:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.95 on epoch=387
05/16/2022 16:42:33 - INFO - __main__ - Global step 1550 Train loss 0.99 Classification-F1 0.1 on epoch=387
05/16/2022 16:42:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.03 on epoch=389
05/16/2022 16:42:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.00 on epoch=392
05/16/2022 16:42:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.97 on epoch=394
05/16/2022 16:42:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.04 on epoch=397
05/16/2022 16:42:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
05/16/2022 16:42:40 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.1302118933697881 on epoch=399
05/16/2022 16:42:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.01 on epoch=402
05/16/2022 16:42:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/16/2022 16:42:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.04 on epoch=407
05/16/2022 16:42:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.99 on epoch=409
05/16/2022 16:42:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.09 on epoch=412
05/16/2022 16:42:47 - INFO - __main__ - Global step 1650 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=412
05/16/2022 16:42:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.08 on epoch=414
05/16/2022 16:42:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.04 on epoch=417
05/16/2022 16:42:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
05/16/2022 16:42:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.03 on epoch=422
05/16/2022 16:42:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=424
05/16/2022 16:42:54 - INFO - __main__ - Global step 1700 Train loss 1.05 Classification-F1 0.2120826259196378 on epoch=424
05/16/2022 16:42:54 - INFO - __main__ - Saving model with best Classification-F1: 0.1778115501519757 -> 0.2120826259196378 on epoch=424, global_step=1700
05/16/2022 16:42:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.96 on epoch=427
05/16/2022 16:42:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/16/2022 16:42:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.90 on epoch=432
05/16/2022 16:42:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.05 on epoch=434
05/16/2022 16:43:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.91 on epoch=437
05/16/2022 16:43:01 - INFO - __main__ - Global step 1750 Train loss 0.97 Classification-F1 0.1850282485875706 on epoch=437
05/16/2022 16:43:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=439
05/16/2022 16:43:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.98 on epoch=442
05/16/2022 16:43:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/16/2022 16:43:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.99 on epoch=447
05/16/2022 16:43:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.01 on epoch=449
05/16/2022 16:43:07 - INFO - __main__ - Global step 1800 Train loss 0.98 Classification-F1 0.13904109589041097 on epoch=449
05/16/2022 16:43:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/16/2022 16:43:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
05/16/2022 16:43:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.99 on epoch=457
05/16/2022 16:43:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.98 on epoch=459
05/16/2022 16:43:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=462
05/16/2022 16:43:14 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.10869565217391305 on epoch=462
05/16/2022 16:43:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.06 on epoch=464
05/16/2022 16:43:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.02 on epoch=467
05/16/2022 16:43:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.02 on epoch=469
05/16/2022 16:43:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.10 on epoch=472
05/16/2022 16:43:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.98 on epoch=474
05/16/2022 16:43:21 - INFO - __main__ - Global step 1900 Train loss 1.03 Classification-F1 0.09493670886075949 on epoch=474
05/16/2022 16:43:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
05/16/2022 16:43:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
05/16/2022 16:43:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.00 on epoch=482
05/16/2022 16:43:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/16/2022 16:43:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.92 on epoch=487
05/16/2022 16:43:29 - INFO - __main__ - Global step 1950 Train loss 0.96 Classification-F1 0.09090909090909091 on epoch=487
05/16/2022 16:43:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.83 on epoch=489
05/16/2022 16:43:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/16/2022 16:43:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.98 on epoch=494
05/16/2022 16:43:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.98 on epoch=497
05/16/2022 16:43:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.93 on epoch=499
05/16/2022 16:43:36 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.0945945945945946 on epoch=499
05/16/2022 16:43:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.93 on epoch=502
05/16/2022 16:43:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.95 on epoch=504
05/16/2022 16:43:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.95 on epoch=507
05/16/2022 16:43:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.04 on epoch=509
05/16/2022 16:43:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.87 on epoch=512
05/16/2022 16:43:43 - INFO - __main__ - Global step 2050 Train loss 0.95 Classification-F1 0.15555555555555556 on epoch=512
05/16/2022 16:43:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=514
05/16/2022 16:43:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.90 on epoch=517
05/16/2022 16:43:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.97 on epoch=519
05/16/2022 16:43:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
05/16/2022 16:43:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.91 on epoch=524
05/16/2022 16:43:50 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.10380835380835382 on epoch=524
05/16/2022 16:43:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.00 on epoch=527
05/16/2022 16:43:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.03 on epoch=529
05/16/2022 16:43:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/16/2022 16:43:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.87 on epoch=534
05/16/2022 16:43:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.86 on epoch=537
05/16/2022 16:43:57 - INFO - __main__ - Global step 2150 Train loss 0.95 Classification-F1 0.1 on epoch=537
05/16/2022 16:43:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.79 on epoch=539
05/16/2022 16:44:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.96 on epoch=542
05/16/2022 16:44:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.95 on epoch=544
05/16/2022 16:44:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.95 on epoch=547
05/16/2022 16:44:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=549
05/16/2022 16:44:04 - INFO - __main__ - Global step 2200 Train loss 0.91 Classification-F1 0.1388888888888889 on epoch=549
05/16/2022 16:44:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.97 on epoch=552
05/16/2022 16:44:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.87 on epoch=554
05/16/2022 16:44:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.94 on epoch=557
05/16/2022 16:44:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/16/2022 16:44:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
05/16/2022 16:44:11 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.09615384615384615 on epoch=562
05/16/2022 16:44:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.88 on epoch=564
05/16/2022 16:44:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
05/16/2022 16:44:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.96 on epoch=569
05/16/2022 16:44:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
05/16/2022 16:44:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.93 on epoch=574
05/16/2022 16:44:17 - INFO - __main__ - Global step 2300 Train loss 0.94 Classification-F1 0.1503587736464449 on epoch=574
05/16/2022 16:44:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.94 on epoch=577
05/16/2022 16:44:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/16/2022 16:44:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.94 on epoch=582
05/16/2022 16:44:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.89 on epoch=584
05/16/2022 16:44:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.90 on epoch=587
05/16/2022 16:44:24 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.09493670886075949 on epoch=587
05/16/2022 16:44:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.03 on epoch=589
05/16/2022 16:44:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.91 on epoch=592
05/16/2022 16:44:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.89 on epoch=594
05/16/2022 16:44:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
05/16/2022 16:44:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.81 on epoch=599
05/16/2022 16:44:31 - INFO - __main__ - Global step 2400 Train loss 0.92 Classification-F1 0.1 on epoch=599
05/16/2022 16:44:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
05/16/2022 16:44:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/16/2022 16:44:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.92 on epoch=607
05/16/2022 16:44:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.93 on epoch=609
05/16/2022 16:44:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
05/16/2022 16:44:38 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1 on epoch=612
05/16/2022 16:44:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.86 on epoch=614
05/16/2022 16:44:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.91 on epoch=617
05/16/2022 16:44:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.97 on epoch=619
05/16/2022 16:44:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/16/2022 16:44:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/16/2022 16:44:44 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.14095238095238094 on epoch=624
05/16/2022 16:44:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.94 on epoch=627
05/16/2022 16:44:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.95 on epoch=629
05/16/2022 16:44:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=632
05/16/2022 16:44:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/16/2022 16:44:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/16/2022 16:44:51 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.0974025974025974 on epoch=637
05/16/2022 16:44:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
05/16/2022 16:44:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.88 on epoch=642
05/16/2022 16:44:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.96 on epoch=644
05/16/2022 16:44:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.90 on epoch=647
05/16/2022 16:44:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.01 on epoch=649
05/16/2022 16:44:58 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.10126582278481013 on epoch=649
05/16/2022 16:44:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/16/2022 16:45:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/16/2022 16:45:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.99 on epoch=657
05/16/2022 16:45:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
05/16/2022 16:45:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.98 on epoch=662
05/16/2022 16:45:05 - INFO - __main__ - Global step 2650 Train loss 0.96 Classification-F1 0.11710526315789474 on epoch=662
05/16/2022 16:45:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.91 on epoch=664
05/16/2022 16:45:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
05/16/2022 16:45:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=669
05/16/2022 16:45:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=672
05/16/2022 16:45:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.89 on epoch=674
05/16/2022 16:45:12 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.14095238095238094 on epoch=674
05/16/2022 16:45:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.94 on epoch=677
05/16/2022 16:45:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
05/16/2022 16:45:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
05/16/2022 16:45:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.88 on epoch=684
05/16/2022 16:45:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.87 on epoch=687
05/16/2022 16:45:19 - INFO - __main__ - Global step 2750 Train loss 0.89 Classification-F1 0.1 on epoch=687
05/16/2022 16:45:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
05/16/2022 16:45:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
05/16/2022 16:45:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/16/2022 16:45:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
05/16/2022 16:45:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.87 on epoch=699
05/16/2022 16:45:26 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.10256410256410256 on epoch=699
05/16/2022 16:45:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.85 on epoch=702
05/16/2022 16:45:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
05/16/2022 16:45:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.87 on epoch=707
05/16/2022 16:45:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/16/2022 16:45:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
05/16/2022 16:45:33 - INFO - __main__ - Global step 2850 Train loss 0.90 Classification-F1 0.1 on epoch=712
05/16/2022 16:45:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.94 on epoch=714
05/16/2022 16:45:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.03 on epoch=717
05/16/2022 16:45:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/16/2022 16:45:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
05/16/2022 16:45:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.93 on epoch=724
05/16/2022 16:45:40 - INFO - __main__ - Global step 2900 Train loss 0.95 Classification-F1 0.11722488038277512 on epoch=724
05/16/2022 16:45:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.88 on epoch=727
05/16/2022 16:45:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/16/2022 16:45:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.87 on epoch=732
05/16/2022 16:45:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.89 on epoch=734
05/16/2022 16:45:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.82 on epoch=737
05/16/2022 16:45:47 - INFO - __main__ - Global step 2950 Train loss 0.88 Classification-F1 0.1565276828434723 on epoch=737
05/16/2022 16:45:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.88 on epoch=739
05/16/2022 16:45:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.88 on epoch=742
05/16/2022 16:45:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.93 on epoch=744
05/16/2022 16:45:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.88 on epoch=747
05/16/2022 16:45:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
05/16/2022 16:45:54 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.1 on epoch=749
05/16/2022 16:45:54 - INFO - __main__ - save last model!
05/16/2022 16:45:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 16:45:54 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 16:45:54 - INFO - __main__ - Printing 3 examples
05/16/2022 16:45:54 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 16:45:54 - INFO - __main__ - ['others']
05/16/2022 16:45:54 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 16:45:54 - INFO - __main__ - ['others']
05/16/2022 16:45:54 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 16:45:54 - INFO - __main__ - ['others']
05/16/2022 16:45:54 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:45:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:45:55 - INFO - __main__ - Printing 3 examples
05/16/2022 16:45:55 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:45:55 - INFO - __main__ - ['others']
05/16/2022 16:45:55 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:45:55 - INFO - __main__ - ['others']
05/16/2022 16:45:55 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:45:55 - INFO - __main__ - ['others']
05/16/2022 16:45:55 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:45:55 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:45:55 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:45:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:45:55 - INFO - __main__ - Printing 3 examples
05/16/2022 16:45:55 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:45:55 - INFO - __main__ - ['others']
05/16/2022 16:45:55 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:45:55 - INFO - __main__ - ['others']
05/16/2022 16:45:55 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:45:55 - INFO - __main__ - ['others']
05/16/2022 16:45:55 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:45:55 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:45:55 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:45:56 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:46:00 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:46:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:46:00 - INFO - __main__ - Starting training!
05/16/2022 16:46:02 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 16:46:45 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.4_8_predictions.txt
05/16/2022 16:46:46 - INFO - __main__ - Classification-F1 on test data: 0.0276
05/16/2022 16:46:46 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.2120826259196378, test_performance=0.027648234964029166
05/16/2022 16:46:46 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
05/16/2022 16:46:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:46:47 - INFO - __main__ - Printing 3 examples
05/16/2022 16:46:47 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:46:47 - INFO - __main__ - ['others']
05/16/2022 16:46:47 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:46:47 - INFO - __main__ - ['others']
05/16/2022 16:46:47 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:46:47 - INFO - __main__ - ['others']
05/16/2022 16:46:47 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:46:47 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:46:47 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:46:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:46:47 - INFO - __main__ - Printing 3 examples
05/16/2022 16:46:47 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:46:47 - INFO - __main__ - ['others']
05/16/2022 16:46:47 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:46:47 - INFO - __main__ - ['others']
05/16/2022 16:46:47 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:46:47 - INFO - __main__ - ['others']
05/16/2022 16:46:47 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:46:47 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:46:47 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:46:53 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:46:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:46:54 - INFO - __main__ - Starting training!
05/16/2022 16:46:55 - INFO - __main__ - Step 10 Global step 10 Train loss 6.65 on epoch=2
05/16/2022 16:46:57 - INFO - __main__ - Step 20 Global step 20 Train loss 6.64 on epoch=4
05/16/2022 16:46:58 - INFO - __main__ - Step 30 Global step 30 Train loss 6.49 on epoch=7
05/16/2022 16:46:59 - INFO - __main__ - Step 40 Global step 40 Train loss 6.36 on epoch=9
05/16/2022 16:47:01 - INFO - __main__ - Step 50 Global step 50 Train loss 6.12 on epoch=12
05/16/2022 16:47:04 - INFO - __main__ - Global step 50 Train loss 6.45 Classification-F1 0.0 on epoch=12
05/16/2022 16:47:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 16:47:06 - INFO - __main__ - Step 60 Global step 60 Train loss 6.00 on epoch=14
05/16/2022 16:47:07 - INFO - __main__ - Step 70 Global step 70 Train loss 5.87 on epoch=17
05/16/2022 16:47:08 - INFO - __main__ - Step 80 Global step 80 Train loss 5.81 on epoch=19
05/16/2022 16:47:10 - INFO - __main__ - Step 90 Global step 90 Train loss 5.79 on epoch=22
05/16/2022 16:47:11 - INFO - __main__ - Step 100 Global step 100 Train loss 5.52 on epoch=24
05/16/2022 16:47:13 - INFO - __main__ - Global step 100 Train loss 5.79 Classification-F1 0.0 on epoch=24
05/16/2022 16:47:15 - INFO - __main__ - Step 110 Global step 110 Train loss 5.57 on epoch=27
05/16/2022 16:47:16 - INFO - __main__ - Step 120 Global step 120 Train loss 5.34 on epoch=29
05/16/2022 16:47:17 - INFO - __main__ - Step 130 Global step 130 Train loss 5.23 on epoch=32
05/16/2022 16:47:19 - INFO - __main__ - Step 140 Global step 140 Train loss 5.11 on epoch=34
05/16/2022 16:47:20 - INFO - __main__ - Step 150 Global step 150 Train loss 4.98 on epoch=37
05/16/2022 16:47:22 - INFO - __main__ - Global step 150 Train loss 5.25 Classification-F1 0.0 on epoch=37
05/16/2022 16:47:23 - INFO - __main__ - Step 160 Global step 160 Train loss 4.78 on epoch=39
05/16/2022 16:47:24 - INFO - __main__ - Step 170 Global step 170 Train loss 4.76 on epoch=42
05/16/2022 16:47:26 - INFO - __main__ - Step 180 Global step 180 Train loss 4.63 on epoch=44
05/16/2022 16:47:27 - INFO - __main__ - Step 190 Global step 190 Train loss 4.63 on epoch=47
05/16/2022 16:47:29 - INFO - __main__ - Step 200 Global step 200 Train loss 4.50 on epoch=49
05/16/2022 16:47:29 - INFO - __main__ - Global step 200 Train loss 4.66 Classification-F1 0.1 on epoch=49
05/16/2022 16:47:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.1 on epoch=49, global_step=200
05/16/2022 16:47:31 - INFO - __main__ - Step 210 Global step 210 Train loss 4.33 on epoch=52
05/16/2022 16:47:32 - INFO - __main__ - Step 220 Global step 220 Train loss 4.18 on epoch=54
05/16/2022 16:47:33 - INFO - __main__ - Step 230 Global step 230 Train loss 4.09 on epoch=57
05/16/2022 16:47:35 - INFO - __main__ - Step 240 Global step 240 Train loss 4.11 on epoch=59
05/16/2022 16:47:36 - INFO - __main__ - Step 250 Global step 250 Train loss 3.99 on epoch=62
05/16/2022 16:47:37 - INFO - __main__ - Global step 250 Train loss 4.14 Classification-F1 0.19865392965696915 on epoch=62
05/16/2022 16:47:37 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.19865392965696915 on epoch=62, global_step=250
05/16/2022 16:47:38 - INFO - __main__ - Step 260 Global step 260 Train loss 3.74 on epoch=64
05/16/2022 16:47:39 - INFO - __main__ - Step 270 Global step 270 Train loss 3.61 on epoch=67
05/16/2022 16:47:41 - INFO - __main__ - Step 280 Global step 280 Train loss 3.54 on epoch=69
05/16/2022 16:47:42 - INFO - __main__ - Step 290 Global step 290 Train loss 3.41 on epoch=72
05/16/2022 16:47:43 - INFO - __main__ - Step 300 Global step 300 Train loss 3.35 on epoch=74
05/16/2022 16:47:44 - INFO - __main__ - Global step 300 Train loss 3.53 Classification-F1 0.09126984126984126 on epoch=74
05/16/2022 16:47:45 - INFO - __main__ - Step 310 Global step 310 Train loss 3.38 on epoch=77
05/16/2022 16:47:47 - INFO - __main__ - Step 320 Global step 320 Train loss 3.20 on epoch=79
05/16/2022 16:47:48 - INFO - __main__ - Step 330 Global step 330 Train loss 3.11 on epoch=82
05/16/2022 16:47:49 - INFO - __main__ - Step 340 Global step 340 Train loss 2.97 on epoch=84
05/16/2022 16:47:51 - INFO - __main__ - Step 350 Global step 350 Train loss 3.16 on epoch=87
05/16/2022 16:47:51 - INFO - __main__ - Global step 350 Train loss 3.16 Classification-F1 0.12368421052631579 on epoch=87
05/16/2022 16:47:52 - INFO - __main__ - Step 360 Global step 360 Train loss 2.98 on epoch=89
05/16/2022 16:47:54 - INFO - __main__ - Step 370 Global step 370 Train loss 3.17 on epoch=92
05/16/2022 16:47:55 - INFO - __main__ - Step 380 Global step 380 Train loss 2.83 on epoch=94
05/16/2022 16:47:56 - INFO - __main__ - Step 390 Global step 390 Train loss 2.92 on epoch=97
05/16/2022 16:47:58 - INFO - __main__ - Step 400 Global step 400 Train loss 2.84 on epoch=99
05/16/2022 16:47:58 - INFO - __main__ - Global step 400 Train loss 2.95 Classification-F1 0.1238095238095238 on epoch=99
05/16/2022 16:48:00 - INFO - __main__ - Step 410 Global step 410 Train loss 2.79 on epoch=102
05/16/2022 16:48:01 - INFO - __main__ - Step 420 Global step 420 Train loss 2.67 on epoch=104
05/16/2022 16:48:02 - INFO - __main__ - Step 430 Global step 430 Train loss 2.74 on epoch=107
05/16/2022 16:48:04 - INFO - __main__ - Step 440 Global step 440 Train loss 2.57 on epoch=109
05/16/2022 16:48:05 - INFO - __main__ - Step 450 Global step 450 Train loss 2.61 on epoch=112
05/16/2022 16:48:06 - INFO - __main__ - Global step 450 Train loss 2.68 Classification-F1 0.1 on epoch=112
05/16/2022 16:48:07 - INFO - __main__ - Step 460 Global step 460 Train loss 2.50 on epoch=114
05/16/2022 16:48:09 - INFO - __main__ - Step 470 Global step 470 Train loss 2.54 on epoch=117
05/16/2022 16:48:10 - INFO - __main__ - Step 480 Global step 480 Train loss 2.53 on epoch=119
05/16/2022 16:48:11 - INFO - __main__ - Step 490 Global step 490 Train loss 2.69 on epoch=122
05/16/2022 16:48:13 - INFO - __main__ - Step 500 Global step 500 Train loss 2.50 on epoch=124
05/16/2022 16:48:13 - INFO - __main__ - Global step 500 Train loss 2.55 Classification-F1 0.1 on epoch=124
05/16/2022 16:48:15 - INFO - __main__ - Step 510 Global step 510 Train loss 2.38 on epoch=127
05/16/2022 16:48:16 - INFO - __main__ - Step 520 Global step 520 Train loss 2.27 on epoch=129
05/16/2022 16:48:17 - INFO - __main__ - Step 530 Global step 530 Train loss 2.30 on epoch=132
05/16/2022 16:48:19 - INFO - __main__ - Step 540 Global step 540 Train loss 2.09 on epoch=134
05/16/2022 16:48:20 - INFO - __main__ - Step 550 Global step 550 Train loss 2.21 on epoch=137
05/16/2022 16:48:21 - INFO - __main__ - Global step 550 Train loss 2.25 Classification-F1 0.18284347231715653 on epoch=137
05/16/2022 16:48:22 - INFO - __main__ - Step 560 Global step 560 Train loss 2.14 on epoch=139
05/16/2022 16:48:23 - INFO - __main__ - Step 570 Global step 570 Train loss 2.19 on epoch=142
05/16/2022 16:48:25 - INFO - __main__ - Step 580 Global step 580 Train loss 2.10 on epoch=144
05/16/2022 16:48:26 - INFO - __main__ - Step 590 Global step 590 Train loss 2.08 on epoch=147
05/16/2022 16:48:27 - INFO - __main__ - Step 600 Global step 600 Train loss 1.99 on epoch=149
05/16/2022 16:48:28 - INFO - __main__ - Global step 600 Train loss 2.10 Classification-F1 0.1715492957746479 on epoch=149
05/16/2022 16:48:29 - INFO - __main__ - Step 610 Global step 610 Train loss 2.11 on epoch=152
05/16/2022 16:48:30 - INFO - __main__ - Step 620 Global step 620 Train loss 2.06 on epoch=154
05/16/2022 16:48:32 - INFO - __main__ - Step 630 Global step 630 Train loss 2.03 on epoch=157
05/16/2022 16:48:33 - INFO - __main__ - Step 640 Global step 640 Train loss 1.95 on epoch=159
05/16/2022 16:48:34 - INFO - __main__ - Step 650 Global step 650 Train loss 2.04 on epoch=162
05/16/2022 16:48:35 - INFO - __main__ - Global step 650 Train loss 2.04 Classification-F1 0.11439888164026094 on epoch=162
05/16/2022 16:48:36 - INFO - __main__ - Step 660 Global step 660 Train loss 2.00 on epoch=164
05/16/2022 16:48:38 - INFO - __main__ - Step 670 Global step 670 Train loss 2.06 on epoch=167
05/16/2022 16:48:39 - INFO - __main__ - Step 680 Global step 680 Train loss 1.92 on epoch=169
05/16/2022 16:48:41 - INFO - __main__ - Step 690 Global step 690 Train loss 1.95 on epoch=172
05/16/2022 16:48:42 - INFO - __main__ - Step 700 Global step 700 Train loss 2.01 on epoch=174
05/16/2022 16:48:42 - INFO - __main__ - Global step 700 Train loss 1.99 Classification-F1 0.08658008658008658 on epoch=174
05/16/2022 16:48:44 - INFO - __main__ - Step 710 Global step 710 Train loss 2.13 on epoch=177
05/16/2022 16:48:45 - INFO - __main__ - Step 720 Global step 720 Train loss 1.90 on epoch=179
05/16/2022 16:48:46 - INFO - __main__ - Step 730 Global step 730 Train loss 1.87 on epoch=182
05/16/2022 16:48:47 - INFO - __main__ - Step 740 Global step 740 Train loss 1.89 on epoch=184
05/16/2022 16:48:49 - INFO - __main__ - Step 750 Global step 750 Train loss 1.86 on epoch=187
05/16/2022 16:48:49 - INFO - __main__ - Global step 750 Train loss 1.93 Classification-F1 0.15339578454332553 on epoch=187
05/16/2022 16:48:51 - INFO - __main__ - Step 760 Global step 760 Train loss 1.88 on epoch=189
05/16/2022 16:48:52 - INFO - __main__ - Step 770 Global step 770 Train loss 1.76 on epoch=192
05/16/2022 16:48:53 - INFO - __main__ - Step 780 Global step 780 Train loss 1.60 on epoch=194
05/16/2022 16:48:54 - INFO - __main__ - Step 790 Global step 790 Train loss 1.70 on epoch=197
05/16/2022 16:48:56 - INFO - __main__ - Step 800 Global step 800 Train loss 1.73 on epoch=199
05/16/2022 16:48:56 - INFO - __main__ - Global step 800 Train loss 1.74 Classification-F1 0.17368421052631577 on epoch=199
05/16/2022 16:48:58 - INFO - __main__ - Step 810 Global step 810 Train loss 1.79 on epoch=202
05/16/2022 16:48:59 - INFO - __main__ - Step 820 Global step 820 Train loss 1.68 on epoch=204
05/16/2022 16:49:00 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/16/2022 16:49:02 - INFO - __main__ - Step 840 Global step 840 Train loss 1.62 on epoch=209
05/16/2022 16:49:03 - INFO - __main__ - Step 850 Global step 850 Train loss 1.69 on epoch=212
05/16/2022 16:49:03 - INFO - __main__ - Global step 850 Train loss 1.69 Classification-F1 0.14621798689696247 on epoch=212
05/16/2022 16:49:05 - INFO - __main__ - Step 860 Global step 860 Train loss 1.69 on epoch=214
05/16/2022 16:49:06 - INFO - __main__ - Step 870 Global step 870 Train loss 1.85 on epoch=217
05/16/2022 16:49:07 - INFO - __main__ - Step 880 Global step 880 Train loss 1.42 on epoch=219
05/16/2022 16:49:09 - INFO - __main__ - Step 890 Global step 890 Train loss 1.81 on epoch=222
05/16/2022 16:49:10 - INFO - __main__ - Step 900 Global step 900 Train loss 1.64 on epoch=224
05/16/2022 16:49:10 - INFO - __main__ - Global step 900 Train loss 1.68 Classification-F1 0.13067758749069247 on epoch=224
05/16/2022 16:49:12 - INFO - __main__ - Step 910 Global step 910 Train loss 1.66 on epoch=227
05/16/2022 16:49:13 - INFO - __main__ - Step 920 Global step 920 Train loss 1.57 on epoch=229
05/16/2022 16:49:14 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=232
05/16/2022 16:49:16 - INFO - __main__ - Step 940 Global step 940 Train loss 1.48 on epoch=234
05/16/2022 16:49:17 - INFO - __main__ - Step 950 Global step 950 Train loss 1.48 on epoch=237
05/16/2022 16:49:17 - INFO - __main__ - Global step 950 Train loss 1.54 Classification-F1 0.1458980044345898 on epoch=237
05/16/2022 16:49:19 - INFO - __main__ - Step 960 Global step 960 Train loss 1.45 on epoch=239
05/16/2022 16:49:20 - INFO - __main__ - Step 970 Global step 970 Train loss 1.52 on epoch=242
05/16/2022 16:49:21 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
05/16/2022 16:49:23 - INFO - __main__ - Step 990 Global step 990 Train loss 1.48 on epoch=247
05/16/2022 16:49:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.39 on epoch=249
05/16/2022 16:49:25 - INFO - __main__ - Global step 1000 Train loss 1.43 Classification-F1 0.1115492957746479 on epoch=249
05/16/2022 16:49:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.54 on epoch=252
05/16/2022 16:49:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.50 on epoch=254
05/16/2022 16:49:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.42 on epoch=257
05/16/2022 16:49:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.58 on epoch=259
05/16/2022 16:49:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.40 on epoch=262
05/16/2022 16:49:32 - INFO - __main__ - Global step 1050 Train loss 1.49 Classification-F1 0.16059379217273953 on epoch=262
05/16/2022 16:49:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.37 on epoch=264
05/16/2022 16:49:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.40 on epoch=267
05/16/2022 16:49:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.31 on epoch=269
05/16/2022 16:49:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.38 on epoch=272
05/16/2022 16:49:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.36 on epoch=274
05/16/2022 16:49:39 - INFO - __main__ - Global step 1100 Train loss 1.36 Classification-F1 0.1 on epoch=274
05/16/2022 16:49:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.29 on epoch=277
05/16/2022 16:49:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.36 on epoch=279
05/16/2022 16:49:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.25 on epoch=282
05/16/2022 16:49:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.42 on epoch=284
05/16/2022 16:49:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.28 on epoch=287
05/16/2022 16:49:46 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.10389610389610389 on epoch=287
05/16/2022 16:49:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
05/16/2022 16:49:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.39 on epoch=292
05/16/2022 16:49:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.36 on epoch=294
05/16/2022 16:49:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.35 on epoch=297
05/16/2022 16:49:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.30 on epoch=299
05/16/2022 16:49:54 - INFO - __main__ - Global step 1200 Train loss 1.32 Classification-F1 0.1360774818401937 on epoch=299
05/16/2022 16:49:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.38 on epoch=302
05/16/2022 16:49:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.32 on epoch=304
05/16/2022 16:49:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.34 on epoch=307
05/16/2022 16:50:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.28 on epoch=309
05/16/2022 16:50:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.35 on epoch=312
05/16/2022 16:50:02 - INFO - __main__ - Global step 1250 Train loss 1.33 Classification-F1 0.13514173998044965 on epoch=312
05/16/2022 16:50:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.15 on epoch=314
05/16/2022 16:50:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.25 on epoch=317
05/16/2022 16:50:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.36 on epoch=319
05/16/2022 16:50:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.25 on epoch=322
05/16/2022 16:50:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.25 on epoch=324
05/16/2022 16:50:10 - INFO - __main__ - Global step 1300 Train loss 1.25 Classification-F1 0.1 on epoch=324
05/16/2022 16:50:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.28 on epoch=327
05/16/2022 16:50:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.15 on epoch=329
05/16/2022 16:50:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=332
05/16/2022 16:50:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.24 on epoch=334
05/16/2022 16:50:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.22 on epoch=337
05/16/2022 16:50:17 - INFO - __main__ - Global step 1350 Train loss 1.22 Classification-F1 0.10126582278481013 on epoch=337
05/16/2022 16:50:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.34 on epoch=339
05/16/2022 16:50:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.35 on epoch=342
05/16/2022 16:50:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.18 on epoch=344
05/16/2022 16:50:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.29 on epoch=347
05/16/2022 16:50:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
05/16/2022 16:50:25 - INFO - __main__ - Global step 1400 Train loss 1.25 Classification-F1 0.14004914004914004 on epoch=349
05/16/2022 16:50:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.33 on epoch=352
05/16/2022 16:50:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.08 on epoch=354
05/16/2022 16:50:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.26 on epoch=357
05/16/2022 16:50:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.29 on epoch=359
05/16/2022 16:50:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.28 on epoch=362
05/16/2022 16:50:32 - INFO - __main__ - Global step 1450 Train loss 1.25 Classification-F1 0.12393162393162392 on epoch=362
05/16/2022 16:50:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/16/2022 16:50:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.29 on epoch=367
05/16/2022 16:50:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.30 on epoch=369
05/16/2022 16:50:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/16/2022 16:50:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.26 on epoch=374
05/16/2022 16:50:39 - INFO - __main__ - Global step 1500 Train loss 1.25 Classification-F1 0.09868421052631579 on epoch=374
05/16/2022 16:50:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.05 on epoch=377
05/16/2022 16:50:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.39 on epoch=379
05/16/2022 16:50:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/16/2022 16:50:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.12 on epoch=384
05/16/2022 16:50:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.19 on epoch=387
05/16/2022 16:50:46 - INFO - __main__ - Global step 1550 Train loss 1.17 Classification-F1 0.14248366013071895 on epoch=387
05/16/2022 16:50:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.16 on epoch=389
05/16/2022 16:50:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.18 on epoch=392
05/16/2022 16:50:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.16 on epoch=394
05/16/2022 16:50:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.09 on epoch=397
05/16/2022 16:50:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.07 on epoch=399
05/16/2022 16:50:54 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.11657231085949563 on epoch=399
05/16/2022 16:50:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.03 on epoch=402
05/16/2022 16:50:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.17 on epoch=404
05/16/2022 16:50:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.16 on epoch=407
05/16/2022 16:50:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/16/2022 16:51:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/16/2022 16:51:01 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.09708159618820728 on epoch=412
05/16/2022 16:51:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.20 on epoch=414
05/16/2022 16:51:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.12 on epoch=417
05/16/2022 16:51:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=419
05/16/2022 16:51:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=422
05/16/2022 16:51:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.01 on epoch=424
05/16/2022 16:51:08 - INFO - __main__ - Global step 1700 Train loss 1.10 Classification-F1 0.0880952380952381 on epoch=424
05/16/2022 16:51:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.12 on epoch=427
05/16/2022 16:51:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.04 on epoch=429
05/16/2022 16:51:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.01 on epoch=432
05/16/2022 16:51:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=434
05/16/2022 16:51:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.07 on epoch=437
05/16/2022 16:51:15 - INFO - __main__ - Global step 1750 Train loss 1.08 Classification-F1 0.1237183868762816 on epoch=437
05/16/2022 16:51:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
05/16/2022 16:51:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
05/16/2022 16:51:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/16/2022 16:51:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.08 on epoch=447
05/16/2022 16:51:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
05/16/2022 16:51:22 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.13067758749069247 on epoch=449
05/16/2022 16:51:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.10 on epoch=452
05/16/2022 16:51:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.21 on epoch=454
05/16/2022 16:51:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.18 on epoch=457
05/16/2022 16:51:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.11 on epoch=459
05/16/2022 16:51:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.13 on epoch=462
05/16/2022 16:51:30 - INFO - __main__ - Global step 1850 Train loss 1.15 Classification-F1 0.1796875 on epoch=462
05/16/2022 16:51:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.04 on epoch=464
05/16/2022 16:51:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.04 on epoch=467
05/16/2022 16:51:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.06 on epoch=469
05/16/2022 16:51:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.97 on epoch=472
05/16/2022 16:51:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.98 on epoch=474
05/16/2022 16:51:37 - INFO - __main__ - Global step 1900 Train loss 1.02 Classification-F1 0.17569930069930068 on epoch=474
05/16/2022 16:51:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.97 on epoch=477
05/16/2022 16:51:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=479
05/16/2022 16:51:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.11 on epoch=482
05/16/2022 16:51:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.24 on epoch=484
05/16/2022 16:51:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.15 on epoch=487
05/16/2022 16:51:45 - INFO - __main__ - Global step 1950 Train loss 1.10 Classification-F1 0.14814814814814814 on epoch=487
05/16/2022 16:51:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.09 on epoch=489
05/16/2022 16:51:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.00 on epoch=492
05/16/2022 16:51:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.00 on epoch=494
05/16/2022 16:51:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.14 on epoch=497
05/16/2022 16:51:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/16/2022 16:51:52 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.1145104895104895 on epoch=499
05/16/2022 16:51:53 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/16/2022 16:51:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.13 on epoch=504
05/16/2022 16:51:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.03 on epoch=507
05/16/2022 16:51:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/16/2022 16:51:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.26 on epoch=512
05/16/2022 16:51:59 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.09493670886075949 on epoch=512
05/16/2022 16:52:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/16/2022 16:52:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.93 on epoch=517
05/16/2022 16:52:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.88 on epoch=519
05/16/2022 16:52:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
05/16/2022 16:52:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
05/16/2022 16:52:07 - INFO - __main__ - Global step 2100 Train loss 0.99 Classification-F1 0.1451990632318501 on epoch=524
05/16/2022 16:52:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/16/2022 16:52:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.12 on epoch=529
05/16/2022 16:52:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.06 on epoch=532
05/16/2022 16:52:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/16/2022 16:52:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
05/16/2022 16:52:14 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.09868421052631579 on epoch=537
05/16/2022 16:52:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
05/16/2022 16:52:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
05/16/2022 16:52:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/16/2022 16:52:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.07 on epoch=547
05/16/2022 16:52:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.11 on epoch=549
05/16/2022 16:52:21 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.13149768399382397 on epoch=549
05/16/2022 16:52:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.11 on epoch=552
05/16/2022 16:52:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.03 on epoch=554
05/16/2022 16:52:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.03 on epoch=557
05/16/2022 16:52:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/16/2022 16:52:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/16/2022 16:52:28 - INFO - __main__ - Global step 2250 Train loss 1.05 Classification-F1 0.16261904761904764 on epoch=562
05/16/2022 16:52:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.97 on epoch=564
05/16/2022 16:52:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.94 on epoch=567
05/16/2022 16:52:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/16/2022 16:52:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
05/16/2022 16:52:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.92 on epoch=574
05/16/2022 16:52:36 - INFO - __main__ - Global step 2300 Train loss 0.96 Classification-F1 0.18356374807987713 on epoch=574
05/16/2022 16:52:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/16/2022 16:52:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.01 on epoch=579
05/16/2022 16:52:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
05/16/2022 16:52:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.97 on epoch=584
05/16/2022 16:52:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/16/2022 16:52:44 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.140625 on epoch=587
05/16/2022 16:52:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/16/2022 16:52:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
05/16/2022 16:52:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.06 on epoch=594
05/16/2022 16:52:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.95 on epoch=597
05/16/2022 16:52:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/16/2022 16:52:51 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.17712418300653593 on epoch=599
05/16/2022 16:52:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.92 on epoch=602
05/16/2022 16:52:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
05/16/2022 16:52:55 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.96 on epoch=607
05/16/2022 16:52:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.90 on epoch=609
05/16/2022 16:52:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.94 on epoch=612
05/16/2022 16:52:59 - INFO - __main__ - Global step 2450 Train loss 0.95 Classification-F1 0.19408369408369408 on epoch=612
05/16/2022 16:53:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.02 on epoch=614
05/16/2022 16:53:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=617
05/16/2022 16:53:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/16/2022 16:53:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/16/2022 16:53:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
05/16/2022 16:53:06 - INFO - __main__ - Global step 2500 Train loss 0.97 Classification-F1 0.1 on epoch=624
05/16/2022 16:53:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.98 on epoch=627
05/16/2022 16:53:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.88 on epoch=629
05/16/2022 16:53:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.06 on epoch=632
05/16/2022 16:53:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.05 on epoch=634
05/16/2022 16:53:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
05/16/2022 16:53:14 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.1408918406072106 on epoch=637
05/16/2022 16:53:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.08 on epoch=639
05/16/2022 16:53:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.00 on epoch=642
05/16/2022 16:53:18 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.99 on epoch=644
05/16/2022 16:53:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.96 on epoch=647
05/16/2022 16:53:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/16/2022 16:53:21 - INFO - __main__ - Global step 2600 Train loss 1.01 Classification-F1 0.0998185117967332 on epoch=649
05/16/2022 16:53:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
05/16/2022 16:53:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/16/2022 16:53:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.03 on epoch=657
05/16/2022 16:53:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.00 on epoch=659
05/16/2022 16:53:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
05/16/2022 16:53:28 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.1115492957746479 on epoch=662
05/16/2022 16:53:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.93 on epoch=664
05/16/2022 16:53:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.90 on epoch=667
05/16/2022 16:53:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/16/2022 16:53:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.91 on epoch=672
05/16/2022 16:53:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.98 on epoch=674
05/16/2022 16:53:36 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.18782608695652175 on epoch=674
05/16/2022 16:53:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/16/2022 16:53:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.11 on epoch=679
05/16/2022 16:53:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/16/2022 16:53:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.93 on epoch=684
05/16/2022 16:53:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.03 on epoch=687
05/16/2022 16:53:43 - INFO - __main__ - Global step 2750 Train loss 1.04 Classification-F1 0.15285714285714286 on epoch=687
05/16/2022 16:53:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=689
05/16/2022 16:53:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.06 on epoch=692
05/16/2022 16:53:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.02 on epoch=694
05/16/2022 16:53:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.89 on epoch=697
05/16/2022 16:53:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
05/16/2022 16:53:50 - INFO - __main__ - Global step 2800 Train loss 0.97 Classification-F1 0.17798594847775173 on epoch=699
05/16/2022 16:53:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.92 on epoch=702
05/16/2022 16:53:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.93 on epoch=704
05/16/2022 16:53:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
05/16/2022 16:53:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.90 on epoch=709
05/16/2022 16:53:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.98 on epoch=712
05/16/2022 16:53:57 - INFO - __main__ - Global step 2850 Train loss 0.94 Classification-F1 0.10256410256410256 on epoch=712
05/16/2022 16:53:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.83 on epoch=714
05/16/2022 16:54:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.92 on epoch=717
05/16/2022 16:54:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.97 on epoch=719
05/16/2022 16:54:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/16/2022 16:54:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.92 on epoch=724
05/16/2022 16:54:05 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.08552631578947369 on epoch=724
05/16/2022 16:54:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.03 on epoch=727
05/16/2022 16:54:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/16/2022 16:54:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.01 on epoch=732
05/16/2022 16:54:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/16/2022 16:54:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.01 on epoch=737
05/16/2022 16:54:13 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.1 on epoch=737
05/16/2022 16:54:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.91 on epoch=739
05/16/2022 16:54:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/16/2022 16:54:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.91 on epoch=744
05/16/2022 16:54:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.03 on epoch=747
05/16/2022 16:54:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.96 on epoch=749
05/16/2022 16:54:20 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.1697802197802198 on epoch=749
05/16/2022 16:54:20 - INFO - __main__ - save last model!
05/16/2022 16:54:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 16:54:20 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 16:54:20 - INFO - __main__ - Printing 3 examples
05/16/2022 16:54:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 16:54:20 - INFO - __main__ - ['others']
05/16/2022 16:54:20 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 16:54:20 - INFO - __main__ - ['others']
05/16/2022 16:54:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 16:54:20 - INFO - __main__ - ['others']
05/16/2022 16:54:20 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:54:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:54:22 - INFO - __main__ - Printing 3 examples
05/16/2022 16:54:22 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:54:22 - INFO - __main__ - ['others']
05/16/2022 16:54:22 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:54:22 - INFO - __main__ - ['others']
05/16/2022 16:54:22 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:54:22 - INFO - __main__ - ['others']
05/16/2022 16:54:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:54:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:54:22 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:54:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:54:22 - INFO - __main__ - Printing 3 examples
05/16/2022 16:54:22 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:54:22 - INFO - __main__ - ['others']
05/16/2022 16:54:22 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:54:22 - INFO - __main__ - ['others']
05/16/2022 16:54:22 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:54:22 - INFO - __main__ - ['others']
05/16/2022 16:54:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:54:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:54:22 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:54:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:54:27 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:54:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:54:27 - INFO - __main__ - Starting training!
05/16/2022 16:54:29 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 16:55:15 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.3_8_predictions.txt
05/16/2022 16:55:15 - INFO - __main__ - Classification-F1 on test data: 0.0553
05/16/2022 16:55:16 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.19865392965696915, test_performance=0.05534399999455197
05/16/2022 16:55:16 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
05/16/2022 16:55:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:55:17 - INFO - __main__ - Printing 3 examples
05/16/2022 16:55:17 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/16/2022 16:55:17 - INFO - __main__ - ['others']
05/16/2022 16:55:17 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/16/2022 16:55:17 - INFO - __main__ - ['others']
05/16/2022 16:55:17 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/16/2022 16:55:17 - INFO - __main__ - ['others']
05/16/2022 16:55:17 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:55:17 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:55:17 - INFO - __main__ - Loaded 64 examples from train data
05/16/2022 16:55:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/16/2022 16:55:17 - INFO - __main__ - Printing 3 examples
05/16/2022 16:55:17 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/16/2022 16:55:17 - INFO - __main__ - ['others']
05/16/2022 16:55:17 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/16/2022 16:55:17 - INFO - __main__ - ['others']
05/16/2022 16:55:17 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/16/2022 16:55:17 - INFO - __main__ - ['others']
05/16/2022 16:55:17 - INFO - __main__ - Tokenizing Input ...
05/16/2022 16:55:17 - INFO - __main__ - Tokenizing Output ...
05/16/2022 16:55:17 - INFO - __main__ - Loaded 64 examples from dev data
05/16/2022 16:55:23 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 16:55:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 16:55:23 - INFO - __main__ - Starting training!
05/16/2022 16:55:25 - INFO - __main__ - Step 10 Global step 10 Train loss 6.84 on epoch=2
05/16/2022 16:55:26 - INFO - __main__ - Step 20 Global step 20 Train loss 6.57 on epoch=4
05/16/2022 16:55:27 - INFO - __main__ - Step 30 Global step 30 Train loss 6.60 on epoch=7
05/16/2022 16:55:29 - INFO - __main__ - Step 40 Global step 40 Train loss 6.46 on epoch=9
05/16/2022 16:55:30 - INFO - __main__ - Step 50 Global step 50 Train loss 6.27 on epoch=12
05/16/2022 16:55:38 - INFO - __main__ - Global step 50 Train loss 6.55 Classification-F1 0.0 on epoch=12
05/16/2022 16:55:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/16/2022 16:55:40 - INFO - __main__ - Step 60 Global step 60 Train loss 6.06 on epoch=14
05/16/2022 16:55:41 - INFO - __main__ - Step 70 Global step 70 Train loss 5.98 on epoch=17
05/16/2022 16:55:42 - INFO - __main__ - Step 80 Global step 80 Train loss 5.76 on epoch=19
05/16/2022 16:55:43 - INFO - __main__ - Step 90 Global step 90 Train loss 5.75 on epoch=22
05/16/2022 16:55:45 - INFO - __main__ - Step 100 Global step 100 Train loss 5.76 on epoch=24
05/16/2022 16:55:47 - INFO - __main__ - Global step 100 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/16/2022 16:55:49 - INFO - __main__ - Step 110 Global step 110 Train loss 5.68 on epoch=27
05/16/2022 16:55:50 - INFO - __main__ - Step 120 Global step 120 Train loss 5.44 on epoch=29
05/16/2022 16:55:51 - INFO - __main__ - Step 130 Global step 130 Train loss 5.37 on epoch=32
05/16/2022 16:55:53 - INFO - __main__ - Step 140 Global step 140 Train loss 5.39 on epoch=34
05/16/2022 16:55:54 - INFO - __main__ - Step 150 Global step 150 Train loss 5.14 on epoch=37
05/16/2022 16:55:56 - INFO - __main__ - Global step 150 Train loss 5.41 Classification-F1 0.0 on epoch=37
05/16/2022 16:55:58 - INFO - __main__ - Step 160 Global step 160 Train loss 5.15 on epoch=39
05/16/2022 16:55:59 - INFO - __main__ - Step 170 Global step 170 Train loss 5.11 on epoch=42
05/16/2022 16:56:00 - INFO - __main__ - Step 180 Global step 180 Train loss 4.87 on epoch=44
05/16/2022 16:56:01 - INFO - __main__ - Step 190 Global step 190 Train loss 5.11 on epoch=47
05/16/2022 16:56:03 - INFO - __main__ - Step 200 Global step 200 Train loss 4.70 on epoch=49
05/16/2022 16:56:06 - INFO - __main__ - Global step 200 Train loss 4.99 Classification-F1 0.0 on epoch=49
05/16/2022 16:56:07 - INFO - __main__ - Step 210 Global step 210 Train loss 4.63 on epoch=52
05/16/2022 16:56:08 - INFO - __main__ - Step 220 Global step 220 Train loss 4.61 on epoch=54
05/16/2022 16:56:10 - INFO - __main__ - Step 230 Global step 230 Train loss 4.47 on epoch=57
05/16/2022 16:56:11 - INFO - __main__ - Step 240 Global step 240 Train loss 4.31 on epoch=59
05/16/2022 16:56:13 - INFO - __main__ - Step 250 Global step 250 Train loss 4.22 on epoch=62
05/16/2022 16:56:13 - INFO - __main__ - Global step 250 Train loss 4.45 Classification-F1 0.08235243017851714 on epoch=62
05/16/2022 16:56:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08235243017851714 on epoch=62, global_step=250
05/16/2022 16:56:15 - INFO - __main__ - Step 260 Global step 260 Train loss 4.14 on epoch=64
05/16/2022 16:56:16 - INFO - __main__ - Step 270 Global step 270 Train loss 4.15 on epoch=67
05/16/2022 16:56:17 - INFO - __main__ - Step 280 Global step 280 Train loss 3.95 on epoch=69
05/16/2022 16:56:19 - INFO - __main__ - Step 290 Global step 290 Train loss 3.97 on epoch=72
05/16/2022 16:56:20 - INFO - __main__ - Step 300 Global step 300 Train loss 3.84 on epoch=74
05/16/2022 16:56:21 - INFO - __main__ - Global step 300 Train loss 4.01 Classification-F1 0.15141579731743665 on epoch=74
05/16/2022 16:56:21 - INFO - __main__ - Saving model with best Classification-F1: 0.08235243017851714 -> 0.15141579731743665 on epoch=74, global_step=300
05/16/2022 16:56:22 - INFO - __main__ - Step 310 Global step 310 Train loss 3.83 on epoch=77
05/16/2022 16:56:23 - INFO - __main__ - Step 320 Global step 320 Train loss 3.72 on epoch=79
05/16/2022 16:56:25 - INFO - __main__ - Step 330 Global step 330 Train loss 3.68 on epoch=82
05/16/2022 16:56:26 - INFO - __main__ - Step 340 Global step 340 Train loss 3.43 on epoch=84
05/16/2022 16:56:27 - INFO - __main__ - Step 350 Global step 350 Train loss 3.41 on epoch=87
05/16/2022 16:56:28 - INFO - __main__ - Global step 350 Train loss 3.61 Classification-F1 0.13034188034188032 on epoch=87
05/16/2022 16:56:29 - INFO - __main__ - Step 360 Global step 360 Train loss 3.28 on epoch=89
05/16/2022 16:56:30 - INFO - __main__ - Step 370 Global step 370 Train loss 3.31 on epoch=92
05/16/2022 16:56:32 - INFO - __main__ - Step 380 Global step 380 Train loss 3.03 on epoch=94
05/16/2022 16:56:33 - INFO - __main__ - Step 390 Global step 390 Train loss 3.11 on epoch=97
05/16/2022 16:56:35 - INFO - __main__ - Step 400 Global step 400 Train loss 3.11 on epoch=99
05/16/2022 16:56:35 - INFO - __main__ - Global step 400 Train loss 3.17 Classification-F1 0.1237183868762816 on epoch=99
05/16/2022 16:56:36 - INFO - __main__ - Step 410 Global step 410 Train loss 2.95 on epoch=102
05/16/2022 16:56:38 - INFO - __main__ - Step 420 Global step 420 Train loss 2.92 on epoch=104
05/16/2022 16:56:39 - INFO - __main__ - Step 430 Global step 430 Train loss 2.99 on epoch=107
05/16/2022 16:56:40 - INFO - __main__ - Step 440 Global step 440 Train loss 2.80 on epoch=109
05/16/2022 16:56:42 - INFO - __main__ - Step 450 Global step 450 Train loss 2.90 on epoch=112
05/16/2022 16:56:42 - INFO - __main__ - Global step 450 Train loss 2.91 Classification-F1 0.1 on epoch=112
05/16/2022 16:56:44 - INFO - __main__ - Step 460 Global step 460 Train loss 2.68 on epoch=114
05/16/2022 16:56:45 - INFO - __main__ - Step 470 Global step 470 Train loss 2.78 on epoch=117
05/16/2022 16:56:46 - INFO - __main__ - Step 480 Global step 480 Train loss 2.56 on epoch=119
05/16/2022 16:56:48 - INFO - __main__ - Step 490 Global step 490 Train loss 2.56 on epoch=122
05/16/2022 16:56:49 - INFO - __main__ - Step 500 Global step 500 Train loss 2.47 on epoch=124
05/16/2022 16:56:50 - INFO - __main__ - Global step 500 Train loss 2.61 Classification-F1 0.10256410256410256 on epoch=124
05/16/2022 16:56:51 - INFO - __main__ - Step 510 Global step 510 Train loss 2.58 on epoch=127
05/16/2022 16:56:52 - INFO - __main__ - Step 520 Global step 520 Train loss 2.46 on epoch=129
05/16/2022 16:56:54 - INFO - __main__ - Step 530 Global step 530 Train loss 2.52 on epoch=132
05/16/2022 16:56:55 - INFO - __main__ - Step 540 Global step 540 Train loss 2.34 on epoch=134
05/16/2022 16:56:56 - INFO - __main__ - Step 550 Global step 550 Train loss 2.48 on epoch=137
05/16/2022 16:56:57 - INFO - __main__ - Global step 550 Train loss 2.48 Classification-F1 0.19673202614379087 on epoch=137
05/16/2022 16:56:57 - INFO - __main__ - Saving model with best Classification-F1: 0.15141579731743665 -> 0.19673202614379087 on epoch=137, global_step=550
05/16/2022 16:56:58 - INFO - __main__ - Step 560 Global step 560 Train loss 2.28 on epoch=139
05/16/2022 16:57:00 - INFO - __main__ - Step 570 Global step 570 Train loss 2.36 on epoch=142
05/16/2022 16:57:01 - INFO - __main__ - Step 580 Global step 580 Train loss 2.21 on epoch=144
05/16/2022 16:57:02 - INFO - __main__ - Step 590 Global step 590 Train loss 2.26 on epoch=147
05/16/2022 16:57:04 - INFO - __main__ - Step 600 Global step 600 Train loss 2.08 on epoch=149
05/16/2022 16:57:04 - INFO - __main__ - Global step 600 Train loss 2.24 Classification-F1 0.10135135135135136 on epoch=149
05/16/2022 16:57:05 - INFO - __main__ - Step 610 Global step 610 Train loss 2.13 on epoch=152
05/16/2022 16:57:07 - INFO - __main__ - Step 620 Global step 620 Train loss 2.06 on epoch=154
05/16/2022 16:57:08 - INFO - __main__ - Step 630 Global step 630 Train loss 2.26 on epoch=157
05/16/2022 16:57:10 - INFO - __main__ - Step 640 Global step 640 Train loss 2.17 on epoch=159
05/16/2022 16:57:11 - INFO - __main__ - Step 650 Global step 650 Train loss 2.27 on epoch=162
05/16/2022 16:57:12 - INFO - __main__ - Global step 650 Train loss 2.18 Classification-F1 0.11714285714285715 on epoch=162
05/16/2022 16:57:13 - INFO - __main__ - Step 660 Global step 660 Train loss 1.90 on epoch=164
05/16/2022 16:57:14 - INFO - __main__ - Step 670 Global step 670 Train loss 1.97 on epoch=167
05/16/2022 16:57:16 - INFO - __main__ - Step 680 Global step 680 Train loss 2.01 on epoch=169
05/16/2022 16:57:17 - INFO - __main__ - Step 690 Global step 690 Train loss 2.02 on epoch=172
05/16/2022 16:57:18 - INFO - __main__ - Step 700 Global step 700 Train loss 1.98 on epoch=174
05/16/2022 16:57:19 - INFO - __main__ - Global step 700 Train loss 1.98 Classification-F1 0.10256410256410256 on epoch=174
05/16/2022 16:57:20 - INFO - __main__ - Step 710 Global step 710 Train loss 2.02 on epoch=177
05/16/2022 16:57:21 - INFO - __main__ - Step 720 Global step 720 Train loss 1.80 on epoch=179
05/16/2022 16:57:23 - INFO - __main__ - Step 730 Global step 730 Train loss 1.77 on epoch=182
05/16/2022 16:57:24 - INFO - __main__ - Step 740 Global step 740 Train loss 1.77 on epoch=184
05/16/2022 16:57:25 - INFO - __main__ - Step 750 Global step 750 Train loss 1.87 on epoch=187
05/16/2022 16:57:26 - INFO - __main__ - Global step 750 Train loss 1.85 Classification-F1 0.1 on epoch=187
05/16/2022 16:57:27 - INFO - __main__ - Step 760 Global step 760 Train loss 1.78 on epoch=189
05/16/2022 16:57:29 - INFO - __main__ - Step 770 Global step 770 Train loss 2.00 on epoch=192
05/16/2022 16:57:30 - INFO - __main__ - Step 780 Global step 780 Train loss 1.69 on epoch=194
05/16/2022 16:57:31 - INFO - __main__ - Step 790 Global step 790 Train loss 1.87 on epoch=197
05/16/2022 16:57:33 - INFO - __main__ - Step 800 Global step 800 Train loss 1.62 on epoch=199
05/16/2022 16:57:33 - INFO - __main__ - Global step 800 Train loss 1.79 Classification-F1 0.10126582278481013 on epoch=199
05/16/2022 16:57:35 - INFO - __main__ - Step 810 Global step 810 Train loss 1.84 on epoch=202
05/16/2022 16:57:36 - INFO - __main__ - Step 820 Global step 820 Train loss 1.69 on epoch=204
05/16/2022 16:57:37 - INFO - __main__ - Step 830 Global step 830 Train loss 1.85 on epoch=207
05/16/2022 16:57:39 - INFO - __main__ - Step 840 Global step 840 Train loss 1.71 on epoch=209
05/16/2022 16:57:40 - INFO - __main__ - Step 850 Global step 850 Train loss 1.52 on epoch=212
05/16/2022 16:57:41 - INFO - __main__ - Global step 850 Train loss 1.72 Classification-F1 0.1 on epoch=212
05/16/2022 16:57:42 - INFO - __main__ - Step 860 Global step 860 Train loss 1.62 on epoch=214
05/16/2022 16:57:44 - INFO - __main__ - Step 870 Global step 870 Train loss 1.58 on epoch=217
05/16/2022 16:57:45 - INFO - __main__ - Step 880 Global step 880 Train loss 1.72 on epoch=219
05/16/2022 16:57:46 - INFO - __main__ - Step 890 Global step 890 Train loss 1.67 on epoch=222
05/16/2022 16:57:48 - INFO - __main__ - Step 900 Global step 900 Train loss 1.68 on epoch=224
05/16/2022 16:57:48 - INFO - __main__ - Global step 900 Train loss 1.66 Classification-F1 0.1 on epoch=224
05/16/2022 16:57:50 - INFO - __main__ - Step 910 Global step 910 Train loss 1.67 on epoch=227
05/16/2022 16:57:51 - INFO - __main__ - Step 920 Global step 920 Train loss 1.61 on epoch=229
05/16/2022 16:57:52 - INFO - __main__ - Step 930 Global step 930 Train loss 1.49 on epoch=232
05/16/2022 16:57:54 - INFO - __main__ - Step 940 Global step 940 Train loss 1.66 on epoch=234
05/16/2022 16:57:55 - INFO - __main__ - Step 950 Global step 950 Train loss 1.63 on epoch=237
05/16/2022 16:57:56 - INFO - __main__ - Global step 950 Train loss 1.61 Classification-F1 0.1 on epoch=237
05/16/2022 16:57:57 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/16/2022 16:57:58 - INFO - __main__ - Step 970 Global step 970 Train loss 1.39 on epoch=242
05/16/2022 16:58:00 - INFO - __main__ - Step 980 Global step 980 Train loss 1.45 on epoch=244
05/16/2022 16:58:01 - INFO - __main__ - Step 990 Global step 990 Train loss 1.55 on epoch=247
05/16/2022 16:58:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.64 on epoch=249
05/16/2022 16:58:03 - INFO - __main__ - Global step 1000 Train loss 1.47 Classification-F1 0.1 on epoch=249
05/16/2022 16:58:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/16/2022 16:58:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.48 on epoch=254
05/16/2022 16:58:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.56 on epoch=257
05/16/2022 16:58:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.47 on epoch=259
05/16/2022 16:58:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.38 on epoch=262
05/16/2022 16:58:10 - INFO - __main__ - Global step 1050 Train loss 1.45 Classification-F1 0.1 on epoch=262
05/16/2022 16:58:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.39 on epoch=264
05/16/2022 16:58:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.47 on epoch=267
05/16/2022 16:58:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.50 on epoch=269
05/16/2022 16:58:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.53 on epoch=272
05/16/2022 16:58:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.47 on epoch=274
05/16/2022 16:58:17 - INFO - __main__ - Global step 1100 Train loss 1.47 Classification-F1 0.18907563025210083 on epoch=274
05/16/2022 16:58:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.53 on epoch=277
05/16/2022 16:58:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.43 on epoch=279
05/16/2022 16:58:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.37 on epoch=282
05/16/2022 16:58:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.43 on epoch=284
05/16/2022 16:58:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.42 on epoch=287
05/16/2022 16:58:24 - INFO - __main__ - Global step 1150 Train loss 1.44 Classification-F1 0.18928571428571428 on epoch=287
05/16/2022 16:58:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.42 on epoch=289
05/16/2022 16:58:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.31 on epoch=292
05/16/2022 16:58:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.32 on epoch=294
05/16/2022 16:58:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.34 on epoch=297
05/16/2022 16:58:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.32 on epoch=299
05/16/2022 16:58:32 - INFO - __main__ - Global step 1200 Train loss 1.34 Classification-F1 0.13034188034188032 on epoch=299
05/16/2022 16:58:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.39 on epoch=302
05/16/2022 16:58:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.24 on epoch=304
05/16/2022 16:58:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.39 on epoch=307
05/16/2022 16:58:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.19 on epoch=309
05/16/2022 16:58:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.25 on epoch=312
05/16/2022 16:58:39 - INFO - __main__ - Global step 1250 Train loss 1.29 Classification-F1 0.1581196581196581 on epoch=312
05/16/2022 16:58:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=314
05/16/2022 16:58:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.51 on epoch=317
05/16/2022 16:58:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.37 on epoch=319
05/16/2022 16:58:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.34 on epoch=322
05/16/2022 16:58:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.32 on epoch=324
05/16/2022 16:58:47 - INFO - __main__ - Global step 1300 Train loss 1.38 Classification-F1 0.1 on epoch=324
05/16/2022 16:58:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.40 on epoch=327
05/16/2022 16:58:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.28 on epoch=329
05/16/2022 16:58:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.32 on epoch=332
05/16/2022 16:58:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.17 on epoch=334
05/16/2022 16:58:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.28 on epoch=337
05/16/2022 16:58:54 - INFO - __main__ - Global step 1350 Train loss 1.29 Classification-F1 0.17552334943639292 on epoch=337
05/16/2022 16:58:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.25 on epoch=339
05/16/2022 16:58:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.21 on epoch=342
05/16/2022 16:58:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.23 on epoch=344
05/16/2022 16:59:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.31 on epoch=347
05/16/2022 16:59:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.16 on epoch=349
05/16/2022 16:59:02 - INFO - __main__ - Global step 1400 Train loss 1.23 Classification-F1 0.16526054590570718 on epoch=349
05/16/2022 16:59:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/16/2022 16:59:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=354
05/16/2022 16:59:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.27 on epoch=357
05/16/2022 16:59:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.13 on epoch=359
05/16/2022 16:59:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.31 on epoch=362
05/16/2022 16:59:09 - INFO - __main__ - Global step 1450 Train loss 1.24 Classification-F1 0.1238095238095238 on epoch=362
05/16/2022 16:59:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.30 on epoch=364
05/16/2022 16:59:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.27 on epoch=367
05/16/2022 16:59:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.27 on epoch=369
05/16/2022 16:59:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.12 on epoch=372
05/16/2022 16:59:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.17 on epoch=374
05/16/2022 16:59:16 - INFO - __main__ - Global step 1500 Train loss 1.22 Classification-F1 0.17809523809523808 on epoch=374
05/16/2022 16:59:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.18 on epoch=377
05/16/2022 16:59:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.31 on epoch=379
05/16/2022 16:59:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.23 on epoch=382
05/16/2022 16:59:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.23 on epoch=384
05/16/2022 16:59:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.21 on epoch=387
05/16/2022 16:59:23 - INFO - __main__ - Global step 1550 Train loss 1.23 Classification-F1 0.1 on epoch=387
05/16/2022 16:59:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=389
05/16/2022 16:59:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.21 on epoch=392
05/16/2022 16:59:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.21 on epoch=394
05/16/2022 16:59:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.10 on epoch=397
05/16/2022 16:59:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.27 on epoch=399
05/16/2022 16:59:31 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.18561872909698998 on epoch=399
05/16/2022 16:59:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
05/16/2022 16:59:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.25 on epoch=404
05/16/2022 16:59:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.17 on epoch=407
05/16/2022 16:59:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.33 on epoch=409
05/16/2022 16:59:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.26 on epoch=412
05/16/2022 16:59:38 - INFO - __main__ - Global step 1650 Train loss 1.23 Classification-F1 0.18406593406593408 on epoch=412
05/16/2022 16:59:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.25 on epoch=414
05/16/2022 16:59:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.25 on epoch=417
05/16/2022 16:59:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.08 on epoch=419
05/16/2022 16:59:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.16 on epoch=422
05/16/2022 16:59:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.30 on epoch=424
05/16/2022 16:59:45 - INFO - __main__ - Global step 1700 Train loss 1.21 Classification-F1 0.19267605633802815 on epoch=424
05/16/2022 16:59:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=427
05/16/2022 16:59:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
05/16/2022 16:59:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.15 on epoch=432
05/16/2022 16:59:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.25 on epoch=434
05/16/2022 16:59:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.29 on epoch=437
05/16/2022 16:59:52 - INFO - __main__ - Global step 1750 Train loss 1.21 Classification-F1 0.1313186813186813 on epoch=437
05/16/2022 16:59:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.11 on epoch=439
05/16/2022 16:59:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.21 on epoch=442
05/16/2022 16:59:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/16/2022 16:59:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.21 on epoch=447
05/16/2022 16:59:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/16/2022 17:00:00 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.17813765182186234 on epoch=449
05/16/2022 17:00:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.22 on epoch=452
05/16/2022 17:00:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/16/2022 17:00:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.20 on epoch=457
05/16/2022 17:00:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.13 on epoch=459
05/16/2022 17:00:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.20 on epoch=462
05/16/2022 17:00:07 - INFO - __main__ - Global step 1850 Train loss 1.18 Classification-F1 0.1565276828434723 on epoch=462
05/16/2022 17:00:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.18 on epoch=464
05/16/2022 17:00:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.14 on epoch=467
05/16/2022 17:00:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.16 on epoch=469
05/16/2022 17:00:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.25 on epoch=472
05/16/2022 17:00:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/16/2022 17:00:14 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.13333333333333333 on epoch=474
05/16/2022 17:00:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.11 on epoch=477
05/16/2022 17:00:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.08 on epoch=479
05/16/2022 17:00:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.18 on epoch=482
05/16/2022 17:00:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
05/16/2022 17:00:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.97 on epoch=487
05/16/2022 17:00:21 - INFO - __main__ - Global step 1950 Train loss 1.07 Classification-F1 0.1736111111111111 on epoch=487
05/16/2022 17:00:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.15 on epoch=489
05/16/2022 17:00:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.12 on epoch=492
05/16/2022 17:00:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.10 on epoch=494
05/16/2022 17:00:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=497
05/16/2022 17:00:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.10 on epoch=499
05/16/2022 17:00:28 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.15526315789473685 on epoch=499
05/16/2022 17:00:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.16 on epoch=502
05/16/2022 17:00:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
05/16/2022 17:00:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.17 on epoch=507
05/16/2022 17:00:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.09 on epoch=509
05/16/2022 17:00:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.04 on epoch=512
05/16/2022 17:00:36 - INFO - __main__ - Global step 2050 Train loss 1.09 Classification-F1 0.109375 on epoch=512
05/16/2022 17:00:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.96 on epoch=514
05/16/2022 17:00:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.17 on epoch=517
05/16/2022 17:00:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.13 on epoch=519
05/16/2022 17:00:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
05/16/2022 17:00:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
05/16/2022 17:00:43 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.2091503267973856 on epoch=524
05/16/2022 17:00:43 - INFO - __main__ - Saving model with best Classification-F1: 0.19673202614379087 -> 0.2091503267973856 on epoch=524, global_step=2100
05/16/2022 17:00:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.05 on epoch=527
05/16/2022 17:00:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.09 on epoch=529
05/16/2022 17:00:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.23 on epoch=532
05/16/2022 17:00:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.17 on epoch=534
05/16/2022 17:00:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.17 on epoch=537
05/16/2022 17:00:50 - INFO - __main__ - Global step 2150 Train loss 1.14 Classification-F1 0.18276972624798712 on epoch=537
05/16/2022 17:00:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.16 on epoch=539
05/16/2022 17:00:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.16 on epoch=542
05/16/2022 17:00:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.15 on epoch=544
05/16/2022 17:00:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.16 on epoch=547
05/16/2022 17:00:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.17 on epoch=549
05/16/2022 17:00:57 - INFO - __main__ - Global step 2200 Train loss 1.16 Classification-F1 0.1468058968058968 on epoch=549
05/16/2022 17:00:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.16 on epoch=552
05/16/2022 17:01:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=554
05/16/2022 17:01:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/16/2022 17:01:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
05/16/2022 17:01:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.07 on epoch=562
05/16/2022 17:01:05 - INFO - __main__ - Global step 2250 Train loss 1.08 Classification-F1 0.1581196581196581 on epoch=562
05/16/2022 17:01:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/16/2022 17:01:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.11 on epoch=567
05/16/2022 17:01:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.14 on epoch=569
05/16/2022 17:01:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.07 on epoch=572
05/16/2022 17:01:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.16 on epoch=574
05/16/2022 17:01:12 - INFO - __main__ - Global step 2300 Train loss 1.12 Classification-F1 0.171875 on epoch=574
05/16/2022 17:01:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/16/2022 17:01:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.18 on epoch=579
05/16/2022 17:01:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.06 on epoch=582
05/16/2022 17:01:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/16/2022 17:01:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.15 on epoch=587
05/16/2022 17:01:20 - INFO - __main__ - Global step 2350 Train loss 1.10 Classification-F1 0.180905815748842 on epoch=587
05/16/2022 17:01:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.20 on epoch=589
05/16/2022 17:01:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.04 on epoch=592
05/16/2022 17:01:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/16/2022 17:01:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=597
05/16/2022 17:01:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.16 on epoch=599
05/16/2022 17:01:27 - INFO - __main__ - Global step 2400 Train loss 1.09 Classification-F1 0.13430127041742287 on epoch=599
05/16/2022 17:01:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.08 on epoch=602
05/16/2022 17:01:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/16/2022 17:01:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/16/2022 17:01:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/16/2022 17:01:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.97 on epoch=612
05/16/2022 17:01:34 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.18881118881118883 on epoch=612
05/16/2022 17:01:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
05/16/2022 17:01:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/16/2022 17:01:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.96 on epoch=619
05/16/2022 17:01:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.00 on epoch=622
05/16/2022 17:01:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
05/16/2022 17:01:41 - INFO - __main__ - Global step 2500 Train loss 1.03 Classification-F1 0.16888045540796964 on epoch=624
05/16/2022 17:01:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.14 on epoch=627
05/16/2022 17:01:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.02 on epoch=629
05/16/2022 17:01:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.00 on epoch=632
05/16/2022 17:01:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.02 on epoch=634
05/16/2022 17:01:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.02 on epoch=637
05/16/2022 17:01:49 - INFO - __main__ - Global step 2550 Train loss 1.04 Classification-F1 0.1581196581196581 on epoch=637
05/16/2022 17:01:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.03 on epoch=639
05/16/2022 17:01:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
05/16/2022 17:01:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.06 on epoch=644
05/16/2022 17:01:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
05/16/2022 17:01:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.00 on epoch=649
05/16/2022 17:01:56 - INFO - __main__ - Global step 2600 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=649
05/16/2022 17:01:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.08 on epoch=652
05/16/2022 17:01:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.03 on epoch=654
05/16/2022 17:02:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.01 on epoch=657
05/16/2022 17:02:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.03 on epoch=659
05/16/2022 17:02:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/16/2022 17:02:03 - INFO - __main__ - Global step 2650 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=662
05/16/2022 17:02:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.09 on epoch=664
05/16/2022 17:02:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.10 on epoch=667
05/16/2022 17:02:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.05 on epoch=669
05/16/2022 17:02:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/16/2022 17:02:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.06 on epoch=674
05/16/2022 17:02:10 - INFO - __main__ - Global step 2700 Train loss 1.06 Classification-F1 0.13067758749069247 on epoch=674
05/16/2022 17:02:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/16/2022 17:02:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.03 on epoch=679
05/16/2022 17:02:14 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.16 on epoch=682
05/16/2022 17:02:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.03 on epoch=684
05/16/2022 17:02:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.02 on epoch=687
05/16/2022 17:02:18 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.1 on epoch=687
05/16/2022 17:02:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.05 on epoch=689
05/16/2022 17:02:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.08 on epoch=692
05/16/2022 17:02:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.06 on epoch=694
05/16/2022 17:02:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.03 on epoch=697
05/16/2022 17:02:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.04 on epoch=699
05/16/2022 17:02:25 - INFO - __main__ - Global step 2800 Train loss 1.05 Classification-F1 0.13067758749069247 on epoch=699
05/16/2022 17:02:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.09 on epoch=702
05/16/2022 17:02:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.96 on epoch=704
05/16/2022 17:02:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.07 on epoch=707
05/16/2022 17:02:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.15 on epoch=709
05/16/2022 17:02:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.02 on epoch=712
05/16/2022 17:02:32 - INFO - __main__ - Global step 2850 Train loss 1.06 Classification-F1 0.09493670886075949 on epoch=712
05/16/2022 17:02:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.11 on epoch=714
05/16/2022 17:02:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.12 on epoch=717
05/16/2022 17:02:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.96 on epoch=719
05/16/2022 17:02:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.15 on epoch=722
05/16/2022 17:02:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
05/16/2022 17:02:40 - INFO - __main__ - Global step 2900 Train loss 1.06 Classification-F1 0.13026315789473686 on epoch=724
05/16/2022 17:02:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.01 on epoch=727
05/16/2022 17:02:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
05/16/2022 17:02:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.06 on epoch=732
05/16/2022 17:02:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.02 on epoch=734
05/16/2022 17:02:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.07 on epoch=737
05/16/2022 17:02:47 - INFO - __main__ - Global step 2950 Train loss 1.03 Classification-F1 0.1 on epoch=737
05/16/2022 17:02:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.05 on epoch=739
05/16/2022 17:02:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.12 on epoch=742
05/16/2022 17:02:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.13 on epoch=744
05/16/2022 17:02:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.07 on epoch=747
05/16/2022 17:02:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.97 on epoch=749
05/16/2022 17:02:54 - INFO - __main__ - Global step 3000 Train loss 1.07 Classification-F1 0.18276972624798712 on epoch=749
05/16/2022 17:02:54 - INFO - __main__ - save last model!
05/16/2022 17:02:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 17:02:54 - INFO - __main__ - Start tokenizing ... 5509 instances
05/16/2022 17:02:54 - INFO - __main__ - Printing 3 examples
05/16/2022 17:02:54 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/16/2022 17:02:54 - INFO - __main__ - ['others']
05/16/2022 17:02:54 - INFO - __main__ -  [emo] what you like very little things ok
05/16/2022 17:02:54 - INFO - __main__ - ['others']
05/16/2022 17:02:54 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/16/2022 17:02:54 - INFO - __main__ - ['others']
05/16/2022 17:02:54 - INFO - __main__ - Tokenizing Input ...
05/16/2022 17:02:57 - INFO - __main__ - Tokenizing Output ...
05/16/2022 17:03:02 - INFO - __main__ - Loaded 5509 examples from test data
05/16/2022 17:03:46 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.2_8_predictions.txt
05/16/2022 17:03:46 - INFO - __main__ - Classification-F1 on test data: 0.0428
05/16/2022 17:03:46 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.2091503267973856, test_performance=0.04281145790239352
05/20/2022 16:44:09 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/20/2022 16:44:09 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo
05/20/2022 16:44:09 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/20/2022 16:44:09 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo
05/20/2022 16:44:11 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/20/2022 16:44:11 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/20/2022 16:44:11 - INFO - __main__ - args.device: cuda:0
05/20/2022 16:44:11 - INFO - __main__ - Using 2 gpus
05/20/2022 16:44:11 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/20/2022 16:44:11 - INFO - __main__ - args.device: cuda:1
05/20/2022 16:44:11 - INFO - __main__ - Using 2 gpus
05/20/2022 16:44:11 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/20/2022 16:44:17 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
05/20/2022 16:44:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:44:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:44:18 - INFO - __main__ - Printing 3 examples
05/20/2022 16:44:18 - INFO - __main__ - Printing 3 examples
05/20/2022 16:44:18 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 16:44:18 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 16:44:18 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 16:44:18 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:44:18 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 16:44:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:44:18 - INFO - __main__ - Printing 3 examples
05/20/2022 16:44:18 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:44:18 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 16:44:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:44:18 - INFO - __main__ - Printing 3 examples
05/20/2022 16:44:18 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 16:44:18 - INFO - __main__ - ['others']
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:44:18 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:44:18 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 16:44:18 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 16:44:24 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 16:44:24 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 16:44:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 16:44:25 - INFO - __main__ - Starting training!
05/20/2022 16:44:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 16:44:30 - INFO - __main__ - Starting training!
05/20/2022 16:44:31 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=2
05/20/2022 16:44:33 - INFO - __main__ - Step 20 Global step 20 Train loss 6.44 on epoch=4
05/20/2022 16:44:34 - INFO - __main__ - Step 30 Global step 30 Train loss 6.36 on epoch=7
05/20/2022 16:44:35 - INFO - __main__ - Step 40 Global step 40 Train loss 5.90 on epoch=9
05/20/2022 16:44:37 - INFO - __main__ - Step 50 Global step 50 Train loss 5.57 on epoch=12
05/20/2022 16:44:39 - INFO - __main__ - Global step 50 Train loss 6.19 Classification-F1 0.0 on epoch=12
05/20/2022 16:44:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 16:44:40 - INFO - __main__ - Step 60 Global step 60 Train loss 5.52 on epoch=14
05/20/2022 16:44:42 - INFO - __main__ - Step 70 Global step 70 Train loss 5.19 on epoch=17
05/20/2022 16:44:43 - INFO - __main__ - Step 80 Global step 80 Train loss 4.85 on epoch=19
05/20/2022 16:44:44 - INFO - __main__ - Step 90 Global step 90 Train loss 4.60 on epoch=22
05/20/2022 16:44:46 - INFO - __main__ - Step 100 Global step 100 Train loss 4.31 on epoch=24
05/20/2022 16:44:47 - INFO - __main__ - Global step 100 Train loss 4.90 Classification-F1 0.06015037593984963 on epoch=24
05/20/2022 16:44:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06015037593984963 on epoch=24, global_step=100
05/20/2022 16:44:48 - INFO - __main__ - Step 110 Global step 110 Train loss 4.12 on epoch=27
05/20/2022 16:44:49 - INFO - __main__ - Step 120 Global step 120 Train loss 3.90 on epoch=29
05/20/2022 16:44:51 - INFO - __main__ - Step 130 Global step 130 Train loss 3.71 on epoch=32
05/20/2022 16:44:52 - INFO - __main__ - Step 140 Global step 140 Train loss 3.49 on epoch=34
05/20/2022 16:44:53 - INFO - __main__ - Step 150 Global step 150 Train loss 3.28 on epoch=37
05/20/2022 16:44:56 - INFO - __main__ - Global step 150 Train loss 3.70 Classification-F1 0.13660130718954247 on epoch=37
05/20/2022 16:44:56 - INFO - __main__ - Saving model with best Classification-F1: 0.06015037593984963 -> 0.13660130718954247 on epoch=37, global_step=150
05/20/2022 16:44:57 - INFO - __main__ - Step 160 Global step 160 Train loss 3.03 on epoch=39
05/20/2022 16:44:58 - INFO - __main__ - Step 170 Global step 170 Train loss 3.15 on epoch=42
05/20/2022 16:45:00 - INFO - __main__ - Step 180 Global step 180 Train loss 2.93 on epoch=44
05/20/2022 16:45:01 - INFO - __main__ - Step 190 Global step 190 Train loss 3.09 on epoch=47
05/20/2022 16:45:03 - INFO - __main__ - Step 200 Global step 200 Train loss 2.84 on epoch=49
05/20/2022 16:45:03 - INFO - __main__ - Global step 200 Train loss 3.01 Classification-F1 0.1 on epoch=49
05/20/2022 16:45:04 - INFO - __main__ - Step 210 Global step 210 Train loss 2.91 on epoch=52
05/20/2022 16:45:06 - INFO - __main__ - Step 220 Global step 220 Train loss 2.73 on epoch=54
05/20/2022 16:45:07 - INFO - __main__ - Step 230 Global step 230 Train loss 2.77 on epoch=57
05/20/2022 16:45:09 - INFO - __main__ - Step 240 Global step 240 Train loss 2.52 on epoch=59
05/20/2022 16:45:10 - INFO - __main__ - Step 250 Global step 250 Train loss 2.65 on epoch=62
05/20/2022 16:45:11 - INFO - __main__ - Global step 250 Train loss 2.71 Classification-F1 0.12417582417582418 on epoch=62
05/20/2022 16:45:12 - INFO - __main__ - Step 260 Global step 260 Train loss 2.42 on epoch=64
05/20/2022 16:45:13 - INFO - __main__ - Step 270 Global step 270 Train loss 2.36 on epoch=67
05/20/2022 16:45:15 - INFO - __main__ - Step 280 Global step 280 Train loss 2.39 on epoch=69
05/20/2022 16:45:16 - INFO - __main__ - Step 290 Global step 290 Train loss 2.35 on epoch=72
05/20/2022 16:45:18 - INFO - __main__ - Step 300 Global step 300 Train loss 2.16 on epoch=74
05/20/2022 16:45:18 - INFO - __main__ - Global step 300 Train loss 2.34 Classification-F1 0.0974025974025974 on epoch=74
05/20/2022 16:45:19 - INFO - __main__ - Step 310 Global step 310 Train loss 2.39 on epoch=77
05/20/2022 16:45:21 - INFO - __main__ - Step 320 Global step 320 Train loss 2.10 on epoch=79
05/20/2022 16:45:22 - INFO - __main__ - Step 330 Global step 330 Train loss 2.25 on epoch=82
05/20/2022 16:45:24 - INFO - __main__ - Step 340 Global step 340 Train loss 2.02 on epoch=84
05/20/2022 16:45:25 - INFO - __main__ - Step 350 Global step 350 Train loss 2.20 on epoch=87
05/20/2022 16:45:26 - INFO - __main__ - Global step 350 Train loss 2.19 Classification-F1 0.1 on epoch=87
05/20/2022 16:45:27 - INFO - __main__ - Step 360 Global step 360 Train loss 2.10 on epoch=89
05/20/2022 16:45:28 - INFO - __main__ - Step 370 Global step 370 Train loss 2.05 on epoch=92
05/20/2022 16:45:30 - INFO - __main__ - Step 380 Global step 380 Train loss 1.96 on epoch=94
05/20/2022 16:45:31 - INFO - __main__ - Step 390 Global step 390 Train loss 2.09 on epoch=97
05/20/2022 16:45:32 - INFO - __main__ - Step 400 Global step 400 Train loss 1.87 on epoch=99
05/20/2022 16:45:33 - INFO - __main__ - Global step 400 Train loss 2.02 Classification-F1 0.10126582278481013 on epoch=99
05/20/2022 16:45:34 - INFO - __main__ - Step 410 Global step 410 Train loss 1.81 on epoch=102
05/20/2022 16:45:36 - INFO - __main__ - Step 420 Global step 420 Train loss 1.91 on epoch=104
05/20/2022 16:45:37 - INFO - __main__ - Step 430 Global step 430 Train loss 1.91 on epoch=107
05/20/2022 16:45:39 - INFO - __main__ - Step 440 Global step 440 Train loss 1.69 on epoch=109
05/20/2022 16:45:40 - INFO - __main__ - Step 450 Global step 450 Train loss 1.74 on epoch=112
05/20/2022 16:45:40 - INFO - __main__ - Global step 450 Train loss 1.81 Classification-F1 0.10126582278481013 on epoch=112
05/20/2022 16:45:42 - INFO - __main__ - Step 460 Global step 460 Train loss 1.59 on epoch=114
05/20/2022 16:45:43 - INFO - __main__ - Step 470 Global step 470 Train loss 1.95 on epoch=117
05/20/2022 16:45:45 - INFO - __main__ - Step 480 Global step 480 Train loss 1.76 on epoch=119
05/20/2022 16:45:46 - INFO - __main__ - Step 490 Global step 490 Train loss 1.80 on epoch=122
05/20/2022 16:45:47 - INFO - __main__ - Step 500 Global step 500 Train loss 1.84 on epoch=124
05/20/2022 16:45:48 - INFO - __main__ - Global step 500 Train loss 1.79 Classification-F1 0.1 on epoch=124
05/20/2022 16:45:49 - INFO - __main__ - Step 510 Global step 510 Train loss 1.64 on epoch=127
05/20/2022 16:45:51 - INFO - __main__ - Step 520 Global step 520 Train loss 1.49 on epoch=129
05/20/2022 16:45:52 - INFO - __main__ - Step 530 Global step 530 Train loss 1.70 on epoch=132
05/20/2022 16:45:53 - INFO - __main__ - Step 540 Global step 540 Train loss 1.49 on epoch=134
05/20/2022 16:45:55 - INFO - __main__ - Step 550 Global step 550 Train loss 1.51 on epoch=137
05/20/2022 16:45:55 - INFO - __main__ - Global step 550 Train loss 1.56 Classification-F1 0.10126582278481013 on epoch=137
05/20/2022 16:45:56 - INFO - __main__ - Step 560 Global step 560 Train loss 1.48 on epoch=139
05/20/2022 16:45:58 - INFO - __main__ - Step 570 Global step 570 Train loss 1.52 on epoch=142
05/20/2022 16:45:59 - INFO - __main__ - Step 580 Global step 580 Train loss 1.44 on epoch=144
05/20/2022 16:46:00 - INFO - __main__ - Step 590 Global step 590 Train loss 1.45 on epoch=147
05/20/2022 16:46:02 - INFO - __main__ - Step 600 Global step 600 Train loss 1.31 on epoch=149
05/20/2022 16:46:02 - INFO - __main__ - Global step 600 Train loss 1.44 Classification-F1 0.21944444444444447 on epoch=149
05/20/2022 16:46:02 - INFO - __main__ - Saving model with best Classification-F1: 0.13660130718954247 -> 0.21944444444444447 on epoch=149, global_step=600
05/20/2022 16:46:04 - INFO - __main__ - Step 610 Global step 610 Train loss 1.45 on epoch=152
05/20/2022 16:46:05 - INFO - __main__ - Step 620 Global step 620 Train loss 1.43 on epoch=154
05/20/2022 16:46:07 - INFO - __main__ - Step 630 Global step 630 Train loss 1.46 on epoch=157
05/20/2022 16:46:08 - INFO - __main__ - Step 640 Global step 640 Train loss 1.44 on epoch=159
05/20/2022 16:46:09 - INFO - __main__ - Step 650 Global step 650 Train loss 1.39 on epoch=162
05/20/2022 16:46:10 - INFO - __main__ - Global step 650 Train loss 1.43 Classification-F1 0.18284936479128855 on epoch=162
05/20/2022 16:46:11 - INFO - __main__ - Step 660 Global step 660 Train loss 1.50 on epoch=164
05/20/2022 16:46:13 - INFO - __main__ - Step 670 Global step 670 Train loss 1.31 on epoch=167
05/20/2022 16:46:14 - INFO - __main__ - Step 680 Global step 680 Train loss 1.28 on epoch=169
05/20/2022 16:46:16 - INFO - __main__ - Step 690 Global step 690 Train loss 1.42 on epoch=172
05/20/2022 16:46:17 - INFO - __main__ - Step 700 Global step 700 Train loss 1.35 on epoch=174
05/20/2022 16:46:17 - INFO - __main__ - Global step 700 Train loss 1.37 Classification-F1 0.1 on epoch=174
05/20/2022 16:46:19 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=177
05/20/2022 16:46:20 - INFO - __main__ - Step 720 Global step 720 Train loss 1.22 on epoch=179
05/20/2022 16:46:22 - INFO - __main__ - Step 730 Global step 730 Train loss 1.28 on epoch=182
05/20/2022 16:46:23 - INFO - __main__ - Step 740 Global step 740 Train loss 1.32 on epoch=184
05/20/2022 16:46:24 - INFO - __main__ - Step 750 Global step 750 Train loss 1.28 on epoch=187
05/20/2022 16:46:25 - INFO - __main__ - Global step 750 Train loss 1.28 Classification-F1 0.11996779388083736 on epoch=187
05/20/2022 16:46:26 - INFO - __main__ - Step 760 Global step 760 Train loss 1.25 on epoch=189
05/20/2022 16:46:28 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=192
05/20/2022 16:46:29 - INFO - __main__ - Step 780 Global step 780 Train loss 1.29 on epoch=194
05/20/2022 16:46:30 - INFO - __main__ - Step 790 Global step 790 Train loss 1.27 on epoch=197
05/20/2022 16:46:32 - INFO - __main__ - Step 800 Global step 800 Train loss 1.17 on epoch=199
05/20/2022 16:46:32 - INFO - __main__ - Global step 800 Train loss 1.24 Classification-F1 0.19157427937915744 on epoch=199
05/20/2022 16:46:34 - INFO - __main__ - Step 810 Global step 810 Train loss 1.25 on epoch=202
05/20/2022 16:46:35 - INFO - __main__ - Step 820 Global step 820 Train loss 1.12 on epoch=204
05/20/2022 16:46:37 - INFO - __main__ - Step 830 Global step 830 Train loss 1.38 on epoch=207
05/20/2022 16:46:38 - INFO - __main__ - Step 840 Global step 840 Train loss 1.22 on epoch=209
05/20/2022 16:46:39 - INFO - __main__ - Step 850 Global step 850 Train loss 1.18 on epoch=212
05/20/2022 16:46:40 - INFO - __main__ - Global step 850 Train loss 1.23 Classification-F1 0.19267605633802815 on epoch=212
05/20/2022 16:46:41 - INFO - __main__ - Step 860 Global step 860 Train loss 1.25 on epoch=214
05/20/2022 16:46:43 - INFO - __main__ - Step 870 Global step 870 Train loss 1.16 on epoch=217
05/20/2022 16:46:44 - INFO - __main__ - Step 880 Global step 880 Train loss 1.17 on epoch=219
05/20/2022 16:46:45 - INFO - __main__ - Step 890 Global step 890 Train loss 1.12 on epoch=222
05/20/2022 16:46:47 - INFO - __main__ - Step 900 Global step 900 Train loss 1.24 on epoch=224
05/20/2022 16:46:47 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.09090909090909091 on epoch=224
05/20/2022 16:46:49 - INFO - __main__ - Step 910 Global step 910 Train loss 1.11 on epoch=227
05/20/2022 16:46:50 - INFO - __main__ - Step 920 Global step 920 Train loss 1.13 on epoch=229
05/20/2022 16:46:51 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
05/20/2022 16:46:53 - INFO - __main__ - Step 940 Global step 940 Train loss 1.22 on epoch=234
05/20/2022 16:46:54 - INFO - __main__ - Step 950 Global step 950 Train loss 1.12 on epoch=237
05/20/2022 16:46:55 - INFO - __main__ - Global step 950 Train loss 1.20 Classification-F1 0.1 on epoch=237
05/20/2022 16:46:56 - INFO - __main__ - Step 960 Global step 960 Train loss 1.15 on epoch=239
05/20/2022 16:46:57 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=242
05/20/2022 16:46:59 - INFO - __main__ - Step 980 Global step 980 Train loss 1.22 on epoch=244
05/20/2022 16:47:00 - INFO - __main__ - Step 990 Global step 990 Train loss 1.10 on epoch=247
05/20/2022 16:47:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.07 on epoch=249
05/20/2022 16:47:02 - INFO - __main__ - Global step 1000 Train loss 1.13 Classification-F1 0.1 on epoch=249
05/20/2022 16:47:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
05/20/2022 16:47:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.04 on epoch=254
05/20/2022 16:47:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.09 on epoch=257
05/20/2022 16:47:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.09 on epoch=259
05/20/2022 16:47:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=262
05/20/2022 16:47:09 - INFO - __main__ - Global step 1050 Train loss 1.08 Classification-F1 0.1 on epoch=262
05/20/2022 16:47:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=264
05/20/2022 16:47:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.04 on epoch=267
05/20/2022 16:47:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.05 on epoch=269
05/20/2022 16:47:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.16 on epoch=272
05/20/2022 16:47:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.12 on epoch=274
05/20/2022 16:47:17 - INFO - __main__ - Global step 1100 Train loss 1.08 Classification-F1 0.1 on epoch=274
05/20/2022 16:47:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.02 on epoch=277
05/20/2022 16:47:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.10 on epoch=279
05/20/2022 16:47:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.06 on epoch=282
05/20/2022 16:47:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.09 on epoch=284
05/20/2022 16:47:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=287
05/20/2022 16:47:24 - INFO - __main__ - Global step 1150 Train loss 1.08 Classification-F1 0.1 on epoch=287
05/20/2022 16:47:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.05 on epoch=289
05/20/2022 16:47:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.00 on epoch=292
05/20/2022 16:47:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.01 on epoch=294
05/20/2022 16:47:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.93 on epoch=297
05/20/2022 16:47:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.09 on epoch=299
05/20/2022 16:47:32 - INFO - __main__ - Global step 1200 Train loss 1.02 Classification-F1 0.18026315789473685 on epoch=299
05/20/2022 16:47:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.11 on epoch=302
05/20/2022 16:47:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.07 on epoch=304
05/20/2022 16:47:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.97 on epoch=307
05/20/2022 16:47:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.90 on epoch=309
05/20/2022 16:47:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.01 on epoch=312
05/20/2022 16:47:39 - INFO - __main__ - Global step 1250 Train loss 1.01 Classification-F1 0.12407862407862408 on epoch=312
05/20/2022 16:47:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.05 on epoch=314
05/20/2022 16:47:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.10 on epoch=317
05/20/2022 16:47:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.13 on epoch=319
05/20/2022 16:47:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.00 on epoch=322
05/20/2022 16:47:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.00 on epoch=324
05/20/2022 16:47:47 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.12447885646217988 on epoch=324
05/20/2022 16:47:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.92 on epoch=327
05/20/2022 16:47:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.04 on epoch=329
05/20/2022 16:47:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.05 on epoch=332
05/20/2022 16:47:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.06 on epoch=334
05/20/2022 16:47:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.06 on epoch=337
05/20/2022 16:47:54 - INFO - __main__ - Global step 1350 Train loss 1.03 Classification-F1 0.13482414242292662 on epoch=337
05/20/2022 16:47:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/20/2022 16:47:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.00 on epoch=342
05/20/2022 16:47:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/20/2022 16:48:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.11 on epoch=347
05/20/2022 16:48:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.93 on epoch=349
05/20/2022 16:48:02 - INFO - __main__ - Global step 1400 Train loss 1.03 Classification-F1 0.10256410256410256 on epoch=349
05/20/2022 16:48:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.04 on epoch=352
05/20/2022 16:48:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.97 on epoch=354
05/20/2022 16:48:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=357
05/20/2022 16:48:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.95 on epoch=359
05/20/2022 16:48:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.06 on epoch=362
05/20/2022 16:48:09 - INFO - __main__ - Global step 1450 Train loss 1.04 Classification-F1 0.19307400379506642 on epoch=362
05/20/2022 16:48:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.04 on epoch=364
05/20/2022 16:48:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.04 on epoch=367
05/20/2022 16:48:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.08 on epoch=369
05/20/2022 16:48:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=372
05/20/2022 16:48:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.92 on epoch=374
05/20/2022 16:48:17 - INFO - __main__ - Global step 1500 Train loss 1.01 Classification-F1 0.1 on epoch=374
05/20/2022 16:48:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.02 on epoch=377
05/20/2022 16:48:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.01 on epoch=379
05/20/2022 16:48:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/20/2022 16:48:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.99 on epoch=384
05/20/2022 16:48:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.96 on epoch=387
05/20/2022 16:48:24 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.2505484861781483 on epoch=387
05/20/2022 16:48:24 - INFO - __main__ - Saving model with best Classification-F1: 0.21944444444444447 -> 0.2505484861781483 on epoch=387, global_step=1550
05/20/2022 16:48:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.00 on epoch=389
05/20/2022 16:48:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
05/20/2022 16:48:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.96 on epoch=394
05/20/2022 16:48:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=397
05/20/2022 16:48:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.98 on epoch=399
05/20/2022 16:48:32 - INFO - __main__ - Global step 1600 Train loss 0.98 Classification-F1 0.1497584541062802 on epoch=399
05/20/2022 16:48:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.00 on epoch=402
05/20/2022 16:48:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/20/2022 16:48:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.96 on epoch=407
05/20/2022 16:48:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.93 on epoch=409
05/20/2022 16:48:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.01 on epoch=412
05/20/2022 16:48:39 - INFO - __main__ - Global step 1650 Train loss 0.98 Classification-F1 0.13034188034188032 on epoch=412
05/20/2022 16:48:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.02 on epoch=414
05/20/2022 16:48:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/20/2022 16:48:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.95 on epoch=419
05/20/2022 16:48:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/20/2022 16:48:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.04 on epoch=424
05/20/2022 16:48:47 - INFO - __main__ - Global step 1700 Train loss 1.02 Classification-F1 0.17809523809523808 on epoch=424
05/20/2022 16:48:48 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.97 on epoch=427
05/20/2022 16:48:50 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.87 on epoch=429
05/20/2022 16:48:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.99 on epoch=432
05/20/2022 16:48:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.98 on epoch=434
05/20/2022 16:48:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.95 on epoch=437
05/20/2022 16:48:54 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.16407982261640797 on epoch=437
05/20/2022 16:48:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=439
05/20/2022 16:48:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.97 on epoch=442
05/20/2022 16:48:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.88 on epoch=444
05/20/2022 16:49:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.98 on epoch=447
05/20/2022 16:49:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.97 on epoch=449
05/20/2022 16:49:02 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.17124542124542122 on epoch=449
05/20/2022 16:49:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.87 on epoch=452
05/20/2022 16:49:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.90 on epoch=454
05/20/2022 16:49:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.00 on epoch=457
05/20/2022 16:49:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.04 on epoch=459
05/20/2022 16:49:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.96 on epoch=462
05/20/2022 16:49:10 - INFO - __main__ - Global step 1850 Train loss 0.95 Classification-F1 0.19165085388994307 on epoch=462
05/20/2022 16:49:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/20/2022 16:49:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=467
05/20/2022 16:49:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.94 on epoch=469
05/20/2022 16:49:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.01 on epoch=472
05/20/2022 16:49:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.83 on epoch=474
05/20/2022 16:49:17 - INFO - __main__ - Global step 1900 Train loss 0.93 Classification-F1 0.11612903225806451 on epoch=474
05/20/2022 16:49:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.92 on epoch=477
05/20/2022 16:49:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
05/20/2022 16:49:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
05/20/2022 16:49:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.96 on epoch=484
05/20/2022 16:49:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.83 on epoch=487
05/20/2022 16:49:25 - INFO - __main__ - Global step 1950 Train loss 0.93 Classification-F1 0.12819829424307036 on epoch=487
05/20/2022 16:49:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.94 on epoch=489
05/20/2022 16:49:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.04 on epoch=492
05/20/2022 16:49:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.94 on epoch=494
05/20/2022 16:49:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.90 on epoch=497
05/20/2022 16:49:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.03 on epoch=499
05/20/2022 16:49:32 - INFO - __main__ - Global step 2000 Train loss 0.97 Classification-F1 0.09999999999999999 on epoch=499
05/20/2022 16:49:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.00 on epoch=502
05/20/2022 16:49:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.88 on epoch=504
05/20/2022 16:49:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.94 on epoch=507
05/20/2022 16:49:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.94 on epoch=509
05/20/2022 16:49:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.92 on epoch=512
05/20/2022 16:49:40 - INFO - __main__ - Global step 2050 Train loss 0.94 Classification-F1 0.14642857142857144 on epoch=512
05/20/2022 16:49:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.05 on epoch=514
05/20/2022 16:49:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.97 on epoch=517
05/20/2022 16:49:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.02 on epoch=519
05/20/2022 16:49:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.87 on epoch=522
05/20/2022 16:49:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.92 on epoch=524
05/20/2022 16:49:49 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.15782608695652173 on epoch=524
05/20/2022 16:49:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
05/20/2022 16:49:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.89 on epoch=529
05/20/2022 16:49:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.94 on epoch=532
05/20/2022 16:49:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.03 on epoch=534
05/20/2022 16:49:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.93 on epoch=537
05/20/2022 16:49:56 - INFO - __main__ - Global step 2150 Train loss 0.94 Classification-F1 0.16795711733174506 on epoch=537
05/20/2022 16:49:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.92 on epoch=539
05/20/2022 16:49:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.94 on epoch=542
05/20/2022 16:50:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
05/20/2022 16:50:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.96 on epoch=547
05/20/2022 16:50:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.95 on epoch=549
05/20/2022 16:50:04 - INFO - __main__ - Global step 2200 Train loss 0.95 Classification-F1 0.15306730196545562 on epoch=549
05/20/2022 16:50:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.95 on epoch=552
05/20/2022 16:50:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.95 on epoch=554
05/20/2022 16:50:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.91 on epoch=557
05/20/2022 16:50:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.91 on epoch=559
05/20/2022 16:50:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.91 on epoch=562
05/20/2022 16:50:11 - INFO - __main__ - Global step 2250 Train loss 0.93 Classification-F1 0.1565452091767881 on epoch=562
05/20/2022 16:50:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.94 on epoch=564
05/20/2022 16:50:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
05/20/2022 16:50:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.92 on epoch=569
05/20/2022 16:50:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/20/2022 16:50:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.89 on epoch=574
05/20/2022 16:50:19 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.14304993252361672 on epoch=574
05/20/2022 16:50:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.99 on epoch=577
05/20/2022 16:50:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.87 on epoch=579
05/20/2022 16:50:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/20/2022 16:50:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/20/2022 16:50:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.96 on epoch=587
05/20/2022 16:50:26 - INFO - __main__ - Global step 2350 Train loss 0.95 Classification-F1 0.22751322751322753 on epoch=587
05/20/2022 16:50:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.85 on epoch=589
05/20/2022 16:50:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.87 on epoch=592
05/20/2022 16:50:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/20/2022 16:50:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
05/20/2022 16:50:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.97 on epoch=599
05/20/2022 16:50:34 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.17489919354838712 on epoch=599
05/20/2022 16:50:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/20/2022 16:50:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/20/2022 16:50:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.99 on epoch=607
05/20/2022 16:50:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/20/2022 16:50:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.90 on epoch=612
05/20/2022 16:50:41 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.13067758749069247 on epoch=612
05/20/2022 16:50:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.94 on epoch=614
05/20/2022 16:50:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.85 on epoch=617
05/20/2022 16:50:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/20/2022 16:50:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.92 on epoch=622
05/20/2022 16:50:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.88 on epoch=624
05/20/2022 16:50:48 - INFO - __main__ - Global step 2500 Train loss 0.92 Classification-F1 0.09615384615384615 on epoch=624
05/20/2022 16:50:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.94 on epoch=627
05/20/2022 16:50:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.87 on epoch=629
05/20/2022 16:50:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.87 on epoch=632
05/20/2022 16:50:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/20/2022 16:50:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/20/2022 16:50:56 - INFO - __main__ - Global step 2550 Train loss 0.90 Classification-F1 0.1640625 on epoch=637
05/20/2022 16:50:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.89 on epoch=639
05/20/2022 16:50:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.86 on epoch=642
05/20/2022 16:51:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/20/2022 16:51:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/20/2022 16:51:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/20/2022 16:51:03 - INFO - __main__ - Global step 2600 Train loss 0.91 Classification-F1 0.15833333333333333 on epoch=649
05/20/2022 16:51:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.95 on epoch=652
05/20/2022 16:51:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/20/2022 16:51:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/20/2022 16:51:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.88 on epoch=659
05/20/2022 16:51:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.89 on epoch=662
05/20/2022 16:51:11 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.1 on epoch=662
05/20/2022 16:51:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.85 on epoch=664
05/20/2022 16:51:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
05/20/2022 16:51:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=669
05/20/2022 16:51:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.89 on epoch=672
05/20/2022 16:51:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.97 on epoch=674
05/20/2022 16:51:18 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.10126582278481013 on epoch=674
05/20/2022 16:51:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.96 on epoch=677
05/20/2022 16:51:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.95 on epoch=679
05/20/2022 16:51:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.97 on epoch=682
05/20/2022 16:51:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/20/2022 16:51:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.02 on epoch=687
05/20/2022 16:51:26 - INFO - __main__ - Global step 2750 Train loss 0.95 Classification-F1 0.1 on epoch=687
05/20/2022 16:51:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/20/2022 16:51:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.83 on epoch=692
05/20/2022 16:51:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/20/2022 16:51:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.86 on epoch=697
05/20/2022 16:51:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.85 on epoch=699
05/20/2022 16:51:33 - INFO - __main__ - Global step 2800 Train loss 0.89 Classification-F1 0.1 on epoch=699
05/20/2022 16:51:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.93 on epoch=702
05/20/2022 16:51:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/20/2022 16:51:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/20/2022 16:51:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.88 on epoch=709
05/20/2022 16:51:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/20/2022 16:51:41 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.16666666666666666 on epoch=712
05/20/2022 16:51:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.88 on epoch=714
05/20/2022 16:51:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.87 on epoch=717
05/20/2022 16:51:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/20/2022 16:51:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
05/20/2022 16:51:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
05/20/2022 16:51:48 - INFO - __main__ - Global step 2900 Train loss 0.90 Classification-F1 0.09868421052631579 on epoch=724
05/20/2022 16:51:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.93 on epoch=727
05/20/2022 16:51:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.86 on epoch=729
05/20/2022 16:51:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.82 on epoch=732
05/20/2022 16:51:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.87 on epoch=734
05/20/2022 16:51:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.88 on epoch=737
05/20/2022 16:51:56 - INFO - __main__ - Global step 2950 Train loss 0.87 Classification-F1 0.15 on epoch=737
05/20/2022 16:51:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.81 on epoch=739
05/20/2022 16:51:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.90 on epoch=742
05/20/2022 16:52:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.90 on epoch=744
05/20/2022 16:52:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.92 on epoch=747
05/20/2022 16:52:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.87 on epoch=749
05/20/2022 16:52:03 - INFO - __main__ - Global step 3000 Train loss 0.88 Classification-F1 0.17569930069930068 on epoch=749
05/20/2022 16:52:03 - INFO - __main__ - save last model!
05/20/2022 16:52:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 16:52:03 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 16:52:03 - INFO - __main__ - Printing 3 examples
05/20/2022 16:52:03 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 16:52:03 - INFO - __main__ - ['others']
05/20/2022 16:52:03 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 16:52:03 - INFO - __main__ - ['others']
05/20/2022 16:52:03 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 16:52:03 - INFO - __main__ - ['others']
05/20/2022 16:52:03 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:52:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:52:04 - INFO - __main__ - Printing 3 examples
05/20/2022 16:52:04 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 16:52:04 - INFO - __main__ - ['others']
05/20/2022 16:52:04 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 16:52:04 - INFO - __main__ - ['others']
05/20/2022 16:52:04 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 16:52:04 - INFO - __main__ - ['others']
05/20/2022 16:52:04 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:52:04 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:52:04 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 16:52:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:52:04 - INFO - __main__ - Printing 3 examples
05/20/2022 16:52:04 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 16:52:04 - INFO - __main__ - ['others']
05/20/2022 16:52:04 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 16:52:04 - INFO - __main__ - ['others']
05/20/2022 16:52:04 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 16:52:04 - INFO - __main__ - ['others']
05/20/2022 16:52:04 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:52:04 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:52:04 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 16:52:05 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:52:11 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 16:52:11 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 16:52:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 16:52:11 - INFO - __main__ - Starting training!
05/20/2022 16:52:54 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.5_8_predictions.txt
05/20/2022 16:52:54 - INFO - __main__ - Classification-F1 on test data: 0.0473
05/20/2022 16:52:54 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.2505484861781483, test_performance=0.04729741568112133
05/20/2022 16:52:54 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
05/20/2022 16:52:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:52:55 - INFO - __main__ - Printing 3 examples
05/20/2022 16:52:55 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 16:52:55 - INFO - __main__ - ['others']
05/20/2022 16:52:55 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 16:52:55 - INFO - __main__ - ['others']
05/20/2022 16:52:55 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 16:52:55 - INFO - __main__ - ['others']
05/20/2022 16:52:55 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:52:55 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:52:55 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 16:52:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 16:52:55 - INFO - __main__ - Printing 3 examples
05/20/2022 16:52:55 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 16:52:55 - INFO - __main__ - ['others']
05/20/2022 16:52:55 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 16:52:55 - INFO - __main__ - ['others']
05/20/2022 16:52:55 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 16:52:55 - INFO - __main__ - ['others']
05/20/2022 16:52:55 - INFO - __main__ - Tokenizing Input ...
05/20/2022 16:52:55 - INFO - __main__ - Tokenizing Output ...
05/20/2022 16:52:55 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 16:53:02 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 16:53:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 16:53:02 - INFO - __main__ - Starting training!
05/20/2022 16:53:03 - INFO - __main__ - Step 10 Global step 10 Train loss 6.76 on epoch=2
05/20/2022 16:53:05 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/20/2022 16:53:06 - INFO - __main__ - Step 30 Global step 30 Train loss 6.22 on epoch=7
05/20/2022 16:53:08 - INFO - __main__ - Step 40 Global step 40 Train loss 6.03 on epoch=9
05/20/2022 16:53:09 - INFO - __main__ - Step 50 Global step 50 Train loss 5.81 on epoch=12
05/20/2022 16:53:21 - INFO - __main__ - Global step 50 Train loss 6.28 Classification-F1 0.0 on epoch=12
05/20/2022 16:53:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 16:53:22 - INFO - __main__ - Step 60 Global step 60 Train loss 5.64 on epoch=14
05/20/2022 16:53:23 - INFO - __main__ - Step 70 Global step 70 Train loss 5.56 on epoch=17
05/20/2022 16:53:25 - INFO - __main__ - Step 80 Global step 80 Train loss 5.44 on epoch=19
05/20/2022 16:53:26 - INFO - __main__ - Step 90 Global step 90 Train loss 5.10 on epoch=22
05/20/2022 16:53:27 - INFO - __main__ - Step 100 Global step 100 Train loss 4.90 on epoch=24
05/20/2022 16:53:29 - INFO - __main__ - Global step 100 Train loss 5.33 Classification-F1 0.009049773755656108 on epoch=24
05/20/2022 16:53:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009049773755656108 on epoch=24, global_step=100
05/20/2022 16:53:30 - INFO - __main__ - Step 110 Global step 110 Train loss 4.73 on epoch=27
05/20/2022 16:53:32 - INFO - __main__ - Step 120 Global step 120 Train loss 4.50 on epoch=29
05/20/2022 16:53:33 - INFO - __main__ - Step 130 Global step 130 Train loss 4.27 on epoch=32
05/20/2022 16:53:35 - INFO - __main__ - Step 140 Global step 140 Train loss 4.05 on epoch=34
05/20/2022 16:53:36 - INFO - __main__ - Step 150 Global step 150 Train loss 3.85 on epoch=37
05/20/2022 16:53:37 - INFO - __main__ - Global step 150 Train loss 4.28 Classification-F1 0.08421052631578949 on epoch=37
05/20/2022 16:53:37 - INFO - __main__ - Saving model with best Classification-F1: 0.009049773755656108 -> 0.08421052631578949 on epoch=37, global_step=150
05/20/2022 16:53:38 - INFO - __main__ - Step 160 Global step 160 Train loss 3.71 on epoch=39
05/20/2022 16:53:40 - INFO - __main__ - Step 170 Global step 170 Train loss 3.72 on epoch=42
05/20/2022 16:53:41 - INFO - __main__ - Step 180 Global step 180 Train loss 3.40 on epoch=44
05/20/2022 16:53:42 - INFO - __main__ - Step 190 Global step 190 Train loss 3.07 on epoch=47
05/20/2022 16:53:43 - INFO - __main__ - Step 200 Global step 200 Train loss 3.10 on epoch=49
05/20/2022 16:53:44 - INFO - __main__ - Global step 200 Train loss 3.40 Classification-F1 0.1237183868762816 on epoch=49
05/20/2022 16:53:44 - INFO - __main__ - Saving model with best Classification-F1: 0.08421052631578949 -> 0.1237183868762816 on epoch=49, global_step=200
05/20/2022 16:53:45 - INFO - __main__ - Step 210 Global step 210 Train loss 2.93 on epoch=52
05/20/2022 16:53:47 - INFO - __main__ - Step 220 Global step 220 Train loss 2.85 on epoch=54
05/20/2022 16:53:48 - INFO - __main__ - Step 230 Global step 230 Train loss 2.78 on epoch=57
05/20/2022 16:53:49 - INFO - __main__ - Step 240 Global step 240 Train loss 2.58 on epoch=59
05/20/2022 16:53:51 - INFO - __main__ - Step 250 Global step 250 Train loss 2.58 on epoch=62
05/20/2022 16:53:51 - INFO - __main__ - Global step 250 Train loss 2.75 Classification-F1 0.09210526315789473 on epoch=62
05/20/2022 16:53:53 - INFO - __main__ - Step 260 Global step 260 Train loss 2.54 on epoch=64
05/20/2022 16:53:54 - INFO - __main__ - Step 270 Global step 270 Train loss 2.51 on epoch=67
05/20/2022 16:53:55 - INFO - __main__ - Step 280 Global step 280 Train loss 2.28 on epoch=69
05/20/2022 16:53:57 - INFO - __main__ - Step 290 Global step 290 Train loss 2.32 on epoch=72
05/20/2022 16:53:58 - INFO - __main__ - Step 300 Global step 300 Train loss 2.19 on epoch=74
05/20/2022 16:53:59 - INFO - __main__ - Global step 300 Train loss 2.37 Classification-F1 0.1527777777777778 on epoch=74
05/20/2022 16:53:59 - INFO - __main__ - Saving model with best Classification-F1: 0.1237183868762816 -> 0.1527777777777778 on epoch=74, global_step=300
05/20/2022 16:54:00 - INFO - __main__ - Step 310 Global step 310 Train loss 2.51 on epoch=77
05/20/2022 16:54:01 - INFO - __main__ - Step 320 Global step 320 Train loss 2.28 on epoch=79
05/20/2022 16:54:03 - INFO - __main__ - Step 330 Global step 330 Train loss 2.18 on epoch=82
05/20/2022 16:54:04 - INFO - __main__ - Step 340 Global step 340 Train loss 2.01 on epoch=84
05/20/2022 16:54:05 - INFO - __main__ - Step 350 Global step 350 Train loss 2.17 on epoch=87
05/20/2022 16:54:06 - INFO - __main__ - Global step 350 Train loss 2.23 Classification-F1 0.1565276828434723 on epoch=87
05/20/2022 16:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1527777777777778 -> 0.1565276828434723 on epoch=87, global_step=350
05/20/2022 16:54:07 - INFO - __main__ - Step 360 Global step 360 Train loss 2.00 on epoch=89
05/20/2022 16:54:09 - INFO - __main__ - Step 370 Global step 370 Train loss 1.95 on epoch=92
05/20/2022 16:54:10 - INFO - __main__ - Step 380 Global step 380 Train loss 1.95 on epoch=94
05/20/2022 16:54:11 - INFO - __main__ - Step 390 Global step 390 Train loss 1.97 on epoch=97
05/20/2022 16:54:13 - INFO - __main__ - Step 400 Global step 400 Train loss 1.79 on epoch=99
05/20/2022 16:54:13 - INFO - __main__ - Global step 400 Train loss 1.93 Classification-F1 0.10234192037470727 on epoch=99
05/20/2022 16:54:15 - INFO - __main__ - Step 410 Global step 410 Train loss 1.96 on epoch=102
05/20/2022 16:54:16 - INFO - __main__ - Step 420 Global step 420 Train loss 1.77 on epoch=104
05/20/2022 16:54:18 - INFO - __main__ - Step 430 Global step 430 Train loss 1.88 on epoch=107
05/20/2022 16:54:19 - INFO - __main__ - Step 440 Global step 440 Train loss 1.66 on epoch=109
05/20/2022 16:54:20 - INFO - __main__ - Step 450 Global step 450 Train loss 1.73 on epoch=112
05/20/2022 16:54:21 - INFO - __main__ - Global step 450 Train loss 1.80 Classification-F1 0.16969147005444646 on epoch=112
05/20/2022 16:54:21 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.16969147005444646 on epoch=112, global_step=450
05/20/2022 16:54:22 - INFO - __main__ - Step 460 Global step 460 Train loss 1.53 on epoch=114
05/20/2022 16:54:24 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=117
05/20/2022 16:54:25 - INFO - __main__ - Step 480 Global step 480 Train loss 1.63 on epoch=119
05/20/2022 16:54:26 - INFO - __main__ - Step 490 Global step 490 Train loss 1.67 on epoch=122
05/20/2022 16:54:28 - INFO - __main__ - Step 500 Global step 500 Train loss 1.67 on epoch=124
05/20/2022 16:54:28 - INFO - __main__ - Global step 500 Train loss 1.64 Classification-F1 0.1 on epoch=124
05/20/2022 16:54:30 - INFO - __main__ - Step 510 Global step 510 Train loss 1.60 on epoch=127
05/20/2022 16:54:31 - INFO - __main__ - Step 520 Global step 520 Train loss 1.44 on epoch=129
05/20/2022 16:54:33 - INFO - __main__ - Step 530 Global step 530 Train loss 1.67 on epoch=132
05/20/2022 16:54:34 - INFO - __main__ - Step 540 Global step 540 Train loss 1.56 on epoch=134
05/20/2022 16:54:36 - INFO - __main__ - Step 550 Global step 550 Train loss 1.42 on epoch=137
05/20/2022 16:54:36 - INFO - __main__ - Global step 550 Train loss 1.54 Classification-F1 0.18643263757115752 on epoch=137
05/20/2022 16:54:36 - INFO - __main__ - Saving model with best Classification-F1: 0.16969147005444646 -> 0.18643263757115752 on epoch=137, global_step=550
05/20/2022 16:54:38 - INFO - __main__ - Step 560 Global step 560 Train loss 1.46 on epoch=139
05/20/2022 16:54:39 - INFO - __main__ - Step 570 Global step 570 Train loss 1.45 on epoch=142
05/20/2022 16:54:40 - INFO - __main__ - Step 580 Global step 580 Train loss 1.40 on epoch=144
05/20/2022 16:54:42 - INFO - __main__ - Step 590 Global step 590 Train loss 1.39 on epoch=147
05/20/2022 16:54:43 - INFO - __main__ - Step 600 Global step 600 Train loss 1.39 on epoch=149
05/20/2022 16:54:44 - INFO - __main__ - Global step 600 Train loss 1.42 Classification-F1 0.1 on epoch=149
05/20/2022 16:54:45 - INFO - __main__ - Step 610 Global step 610 Train loss 1.44 on epoch=152
05/20/2022 16:54:47 - INFO - __main__ - Step 620 Global step 620 Train loss 1.27 on epoch=154
05/20/2022 16:54:48 - INFO - __main__ - Step 630 Global step 630 Train loss 1.33 on epoch=157
05/20/2022 16:54:49 - INFO - __main__ - Step 640 Global step 640 Train loss 1.23 on epoch=159
05/20/2022 16:54:51 - INFO - __main__ - Step 650 Global step 650 Train loss 1.38 on epoch=162
05/20/2022 16:54:51 - INFO - __main__ - Global step 650 Train loss 1.33 Classification-F1 0.10126582278481013 on epoch=162
05/20/2022 16:54:53 - INFO - __main__ - Step 660 Global step 660 Train loss 1.32 on epoch=164
05/20/2022 16:54:54 - INFO - __main__ - Step 670 Global step 670 Train loss 1.29 on epoch=167
05/20/2022 16:54:55 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=169
05/20/2022 16:54:57 - INFO - __main__ - Step 690 Global step 690 Train loss 1.29 on epoch=172
05/20/2022 16:54:58 - INFO - __main__ - Step 700 Global step 700 Train loss 1.29 on epoch=174
05/20/2022 16:54:59 - INFO - __main__ - Global step 700 Train loss 1.29 Classification-F1 0.12399355877616748 on epoch=174
05/20/2022 16:55:00 - INFO - __main__ - Step 710 Global step 710 Train loss 1.35 on epoch=177
05/20/2022 16:55:02 - INFO - __main__ - Step 720 Global step 720 Train loss 1.23 on epoch=179
05/20/2022 16:55:03 - INFO - __main__ - Step 730 Global step 730 Train loss 1.19 on epoch=182
05/20/2022 16:55:04 - INFO - __main__ - Step 740 Global step 740 Train loss 1.20 on epoch=184
05/20/2022 16:55:06 - INFO - __main__ - Step 750 Global step 750 Train loss 1.22 on epoch=187
05/20/2022 16:55:06 - INFO - __main__ - Global step 750 Train loss 1.24 Classification-F1 0.177928916191312 on epoch=187
05/20/2022 16:55:07 - INFO - __main__ - Step 760 Global step 760 Train loss 1.27 on epoch=189
05/20/2022 16:55:09 - INFO - __main__ - Step 770 Global step 770 Train loss 1.29 on epoch=192
05/20/2022 16:55:10 - INFO - __main__ - Step 780 Global step 780 Train loss 1.16 on epoch=194
05/20/2022 16:55:12 - INFO - __main__ - Step 790 Global step 790 Train loss 1.06 on epoch=197
05/20/2022 16:55:13 - INFO - __main__ - Step 800 Global step 800 Train loss 1.19 on epoch=199
05/20/2022 16:55:14 - INFO - __main__ - Global step 800 Train loss 1.19 Classification-F1 0.09999999999999999 on epoch=199
05/20/2022 16:55:15 - INFO - __main__ - Step 810 Global step 810 Train loss 1.18 on epoch=202
05/20/2022 16:55:16 - INFO - __main__ - Step 820 Global step 820 Train loss 1.18 on epoch=204
05/20/2022 16:55:18 - INFO - __main__ - Step 830 Global step 830 Train loss 1.11 on epoch=207
05/20/2022 16:55:19 - INFO - __main__ - Step 840 Global step 840 Train loss 1.14 on epoch=209
05/20/2022 16:55:21 - INFO - __main__ - Step 850 Global step 850 Train loss 1.17 on epoch=212
05/20/2022 16:55:21 - INFO - __main__ - Global step 850 Train loss 1.16 Classification-F1 0.08571428571428572 on epoch=212
05/20/2022 16:55:22 - INFO - __main__ - Step 860 Global step 860 Train loss 1.02 on epoch=214
05/20/2022 16:55:24 - INFO - __main__ - Step 870 Global step 870 Train loss 1.36 on epoch=217
05/20/2022 16:55:25 - INFO - __main__ - Step 880 Global step 880 Train loss 1.14 on epoch=219
05/20/2022 16:55:27 - INFO - __main__ - Step 890 Global step 890 Train loss 1.23 on epoch=222
05/20/2022 16:55:28 - INFO - __main__ - Step 900 Global step 900 Train loss 1.16 on epoch=224
05/20/2022 16:55:29 - INFO - __main__ - Global step 900 Train loss 1.18 Classification-F1 0.13333333333333333 on epoch=224
05/20/2022 16:55:30 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/20/2022 16:55:31 - INFO - __main__ - Step 920 Global step 920 Train loss 1.10 on epoch=229
05/20/2022 16:55:33 - INFO - __main__ - Step 930 Global step 930 Train loss 1.17 on epoch=232
05/20/2022 16:55:34 - INFO - __main__ - Step 940 Global step 940 Train loss 1.17 on epoch=234
05/20/2022 16:55:35 - INFO - __main__ - Step 950 Global step 950 Train loss 1.25 on epoch=237
05/20/2022 16:55:36 - INFO - __main__ - Global step 950 Train loss 1.18 Classification-F1 0.2277777777777778 on epoch=237
05/20/2022 16:55:36 - INFO - __main__ - Saving model with best Classification-F1: 0.18643263757115752 -> 0.2277777777777778 on epoch=237, global_step=950
05/20/2022 16:55:37 - INFO - __main__ - Step 960 Global step 960 Train loss 1.08 on epoch=239
05/20/2022 16:55:39 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=242
05/20/2022 16:55:40 - INFO - __main__ - Step 980 Global step 980 Train loss 1.21 on epoch=244
05/20/2022 16:55:41 - INFO - __main__ - Step 990 Global step 990 Train loss 1.04 on epoch=247
05/20/2022 16:55:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.06 on epoch=249
05/20/2022 16:55:43 - INFO - __main__ - Global step 1000 Train loss 1.11 Classification-F1 0.09493670886075949 on epoch=249
05/20/2022 16:55:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.07 on epoch=252
05/20/2022 16:55:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.10 on epoch=254
05/20/2022 16:55:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/20/2022 16:55:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=259
05/20/2022 16:55:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.10 on epoch=262
05/20/2022 16:55:51 - INFO - __main__ - Global step 1050 Train loss 1.09 Classification-F1 0.1575757575757576 on epoch=262
05/20/2022 16:55:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.10 on epoch=264
05/20/2022 16:55:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=267
05/20/2022 16:55:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/20/2022 16:55:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.21 on epoch=272
05/20/2022 16:55:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
05/20/2022 16:55:58 - INFO - __main__ - Global step 1100 Train loss 1.14 Classification-F1 0.12447885646217988 on epoch=274
05/20/2022 16:56:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.12 on epoch=277
05/20/2022 16:56:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.98 on epoch=279
05/20/2022 16:56:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=282
05/20/2022 16:56:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.10 on epoch=284
05/20/2022 16:56:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.09 on epoch=287
05/20/2022 16:56:06 - INFO - __main__ - Global step 1150 Train loss 1.06 Classification-F1 0.13427800269905532 on epoch=287
05/20/2022 16:56:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.11 on epoch=289
05/20/2022 16:56:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.20 on epoch=292
05/20/2022 16:56:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/20/2022 16:56:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.12 on epoch=297
05/20/2022 16:56:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.05 on epoch=299
05/20/2022 16:56:13 - INFO - __main__ - Global step 1200 Train loss 1.13 Classification-F1 0.1 on epoch=299
05/20/2022 16:56:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.18 on epoch=302
05/20/2022 16:56:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.05 on epoch=304
05/20/2022 16:56:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.10 on epoch=307
05/20/2022 16:56:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
05/20/2022 16:56:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=312
05/20/2022 16:56:21 - INFO - __main__ - Global step 1250 Train loss 1.10 Classification-F1 0.1 on epoch=312
05/20/2022 16:56:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.11 on epoch=314
05/20/2022 16:56:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.17 on epoch=317
05/20/2022 16:56:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.01 on epoch=319
05/20/2022 16:56:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.01 on epoch=322
05/20/2022 16:56:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.14 on epoch=324
05/20/2022 16:56:28 - INFO - __main__ - Global step 1300 Train loss 1.09 Classification-F1 0.13154929577464788 on epoch=324
05/20/2022 16:56:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
05/20/2022 16:56:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.12 on epoch=329
05/20/2022 16:56:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.08 on epoch=332
05/20/2022 16:56:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.95 on epoch=334
05/20/2022 16:56:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.08 on epoch=337
05/20/2022 16:56:36 - INFO - __main__ - Global step 1350 Train loss 1.05 Classification-F1 0.19821428571428573 on epoch=337
05/20/2022 16:56:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.10 on epoch=339
05/20/2022 16:56:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.07 on epoch=342
05/20/2022 16:56:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.02 on epoch=344
05/20/2022 16:56:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
05/20/2022 16:56:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.90 on epoch=349
05/20/2022 16:56:43 - INFO - __main__ - Global step 1400 Train loss 1.05 Classification-F1 0.1774628879892038 on epoch=349
05/20/2022 16:56:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.13 on epoch=352
05/20/2022 16:56:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.94 on epoch=354
05/20/2022 16:56:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.97 on epoch=357
05/20/2022 16:56:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.05 on epoch=359
05/20/2022 16:56:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.07 on epoch=362
05/20/2022 16:56:51 - INFO - __main__ - Global step 1450 Train loss 1.03 Classification-F1 0.14913151364764268 on epoch=362
05/20/2022 16:56:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=364
05/20/2022 16:56:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.98 on epoch=367
05/20/2022 16:56:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
05/20/2022 16:56:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.96 on epoch=372
05/20/2022 16:56:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.06 on epoch=374
05/20/2022 16:56:58 - INFO - __main__ - Global step 1500 Train loss 1.01 Classification-F1 0.13123993558776167 on epoch=374
05/20/2022 16:56:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
05/20/2022 16:57:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/20/2022 16:57:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.04 on epoch=382
05/20/2022 16:57:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.97 on epoch=384
05/20/2022 16:57:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.99 on epoch=387
05/20/2022 16:57:05 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.13482414242292662 on epoch=387
05/20/2022 16:57:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.07 on epoch=389
05/20/2022 16:57:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.01 on epoch=392
05/20/2022 16:57:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.06 on epoch=394
05/20/2022 16:57:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.01 on epoch=397
05/20/2022 16:57:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.97 on epoch=399
05/20/2022 16:57:12 - INFO - __main__ - Global step 1600 Train loss 1.02 Classification-F1 0.16563380281690143 on epoch=399
05/20/2022 16:57:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=402
05/20/2022 16:57:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.89 on epoch=404
05/20/2022 16:57:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.12 on epoch=407
05/20/2022 16:57:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.00 on epoch=409
05/20/2022 16:57:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.03 on epoch=412
05/20/2022 16:57:19 - INFO - __main__ - Global step 1650 Train loss 1.01 Classification-F1 0.17712418300653593 on epoch=412
05/20/2022 16:57:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.89 on epoch=414
05/20/2022 16:57:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.91 on epoch=417
05/20/2022 16:57:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.10 on epoch=419
05/20/2022 16:57:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.94 on epoch=422
05/20/2022 16:57:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.06 on epoch=424
05/20/2022 16:57:27 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.14600840336134455 on epoch=424
05/20/2022 16:57:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.02 on epoch=427
05/20/2022 16:57:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.85 on epoch=429
05/20/2022 16:57:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.03 on epoch=432
05/20/2022 16:57:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.97 on epoch=434
05/20/2022 16:57:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.98 on epoch=437
05/20/2022 16:57:34 - INFO - __main__ - Global step 1750 Train loss 0.97 Classification-F1 0.16137566137566137 on epoch=437
05/20/2022 16:57:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.99 on epoch=439
05/20/2022 16:57:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/20/2022 16:57:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.86 on epoch=444
05/20/2022 16:57:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.93 on epoch=447
05/20/2022 16:57:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
05/20/2022 16:57:41 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.15587044534412953 on epoch=449
05/20/2022 16:57:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.02 on epoch=452
05/20/2022 16:57:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.02 on epoch=454
05/20/2022 16:57:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.98 on epoch=457
05/20/2022 16:57:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=459
05/20/2022 16:57:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/20/2022 16:57:48 - INFO - __main__ - Global step 1850 Train loss 1.02 Classification-F1 0.15682382133995038 on epoch=462
05/20/2022 16:57:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/20/2022 16:57:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=467
05/20/2022 16:57:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
05/20/2022 16:57:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/20/2022 16:57:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.95 on epoch=474
05/20/2022 16:57:56 - INFO - __main__ - Global step 1900 Train loss 0.95 Classification-F1 0.12447885646217988 on epoch=474
05/20/2022 16:57:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/20/2022 16:57:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.08 on epoch=479
05/20/2022 16:58:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.95 on epoch=482
05/20/2022 16:58:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/20/2022 16:58:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.09 on epoch=487
05/20/2022 16:58:03 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.20833333333333331 on epoch=487
05/20/2022 16:58:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.89 on epoch=489
05/20/2022 16:58:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=492
05/20/2022 16:58:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.96 on epoch=494
05/20/2022 16:58:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.01 on epoch=497
05/20/2022 16:58:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.91 on epoch=499
05/20/2022 16:58:10 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.13034188034188032 on epoch=499
05/20/2022 16:58:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.90 on epoch=502
05/20/2022 16:58:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.99 on epoch=504
05/20/2022 16:58:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.08 on epoch=507
05/20/2022 16:58:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.92 on epoch=509
05/20/2022 16:58:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.09 on epoch=512
05/20/2022 16:58:17 - INFO - __main__ - Global step 2050 Train loss 1.00 Classification-F1 0.09333333333333334 on epoch=512
05/20/2022 16:58:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.04 on epoch=514
05/20/2022 16:58:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.98 on epoch=517
05/20/2022 16:58:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.94 on epoch=519
05/20/2022 16:58:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.92 on epoch=522
05/20/2022 16:58:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/20/2022 16:58:24 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.09482363719651855 on epoch=524
05/20/2022 16:58:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.86 on epoch=527
05/20/2022 16:58:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
05/20/2022 16:58:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/20/2022 16:58:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.90 on epoch=534
05/20/2022 16:58:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.95 on epoch=537
05/20/2022 16:58:32 - INFO - __main__ - Global step 2150 Train loss 0.94 Classification-F1 0.10126582278481013 on epoch=537
05/20/2022 16:58:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
05/20/2022 16:58:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.87 on epoch=542
05/20/2022 16:58:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.92 on epoch=544
05/20/2022 16:58:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.95 on epoch=547
05/20/2022 16:58:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.03 on epoch=549
05/20/2022 16:58:39 - INFO - __main__ - Global step 2200 Train loss 0.94 Classification-F1 0.09615384615384615 on epoch=549
05/20/2022 16:58:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.04 on epoch=552
05/20/2022 16:58:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.89 on epoch=554
05/20/2022 16:58:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=557
05/20/2022 16:58:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.95 on epoch=559
05/20/2022 16:58:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.04 on epoch=562
05/20/2022 16:58:46 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.13251935675997617 on epoch=562
05/20/2022 16:58:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.86 on epoch=564
05/20/2022 16:58:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.91 on epoch=567
05/20/2022 16:58:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/20/2022 16:58:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
05/20/2022 16:58:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.03 on epoch=574
05/20/2022 16:58:54 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.09391534391534392 on epoch=574
05/20/2022 16:58:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/20/2022 16:58:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.92 on epoch=579
05/20/2022 16:58:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.04 on epoch=582
05/20/2022 16:58:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/20/2022 16:59:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.05 on epoch=587
05/20/2022 16:59:01 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.18614718614718614 on epoch=587
05/20/2022 16:59:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.91 on epoch=589
05/20/2022 16:59:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/20/2022 16:59:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.93 on epoch=594
05/20/2022 16:59:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.01 on epoch=597
05/20/2022 16:59:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.84 on epoch=599
05/20/2022 16:59:08 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.15188470066518847 on epoch=599
05/20/2022 16:59:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/20/2022 16:59:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/20/2022 16:59:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.98 on epoch=607
05/20/2022 16:59:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.94 on epoch=609
05/20/2022 16:59:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.95 on epoch=612
05/20/2022 16:59:15 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.15306730196545562 on epoch=612
05/20/2022 16:59:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.90 on epoch=614
05/20/2022 16:59:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/20/2022 16:59:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.91 on epoch=619
05/20/2022 16:59:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.91 on epoch=622
05/20/2022 16:59:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.90 on epoch=624
05/20/2022 16:59:23 - INFO - __main__ - Global step 2500 Train loss 0.93 Classification-F1 0.09493670886075949 on epoch=624
05/20/2022 16:59:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=627
05/20/2022 16:59:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.93 on epoch=629
05/20/2022 16:59:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.92 on epoch=632
05/20/2022 16:59:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.90 on epoch=634
05/20/2022 16:59:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
05/20/2022 16:59:31 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.1486842105263158 on epoch=637
05/20/2022 16:59:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.86 on epoch=639
05/20/2022 16:59:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.84 on epoch=642
05/20/2022 16:59:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.86 on epoch=644
05/20/2022 16:59:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/20/2022 16:59:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.88 on epoch=649
05/20/2022 16:59:38 - INFO - __main__ - Global step 2600 Train loss 0.89 Classification-F1 0.09285714285714285 on epoch=649
05/20/2022 16:59:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.07 on epoch=652
05/20/2022 16:59:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.87 on epoch=654
05/20/2022 16:59:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.87 on epoch=657
05/20/2022 16:59:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
05/20/2022 16:59:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/20/2022 16:59:46 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.15306730196545562 on epoch=662
05/20/2022 16:59:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.08 on epoch=664
05/20/2022 16:59:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/20/2022 16:59:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
05/20/2022 16:59:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.99 on epoch=672
05/20/2022 16:59:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/20/2022 16:59:53 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.1458966565349544 on epoch=674
05/20/2022 16:59:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/20/2022 16:59:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.86 on epoch=679
05/20/2022 16:59:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/20/2022 16:59:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.91 on epoch=684
05/20/2022 17:00:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.92 on epoch=687
05/20/2022 17:00:01 - INFO - __main__ - Global step 2750 Train loss 0.91 Classification-F1 0.18623481781376516 on epoch=687
05/20/2022 17:00:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
05/20/2022 17:00:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
05/20/2022 17:00:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.86 on epoch=694
05/20/2022 17:00:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
05/20/2022 17:00:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.86 on epoch=699
05/20/2022 17:00:08 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.10023419203747073 on epoch=699
05/20/2022 17:00:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.86 on epoch=702
05/20/2022 17:00:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/20/2022 17:00:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.05 on epoch=707
05/20/2022 17:00:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.84 on epoch=709
05/20/2022 17:00:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=712
05/20/2022 17:00:16 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.13859154929577466 on epoch=712
05/20/2022 17:00:17 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.92 on epoch=714
05/20/2022 17:00:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.97 on epoch=717
05/20/2022 17:00:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/20/2022 17:00:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.91 on epoch=722
05/20/2022 17:00:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
05/20/2022 17:00:23 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.16923774954627951 on epoch=724
05/20/2022 17:00:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.96 on epoch=727
05/20/2022 17:00:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.97 on epoch=729
05/20/2022 17:00:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
05/20/2022 17:00:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.00 on epoch=734
05/20/2022 17:00:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.79 on epoch=737
05/20/2022 17:00:30 - INFO - __main__ - Global step 2950 Train loss 0.92 Classification-F1 0.11805555555555555 on epoch=737
05/20/2022 17:00:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.06 on epoch=739
05/20/2022 17:00:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.85 on epoch=742
05/20/2022 17:00:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.92 on epoch=744
05/20/2022 17:00:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.87 on epoch=747
05/20/2022 17:00:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.81 on epoch=749
05/20/2022 17:00:38 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.12521739130434784 on epoch=749
05/20/2022 17:00:38 - INFO - __main__ - save last model!
05/20/2022 17:00:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 17:00:38 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 17:00:38 - INFO - __main__ - Printing 3 examples
05/20/2022 17:00:38 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:00:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:00:38 - INFO - __main__ - Printing 3 examples
05/20/2022 17:00:38 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:00:38 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:00:38 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:00:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:00:38 - INFO - __main__ - Printing 3 examples
05/20/2022 17:00:38 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 17:00:38 - INFO - __main__ - ['others']
05/20/2022 17:00:38 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:00:38 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:00:39 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:00:41 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:00:45 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:00:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:00:45 - INFO - __main__ - Starting training!
05/20/2022 17:00:46 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 17:01:30 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.4_8_predictions.txt
05/20/2022 17:01:30 - INFO - __main__ - Classification-F1 on test data: 0.0438
05/20/2022 17:01:30 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.2277777777777778, test_performance=0.043761291883696464
05/20/2022 17:01:30 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
05/20/2022 17:01:31 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:01:31 - INFO - __main__ - Printing 3 examples
05/20/2022 17:01:31 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 17:01:31 - INFO - __main__ - ['others']
05/20/2022 17:01:31 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 17:01:31 - INFO - __main__ - ['others']
05/20/2022 17:01:31 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 17:01:31 - INFO - __main__ - ['others']
05/20/2022 17:01:31 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:01:31 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:01:31 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:01:31 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:01:31 - INFO - __main__ - Printing 3 examples
05/20/2022 17:01:31 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 17:01:31 - INFO - __main__ - ['others']
05/20/2022 17:01:31 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 17:01:31 - INFO - __main__ - ['others']
05/20/2022 17:01:31 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 17:01:31 - INFO - __main__ - ['others']
05/20/2022 17:01:31 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:01:31 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:01:31 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:01:38 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:01:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:01:39 - INFO - __main__ - Starting training!
05/20/2022 17:01:40 - INFO - __main__ - Step 10 Global step 10 Train loss 6.95 on epoch=2
05/20/2022 17:01:41 - INFO - __main__ - Step 20 Global step 20 Train loss 6.55 on epoch=4
05/20/2022 17:01:43 - INFO - __main__ - Step 30 Global step 30 Train loss 6.14 on epoch=7
05/20/2022 17:01:44 - INFO - __main__ - Step 40 Global step 40 Train loss 6.17 on epoch=9
05/20/2022 17:01:45 - INFO - __main__ - Step 50 Global step 50 Train loss 5.94 on epoch=12
05/20/2022 17:01:48 - INFO - __main__ - Global step 50 Train loss 6.35 Classification-F1 0.0 on epoch=12
05/20/2022 17:01:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 17:01:49 - INFO - __main__ - Step 60 Global step 60 Train loss 5.78 on epoch=14
05/20/2022 17:01:51 - INFO - __main__ - Step 70 Global step 70 Train loss 5.65 on epoch=17
05/20/2022 17:01:52 - INFO - __main__ - Step 80 Global step 80 Train loss 5.50 on epoch=19
05/20/2022 17:01:53 - INFO - __main__ - Step 90 Global step 90 Train loss 5.36 on epoch=22
05/20/2022 17:01:55 - INFO - __main__ - Step 100 Global step 100 Train loss 5.17 on epoch=24
05/20/2022 17:01:57 - INFO - __main__ - Global step 100 Train loss 5.49 Classification-F1 0.0 on epoch=24
05/20/2022 17:01:58 - INFO - __main__ - Step 110 Global step 110 Train loss 5.02 on epoch=27
05/20/2022 17:01:59 - INFO - __main__ - Step 120 Global step 120 Train loss 5.06 on epoch=29
05/20/2022 17:02:01 - INFO - __main__ - Step 130 Global step 130 Train loss 4.80 on epoch=32
05/20/2022 17:02:02 - INFO - __main__ - Step 140 Global step 140 Train loss 4.65 on epoch=34
05/20/2022 17:02:04 - INFO - __main__ - Step 150 Global step 150 Train loss 4.62 on epoch=37
05/20/2022 17:02:05 - INFO - __main__ - Global step 150 Train loss 4.83 Classification-F1 0.03214285714285714 on epoch=37
05/20/2022 17:02:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03214285714285714 on epoch=37, global_step=150
05/20/2022 17:02:06 - INFO - __main__ - Step 160 Global step 160 Train loss 4.34 on epoch=39
05/20/2022 17:02:07 - INFO - __main__ - Step 170 Global step 170 Train loss 4.31 on epoch=42
05/20/2022 17:02:09 - INFO - __main__ - Step 180 Global step 180 Train loss 4.13 on epoch=44
05/20/2022 17:02:10 - INFO - __main__ - Step 190 Global step 190 Train loss 4.19 on epoch=47
05/20/2022 17:02:11 - INFO - __main__ - Step 200 Global step 200 Train loss 4.07 on epoch=49
05/20/2022 17:02:12 - INFO - __main__ - Global step 200 Train loss 4.21 Classification-F1 0.16666666666666666 on epoch=49
05/20/2022 17:02:12 - INFO - __main__ - Saving model with best Classification-F1: 0.03214285714285714 -> 0.16666666666666666 on epoch=49, global_step=200
05/20/2022 17:02:13 - INFO - __main__ - Step 210 Global step 210 Train loss 4.01 on epoch=52
05/20/2022 17:02:15 - INFO - __main__ - Step 220 Global step 220 Train loss 3.76 on epoch=54
05/20/2022 17:02:16 - INFO - __main__ - Step 230 Global step 230 Train loss 3.65 on epoch=57
05/20/2022 17:02:18 - INFO - __main__ - Step 240 Global step 240 Train loss 3.55 on epoch=59
05/20/2022 17:02:19 - INFO - __main__ - Step 250 Global step 250 Train loss 3.40 on epoch=62
05/20/2022 17:02:20 - INFO - __main__ - Global step 250 Train loss 3.67 Classification-F1 0.09333333333333334 on epoch=62
05/20/2022 17:02:21 - INFO - __main__ - Step 260 Global step 260 Train loss 3.50 on epoch=64
05/20/2022 17:02:22 - INFO - __main__ - Step 270 Global step 270 Train loss 3.47 on epoch=67
05/20/2022 17:02:24 - INFO - __main__ - Step 280 Global step 280 Train loss 3.13 on epoch=69
05/20/2022 17:02:25 - INFO - __main__ - Step 290 Global step 290 Train loss 3.28 on epoch=72
05/20/2022 17:02:26 - INFO - __main__ - Step 300 Global step 300 Train loss 3.00 on epoch=74
05/20/2022 17:02:27 - INFO - __main__ - Global step 300 Train loss 3.28 Classification-F1 0.11507936507936507 on epoch=74
05/20/2022 17:02:28 - INFO - __main__ - Step 310 Global step 310 Train loss 3.09 on epoch=77
05/20/2022 17:02:30 - INFO - __main__ - Step 320 Global step 320 Train loss 2.96 on epoch=79
05/20/2022 17:02:31 - INFO - __main__ - Step 330 Global step 330 Train loss 3.06 on epoch=82
05/20/2022 17:02:32 - INFO - __main__ - Step 340 Global step 340 Train loss 2.88 on epoch=84
05/20/2022 17:02:34 - INFO - __main__ - Step 350 Global step 350 Train loss 2.76 on epoch=87
05/20/2022 17:02:34 - INFO - __main__ - Global step 350 Train loss 2.95 Classification-F1 0.14383875400824553 on epoch=87
05/20/2022 17:02:36 - INFO - __main__ - Step 360 Global step 360 Train loss 2.76 on epoch=89
05/20/2022 17:02:37 - INFO - __main__ - Step 370 Global step 370 Train loss 2.83 on epoch=92
05/20/2022 17:02:38 - INFO - __main__ - Step 380 Global step 380 Train loss 2.71 on epoch=94
05/20/2022 17:02:39 - INFO - __main__ - Step 390 Global step 390 Train loss 2.70 on epoch=97
05/20/2022 17:02:41 - INFO - __main__ - Step 400 Global step 400 Train loss 2.60 on epoch=99
05/20/2022 17:02:41 - INFO - __main__ - Global step 400 Train loss 2.72 Classification-F1 0.1 on epoch=99
05/20/2022 17:02:43 - INFO - __main__ - Step 410 Global step 410 Train loss 2.69 on epoch=102
05/20/2022 17:02:44 - INFO - __main__ - Step 420 Global step 420 Train loss 2.57 on epoch=104
05/20/2022 17:02:46 - INFO - __main__ - Step 430 Global step 430 Train loss 2.54 on epoch=107
05/20/2022 17:02:47 - INFO - __main__ - Step 440 Global step 440 Train loss 2.25 on epoch=109
05/20/2022 17:02:48 - INFO - __main__ - Step 450 Global step 450 Train loss 2.34 on epoch=112
05/20/2022 17:02:49 - INFO - __main__ - Global step 450 Train loss 2.48 Classification-F1 0.1 on epoch=112
05/20/2022 17:02:50 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=114
05/20/2022 17:02:52 - INFO - __main__ - Step 470 Global step 470 Train loss 2.38 on epoch=117
05/20/2022 17:02:53 - INFO - __main__ - Step 480 Global step 480 Train loss 2.24 on epoch=119
05/20/2022 17:02:54 - INFO - __main__ - Step 490 Global step 490 Train loss 2.23 on epoch=122
05/20/2022 17:02:56 - INFO - __main__ - Step 500 Global step 500 Train loss 2.16 on epoch=124
05/20/2022 17:02:56 - INFO - __main__ - Global step 500 Train loss 2.27 Classification-F1 0.1238095238095238 on epoch=124
05/20/2022 17:02:58 - INFO - __main__ - Step 510 Global step 510 Train loss 2.07 on epoch=127
05/20/2022 17:02:59 - INFO - __main__ - Step 520 Global step 520 Train loss 2.16 on epoch=129
05/20/2022 17:03:00 - INFO - __main__ - Step 530 Global step 530 Train loss 2.05 on epoch=132
05/20/2022 17:03:02 - INFO - __main__ - Step 540 Global step 540 Train loss 2.00 on epoch=134
05/20/2022 17:03:03 - INFO - __main__ - Step 550 Global step 550 Train loss 2.13 on epoch=137
05/20/2022 17:03:03 - INFO - __main__ - Global step 550 Train loss 2.08 Classification-F1 0.18614718614718614 on epoch=137
05/20/2022 17:03:03 - INFO - __main__ - Saving model with best Classification-F1: 0.16666666666666666 -> 0.18614718614718614 on epoch=137, global_step=550
05/20/2022 17:03:05 - INFO - __main__ - Step 560 Global step 560 Train loss 1.98 on epoch=139
05/20/2022 17:03:06 - INFO - __main__ - Step 570 Global step 570 Train loss 1.98 on epoch=142
05/20/2022 17:03:07 - INFO - __main__ - Step 580 Global step 580 Train loss 1.89 on epoch=144
05/20/2022 17:03:09 - INFO - __main__ - Step 590 Global step 590 Train loss 1.89 on epoch=147
05/20/2022 17:03:10 - INFO - __main__ - Step 600 Global step 600 Train loss 1.86 on epoch=149
05/20/2022 17:03:10 - INFO - __main__ - Global step 600 Train loss 1.92 Classification-F1 0.1 on epoch=149
05/20/2022 17:03:12 - INFO - __main__ - Step 610 Global step 610 Train loss 2.11 on epoch=152
05/20/2022 17:03:13 - INFO - __main__ - Step 620 Global step 620 Train loss 1.94 on epoch=154
05/20/2022 17:03:14 - INFO - __main__ - Step 630 Global step 630 Train loss 1.99 on epoch=157
05/20/2022 17:03:16 - INFO - __main__ - Step 640 Global step 640 Train loss 1.79 on epoch=159
05/20/2022 17:03:17 - INFO - __main__ - Step 650 Global step 650 Train loss 1.75 on epoch=162
05/20/2022 17:03:18 - INFO - __main__ - Global step 650 Train loss 1.91 Classification-F1 0.189010989010989 on epoch=162
05/20/2022 17:03:18 - INFO - __main__ - Saving model with best Classification-F1: 0.18614718614718614 -> 0.189010989010989 on epoch=162, global_step=650
05/20/2022 17:03:19 - INFO - __main__ - Step 660 Global step 660 Train loss 1.75 on epoch=164
05/20/2022 17:03:20 - INFO - __main__ - Step 670 Global step 670 Train loss 1.67 on epoch=167
05/20/2022 17:03:22 - INFO - __main__ - Step 680 Global step 680 Train loss 1.65 on epoch=169
05/20/2022 17:03:23 - INFO - __main__ - Step 690 Global step 690 Train loss 1.77 on epoch=172
05/20/2022 17:03:24 - INFO - __main__ - Step 700 Global step 700 Train loss 1.75 on epoch=174
05/20/2022 17:03:25 - INFO - __main__ - Global step 700 Train loss 1.72 Classification-F1 0.09493670886075949 on epoch=174
05/20/2022 17:03:26 - INFO - __main__ - Step 710 Global step 710 Train loss 1.71 on epoch=177
05/20/2022 17:03:28 - INFO - __main__ - Step 720 Global step 720 Train loss 1.50 on epoch=179
05/20/2022 17:03:29 - INFO - __main__ - Step 730 Global step 730 Train loss 1.57 on epoch=182
05/20/2022 17:03:30 - INFO - __main__ - Step 740 Global step 740 Train loss 1.64 on epoch=184
05/20/2022 17:03:31 - INFO - __main__ - Step 750 Global step 750 Train loss 1.60 on epoch=187
05/20/2022 17:03:32 - INFO - __main__ - Global step 750 Train loss 1.60 Classification-F1 0.16223908918406071 on epoch=187
05/20/2022 17:03:33 - INFO - __main__ - Step 760 Global step 760 Train loss 1.51 on epoch=189
05/20/2022 17:03:35 - INFO - __main__ - Step 770 Global step 770 Train loss 1.46 on epoch=192
05/20/2022 17:03:36 - INFO - __main__ - Step 780 Global step 780 Train loss 1.47 on epoch=194
05/20/2022 17:03:37 - INFO - __main__ - Step 790 Global step 790 Train loss 1.57 on epoch=197
05/20/2022 17:03:39 - INFO - __main__ - Step 800 Global step 800 Train loss 1.50 on epoch=199
05/20/2022 17:03:39 - INFO - __main__ - Global step 800 Train loss 1.50 Classification-F1 0.20714285714285713 on epoch=199
05/20/2022 17:03:39 - INFO - __main__ - Saving model with best Classification-F1: 0.189010989010989 -> 0.20714285714285713 on epoch=199, global_step=800
05/20/2022 17:03:41 - INFO - __main__ - Step 810 Global step 810 Train loss 1.48 on epoch=202
05/20/2022 17:03:42 - INFO - __main__ - Step 820 Global step 820 Train loss 1.52 on epoch=204
05/20/2022 17:03:43 - INFO - __main__ - Step 830 Global step 830 Train loss 1.43 on epoch=207
05/20/2022 17:03:45 - INFO - __main__ - Step 840 Global step 840 Train loss 1.39 on epoch=209
05/20/2022 17:03:46 - INFO - __main__ - Step 850 Global step 850 Train loss 1.47 on epoch=212
05/20/2022 17:03:47 - INFO - __main__ - Global step 850 Train loss 1.46 Classification-F1 0.19270833333333334 on epoch=212
05/20/2022 17:03:48 - INFO - __main__ - Step 860 Global step 860 Train loss 1.25 on epoch=214
05/20/2022 17:03:49 - INFO - __main__ - Step 870 Global step 870 Train loss 1.53 on epoch=217
05/20/2022 17:03:51 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
05/20/2022 17:03:52 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
05/20/2022 17:03:54 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
05/20/2022 17:03:54 - INFO - __main__ - Global step 900 Train loss 1.39 Classification-F1 0.13067758749069247 on epoch=224
05/20/2022 17:03:55 - INFO - __main__ - Step 910 Global step 910 Train loss 1.41 on epoch=227
05/20/2022 17:03:57 - INFO - __main__ - Step 920 Global step 920 Train loss 1.32 on epoch=229
05/20/2022 17:03:58 - INFO - __main__ - Step 930 Global step 930 Train loss 1.30 on epoch=232
05/20/2022 17:04:00 - INFO - __main__ - Step 940 Global step 940 Train loss 1.23 on epoch=234
05/20/2022 17:04:01 - INFO - __main__ - Step 950 Global step 950 Train loss 1.39 on epoch=237
05/20/2022 17:04:01 - INFO - __main__ - Global step 950 Train loss 1.33 Classification-F1 0.1 on epoch=237
05/20/2022 17:04:03 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/20/2022 17:04:04 - INFO - __main__ - Step 970 Global step 970 Train loss 1.39 on epoch=242
05/20/2022 17:04:05 - INFO - __main__ - Step 980 Global step 980 Train loss 1.37 on epoch=244
05/20/2022 17:04:07 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=247
05/20/2022 17:04:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.30 on epoch=249
05/20/2022 17:04:09 - INFO - __main__ - Global step 1000 Train loss 1.33 Classification-F1 0.18318622882517405 on epoch=249
05/20/2022 17:04:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.44 on epoch=252
05/20/2022 17:04:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.44 on epoch=254
05/20/2022 17:04:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.33 on epoch=257
05/20/2022 17:04:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.32 on epoch=259
05/20/2022 17:04:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.31 on epoch=262
05/20/2022 17:04:16 - INFO - __main__ - Global step 1050 Train loss 1.36 Classification-F1 0.13936867182846935 on epoch=262
05/20/2022 17:04:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.23 on epoch=264
05/20/2022 17:04:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.19 on epoch=267
05/20/2022 17:04:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.33 on epoch=269
05/20/2022 17:04:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.30 on epoch=272
05/20/2022 17:04:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.24 on epoch=274
05/20/2022 17:04:23 - INFO - __main__ - Global step 1100 Train loss 1.26 Classification-F1 0.1 on epoch=274
05/20/2022 17:04:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/20/2022 17:04:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.37 on epoch=279
05/20/2022 17:04:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.29 on epoch=282
05/20/2022 17:04:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.34 on epoch=284
05/20/2022 17:04:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.27 on epoch=287
05/20/2022 17:04:30 - INFO - __main__ - Global step 1150 Train loss 1.30 Classification-F1 0.1 on epoch=287
05/20/2022 17:04:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.32 on epoch=289
05/20/2022 17:04:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.18 on epoch=292
05/20/2022 17:04:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.17 on epoch=294
05/20/2022 17:04:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.20 on epoch=297
05/20/2022 17:04:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.25 on epoch=299
05/20/2022 17:04:38 - INFO - __main__ - Global step 1200 Train loss 1.22 Classification-F1 0.1 on epoch=299
05/20/2022 17:04:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.19 on epoch=302
05/20/2022 17:04:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.22 on epoch=304
05/20/2022 17:04:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.23 on epoch=307
05/20/2022 17:04:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/20/2022 17:04:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.13 on epoch=312
05/20/2022 17:04:46 - INFO - __main__ - Global step 1250 Train loss 1.19 Classification-F1 0.1 on epoch=312
05/20/2022 17:04:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.22 on epoch=314
05/20/2022 17:04:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.12 on epoch=317
05/20/2022 17:04:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.02 on epoch=319
05/20/2022 17:04:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.37 on epoch=322
05/20/2022 17:04:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.14 on epoch=324
05/20/2022 17:04:53 - INFO - __main__ - Global step 1300 Train loss 1.17 Classification-F1 0.1 on epoch=324
05/20/2022 17:04:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.09 on epoch=327
05/20/2022 17:04:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=329
05/20/2022 17:04:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=332
05/20/2022 17:04:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.12 on epoch=334
05/20/2022 17:05:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.18 on epoch=337
05/20/2022 17:05:01 - INFO - __main__ - Global step 1350 Train loss 1.16 Classification-F1 0.1 on epoch=337
05/20/2022 17:05:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.09 on epoch=339
05/20/2022 17:05:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.23 on epoch=342
05/20/2022 17:05:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/20/2022 17:05:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.05 on epoch=347
05/20/2022 17:05:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.10 on epoch=349
05/20/2022 17:05:08 - INFO - __main__ - Global step 1400 Train loss 1.11 Classification-F1 0.1 on epoch=349
05/20/2022 17:05:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.08 on epoch=352
05/20/2022 17:05:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.12 on epoch=354
05/20/2022 17:05:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.30 on epoch=357
05/20/2022 17:05:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.14 on epoch=359
05/20/2022 17:05:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.20 on epoch=362
05/20/2022 17:05:16 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.13034188034188032 on epoch=362
05/20/2022 17:05:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.03 on epoch=364
05/20/2022 17:05:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.12 on epoch=367
05/20/2022 17:05:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
05/20/2022 17:05:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.21 on epoch=372
05/20/2022 17:05:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.11 on epoch=374
05/20/2022 17:05:23 - INFO - __main__ - Global step 1500 Train loss 1.09 Classification-F1 0.13197586726998492 on epoch=374
05/20/2022 17:05:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.18 on epoch=377
05/20/2022 17:05:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
05/20/2022 17:05:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
05/20/2022 17:05:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
05/20/2022 17:05:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=387
05/20/2022 17:05:31 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.1581196581196581 on epoch=387
05/20/2022 17:05:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.10 on epoch=389
05/20/2022 17:05:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=392
05/20/2022 17:05:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.05 on epoch=394
05/20/2022 17:05:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
05/20/2022 17:05:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.11 on epoch=399
05/20/2022 17:05:38 - INFO - __main__ - Global step 1600 Train loss 1.11 Classification-F1 0.23552022689953725 on epoch=399
05/20/2022 17:05:38 - INFO - __main__ - Saving model with best Classification-F1: 0.20714285714285713 -> 0.23552022689953725 on epoch=399, global_step=1600
05/20/2022 17:05:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=402
05/20/2022 17:05:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/20/2022 17:05:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.12 on epoch=407
05/20/2022 17:05:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.21 on epoch=409
05/20/2022 17:05:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/20/2022 17:05:46 - INFO - __main__ - Global step 1650 Train loss 1.10 Classification-F1 0.1 on epoch=412
05/20/2022 17:05:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.06 on epoch=414
05/20/2022 17:05:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.16 on epoch=417
05/20/2022 17:05:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
05/20/2022 17:05:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/20/2022 17:05:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.00 on epoch=424
05/20/2022 17:05:54 - INFO - __main__ - Global step 1700 Train loss 1.06 Classification-F1 0.08783783783783784 on epoch=424
05/20/2022 17:05:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.13 on epoch=427
05/20/2022 17:05:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
05/20/2022 17:05:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.13 on epoch=432
05/20/2022 17:05:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=434
05/20/2022 17:06:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.14 on epoch=437
05/20/2022 17:06:01 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.07857142857142856 on epoch=437
05/20/2022 17:06:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.98 on epoch=439
05/20/2022 17:06:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.05 on epoch=442
05/20/2022 17:06:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.05 on epoch=444
05/20/2022 17:06:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/20/2022 17:06:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.95 on epoch=449
05/20/2022 17:06:09 - INFO - __main__ - Global step 1800 Train loss 1.02 Classification-F1 0.14304519526107942 on epoch=449
05/20/2022 17:06:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.08 on epoch=452
05/20/2022 17:06:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.10 on epoch=454
05/20/2022 17:06:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.09 on epoch=457
05/20/2022 17:06:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.01 on epoch=459
05/20/2022 17:06:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=462
05/20/2022 17:06:16 - INFO - __main__ - Global step 1850 Train loss 1.05 Classification-F1 0.1575934721714773 on epoch=462
05/20/2022 17:06:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.02 on epoch=464
05/20/2022 17:06:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.18 on epoch=467
05/20/2022 17:06:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.08 on epoch=469
05/20/2022 17:06:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.03 on epoch=472
05/20/2022 17:06:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.06 on epoch=474
05/20/2022 17:06:24 - INFO - __main__ - Global step 1900 Train loss 1.07 Classification-F1 0.10126582278481013 on epoch=474
05/20/2022 17:06:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.04 on epoch=477
05/20/2022 17:06:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.00 on epoch=479
05/20/2022 17:06:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.03 on epoch=482
05/20/2022 17:06:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/20/2022 17:06:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.96 on epoch=487
05/20/2022 17:06:32 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.1 on epoch=487
05/20/2022 17:06:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=489
05/20/2022 17:06:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=492
05/20/2022 17:06:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.93 on epoch=494
05/20/2022 17:06:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
05/20/2022 17:06:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.99 on epoch=499
05/20/2022 17:06:40 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.1 on epoch=499
05/20/2022 17:06:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.09 on epoch=502
05/20/2022 17:06:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.96 on epoch=504
05/20/2022 17:06:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
05/20/2022 17:06:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/20/2022 17:06:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.05 on epoch=512
05/20/2022 17:06:48 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.1 on epoch=512
05/20/2022 17:06:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/20/2022 17:06:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/20/2022 17:06:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.08 on epoch=519
05/20/2022 17:06:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
05/20/2022 17:06:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.02 on epoch=524
05/20/2022 17:06:56 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.1 on epoch=524
05/20/2022 17:06:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.99 on epoch=527
05/20/2022 17:06:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
05/20/2022 17:07:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.09 on epoch=532
05/20/2022 17:07:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=534
05/20/2022 17:07:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.02 on epoch=537
05/20/2022 17:07:03 - INFO - __main__ - Global step 2150 Train loss 1.03 Classification-F1 0.14621798689696247 on epoch=537
05/20/2022 17:07:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.97 on epoch=539
05/20/2022 17:07:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.98 on epoch=542
05/20/2022 17:07:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.98 on epoch=544
05/20/2022 17:07:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/20/2022 17:07:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.01 on epoch=549
05/20/2022 17:07:11 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.1595890410958904 on epoch=549
05/20/2022 17:07:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/20/2022 17:07:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.93 on epoch=554
05/20/2022 17:07:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/20/2022 17:07:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/20/2022 17:07:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.94 on epoch=562
05/20/2022 17:07:18 - INFO - __main__ - Global step 2250 Train loss 0.97 Classification-F1 0.15328054298642532 on epoch=562
05/20/2022 17:07:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.97 on epoch=564
05/20/2022 17:07:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.92 on epoch=567
05/20/2022 17:07:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.08 on epoch=569
05/20/2022 17:07:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
05/20/2022 17:07:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/20/2022 17:07:26 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.12393162393162392 on epoch=574
05/20/2022 17:07:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
05/20/2022 17:07:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/20/2022 17:07:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.96 on epoch=582
05/20/2022 17:07:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/20/2022 17:07:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/20/2022 17:07:33 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=587
05/20/2022 17:07:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.99 on epoch=589
05/20/2022 17:07:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/20/2022 17:07:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
05/20/2022 17:07:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.05 on epoch=597
05/20/2022 17:07:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.06 on epoch=599
05/20/2022 17:07:40 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.11710526315789474 on epoch=599
05/20/2022 17:07:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/20/2022 17:07:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.01 on epoch=604
05/20/2022 17:07:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
05/20/2022 17:07:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/20/2022 17:07:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.02 on epoch=612
05/20/2022 17:07:48 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=612
05/20/2022 17:07:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.04 on epoch=614
05/20/2022 17:07:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=617
05/20/2022 17:07:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/20/2022 17:07:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.06 on epoch=622
05/20/2022 17:07:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.92 on epoch=624
05/20/2022 17:07:56 - INFO - __main__ - Global step 2500 Train loss 1.01 Classification-F1 0.1238095238095238 on epoch=624
05/20/2022 17:07:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.20 on epoch=627
05/20/2022 17:07:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.87 on epoch=629
05/20/2022 17:08:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.04 on epoch=632
05/20/2022 17:08:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/20/2022 17:08:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
05/20/2022 17:08:03 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.13047619047619047 on epoch=637
05/20/2022 17:08:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
05/20/2022 17:08:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
05/20/2022 17:08:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/20/2022 17:08:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
05/20/2022 17:08:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
05/20/2022 17:08:10 - INFO - __main__ - Global step 2600 Train loss 1.00 Classification-F1 0.1554709658157934 on epoch=649
05/20/2022 17:08:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/20/2022 17:08:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
05/20/2022 17:08:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/20/2022 17:08:16 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/20/2022 17:08:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
05/20/2022 17:08:18 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.17220843672456576 on epoch=662
05/20/2022 17:08:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.97 on epoch=664
05/20/2022 17:08:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.92 on epoch=667
05/20/2022 17:08:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
05/20/2022 17:08:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=672
05/20/2022 17:08:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/20/2022 17:08:25 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.1255656108597285 on epoch=674
05/20/2022 17:08:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.95 on epoch=677
05/20/2022 17:08:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.02 on epoch=679
05/20/2022 17:08:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/20/2022 17:08:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=684
05/20/2022 17:08:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=687
05/20/2022 17:08:33 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.13067758749069247 on epoch=687
05/20/2022 17:08:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.96 on epoch=689
05/20/2022 17:08:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.88 on epoch=692
05/20/2022 17:08:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.03 on epoch=694
05/20/2022 17:08:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.04 on epoch=697
05/20/2022 17:08:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.99 on epoch=699
05/20/2022 17:08:41 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.1468058968058968 on epoch=699
05/20/2022 17:08:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.02 on epoch=702
05/20/2022 17:08:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/20/2022 17:08:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.96 on epoch=707
05/20/2022 17:08:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.91 on epoch=709
05/20/2022 17:08:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
05/20/2022 17:08:48 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.1 on epoch=712
05/20/2022 17:08:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.95 on epoch=714
05/20/2022 17:08:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.05 on epoch=717
05/20/2022 17:08:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/20/2022 17:08:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.92 on epoch=722
05/20/2022 17:08:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/20/2022 17:08:56 - INFO - __main__ - Global step 2900 Train loss 0.96 Classification-F1 0.16795711733174506 on epoch=724
05/20/2022 17:08:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.02 on epoch=727
05/20/2022 17:09:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.92 on epoch=729
05/20/2022 17:09:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.93 on epoch=732
05/20/2022 17:09:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/20/2022 17:09:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.96 on epoch=737
05/20/2022 17:09:05 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.1 on epoch=737
05/20/2022 17:09:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.89 on epoch=739
05/20/2022 17:09:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.92 on epoch=742
05/20/2022 17:09:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.02 on epoch=744
05/20/2022 17:09:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/20/2022 17:09:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.82 on epoch=749
05/20/2022 17:09:13 - INFO - __main__ - Global step 3000 Train loss 0.93 Classification-F1 0.13067758749069247 on epoch=749
05/20/2022 17:09:13 - INFO - __main__ - save last model!
05/20/2022 17:09:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 17:09:13 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 17:09:13 - INFO - __main__ - Printing 3 examples
05/20/2022 17:09:13 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 17:09:13 - INFO - __main__ - ['others']
05/20/2022 17:09:13 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 17:09:13 - INFO - __main__ - ['others']
05/20/2022 17:09:13 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 17:09:13 - INFO - __main__ - ['others']
05/20/2022 17:09:13 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:09:14 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:09:14 - INFO - __main__ - Printing 3 examples
05/20/2022 17:09:14 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 17:09:14 - INFO - __main__ - ['others']
05/20/2022 17:09:14 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 17:09:14 - INFO - __main__ - ['others']
05/20/2022 17:09:14 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 17:09:14 - INFO - __main__ - ['others']
05/20/2022 17:09:14 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:09:14 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:09:14 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:09:14 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:09:14 - INFO - __main__ - Printing 3 examples
05/20/2022 17:09:14 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 17:09:14 - INFO - __main__ - ['others']
05/20/2022 17:09:14 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 17:09:14 - INFO - __main__ - ['others']
05/20/2022 17:09:14 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 17:09:14 - INFO - __main__ - ['others']
05/20/2022 17:09:14 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:09:14 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:09:14 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:09:15 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:09:20 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:09:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:09:20 - INFO - __main__ - Starting training!
05/20/2022 17:09:21 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 17:10:05 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.3_8_predictions.txt
05/20/2022 17:10:05 - INFO - __main__ - Classification-F1 on test data: 0.0343
05/20/2022 17:10:05 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.23552022689953725, test_performance=0.03427363395026725
05/20/2022 17:10:05 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
05/20/2022 17:10:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:10:06 - INFO - __main__ - Printing 3 examples
05/20/2022 17:10:06 - INFO - __main__ -  [emo] how cause yes am listening
05/20/2022 17:10:06 - INFO - __main__ - ['others']
05/20/2022 17:10:06 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/20/2022 17:10:06 - INFO - __main__ - ['others']
05/20/2022 17:10:06 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/20/2022 17:10:06 - INFO - __main__ - ['others']
05/20/2022 17:10:06 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:10:06 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:10:06 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:10:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:10:06 - INFO - __main__ - Printing 3 examples
05/20/2022 17:10:06 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/20/2022 17:10:06 - INFO - __main__ - ['others']
05/20/2022 17:10:06 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/20/2022 17:10:06 - INFO - __main__ - ['others']
05/20/2022 17:10:06 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/20/2022 17:10:06 - INFO - __main__ - ['others']
05/20/2022 17:10:06 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:10:06 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:10:06 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:10:12 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:10:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:10:12 - INFO - __main__ - Starting training!
05/20/2022 17:10:14 - INFO - __main__ - Step 10 Global step 10 Train loss 6.77 on epoch=2
05/20/2022 17:10:15 - INFO - __main__ - Step 20 Global step 20 Train loss 6.71 on epoch=4
05/20/2022 17:10:17 - INFO - __main__ - Step 30 Global step 30 Train loss 6.51 on epoch=7
05/20/2022 17:10:18 - INFO - __main__ - Step 40 Global step 40 Train loss 6.45 on epoch=9
05/20/2022 17:10:19 - INFO - __main__ - Step 50 Global step 50 Train loss 6.20 on epoch=12
05/20/2022 17:10:24 - INFO - __main__ - Global step 50 Train loss 6.53 Classification-F1 0.0 on epoch=12
05/20/2022 17:10:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 17:10:25 - INFO - __main__ - Step 60 Global step 60 Train loss 6.13 on epoch=14
05/20/2022 17:10:27 - INFO - __main__ - Step 70 Global step 70 Train loss 6.18 on epoch=17
05/20/2022 17:10:28 - INFO - __main__ - Step 80 Global step 80 Train loss 6.06 on epoch=19
05/20/2022 17:10:29 - INFO - __main__ - Step 90 Global step 90 Train loss 5.79 on epoch=22
05/20/2022 17:10:31 - INFO - __main__ - Step 100 Global step 100 Train loss 5.63 on epoch=24
05/20/2022 17:10:33 - INFO - __main__ - Global step 100 Train loss 5.96 Classification-F1 0.0 on epoch=24
05/20/2022 17:10:35 - INFO - __main__ - Step 110 Global step 110 Train loss 5.50 on epoch=27
05/20/2022 17:10:36 - INFO - __main__ - Step 120 Global step 120 Train loss 5.51 on epoch=29
05/20/2022 17:10:38 - INFO - __main__ - Step 130 Global step 130 Train loss 5.35 on epoch=32
05/20/2022 17:10:39 - INFO - __main__ - Step 140 Global step 140 Train loss 5.23 on epoch=34
05/20/2022 17:10:40 - INFO - __main__ - Step 150 Global step 150 Train loss 5.16 on epoch=37
05/20/2022 17:10:42 - INFO - __main__ - Global step 150 Train loss 5.35 Classification-F1 0.0 on epoch=37
05/20/2022 17:10:43 - INFO - __main__ - Step 160 Global step 160 Train loss 4.96 on epoch=39
05/20/2022 17:10:44 - INFO - __main__ - Step 170 Global step 170 Train loss 4.82 on epoch=42
05/20/2022 17:10:46 - INFO - __main__ - Step 180 Global step 180 Train loss 4.84 on epoch=44
05/20/2022 17:10:47 - INFO - __main__ - Step 190 Global step 190 Train loss 4.62 on epoch=47
05/20/2022 17:10:49 - INFO - __main__ - Step 200 Global step 200 Train loss 4.73 on epoch=49
05/20/2022 17:10:52 - INFO - __main__ - Global step 200 Train loss 4.79 Classification-F1 0.0 on epoch=49
05/20/2022 17:10:53 - INFO - __main__ - Step 210 Global step 210 Train loss 4.56 on epoch=52
05/20/2022 17:10:55 - INFO - __main__ - Step 220 Global step 220 Train loss 4.47 on epoch=54
05/20/2022 17:10:56 - INFO - __main__ - Step 230 Global step 230 Train loss 4.43 on epoch=57
05/20/2022 17:10:57 - INFO - __main__ - Step 240 Global step 240 Train loss 4.29 on epoch=59
05/20/2022 17:10:59 - INFO - __main__ - Step 250 Global step 250 Train loss 4.30 on epoch=62
05/20/2022 17:10:59 - INFO - __main__ - Global step 250 Train loss 4.41 Classification-F1 0.06111801242236026 on epoch=62
05/20/2022 17:10:59 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06111801242236026 on epoch=62, global_step=250
05/20/2022 17:11:01 - INFO - __main__ - Step 260 Global step 260 Train loss 4.22 on epoch=64
05/20/2022 17:11:02 - INFO - __main__ - Step 270 Global step 270 Train loss 4.17 on epoch=67
05/20/2022 17:11:03 - INFO - __main__ - Step 280 Global step 280 Train loss 4.00 on epoch=69
05/20/2022 17:11:05 - INFO - __main__ - Step 290 Global step 290 Train loss 4.01 on epoch=72
05/20/2022 17:11:06 - INFO - __main__ - Step 300 Global step 300 Train loss 4.05 on epoch=74
05/20/2022 17:11:07 - INFO - __main__ - Global step 300 Train loss 4.09 Classification-F1 0.08206896551724137 on epoch=74
05/20/2022 17:11:07 - INFO - __main__ - Saving model with best Classification-F1: 0.06111801242236026 -> 0.08206896551724137 on epoch=74, global_step=300
05/20/2022 17:11:08 - INFO - __main__ - Step 310 Global step 310 Train loss 3.81 on epoch=77
05/20/2022 17:11:10 - INFO - __main__ - Step 320 Global step 320 Train loss 3.74 on epoch=79
05/20/2022 17:11:11 - INFO - __main__ - Step 330 Global step 330 Train loss 3.89 on epoch=82
05/20/2022 17:11:12 - INFO - __main__ - Step 340 Global step 340 Train loss 3.60 on epoch=84
05/20/2022 17:11:14 - INFO - __main__ - Step 350 Global step 350 Train loss 3.72 on epoch=87
05/20/2022 17:11:14 - INFO - __main__ - Global step 350 Train loss 3.75 Classification-F1 0.1081904761904762 on epoch=87
05/20/2022 17:11:14 - INFO - __main__ - Saving model with best Classification-F1: 0.08206896551724137 -> 0.1081904761904762 on epoch=87, global_step=350
05/20/2022 17:11:16 - INFO - __main__ - Step 360 Global step 360 Train loss 3.51 on epoch=89
05/20/2022 17:11:17 - INFO - __main__ - Step 370 Global step 370 Train loss 3.51 on epoch=92
05/20/2022 17:11:18 - INFO - __main__ - Step 380 Global step 380 Train loss 3.49 on epoch=94
05/20/2022 17:11:20 - INFO - __main__ - Step 390 Global step 390 Train loss 3.69 on epoch=97
05/20/2022 17:11:21 - INFO - __main__ - Step 400 Global step 400 Train loss 3.47 on epoch=99
05/20/2022 17:11:22 - INFO - __main__ - Global step 400 Train loss 3.53 Classification-F1 0.07344632768361581 on epoch=99
05/20/2022 17:11:24 - INFO - __main__ - Step 410 Global step 410 Train loss 3.42 on epoch=102
05/20/2022 17:11:25 - INFO - __main__ - Step 420 Global step 420 Train loss 3.36 on epoch=104
05/20/2022 17:11:26 - INFO - __main__ - Step 430 Global step 430 Train loss 3.29 on epoch=107
05/20/2022 17:11:28 - INFO - __main__ - Step 440 Global step 440 Train loss 2.97 on epoch=109
05/20/2022 17:11:29 - INFO - __main__ - Step 450 Global step 450 Train loss 3.31 on epoch=112
05/20/2022 17:11:30 - INFO - __main__ - Global step 450 Train loss 3.27 Classification-F1 0.05555555555555556 on epoch=112
05/20/2022 17:11:31 - INFO - __main__ - Step 460 Global step 460 Train loss 3.15 on epoch=114
05/20/2022 17:11:32 - INFO - __main__ - Step 470 Global step 470 Train loss 3.19 on epoch=117
05/20/2022 17:11:34 - INFO - __main__ - Step 480 Global step 480 Train loss 3.02 on epoch=119
05/20/2022 17:11:35 - INFO - __main__ - Step 490 Global step 490 Train loss 3.00 on epoch=122
05/20/2022 17:11:36 - INFO - __main__ - Step 500 Global step 500 Train loss 2.94 on epoch=124
05/20/2022 17:11:37 - INFO - __main__ - Global step 500 Train loss 3.06 Classification-F1 0.1 on epoch=124
05/20/2022 17:11:38 - INFO - __main__ - Step 510 Global step 510 Train loss 3.08 on epoch=127
05/20/2022 17:11:40 - INFO - __main__ - Step 520 Global step 520 Train loss 3.01 on epoch=129
05/20/2022 17:11:41 - INFO - __main__ - Step 530 Global step 530 Train loss 2.99 on epoch=132
05/20/2022 17:11:42 - INFO - __main__ - Step 540 Global step 540 Train loss 2.85 on epoch=134
05/20/2022 17:11:43 - INFO - __main__ - Step 550 Global step 550 Train loss 2.99 on epoch=137
05/20/2022 17:11:44 - INFO - __main__ - Global step 550 Train loss 2.98 Classification-F1 0.13026315789473686 on epoch=137
05/20/2022 17:11:44 - INFO - __main__ - Saving model with best Classification-F1: 0.1081904761904762 -> 0.13026315789473686 on epoch=137, global_step=550
05/20/2022 17:11:45 - INFO - __main__ - Step 560 Global step 560 Train loss 2.76 on epoch=139
05/20/2022 17:11:47 - INFO - __main__ - Step 570 Global step 570 Train loss 2.90 on epoch=142
05/20/2022 17:11:48 - INFO - __main__ - Step 580 Global step 580 Train loss 2.78 on epoch=144
05/20/2022 17:11:50 - INFO - __main__ - Step 590 Global step 590 Train loss 2.66 on epoch=147
05/20/2022 17:11:51 - INFO - __main__ - Step 600 Global step 600 Train loss 2.80 on epoch=149
05/20/2022 17:11:51 - INFO - __main__ - Global step 600 Train loss 2.78 Classification-F1 0.1 on epoch=149
05/20/2022 17:11:53 - INFO - __main__ - Step 610 Global step 610 Train loss 2.74 on epoch=152
05/20/2022 17:11:54 - INFO - __main__ - Step 620 Global step 620 Train loss 2.49 on epoch=154
05/20/2022 17:11:55 - INFO - __main__ - Step 630 Global step 630 Train loss 2.53 on epoch=157
05/20/2022 17:11:57 - INFO - __main__ - Step 640 Global step 640 Train loss 2.58 on epoch=159
05/20/2022 17:11:58 - INFO - __main__ - Step 650 Global step 650 Train loss 2.59 on epoch=162
05/20/2022 17:11:58 - INFO - __main__ - Global step 650 Train loss 2.59 Classification-F1 0.13034188034188032 on epoch=162
05/20/2022 17:11:59 - INFO - __main__ - Saving model with best Classification-F1: 0.13026315789473686 -> 0.13034188034188032 on epoch=162, global_step=650
05/20/2022 17:12:00 - INFO - __main__ - Step 660 Global step 660 Train loss 2.47 on epoch=164
05/20/2022 17:12:01 - INFO - __main__ - Step 670 Global step 670 Train loss 2.79 on epoch=167
05/20/2022 17:12:03 - INFO - __main__ - Step 680 Global step 680 Train loss 2.38 on epoch=169
05/20/2022 17:12:04 - INFO - __main__ - Step 690 Global step 690 Train loss 2.66 on epoch=172
05/20/2022 17:12:05 - INFO - __main__ - Step 700 Global step 700 Train loss 2.45 on epoch=174
05/20/2022 17:12:06 - INFO - __main__ - Global step 700 Train loss 2.55 Classification-F1 0.1 on epoch=174
05/20/2022 17:12:07 - INFO - __main__ - Step 710 Global step 710 Train loss 2.56 on epoch=177
05/20/2022 17:12:09 - INFO - __main__ - Step 720 Global step 720 Train loss 2.49 on epoch=179
05/20/2022 17:12:10 - INFO - __main__ - Step 730 Global step 730 Train loss 2.46 on epoch=182
05/20/2022 17:12:11 - INFO - __main__ - Step 740 Global step 740 Train loss 2.25 on epoch=184
05/20/2022 17:12:13 - INFO - __main__ - Step 750 Global step 750 Train loss 2.37 on epoch=187
05/20/2022 17:12:13 - INFO - __main__ - Global step 750 Train loss 2.43 Classification-F1 0.10256410256410256 on epoch=187
05/20/2022 17:12:14 - INFO - __main__ - Step 760 Global step 760 Train loss 2.43 on epoch=189
05/20/2022 17:12:16 - INFO - __main__ - Step 770 Global step 770 Train loss 2.34 on epoch=192
05/20/2022 17:12:17 - INFO - __main__ - Step 780 Global step 780 Train loss 2.30 on epoch=194
05/20/2022 17:12:18 - INFO - __main__ - Step 790 Global step 790 Train loss 2.35 on epoch=197
05/20/2022 17:12:19 - INFO - __main__ - Step 800 Global step 800 Train loss 2.28 on epoch=199
05/20/2022 17:12:20 - INFO - __main__ - Global step 800 Train loss 2.34 Classification-F1 0.16695652173913045 on epoch=199
05/20/2022 17:12:20 - INFO - __main__ - Saving model with best Classification-F1: 0.13034188034188032 -> 0.16695652173913045 on epoch=199, global_step=800
05/20/2022 17:12:21 - INFO - __main__ - Step 810 Global step 810 Train loss 2.09 on epoch=202
05/20/2022 17:12:23 - INFO - __main__ - Step 820 Global step 820 Train loss 2.19 on epoch=204
05/20/2022 17:12:24 - INFO - __main__ - Step 830 Global step 830 Train loss 2.27 on epoch=207
05/20/2022 17:12:25 - INFO - __main__ - Step 840 Global step 840 Train loss 2.23 on epoch=209
05/20/2022 17:12:27 - INFO - __main__ - Step 850 Global step 850 Train loss 2.28 on epoch=212
05/20/2022 17:12:27 - INFO - __main__ - Global step 850 Train loss 2.21 Classification-F1 0.15339578454332553 on epoch=212
05/20/2022 17:12:28 - INFO - __main__ - Step 860 Global step 860 Train loss 2.08 on epoch=214
05/20/2022 17:12:30 - INFO - __main__ - Step 870 Global step 870 Train loss 2.21 on epoch=217
05/20/2022 17:12:31 - INFO - __main__ - Step 880 Global step 880 Train loss 2.05 on epoch=219
05/20/2022 17:12:33 - INFO - __main__ - Step 890 Global step 890 Train loss 2.09 on epoch=222
05/20/2022 17:12:34 - INFO - __main__ - Step 900 Global step 900 Train loss 2.08 on epoch=224
05/20/2022 17:12:35 - INFO - __main__ - Global step 900 Train loss 2.10 Classification-F1 0.18623481781376516 on epoch=224
05/20/2022 17:12:35 - INFO - __main__ - Saving model with best Classification-F1: 0.16695652173913045 -> 0.18623481781376516 on epoch=224, global_step=900
05/20/2022 17:12:36 - INFO - __main__ - Step 910 Global step 910 Train loss 2.09 on epoch=227
05/20/2022 17:12:37 - INFO - __main__ - Step 920 Global step 920 Train loss 2.04 on epoch=229
05/20/2022 17:12:38 - INFO - __main__ - Step 930 Global step 930 Train loss 2.14 on epoch=232
05/20/2022 17:12:40 - INFO - __main__ - Step 940 Global step 940 Train loss 2.06 on epoch=234
05/20/2022 17:12:41 - INFO - __main__ - Step 950 Global step 950 Train loss 2.12 on epoch=237
05/20/2022 17:12:42 - INFO - __main__ - Global step 950 Train loss 2.09 Classification-F1 0.217858709960509 on epoch=237
05/20/2022 17:12:42 - INFO - __main__ - Saving model with best Classification-F1: 0.18623481781376516 -> 0.217858709960509 on epoch=237, global_step=950
05/20/2022 17:12:43 - INFO - __main__ - Step 960 Global step 960 Train loss 2.09 on epoch=239
05/20/2022 17:12:45 - INFO - __main__ - Step 970 Global step 970 Train loss 2.11 on epoch=242
05/20/2022 17:12:46 - INFO - __main__ - Step 980 Global step 980 Train loss 1.91 on epoch=244
05/20/2022 17:12:47 - INFO - __main__ - Step 990 Global step 990 Train loss 1.83 on epoch=247
05/20/2022 17:12:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.96 on epoch=249
05/20/2022 17:12:49 - INFO - __main__ - Global step 1000 Train loss 1.98 Classification-F1 0.16464237516869096 on epoch=249
05/20/2022 17:12:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.83 on epoch=252
05/20/2022 17:12:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.84 on epoch=254
05/20/2022 17:12:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.93 on epoch=257
05/20/2022 17:12:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.88 on epoch=259
05/20/2022 17:12:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.82 on epoch=262
05/20/2022 17:12:56 - INFO - __main__ - Global step 1050 Train loss 1.86 Classification-F1 0.17267605633802818 on epoch=262
05/20/2022 17:12:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.73 on epoch=264
05/20/2022 17:12:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.95 on epoch=267
05/20/2022 17:13:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.77 on epoch=269
05/20/2022 17:13:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.94 on epoch=272
05/20/2022 17:13:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.71 on epoch=274
05/20/2022 17:13:03 - INFO - __main__ - Global step 1100 Train loss 1.82 Classification-F1 0.13225806451612904 on epoch=274
05/20/2022 17:13:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.81 on epoch=277
05/20/2022 17:13:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.78 on epoch=279
05/20/2022 17:13:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.88 on epoch=282
05/20/2022 17:13:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.72 on epoch=284
05/20/2022 17:13:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.72 on epoch=287
05/20/2022 17:13:10 - INFO - __main__ - Global step 1150 Train loss 1.78 Classification-F1 0.1302118933697881 on epoch=287
05/20/2022 17:13:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.51 on epoch=289
05/20/2022 17:13:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.64 on epoch=292
05/20/2022 17:13:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.47 on epoch=294
05/20/2022 17:13:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.58 on epoch=297
05/20/2022 17:13:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.59 on epoch=299
05/20/2022 17:13:18 - INFO - __main__ - Global step 1200 Train loss 1.56 Classification-F1 0.2000907441016334 on epoch=299
05/20/2022 17:13:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.82 on epoch=302
05/20/2022 17:13:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.66 on epoch=304
05/20/2022 17:13:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.63 on epoch=307
05/20/2022 17:13:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.68 on epoch=309
05/20/2022 17:13:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.52 on epoch=312
05/20/2022 17:13:25 - INFO - __main__ - Global step 1250 Train loss 1.66 Classification-F1 0.171875 on epoch=312
05/20/2022 17:13:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.49 on epoch=314
05/20/2022 17:13:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.57 on epoch=317
05/20/2022 17:13:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.51 on epoch=319
05/20/2022 17:13:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.58 on epoch=322
05/20/2022 17:13:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.52 on epoch=324
05/20/2022 17:13:32 - INFO - __main__ - Global step 1300 Train loss 1.53 Classification-F1 0.1523109243697479 on epoch=324
05/20/2022 17:13:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.57 on epoch=327
05/20/2022 17:13:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.65 on epoch=329
05/20/2022 17:13:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.43 on epoch=332
05/20/2022 17:13:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.51 on epoch=334
05/20/2022 17:13:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.48 on epoch=337
05/20/2022 17:13:40 - INFO - __main__ - Global step 1350 Train loss 1.53 Classification-F1 0.17377495462794917 on epoch=337
05/20/2022 17:13:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.37 on epoch=339
05/20/2022 17:13:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.53 on epoch=342
05/20/2022 17:13:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.43 on epoch=344
05/20/2022 17:13:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.54 on epoch=347
05/20/2022 17:13:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.38 on epoch=349
05/20/2022 17:13:47 - INFO - __main__ - Global step 1400 Train loss 1.45 Classification-F1 0.16078790655061842 on epoch=349
05/20/2022 17:13:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.35 on epoch=352
05/20/2022 17:13:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.42 on epoch=354
05/20/2022 17:13:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.43 on epoch=357
05/20/2022 17:13:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.29 on epoch=359
05/20/2022 17:13:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.38 on epoch=362
05/20/2022 17:13:54 - INFO - __main__ - Global step 1450 Train loss 1.37 Classification-F1 0.14563380281690141 on epoch=362
05/20/2022 17:13:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.26 on epoch=364
05/20/2022 17:13:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.50 on epoch=367
05/20/2022 17:13:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.39 on epoch=369
05/20/2022 17:14:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.51 on epoch=372
05/20/2022 17:14:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.28 on epoch=374
05/20/2022 17:14:02 - INFO - __main__ - Global step 1500 Train loss 1.39 Classification-F1 0.1 on epoch=374
05/20/2022 17:14:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.45 on epoch=377
05/20/2022 17:14:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.44 on epoch=379
05/20/2022 17:14:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.49 on epoch=382
05/20/2022 17:14:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.33 on epoch=384
05/20/2022 17:14:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
05/20/2022 17:14:09 - INFO - __main__ - Global step 1550 Train loss 1.42 Classification-F1 0.1869328493647913 on epoch=387
05/20/2022 17:14:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.44 on epoch=389
05/20/2022 17:14:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.37 on epoch=392
05/20/2022 17:14:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.29 on epoch=394
05/20/2022 17:14:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.29 on epoch=397
05/20/2022 17:14:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.32 on epoch=399
05/20/2022 17:14:16 - INFO - __main__ - Global step 1600 Train loss 1.34 Classification-F1 0.1 on epoch=399
05/20/2022 17:14:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.35 on epoch=402
05/20/2022 17:14:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.22 on epoch=404
05/20/2022 17:14:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.30 on epoch=407
05/20/2022 17:14:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.38 on epoch=409
05/20/2022 17:14:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.35 on epoch=412
05/20/2022 17:14:24 - INFO - __main__ - Global step 1650 Train loss 1.32 Classification-F1 0.1875814155449414 on epoch=412
05/20/2022 17:14:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.33 on epoch=414
05/20/2022 17:14:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.32 on epoch=417
05/20/2022 17:14:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.32 on epoch=419
05/20/2022 17:14:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.19 on epoch=422
05/20/2022 17:14:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.16 on epoch=424
05/20/2022 17:14:31 - INFO - __main__ - Global step 1700 Train loss 1.26 Classification-F1 0.12403499742665978 on epoch=424
05/20/2022 17:14:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.15 on epoch=427
05/20/2022 17:14:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.15 on epoch=429
05/20/2022 17:14:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.23 on epoch=432
05/20/2022 17:14:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.24 on epoch=434
05/20/2022 17:14:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=437
05/20/2022 17:14:39 - INFO - __main__ - Global step 1750 Train loss 1.20 Classification-F1 0.10126582278481013 on epoch=437
05/20/2022 17:14:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.22 on epoch=439
05/20/2022 17:14:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.36 on epoch=442
05/20/2022 17:14:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.37 on epoch=444
05/20/2022 17:14:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.29 on epoch=447
05/20/2022 17:14:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.21 on epoch=449
05/20/2022 17:14:46 - INFO - __main__ - Global step 1800 Train loss 1.29 Classification-F1 0.1 on epoch=449
05/20/2022 17:14:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.29 on epoch=452
05/20/2022 17:14:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.14 on epoch=454
05/20/2022 17:14:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.25 on epoch=457
05/20/2022 17:14:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.14 on epoch=459
05/20/2022 17:14:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.19 on epoch=462
05/20/2022 17:14:54 - INFO - __main__ - Global step 1850 Train loss 1.20 Classification-F1 0.11762954139368673 on epoch=462
05/20/2022 17:14:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.22 on epoch=464
05/20/2022 17:14:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.24 on epoch=467
05/20/2022 17:14:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.25 on epoch=469
05/20/2022 17:14:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.26 on epoch=472
05/20/2022 17:15:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.21 on epoch=474
05/20/2022 17:15:01 - INFO - __main__ - Global step 1900 Train loss 1.24 Classification-F1 0.16608695652173913 on epoch=474
05/20/2022 17:15:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.29 on epoch=477
05/20/2022 17:15:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.27 on epoch=479
05/20/2022 17:15:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.23 on epoch=482
05/20/2022 17:15:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.12 on epoch=484
05/20/2022 17:15:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.26 on epoch=487
05/20/2022 17:15:09 - INFO - __main__ - Global step 1950 Train loss 1.23 Classification-F1 0.1 on epoch=487
05/20/2022 17:15:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.24 on epoch=489
05/20/2022 17:15:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.30 on epoch=492
05/20/2022 17:15:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.18 on epoch=494
05/20/2022 17:15:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.30 on epoch=497
05/20/2022 17:15:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.17 on epoch=499
05/20/2022 17:15:16 - INFO - __main__ - Global step 2000 Train loss 1.24 Classification-F1 0.17809523809523808 on epoch=499
05/20/2022 17:15:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.20 on epoch=502
05/20/2022 17:15:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.09 on epoch=504
05/20/2022 17:15:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.19 on epoch=507
05/20/2022 17:15:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.22 on epoch=509
05/20/2022 17:15:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.24 on epoch=512
05/20/2022 17:15:23 - INFO - __main__ - Global step 2050 Train loss 1.19 Classification-F1 0.17573497147871872 on epoch=512
05/20/2022 17:15:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.19 on epoch=514
05/20/2022 17:15:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.25 on epoch=517
05/20/2022 17:15:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.13 on epoch=519
05/20/2022 17:15:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.23 on epoch=522
05/20/2022 17:15:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.16 on epoch=524
05/20/2022 17:15:31 - INFO - __main__ - Global step 2100 Train loss 1.19 Classification-F1 0.1 on epoch=524
05/20/2022 17:15:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.17 on epoch=527
05/20/2022 17:15:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.24 on epoch=529
05/20/2022 17:15:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.18 on epoch=532
05/20/2022 17:15:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.17 on epoch=534
05/20/2022 17:15:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.16 on epoch=537
05/20/2022 17:15:38 - INFO - __main__ - Global step 2150 Train loss 1.18 Classification-F1 0.12393162393162392 on epoch=537
05/20/2022 17:15:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.19 on epoch=539
05/20/2022 17:15:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.16 on epoch=542
05/20/2022 17:15:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.21 on epoch=544
05/20/2022 17:15:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.20 on epoch=547
05/20/2022 17:15:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.20 on epoch=549
05/20/2022 17:15:45 - INFO - __main__ - Global step 2200 Train loss 1.19 Classification-F1 0.1 on epoch=549
05/20/2022 17:15:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.08 on epoch=552
05/20/2022 17:15:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.09 on epoch=554
05/20/2022 17:15:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.23 on epoch=557
05/20/2022 17:15:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.01 on epoch=559
05/20/2022 17:15:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.08 on epoch=562
05/20/2022 17:15:53 - INFO - __main__ - Global step 2250 Train loss 1.10 Classification-F1 0.1 on epoch=562
05/20/2022 17:15:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.08 on epoch=564
05/20/2022 17:15:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.15 on epoch=567
05/20/2022 17:15:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.11 on epoch=569
05/20/2022 17:15:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.15 on epoch=572
05/20/2022 17:16:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.24 on epoch=574
05/20/2022 17:16:00 - INFO - __main__ - Global step 2300 Train loss 1.15 Classification-F1 0.13067758749069247 on epoch=574
05/20/2022 17:16:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.27 on epoch=577
05/20/2022 17:16:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
05/20/2022 17:16:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.20 on epoch=582
05/20/2022 17:16:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.13 on epoch=584
05/20/2022 17:16:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.16 on epoch=587
05/20/2022 17:16:08 - INFO - __main__ - Global step 2350 Train loss 1.18 Classification-F1 0.1283068783068783 on epoch=587
05/20/2022 17:16:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.12 on epoch=589
05/20/2022 17:16:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.10 on epoch=592
05/20/2022 17:16:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
05/20/2022 17:16:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
05/20/2022 17:16:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.14 on epoch=599
05/20/2022 17:16:16 - INFO - __main__ - Global step 2400 Train loss 1.10 Classification-F1 0.14450704225352112 on epoch=599
05/20/2022 17:16:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.30 on epoch=602
05/20/2022 17:16:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.12 on epoch=604
05/20/2022 17:16:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.10 on epoch=607
05/20/2022 17:16:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
05/20/2022 17:16:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.10 on epoch=612
05/20/2022 17:16:23 - INFO - __main__ - Global step 2450 Train loss 1.12 Classification-F1 0.09493670886075949 on epoch=612
05/20/2022 17:16:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.24 on epoch=614
05/20/2022 17:16:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.10 on epoch=617
05/20/2022 17:16:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.05 on epoch=619
05/20/2022 17:16:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
05/20/2022 17:16:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.20 on epoch=624
05/20/2022 17:16:31 - INFO - __main__ - Global step 2500 Train loss 1.12 Classification-F1 0.1 on epoch=624
05/20/2022 17:16:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.15 on epoch=627
05/20/2022 17:16:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
05/20/2022 17:16:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.17 on epoch=632
05/20/2022 17:16:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.07 on epoch=634
05/20/2022 17:16:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.08 on epoch=637
05/20/2022 17:16:39 - INFO - __main__ - Global step 2550 Train loss 1.11 Classification-F1 0.1 on epoch=637
05/20/2022 17:16:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.03 on epoch=639
05/20/2022 17:16:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.05 on epoch=642
05/20/2022 17:16:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.11 on epoch=644
05/20/2022 17:16:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.07 on epoch=647
05/20/2022 17:16:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.07 on epoch=649
05/20/2022 17:16:46 - INFO - __main__ - Global step 2600 Train loss 1.07 Classification-F1 0.1 on epoch=649
05/20/2022 17:16:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/20/2022 17:16:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.15 on epoch=654
05/20/2022 17:16:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.04 on epoch=657
05/20/2022 17:16:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.18 on epoch=659
05/20/2022 17:16:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.12 on epoch=662
05/20/2022 17:16:53 - INFO - __main__ - Global step 2650 Train loss 1.09 Classification-F1 0.1434065934065934 on epoch=662
05/20/2022 17:16:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.05 on epoch=664
05/20/2022 17:16:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.04 on epoch=667
05/20/2022 17:16:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.06 on epoch=669
05/20/2022 17:16:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/20/2022 17:17:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.07 on epoch=674
05/20/2022 17:17:01 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.16515151515151516 on epoch=674
05/20/2022 17:17:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.07 on epoch=677
05/20/2022 17:17:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
05/20/2022 17:17:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.09 on epoch=682
05/20/2022 17:17:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.01 on epoch=684
05/20/2022 17:17:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.11 on epoch=687
05/20/2022 17:17:08 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.18679549114331723 on epoch=687
05/20/2022 17:17:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.16 on epoch=689
05/20/2022 17:17:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.09 on epoch=692
05/20/2022 17:17:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/20/2022 17:17:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
05/20/2022 17:17:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.08 on epoch=699
05/20/2022 17:17:16 - INFO - __main__ - Global step 2800 Train loss 1.05 Classification-F1 0.14180672268907563 on epoch=699
05/20/2022 17:17:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
05/20/2022 17:17:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.19 on epoch=704
05/20/2022 17:17:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.05 on epoch=707
05/20/2022 17:17:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/20/2022 17:17:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
05/20/2022 17:17:24 - INFO - __main__ - Global step 2850 Train loss 1.07 Classification-F1 0.10526315789473685 on epoch=712
05/20/2022 17:17:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.93 on epoch=714
05/20/2022 17:17:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.14 on epoch=717
05/20/2022 17:17:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.20 on epoch=719
05/20/2022 17:17:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.11 on epoch=722
05/20/2022 17:17:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.21 on epoch=724
05/20/2022 17:17:31 - INFO - __main__ - Global step 2900 Train loss 1.12 Classification-F1 0.14509803921568626 on epoch=724
05/20/2022 17:17:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.06 on epoch=727
05/20/2022 17:17:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.13 on epoch=729
05/20/2022 17:17:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.96 on epoch=732
05/20/2022 17:17:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.05 on epoch=734
05/20/2022 17:17:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.99 on epoch=737
05/20/2022 17:17:39 - INFO - __main__ - Global step 2950 Train loss 1.04 Classification-F1 0.1517857142857143 on epoch=737
05/20/2022 17:17:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/20/2022 17:17:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.09 on epoch=742
05/20/2022 17:17:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.15 on epoch=744
05/20/2022 17:17:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.03 on epoch=747
05/20/2022 17:17:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.00 on epoch=749
05/20/2022 17:17:46 - INFO - __main__ - Global step 3000 Train loss 1.05 Classification-F1 0.13034188034188032 on epoch=749
05/20/2022 17:17:46 - INFO - __main__ - save last model!
05/20/2022 17:17:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 17:17:46 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 17:17:46 - INFO - __main__ - Printing 3 examples
05/20/2022 17:17:46 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 17:17:46 - INFO - __main__ - ['others']
05/20/2022 17:17:46 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 17:17:46 - INFO - __main__ - ['others']
05/20/2022 17:17:46 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 17:17:46 - INFO - __main__ - ['others']
05/20/2022 17:17:46 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:17:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:17:47 - INFO - __main__ - Printing 3 examples
05/20/2022 17:17:47 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:17:47 - INFO - __main__ - ['others']
05/20/2022 17:17:47 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:17:47 - INFO - __main__ - ['others']
05/20/2022 17:17:47 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:17:47 - INFO - __main__ - ['others']
05/20/2022 17:17:47 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:17:47 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:17:47 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:17:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:17:47 - INFO - __main__ - Printing 3 examples
05/20/2022 17:17:47 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:17:47 - INFO - __main__ - ['others']
05/20/2022 17:17:47 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:17:47 - INFO - __main__ - ['others']
05/20/2022 17:17:47 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:17:47 - INFO - __main__ - ['others']
05/20/2022 17:17:47 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:17:47 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:17:47 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:17:48 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:17:53 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:17:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:17:54 - INFO - __main__ - Starting training!
05/20/2022 17:17:54 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 17:18:36 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.2_8_predictions.txt
05/20/2022 17:18:36 - INFO - __main__ - Classification-F1 on test data: 0.0339
05/20/2022 17:18:36 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.217858709960509, test_performance=0.03393767675257918
05/20/2022 17:18:36 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
05/20/2022 17:18:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:18:37 - INFO - __main__ - Printing 3 examples
05/20/2022 17:18:37 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:18:37 - INFO - __main__ - ['others']
05/20/2022 17:18:37 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:18:37 - INFO - __main__ - ['others']
05/20/2022 17:18:37 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:18:37 - INFO - __main__ - ['others']
05/20/2022 17:18:37 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:18:37 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:18:38 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:18:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:18:38 - INFO - __main__ - Printing 3 examples
05/20/2022 17:18:38 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:18:38 - INFO - __main__ - ['others']
05/20/2022 17:18:38 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:18:38 - INFO - __main__ - ['others']
05/20/2022 17:18:38 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:18:38 - INFO - __main__ - ['others']
05/20/2022 17:18:38 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:18:38 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:18:38 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:18:43 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:18:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:18:44 - INFO - __main__ - Starting training!
05/20/2022 17:18:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.71 on epoch=2
05/20/2022 17:18:47 - INFO - __main__ - Step 20 Global step 20 Train loss 6.49 on epoch=4
05/20/2022 17:18:49 - INFO - __main__ - Step 30 Global step 30 Train loss 5.99 on epoch=7
05/20/2022 17:18:50 - INFO - __main__ - Step 40 Global step 40 Train loss 5.80 on epoch=9
05/20/2022 17:18:51 - INFO - __main__ - Step 50 Global step 50 Train loss 5.51 on epoch=12
05/20/2022 17:18:54 - INFO - __main__ - Global step 50 Train loss 6.10 Classification-F1 0.0 on epoch=12
05/20/2022 17:18:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 17:18:56 - INFO - __main__ - Step 60 Global step 60 Train loss 5.18 on epoch=14
05/20/2022 17:18:57 - INFO - __main__ - Step 70 Global step 70 Train loss 5.09 on epoch=17
05/20/2022 17:18:58 - INFO - __main__ - Step 80 Global step 80 Train loss 4.72 on epoch=19
05/20/2022 17:19:00 - INFO - __main__ - Step 90 Global step 90 Train loss 4.43 on epoch=22
05/20/2022 17:19:01 - INFO - __main__ - Step 100 Global step 100 Train loss 4.13 on epoch=24
05/20/2022 17:19:02 - INFO - __main__ - Global step 100 Train loss 4.71 Classification-F1 0.17584541062801934 on epoch=24
05/20/2022 17:19:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.17584541062801934 on epoch=24, global_step=100
05/20/2022 17:19:03 - INFO - __main__ - Step 110 Global step 110 Train loss 3.87 on epoch=27
05/20/2022 17:19:04 - INFO - __main__ - Step 120 Global step 120 Train loss 3.74 on epoch=29
05/20/2022 17:19:06 - INFO - __main__ - Step 130 Global step 130 Train loss 3.86 on epoch=32
05/20/2022 17:19:07 - INFO - __main__ - Step 140 Global step 140 Train loss 3.44 on epoch=34
05/20/2022 17:19:09 - INFO - __main__ - Step 150 Global step 150 Train loss 3.45 on epoch=37
05/20/2022 17:19:09 - INFO - __main__ - Global step 150 Train loss 3.67 Classification-F1 0.10404761904761906 on epoch=37
05/20/2022 17:19:11 - INFO - __main__ - Step 160 Global step 160 Train loss 3.24 on epoch=39
05/20/2022 17:19:12 - INFO - __main__ - Step 170 Global step 170 Train loss 3.20 on epoch=42
05/20/2022 17:19:13 - INFO - __main__ - Step 180 Global step 180 Train loss 3.09 on epoch=44
05/20/2022 17:19:15 - INFO - __main__ - Step 190 Global step 190 Train loss 3.04 on epoch=47
05/20/2022 17:19:16 - INFO - __main__ - Step 200 Global step 200 Train loss 2.95 on epoch=49
05/20/2022 17:19:16 - INFO - __main__ - Global step 200 Train loss 3.10 Classification-F1 0.08450704225352113 on epoch=49
05/20/2022 17:19:18 - INFO - __main__ - Step 210 Global step 210 Train loss 2.72 on epoch=52
05/20/2022 17:19:19 - INFO - __main__ - Step 220 Global step 220 Train loss 2.76 on epoch=54
05/20/2022 17:19:20 - INFO - __main__ - Step 230 Global step 230 Train loss 2.73 on epoch=57
05/20/2022 17:19:22 - INFO - __main__ - Step 240 Global step 240 Train loss 2.40 on epoch=59
05/20/2022 17:19:23 - INFO - __main__ - Step 250 Global step 250 Train loss 2.52 on epoch=62
05/20/2022 17:19:24 - INFO - __main__ - Global step 250 Train loss 2.63 Classification-F1 0.12368421052631579 on epoch=62
05/20/2022 17:19:25 - INFO - __main__ - Step 260 Global step 260 Train loss 2.59 on epoch=64
05/20/2022 17:19:27 - INFO - __main__ - Step 270 Global step 270 Train loss 2.39 on epoch=67
05/20/2022 17:19:28 - INFO - __main__ - Step 280 Global step 280 Train loss 2.14 on epoch=69
05/20/2022 17:19:30 - INFO - __main__ - Step 290 Global step 290 Train loss 2.26 on epoch=72
05/20/2022 17:19:31 - INFO - __main__ - Step 300 Global step 300 Train loss 2.05 on epoch=74
05/20/2022 17:19:32 - INFO - __main__ - Global step 300 Train loss 2.29 Classification-F1 0.1970899470899471 on epoch=74
05/20/2022 17:19:32 - INFO - __main__ - Saving model with best Classification-F1: 0.17584541062801934 -> 0.1970899470899471 on epoch=74, global_step=300
05/20/2022 17:19:33 - INFO - __main__ - Step 310 Global step 310 Train loss 2.12 on epoch=77
05/20/2022 17:19:35 - INFO - __main__ - Step 320 Global step 320 Train loss 2.14 on epoch=79
05/20/2022 17:19:36 - INFO - __main__ - Step 330 Global step 330 Train loss 1.99 on epoch=82
05/20/2022 17:19:37 - INFO - __main__ - Step 340 Global step 340 Train loss 1.88 on epoch=84
05/20/2022 17:19:39 - INFO - __main__ - Step 350 Global step 350 Train loss 1.90 on epoch=87
05/20/2022 17:19:39 - INFO - __main__ - Global step 350 Train loss 2.01 Classification-F1 0.18029871977240397 on epoch=87
05/20/2022 17:19:41 - INFO - __main__ - Step 360 Global step 360 Train loss 1.86 on epoch=89
05/20/2022 17:19:42 - INFO - __main__ - Step 370 Global step 370 Train loss 1.88 on epoch=92
05/20/2022 17:19:43 - INFO - __main__ - Step 380 Global step 380 Train loss 1.65 on epoch=94
05/20/2022 17:19:45 - INFO - __main__ - Step 390 Global step 390 Train loss 1.78 on epoch=97
05/20/2022 17:19:46 - INFO - __main__ - Step 400 Global step 400 Train loss 1.59 on epoch=99
05/20/2022 17:19:47 - INFO - __main__ - Global step 400 Train loss 1.75 Classification-F1 0.19542483660130716 on epoch=99
05/20/2022 17:19:48 - INFO - __main__ - Step 410 Global step 410 Train loss 1.66 on epoch=102
05/20/2022 17:19:49 - INFO - __main__ - Step 420 Global step 420 Train loss 1.70 on epoch=104
05/20/2022 17:19:51 - INFO - __main__ - Step 430 Global step 430 Train loss 1.73 on epoch=107
05/20/2022 17:19:52 - INFO - __main__ - Step 440 Global step 440 Train loss 1.54 on epoch=109
05/20/2022 17:19:53 - INFO - __main__ - Step 450 Global step 450 Train loss 1.57 on epoch=112
05/20/2022 17:19:54 - INFO - __main__ - Global step 450 Train loss 1.64 Classification-F1 0.142512077294686 on epoch=112
05/20/2022 17:19:56 - INFO - __main__ - Step 460 Global step 460 Train loss 1.51 on epoch=114
05/20/2022 17:19:57 - INFO - __main__ - Step 470 Global step 470 Train loss 1.51 on epoch=117
05/20/2022 17:19:58 - INFO - __main__ - Step 480 Global step 480 Train loss 1.43 on epoch=119
05/20/2022 17:20:00 - INFO - __main__ - Step 490 Global step 490 Train loss 1.36 on epoch=122
05/20/2022 17:20:01 - INFO - __main__ - Step 500 Global step 500 Train loss 1.47 on epoch=124
05/20/2022 17:20:01 - INFO - __main__ - Global step 500 Train loss 1.46 Classification-F1 0.1853146853146853 on epoch=124
05/20/2022 17:20:03 - INFO - __main__ - Step 510 Global step 510 Train loss 1.45 on epoch=127
05/20/2022 17:20:04 - INFO - __main__ - Step 520 Global step 520 Train loss 1.32 on epoch=129
05/20/2022 17:20:05 - INFO - __main__ - Step 530 Global step 530 Train loss 1.29 on epoch=132
05/20/2022 17:20:07 - INFO - __main__ - Step 540 Global step 540 Train loss 1.39 on epoch=134
05/20/2022 17:20:08 - INFO - __main__ - Step 550 Global step 550 Train loss 1.34 on epoch=137
05/20/2022 17:20:09 - INFO - __main__ - Global step 550 Train loss 1.36 Classification-F1 0.1576923076923077 on epoch=137
05/20/2022 17:20:10 - INFO - __main__ - Step 560 Global step 560 Train loss 1.32 on epoch=139
05/20/2022 17:20:11 - INFO - __main__ - Step 570 Global step 570 Train loss 1.41 on epoch=142
05/20/2022 17:20:13 - INFO - __main__ - Step 580 Global step 580 Train loss 1.25 on epoch=144
05/20/2022 17:20:14 - INFO - __main__ - Step 590 Global step 590 Train loss 1.30 on epoch=147
05/20/2022 17:20:15 - INFO - __main__ - Step 600 Global step 600 Train loss 1.22 on epoch=149
05/20/2022 17:20:16 - INFO - __main__ - Global step 600 Train loss 1.30 Classification-F1 0.09868421052631579 on epoch=149
05/20/2022 17:20:17 - INFO - __main__ - Step 610 Global step 610 Train loss 1.28 on epoch=152
05/20/2022 17:20:19 - INFO - __main__ - Step 620 Global step 620 Train loss 1.29 on epoch=154
05/20/2022 17:20:20 - INFO - __main__ - Step 630 Global step 630 Train loss 1.31 on epoch=157
05/20/2022 17:20:22 - INFO - __main__ - Step 640 Global step 640 Train loss 1.30 on epoch=159
05/20/2022 17:20:23 - INFO - __main__ - Step 650 Global step 650 Train loss 1.17 on epoch=162
05/20/2022 17:20:24 - INFO - __main__ - Global step 650 Train loss 1.27 Classification-F1 0.1 on epoch=162
05/20/2022 17:20:25 - INFO - __main__ - Step 660 Global step 660 Train loss 1.20 on epoch=164
05/20/2022 17:20:26 - INFO - __main__ - Step 670 Global step 670 Train loss 1.21 on epoch=167
05/20/2022 17:20:28 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=169
05/20/2022 17:20:29 - INFO - __main__ - Step 690 Global step 690 Train loss 1.23 on epoch=172
05/20/2022 17:20:30 - INFO - __main__ - Step 700 Global step 700 Train loss 1.21 on epoch=174
05/20/2022 17:20:31 - INFO - __main__ - Global step 700 Train loss 1.22 Classification-F1 0.15682382133995038 on epoch=174
05/20/2022 17:20:32 - INFO - __main__ - Step 710 Global step 710 Train loss 1.24 on epoch=177
05/20/2022 17:20:34 - INFO - __main__ - Step 720 Global step 720 Train loss 1.23 on epoch=179
05/20/2022 17:20:35 - INFO - __main__ - Step 730 Global step 730 Train loss 1.17 on epoch=182
05/20/2022 17:20:36 - INFO - __main__ - Step 740 Global step 740 Train loss 1.28 on epoch=184
05/20/2022 17:20:37 - INFO - __main__ - Step 750 Global step 750 Train loss 1.14 on epoch=187
05/20/2022 17:20:38 - INFO - __main__ - Global step 750 Train loss 1.21 Classification-F1 0.20277777777777778 on epoch=187
05/20/2022 17:20:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1970899470899471 -> 0.20277777777777778 on epoch=187, global_step=750
05/20/2022 17:20:39 - INFO - __main__ - Step 760 Global step 760 Train loss 1.15 on epoch=189
05/20/2022 17:20:41 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=192
05/20/2022 17:20:42 - INFO - __main__ - Step 780 Global step 780 Train loss 1.19 on epoch=194
05/20/2022 17:20:43 - INFO - __main__ - Step 790 Global step 790 Train loss 1.11 on epoch=197
05/20/2022 17:20:45 - INFO - __main__ - Step 800 Global step 800 Train loss 1.29 on epoch=199
05/20/2022 17:20:45 - INFO - __main__ - Global step 800 Train loss 1.19 Classification-F1 0.0974025974025974 on epoch=199
05/20/2022 17:20:47 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=202
05/20/2022 17:20:49 - INFO - __main__ - Step 820 Global step 820 Train loss 1.16 on epoch=204
05/20/2022 17:20:50 - INFO - __main__ - Step 830 Global step 830 Train loss 1.22 on epoch=207
05/20/2022 17:20:52 - INFO - __main__ - Step 840 Global step 840 Train loss 1.14 on epoch=209
05/20/2022 17:20:54 - INFO - __main__ - Step 850 Global step 850 Train loss 1.24 on epoch=212
05/20/2022 17:20:55 - INFO - __main__ - Global step 850 Train loss 1.17 Classification-F1 0.23076923076923078 on epoch=212
05/20/2022 17:20:55 - INFO - __main__ - Saving model with best Classification-F1: 0.20277777777777778 -> 0.23076923076923078 on epoch=212, global_step=850
05/20/2022 17:20:56 - INFO - __main__ - Step 860 Global step 860 Train loss 1.10 on epoch=214
05/20/2022 17:20:58 - INFO - __main__ - Step 870 Global step 870 Train loss 1.17 on epoch=217
05/20/2022 17:20:59 - INFO - __main__ - Step 880 Global step 880 Train loss 1.19 on epoch=219
05/20/2022 17:21:00 - INFO - __main__ - Step 890 Global step 890 Train loss 1.18 on epoch=222
05/20/2022 17:21:02 - INFO - __main__ - Step 900 Global step 900 Train loss 1.18 on epoch=224
05/20/2022 17:21:02 - INFO - __main__ - Global step 900 Train loss 1.17 Classification-F1 0.1256338028169014 on epoch=224
05/20/2022 17:21:03 - INFO - __main__ - Step 910 Global step 910 Train loss 1.18 on epoch=227
05/20/2022 17:21:05 - INFO - __main__ - Step 920 Global step 920 Train loss 1.18 on epoch=229
05/20/2022 17:21:06 - INFO - __main__ - Step 930 Global step 930 Train loss 1.20 on epoch=232
05/20/2022 17:21:07 - INFO - __main__ - Step 940 Global step 940 Train loss 1.06 on epoch=234
05/20/2022 17:21:09 - INFO - __main__ - Step 950 Global step 950 Train loss 1.10 on epoch=237
05/20/2022 17:21:09 - INFO - __main__ - Global step 950 Train loss 1.14 Classification-F1 0.22059553349875932 on epoch=237
05/20/2022 17:21:11 - INFO - __main__ - Step 960 Global step 960 Train loss 1.12 on epoch=239
05/20/2022 17:21:12 - INFO - __main__ - Step 970 Global step 970 Train loss 1.06 on epoch=242
05/20/2022 17:21:14 - INFO - __main__ - Step 980 Global step 980 Train loss 1.04 on epoch=244
05/20/2022 17:21:15 - INFO - __main__ - Step 990 Global step 990 Train loss 1.12 on epoch=247
05/20/2022 17:21:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.04 on epoch=249
05/20/2022 17:21:17 - INFO - __main__ - Global step 1000 Train loss 1.08 Classification-F1 0.16666666666666666 on epoch=249
05/20/2022 17:21:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.16 on epoch=252
05/20/2022 17:21:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.03 on epoch=254
05/20/2022 17:21:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/20/2022 17:21:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.91 on epoch=259
05/20/2022 17:21:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.12 on epoch=262
05/20/2022 17:21:25 - INFO - __main__ - Global step 1050 Train loss 1.06 Classification-F1 0.21743697478991597 on epoch=262
05/20/2022 17:21:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=264
05/20/2022 17:21:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.99 on epoch=267
05/20/2022 17:21:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=269
05/20/2022 17:21:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.12 on epoch=272
05/20/2022 17:21:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.10 on epoch=274
05/20/2022 17:21:32 - INFO - __main__ - Global step 1100 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=274
05/20/2022 17:21:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.10 on epoch=277
05/20/2022 17:21:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.04 on epoch=279
05/20/2022 17:21:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.10 on epoch=282
05/20/2022 17:21:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.07 on epoch=284
05/20/2022 17:21:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.98 on epoch=287
05/20/2022 17:21:40 - INFO - __main__ - Global step 1150 Train loss 1.06 Classification-F1 0.11762954139368673 on epoch=287
05/20/2022 17:21:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.04 on epoch=289
05/20/2022 17:21:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.10 on epoch=292
05/20/2022 17:21:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.06 on epoch=294
05/20/2022 17:21:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.17 on epoch=297
05/20/2022 17:21:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.04 on epoch=299
05/20/2022 17:21:47 - INFO - __main__ - Global step 1200 Train loss 1.08 Classification-F1 0.16785714285714287 on epoch=299
05/20/2022 17:21:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.07 on epoch=302
05/20/2022 17:21:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.16 on epoch=304
05/20/2022 17:21:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.07 on epoch=307
05/20/2022 17:21:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
05/20/2022 17:21:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.16 on epoch=312
05/20/2022 17:21:54 - INFO - __main__ - Global step 1250 Train loss 1.11 Classification-F1 0.11714285714285715 on epoch=312
05/20/2022 17:21:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.05 on epoch=314
05/20/2022 17:21:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.08 on epoch=317
05/20/2022 17:21:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.99 on epoch=319
05/20/2022 17:22:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.04 on epoch=322
05/20/2022 17:22:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.11 on epoch=324
05/20/2022 17:22:02 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.22026143790849673 on epoch=324
05/20/2022 17:22:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.04 on epoch=327
05/20/2022 17:22:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.03 on epoch=329
05/20/2022 17:22:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.95 on epoch=332
05/20/2022 17:22:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.99 on epoch=334
05/20/2022 17:22:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.02 on epoch=337
05/20/2022 17:22:10 - INFO - __main__ - Global step 1350 Train loss 1.01 Classification-F1 0.1527777777777778 on epoch=337
05/20/2022 17:22:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.02 on epoch=339
05/20/2022 17:22:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/20/2022 17:22:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.13 on epoch=344
05/20/2022 17:22:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.24 on epoch=347
05/20/2022 17:22:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.13 on epoch=349
05/20/2022 17:22:17 - INFO - __main__ - Global step 1400 Train loss 1.12 Classification-F1 0.13067758749069247 on epoch=349
05/20/2022 17:22:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.15 on epoch=352
05/20/2022 17:22:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.21 on epoch=354
05/20/2022 17:22:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.05 on epoch=357
05/20/2022 17:22:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.21 on epoch=359
05/20/2022 17:22:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=362
05/20/2022 17:22:25 - INFO - __main__ - Global step 1450 Train loss 1.14 Classification-F1 0.21827759963353183 on epoch=362
05/20/2022 17:22:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.11 on epoch=364
05/20/2022 17:22:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.17 on epoch=367
05/20/2022 17:22:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.13 on epoch=369
05/20/2022 17:22:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.10 on epoch=372
05/20/2022 17:22:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.16 on epoch=374
05/20/2022 17:22:33 - INFO - __main__ - Global step 1500 Train loss 1.13 Classification-F1 0.1873628784554629 on epoch=374
05/20/2022 17:22:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.09 on epoch=377
05/20/2022 17:22:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
05/20/2022 17:22:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
05/20/2022 17:22:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.18 on epoch=384
05/20/2022 17:22:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.02 on epoch=387
05/20/2022 17:22:40 - INFO - __main__ - Global step 1550 Train loss 1.08 Classification-F1 0.1732142857142857 on epoch=387
05/20/2022 17:22:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.00 on epoch=389
05/20/2022 17:22:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.12 on epoch=392
05/20/2022 17:22:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.02 on epoch=394
05/20/2022 17:22:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=397
05/20/2022 17:22:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
05/20/2022 17:22:49 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.15625 on epoch=399
05/20/2022 17:22:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.09 on epoch=402
05/20/2022 17:22:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/20/2022 17:22:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.04 on epoch=407
05/20/2022 17:22:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.90 on epoch=409
05/20/2022 17:22:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.16 on epoch=412
05/20/2022 17:22:56 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.14583333333333334 on epoch=412
05/20/2022 17:22:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.05 on epoch=414
05/20/2022 17:23:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.03 on epoch=417
05/20/2022 17:23:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.09 on epoch=419
05/20/2022 17:23:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.13 on epoch=422
05/20/2022 17:23:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=424
05/20/2022 17:23:05 - INFO - __main__ - Global step 1700 Train loss 1.07 Classification-F1 0.13067758749069247 on epoch=424
05/20/2022 17:23:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.98 on epoch=427
05/20/2022 17:23:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.03 on epoch=429
05/20/2022 17:23:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.06 on epoch=432
05/20/2022 17:23:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
05/20/2022 17:23:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.19 on epoch=437
05/20/2022 17:23:12 - INFO - __main__ - Global step 1750 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=437
05/20/2022 17:23:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
05/20/2022 17:23:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
05/20/2022 17:23:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/20/2022 17:23:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.98 on epoch=447
05/20/2022 17:23:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=449
05/20/2022 17:23:20 - INFO - __main__ - Global step 1800 Train loss 1.04 Classification-F1 0.1 on epoch=449
05/20/2022 17:23:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/20/2022 17:23:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.08 on epoch=454
05/20/2022 17:23:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.07 on epoch=457
05/20/2022 17:23:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.24 on epoch=459
05/20/2022 17:23:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.15 on epoch=462
05/20/2022 17:23:28 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.16666666666666666 on epoch=462
05/20/2022 17:23:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.05 on epoch=464
05/20/2022 17:23:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.97 on epoch=467
05/20/2022 17:23:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.08 on epoch=469
05/20/2022 17:23:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.97 on epoch=472
05/20/2022 17:23:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.00 on epoch=474
05/20/2022 17:23:35 - INFO - __main__ - Global step 1900 Train loss 1.01 Classification-F1 0.11714285714285715 on epoch=474
05/20/2022 17:23:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
05/20/2022 17:23:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
05/20/2022 17:23:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.93 on epoch=482
05/20/2022 17:23:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
05/20/2022 17:23:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.95 on epoch=487
05/20/2022 17:23:43 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.1 on epoch=487
05/20/2022 17:23:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.03 on epoch=489
05/20/2022 17:23:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/20/2022 17:23:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.92 on epoch=494
05/20/2022 17:23:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.11 on epoch=497
05/20/2022 17:23:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.94 on epoch=499
05/20/2022 17:23:50 - INFO - __main__ - Global step 2000 Train loss 1.00 Classification-F1 0.10256410256410256 on epoch=499
05/20/2022 17:23:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.09 on epoch=502
05/20/2022 17:23:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.93 on epoch=504
05/20/2022 17:23:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.07 on epoch=507
05/20/2022 17:23:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.04 on epoch=509
05/20/2022 17:23:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.98 on epoch=512
05/20/2022 17:23:58 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.1 on epoch=512
05/20/2022 17:23:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.08 on epoch=514
05/20/2022 17:24:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
05/20/2022 17:24:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.06 on epoch=519
05/20/2022 17:24:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.98 on epoch=522
05/20/2022 17:24:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.01 on epoch=524
05/20/2022 17:24:05 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.09493670886075949 on epoch=524
05/20/2022 17:24:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.10 on epoch=527
05/20/2022 17:24:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
05/20/2022 17:24:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
05/20/2022 17:24:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.89 on epoch=534
05/20/2022 17:24:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
05/20/2022 17:24:12 - INFO - __main__ - Global step 2150 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=537
05/20/2022 17:24:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.95 on epoch=539
05/20/2022 17:24:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.89 on epoch=542
05/20/2022 17:24:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/20/2022 17:24:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/20/2022 17:24:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
05/20/2022 17:24:20 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.1 on epoch=549
05/20/2022 17:24:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/20/2022 17:24:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.05 on epoch=554
05/20/2022 17:24:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=557
05/20/2022 17:24:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.92 on epoch=559
05/20/2022 17:24:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/20/2022 17:24:27 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.1796875 on epoch=562
05/20/2022 17:24:28 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.02 on epoch=564
05/20/2022 17:24:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.04 on epoch=567
05/20/2022 17:24:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.98 on epoch=569
05/20/2022 17:24:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
05/20/2022 17:24:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/20/2022 17:24:34 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.14304993252361672 on epoch=574
05/20/2022 17:24:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.97 on epoch=577
05/20/2022 17:24:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/20/2022 17:24:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.91 on epoch=582
05/20/2022 17:24:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.90 on epoch=584
05/20/2022 17:24:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.92 on epoch=587
05/20/2022 17:24:42 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.1576923076923077 on epoch=587
05/20/2022 17:24:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.95 on epoch=589
05/20/2022 17:24:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.96 on epoch=592
05/20/2022 17:24:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.97 on epoch=594
05/20/2022 17:24:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.07 on epoch=597
05/20/2022 17:24:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.91 on epoch=599
05/20/2022 17:24:49 - INFO - __main__ - Global step 2400 Train loss 0.97 Classification-F1 0.1 on epoch=599
05/20/2022 17:24:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.95 on epoch=602
05/20/2022 17:24:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.92 on epoch=604
05/20/2022 17:24:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.02 on epoch=607
05/20/2022 17:24:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.86 on epoch=609
05/20/2022 17:24:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.93 on epoch=612
05/20/2022 17:24:57 - INFO - __main__ - Global step 2450 Train loss 0.94 Classification-F1 0.1 on epoch=612
05/20/2022 17:24:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.01 on epoch=614
05/20/2022 17:25:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/20/2022 17:25:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.93 on epoch=619
05/20/2022 17:25:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
05/20/2022 17:25:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.99 on epoch=624
05/20/2022 17:25:05 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.1682769726247987 on epoch=624
05/20/2022 17:25:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/20/2022 17:25:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.03 on epoch=629
05/20/2022 17:25:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.01 on epoch=632
05/20/2022 17:25:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/20/2022 17:25:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.00 on epoch=637
05/20/2022 17:25:12 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=637
05/20/2022 17:25:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.07 on epoch=639
05/20/2022 17:25:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.97 on epoch=642
05/20/2022 17:25:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.86 on epoch=644
05/20/2022 17:25:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/20/2022 17:25:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.93 on epoch=649
05/20/2022 17:25:20 - INFO - __main__ - Global step 2600 Train loss 0.95 Classification-F1 0.15625 on epoch=649
05/20/2022 17:25:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/20/2022 17:25:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
05/20/2022 17:25:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.02 on epoch=657
05/20/2022 17:25:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.09 on epoch=659
05/20/2022 17:25:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
05/20/2022 17:25:27 - INFO - __main__ - Global step 2650 Train loss 1.02 Classification-F1 0.1354895104895105 on epoch=662
05/20/2022 17:25:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.96 on epoch=664
05/20/2022 17:25:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/20/2022 17:25:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
05/20/2022 17:25:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.07 on epoch=672
05/20/2022 17:25:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/20/2022 17:25:35 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.20980302336234538 on epoch=674
05/20/2022 17:25:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/20/2022 17:25:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.98 on epoch=679
05/20/2022 17:25:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.02 on epoch=682
05/20/2022 17:25:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.93 on epoch=684
05/20/2022 17:25:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=687
05/20/2022 17:25:42 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.1767857142857143 on epoch=687
05/20/2022 17:25:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.03 on epoch=689
05/20/2022 17:25:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
05/20/2022 17:25:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/20/2022 17:25:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
05/20/2022 17:25:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=699
05/20/2022 17:25:50 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.10126582278481013 on epoch=699
05/20/2022 17:25:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.99 on epoch=702
05/20/2022 17:25:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.03 on epoch=704
05/20/2022 17:25:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.97 on epoch=707
05/20/2022 17:25:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/20/2022 17:25:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
05/20/2022 17:25:57 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.10126582278481013 on epoch=712
05/20/2022 17:25:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.03 on epoch=714
05/20/2022 17:26:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.82 on epoch=717
05/20/2022 17:26:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.90 on epoch=719
05/20/2022 17:26:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/20/2022 17:26:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
05/20/2022 17:26:05 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.14383875400824553 on epoch=724
05/20/2022 17:26:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.93 on epoch=727
05/20/2022 17:26:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/20/2022 17:26:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.02 on epoch=732
05/20/2022 17:26:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
05/20/2022 17:26:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/20/2022 17:26:12 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.1171875 on epoch=737
05/20/2022 17:26:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/20/2022 17:26:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/20/2022 17:26:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
05/20/2022 17:26:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/20/2022 17:26:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.00 on epoch=749
05/20/2022 17:26:20 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.14583333333333331 on epoch=749
05/20/2022 17:26:20 - INFO - __main__ - save last model!
05/20/2022 17:26:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 17:26:20 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 17:26:20 - INFO - __main__ - Printing 3 examples
05/20/2022 17:26:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 17:26:20 - INFO - __main__ - ['others']
05/20/2022 17:26:20 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 17:26:20 - INFO - __main__ - ['others']
05/20/2022 17:26:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 17:26:20 - INFO - __main__ - ['others']
05/20/2022 17:26:20 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:26:20 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:26:20 - INFO - __main__ - Printing 3 examples
05/20/2022 17:26:20 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:26:20 - INFO - __main__ - ['others']
05/20/2022 17:26:20 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:26:20 - INFO - __main__ - ['others']
05/20/2022 17:26:20 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:26:20 - INFO - __main__ - ['others']
05/20/2022 17:26:20 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:26:20 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:26:21 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:26:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:26:21 - INFO - __main__ - Printing 3 examples
05/20/2022 17:26:21 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:26:21 - INFO - __main__ - ['others']
05/20/2022 17:26:21 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:26:21 - INFO - __main__ - ['others']
05/20/2022 17:26:21 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:26:21 - INFO - __main__ - ['others']
05/20/2022 17:26:21 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:26:21 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:26:21 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:26:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:26:27 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:26:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:26:27 - INFO - __main__ - Starting training!
05/20/2022 17:26:29 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 17:27:16 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.5_8_predictions.txt
05/20/2022 17:27:17 - INFO - __main__ - Classification-F1 on test data: 0.0401
05/20/2022 17:27:17 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.23076923076923078, test_performance=0.04012249342932043
05/20/2022 17:27:17 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
05/20/2022 17:27:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:27:18 - INFO - __main__ - Printing 3 examples
05/20/2022 17:27:18 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:27:18 - INFO - __main__ - ['others']
05/20/2022 17:27:18 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:27:18 - INFO - __main__ - ['others']
05/20/2022 17:27:18 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:27:18 - INFO - __main__ - ['others']
05/20/2022 17:27:18 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:27:18 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:27:19 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:27:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:27:19 - INFO - __main__ - Printing 3 examples
05/20/2022 17:27:19 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:27:19 - INFO - __main__ - ['others']
05/20/2022 17:27:19 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:27:19 - INFO - __main__ - ['others']
05/20/2022 17:27:19 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:27:19 - INFO - __main__ - ['others']
05/20/2022 17:27:19 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:27:19 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:27:19 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:27:24 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:27:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:27:25 - INFO - __main__ - Starting training!
05/20/2022 17:27:26 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=2
05/20/2022 17:27:27 - INFO - __main__ - Step 20 Global step 20 Train loss 6.37 on epoch=4
05/20/2022 17:27:29 - INFO - __main__ - Step 30 Global step 30 Train loss 5.99 on epoch=7
05/20/2022 17:27:30 - INFO - __main__ - Step 40 Global step 40 Train loss 5.61 on epoch=9
05/20/2022 17:27:31 - INFO - __main__ - Step 50 Global step 50 Train loss 5.46 on epoch=12
05/20/2022 17:27:35 - INFO - __main__ - Global step 50 Train loss 6.03 Classification-F1 0.0 on epoch=12
05/20/2022 17:27:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 17:27:36 - INFO - __main__ - Step 60 Global step 60 Train loss 5.21 on epoch=14
05/20/2022 17:27:37 - INFO - __main__ - Step 70 Global step 70 Train loss 5.05 on epoch=17
05/20/2022 17:27:39 - INFO - __main__ - Step 80 Global step 80 Train loss 4.74 on epoch=19
05/20/2022 17:27:40 - INFO - __main__ - Step 90 Global step 90 Train loss 4.67 on epoch=22
05/20/2022 17:27:42 - INFO - __main__ - Step 100 Global step 100 Train loss 4.65 on epoch=24
05/20/2022 17:27:46 - INFO - __main__ - Global step 100 Train loss 4.86 Classification-F1 0.0101010101010101 on epoch=24
05/20/2022 17:27:46 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0101010101010101 on epoch=24, global_step=100
05/20/2022 17:27:48 - INFO - __main__ - Step 110 Global step 110 Train loss 4.50 on epoch=27
05/20/2022 17:27:49 - INFO - __main__ - Step 120 Global step 120 Train loss 4.44 on epoch=29
05/20/2022 17:27:51 - INFO - __main__ - Step 130 Global step 130 Train loss 4.29 on epoch=32
05/20/2022 17:27:52 - INFO - __main__ - Step 140 Global step 140 Train loss 3.96 on epoch=34
05/20/2022 17:27:54 - INFO - __main__ - Step 150 Global step 150 Train loss 4.11 on epoch=37
05/20/2022 17:27:54 - INFO - __main__ - Global step 150 Train loss 4.26 Classification-F1 0.1 on epoch=37
05/20/2022 17:27:54 - INFO - __main__ - Saving model with best Classification-F1: 0.0101010101010101 -> 0.1 on epoch=37, global_step=150
05/20/2022 17:27:55 - INFO - __main__ - Step 160 Global step 160 Train loss 3.78 on epoch=39
05/20/2022 17:27:57 - INFO - __main__ - Step 170 Global step 170 Train loss 3.77 on epoch=42
05/20/2022 17:27:58 - INFO - __main__ - Step 180 Global step 180 Train loss 3.47 on epoch=44
05/20/2022 17:28:00 - INFO - __main__ - Step 190 Global step 190 Train loss 3.63 on epoch=47
05/20/2022 17:28:01 - INFO - __main__ - Step 200 Global step 200 Train loss 3.36 on epoch=49
05/20/2022 17:28:02 - INFO - __main__ - Global step 200 Train loss 3.60 Classification-F1 0.1 on epoch=49
05/20/2022 17:28:03 - INFO - __main__ - Step 210 Global step 210 Train loss 3.43 on epoch=52
05/20/2022 17:28:04 - INFO - __main__ - Step 220 Global step 220 Train loss 3.09 on epoch=54
05/20/2022 17:28:06 - INFO - __main__ - Step 230 Global step 230 Train loss 3.27 on epoch=57
05/20/2022 17:28:07 - INFO - __main__ - Step 240 Global step 240 Train loss 3.16 on epoch=59
05/20/2022 17:28:09 - INFO - __main__ - Step 250 Global step 250 Train loss 3.16 on epoch=62
05/20/2022 17:28:09 - INFO - __main__ - Global step 250 Train loss 3.22 Classification-F1 0.08108108108108109 on epoch=62
05/20/2022 17:28:11 - INFO - __main__ - Step 260 Global step 260 Train loss 3.05 on epoch=64
05/20/2022 17:28:12 - INFO - __main__ - Step 270 Global step 270 Train loss 3.19 on epoch=67
05/20/2022 17:28:13 - INFO - __main__ - Step 280 Global step 280 Train loss 2.76 on epoch=69
05/20/2022 17:28:15 - INFO - __main__ - Step 290 Global step 290 Train loss 2.76 on epoch=72
05/20/2022 17:28:16 - INFO - __main__ - Step 300 Global step 300 Train loss 2.83 on epoch=74
05/20/2022 17:28:17 - INFO - __main__ - Global step 300 Train loss 2.92 Classification-F1 0.10256410256410256 on epoch=74
05/20/2022 17:28:17 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10256410256410256 on epoch=74, global_step=300
05/20/2022 17:28:18 - INFO - __main__ - Step 310 Global step 310 Train loss 2.76 on epoch=77
05/20/2022 17:28:20 - INFO - __main__ - Step 320 Global step 320 Train loss 2.60 on epoch=79
05/20/2022 17:28:21 - INFO - __main__ - Step 330 Global step 330 Train loss 2.85 on epoch=82
05/20/2022 17:28:23 - INFO - __main__ - Step 340 Global step 340 Train loss 2.52 on epoch=84
05/20/2022 17:28:24 - INFO - __main__ - Step 350 Global step 350 Train loss 2.61 on epoch=87
05/20/2022 17:28:25 - INFO - __main__ - Global step 350 Train loss 2.67 Classification-F1 0.23911070780399274 on epoch=87
05/20/2022 17:28:25 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.23911070780399274 on epoch=87, global_step=350
05/20/2022 17:28:26 - INFO - __main__ - Step 360 Global step 360 Train loss 2.34 on epoch=89
05/20/2022 17:28:28 - INFO - __main__ - Step 370 Global step 370 Train loss 2.56 on epoch=92
05/20/2022 17:28:29 - INFO - __main__ - Step 380 Global step 380 Train loss 2.29 on epoch=94
05/20/2022 17:28:30 - INFO - __main__ - Step 390 Global step 390 Train loss 2.43 on epoch=97
05/20/2022 17:28:32 - INFO - __main__ - Step 400 Global step 400 Train loss 2.16 on epoch=99
05/20/2022 17:28:32 - INFO - __main__ - Global step 400 Train loss 2.35 Classification-F1 0.1 on epoch=99
05/20/2022 17:28:33 - INFO - __main__ - Step 410 Global step 410 Train loss 2.30 on epoch=102
05/20/2022 17:28:35 - INFO - __main__ - Step 420 Global step 420 Train loss 2.06 on epoch=104
05/20/2022 17:28:36 - INFO - __main__ - Step 430 Global step 430 Train loss 2.19 on epoch=107
05/20/2022 17:28:38 - INFO - __main__ - Step 440 Global step 440 Train loss 2.25 on epoch=109
05/20/2022 17:28:39 - INFO - __main__ - Step 450 Global step 450 Train loss 2.13 on epoch=112
05/20/2022 17:28:40 - INFO - __main__ - Global step 450 Train loss 2.19 Classification-F1 0.1237183868762816 on epoch=112
05/20/2022 17:28:41 - INFO - __main__ - Step 460 Global step 460 Train loss 2.16 on epoch=114
05/20/2022 17:28:42 - INFO - __main__ - Step 470 Global step 470 Train loss 2.08 on epoch=117
05/20/2022 17:28:44 - INFO - __main__ - Step 480 Global step 480 Train loss 2.00 on epoch=119
05/20/2022 17:28:45 - INFO - __main__ - Step 490 Global step 490 Train loss 2.12 on epoch=122
05/20/2022 17:28:46 - INFO - __main__ - Step 500 Global step 500 Train loss 1.92 on epoch=124
05/20/2022 17:28:47 - INFO - __main__ - Global step 500 Train loss 2.05 Classification-F1 0.1 on epoch=124
05/20/2022 17:28:48 - INFO - __main__ - Step 510 Global step 510 Train loss 1.92 on epoch=127
05/20/2022 17:28:50 - INFO - __main__ - Step 520 Global step 520 Train loss 1.85 on epoch=129
05/20/2022 17:28:51 - INFO - __main__ - Step 530 Global step 530 Train loss 1.89 on epoch=132
05/20/2022 17:28:52 - INFO - __main__ - Step 540 Global step 540 Train loss 1.92 on epoch=134
05/20/2022 17:28:54 - INFO - __main__ - Step 550 Global step 550 Train loss 1.72 on epoch=137
05/20/2022 17:28:54 - INFO - __main__ - Global step 550 Train loss 1.86 Classification-F1 0.16666666666666666 on epoch=137
05/20/2022 17:28:56 - INFO - __main__ - Step 560 Global step 560 Train loss 1.68 on epoch=139
05/20/2022 17:28:57 - INFO - __main__ - Step 570 Global step 570 Train loss 1.83 on epoch=142
05/20/2022 17:28:58 - INFO - __main__ - Step 580 Global step 580 Train loss 1.83 on epoch=144
05/20/2022 17:29:00 - INFO - __main__ - Step 590 Global step 590 Train loss 1.77 on epoch=147
05/20/2022 17:29:01 - INFO - __main__ - Step 600 Global step 600 Train loss 1.57 on epoch=149
05/20/2022 17:29:01 - INFO - __main__ - Global step 600 Train loss 1.74 Classification-F1 0.16407982261640797 on epoch=149
05/20/2022 17:29:03 - INFO - __main__ - Step 610 Global step 610 Train loss 1.62 on epoch=152
05/20/2022 17:29:04 - INFO - __main__ - Step 620 Global step 620 Train loss 1.66 on epoch=154
05/20/2022 17:29:05 - INFO - __main__ - Step 630 Global step 630 Train loss 1.77 on epoch=157
05/20/2022 17:29:07 - INFO - __main__ - Step 640 Global step 640 Train loss 1.61 on epoch=159
05/20/2022 17:29:08 - INFO - __main__ - Step 650 Global step 650 Train loss 1.67 on epoch=162
05/20/2022 17:29:09 - INFO - __main__ - Global step 650 Train loss 1.67 Classification-F1 0.14107142857142857 on epoch=162
05/20/2022 17:29:10 - INFO - __main__ - Step 660 Global step 660 Train loss 1.63 on epoch=164
05/20/2022 17:29:11 - INFO - __main__ - Step 670 Global step 670 Train loss 1.51 on epoch=167
05/20/2022 17:29:13 - INFO - __main__ - Step 680 Global step 680 Train loss 1.46 on epoch=169
05/20/2022 17:29:14 - INFO - __main__ - Step 690 Global step 690 Train loss 1.62 on epoch=172
05/20/2022 17:29:15 - INFO - __main__ - Step 700 Global step 700 Train loss 1.48 on epoch=174
05/20/2022 17:29:16 - INFO - __main__ - Global step 700 Train loss 1.54 Classification-F1 0.08863636363636362 on epoch=174
05/20/2022 17:29:17 - INFO - __main__ - Step 710 Global step 710 Train loss 1.63 on epoch=177
05/20/2022 17:29:18 - INFO - __main__ - Step 720 Global step 720 Train loss 1.44 on epoch=179
05/20/2022 17:29:20 - INFO - __main__ - Step 730 Global step 730 Train loss 1.45 on epoch=182
05/20/2022 17:29:21 - INFO - __main__ - Step 740 Global step 740 Train loss 1.43 on epoch=184
05/20/2022 17:29:23 - INFO - __main__ - Step 750 Global step 750 Train loss 1.31 on epoch=187
05/20/2022 17:29:23 - INFO - __main__ - Global step 750 Train loss 1.45 Classification-F1 0.19149305555555554 on epoch=187
05/20/2022 17:29:25 - INFO - __main__ - Step 760 Global step 760 Train loss 1.61 on epoch=189
05/20/2022 17:29:26 - INFO - __main__ - Step 770 Global step 770 Train loss 1.30 on epoch=192
05/20/2022 17:29:27 - INFO - __main__ - Step 780 Global step 780 Train loss 1.35 on epoch=194
05/20/2022 17:29:29 - INFO - __main__ - Step 790 Global step 790 Train loss 1.46 on epoch=197
05/20/2022 17:29:30 - INFO - __main__ - Step 800 Global step 800 Train loss 1.33 on epoch=199
05/20/2022 17:29:30 - INFO - __main__ - Global step 800 Train loss 1.41 Classification-F1 0.13525835866261396 on epoch=199
05/20/2022 17:29:32 - INFO - __main__ - Step 810 Global step 810 Train loss 1.38 on epoch=202
05/20/2022 17:29:33 - INFO - __main__ - Step 820 Global step 820 Train loss 1.43 on epoch=204
05/20/2022 17:29:35 - INFO - __main__ - Step 830 Global step 830 Train loss 1.31 on epoch=207
05/20/2022 17:29:36 - INFO - __main__ - Step 840 Global step 840 Train loss 1.43 on epoch=209
05/20/2022 17:29:37 - INFO - __main__ - Step 850 Global step 850 Train loss 1.30 on epoch=212
05/20/2022 17:29:38 - INFO - __main__ - Global step 850 Train loss 1.37 Classification-F1 0.13475499092558985 on epoch=212
05/20/2022 17:29:39 - INFO - __main__ - Step 860 Global step 860 Train loss 1.23 on epoch=214
05/20/2022 17:29:41 - INFO - __main__ - Step 870 Global step 870 Train loss 1.24 on epoch=217
05/20/2022 17:29:42 - INFO - __main__ - Step 880 Global step 880 Train loss 1.38 on epoch=219
05/20/2022 17:29:43 - INFO - __main__ - Step 890 Global step 890 Train loss 1.25 on epoch=222
05/20/2022 17:29:45 - INFO - __main__ - Step 900 Global step 900 Train loss 1.24 on epoch=224
05/20/2022 17:29:45 - INFO - __main__ - Global step 900 Train loss 1.27 Classification-F1 0.13026315789473686 on epoch=224
05/20/2022 17:29:47 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/20/2022 17:29:48 - INFO - __main__ - Step 920 Global step 920 Train loss 1.27 on epoch=229
05/20/2022 17:29:50 - INFO - __main__ - Step 930 Global step 930 Train loss 1.27 on epoch=232
05/20/2022 17:29:51 - INFO - __main__ - Step 940 Global step 940 Train loss 1.15 on epoch=234
05/20/2022 17:29:52 - INFO - __main__ - Step 950 Global step 950 Train loss 1.30 on epoch=237
05/20/2022 17:29:53 - INFO - __main__ - Global step 950 Train loss 1.24 Classification-F1 0.10666666666666667 on epoch=237
05/20/2022 17:29:54 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
05/20/2022 17:29:56 - INFO - __main__ - Step 970 Global step 970 Train loss 1.27 on epoch=242
05/20/2022 17:29:57 - INFO - __main__ - Step 980 Global step 980 Train loss 1.21 on epoch=244
05/20/2022 17:29:58 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=247
05/20/2022 17:30:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.24 on epoch=249
05/20/2022 17:30:00 - INFO - __main__ - Global step 1000 Train loss 1.28 Classification-F1 0.13067758749069247 on epoch=249
05/20/2022 17:30:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.20 on epoch=252
05/20/2022 17:30:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.36 on epoch=254
05/20/2022 17:30:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.21 on epoch=257
05/20/2022 17:30:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.23 on epoch=259
05/20/2022 17:30:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.16 on epoch=262
05/20/2022 17:30:08 - INFO - __main__ - Global step 1050 Train loss 1.23 Classification-F1 0.18920361247947456 on epoch=262
05/20/2022 17:30:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.21 on epoch=264
05/20/2022 17:30:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.24 on epoch=267
05/20/2022 17:30:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
05/20/2022 17:30:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.20 on epoch=272
05/20/2022 17:30:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.07 on epoch=274
05/20/2022 17:30:15 - INFO - __main__ - Global step 1100 Train loss 1.18 Classification-F1 0.15208955223880596 on epoch=274
05/20/2022 17:30:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.00 on epoch=277
05/20/2022 17:30:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.05 on epoch=279
05/20/2022 17:30:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.21 on epoch=282
05/20/2022 17:30:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.98 on epoch=284
05/20/2022 17:30:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.27 on epoch=287
05/20/2022 17:30:23 - INFO - __main__ - Global step 1150 Train loss 1.10 Classification-F1 0.178243195475433 on epoch=287
05/20/2022 17:30:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.15 on epoch=289
05/20/2022 17:30:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.14 on epoch=292
05/20/2022 17:30:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.07 on epoch=294
05/20/2022 17:30:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.17 on epoch=297
05/20/2022 17:30:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.26 on epoch=299
05/20/2022 17:30:30 - INFO - __main__ - Global step 1200 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=299
05/20/2022 17:30:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
05/20/2022 17:30:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.08 on epoch=304
05/20/2022 17:30:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.19 on epoch=307
05/20/2022 17:30:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.16 on epoch=309
05/20/2022 17:30:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.02 on epoch=312
05/20/2022 17:30:37 - INFO - __main__ - Global step 1250 Train loss 1.12 Classification-F1 0.18860472005529771 on epoch=312
05/20/2022 17:30:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.01 on epoch=314
05/20/2022 17:30:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.07 on epoch=317
05/20/2022 17:30:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
05/20/2022 17:30:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.17 on epoch=322
05/20/2022 17:30:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.10 on epoch=324
05/20/2022 17:30:45 - INFO - __main__ - Global step 1300 Train loss 1.10 Classification-F1 0.14210526315789473 on epoch=324
05/20/2022 17:30:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.17 on epoch=327
05/20/2022 17:30:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.08 on epoch=329
05/20/2022 17:30:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=332
05/20/2022 17:30:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.10 on epoch=334
05/20/2022 17:30:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.13 on epoch=337
05/20/2022 17:30:52 - INFO - __main__ - Global step 1350 Train loss 1.14 Classification-F1 0.12407862407862408 on epoch=337
05/20/2022 17:30:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/20/2022 17:30:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/20/2022 17:30:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.07 on epoch=344
05/20/2022 17:30:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.17 on epoch=347
05/20/2022 17:30:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=349
05/20/2022 17:31:00 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.10666666666666667 on epoch=349
05/20/2022 17:31:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.08 on epoch=352
05/20/2022 17:31:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.04 on epoch=354
05/20/2022 17:31:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/20/2022 17:31:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.05 on epoch=359
05/20/2022 17:31:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.05 on epoch=362
05/20/2022 17:31:07 - INFO - __main__ - Global step 1450 Train loss 1.07 Classification-F1 0.15838509316770188 on epoch=362
05/20/2022 17:31:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/20/2022 17:31:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.07 on epoch=367
05/20/2022 17:31:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.08 on epoch=369
05/20/2022 17:31:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.94 on epoch=372
05/20/2022 17:31:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.01 on epoch=374
05/20/2022 17:31:14 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.1497584541062802 on epoch=374
05/20/2022 17:31:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.15 on epoch=377
05/20/2022 17:31:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=379
05/20/2022 17:31:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.19 on epoch=382
05/20/2022 17:31:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=384
05/20/2022 17:31:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
05/20/2022 17:31:22 - INFO - __main__ - Global step 1550 Train loss 1.09 Classification-F1 0.10389610389610389 on epoch=387
05/20/2022 17:31:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.02 on epoch=389
05/20/2022 17:31:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.11 on epoch=392
05/20/2022 17:31:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.10 on epoch=394
05/20/2022 17:31:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.02 on epoch=397
05/20/2022 17:31:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.95 on epoch=399
05/20/2022 17:31:29 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.11157407407407408 on epoch=399
05/20/2022 17:31:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
05/20/2022 17:31:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/20/2022 17:31:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.07 on epoch=407
05/20/2022 17:31:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/20/2022 17:31:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/20/2022 17:31:37 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.20924825940892933 on epoch=412
05/20/2022 17:31:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.96 on epoch=414
05/20/2022 17:31:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.93 on epoch=417
05/20/2022 17:31:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.97 on epoch=419
05/20/2022 17:31:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.02 on epoch=422
05/20/2022 17:31:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.02 on epoch=424
05/20/2022 17:31:44 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.2109375 on epoch=424
05/20/2022 17:31:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.07 on epoch=427
05/20/2022 17:31:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.97 on epoch=429
05/20/2022 17:31:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.04 on epoch=432
05/20/2022 17:31:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
05/20/2022 17:31:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.97 on epoch=437
05/20/2022 17:31:51 - INFO - __main__ - Global step 1750 Train loss 1.03 Classification-F1 0.1 on epoch=437
05/20/2022 17:31:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
05/20/2022 17:31:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.03 on epoch=442
05/20/2022 17:31:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/20/2022 17:31:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.00 on epoch=447
05/20/2022 17:31:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
05/20/2022 17:31:59 - INFO - __main__ - Global step 1800 Train loss 1.03 Classification-F1 0.1 on epoch=449
05/20/2022 17:32:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.95 on epoch=452
05/20/2022 17:32:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.91 on epoch=454
05/20/2022 17:32:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.12 on epoch=457
05/20/2022 17:32:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.02 on epoch=459
05/20/2022 17:32:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.00 on epoch=462
05/20/2022 17:32:06 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.20614919354838712 on epoch=462
05/20/2022 17:32:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/20/2022 17:32:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.00 on epoch=467
05/20/2022 17:32:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.90 on epoch=469
05/20/2022 17:32:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.94 on epoch=472
05/20/2022 17:32:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.13 on epoch=474
05/20/2022 17:32:13 - INFO - __main__ - Global step 1900 Train loss 0.99 Classification-F1 0.13026315789473686 on epoch=474
05/20/2022 17:32:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
05/20/2022 17:32:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.07 on epoch=479
05/20/2022 17:32:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.99 on epoch=482
05/20/2022 17:32:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.98 on epoch=484
05/20/2022 17:32:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.04 on epoch=487
05/20/2022 17:32:20 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.13194444444444445 on epoch=487
05/20/2022 17:32:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.97 on epoch=489
05/20/2022 17:32:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=492
05/20/2022 17:32:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.05 on epoch=494
05/20/2022 17:32:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=497
05/20/2022 17:32:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.98 on epoch=499
05/20/2022 17:32:28 - INFO - __main__ - Global step 2000 Train loss 1.01 Classification-F1 0.13034188034188032 on epoch=499
05/20/2022 17:32:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/20/2022 17:32:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.06 on epoch=504
05/20/2022 17:32:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
05/20/2022 17:32:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.01 on epoch=509
05/20/2022 17:32:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.99 on epoch=512
05/20/2022 17:32:36 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.18948412698412698 on epoch=512
05/20/2022 17:32:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.02 on epoch=514
05/20/2022 17:32:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/20/2022 17:32:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.98 on epoch=519
05/20/2022 17:32:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.05 on epoch=522
05/20/2022 17:32:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
05/20/2022 17:32:43 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.16666666666666669 on epoch=524
05/20/2022 17:32:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.06 on epoch=527
05/20/2022 17:32:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.05 on epoch=529
05/20/2022 17:32:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/20/2022 17:32:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.92 on epoch=534
05/20/2022 17:32:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.97 on epoch=537
05/20/2022 17:32:50 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=537
05/20/2022 17:32:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/20/2022 17:32:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
05/20/2022 17:32:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.96 on epoch=544
05/20/2022 17:32:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/20/2022 17:32:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=549
05/20/2022 17:32:58 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.13430127041742287 on epoch=549
05/20/2022 17:32:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.91 on epoch=552
05/20/2022 17:33:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.98 on epoch=554
05/20/2022 17:33:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.98 on epoch=557
05/20/2022 17:33:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.05 on epoch=559
05/20/2022 17:33:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.02 on epoch=562
05/20/2022 17:33:05 - INFO - __main__ - Global step 2250 Train loss 0.99 Classification-F1 0.2897623608830505 on epoch=562
05/20/2022 17:33:05 - INFO - __main__ - Saving model with best Classification-F1: 0.23911070780399274 -> 0.2897623608830505 on epoch=562, global_step=2250
05/20/2022 17:33:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.09 on epoch=564
05/20/2022 17:33:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.92 on epoch=567
05/20/2022 17:33:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.93 on epoch=569
05/20/2022 17:33:11 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.97 on epoch=572
05/20/2022 17:33:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
05/20/2022 17:33:13 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.15718418514946964 on epoch=574
05/20/2022 17:33:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
05/20/2022 17:33:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
05/20/2022 17:33:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/20/2022 17:33:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.91 on epoch=584
05/20/2022 17:33:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.03 on epoch=587
05/20/2022 17:33:20 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.12091038406827881 on epoch=587
05/20/2022 17:33:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.92 on epoch=589
05/20/2022 17:33:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/20/2022 17:33:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.95 on epoch=594
05/20/2022 17:33:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.99 on epoch=597
05/20/2022 17:33:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.98 on epoch=599
05/20/2022 17:33:27 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.17075892857142858 on epoch=599
05/20/2022 17:33:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/20/2022 17:33:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
05/20/2022 17:33:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.94 on epoch=607
05/20/2022 17:33:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.98 on epoch=609
05/20/2022 17:33:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.92 on epoch=612
05/20/2022 17:33:35 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.19285387081997252 on epoch=612
05/20/2022 17:33:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.97 on epoch=614
05/20/2022 17:33:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.89 on epoch=617
05/20/2022 17:33:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.03 on epoch=619
05/20/2022 17:33:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.93 on epoch=622
05/20/2022 17:33:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/20/2022 17:33:42 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.09589041095890412 on epoch=624
05/20/2022 17:33:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.00 on epoch=627
05/20/2022 17:33:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=629
05/20/2022 17:33:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.88 on epoch=632
05/20/2022 17:33:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/20/2022 17:33:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
05/20/2022 17:33:50 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.16666666666666666 on epoch=637
05/20/2022 17:33:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.04 on epoch=639
05/20/2022 17:33:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.89 on epoch=642
05/20/2022 17:33:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.01 on epoch=644
05/20/2022 17:33:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.97 on epoch=647
05/20/2022 17:33:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.90 on epoch=649
05/20/2022 17:33:57 - INFO - __main__ - Global step 2600 Train loss 0.96 Classification-F1 0.23394278135657448 on epoch=649
05/20/2022 17:33:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.91 on epoch=652
05/20/2022 17:34:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
05/20/2022 17:34:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.90 on epoch=657
05/20/2022 17:34:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.99 on epoch=659
05/20/2022 17:34:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/20/2022 17:34:04 - INFO - __main__ - Global step 2650 Train loss 0.93 Classification-F1 0.09333333333333334 on epoch=662
05/20/2022 17:34:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.02 on epoch=664
05/20/2022 17:34:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
05/20/2022 17:34:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.90 on epoch=669
05/20/2022 17:34:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=672
05/20/2022 17:34:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.00 on epoch=674
05/20/2022 17:34:12 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.20380692599620492 on epoch=674
05/20/2022 17:34:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/20/2022 17:34:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.91 on epoch=679
05/20/2022 17:34:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.88 on epoch=682
05/20/2022 17:34:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/20/2022 17:34:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.89 on epoch=687
05/20/2022 17:34:19 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.1015625 on epoch=687
05/20/2022 17:34:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.11 on epoch=689
05/20/2022 17:34:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.96 on epoch=692
05/20/2022 17:34:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.03 on epoch=694
05/20/2022 17:34:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.90 on epoch=697
05/20/2022 17:34:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.00 on epoch=699
05/20/2022 17:34:26 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.12400635930047696 on epoch=699
05/20/2022 17:34:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.95 on epoch=702
05/20/2022 17:34:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.05 on epoch=704
05/20/2022 17:34:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.94 on epoch=707
05/20/2022 17:34:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/20/2022 17:34:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.92 on epoch=712
05/20/2022 17:34:34 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=712
05/20/2022 17:34:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.93 on epoch=714
05/20/2022 17:34:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.00 on epoch=717
05/20/2022 17:34:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.00 on epoch=719
05/20/2022 17:34:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/20/2022 17:34:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/20/2022 17:34:41 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.15521739130434786 on epoch=724
05/20/2022 17:34:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.92 on epoch=727
05/20/2022 17:34:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.99 on epoch=729
05/20/2022 17:34:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
05/20/2022 17:34:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/20/2022 17:34:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
05/20/2022 17:34:49 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.12228260869565218 on epoch=737
05/20/2022 17:34:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.08 on epoch=739
05/20/2022 17:34:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.96 on epoch=742
05/20/2022 17:34:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/20/2022 17:34:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.90 on epoch=747
05/20/2022 17:34:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.91 on epoch=749
05/20/2022 17:34:56 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1 on epoch=749
05/20/2022 17:34:56 - INFO - __main__ - save last model!
05/20/2022 17:34:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 17:34:56 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 17:34:56 - INFO - __main__ - Printing 3 examples
05/20/2022 17:34:56 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 17:34:56 - INFO - __main__ - ['others']
05/20/2022 17:34:56 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 17:34:56 - INFO - __main__ - ['others']
05/20/2022 17:34:56 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 17:34:56 - INFO - __main__ - ['others']
05/20/2022 17:34:56 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:34:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:34:57 - INFO - __main__ - Printing 3 examples
05/20/2022 17:34:57 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:34:57 - INFO - __main__ - ['others']
05/20/2022 17:34:57 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:34:57 - INFO - __main__ - ['others']
05/20/2022 17:34:57 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:34:57 - INFO - __main__ - ['others']
05/20/2022 17:34:57 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:34:57 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:34:57 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:34:57 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:34:57 - INFO - __main__ - Printing 3 examples
05/20/2022 17:34:57 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:34:57 - INFO - __main__ - ['others']
05/20/2022 17:34:57 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:34:57 - INFO - __main__ - ['others']
05/20/2022 17:34:57 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:34:57 - INFO - __main__ - ['others']
05/20/2022 17:34:57 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:34:57 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:34:57 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:34:59 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:35:04 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:35:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:35:04 - INFO - __main__ - Starting training!
05/20/2022 17:35:05 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 17:35:53 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.4_8_predictions.txt
05/20/2022 17:35:54 - INFO - __main__ - Classification-F1 on test data: 0.0315
05/20/2022 17:35:54 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.2897623608830505, test_performance=0.03154834166311928
05/20/2022 17:35:54 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
05/20/2022 17:35:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:35:55 - INFO - __main__ - Printing 3 examples
05/20/2022 17:35:55 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:35:55 - INFO - __main__ - ['others']
05/20/2022 17:35:55 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:35:55 - INFO - __main__ - ['others']
05/20/2022 17:35:55 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:35:55 - INFO - __main__ - ['others']
05/20/2022 17:35:55 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:35:55 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:35:55 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:35:55 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:35:55 - INFO - __main__ - Printing 3 examples
05/20/2022 17:35:55 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:35:55 - INFO - __main__ - ['others']
05/20/2022 17:35:55 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:35:55 - INFO - __main__ - ['others']
05/20/2022 17:35:55 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:35:55 - INFO - __main__ - ['others']
05/20/2022 17:35:55 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:35:55 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:35:55 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:36:02 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:36:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:36:02 - INFO - __main__ - Starting training!
05/20/2022 17:36:04 - INFO - __main__ - Step 10 Global step 10 Train loss 6.67 on epoch=2
05/20/2022 17:36:05 - INFO - __main__ - Step 20 Global step 20 Train loss 6.58 on epoch=4
05/20/2022 17:36:07 - INFO - __main__ - Step 30 Global step 30 Train loss 6.29 on epoch=7
05/20/2022 17:36:08 - INFO - __main__ - Step 40 Global step 40 Train loss 6.15 on epoch=9
05/20/2022 17:36:09 - INFO - __main__ - Step 50 Global step 50 Train loss 5.94 on epoch=12
05/20/2022 17:36:18 - INFO - __main__ - Global step 50 Train loss 6.32 Classification-F1 0.0 on epoch=12
05/20/2022 17:36:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 17:36:19 - INFO - __main__ - Step 60 Global step 60 Train loss 5.72 on epoch=14
05/20/2022 17:36:21 - INFO - __main__ - Step 70 Global step 70 Train loss 5.55 on epoch=17
05/20/2022 17:36:22 - INFO - __main__ - Step 80 Global step 80 Train loss 5.44 on epoch=19
05/20/2022 17:36:23 - INFO - __main__ - Step 90 Global step 90 Train loss 5.28 on epoch=22
05/20/2022 17:36:25 - INFO - __main__ - Step 100 Global step 100 Train loss 5.08 on epoch=24
05/20/2022 17:36:26 - INFO - __main__ - Global step 100 Train loss 5.41 Classification-F1 0.0 on epoch=24
05/20/2022 17:36:28 - INFO - __main__ - Step 110 Global step 110 Train loss 4.88 on epoch=27
05/20/2022 17:36:29 - INFO - __main__ - Step 120 Global step 120 Train loss 4.79 on epoch=29
05/20/2022 17:36:30 - INFO - __main__ - Step 130 Global step 130 Train loss 4.51 on epoch=32
05/20/2022 17:36:32 - INFO - __main__ - Step 140 Global step 140 Train loss 4.47 on epoch=34
05/20/2022 17:36:33 - INFO - __main__ - Step 150 Global step 150 Train loss 4.41 on epoch=37
05/20/2022 17:36:34 - INFO - __main__ - Global step 150 Train loss 4.61 Classification-F1 0.07915893630179342 on epoch=37
05/20/2022 17:36:34 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07915893630179342 on epoch=37, global_step=150
05/20/2022 17:36:35 - INFO - __main__ - Step 160 Global step 160 Train loss 4.15 on epoch=39
05/20/2022 17:36:37 - INFO - __main__ - Step 170 Global step 170 Train loss 4.13 on epoch=42
05/20/2022 17:36:38 - INFO - __main__ - Step 180 Global step 180 Train loss 3.93 on epoch=44
05/20/2022 17:36:39 - INFO - __main__ - Step 190 Global step 190 Train loss 3.80 on epoch=47
05/20/2022 17:36:41 - INFO - __main__ - Step 200 Global step 200 Train loss 3.82 on epoch=49
05/20/2022 17:36:41 - INFO - __main__ - Global step 200 Train loss 3.96 Classification-F1 0.09477124183006536 on epoch=49
05/20/2022 17:36:41 - INFO - __main__ - Saving model with best Classification-F1: 0.07915893630179342 -> 0.09477124183006536 on epoch=49, global_step=200
05/20/2022 17:36:43 - INFO - __main__ - Step 210 Global step 210 Train loss 3.67 on epoch=52
05/20/2022 17:36:44 - INFO - __main__ - Step 220 Global step 220 Train loss 3.40 on epoch=54
05/20/2022 17:36:45 - INFO - __main__ - Step 230 Global step 230 Train loss 3.49 on epoch=57
05/20/2022 17:36:47 - INFO - __main__ - Step 240 Global step 240 Train loss 3.20 on epoch=59
05/20/2022 17:36:48 - INFO - __main__ - Step 250 Global step 250 Train loss 3.30 on epoch=62
05/20/2022 17:36:49 - INFO - __main__ - Global step 250 Train loss 3.41 Classification-F1 0.16084656084656085 on epoch=62
05/20/2022 17:36:49 - INFO - __main__ - Saving model with best Classification-F1: 0.09477124183006536 -> 0.16084656084656085 on epoch=62, global_step=250
05/20/2022 17:36:50 - INFO - __main__ - Step 260 Global step 260 Train loss 3.37 on epoch=64
05/20/2022 17:36:51 - INFO - __main__ - Step 270 Global step 270 Train loss 3.17 on epoch=67
05/20/2022 17:36:53 - INFO - __main__ - Step 280 Global step 280 Train loss 3.02 on epoch=69
05/20/2022 17:36:54 - INFO - __main__ - Step 290 Global step 290 Train loss 3.09 on epoch=72
05/20/2022 17:36:55 - INFO - __main__ - Step 300 Global step 300 Train loss 2.82 on epoch=74
05/20/2022 17:36:56 - INFO - __main__ - Global step 300 Train loss 3.09 Classification-F1 0.13198653198653199 on epoch=74
05/20/2022 17:36:57 - INFO - __main__ - Step 310 Global step 310 Train loss 3.05 on epoch=77
05/20/2022 17:36:59 - INFO - __main__ - Step 320 Global step 320 Train loss 2.66 on epoch=79
05/20/2022 17:37:00 - INFO - __main__ - Step 330 Global step 330 Train loss 2.89 on epoch=82
05/20/2022 17:37:01 - INFO - __main__ - Step 340 Global step 340 Train loss 2.62 on epoch=84
05/20/2022 17:37:03 - INFO - __main__ - Step 350 Global step 350 Train loss 2.79 on epoch=87
05/20/2022 17:37:03 - INFO - __main__ - Global step 350 Train loss 2.80 Classification-F1 0.13034188034188032 on epoch=87
05/20/2022 17:37:05 - INFO - __main__ - Step 360 Global step 360 Train loss 2.62 on epoch=89
05/20/2022 17:37:06 - INFO - __main__ - Step 370 Global step 370 Train loss 2.69 on epoch=92
05/20/2022 17:37:07 - INFO - __main__ - Step 380 Global step 380 Train loss 2.48 on epoch=94
05/20/2022 17:37:09 - INFO - __main__ - Step 390 Global step 390 Train loss 2.57 on epoch=97
05/20/2022 17:37:10 - INFO - __main__ - Step 400 Global step 400 Train loss 2.47 on epoch=99
05/20/2022 17:37:11 - INFO - __main__ - Global step 400 Train loss 2.57 Classification-F1 0.20804195804195807 on epoch=99
05/20/2022 17:37:11 - INFO - __main__ - Saving model with best Classification-F1: 0.16084656084656085 -> 0.20804195804195807 on epoch=99, global_step=400
05/20/2022 17:37:12 - INFO - __main__ - Step 410 Global step 410 Train loss 2.71 on epoch=102
05/20/2022 17:37:14 - INFO - __main__ - Step 420 Global step 420 Train loss 2.31 on epoch=104
05/20/2022 17:37:15 - INFO - __main__ - Step 430 Global step 430 Train loss 2.44 on epoch=107
05/20/2022 17:37:16 - INFO - __main__ - Step 440 Global step 440 Train loss 2.37 on epoch=109
05/20/2022 17:37:18 - INFO - __main__ - Step 450 Global step 450 Train loss 2.66 on epoch=112
05/20/2022 17:37:18 - INFO - __main__ - Global step 450 Train loss 2.50 Classification-F1 0.14242424242424243 on epoch=112
05/20/2022 17:37:19 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=114
05/20/2022 17:37:21 - INFO - __main__ - Step 470 Global step 470 Train loss 2.43 on epoch=117
05/20/2022 17:37:22 - INFO - __main__ - Step 480 Global step 480 Train loss 2.24 on epoch=119
05/20/2022 17:37:24 - INFO - __main__ - Step 490 Global step 490 Train loss 2.50 on epoch=122
05/20/2022 17:37:25 - INFO - __main__ - Step 500 Global step 500 Train loss 2.10 on epoch=124
05/20/2022 17:37:25 - INFO - __main__ - Global step 500 Train loss 2.32 Classification-F1 0.1565276828434723 on epoch=124
05/20/2022 17:37:27 - INFO - __main__ - Step 510 Global step 510 Train loss 2.22 on epoch=127
05/20/2022 17:37:28 - INFO - __main__ - Step 520 Global step 520 Train loss 2.08 on epoch=129
05/20/2022 17:37:30 - INFO - __main__ - Step 530 Global step 530 Train loss 2.27 on epoch=132
05/20/2022 17:37:31 - INFO - __main__ - Step 540 Global step 540 Train loss 2.01 on epoch=134
05/20/2022 17:37:32 - INFO - __main__ - Step 550 Global step 550 Train loss 2.14 on epoch=137
05/20/2022 17:37:33 - INFO - __main__ - Global step 550 Train loss 2.14 Classification-F1 0.1105263157894737 on epoch=137
05/20/2022 17:37:34 - INFO - __main__ - Step 560 Global step 560 Train loss 2.22 on epoch=139
05/20/2022 17:37:35 - INFO - __main__ - Step 570 Global step 570 Train loss 2.04 on epoch=142
05/20/2022 17:37:37 - INFO - __main__ - Step 580 Global step 580 Train loss 1.98 on epoch=144
05/20/2022 17:37:38 - INFO - __main__ - Step 590 Global step 590 Train loss 2.13 on epoch=147
05/20/2022 17:37:40 - INFO - __main__ - Step 600 Global step 600 Train loss 1.92 on epoch=149
05/20/2022 17:37:40 - INFO - __main__ - Global step 600 Train loss 2.06 Classification-F1 0.16666666666666666 on epoch=149
05/20/2022 17:37:42 - INFO - __main__ - Step 610 Global step 610 Train loss 1.98 on epoch=152
05/20/2022 17:37:43 - INFO - __main__ - Step 620 Global step 620 Train loss 1.95 on epoch=154
05/20/2022 17:37:44 - INFO - __main__ - Step 630 Global step 630 Train loss 2.00 on epoch=157
05/20/2022 17:37:46 - INFO - __main__ - Step 640 Global step 640 Train loss 1.95 on epoch=159
05/20/2022 17:37:47 - INFO - __main__ - Step 650 Global step 650 Train loss 1.96 on epoch=162
05/20/2022 17:37:47 - INFO - __main__ - Global step 650 Train loss 1.97 Classification-F1 0.18614718614718614 on epoch=162
05/20/2022 17:37:49 - INFO - __main__ - Step 660 Global step 660 Train loss 1.67 on epoch=164
05/20/2022 17:37:50 - INFO - __main__ - Step 670 Global step 670 Train loss 1.86 on epoch=167
05/20/2022 17:37:52 - INFO - __main__ - Step 680 Global step 680 Train loss 1.83 on epoch=169
05/20/2022 17:37:53 - INFO - __main__ - Step 690 Global step 690 Train loss 1.74 on epoch=172
05/20/2022 17:37:54 - INFO - __main__ - Step 700 Global step 700 Train loss 1.84 on epoch=174
05/20/2022 17:37:55 - INFO - __main__ - Global step 700 Train loss 1.79 Classification-F1 0.11710526315789474 on epoch=174
05/20/2022 17:37:56 - INFO - __main__ - Step 710 Global step 710 Train loss 1.93 on epoch=177
05/20/2022 17:37:57 - INFO - __main__ - Step 720 Global step 720 Train loss 1.64 on epoch=179
05/20/2022 17:37:59 - INFO - __main__ - Step 730 Global step 730 Train loss 1.72 on epoch=182
05/20/2022 17:38:00 - INFO - __main__ - Step 740 Global step 740 Train loss 1.83 on epoch=184
05/20/2022 17:38:02 - INFO - __main__ - Step 750 Global step 750 Train loss 1.69 on epoch=187
05/20/2022 17:38:02 - INFO - __main__ - Global step 750 Train loss 1.76 Classification-F1 0.09493670886075949 on epoch=187
05/20/2022 17:38:04 - INFO - __main__ - Step 760 Global step 760 Train loss 1.82 on epoch=189
05/20/2022 17:38:05 - INFO - __main__ - Step 770 Global step 770 Train loss 1.57 on epoch=192
05/20/2022 17:38:06 - INFO - __main__ - Step 780 Global step 780 Train loss 1.67 on epoch=194
05/20/2022 17:38:08 - INFO - __main__ - Step 790 Global step 790 Train loss 1.74 on epoch=197
05/20/2022 17:38:09 - INFO - __main__ - Step 800 Global step 800 Train loss 1.51 on epoch=199
05/20/2022 17:38:10 - INFO - __main__ - Global step 800 Train loss 1.66 Classification-F1 0.13936867182846935 on epoch=199
05/20/2022 17:38:11 - INFO - __main__ - Step 810 Global step 810 Train loss 1.65 on epoch=202
05/20/2022 17:38:12 - INFO - __main__ - Step 820 Global step 820 Train loss 1.61 on epoch=204
05/20/2022 17:38:14 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/20/2022 17:38:15 - INFO - __main__ - Step 840 Global step 840 Train loss 1.48 on epoch=209
05/20/2022 17:38:17 - INFO - __main__ - Step 850 Global step 850 Train loss 1.59 on epoch=212
05/20/2022 17:38:17 - INFO - __main__ - Global step 850 Train loss 1.60 Classification-F1 0.13624338624338622 on epoch=212
05/20/2022 17:38:18 - INFO - __main__ - Step 860 Global step 860 Train loss 1.57 on epoch=214
05/20/2022 17:38:20 - INFO - __main__ - Step 870 Global step 870 Train loss 1.42 on epoch=217
05/20/2022 17:38:21 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
05/20/2022 17:38:23 - INFO - __main__ - Step 890 Global step 890 Train loss 1.49 on epoch=222
05/20/2022 17:38:24 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
05/20/2022 17:38:24 - INFO - __main__ - Global step 900 Train loss 1.46 Classification-F1 0.19016393442622948 on epoch=224
05/20/2022 17:38:26 - INFO - __main__ - Step 910 Global step 910 Train loss 1.58 on epoch=227
05/20/2022 17:38:27 - INFO - __main__ - Step 920 Global step 920 Train loss 1.27 on epoch=229
05/20/2022 17:38:28 - INFO - __main__ - Step 930 Global step 930 Train loss 1.41 on epoch=232
05/20/2022 17:38:30 - INFO - __main__ - Step 940 Global step 940 Train loss 1.42 on epoch=234
05/20/2022 17:38:31 - INFO - __main__ - Step 950 Global step 950 Train loss 1.54 on epoch=237
05/20/2022 17:38:32 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.1576923076923077 on epoch=237
05/20/2022 17:38:33 - INFO - __main__ - Step 960 Global step 960 Train loss 1.30 on epoch=239
05/20/2022 17:38:34 - INFO - __main__ - Step 970 Global step 970 Train loss 1.56 on epoch=242
05/20/2022 17:38:35 - INFO - __main__ - Step 980 Global step 980 Train loss 1.32 on epoch=244
05/20/2022 17:38:37 - INFO - __main__ - Step 990 Global step 990 Train loss 1.37 on epoch=247
05/20/2022 17:38:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.36 on epoch=249
05/20/2022 17:38:39 - INFO - __main__ - Global step 1000 Train loss 1.38 Classification-F1 0.1302118933697881 on epoch=249
05/20/2022 17:38:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.43 on epoch=252
05/20/2022 17:38:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
05/20/2022 17:38:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.24 on epoch=257
05/20/2022 17:38:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.36 on epoch=259
05/20/2022 17:38:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.57 on epoch=262
05/20/2022 17:38:46 - INFO - __main__ - Global step 1050 Train loss 1.39 Classification-F1 0.08333333333333333 on epoch=262
05/20/2022 17:38:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.32 on epoch=264
05/20/2022 17:38:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.58 on epoch=267
05/20/2022 17:38:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.35 on epoch=269
05/20/2022 17:38:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.46 on epoch=272
05/20/2022 17:38:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
05/20/2022 17:38:53 - INFO - __main__ - Global step 1100 Train loss 1.38 Classification-F1 0.09333333333333334 on epoch=274
05/20/2022 17:38:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/20/2022 17:38:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.32 on epoch=279
05/20/2022 17:38:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.22 on epoch=282
05/20/2022 17:38:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.39 on epoch=284
05/20/2022 17:38:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.17 on epoch=287
05/20/2022 17:39:00 - INFO - __main__ - Global step 1150 Train loss 1.27 Classification-F1 0.1 on epoch=287
05/20/2022 17:39:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.21 on epoch=289
05/20/2022 17:39:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.28 on epoch=292
05/20/2022 17:39:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.20 on epoch=294
05/20/2022 17:39:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.37 on epoch=297
05/20/2022 17:39:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.27 on epoch=299
05/20/2022 17:39:08 - INFO - __main__ - Global step 1200 Train loss 1.26 Classification-F1 0.1 on epoch=299
05/20/2022 17:39:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.35 on epoch=302
05/20/2022 17:39:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.22 on epoch=304
05/20/2022 17:39:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=307
05/20/2022 17:39:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.30 on epoch=309
05/20/2022 17:39:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.24 on epoch=312
05/20/2022 17:39:15 - INFO - __main__ - Global step 1250 Train loss 1.28 Classification-F1 0.10256410256410256 on epoch=312
05/20/2022 17:39:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
05/20/2022 17:39:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.38 on epoch=317
05/20/2022 17:39:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.23 on epoch=319
05/20/2022 17:39:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.15 on epoch=322
05/20/2022 17:39:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.13 on epoch=324
05/20/2022 17:39:22 - INFO - __main__ - Global step 1300 Train loss 1.24 Classification-F1 0.1611111111111111 on epoch=324
05/20/2022 17:39:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.24 on epoch=327
05/20/2022 17:39:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.18 on epoch=329
05/20/2022 17:39:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.11 on epoch=332
05/20/2022 17:39:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.27 on epoch=334
05/20/2022 17:39:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.21 on epoch=337
05/20/2022 17:39:30 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.1658268437929455 on epoch=337
05/20/2022 17:39:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/20/2022 17:39:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.20 on epoch=342
05/20/2022 17:39:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.29 on epoch=344
05/20/2022 17:39:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.16 on epoch=347
05/20/2022 17:39:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
05/20/2022 17:39:37 - INFO - __main__ - Global step 1400 Train loss 1.21 Classification-F1 0.10126582278481013 on epoch=349
05/20/2022 17:39:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.24 on epoch=352
05/20/2022 17:39:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.28 on epoch=354
05/20/2022 17:39:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.15 on epoch=357
05/20/2022 17:39:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.21 on epoch=359
05/20/2022 17:39:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.21 on epoch=362
05/20/2022 17:39:44 - INFO - __main__ - Global step 1450 Train loss 1.22 Classification-F1 0.13034188034188032 on epoch=362
05/20/2022 17:39:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.21 on epoch=364
05/20/2022 17:39:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.26 on epoch=367
05/20/2022 17:39:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
05/20/2022 17:39:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/20/2022 17:39:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.18 on epoch=374
05/20/2022 17:39:52 - INFO - __main__ - Global step 1500 Train loss 1.19 Classification-F1 0.10126582278481013 on epoch=374
05/20/2022 17:39:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.16 on epoch=377
05/20/2022 17:39:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.18 on epoch=379
05/20/2022 17:39:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.14 on epoch=382
05/20/2022 17:39:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.14 on epoch=384
05/20/2022 17:39:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=387
05/20/2022 17:39:59 - INFO - __main__ - Global step 1550 Train loss 1.16 Classification-F1 0.0901639344262295 on epoch=387
05/20/2022 17:40:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.15 on epoch=389
05/20/2022 17:40:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.22 on epoch=392
05/20/2022 17:40:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.11 on epoch=394
05/20/2022 17:40:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
05/20/2022 17:40:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
05/20/2022 17:40:06 - INFO - __main__ - Global step 1600 Train loss 1.14 Classification-F1 0.13846153846153847 on epoch=399
05/20/2022 17:40:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.11 on epoch=402
05/20/2022 17:40:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.24 on epoch=404
05/20/2022 17:40:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.15 on epoch=407
05/20/2022 17:40:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.07 on epoch=409
05/20/2022 17:40:13 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.10 on epoch=412
05/20/2022 17:40:13 - INFO - __main__ - Global step 1650 Train loss 1.13 Classification-F1 0.20555555555555555 on epoch=412
05/20/2022 17:40:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.13 on epoch=414
05/20/2022 17:40:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.25 on epoch=417
05/20/2022 17:40:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.19 on epoch=419
05/20/2022 17:40:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.18 on epoch=422
05/20/2022 17:40:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
05/20/2022 17:40:21 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.20853462157809982 on epoch=424
05/20/2022 17:40:21 - INFO - __main__ - Saving model with best Classification-F1: 0.20804195804195807 -> 0.20853462157809982 on epoch=424, global_step=1700
05/20/2022 17:40:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.23 on epoch=427
05/20/2022 17:40:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=429
05/20/2022 17:40:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.17 on epoch=432
05/20/2022 17:40:26 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.07 on epoch=434
05/20/2022 17:40:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.13 on epoch=437
05/20/2022 17:40:28 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.18055555555555555 on epoch=437
05/20/2022 17:40:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
05/20/2022 17:40:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.05 on epoch=442
05/20/2022 17:40:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.99 on epoch=444
05/20/2022 17:40:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/20/2022 17:40:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.11 on epoch=449
05/20/2022 17:40:36 - INFO - __main__ - Global step 1800 Train loss 1.04 Classification-F1 0.13427800269905532 on epoch=449
05/20/2022 17:40:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.12 on epoch=452
05/20/2022 17:40:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.03 on epoch=454
05/20/2022 17:40:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.17 on epoch=457
05/20/2022 17:40:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.03 on epoch=459
05/20/2022 17:40:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.22 on epoch=462
05/20/2022 17:40:43 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.09493670886075949 on epoch=462
05/20/2022 17:40:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=464
05/20/2022 17:40:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.05 on epoch=467
05/20/2022 17:40:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.09 on epoch=469
05/20/2022 17:40:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.20 on epoch=472
05/20/2022 17:40:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/20/2022 17:40:50 - INFO - __main__ - Global step 1900 Train loss 1.11 Classification-F1 0.12575757575757576 on epoch=474
05/20/2022 17:40:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.09 on epoch=477
05/20/2022 17:40:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
05/20/2022 17:40:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
05/20/2022 17:40:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.18 on epoch=484
05/20/2022 17:40:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.17 on epoch=487
05/20/2022 17:40:58 - INFO - __main__ - Global step 1950 Train loss 1.11 Classification-F1 0.09999999999999999 on epoch=487
05/20/2022 17:40:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=489
05/20/2022 17:41:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.07 on epoch=492
05/20/2022 17:41:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.15 on epoch=494
05/20/2022 17:41:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.03 on epoch=497
05/20/2022 17:41:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.18 on epoch=499
05/20/2022 17:41:05 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.07638888888888888 on epoch=499
05/20/2022 17:41:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.21 on epoch=502
05/20/2022 17:41:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.01 on epoch=504
05/20/2022 17:41:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.96 on epoch=507
05/20/2022 17:41:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.20 on epoch=509
05/20/2022 17:41:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.11 on epoch=512
05/20/2022 17:41:12 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.07258064516129033 on epoch=512
05/20/2022 17:41:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/20/2022 17:41:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.12 on epoch=517
05/20/2022 17:41:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.18 on epoch=519
05/20/2022 17:41:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.16 on epoch=522
05/20/2022 17:41:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.01 on epoch=524
05/20/2022 17:41:20 - INFO - __main__ - Global step 2100 Train loss 1.10 Classification-F1 0.12417582417582418 on epoch=524
05/20/2022 17:41:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.12 on epoch=527
05/20/2022 17:41:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.10 on epoch=529
05/20/2022 17:41:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.09 on epoch=532
05/20/2022 17:41:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.97 on epoch=534
05/20/2022 17:41:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.08 on epoch=537
05/20/2022 17:41:28 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.09615384615384615 on epoch=537
05/20/2022 17:41:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/20/2022 17:41:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.09 on epoch=542
05/20/2022 17:41:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.96 on epoch=544
05/20/2022 17:41:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/20/2022 17:41:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.99 on epoch=549
05/20/2022 17:41:36 - INFO - __main__ - Global step 2200 Train loss 1.02 Classification-F1 0.09615384615384615 on epoch=549
05/20/2022 17:41:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.09 on epoch=552
05/20/2022 17:41:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.17 on epoch=554
05/20/2022 17:41:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/20/2022 17:41:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.03 on epoch=559
05/20/2022 17:41:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/20/2022 17:41:44 - INFO - __main__ - Global step 2250 Train loss 1.08 Classification-F1 0.11996779388083736 on epoch=562
05/20/2022 17:41:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.16 on epoch=564
05/20/2022 17:41:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.14 on epoch=567
05/20/2022 17:41:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/20/2022 17:41:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/20/2022 17:41:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.05 on epoch=574
05/20/2022 17:41:51 - INFO - __main__ - Global step 2300 Train loss 1.08 Classification-F1 0.13154929577464788 on epoch=574
05/20/2022 17:41:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.96 on epoch=577
05/20/2022 17:41:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=579
05/20/2022 17:41:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.11 on epoch=582
05/20/2022 17:41:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.01 on epoch=584
05/20/2022 17:41:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.12 on epoch=587
05/20/2022 17:41:59 - INFO - __main__ - Global step 2350 Train loss 1.06 Classification-F1 0.1 on epoch=587
05/20/2022 17:42:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
05/20/2022 17:42:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.98 on epoch=592
05/20/2022 17:42:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/20/2022 17:42:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.03 on epoch=597
05/20/2022 17:42:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.09 on epoch=599
05/20/2022 17:42:06 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.1 on epoch=599
05/20/2022 17:42:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.06 on epoch=602
05/20/2022 17:42:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/20/2022 17:42:11 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.15 on epoch=607
05/20/2022 17:42:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.09 on epoch=609
05/20/2022 17:42:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.04 on epoch=612
05/20/2022 17:42:14 - INFO - __main__ - Global step 2450 Train loss 1.08 Classification-F1 0.09868421052631579 on epoch=612
05/20/2022 17:42:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.12 on epoch=614
05/20/2022 17:42:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.11 on epoch=617
05/20/2022 17:42:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.13 on epoch=619
05/20/2022 17:42:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/20/2022 17:42:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.04 on epoch=624
05/20/2022 17:42:21 - INFO - __main__ - Global step 2500 Train loss 1.09 Classification-F1 0.15490196078431373 on epoch=624
05/20/2022 17:42:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/20/2022 17:42:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
05/20/2022 17:42:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.10 on epoch=632
05/20/2022 17:42:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
05/20/2022 17:42:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.92 on epoch=637
05/20/2022 17:42:29 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.1 on epoch=637
05/20/2022 17:42:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.92 on epoch=639
05/20/2022 17:42:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
05/20/2022 17:42:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.03 on epoch=644
05/20/2022 17:42:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
05/20/2022 17:42:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.18 on epoch=649
05/20/2022 17:42:36 - INFO - __main__ - Global step 2600 Train loss 1.04 Classification-F1 0.17368421052631577 on epoch=649
05/20/2022 17:42:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.10 on epoch=652
05/20/2022 17:42:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.08 on epoch=654
05/20/2022 17:42:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.06 on epoch=657
05/20/2022 17:42:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.98 on epoch=659
05/20/2022 17:42:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/20/2022 17:42:43 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.1717171717171717 on epoch=662
05/20/2022 17:42:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.07 on epoch=664
05/20/2022 17:42:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.03 on epoch=667
05/20/2022 17:42:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.01 on epoch=669
05/20/2022 17:42:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.11 on epoch=672
05/20/2022 17:42:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.04 on epoch=674
05/20/2022 17:42:51 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.1581196581196581 on epoch=674
05/20/2022 17:42:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.08 on epoch=677
05/20/2022 17:42:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.09 on epoch=679
05/20/2022 17:42:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/20/2022 17:42:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
05/20/2022 17:42:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/20/2022 17:42:59 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.11666666666666667 on epoch=687
05/20/2022 17:43:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.04 on epoch=689
05/20/2022 17:43:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/20/2022 17:43:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/20/2022 17:43:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.12 on epoch=697
05/20/2022 17:43:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=699
05/20/2022 17:43:07 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=699
05/20/2022 17:43:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.05 on epoch=702
05/20/2022 17:43:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/20/2022 17:43:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.14 on epoch=707
05/20/2022 17:43:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/20/2022 17:43:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
05/20/2022 17:43:14 - INFO - __main__ - Global step 2850 Train loss 1.01 Classification-F1 0.1 on epoch=712
05/20/2022 17:43:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.04 on epoch=714
05/20/2022 17:43:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/20/2022 17:43:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.05 on epoch=719
05/20/2022 17:43:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.07 on epoch=722
05/20/2022 17:43:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.14 on epoch=724
05/20/2022 17:43:21 - INFO - __main__ - Global step 2900 Train loss 1.06 Classification-F1 0.09589041095890412 on epoch=724
05/20/2022 17:43:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.95 on epoch=727
05/20/2022 17:43:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/20/2022 17:43:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.94 on epoch=732
05/20/2022 17:43:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.93 on epoch=734
05/20/2022 17:43:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.93 on epoch=737
05/20/2022 17:43:29 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.17687747035573123 on epoch=737
05/20/2022 17:43:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/20/2022 17:43:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/20/2022 17:43:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.16 on epoch=744
05/20/2022 17:43:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.94 on epoch=747
05/20/2022 17:43:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/20/2022 17:43:36 - INFO - __main__ - Global step 3000 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=749
05/20/2022 17:43:36 - INFO - __main__ - save last model!
05/20/2022 17:43:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 17:43:36 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 17:43:36 - INFO - __main__ - Printing 3 examples
05/20/2022 17:43:36 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 17:43:36 - INFO - __main__ - ['others']
05/20/2022 17:43:36 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 17:43:36 - INFO - __main__ - ['others']
05/20/2022 17:43:36 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 17:43:36 - INFO - __main__ - ['others']
05/20/2022 17:43:36 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:43:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:43:37 - INFO - __main__ - Printing 3 examples
05/20/2022 17:43:37 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:43:37 - INFO - __main__ - ['others']
05/20/2022 17:43:37 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:43:37 - INFO - __main__ - ['others']
05/20/2022 17:43:37 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:43:37 - INFO - __main__ - ['others']
05/20/2022 17:43:37 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:43:37 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:43:37 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:43:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:43:37 - INFO - __main__ - Printing 3 examples
05/20/2022 17:43:37 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:43:37 - INFO - __main__ - ['others']
05/20/2022 17:43:37 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:43:37 - INFO - __main__ - ['others']
05/20/2022 17:43:37 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:43:37 - INFO - __main__ - ['others']
05/20/2022 17:43:37 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:43:37 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:43:37 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:43:39 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:43:43 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:43:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:43:43 - INFO - __main__ - Starting training!
05/20/2022 17:43:45 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 17:44:29 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.3_8_predictions.txt
05/20/2022 17:44:29 - INFO - __main__ - Classification-F1 on test data: 0.0317
05/20/2022 17:44:29 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.20853462157809982, test_performance=0.03167854221146765
05/20/2022 17:44:29 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
05/20/2022 17:44:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:44:30 - INFO - __main__ - Printing 3 examples
05/20/2022 17:44:30 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/20/2022 17:44:30 - INFO - __main__ - ['others']
05/20/2022 17:44:30 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/20/2022 17:44:30 - INFO - __main__ - ['others']
05/20/2022 17:44:30 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/20/2022 17:44:30 - INFO - __main__ - ['others']
05/20/2022 17:44:30 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:44:30 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:44:30 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:44:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:44:30 - INFO - __main__ - Printing 3 examples
05/20/2022 17:44:30 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/20/2022 17:44:30 - INFO - __main__ - ['others']
05/20/2022 17:44:30 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/20/2022 17:44:30 - INFO - __main__ - ['others']
05/20/2022 17:44:30 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/20/2022 17:44:30 - INFO - __main__ - ['others']
05/20/2022 17:44:30 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:44:30 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:44:30 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:44:36 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:44:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:44:36 - INFO - __main__ - Starting training!
05/20/2022 17:44:37 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=2
05/20/2022 17:44:39 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/20/2022 17:44:40 - INFO - __main__ - Step 30 Global step 30 Train loss 6.43 on epoch=7
05/20/2022 17:44:41 - INFO - __main__ - Step 40 Global step 40 Train loss 6.24 on epoch=9
05/20/2022 17:44:43 - INFO - __main__ - Step 50 Global step 50 Train loss 6.25 on epoch=12
05/20/2022 17:44:47 - INFO - __main__ - Global step 50 Train loss 6.45 Classification-F1 0.0 on epoch=12
05/20/2022 17:44:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 17:44:49 - INFO - __main__ - Step 60 Global step 60 Train loss 6.00 on epoch=14
05/20/2022 17:44:50 - INFO - __main__ - Step 70 Global step 70 Train loss 5.97 on epoch=17
05/20/2022 17:44:52 - INFO - __main__ - Step 80 Global step 80 Train loss 5.78 on epoch=19
05/20/2022 17:44:53 - INFO - __main__ - Step 90 Global step 90 Train loss 5.75 on epoch=22
05/20/2022 17:44:55 - INFO - __main__ - Step 100 Global step 100 Train loss 5.58 on epoch=24
05/20/2022 17:44:57 - INFO - __main__ - Global step 100 Train loss 5.82 Classification-F1 0.0 on epoch=24
05/20/2022 17:44:59 - INFO - __main__ - Step 110 Global step 110 Train loss 5.67 on epoch=27
05/20/2022 17:45:00 - INFO - __main__ - Step 120 Global step 120 Train loss 5.40 on epoch=29
05/20/2022 17:45:01 - INFO - __main__ - Step 130 Global step 130 Train loss 5.37 on epoch=32
05/20/2022 17:45:03 - INFO - __main__ - Step 140 Global step 140 Train loss 5.33 on epoch=34
05/20/2022 17:45:04 - INFO - __main__ - Step 150 Global step 150 Train loss 5.14 on epoch=37
05/20/2022 17:45:06 - INFO - __main__ - Global step 150 Train loss 5.38 Classification-F1 0.0 on epoch=37
05/20/2022 17:45:08 - INFO - __main__ - Step 160 Global step 160 Train loss 4.96 on epoch=39
05/20/2022 17:45:09 - INFO - __main__ - Step 170 Global step 170 Train loss 4.96 on epoch=42
05/20/2022 17:45:11 - INFO - __main__ - Step 180 Global step 180 Train loss 4.91 on epoch=44
05/20/2022 17:45:12 - INFO - __main__ - Step 190 Global step 190 Train loss 4.84 on epoch=47
05/20/2022 17:45:13 - INFO - __main__ - Step 200 Global step 200 Train loss 4.63 on epoch=49
05/20/2022 17:45:16 - INFO - __main__ - Global step 200 Train loss 4.86 Classification-F1 0.009523809523809525 on epoch=49
05/20/2022 17:45:16 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009523809523809525 on epoch=49, global_step=200
05/20/2022 17:45:17 - INFO - __main__ - Step 210 Global step 210 Train loss 4.58 on epoch=52
05/20/2022 17:45:19 - INFO - __main__ - Step 220 Global step 220 Train loss 4.59 on epoch=54
05/20/2022 17:45:20 - INFO - __main__ - Step 230 Global step 230 Train loss 4.45 on epoch=57
05/20/2022 17:45:21 - INFO - __main__ - Step 240 Global step 240 Train loss 4.25 on epoch=59
05/20/2022 17:45:23 - INFO - __main__ - Step 250 Global step 250 Train loss 4.13 on epoch=62
05/20/2022 17:45:24 - INFO - __main__ - Global step 250 Train loss 4.40 Classification-F1 0.15789473684210525 on epoch=62
05/20/2022 17:45:24 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809525 -> 0.15789473684210525 on epoch=62, global_step=250
05/20/2022 17:45:25 - INFO - __main__ - Step 260 Global step 260 Train loss 4.14 on epoch=64
05/20/2022 17:45:26 - INFO - __main__ - Step 270 Global step 270 Train loss 4.06 on epoch=67
05/20/2022 17:45:28 - INFO - __main__ - Step 280 Global step 280 Train loss 3.92 on epoch=69
05/20/2022 17:45:29 - INFO - __main__ - Step 290 Global step 290 Train loss 3.83 on epoch=72
05/20/2022 17:45:30 - INFO - __main__ - Step 300 Global step 300 Train loss 3.86 on epoch=74
05/20/2022 17:45:31 - INFO - __main__ - Global step 300 Train loss 3.96 Classification-F1 0.15339578454332553 on epoch=74
05/20/2022 17:45:32 - INFO - __main__ - Step 310 Global step 310 Train loss 3.81 on epoch=77
05/20/2022 17:45:34 - INFO - __main__ - Step 320 Global step 320 Train loss 3.89 on epoch=79
05/20/2022 17:45:35 - INFO - __main__ - Step 330 Global step 330 Train loss 3.81 on epoch=82
05/20/2022 17:45:36 - INFO - __main__ - Step 340 Global step 340 Train loss 3.67 on epoch=84
05/20/2022 17:45:37 - INFO - __main__ - Step 350 Global step 350 Train loss 3.62 on epoch=87
05/20/2022 17:45:38 - INFO - __main__ - Global step 350 Train loss 3.76 Classification-F1 0.11019607843137255 on epoch=87
05/20/2022 17:45:39 - INFO - __main__ - Step 360 Global step 360 Train loss 3.36 on epoch=89
05/20/2022 17:45:41 - INFO - __main__ - Step 370 Global step 370 Train loss 3.44 on epoch=92
05/20/2022 17:45:42 - INFO - __main__ - Step 380 Global step 380 Train loss 3.23 on epoch=94
05/20/2022 17:45:43 - INFO - __main__ - Step 390 Global step 390 Train loss 3.30 on epoch=97
05/20/2022 17:45:45 - INFO - __main__ - Step 400 Global step 400 Train loss 3.09 on epoch=99
05/20/2022 17:45:45 - INFO - __main__ - Global step 400 Train loss 3.28 Classification-F1 0.1570048309178744 on epoch=99
05/20/2022 17:45:47 - INFO - __main__ - Step 410 Global step 410 Train loss 3.26 on epoch=102
05/20/2022 17:45:48 - INFO - __main__ - Step 420 Global step 420 Train loss 3.12 on epoch=104
05/20/2022 17:45:49 - INFO - __main__ - Step 430 Global step 430 Train loss 3.06 on epoch=107
05/20/2022 17:45:51 - INFO - __main__ - Step 440 Global step 440 Train loss 3.00 on epoch=109
05/20/2022 17:45:52 - INFO - __main__ - Step 450 Global step 450 Train loss 3.04 on epoch=112
05/20/2022 17:45:53 - INFO - __main__ - Global step 450 Train loss 3.09 Classification-F1 0.10126582278481013 on epoch=112
05/20/2022 17:45:54 - INFO - __main__ - Step 460 Global step 460 Train loss 2.97 on epoch=114
05/20/2022 17:45:56 - INFO - __main__ - Step 470 Global step 470 Train loss 2.93 on epoch=117
05/20/2022 17:45:57 - INFO - __main__ - Step 480 Global step 480 Train loss 2.87 on epoch=119
05/20/2022 17:45:58 - INFO - __main__ - Step 490 Global step 490 Train loss 3.10 on epoch=122
05/20/2022 17:46:00 - INFO - __main__ - Step 500 Global step 500 Train loss 2.79 on epoch=124
05/20/2022 17:46:00 - INFO - __main__ - Global step 500 Train loss 2.93 Classification-F1 0.1 on epoch=124
05/20/2022 17:46:01 - INFO - __main__ - Step 510 Global step 510 Train loss 2.96 on epoch=127
05/20/2022 17:46:03 - INFO - __main__ - Step 520 Global step 520 Train loss 2.79 on epoch=129
05/20/2022 17:46:04 - INFO - __main__ - Step 530 Global step 530 Train loss 2.59 on epoch=132
05/20/2022 17:46:06 - INFO - __main__ - Step 540 Global step 540 Train loss 2.84 on epoch=134
05/20/2022 17:46:07 - INFO - __main__ - Step 550 Global step 550 Train loss 2.81 on epoch=137
05/20/2022 17:46:07 - INFO - __main__ - Global step 550 Train loss 2.80 Classification-F1 0.1 on epoch=137
05/20/2022 17:46:09 - INFO - __main__ - Step 560 Global step 560 Train loss 2.53 on epoch=139
05/20/2022 17:46:10 - INFO - __main__ - Step 570 Global step 570 Train loss 2.57 on epoch=142
05/20/2022 17:46:12 - INFO - __main__ - Step 580 Global step 580 Train loss 2.57 on epoch=144
05/20/2022 17:46:13 - INFO - __main__ - Step 590 Global step 590 Train loss 2.67 on epoch=147
05/20/2022 17:46:14 - INFO - __main__ - Step 600 Global step 600 Train loss 2.62 on epoch=149
05/20/2022 17:46:15 - INFO - __main__ - Global step 600 Train loss 2.59 Classification-F1 0.1 on epoch=149
05/20/2022 17:46:16 - INFO - __main__ - Step 610 Global step 610 Train loss 2.53 on epoch=152
05/20/2022 17:46:18 - INFO - __main__ - Step 620 Global step 620 Train loss 2.54 on epoch=154
05/20/2022 17:46:19 - INFO - __main__ - Step 630 Global step 630 Train loss 2.69 on epoch=157
05/20/2022 17:46:20 - INFO - __main__ - Step 640 Global step 640 Train loss 2.39 on epoch=159
05/20/2022 17:46:22 - INFO - __main__ - Step 650 Global step 650 Train loss 2.41 on epoch=162
05/20/2022 17:46:22 - INFO - __main__ - Global step 650 Train loss 2.51 Classification-F1 0.10256410256410256 on epoch=162
05/20/2022 17:46:24 - INFO - __main__ - Step 660 Global step 660 Train loss 2.33 on epoch=164
05/20/2022 17:46:25 - INFO - __main__ - Step 670 Global step 670 Train loss 2.54 on epoch=167
05/20/2022 17:46:26 - INFO - __main__ - Step 680 Global step 680 Train loss 2.31 on epoch=169
05/20/2022 17:46:28 - INFO - __main__ - Step 690 Global step 690 Train loss 2.33 on epoch=172
05/20/2022 17:46:29 - INFO - __main__ - Step 700 Global step 700 Train loss 2.17 on epoch=174
05/20/2022 17:46:30 - INFO - __main__ - Global step 700 Train loss 2.34 Classification-F1 0.10126582278481013 on epoch=174
05/20/2022 17:46:31 - INFO - __main__ - Step 710 Global step 710 Train loss 2.28 on epoch=177
05/20/2022 17:46:32 - INFO - __main__ - Step 720 Global step 720 Train loss 2.32 on epoch=179
05/20/2022 17:46:34 - INFO - __main__ - Step 730 Global step 730 Train loss 2.31 on epoch=182
05/20/2022 17:46:35 - INFO - __main__ - Step 740 Global step 740 Train loss 2.28 on epoch=184
05/20/2022 17:46:37 - INFO - __main__ - Step 750 Global step 750 Train loss 2.35 on epoch=187
05/20/2022 17:46:37 - INFO - __main__ - Global step 750 Train loss 2.31 Classification-F1 0.09615384615384615 on epoch=187
05/20/2022 17:46:39 - INFO - __main__ - Step 760 Global step 760 Train loss 2.13 on epoch=189
05/20/2022 17:46:40 - INFO - __main__ - Step 770 Global step 770 Train loss 2.25 on epoch=192
05/20/2022 17:46:41 - INFO - __main__ - Step 780 Global step 780 Train loss 2.11 on epoch=194
05/20/2022 17:46:43 - INFO - __main__ - Step 790 Global step 790 Train loss 2.28 on epoch=197
05/20/2022 17:46:44 - INFO - __main__ - Step 800 Global step 800 Train loss 2.12 on epoch=199
05/20/2022 17:46:45 - INFO - __main__ - Global step 800 Train loss 2.18 Classification-F1 0.1111111111111111 on epoch=199
05/20/2022 17:46:46 - INFO - __main__ - Step 810 Global step 810 Train loss 2.28 on epoch=202
05/20/2022 17:46:47 - INFO - __main__ - Step 820 Global step 820 Train loss 2.13 on epoch=204
05/20/2022 17:46:49 - INFO - __main__ - Step 830 Global step 830 Train loss 2.23 on epoch=207
05/20/2022 17:46:50 - INFO - __main__ - Step 840 Global step 840 Train loss 2.03 on epoch=209
05/20/2022 17:46:51 - INFO - __main__ - Step 850 Global step 850 Train loss 2.19 on epoch=212
05/20/2022 17:46:52 - INFO - __main__ - Global step 850 Train loss 2.17 Classification-F1 0.1476190476190476 on epoch=212
05/20/2022 17:46:53 - INFO - __main__ - Step 860 Global step 860 Train loss 1.95 on epoch=214
05/20/2022 17:46:55 - INFO - __main__ - Step 870 Global step 870 Train loss 2.08 on epoch=217
05/20/2022 17:46:56 - INFO - __main__ - Step 880 Global step 880 Train loss 1.91 on epoch=219
05/20/2022 17:46:58 - INFO - __main__ - Step 890 Global step 890 Train loss 2.01 on epoch=222
05/20/2022 17:46:59 - INFO - __main__ - Step 900 Global step 900 Train loss 1.82 on epoch=224
05/20/2022 17:47:00 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.17480643240023822 on epoch=224
05/20/2022 17:47:00 - INFO - __main__ - Saving model with best Classification-F1: 0.15789473684210525 -> 0.17480643240023822 on epoch=224, global_step=900
05/20/2022 17:47:01 - INFO - __main__ - Step 910 Global step 910 Train loss 1.94 on epoch=227
05/20/2022 17:47:02 - INFO - __main__ - Step 920 Global step 920 Train loss 1.81 on epoch=229
05/20/2022 17:47:04 - INFO - __main__ - Step 930 Global step 930 Train loss 1.96 on epoch=232
05/20/2022 17:47:05 - INFO - __main__ - Step 940 Global step 940 Train loss 1.78 on epoch=234
05/20/2022 17:47:06 - INFO - __main__ - Step 950 Global step 950 Train loss 1.96 on epoch=237
05/20/2022 17:47:07 - INFO - __main__ - Global step 950 Train loss 1.89 Classification-F1 0.18276972624798712 on epoch=237
05/20/2022 17:47:07 - INFO - __main__ - Saving model with best Classification-F1: 0.17480643240023822 -> 0.18276972624798712 on epoch=237, global_step=950
05/20/2022 17:47:08 - INFO - __main__ - Step 960 Global step 960 Train loss 1.94 on epoch=239
05/20/2022 17:47:10 - INFO - __main__ - Step 970 Global step 970 Train loss 1.95 on epoch=242
05/20/2022 17:47:11 - INFO - __main__ - Step 980 Global step 980 Train loss 1.80 on epoch=244
05/20/2022 17:47:13 - INFO - __main__ - Step 990 Global step 990 Train loss 1.86 on epoch=247
05/20/2022 17:47:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.63 on epoch=249
05/20/2022 17:47:15 - INFO - __main__ - Global step 1000 Train loss 1.84 Classification-F1 0.14563380281690141 on epoch=249
05/20/2022 17:47:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.81 on epoch=252
05/20/2022 17:47:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.61 on epoch=254
05/20/2022 17:47:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.72 on epoch=257
05/20/2022 17:47:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.78 on epoch=259
05/20/2022 17:47:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.81 on epoch=262
05/20/2022 17:47:22 - INFO - __main__ - Global step 1050 Train loss 1.75 Classification-F1 0.21743697478991597 on epoch=262
05/20/2022 17:47:22 - INFO - __main__ - Saving model with best Classification-F1: 0.18276972624798712 -> 0.21743697478991597 on epoch=262, global_step=1050
05/20/2022 17:47:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.67 on epoch=264
05/20/2022 17:47:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.63 on epoch=267
05/20/2022 17:47:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.80 on epoch=269
05/20/2022 17:47:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.65 on epoch=272
05/20/2022 17:47:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.51 on epoch=274
05/20/2022 17:47:29 - INFO - __main__ - Global step 1100 Train loss 1.65 Classification-F1 0.17552334943639292 on epoch=274
05/20/2022 17:47:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.62 on epoch=277
05/20/2022 17:47:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.60 on epoch=279
05/20/2022 17:47:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.66 on epoch=282
05/20/2022 17:47:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.60 on epoch=284
05/20/2022 17:47:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.60 on epoch=287
05/20/2022 17:47:37 - INFO - __main__ - Global step 1150 Train loss 1.61 Classification-F1 0.1302118933697881 on epoch=287
05/20/2022 17:47:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.62 on epoch=289
05/20/2022 17:47:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.69 on epoch=292
05/20/2022 17:47:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.60 on epoch=294
05/20/2022 17:47:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.61 on epoch=297
05/20/2022 17:47:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.63 on epoch=299
05/20/2022 17:47:45 - INFO - __main__ - Global step 1200 Train loss 1.63 Classification-F1 0.11746478873239438 on epoch=299
05/20/2022 17:47:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.51 on epoch=302
05/20/2022 17:47:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.57 on epoch=304
05/20/2022 17:47:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.53 on epoch=307
05/20/2022 17:47:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.51 on epoch=309
05/20/2022 17:47:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.63 on epoch=312
05/20/2022 17:47:53 - INFO - __main__ - Global step 1250 Train loss 1.55 Classification-F1 0.13154929577464788 on epoch=312
05/20/2022 17:47:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.59 on epoch=314
05/20/2022 17:47:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.53 on epoch=317
05/20/2022 17:47:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.43 on epoch=319
05/20/2022 17:47:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.47 on epoch=322
05/20/2022 17:48:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.34 on epoch=324
05/20/2022 17:48:01 - INFO - __main__ - Global step 1300 Train loss 1.47 Classification-F1 0.1640625 on epoch=324
05/20/2022 17:48:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.49 on epoch=327
05/20/2022 17:48:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.46 on epoch=329
05/20/2022 17:48:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.47 on epoch=332
05/20/2022 17:48:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.41 on epoch=334
05/20/2022 17:48:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.37 on epoch=337
05/20/2022 17:48:08 - INFO - __main__ - Global step 1350 Train loss 1.44 Classification-F1 0.1597222222222222 on epoch=337
05/20/2022 17:48:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.57 on epoch=339
05/20/2022 17:48:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.38 on epoch=342
05/20/2022 17:48:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.51 on epoch=344
05/20/2022 17:48:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.47 on epoch=347
05/20/2022 17:48:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.27 on epoch=349
05/20/2022 17:48:16 - INFO - __main__ - Global step 1400 Train loss 1.44 Classification-F1 0.16470588235294115 on epoch=349
05/20/2022 17:48:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.39 on epoch=352
05/20/2022 17:48:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.31 on epoch=354
05/20/2022 17:48:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.49 on epoch=357
05/20/2022 17:48:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.45 on epoch=359
05/20/2022 17:48:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.37 on epoch=362
05/20/2022 17:48:23 - INFO - __main__ - Global step 1450 Train loss 1.40 Classification-F1 0.1875 on epoch=362
05/20/2022 17:48:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.38 on epoch=364
05/20/2022 17:48:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.35 on epoch=367
05/20/2022 17:48:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.44 on epoch=369
05/20/2022 17:48:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.35 on epoch=372
05/20/2022 17:48:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.49 on epoch=374
05/20/2022 17:48:30 - INFO - __main__ - Global step 1500 Train loss 1.40 Classification-F1 0.1457326892109501 on epoch=374
05/20/2022 17:48:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.35 on epoch=377
05/20/2022 17:48:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.23 on epoch=379
05/20/2022 17:48:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.31 on epoch=382
05/20/2022 17:48:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=384
05/20/2022 17:48:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.32 on epoch=387
05/20/2022 17:48:38 - INFO - __main__ - Global step 1550 Train loss 1.29 Classification-F1 0.11485019539730784 on epoch=387
05/20/2022 17:48:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.23 on epoch=389
05/20/2022 17:48:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.26 on epoch=392
05/20/2022 17:48:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=394
05/20/2022 17:48:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.27 on epoch=397
05/20/2022 17:48:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.33 on epoch=399
05/20/2022 17:48:45 - INFO - __main__ - Global step 1600 Train loss 1.26 Classification-F1 0.13154929577464788 on epoch=399
05/20/2022 17:48:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.25 on epoch=402
05/20/2022 17:48:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.27 on epoch=404
05/20/2022 17:48:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.35 on epoch=407
05/20/2022 17:48:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.29 on epoch=409
05/20/2022 17:48:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.39 on epoch=412
05/20/2022 17:48:53 - INFO - __main__ - Global step 1650 Train loss 1.31 Classification-F1 0.13047619047619047 on epoch=412
05/20/2022 17:48:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.27 on epoch=414
05/20/2022 17:48:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.32 on epoch=417
05/20/2022 17:48:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.30 on epoch=419
05/20/2022 17:48:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.33 on epoch=422
05/20/2022 17:49:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.26 on epoch=424
05/20/2022 17:49:00 - INFO - __main__ - Global step 1700 Train loss 1.30 Classification-F1 0.15359477124183005 on epoch=424
05/20/2022 17:49:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.28 on epoch=427
05/20/2022 17:49:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.24 on epoch=429
05/20/2022 17:49:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
05/20/2022 17:49:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.27 on epoch=434
05/20/2022 17:49:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=437
05/20/2022 17:49:07 - INFO - __main__ - Global step 1750 Train loss 1.24 Classification-F1 0.09065934065934066 on epoch=437
05/20/2022 17:49:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.19 on epoch=439
05/20/2022 17:49:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.17 on epoch=442
05/20/2022 17:49:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.18 on epoch=444
05/20/2022 17:49:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.19 on epoch=447
05/20/2022 17:49:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.24 on epoch=449
05/20/2022 17:49:15 - INFO - __main__ - Global step 1800 Train loss 1.19 Classification-F1 0.09109311740890687 on epoch=449
05/20/2022 17:49:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.30 on epoch=452
05/20/2022 17:49:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.22 on epoch=454
05/20/2022 17:49:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.24 on epoch=457
05/20/2022 17:49:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.29 on epoch=459
05/20/2022 17:49:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.26 on epoch=462
05/20/2022 17:49:22 - INFO - __main__ - Global step 1850 Train loss 1.26 Classification-F1 0.15071003206596426 on epoch=462
05/20/2022 17:49:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=464
05/20/2022 17:49:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.17 on epoch=467
05/20/2022 17:49:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.27 on epoch=469
05/20/2022 17:49:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.45 on epoch=472
05/20/2022 17:49:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.24 on epoch=474
05/20/2022 17:49:30 - INFO - __main__ - Global step 1900 Train loss 1.25 Classification-F1 0.1774628879892038 on epoch=474
05/20/2022 17:49:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.25 on epoch=477
05/20/2022 17:49:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.20 on epoch=479
05/20/2022 17:49:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.17 on epoch=482
05/20/2022 17:49:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.12 on epoch=484
05/20/2022 17:49:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.27 on epoch=487
05/20/2022 17:49:37 - INFO - __main__ - Global step 1950 Train loss 1.20 Classification-F1 0.09414519906323185 on epoch=487
05/20/2022 17:49:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.11 on epoch=489
05/20/2022 17:49:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.28 on epoch=492
05/20/2022 17:49:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.24 on epoch=494
05/20/2022 17:49:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
05/20/2022 17:49:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.20 on epoch=499
05/20/2022 17:49:44 - INFO - __main__ - Global step 2000 Train loss 1.18 Classification-F1 0.11781609195402298 on epoch=499
05/20/2022 17:49:46 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.25 on epoch=502
05/20/2022 17:49:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.14 on epoch=504
05/20/2022 17:49:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.20 on epoch=507
05/20/2022 17:49:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.15 on epoch=509
05/20/2022 17:49:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.18 on epoch=512
05/20/2022 17:49:51 - INFO - __main__ - Global step 2050 Train loss 1.18 Classification-F1 0.16451612903225807 on epoch=512
05/20/2022 17:49:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.16 on epoch=514
05/20/2022 17:49:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.22 on epoch=517
05/20/2022 17:49:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.10 on epoch=519
05/20/2022 17:49:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.11 on epoch=522
05/20/2022 17:49:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.08 on epoch=524
05/20/2022 17:49:59 - INFO - __main__ - Global step 2100 Train loss 1.14 Classification-F1 0.14962702939885913 on epoch=524
05/20/2022 17:50:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.15 on epoch=527
05/20/2022 17:50:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.24 on epoch=529
05/20/2022 17:50:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.30 on epoch=532
05/20/2022 17:50:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.22 on epoch=534
05/20/2022 17:50:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.18 on epoch=537
05/20/2022 17:50:06 - INFO - __main__ - Global step 2150 Train loss 1.22 Classification-F1 0.17946136788048553 on epoch=537
05/20/2022 17:50:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.16 on epoch=539
05/20/2022 17:50:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=542
05/20/2022 17:50:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.17 on epoch=544
05/20/2022 17:50:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.25 on epoch=547
05/20/2022 17:50:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.14 on epoch=549
05/20/2022 17:50:13 - INFO - __main__ - Global step 2200 Train loss 1.17 Classification-F1 0.15682382133995038 on epoch=549
05/20/2022 17:50:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.10 on epoch=552
05/20/2022 17:50:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.15 on epoch=554
05/20/2022 17:50:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/20/2022 17:50:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/20/2022 17:50:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/20/2022 17:50:20 - INFO - __main__ - Global step 2250 Train loss 1.12 Classification-F1 0.09210526315789473 on epoch=562
05/20/2022 17:50:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/20/2022 17:50:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.33 on epoch=567
05/20/2022 17:50:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/20/2022 17:50:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.15 on epoch=572
05/20/2022 17:50:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
05/20/2022 17:50:28 - INFO - __main__ - Global step 2300 Train loss 1.15 Classification-F1 0.13626373626373625 on epoch=574
05/20/2022 17:50:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.09 on epoch=577
05/20/2022 17:50:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.13 on epoch=579
05/20/2022 17:50:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.18 on epoch=582
05/20/2022 17:50:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.29 on epoch=584
05/20/2022 17:50:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.11 on epoch=587
05/20/2022 17:50:35 - INFO - __main__ - Global step 2350 Train loss 1.16 Classification-F1 0.1412177985948478 on epoch=587
05/20/2022 17:50:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.07 on epoch=589
05/20/2022 17:50:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.15 on epoch=592
05/20/2022 17:50:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/20/2022 17:50:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.13 on epoch=597
05/20/2022 17:50:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.14 on epoch=599
05/20/2022 17:50:43 - INFO - __main__ - Global step 2400 Train loss 1.11 Classification-F1 0.20634920634920634 on epoch=599
05/20/2022 17:50:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.13 on epoch=602
05/20/2022 17:50:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.11 on epoch=604
05/20/2022 17:50:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.17 on epoch=607
05/20/2022 17:50:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.17 on epoch=609
05/20/2022 17:50:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.03 on epoch=612
05/20/2022 17:50:50 - INFO - __main__ - Global step 2450 Train loss 1.12 Classification-F1 0.13047619047619047 on epoch=612
05/20/2022 17:50:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.09 on epoch=614
05/20/2022 17:50:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.05 on epoch=617
05/20/2022 17:50:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.13 on epoch=619
05/20/2022 17:50:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/20/2022 17:50:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
05/20/2022 17:50:57 - INFO - __main__ - Global step 2500 Train loss 1.08 Classification-F1 0.1497584541062802 on epoch=624
05/20/2022 17:50:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.01 on epoch=627
05/20/2022 17:51:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
05/20/2022 17:51:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.20 on epoch=632
05/20/2022 17:51:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.13 on epoch=634
05/20/2022 17:51:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.21 on epoch=637
05/20/2022 17:51:04 - INFO - __main__ - Global step 2550 Train loss 1.14 Classification-F1 0.15434782608695652 on epoch=637
05/20/2022 17:51:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.12 on epoch=639
05/20/2022 17:51:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.18 on epoch=642
05/20/2022 17:51:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.12 on epoch=644
05/20/2022 17:51:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/20/2022 17:51:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/20/2022 17:51:11 - INFO - __main__ - Global step 2600 Train loss 1.10 Classification-F1 0.15587044534412953 on epoch=649
05/20/2022 17:51:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.06 on epoch=652
05/20/2022 17:51:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.16 on epoch=654
05/20/2022 17:51:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
05/20/2022 17:51:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.24 on epoch=659
05/20/2022 17:51:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.18 on epoch=662
05/20/2022 17:51:19 - INFO - __main__ - Global step 2650 Train loss 1.12 Classification-F1 0.14095238095238094 on epoch=662
05/20/2022 17:51:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.20 on epoch=664
05/20/2022 17:51:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.16 on epoch=667
05/20/2022 17:51:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.08 on epoch=669
05/20/2022 17:51:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.02 on epoch=672
05/20/2022 17:51:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/20/2022 17:51:27 - INFO - __main__ - Global step 2700 Train loss 1.10 Classification-F1 0.12541806020066892 on epoch=674
05/20/2022 17:51:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.06 on epoch=677
05/20/2022 17:51:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.13 on epoch=679
05/20/2022 17:51:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.10 on epoch=682
05/20/2022 17:51:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.08 on epoch=684
05/20/2022 17:51:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.07 on epoch=687
05/20/2022 17:51:34 - INFO - __main__ - Global step 2750 Train loss 1.09 Classification-F1 0.12564102564102564 on epoch=687
05/20/2022 17:51:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.10 on epoch=689
05/20/2022 17:51:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.13 on epoch=692
05/20/2022 17:51:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.10 on epoch=694
05/20/2022 17:51:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
05/20/2022 17:51:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.11 on epoch=699
05/20/2022 17:51:41 - INFO - __main__ - Global step 2800 Train loss 1.09 Classification-F1 0.15260416666666665 on epoch=699
05/20/2022 17:51:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.02 on epoch=702
05/20/2022 17:51:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.09 on epoch=704
05/20/2022 17:51:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.28 on epoch=707
05/20/2022 17:51:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.04 on epoch=709
05/20/2022 17:51:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.11 on epoch=712
05/20/2022 17:51:49 - INFO - __main__ - Global step 2850 Train loss 1.11 Classification-F1 0.12407862407862408 on epoch=712
05/20/2022 17:51:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.15 on epoch=714
05/20/2022 17:51:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.09 on epoch=717
05/20/2022 17:51:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/20/2022 17:51:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.20 on epoch=722
05/20/2022 17:51:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.11 on epoch=724
05/20/2022 17:51:56 - INFO - __main__ - Global step 2900 Train loss 1.11 Classification-F1 0.13430127041742287 on epoch=724
05/20/2022 17:51:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.17 on epoch=727
05/20/2022 17:51:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.20 on epoch=729
05/20/2022 17:52:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.05 on epoch=732
05/20/2022 17:52:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.06 on epoch=734
05/20/2022 17:52:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.05 on epoch=737
05/20/2022 17:52:03 - INFO - __main__ - Global step 2950 Train loss 1.10 Classification-F1 0.1875 on epoch=737
05/20/2022 17:52:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.04 on epoch=739
05/20/2022 17:52:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.10 on epoch=742
05/20/2022 17:52:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.10 on epoch=744
05/20/2022 17:52:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.09 on epoch=747
05/20/2022 17:52:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.18 on epoch=749
05/20/2022 17:52:11 - INFO - __main__ - Global step 3000 Train loss 1.10 Classification-F1 0.13251935675997617 on epoch=749
05/20/2022 17:52:11 - INFO - __main__ - save last model!
05/20/2022 17:52:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 17:52:11 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 17:52:11 - INFO - __main__ - Printing 3 examples
05/20/2022 17:52:11 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 17:52:11 - INFO - __main__ - ['others']
05/20/2022 17:52:11 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 17:52:11 - INFO - __main__ - ['others']
05/20/2022 17:52:11 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 17:52:11 - INFO - __main__ - ['others']
05/20/2022 17:52:11 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:52:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:52:11 - INFO - __main__ - Printing 3 examples
05/20/2022 17:52:11 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 17:52:11 - INFO - __main__ - ['sad']
05/20/2022 17:52:11 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 17:52:11 - INFO - __main__ - ['sad']
05/20/2022 17:52:11 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 17:52:11 - INFO - __main__ - ['sad']
05/20/2022 17:52:11 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:52:11 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:52:11 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:52:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:52:11 - INFO - __main__ - Printing 3 examples
05/20/2022 17:52:11 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 17:52:11 - INFO - __main__ - ['sad']
05/20/2022 17:52:11 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 17:52:11 - INFO - __main__ - ['sad']
05/20/2022 17:52:11 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 17:52:11 - INFO - __main__ - ['sad']
05/20/2022 17:52:11 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:52:11 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:52:11 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:52:13 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:52:17 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:52:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:52:18 - INFO - __main__ - Starting training!
05/20/2022 17:52:19 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 17:53:03 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.2_8_predictions.txt
05/20/2022 17:53:03 - INFO - __main__ - Classification-F1 on test data: 0.0383
05/20/2022 17:53:03 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.21743697478991597, test_performance=0.03826613080547574
05/20/2022 17:53:03 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
05/20/2022 17:53:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:53:04 - INFO - __main__ - Printing 3 examples
05/20/2022 17:53:04 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 17:53:04 - INFO - __main__ - ['sad']
05/20/2022 17:53:04 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 17:53:04 - INFO - __main__ - ['sad']
05/20/2022 17:53:04 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 17:53:04 - INFO - __main__ - ['sad']
05/20/2022 17:53:04 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:53:04 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:53:04 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 17:53:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 17:53:04 - INFO - __main__ - Printing 3 examples
05/20/2022 17:53:04 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 17:53:04 - INFO - __main__ - ['sad']
05/20/2022 17:53:04 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 17:53:04 - INFO - __main__ - ['sad']
05/20/2022 17:53:04 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 17:53:04 - INFO - __main__ - ['sad']
05/20/2022 17:53:04 - INFO - __main__ - Tokenizing Input ...
05/20/2022 17:53:04 - INFO - __main__ - Tokenizing Output ...
05/20/2022 17:53:04 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 17:53:11 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 17:53:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 17:53:11 - INFO - __main__ - Starting training!
05/20/2022 17:53:13 - INFO - __main__ - Step 10 Global step 10 Train loss 6.57 on epoch=2
05/20/2022 17:53:14 - INFO - __main__ - Step 20 Global step 20 Train loss 6.45 on epoch=4
05/20/2022 17:53:16 - INFO - __main__ - Step 30 Global step 30 Train loss 6.23 on epoch=7
05/20/2022 17:53:17 - INFO - __main__ - Step 40 Global step 40 Train loss 5.99 on epoch=9
05/20/2022 17:53:18 - INFO - __main__ - Step 50 Global step 50 Train loss 5.78 on epoch=12
05/20/2022 17:53:22 - INFO - __main__ - Global step 50 Train loss 6.21 Classification-F1 0.0 on epoch=12
05/20/2022 17:53:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 17:53:24 - INFO - __main__ - Step 60 Global step 60 Train loss 5.59 on epoch=14
05/20/2022 17:53:25 - INFO - __main__ - Step 70 Global step 70 Train loss 5.28 on epoch=17
05/20/2022 17:53:27 - INFO - __main__ - Step 80 Global step 80 Train loss 4.97 on epoch=19
05/20/2022 17:53:28 - INFO - __main__ - Step 90 Global step 90 Train loss 4.85 on epoch=22
05/20/2022 17:53:29 - INFO - __main__ - Step 100 Global step 100 Train loss 4.55 on epoch=24
05/20/2022 17:53:30 - INFO - __main__ - Global step 100 Train loss 5.05 Classification-F1 0.06862745098039216 on epoch=24
05/20/2022 17:53:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06862745098039216 on epoch=24, global_step=100
05/20/2022 17:53:32 - INFO - __main__ - Step 110 Global step 110 Train loss 4.41 on epoch=27
05/20/2022 17:53:33 - INFO - __main__ - Step 120 Global step 120 Train loss 4.15 on epoch=29
05/20/2022 17:53:34 - INFO - __main__ - Step 130 Global step 130 Train loss 3.94 on epoch=32
05/20/2022 17:53:36 - INFO - __main__ - Step 140 Global step 140 Train loss 3.64 on epoch=34
05/20/2022 17:53:37 - INFO - __main__ - Step 150 Global step 150 Train loss 3.77 on epoch=37
05/20/2022 17:53:38 - INFO - __main__ - Global step 150 Train loss 3.98 Classification-F1 0.12393162393162392 on epoch=37
05/20/2022 17:53:38 - INFO - __main__ - Saving model with best Classification-F1: 0.06862745098039216 -> 0.12393162393162392 on epoch=37, global_step=150
05/20/2022 17:53:39 - INFO - __main__ - Step 160 Global step 160 Train loss 3.26 on epoch=39
05/20/2022 17:53:41 - INFO - __main__ - Step 170 Global step 170 Train loss 3.44 on epoch=42
05/20/2022 17:53:42 - INFO - __main__ - Step 180 Global step 180 Train loss 3.16 on epoch=44
05/20/2022 17:53:44 - INFO - __main__ - Step 190 Global step 190 Train loss 3.14 on epoch=47
05/20/2022 17:53:45 - INFO - __main__ - Step 200 Global step 200 Train loss 2.96 on epoch=49
05/20/2022 17:53:46 - INFO - __main__ - Global step 200 Train loss 3.19 Classification-F1 0.12145748987854252 on epoch=49
05/20/2022 17:53:47 - INFO - __main__ - Step 210 Global step 210 Train loss 3.09 on epoch=52
05/20/2022 17:53:48 - INFO - __main__ - Step 220 Global step 220 Train loss 2.88 on epoch=54
05/20/2022 17:53:50 - INFO - __main__ - Step 230 Global step 230 Train loss 3.04 on epoch=57
05/20/2022 17:53:51 - INFO - __main__ - Step 240 Global step 240 Train loss 2.77 on epoch=59
05/20/2022 17:53:53 - INFO - __main__ - Step 250 Global step 250 Train loss 2.84 on epoch=62
05/20/2022 17:53:53 - INFO - __main__ - Global step 250 Train loss 2.92 Classification-F1 0.1682769726247987 on epoch=62
05/20/2022 17:53:53 - INFO - __main__ - Saving model with best Classification-F1: 0.12393162393162392 -> 0.1682769726247987 on epoch=62, global_step=250
05/20/2022 17:53:55 - INFO - __main__ - Step 260 Global step 260 Train loss 2.77 on epoch=64
05/20/2022 17:53:56 - INFO - __main__ - Step 270 Global step 270 Train loss 2.87 on epoch=67
05/20/2022 17:53:57 - INFO - __main__ - Step 280 Global step 280 Train loss 2.46 on epoch=69
05/20/2022 17:53:59 - INFO - __main__ - Step 290 Global step 290 Train loss 2.74 on epoch=72
05/20/2022 17:54:00 - INFO - __main__ - Step 300 Global step 300 Train loss 2.60 on epoch=74
05/20/2022 17:54:01 - INFO - __main__ - Global step 300 Train loss 2.69 Classification-F1 0.1 on epoch=74
05/20/2022 17:54:02 - INFO - __main__ - Step 310 Global step 310 Train loss 2.70 on epoch=77
05/20/2022 17:54:04 - INFO - __main__ - Step 320 Global step 320 Train loss 2.42 on epoch=79
05/20/2022 17:54:05 - INFO - __main__ - Step 330 Global step 330 Train loss 2.60 on epoch=82
05/20/2022 17:54:06 - INFO - __main__ - Step 340 Global step 340 Train loss 2.40 on epoch=84
05/20/2022 17:54:08 - INFO - __main__ - Step 350 Global step 350 Train loss 2.45 on epoch=87
05/20/2022 17:54:08 - INFO - __main__ - Global step 350 Train loss 2.51 Classification-F1 0.1 on epoch=87
05/20/2022 17:54:10 - INFO - __main__ - Step 360 Global step 360 Train loss 2.09 on epoch=89
05/20/2022 17:54:11 - INFO - __main__ - Step 370 Global step 370 Train loss 2.32 on epoch=92
05/20/2022 17:54:13 - INFO - __main__ - Step 380 Global step 380 Train loss 2.28 on epoch=94
05/20/2022 17:54:14 - INFO - __main__ - Step 390 Global step 390 Train loss 2.28 on epoch=97
05/20/2022 17:54:16 - INFO - __main__ - Step 400 Global step 400 Train loss 2.20 on epoch=99
05/20/2022 17:54:16 - INFO - __main__ - Global step 400 Train loss 2.24 Classification-F1 0.09615384615384615 on epoch=99
05/20/2022 17:54:18 - INFO - __main__ - Step 410 Global step 410 Train loss 2.12 on epoch=102
05/20/2022 17:54:19 - INFO - __main__ - Step 420 Global step 420 Train loss 2.13 on epoch=104
05/20/2022 17:54:21 - INFO - __main__ - Step 430 Global step 430 Train loss 2.12 on epoch=107
05/20/2022 17:54:22 - INFO - __main__ - Step 440 Global step 440 Train loss 1.94 on epoch=109
05/20/2022 17:54:23 - INFO - __main__ - Step 450 Global step 450 Train loss 1.93 on epoch=112
05/20/2022 17:54:24 - INFO - __main__ - Global step 450 Train loss 2.05 Classification-F1 0.14915966386554622 on epoch=112
05/20/2022 17:54:25 - INFO - __main__ - Step 460 Global step 460 Train loss 1.96 on epoch=114
05/20/2022 17:54:27 - INFO - __main__ - Step 470 Global step 470 Train loss 1.91 on epoch=117
05/20/2022 17:54:28 - INFO - __main__ - Step 480 Global step 480 Train loss 1.83 on epoch=119
05/20/2022 17:54:29 - INFO - __main__ - Step 490 Global step 490 Train loss 1.76 on epoch=122
05/20/2022 17:54:31 - INFO - __main__ - Step 500 Global step 500 Train loss 1.68 on epoch=124
05/20/2022 17:54:32 - INFO - __main__ - Global step 500 Train loss 1.83 Classification-F1 0.13968957871396895 on epoch=124
05/20/2022 17:54:33 - INFO - __main__ - Step 510 Global step 510 Train loss 1.77 on epoch=127
05/20/2022 17:54:34 - INFO - __main__ - Step 520 Global step 520 Train loss 1.69 on epoch=129
05/20/2022 17:54:36 - INFO - __main__ - Step 530 Global step 530 Train loss 1.75 on epoch=132
05/20/2022 17:54:37 - INFO - __main__ - Step 540 Global step 540 Train loss 1.73 on epoch=134
05/20/2022 17:54:39 - INFO - __main__ - Step 550 Global step 550 Train loss 1.70 on epoch=137
05/20/2022 17:54:39 - INFO - __main__ - Global step 550 Train loss 1.73 Classification-F1 0.170995670995671 on epoch=137
05/20/2022 17:54:39 - INFO - __main__ - Saving model with best Classification-F1: 0.1682769726247987 -> 0.170995670995671 on epoch=137, global_step=550
05/20/2022 17:54:41 - INFO - __main__ - Step 560 Global step 560 Train loss 1.55 on epoch=139
05/20/2022 17:54:42 - INFO - __main__ - Step 570 Global step 570 Train loss 1.57 on epoch=142
05/20/2022 17:54:44 - INFO - __main__ - Step 580 Global step 580 Train loss 1.66 on epoch=144
05/20/2022 17:54:45 - INFO - __main__ - Step 590 Global step 590 Train loss 1.61 on epoch=147
05/20/2022 17:54:46 - INFO - __main__ - Step 600 Global step 600 Train loss 1.55 on epoch=149
05/20/2022 17:54:47 - INFO - __main__ - Global step 600 Train loss 1.59 Classification-F1 0.1 on epoch=149
05/20/2022 17:54:48 - INFO - __main__ - Step 610 Global step 610 Train loss 1.51 on epoch=152
05/20/2022 17:54:50 - INFO - __main__ - Step 620 Global step 620 Train loss 1.34 on epoch=154
05/20/2022 17:54:51 - INFO - __main__ - Step 630 Global step 630 Train loss 1.44 on epoch=157
05/20/2022 17:54:52 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=159
05/20/2022 17:54:54 - INFO - __main__ - Step 650 Global step 650 Train loss 1.32 on epoch=162
05/20/2022 17:54:54 - INFO - __main__ - Global step 650 Train loss 1.41 Classification-F1 0.09493670886075949 on epoch=162
05/20/2022 17:54:56 - INFO - __main__ - Step 660 Global step 660 Train loss 1.40 on epoch=164
05/20/2022 17:54:57 - INFO - __main__ - Step 670 Global step 670 Train loss 1.46 on epoch=167
05/20/2022 17:54:58 - INFO - __main__ - Step 680 Global step 680 Train loss 1.32 on epoch=169
05/20/2022 17:55:00 - INFO - __main__ - Step 690 Global step 690 Train loss 1.43 on epoch=172
05/20/2022 17:55:01 - INFO - __main__ - Step 700 Global step 700 Train loss 1.44 on epoch=174
05/20/2022 17:55:02 - INFO - __main__ - Global step 700 Train loss 1.41 Classification-F1 0.1 on epoch=174
05/20/2022 17:55:03 - INFO - __main__ - Step 710 Global step 710 Train loss 1.45 on epoch=177
05/20/2022 17:55:05 - INFO - __main__ - Step 720 Global step 720 Train loss 1.39 on epoch=179
05/20/2022 17:55:06 - INFO - __main__ - Step 730 Global step 730 Train loss 1.31 on epoch=182
05/20/2022 17:55:08 - INFO - __main__ - Step 740 Global step 740 Train loss 1.29 on epoch=184
05/20/2022 17:55:09 - INFO - __main__ - Step 750 Global step 750 Train loss 1.34 on epoch=187
05/20/2022 17:55:09 - INFO - __main__ - Global step 750 Train loss 1.36 Classification-F1 0.09493670886075949 on epoch=187
05/20/2022 17:55:11 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=189
05/20/2022 17:55:12 - INFO - __main__ - Step 770 Global step 770 Train loss 1.30 on epoch=192
05/20/2022 17:55:14 - INFO - __main__ - Step 780 Global step 780 Train loss 1.29 on epoch=194
05/20/2022 17:55:15 - INFO - __main__ - Step 790 Global step 790 Train loss 1.26 on epoch=197
05/20/2022 17:55:17 - INFO - __main__ - Step 800 Global step 800 Train loss 1.31 on epoch=199
05/20/2022 17:55:17 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.1 on epoch=199
05/20/2022 17:55:19 - INFO - __main__ - Step 810 Global step 810 Train loss 1.44 on epoch=202
05/20/2022 17:55:20 - INFO - __main__ - Step 820 Global step 820 Train loss 1.17 on epoch=204
05/20/2022 17:55:21 - INFO - __main__ - Step 830 Global step 830 Train loss 1.25 on epoch=207
05/20/2022 17:55:23 - INFO - __main__ - Step 840 Global step 840 Train loss 1.26 on epoch=209
05/20/2022 17:55:24 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=212
05/20/2022 17:55:25 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.11732186732186733 on epoch=212
05/20/2022 17:55:26 - INFO - __main__ - Step 860 Global step 860 Train loss 1.22 on epoch=214
05/20/2022 17:55:28 - INFO - __main__ - Step 870 Global step 870 Train loss 1.21 on epoch=217
05/20/2022 17:55:29 - INFO - __main__ - Step 880 Global step 880 Train loss 1.23 on epoch=219
05/20/2022 17:55:31 - INFO - __main__ - Step 890 Global step 890 Train loss 1.14 on epoch=222
05/20/2022 17:55:32 - INFO - __main__ - Step 900 Global step 900 Train loss 1.23 on epoch=224
05/20/2022 17:55:33 - INFO - __main__ - Global step 900 Train loss 1.21 Classification-F1 0.13611111111111113 on epoch=224
05/20/2022 17:55:34 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=227
05/20/2022 17:55:35 - INFO - __main__ - Step 920 Global step 920 Train loss 1.28 on epoch=229
05/20/2022 17:55:37 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=232
05/20/2022 17:55:38 - INFO - __main__ - Step 940 Global step 940 Train loss 1.32 on epoch=234
05/20/2022 17:55:40 - INFO - __main__ - Step 950 Global step 950 Train loss 1.16 on epoch=237
05/20/2022 17:55:40 - INFO - __main__ - Global step 950 Train loss 1.26 Classification-F1 0.14915966386554622 on epoch=237
05/20/2022 17:55:42 - INFO - __main__ - Step 960 Global step 960 Train loss 1.18 on epoch=239
05/20/2022 17:55:43 - INFO - __main__ - Step 970 Global step 970 Train loss 1.04 on epoch=242
05/20/2022 17:55:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.27 on epoch=244
05/20/2022 17:55:46 - INFO - __main__ - Step 990 Global step 990 Train loss 1.06 on epoch=247
05/20/2022 17:55:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.27 on epoch=249
05/20/2022 17:55:48 - INFO - __main__ - Global step 1000 Train loss 1.16 Classification-F1 0.11762954139368673 on epoch=249
05/20/2022 17:55:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.12 on epoch=252
05/20/2022 17:55:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.16 on epoch=254
05/20/2022 17:55:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.25 on epoch=257
05/20/2022 17:55:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.21 on epoch=259
05/20/2022 17:55:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.16 on epoch=262
05/20/2022 17:55:56 - INFO - __main__ - Global step 1050 Train loss 1.18 Classification-F1 0.09615384615384615 on epoch=262
05/20/2022 17:55:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.19 on epoch=264
05/20/2022 17:55:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=267
05/20/2022 17:56:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
05/20/2022 17:56:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.18 on epoch=272
05/20/2022 17:56:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
05/20/2022 17:56:03 - INFO - __main__ - Global step 1100 Train loss 1.15 Classification-F1 0.11177278973889145 on epoch=274
05/20/2022 17:56:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/20/2022 17:56:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.22 on epoch=279
05/20/2022 17:56:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.19 on epoch=282
05/20/2022 17:56:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.20 on epoch=284
05/20/2022 17:56:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=287
05/20/2022 17:56:11 - INFO - __main__ - Global step 1150 Train loss 1.20 Classification-F1 0.14753320683111953 on epoch=287
05/20/2022 17:56:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.12 on epoch=289
05/20/2022 17:56:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.12 on epoch=292
05/20/2022 17:56:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.12 on epoch=294
05/20/2022 17:56:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.06 on epoch=297
05/20/2022 17:56:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.21 on epoch=299
05/20/2022 17:56:18 - INFO - __main__ - Global step 1200 Train loss 1.12 Classification-F1 0.14771241830065357 on epoch=299
05/20/2022 17:56:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.12 on epoch=302
05/20/2022 17:56:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.18 on epoch=304
05/20/2022 17:56:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=307
05/20/2022 17:56:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/20/2022 17:56:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=312
05/20/2022 17:56:26 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.140625 on epoch=312
05/20/2022 17:56:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.01 on epoch=314
05/20/2022 17:56:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.98 on epoch=317
05/20/2022 17:56:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.21 on epoch=319
05/20/2022 17:56:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.09 on epoch=322
05/20/2022 17:56:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.09 on epoch=324
05/20/2022 17:56:33 - INFO - __main__ - Global step 1300 Train loss 1.08 Classification-F1 0.15356265356265356 on epoch=324
05/20/2022 17:56:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.12 on epoch=327
05/20/2022 17:56:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.19 on epoch=329
05/20/2022 17:56:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.10 on epoch=332
05/20/2022 17:56:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.13 on epoch=334
05/20/2022 17:56:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.12 on epoch=337
05/20/2022 17:56:41 - INFO - __main__ - Global step 1350 Train loss 1.13 Classification-F1 0.10126582278481013 on epoch=337
05/20/2022 17:56:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.09 on epoch=339
05/20/2022 17:56:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=342
05/20/2022 17:56:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=344
05/20/2022 17:56:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.00 on epoch=347
05/20/2022 17:56:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=349
05/20/2022 17:56:49 - INFO - __main__ - Global step 1400 Train loss 1.03 Classification-F1 0.1611111111111111 on epoch=349
05/20/2022 17:56:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.02 on epoch=352
05/20/2022 17:56:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.10 on epoch=354
05/20/2022 17:56:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.09 on epoch=357
05/20/2022 17:56:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.12 on epoch=359
05/20/2022 17:56:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
05/20/2022 17:56:57 - INFO - __main__ - Global step 1450 Train loss 1.09 Classification-F1 0.10126582278481013 on epoch=362
05/20/2022 17:56:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=364
05/20/2022 17:56:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.05 on epoch=367
05/20/2022 17:57:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.93 on epoch=369
05/20/2022 17:57:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.05 on epoch=372
05/20/2022 17:57:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.13 on epoch=374
05/20/2022 17:57:04 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.1796875 on epoch=374
05/20/2022 17:57:04 - INFO - __main__ - Saving model with best Classification-F1: 0.170995670995671 -> 0.1796875 on epoch=374, global_step=1500
05/20/2022 17:57:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.11 on epoch=377
05/20/2022 17:57:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.93 on epoch=379
05/20/2022 17:57:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.01 on epoch=382
05/20/2022 17:57:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.95 on epoch=384
05/20/2022 17:57:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.07 on epoch=387
05/20/2022 17:57:11 - INFO - __main__ - Global step 1550 Train loss 1.01 Classification-F1 0.0974025974025974 on epoch=387
05/20/2022 17:57:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.94 on epoch=389
05/20/2022 17:57:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.05 on epoch=392
05/20/2022 17:57:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.01 on epoch=394
05/20/2022 17:57:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.05 on epoch=397
05/20/2022 17:57:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.03 on epoch=399
05/20/2022 17:57:19 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.12646198830409355 on epoch=399
05/20/2022 17:57:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.06 on epoch=402
05/20/2022 17:57:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/20/2022 17:57:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.13 on epoch=407
05/20/2022 17:57:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.92 on epoch=409
05/20/2022 17:57:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.95 on epoch=412
05/20/2022 17:57:27 - INFO - __main__ - Global step 1650 Train loss 1.01 Classification-F1 0.11722488038277512 on epoch=412
05/20/2022 17:57:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.97 on epoch=414
05/20/2022 17:57:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.09 on epoch=417
05/20/2022 17:57:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.03 on epoch=419
05/20/2022 17:57:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.92 on epoch=422
05/20/2022 17:57:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.99 on epoch=424
05/20/2022 17:57:34 - INFO - __main__ - Global step 1700 Train loss 1.00 Classification-F1 0.12710084033613445 on epoch=424
05/20/2022 17:57:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
05/20/2022 17:57:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.86 on epoch=429
05/20/2022 17:57:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.96 on epoch=432
05/20/2022 17:57:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.00 on epoch=434
05/20/2022 17:57:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.04 on epoch=437
05/20/2022 17:57:41 - INFO - __main__ - Global step 1750 Train loss 0.98 Classification-F1 0.17369852369852368 on epoch=437
05/20/2022 17:57:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
05/20/2022 17:57:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.09 on epoch=442
05/20/2022 17:57:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.06 on epoch=444
05/20/2022 17:57:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.11 on epoch=447
05/20/2022 17:57:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.19 on epoch=449
05/20/2022 17:57:49 - INFO - __main__ - Global step 1800 Train loss 1.09 Classification-F1 0.21286031042128603 on epoch=449
05/20/2022 17:57:49 - INFO - __main__ - Saving model with best Classification-F1: 0.1796875 -> 0.21286031042128603 on epoch=449, global_step=1800
05/20/2022 17:57:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/20/2022 17:57:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.99 on epoch=454
05/20/2022 17:57:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.12 on epoch=457
05/20/2022 17:57:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.00 on epoch=459
05/20/2022 17:57:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/20/2022 17:57:56 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.2034090909090909 on epoch=462
05/20/2022 17:57:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.00 on epoch=464
05/20/2022 17:57:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.98 on epoch=467
05/20/2022 17:58:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.99 on epoch=469
05/20/2022 17:58:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.95 on epoch=472
05/20/2022 17:58:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.93 on epoch=474
05/20/2022 17:58:04 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.1 on epoch=474
05/20/2022 17:58:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.00 on epoch=477
05/20/2022 17:58:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.05 on epoch=479
05/20/2022 17:58:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=482
05/20/2022 17:58:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.01 on epoch=484
05/20/2022 17:58:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.04 on epoch=487
05/20/2022 17:58:11 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.12393162393162392 on epoch=487
05/20/2022 17:58:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.08 on epoch=489
05/20/2022 17:58:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.10 on epoch=492
05/20/2022 17:58:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.03 on epoch=494
05/20/2022 17:58:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.06 on epoch=497
05/20/2022 17:58:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.05 on epoch=499
05/20/2022 17:58:18 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.1 on epoch=499
05/20/2022 17:58:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/20/2022 17:58:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.11 on epoch=504
05/20/2022 17:58:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=507
05/20/2022 17:58:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.06 on epoch=509
05/20/2022 17:58:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.04 on epoch=512
05/20/2022 17:58:25 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.15498891352549887 on epoch=512
05/20/2022 17:58:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=514
05/20/2022 17:58:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.99 on epoch=517
05/20/2022 17:58:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
05/20/2022 17:58:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.88 on epoch=522
05/20/2022 17:58:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.96 on epoch=524
05/20/2022 17:58:33 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.10256410256410256 on epoch=524
05/20/2022 17:58:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/20/2022 17:58:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.95 on epoch=529
05/20/2022 17:58:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
05/20/2022 17:58:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.00 on epoch=534
05/20/2022 17:58:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.09 on epoch=537
05/20/2022 17:58:40 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.1660839160839161 on epoch=537
05/20/2022 17:58:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.05 on epoch=539
05/20/2022 17:58:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.92 on epoch=542
05/20/2022 17:58:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/20/2022 17:58:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.99 on epoch=547
05/20/2022 17:58:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.96 on epoch=549
05/20/2022 17:58:47 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.16963260619977039 on epoch=549
05/20/2022 17:58:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.89 on epoch=552
05/20/2022 17:58:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.00 on epoch=554
05/20/2022 17:58:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.91 on epoch=557
05/20/2022 17:58:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.01 on epoch=559
05/20/2022 17:58:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=562
05/20/2022 17:58:54 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.12407862407862408 on epoch=562
05/20/2022 17:58:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/20/2022 17:58:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=567
05/20/2022 17:58:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.00 on epoch=569
05/20/2022 17:59:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/20/2022 17:59:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/20/2022 17:59:02 - INFO - __main__ - Global step 2300 Train loss 1.01 Classification-F1 0.13067758749069247 on epoch=574
05/20/2022 17:59:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/20/2022 17:59:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.97 on epoch=579
05/20/2022 17:59:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/20/2022 17:59:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.88 on epoch=584
05/20/2022 17:59:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=587
05/20/2022 17:59:10 - INFO - __main__ - Global step 2350 Train loss 0.94 Classification-F1 0.1437908496732026 on epoch=587
05/20/2022 17:59:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.91 on epoch=589
05/20/2022 17:59:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
05/20/2022 17:59:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.95 on epoch=594
05/20/2022 17:59:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/20/2022 17:59:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.96 on epoch=599
05/20/2022 17:59:17 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.13067758749069247 on epoch=599
05/20/2022 17:59:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.02 on epoch=602
05/20/2022 17:59:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/20/2022 17:59:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.92 on epoch=607
05/20/2022 17:59:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
05/20/2022 17:59:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
05/20/2022 17:59:25 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.23392857142857143 on epoch=612
05/20/2022 17:59:25 - INFO - __main__ - Saving model with best Classification-F1: 0.21286031042128603 -> 0.23392857142857143 on epoch=612, global_step=2450
05/20/2022 17:59:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.89 on epoch=614
05/20/2022 17:59:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=617
05/20/2022 17:59:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
05/20/2022 17:59:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
05/20/2022 17:59:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
05/20/2022 17:59:33 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.10126582278481013 on epoch=624
05/20/2022 17:59:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/20/2022 17:59:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.99 on epoch=629
05/20/2022 17:59:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.85 on epoch=632
05/20/2022 17:59:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/20/2022 17:59:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.01 on epoch=637
05/20/2022 17:59:41 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.21869565217391307 on epoch=637
05/20/2022 17:59:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.92 on epoch=639
05/20/2022 17:59:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.84 on epoch=642
05/20/2022 17:59:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.87 on epoch=644
05/20/2022 17:59:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/20/2022 17:59:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/20/2022 17:59:49 - INFO - __main__ - Global step 2600 Train loss 0.92 Classification-F1 0.17694311767260096 on epoch=649
05/20/2022 17:59:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.08 on epoch=652
05/20/2022 17:59:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
05/20/2022 17:59:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=657
05/20/2022 17:59:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
05/20/2022 17:59:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.94 on epoch=662
05/20/2022 17:59:56 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.0974025974025974 on epoch=662
05/20/2022 17:59:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.87 on epoch=664
05/20/2022 17:59:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.99 on epoch=667
05/20/2022 18:00:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.98 on epoch=669
05/20/2022 18:00:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.95 on epoch=672
05/20/2022 18:00:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.96 on epoch=674
05/20/2022 18:00:03 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.1738412346070504 on epoch=674
05/20/2022 18:00:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.90 on epoch=677
05/20/2022 18:00:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.87 on epoch=679
05/20/2022 18:00:07 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.95 on epoch=682
05/20/2022 18:00:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.01 on epoch=684
05/20/2022 18:00:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.96 on epoch=687
05/20/2022 18:00:11 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.13333333333333333 on epoch=687
05/20/2022 18:00:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.89 on epoch=689
05/20/2022 18:00:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.84 on epoch=692
05/20/2022 18:00:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.94 on epoch=694
05/20/2022 18:00:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
05/20/2022 18:00:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.87 on epoch=699
05/20/2022 18:00:18 - INFO - __main__ - Global step 2800 Train loss 0.90 Classification-F1 0.13566098081023453 on epoch=699
05/20/2022 18:00:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.94 on epoch=702
05/20/2022 18:00:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/20/2022 18:00:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.99 on epoch=707
05/20/2022 18:00:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.86 on epoch=709
05/20/2022 18:00:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.83 on epoch=712
05/20/2022 18:00:26 - INFO - __main__ - Global step 2850 Train loss 0.91 Classification-F1 0.15 on epoch=712
05/20/2022 18:00:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
05/20/2022 18:00:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.87 on epoch=717
05/20/2022 18:00:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.93 on epoch=719
05/20/2022 18:00:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.98 on epoch=722
05/20/2022 18:00:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.85 on epoch=724
05/20/2022 18:00:33 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.1 on epoch=724
05/20/2022 18:00:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.94 on epoch=727
05/20/2022 18:00:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.07 on epoch=729
05/20/2022 18:00:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
05/20/2022 18:00:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.92 on epoch=734
05/20/2022 18:00:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.89 on epoch=737
05/20/2022 18:00:41 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.148970398970399 on epoch=737
05/20/2022 18:00:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=739
05/20/2022 18:00:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.88 on epoch=742
05/20/2022 18:00:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.88 on epoch=744
05/20/2022 18:00:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.91 on epoch=747
05/20/2022 18:00:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.88 on epoch=749
05/20/2022 18:00:48 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.13047619047619047 on epoch=749
05/20/2022 18:00:48 - INFO - __main__ - save last model!
05/20/2022 18:00:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 18:00:48 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 18:00:48 - INFO - __main__ - Printing 3 examples
05/20/2022 18:00:48 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 18:00:48 - INFO - __main__ - ['others']
05/20/2022 18:00:48 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 18:00:48 - INFO - __main__ - ['others']
05/20/2022 18:00:48 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 18:00:48 - INFO - __main__ - ['others']
05/20/2022 18:00:48 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:00:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:00:49 - INFO - __main__ - Printing 3 examples
05/20/2022 18:00:49 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 18:00:49 - INFO - __main__ - ['sad']
05/20/2022 18:00:49 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 18:00:49 - INFO - __main__ - ['sad']
05/20/2022 18:00:49 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 18:00:49 - INFO - __main__ - ['sad']
05/20/2022 18:00:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:00:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:00:49 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:00:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:00:49 - INFO - __main__ - Printing 3 examples
05/20/2022 18:00:49 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 18:00:49 - INFO - __main__ - ['sad']
05/20/2022 18:00:49 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 18:00:49 - INFO - __main__ - ['sad']
05/20/2022 18:00:49 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 18:00:49 - INFO - __main__ - ['sad']
05/20/2022 18:00:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:00:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:00:49 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:00:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:00:55 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:00:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:00:55 - INFO - __main__ - Starting training!
05/20/2022 18:00:58 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 18:01:44 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.5_8_predictions.txt
05/20/2022 18:01:44 - INFO - __main__ - Classification-F1 on test data: 0.0474
05/20/2022 18:01:45 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.23392857142857143, test_performance=0.04740650656882946
05/20/2022 18:01:45 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
05/20/2022 18:01:46 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:01:46 - INFO - __main__ - Printing 3 examples
05/20/2022 18:01:46 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 18:01:46 - INFO - __main__ - ['sad']
05/20/2022 18:01:46 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 18:01:46 - INFO - __main__ - ['sad']
05/20/2022 18:01:46 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 18:01:46 - INFO - __main__ - ['sad']
05/20/2022 18:01:46 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:01:46 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:01:46 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:01:46 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:01:46 - INFO - __main__ - Printing 3 examples
05/20/2022 18:01:46 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 18:01:46 - INFO - __main__ - ['sad']
05/20/2022 18:01:46 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 18:01:46 - INFO - __main__ - ['sad']
05/20/2022 18:01:46 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 18:01:46 - INFO - __main__ - ['sad']
05/20/2022 18:01:46 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:01:46 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:01:46 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:01:53 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:01:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:01:53 - INFO - __main__ - Starting training!
05/20/2022 18:01:54 - INFO - __main__ - Step 10 Global step 10 Train loss 6.72 on epoch=2
05/20/2022 18:01:56 - INFO - __main__ - Step 20 Global step 20 Train loss 6.47 on epoch=4
05/20/2022 18:01:57 - INFO - __main__ - Step 30 Global step 30 Train loss 6.25 on epoch=7
05/20/2022 18:01:58 - INFO - __main__ - Step 40 Global step 40 Train loss 6.07 on epoch=9
05/20/2022 18:02:00 - INFO - __main__ - Step 50 Global step 50 Train loss 5.90 on epoch=12
05/20/2022 18:02:03 - INFO - __main__ - Global step 50 Train loss 6.28 Classification-F1 0.0 on epoch=12
05/20/2022 18:02:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 18:02:04 - INFO - __main__ - Step 60 Global step 60 Train loss 5.66 on epoch=14
05/20/2022 18:02:06 - INFO - __main__ - Step 70 Global step 70 Train loss 5.64 on epoch=17
05/20/2022 18:02:07 - INFO - __main__ - Step 80 Global step 80 Train loss 5.40 on epoch=19
05/20/2022 18:02:09 - INFO - __main__ - Step 90 Global step 90 Train loss 5.30 on epoch=22
05/20/2022 18:02:10 - INFO - __main__ - Step 100 Global step 100 Train loss 5.06 on epoch=24
05/20/2022 18:02:11 - INFO - __main__ - Global step 100 Train loss 5.41 Classification-F1 0.0 on epoch=24
05/20/2022 18:02:13 - INFO - __main__ - Step 110 Global step 110 Train loss 5.02 on epoch=27
05/20/2022 18:02:14 - INFO - __main__ - Step 120 Global step 120 Train loss 4.77 on epoch=29
05/20/2022 18:02:16 - INFO - __main__ - Step 130 Global step 130 Train loss 4.71 on epoch=32
05/20/2022 18:02:17 - INFO - __main__ - Step 140 Global step 140 Train loss 4.55 on epoch=34
05/20/2022 18:02:18 - INFO - __main__ - Step 150 Global step 150 Train loss 4.48 on epoch=37
05/20/2022 18:02:19 - INFO - __main__ - Global step 150 Train loss 4.71 Classification-F1 0.03571428571428571 on epoch=37
05/20/2022 18:02:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03571428571428571 on epoch=37, global_step=150
05/20/2022 18:02:21 - INFO - __main__ - Step 160 Global step 160 Train loss 4.19 on epoch=39
05/20/2022 18:02:22 - INFO - __main__ - Step 170 Global step 170 Train loss 4.17 on epoch=42
05/20/2022 18:02:24 - INFO - __main__ - Step 180 Global step 180 Train loss 4.12 on epoch=44
05/20/2022 18:02:25 - INFO - __main__ - Step 190 Global step 190 Train loss 4.15 on epoch=47
05/20/2022 18:02:27 - INFO - __main__ - Step 200 Global step 200 Train loss 4.03 on epoch=49
05/20/2022 18:02:28 - INFO - __main__ - Global step 200 Train loss 4.13 Classification-F1 0.11805555555555555 on epoch=49
05/20/2022 18:02:28 - INFO - __main__ - Saving model with best Classification-F1: 0.03571428571428571 -> 0.11805555555555555 on epoch=49, global_step=200
05/20/2022 18:02:29 - INFO - __main__ - Step 210 Global step 210 Train loss 4.00 on epoch=52
05/20/2022 18:02:30 - INFO - __main__ - Step 220 Global step 220 Train loss 3.85 on epoch=54
05/20/2022 18:02:32 - INFO - __main__ - Step 230 Global step 230 Train loss 3.83 on epoch=57
05/20/2022 18:02:33 - INFO - __main__ - Step 240 Global step 240 Train loss 3.64 on epoch=59
05/20/2022 18:02:35 - INFO - __main__ - Step 250 Global step 250 Train loss 3.60 on epoch=62
05/20/2022 18:02:36 - INFO - __main__ - Global step 250 Train loss 3.78 Classification-F1 0.1283068783068783 on epoch=62
05/20/2022 18:02:36 - INFO - __main__ - Saving model with best Classification-F1: 0.11805555555555555 -> 0.1283068783068783 on epoch=62, global_step=250
05/20/2022 18:02:37 - INFO - __main__ - Step 260 Global step 260 Train loss 3.46 on epoch=64
05/20/2022 18:02:39 - INFO - __main__ - Step 270 Global step 270 Train loss 3.47 on epoch=67
05/20/2022 18:02:41 - INFO - __main__ - Step 280 Global step 280 Train loss 3.26 on epoch=69
05/20/2022 18:02:42 - INFO - __main__ - Step 290 Global step 290 Train loss 3.24 on epoch=72
05/20/2022 18:02:44 - INFO - __main__ - Step 300 Global step 300 Train loss 3.06 on epoch=74
05/20/2022 18:02:44 - INFO - __main__ - Global step 300 Train loss 3.30 Classification-F1 0.15526315789473685 on epoch=74
05/20/2022 18:02:44 - INFO - __main__ - Saving model with best Classification-F1: 0.1283068783068783 -> 0.15526315789473685 on epoch=74, global_step=300
05/20/2022 18:02:45 - INFO - __main__ - Step 310 Global step 310 Train loss 3.04 on epoch=77
05/20/2022 18:02:47 - INFO - __main__ - Step 320 Global step 320 Train loss 3.00 on epoch=79
05/20/2022 18:02:48 - INFO - __main__ - Step 330 Global step 330 Train loss 3.10 on epoch=82
05/20/2022 18:02:50 - INFO - __main__ - Step 340 Global step 340 Train loss 3.02 on epoch=84
05/20/2022 18:02:51 - INFO - __main__ - Step 350 Global step 350 Train loss 3.04 on epoch=87
05/20/2022 18:02:52 - INFO - __main__ - Global step 350 Train loss 3.04 Classification-F1 0.1869328493647913 on epoch=87
05/20/2022 18:02:52 - INFO - __main__ - Saving model with best Classification-F1: 0.15526315789473685 -> 0.1869328493647913 on epoch=87, global_step=350
05/20/2022 18:02:53 - INFO - __main__ - Step 360 Global step 360 Train loss 2.83 on epoch=89
05/20/2022 18:02:54 - INFO - __main__ - Step 370 Global step 370 Train loss 2.81 on epoch=92
05/20/2022 18:02:56 - INFO - __main__ - Step 380 Global step 380 Train loss 2.69 on epoch=94
05/20/2022 18:02:57 - INFO - __main__ - Step 390 Global step 390 Train loss 2.77 on epoch=97
05/20/2022 18:02:59 - INFO - __main__ - Step 400 Global step 400 Train loss 2.53 on epoch=99
05/20/2022 18:02:59 - INFO - __main__ - Global step 400 Train loss 2.73 Classification-F1 0.18888888888888888 on epoch=99
05/20/2022 18:02:59 - INFO - __main__ - Saving model with best Classification-F1: 0.1869328493647913 -> 0.18888888888888888 on epoch=99, global_step=400
05/20/2022 18:03:01 - INFO - __main__ - Step 410 Global step 410 Train loss 2.50 on epoch=102
05/20/2022 18:03:02 - INFO - __main__ - Step 420 Global step 420 Train loss 2.47 on epoch=104
05/20/2022 18:03:03 - INFO - __main__ - Step 430 Global step 430 Train loss 2.51 on epoch=107
05/20/2022 18:03:05 - INFO - __main__ - Step 440 Global step 440 Train loss 2.37 on epoch=109
05/20/2022 18:03:06 - INFO - __main__ - Step 450 Global step 450 Train loss 2.45 on epoch=112
05/20/2022 18:03:07 - INFO - __main__ - Global step 450 Train loss 2.46 Classification-F1 0.10294117647058824 on epoch=112
05/20/2022 18:03:08 - INFO - __main__ - Step 460 Global step 460 Train loss 2.45 on epoch=114
05/20/2022 18:03:09 - INFO - __main__ - Step 470 Global step 470 Train loss 2.44 on epoch=117
05/20/2022 18:03:11 - INFO - __main__ - Step 480 Global step 480 Train loss 2.41 on epoch=119
05/20/2022 18:03:12 - INFO - __main__ - Step 490 Global step 490 Train loss 2.24 on epoch=122
05/20/2022 18:03:14 - INFO - __main__ - Step 500 Global step 500 Train loss 2.29 on epoch=124
05/20/2022 18:03:14 - INFO - __main__ - Global step 500 Train loss 2.37 Classification-F1 0.1237183868762816 on epoch=124
05/20/2022 18:03:16 - INFO - __main__ - Step 510 Global step 510 Train loss 2.29 on epoch=127
05/20/2022 18:03:17 - INFO - __main__ - Step 520 Global step 520 Train loss 2.12 on epoch=129
05/20/2022 18:03:18 - INFO - __main__ - Step 530 Global step 530 Train loss 2.14 on epoch=132
05/20/2022 18:03:20 - INFO - __main__ - Step 540 Global step 540 Train loss 1.98 on epoch=134
05/20/2022 18:03:21 - INFO - __main__ - Step 550 Global step 550 Train loss 2.12 on epoch=137
05/20/2022 18:03:22 - INFO - __main__ - Global step 550 Train loss 2.13 Classification-F1 0.1 on epoch=137
05/20/2022 18:03:23 - INFO - __main__ - Step 560 Global step 560 Train loss 1.86 on epoch=139
05/20/2022 18:03:24 - INFO - __main__ - Step 570 Global step 570 Train loss 2.00 on epoch=142
05/20/2022 18:03:26 - INFO - __main__ - Step 580 Global step 580 Train loss 1.88 on epoch=144
05/20/2022 18:03:27 - INFO - __main__ - Step 590 Global step 590 Train loss 1.81 on epoch=147
05/20/2022 18:03:28 - INFO - __main__ - Step 600 Global step 600 Train loss 1.84 on epoch=149
05/20/2022 18:03:29 - INFO - __main__ - Global step 600 Train loss 1.88 Classification-F1 0.12393162393162392 on epoch=149
05/20/2022 18:03:30 - INFO - __main__ - Step 610 Global step 610 Train loss 1.89 on epoch=152
05/20/2022 18:03:32 - INFO - __main__ - Step 620 Global step 620 Train loss 1.82 on epoch=154
05/20/2022 18:03:33 - INFO - __main__ - Step 630 Global step 630 Train loss 1.91 on epoch=157
05/20/2022 18:03:35 - INFO - __main__ - Step 640 Global step 640 Train loss 1.66 on epoch=159
05/20/2022 18:03:36 - INFO - __main__ - Step 650 Global step 650 Train loss 1.80 on epoch=162
05/20/2022 18:03:37 - INFO - __main__ - Global step 650 Train loss 1.81 Classification-F1 0.11714285714285715 on epoch=162
05/20/2022 18:03:38 - INFO - __main__ - Step 660 Global step 660 Train loss 1.68 on epoch=164
05/20/2022 18:03:39 - INFO - __main__ - Step 670 Global step 670 Train loss 1.67 on epoch=167
05/20/2022 18:03:41 - INFO - __main__ - Step 680 Global step 680 Train loss 1.59 on epoch=169
05/20/2022 18:03:42 - INFO - __main__ - Step 690 Global step 690 Train loss 1.78 on epoch=172
05/20/2022 18:03:43 - INFO - __main__ - Step 700 Global step 700 Train loss 1.66 on epoch=174
05/20/2022 18:03:44 - INFO - __main__ - Global step 700 Train loss 1.67 Classification-F1 0.19016393442622948 on epoch=174
05/20/2022 18:03:44 - INFO - __main__ - Saving model with best Classification-F1: 0.18888888888888888 -> 0.19016393442622948 on epoch=174, global_step=700
05/20/2022 18:03:45 - INFO - __main__ - Step 710 Global step 710 Train loss 1.69 on epoch=177
05/20/2022 18:03:47 - INFO - __main__ - Step 720 Global step 720 Train loss 1.55 on epoch=179
05/20/2022 18:03:48 - INFO - __main__ - Step 730 Global step 730 Train loss 1.69 on epoch=182
05/20/2022 18:03:50 - INFO - __main__ - Step 740 Global step 740 Train loss 1.58 on epoch=184
05/20/2022 18:03:51 - INFO - __main__ - Step 750 Global step 750 Train loss 1.69 on epoch=187
05/20/2022 18:03:52 - INFO - __main__ - Global step 750 Train loss 1.64 Classification-F1 0.12407862407862408 on epoch=187
05/20/2022 18:03:53 - INFO - __main__ - Step 760 Global step 760 Train loss 1.50 on epoch=189
05/20/2022 18:03:55 - INFO - __main__ - Step 770 Global step 770 Train loss 1.58 on epoch=192
05/20/2022 18:03:56 - INFO - __main__ - Step 780 Global step 780 Train loss 1.49 on epoch=194
05/20/2022 18:03:57 - INFO - __main__ - Step 790 Global step 790 Train loss 1.56 on epoch=197
05/20/2022 18:03:59 - INFO - __main__ - Step 800 Global step 800 Train loss 1.46 on epoch=199
05/20/2022 18:03:59 - INFO - __main__ - Global step 800 Train loss 1.52 Classification-F1 0.13026315789473686 on epoch=199
05/20/2022 18:04:01 - INFO - __main__ - Step 810 Global step 810 Train loss 1.42 on epoch=202
05/20/2022 18:04:02 - INFO - __main__ - Step 820 Global step 820 Train loss 1.45 on epoch=204
05/20/2022 18:04:04 - INFO - __main__ - Step 830 Global step 830 Train loss 1.49 on epoch=207
05/20/2022 18:04:05 - INFO - __main__ - Step 840 Global step 840 Train loss 1.50 on epoch=209
05/20/2022 18:04:06 - INFO - __main__ - Step 850 Global step 850 Train loss 1.46 on epoch=212
05/20/2022 18:04:07 - INFO - __main__ - Global step 850 Train loss 1.46 Classification-F1 0.09333333333333334 on epoch=212
05/20/2022 18:04:08 - INFO - __main__ - Step 860 Global step 860 Train loss 1.41 on epoch=214
05/20/2022 18:04:10 - INFO - __main__ - Step 870 Global step 870 Train loss 1.40 on epoch=217
05/20/2022 18:04:11 - INFO - __main__ - Step 880 Global step 880 Train loss 1.51 on epoch=219
05/20/2022 18:04:12 - INFO - __main__ - Step 890 Global step 890 Train loss 1.37 on epoch=222
05/20/2022 18:04:14 - INFO - __main__ - Step 900 Global step 900 Train loss 1.53 on epoch=224
05/20/2022 18:04:14 - INFO - __main__ - Global step 900 Train loss 1.44 Classification-F1 0.1 on epoch=224
05/20/2022 18:04:16 - INFO - __main__ - Step 910 Global step 910 Train loss 1.41 on epoch=227
05/20/2022 18:04:17 - INFO - __main__ - Step 920 Global step 920 Train loss 1.38 on epoch=229
05/20/2022 18:04:18 - INFO - __main__ - Step 930 Global step 930 Train loss 1.35 on epoch=232
05/20/2022 18:04:20 - INFO - __main__ - Step 940 Global step 940 Train loss 1.41 on epoch=234
05/20/2022 18:04:21 - INFO - __main__ - Step 950 Global step 950 Train loss 1.43 on epoch=237
05/20/2022 18:04:22 - INFO - __main__ - Global step 950 Train loss 1.40 Classification-F1 0.12171899125064337 on epoch=237
05/20/2022 18:04:23 - INFO - __main__ - Step 960 Global step 960 Train loss 1.33 on epoch=239
05/20/2022 18:04:25 - INFO - __main__ - Step 970 Global step 970 Train loss 1.28 on epoch=242
05/20/2022 18:04:26 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
05/20/2022 18:04:27 - INFO - __main__ - Step 990 Global step 990 Train loss 1.28 on epoch=247
05/20/2022 18:04:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.29 on epoch=249
05/20/2022 18:04:29 - INFO - __main__ - Global step 1000 Train loss 1.30 Classification-F1 0.17344312918167784 on epoch=249
05/20/2022 18:04:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/20/2022 18:04:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.21 on epoch=254
05/20/2022 18:04:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.34 on epoch=257
05/20/2022 18:04:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.22 on epoch=259
05/20/2022 18:04:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.23 on epoch=262
05/20/2022 18:04:37 - INFO - __main__ - Global step 1050 Train loss 1.27 Classification-F1 0.1625874125874126 on epoch=262
05/20/2022 18:04:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.34 on epoch=264
05/20/2022 18:04:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.36 on epoch=267
05/20/2022 18:04:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.29 on epoch=269
05/20/2022 18:04:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.25 on epoch=272
05/20/2022 18:04:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.29 on epoch=274
05/20/2022 18:04:44 - INFO - __main__ - Global step 1100 Train loss 1.31 Classification-F1 0.14583333333333331 on epoch=274
05/20/2022 18:04:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.34 on epoch=277
05/20/2022 18:04:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.32 on epoch=279
05/20/2022 18:04:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.34 on epoch=282
05/20/2022 18:04:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.27 on epoch=284
05/20/2022 18:04:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.34 on epoch=287
05/20/2022 18:04:52 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.13034188034188032 on epoch=287
05/20/2022 18:04:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.27 on epoch=289
05/20/2022 18:04:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.21 on epoch=292
05/20/2022 18:04:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/20/2022 18:04:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.13 on epoch=297
05/20/2022 18:04:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.24 on epoch=299
05/20/2022 18:05:00 - INFO - __main__ - Global step 1200 Train loss 1.20 Classification-F1 0.1565276828434723 on epoch=299
05/20/2022 18:05:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.21 on epoch=302
05/20/2022 18:05:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.17 on epoch=304
05/20/2022 18:05:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.12 on epoch=307
05/20/2022 18:05:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/20/2022 18:05:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.09 on epoch=312
05/20/2022 18:05:07 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.12407862407862408 on epoch=312
05/20/2022 18:05:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.22 on epoch=314
05/20/2022 18:05:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.32 on epoch=317
05/20/2022 18:05:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.28 on epoch=319
05/20/2022 18:05:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.12 on epoch=322
05/20/2022 18:05:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.12 on epoch=324
05/20/2022 18:05:15 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.1486842105263158 on epoch=324
05/20/2022 18:05:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.08 on epoch=327
05/20/2022 18:05:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.17 on epoch=329
05/20/2022 18:05:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.23 on epoch=332
05/20/2022 18:05:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.21 on epoch=334
05/20/2022 18:05:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=337
05/20/2022 18:05:22 - INFO - __main__ - Global step 1350 Train loss 1.18 Classification-F1 0.2109375 on epoch=337
05/20/2022 18:05:22 - INFO - __main__ - Saving model with best Classification-F1: 0.19016393442622948 -> 0.2109375 on epoch=337, global_step=1350
05/20/2022 18:05:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/20/2022 18:05:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
05/20/2022 18:05:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.17 on epoch=344
05/20/2022 18:05:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.23 on epoch=347
05/20/2022 18:05:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/20/2022 18:05:30 - INFO - __main__ - Global step 1400 Train loss 1.17 Classification-F1 0.131328171530673 on epoch=349
05/20/2022 18:05:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/20/2022 18:05:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.16 on epoch=354
05/20/2022 18:05:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.18 on epoch=357
05/20/2022 18:05:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.19 on epoch=359
05/20/2022 18:05:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.12 on epoch=362
05/20/2022 18:05:37 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.2144212523719165 on epoch=362
05/20/2022 18:05:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2109375 -> 0.2144212523719165 on epoch=362, global_step=1450
05/20/2022 18:05:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.14 on epoch=364
05/20/2022 18:05:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.21 on epoch=367
05/20/2022 18:05:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/20/2022 18:05:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=372
05/20/2022 18:05:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.27 on epoch=374
05/20/2022 18:05:45 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.1 on epoch=374
05/20/2022 18:05:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.06 on epoch=377
05/20/2022 18:05:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/20/2022 18:05:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.15 on epoch=382
05/20/2022 18:05:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
05/20/2022 18:05:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.12 on epoch=387
05/20/2022 18:05:52 - INFO - __main__ - Global step 1550 Train loss 1.09 Classification-F1 0.18356643356643357 on epoch=387
05/20/2022 18:05:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.11 on epoch=389
05/20/2022 18:05:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
05/20/2022 18:05:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.15 on epoch=394
05/20/2022 18:05:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.07 on epoch=397
05/20/2022 18:05:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.99 on epoch=399
05/20/2022 18:06:00 - INFO - __main__ - Global step 1600 Train loss 1.07 Classification-F1 0.17450980392156862 on epoch=399
05/20/2022 18:06:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.13 on epoch=402
05/20/2022 18:06:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.13 on epoch=404
05/20/2022 18:06:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.18 on epoch=407
05/20/2022 18:06:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.13 on epoch=409
05/20/2022 18:06:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.16 on epoch=412
05/20/2022 18:06:07 - INFO - __main__ - Global step 1650 Train loss 1.15 Classification-F1 0.21827759963353183 on epoch=412
05/20/2022 18:06:07 - INFO - __main__ - Saving model with best Classification-F1: 0.2144212523719165 -> 0.21827759963353183 on epoch=412, global_step=1650
05/20/2022 18:06:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.17 on epoch=414
05/20/2022 18:06:10 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.08 on epoch=417
05/20/2022 18:06:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.23 on epoch=419
05/20/2022 18:06:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.24 on epoch=422
05/20/2022 18:06:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.14 on epoch=424
05/20/2022 18:06:15 - INFO - __main__ - Global step 1700 Train loss 1.17 Classification-F1 0.18869565217391304 on epoch=424
05/20/2022 18:06:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.09 on epoch=427
05/20/2022 18:06:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/20/2022 18:06:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.19 on epoch=432
05/20/2022 18:06:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.11 on epoch=434
05/20/2022 18:06:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.02 on epoch=437
05/20/2022 18:06:22 - INFO - __main__ - Global step 1750 Train loss 1.08 Classification-F1 0.22832890218234186 on epoch=437
05/20/2022 18:06:22 - INFO - __main__ - Saving model with best Classification-F1: 0.21827759963353183 -> 0.22832890218234186 on epoch=437, global_step=1750
05/20/2022 18:06:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.03 on epoch=439
05/20/2022 18:06:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
05/20/2022 18:06:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/20/2022 18:06:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.97 on epoch=447
05/20/2022 18:06:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/20/2022 18:06:30 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.23446115288220554 on epoch=449
05/20/2022 18:06:30 - INFO - __main__ - Saving model with best Classification-F1: 0.22832890218234186 -> 0.23446115288220554 on epoch=449, global_step=1800
05/20/2022 18:06:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.10 on epoch=452
05/20/2022 18:06:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.05 on epoch=454
05/20/2022 18:06:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.15 on epoch=457
05/20/2022 18:06:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.10 on epoch=459
05/20/2022 18:06:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.07 on epoch=462
05/20/2022 18:06:38 - INFO - __main__ - Global step 1850 Train loss 1.10 Classification-F1 0.10606060606060605 on epoch=462
05/20/2022 18:06:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.17 on epoch=464
05/20/2022 18:06:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.12 on epoch=467
05/20/2022 18:06:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.18 on epoch=469
05/20/2022 18:06:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.12 on epoch=472
05/20/2022 18:06:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.09 on epoch=474
05/20/2022 18:06:46 - INFO - __main__ - Global step 1900 Train loss 1.14 Classification-F1 0.18928571428571428 on epoch=474
05/20/2022 18:06:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
05/20/2022 18:06:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
05/20/2022 18:06:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.07 on epoch=482
05/20/2022 18:06:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=484
05/20/2022 18:06:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.97 on epoch=487
05/20/2022 18:06:53 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.17075672111933193 on epoch=487
05/20/2022 18:06:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.06 on epoch=489
05/20/2022 18:06:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.10 on epoch=492
05/20/2022 18:06:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.97 on epoch=494
05/20/2022 18:06:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.94 on epoch=497
05/20/2022 18:07:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.06 on epoch=499
05/20/2022 18:07:01 - INFO - __main__ - Global step 2000 Train loss 1.02 Classification-F1 0.11512749142601521 on epoch=499
05/20/2022 18:07:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.00 on epoch=502
05/20/2022 18:07:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.12 on epoch=504
05/20/2022 18:07:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
05/20/2022 18:07:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.10 on epoch=509
05/20/2022 18:07:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.03 on epoch=512
05/20/2022 18:07:08 - INFO - __main__ - Global step 2050 Train loss 1.06 Classification-F1 0.16953316953316955 on epoch=512
05/20/2022 18:07:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=514
05/20/2022 18:07:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.01 on epoch=517
05/20/2022 18:07:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.08 on epoch=519
05/20/2022 18:07:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.12 on epoch=522
05/20/2022 18:07:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.07 on epoch=524
05/20/2022 18:07:16 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.18714719930525403 on epoch=524
05/20/2022 18:07:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.13 on epoch=527
05/20/2022 18:07:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.04 on epoch=529
05/20/2022 18:07:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.05 on epoch=532
05/20/2022 18:07:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/20/2022 18:07:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.98 on epoch=537
05/20/2022 18:07:23 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.11840411840411841 on epoch=537
05/20/2022 18:07:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.06 on epoch=539
05/20/2022 18:07:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.01 on epoch=542
05/20/2022 18:07:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.09 on epoch=544
05/20/2022 18:07:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=547
05/20/2022 18:07:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
05/20/2022 18:07:31 - INFO - __main__ - Global step 2200 Train loss 1.03 Classification-F1 0.10256410256410256 on epoch=549
05/20/2022 18:07:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.96 on epoch=552
05/20/2022 18:07:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.07 on epoch=554
05/20/2022 18:07:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/20/2022 18:07:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/20/2022 18:07:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=562
05/20/2022 18:07:38 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.1 on epoch=562
05/20/2022 18:07:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/20/2022 18:07:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.03 on epoch=567
05/20/2022 18:07:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.04 on epoch=569
05/20/2022 18:07:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/20/2022 18:07:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.10 on epoch=574
05/20/2022 18:07:46 - INFO - __main__ - Global step 2300 Train loss 1.03 Classification-F1 0.1697802197802198 on epoch=574
05/20/2022 18:07:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/20/2022 18:07:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/20/2022 18:07:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=582
05/20/2022 18:07:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/20/2022 18:07:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.11 on epoch=587
05/20/2022 18:07:53 - INFO - __main__ - Global step 2350 Train loss 1.00 Classification-F1 0.20053238686779057 on epoch=587
05/20/2022 18:07:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.98 on epoch=589
05/20/2022 18:07:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.01 on epoch=592
05/20/2022 18:07:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.01 on epoch=594
05/20/2022 18:07:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.13 on epoch=597
05/20/2022 18:08:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.05 on epoch=599
05/20/2022 18:08:01 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.17343358395989975 on epoch=599
05/20/2022 18:08:02 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.04 on epoch=602
05/20/2022 18:08:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/20/2022 18:08:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.06 on epoch=607
05/20/2022 18:08:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.07 on epoch=609
05/20/2022 18:08:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/20/2022 18:08:08 - INFO - __main__ - Global step 2450 Train loss 1.02 Classification-F1 0.11762954139368673 on epoch=612
05/20/2022 18:08:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.03 on epoch=614
05/20/2022 18:08:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.00 on epoch=617
05/20/2022 18:08:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.01 on epoch=619
05/20/2022 18:08:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/20/2022 18:08:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.13 on epoch=624
05/20/2022 18:08:16 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.18969624776652771 on epoch=624
05/20/2022 18:08:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.09 on epoch=627
05/20/2022 18:08:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.05 on epoch=629
05/20/2022 18:08:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.00 on epoch=632
05/20/2022 18:08:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/20/2022 18:08:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.02 on epoch=637
05/20/2022 18:08:23 - INFO - __main__ - Global step 2550 Train loss 1.03 Classification-F1 0.16451612903225807 on epoch=637
05/20/2022 18:08:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/20/2022 18:08:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
05/20/2022 18:08:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.93 on epoch=644
05/20/2022 18:08:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.04 on epoch=647
05/20/2022 18:08:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/20/2022 18:08:31 - INFO - __main__ - Global step 2600 Train loss 0.99 Classification-F1 0.17694311767260096 on epoch=649
05/20/2022 18:08:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/20/2022 18:08:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=654
05/20/2022 18:08:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
05/20/2022 18:08:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.99 on epoch=659
05/20/2022 18:08:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.97 on epoch=662
05/20/2022 18:08:38 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.20714285714285713 on epoch=662
05/20/2022 18:08:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.05 on epoch=664
05/20/2022 18:08:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.08 on epoch=667
05/20/2022 18:08:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.01 on epoch=669
05/20/2022 18:08:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.98 on epoch=672
05/20/2022 18:08:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.94 on epoch=674
05/20/2022 18:08:46 - INFO - __main__ - Global step 2700 Train loss 1.01 Classification-F1 0.10273972602739727 on epoch=674
05/20/2022 18:08:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/20/2022 18:08:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.10 on epoch=679
05/20/2022 18:08:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/20/2022 18:08:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.06 on epoch=684
05/20/2022 18:08:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.97 on epoch=687
05/20/2022 18:08:54 - INFO - __main__ - Global step 2750 Train loss 1.04 Classification-F1 0.10389610389610389 on epoch=687
05/20/2022 18:08:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.94 on epoch=689
05/20/2022 18:08:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.95 on epoch=692
05/20/2022 18:08:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.89 on epoch=694
05/20/2022 18:08:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=697
05/20/2022 18:09:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.99 on epoch=699
05/20/2022 18:09:01 - INFO - __main__ - Global step 2800 Train loss 0.94 Classification-F1 0.12393162393162392 on epoch=699
05/20/2022 18:09:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.01 on epoch=702
05/20/2022 18:09:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.00 on epoch=704
05/20/2022 18:09:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.03 on epoch=707
05/20/2022 18:09:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/20/2022 18:09:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/20/2022 18:09:09 - INFO - __main__ - Global step 2850 Train loss 0.99 Classification-F1 0.1 on epoch=712
05/20/2022 18:09:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.94 on epoch=714
05/20/2022 18:09:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
05/20/2022 18:09:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.02 on epoch=719
05/20/2022 18:09:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.06 on epoch=722
05/20/2022 18:09:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/20/2022 18:09:16 - INFO - __main__ - Global step 2900 Train loss 1.00 Classification-F1 0.1576923076923077 on epoch=724
05/20/2022 18:09:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.97 on epoch=727
05/20/2022 18:09:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.00 on epoch=729
05/20/2022 18:09:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.99 on epoch=732
05/20/2022 18:09:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.03 on epoch=734
05/20/2022 18:09:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.96 on epoch=737
05/20/2022 18:09:23 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.13865730583589295 on epoch=737
05/20/2022 18:09:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/20/2022 18:09:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.99 on epoch=742
05/20/2022 18:09:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/20/2022 18:09:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/20/2022 18:09:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.84 on epoch=749
05/20/2022 18:09:31 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=749
05/20/2022 18:09:31 - INFO - __main__ - save last model!
05/20/2022 18:09:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 18:09:31 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 18:09:31 - INFO - __main__ - Printing 3 examples
05/20/2022 18:09:31 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 18:09:31 - INFO - __main__ - ['others']
05/20/2022 18:09:31 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 18:09:31 - INFO - __main__ - ['others']
05/20/2022 18:09:31 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 18:09:31 - INFO - __main__ - ['others']
05/20/2022 18:09:31 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:09:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:09:32 - INFO - __main__ - Printing 3 examples
05/20/2022 18:09:32 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 18:09:32 - INFO - __main__ - ['sad']
05/20/2022 18:09:32 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 18:09:32 - INFO - __main__ - ['sad']
05/20/2022 18:09:32 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 18:09:32 - INFO - __main__ - ['sad']
05/20/2022 18:09:32 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:09:32 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:09:32 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:09:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:09:32 - INFO - __main__ - Printing 3 examples
05/20/2022 18:09:32 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 18:09:32 - INFO - __main__ - ['sad']
05/20/2022 18:09:32 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 18:09:32 - INFO - __main__ - ['sad']
05/20/2022 18:09:32 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 18:09:32 - INFO - __main__ - ['sad']
05/20/2022 18:09:32 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:09:32 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:09:32 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:09:34 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:09:38 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:09:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:09:39 - INFO - __main__ - Starting training!
05/20/2022 18:09:39 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 18:10:25 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.4_8_predictions.txt
05/20/2022 18:10:25 - INFO - __main__ - Classification-F1 on test data: 0.0337
05/20/2022 18:10:25 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.23446115288220554, test_performance=0.0337088983910494
05/20/2022 18:10:25 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
05/20/2022 18:10:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:10:26 - INFO - __main__ - Printing 3 examples
05/20/2022 18:10:26 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 18:10:26 - INFO - __main__ - ['sad']
05/20/2022 18:10:26 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 18:10:26 - INFO - __main__ - ['sad']
05/20/2022 18:10:26 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 18:10:26 - INFO - __main__ - ['sad']
05/20/2022 18:10:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:10:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:10:27 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:10:27 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:10:27 - INFO - __main__ - Printing 3 examples
05/20/2022 18:10:27 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 18:10:27 - INFO - __main__ - ['sad']
05/20/2022 18:10:27 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 18:10:27 - INFO - __main__ - ['sad']
05/20/2022 18:10:27 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 18:10:27 - INFO - __main__ - ['sad']
05/20/2022 18:10:27 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:10:27 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:10:27 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:10:33 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:10:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:10:33 - INFO - __main__ - Starting training!
05/20/2022 18:10:35 - INFO - __main__ - Step 10 Global step 10 Train loss 6.61 on epoch=2
05/20/2022 18:10:37 - INFO - __main__ - Step 20 Global step 20 Train loss 6.48 on epoch=4
05/20/2022 18:10:39 - INFO - __main__ - Step 30 Global step 30 Train loss 6.42 on epoch=7
05/20/2022 18:10:40 - INFO - __main__ - Step 40 Global step 40 Train loss 6.05 on epoch=9
05/20/2022 18:10:42 - INFO - __main__ - Step 50 Global step 50 Train loss 5.98 on epoch=12
05/20/2022 18:10:45 - INFO - __main__ - Global step 50 Train loss 6.31 Classification-F1 0.0 on epoch=12
05/20/2022 18:10:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 18:10:47 - INFO - __main__ - Step 60 Global step 60 Train loss 6.02 on epoch=14
05/20/2022 18:10:48 - INFO - __main__ - Step 70 Global step 70 Train loss 5.82 on epoch=17
05/20/2022 18:10:50 - INFO - __main__ - Step 80 Global step 80 Train loss 5.73 on epoch=19
05/20/2022 18:10:51 - INFO - __main__ - Step 90 Global step 90 Train loss 5.63 on epoch=22
05/20/2022 18:10:52 - INFO - __main__ - Step 100 Global step 100 Train loss 5.56 on epoch=24
05/20/2022 18:10:55 - INFO - __main__ - Global step 100 Train loss 5.75 Classification-F1 0.0 on epoch=24
05/20/2022 18:10:56 - INFO - __main__ - Step 110 Global step 110 Train loss 5.49 on epoch=27
05/20/2022 18:10:57 - INFO - __main__ - Step 120 Global step 120 Train loss 5.30 on epoch=29
05/20/2022 18:10:59 - INFO - __main__ - Step 130 Global step 130 Train loss 5.17 on epoch=32
05/20/2022 18:11:00 - INFO - __main__ - Step 140 Global step 140 Train loss 5.05 on epoch=34
05/20/2022 18:11:01 - INFO - __main__ - Step 150 Global step 150 Train loss 5.09 on epoch=37
05/20/2022 18:11:03 - INFO - __main__ - Global step 150 Train loss 5.22 Classification-F1 0.0 on epoch=37
05/20/2022 18:11:05 - INFO - __main__ - Step 160 Global step 160 Train loss 4.78 on epoch=39
05/20/2022 18:11:06 - INFO - __main__ - Step 170 Global step 170 Train loss 4.75 on epoch=42
05/20/2022 18:11:07 - INFO - __main__ - Step 180 Global step 180 Train loss 4.64 on epoch=44
05/20/2022 18:11:09 - INFO - __main__ - Step 190 Global step 190 Train loss 4.70 on epoch=47
05/20/2022 18:11:10 - INFO - __main__ - Step 200 Global step 200 Train loss 4.39 on epoch=49
05/20/2022 18:11:11 - INFO - __main__ - Global step 200 Train loss 4.65 Classification-F1 0.0 on epoch=49
05/20/2022 18:11:13 - INFO - __main__ - Step 210 Global step 210 Train loss 4.32 on epoch=52
05/20/2022 18:11:14 - INFO - __main__ - Step 220 Global step 220 Train loss 4.16 on epoch=54
05/20/2022 18:11:16 - INFO - __main__ - Step 230 Global step 230 Train loss 4.15 on epoch=57
05/20/2022 18:11:17 - INFO - __main__ - Step 240 Global step 240 Train loss 4.09 on epoch=59
05/20/2022 18:11:18 - INFO - __main__ - Step 250 Global step 250 Train loss 3.98 on epoch=62
05/20/2022 18:11:19 - INFO - __main__ - Global step 250 Train loss 4.14 Classification-F1 0.19408369408369408 on epoch=62
05/20/2022 18:11:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.19408369408369408 on epoch=62, global_step=250
05/20/2022 18:11:20 - INFO - __main__ - Step 260 Global step 260 Train loss 3.87 on epoch=64
05/20/2022 18:11:22 - INFO - __main__ - Step 270 Global step 270 Train loss 3.81 on epoch=67
05/20/2022 18:11:23 - INFO - __main__ - Step 280 Global step 280 Train loss 3.62 on epoch=69
05/20/2022 18:11:25 - INFO - __main__ - Step 290 Global step 290 Train loss 3.67 on epoch=72
05/20/2022 18:11:26 - INFO - __main__ - Step 300 Global step 300 Train loss 3.40 on epoch=74
05/20/2022 18:11:27 - INFO - __main__ - Global step 300 Train loss 3.67 Classification-F1 0.15859154929577468 on epoch=74
05/20/2022 18:11:28 - INFO - __main__ - Step 310 Global step 310 Train loss 3.58 on epoch=77
05/20/2022 18:11:30 - INFO - __main__ - Step 320 Global step 320 Train loss 3.28 on epoch=79
05/20/2022 18:11:31 - INFO - __main__ - Step 330 Global step 330 Train loss 3.37 on epoch=82
05/20/2022 18:11:32 - INFO - __main__ - Step 340 Global step 340 Train loss 3.36 on epoch=84
05/20/2022 18:11:34 - INFO - __main__ - Step 350 Global step 350 Train loss 3.37 on epoch=87
05/20/2022 18:11:34 - INFO - __main__ - Global step 350 Train loss 3.39 Classification-F1 0.20606060606060606 on epoch=87
05/20/2022 18:11:34 - INFO - __main__ - Saving model with best Classification-F1: 0.19408369408369408 -> 0.20606060606060606 on epoch=87, global_step=350
05/20/2022 18:11:36 - INFO - __main__ - Step 360 Global step 360 Train loss 3.14 on epoch=89
05/20/2022 18:11:37 - INFO - __main__ - Step 370 Global step 370 Train loss 3.24 on epoch=92
05/20/2022 18:11:39 - INFO - __main__ - Step 380 Global step 380 Train loss 3.08 on epoch=94
05/20/2022 18:11:40 - INFO - __main__ - Step 390 Global step 390 Train loss 3.07 on epoch=97
05/20/2022 18:11:41 - INFO - __main__ - Step 400 Global step 400 Train loss 2.91 on epoch=99
05/20/2022 18:11:42 - INFO - __main__ - Global step 400 Train loss 3.09 Classification-F1 0.10126582278481013 on epoch=99
05/20/2022 18:11:43 - INFO - __main__ - Step 410 Global step 410 Train loss 3.06 on epoch=102
05/20/2022 18:11:45 - INFO - __main__ - Step 420 Global step 420 Train loss 3.05 on epoch=104
05/20/2022 18:11:46 - INFO - __main__ - Step 430 Global step 430 Train loss 2.94 on epoch=107
05/20/2022 18:11:48 - INFO - __main__ - Step 440 Global step 440 Train loss 2.66 on epoch=109
05/20/2022 18:11:49 - INFO - __main__ - Step 450 Global step 450 Train loss 2.83 on epoch=112
05/20/2022 18:11:50 - INFO - __main__ - Global step 450 Train loss 2.91 Classification-F1 0.12447885646217988 on epoch=112
05/20/2022 18:11:51 - INFO - __main__ - Step 460 Global step 460 Train loss 2.68 on epoch=114
05/20/2022 18:11:52 - INFO - __main__ - Step 470 Global step 470 Train loss 2.75 on epoch=117
05/20/2022 18:11:54 - INFO - __main__ - Step 480 Global step 480 Train loss 2.54 on epoch=119
05/20/2022 18:11:55 - INFO - __main__ - Step 490 Global step 490 Train loss 2.73 on epoch=122
05/20/2022 18:11:56 - INFO - __main__ - Step 500 Global step 500 Train loss 2.51 on epoch=124
05/20/2022 18:11:57 - INFO - __main__ - Global step 500 Train loss 2.64 Classification-F1 0.1 on epoch=124
05/20/2022 18:11:58 - INFO - __main__ - Step 510 Global step 510 Train loss 2.47 on epoch=127
05/20/2022 18:12:00 - INFO - __main__ - Step 520 Global step 520 Train loss 2.57 on epoch=129
05/20/2022 18:12:01 - INFO - __main__ - Step 530 Global step 530 Train loss 2.47 on epoch=132
05/20/2022 18:12:02 - INFO - __main__ - Step 540 Global step 540 Train loss 2.34 on epoch=134
05/20/2022 18:12:04 - INFO - __main__ - Step 550 Global step 550 Train loss 2.45 on epoch=137
05/20/2022 18:12:04 - INFO - __main__ - Global step 550 Train loss 2.46 Classification-F1 0.12368421052631579 on epoch=137
05/20/2022 18:12:06 - INFO - __main__ - Step 560 Global step 560 Train loss 2.28 on epoch=139
05/20/2022 18:12:07 - INFO - __main__ - Step 570 Global step 570 Train loss 2.35 on epoch=142
05/20/2022 18:12:08 - INFO - __main__ - Step 580 Global step 580 Train loss 2.23 on epoch=144
05/20/2022 18:12:10 - INFO - __main__ - Step 590 Global step 590 Train loss 2.30 on epoch=147
05/20/2022 18:12:11 - INFO - __main__ - Step 600 Global step 600 Train loss 2.18 on epoch=149
05/20/2022 18:12:12 - INFO - __main__ - Global step 600 Train loss 2.27 Classification-F1 0.10126582278481013 on epoch=149
05/20/2022 18:12:13 - INFO - __main__ - Step 610 Global step 610 Train loss 2.21 on epoch=152
05/20/2022 18:12:14 - INFO - __main__ - Step 620 Global step 620 Train loss 2.03 on epoch=154
05/20/2022 18:12:16 - INFO - __main__ - Step 630 Global step 630 Train loss 2.17 on epoch=157
05/20/2022 18:12:17 - INFO - __main__ - Step 640 Global step 640 Train loss 1.90 on epoch=159
05/20/2022 18:12:18 - INFO - __main__ - Step 650 Global step 650 Train loss 1.91 on epoch=162
05/20/2022 18:12:19 - INFO - __main__ - Global step 650 Train loss 2.05 Classification-F1 0.1402116402116402 on epoch=162
05/20/2022 18:12:20 - INFO - __main__ - Step 660 Global step 660 Train loss 1.83 on epoch=164
05/20/2022 18:12:22 - INFO - __main__ - Step 670 Global step 670 Train loss 1.91 on epoch=167
05/20/2022 18:12:23 - INFO - __main__ - Step 680 Global step 680 Train loss 1.77 on epoch=169
05/20/2022 18:12:25 - INFO - __main__ - Step 690 Global step 690 Train loss 1.84 on epoch=172
05/20/2022 18:12:26 - INFO - __main__ - Step 700 Global step 700 Train loss 1.77 on epoch=174
05/20/2022 18:12:27 - INFO - __main__ - Global step 700 Train loss 1.82 Classification-F1 0.10126582278481013 on epoch=174
05/20/2022 18:12:28 - INFO - __main__ - Step 710 Global step 710 Train loss 1.65 on epoch=177
05/20/2022 18:12:29 - INFO - __main__ - Step 720 Global step 720 Train loss 1.68 on epoch=179
05/20/2022 18:12:31 - INFO - __main__ - Step 730 Global step 730 Train loss 1.73 on epoch=182
05/20/2022 18:12:32 - INFO - __main__ - Step 740 Global step 740 Train loss 1.72 on epoch=184
05/20/2022 18:12:33 - INFO - __main__ - Step 750 Global step 750 Train loss 1.71 on epoch=187
05/20/2022 18:12:34 - INFO - __main__ - Global step 750 Train loss 1.70 Classification-F1 0.16666666666666666 on epoch=187
05/20/2022 18:12:35 - INFO - __main__ - Step 760 Global step 760 Train loss 1.69 on epoch=189
05/20/2022 18:12:36 - INFO - __main__ - Step 770 Global step 770 Train loss 1.65 on epoch=192
05/20/2022 18:12:38 - INFO - __main__ - Step 780 Global step 780 Train loss 1.70 on epoch=194
05/20/2022 18:12:39 - INFO - __main__ - Step 790 Global step 790 Train loss 1.62 on epoch=197
05/20/2022 18:12:41 - INFO - __main__ - Step 800 Global step 800 Train loss 1.44 on epoch=199
05/20/2022 18:12:41 - INFO - __main__ - Global step 800 Train loss 1.62 Classification-F1 0.17979127134724857 on epoch=199
05/20/2022 18:12:43 - INFO - __main__ - Step 810 Global step 810 Train loss 1.67 on epoch=202
05/20/2022 18:12:44 - INFO - __main__ - Step 820 Global step 820 Train loss 1.53 on epoch=204
05/20/2022 18:12:45 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/20/2022 18:12:47 - INFO - __main__ - Step 840 Global step 840 Train loss 1.41 on epoch=209
05/20/2022 18:12:48 - INFO - __main__ - Step 850 Global step 850 Train loss 1.58 on epoch=212
05/20/2022 18:12:49 - INFO - __main__ - Global step 850 Train loss 1.57 Classification-F1 0.20833333333333334 on epoch=212
05/20/2022 18:12:49 - INFO - __main__ - Saving model with best Classification-F1: 0.20606060606060606 -> 0.20833333333333334 on epoch=212, global_step=850
05/20/2022 18:12:50 - INFO - __main__ - Step 860 Global step 860 Train loss 1.51 on epoch=214
05/20/2022 18:12:51 - INFO - __main__ - Step 870 Global step 870 Train loss 1.54 on epoch=217
05/20/2022 18:12:52 - INFO - __main__ - Step 880 Global step 880 Train loss 1.55 on epoch=219
05/20/2022 18:12:54 - INFO - __main__ - Step 890 Global step 890 Train loss 1.51 on epoch=222
05/20/2022 18:12:55 - INFO - __main__ - Step 900 Global step 900 Train loss 1.40 on epoch=224
05/20/2022 18:12:56 - INFO - __main__ - Global step 900 Train loss 1.50 Classification-F1 0.1 on epoch=224
05/20/2022 18:12:57 - INFO - __main__ - Step 910 Global step 910 Train loss 1.50 on epoch=227
05/20/2022 18:12:58 - INFO - __main__ - Step 920 Global step 920 Train loss 1.46 on epoch=229
05/20/2022 18:13:00 - INFO - __main__ - Step 930 Global step 930 Train loss 1.43 on epoch=232
05/20/2022 18:13:01 - INFO - __main__ - Step 940 Global step 940 Train loss 1.40 on epoch=234
05/20/2022 18:13:02 - INFO - __main__ - Step 950 Global step 950 Train loss 1.42 on epoch=237
05/20/2022 18:13:03 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.16953316953316955 on epoch=237
05/20/2022 18:13:04 - INFO - __main__ - Step 960 Global step 960 Train loss 1.48 on epoch=239
05/20/2022 18:13:05 - INFO - __main__ - Step 970 Global step 970 Train loss 1.27 on epoch=242
05/20/2022 18:13:07 - INFO - __main__ - Step 980 Global step 980 Train loss 1.39 on epoch=244
05/20/2022 18:13:08 - INFO - __main__ - Step 990 Global step 990 Train loss 1.49 on epoch=247
05/20/2022 18:13:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.36 on epoch=249
05/20/2022 18:13:10 - INFO - __main__ - Global step 1000 Train loss 1.40 Classification-F1 0.17809523809523808 on epoch=249
05/20/2022 18:13:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=252
05/20/2022 18:13:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
05/20/2022 18:13:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.39 on epoch=257
05/20/2022 18:13:16 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.39 on epoch=259
05/20/2022 18:13:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.29 on epoch=262
05/20/2022 18:13:18 - INFO - __main__ - Global step 1050 Train loss 1.37 Classification-F1 0.17752100840336132 on epoch=262
05/20/2022 18:13:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.18 on epoch=264
05/20/2022 18:13:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.51 on epoch=267
05/20/2022 18:13:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/20/2022 18:13:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.39 on epoch=272
05/20/2022 18:13:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.22 on epoch=274
05/20/2022 18:13:25 - INFO - __main__ - Global step 1100 Train loss 1.30 Classification-F1 0.13859154929577466 on epoch=274
05/20/2022 18:13:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.20 on epoch=277
05/20/2022 18:13:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.35 on epoch=279
05/20/2022 18:13:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.24 on epoch=282
05/20/2022 18:13:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=284
05/20/2022 18:13:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.26 on epoch=287
05/20/2022 18:13:33 - INFO - __main__ - Global step 1150 Train loss 1.26 Classification-F1 0.16110780226325194 on epoch=287
05/20/2022 18:13:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.33 on epoch=289
05/20/2022 18:13:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.24 on epoch=292
05/20/2022 18:13:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.14 on epoch=294
05/20/2022 18:13:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.24 on epoch=297
05/20/2022 18:13:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.41 on epoch=299
05/20/2022 18:13:40 - INFO - __main__ - Global step 1200 Train loss 1.27 Classification-F1 0.11208791208791208 on epoch=299
05/20/2022 18:13:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.24 on epoch=302
05/20/2022 18:13:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.21 on epoch=304
05/20/2022 18:13:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.41 on epoch=307
05/20/2022 18:13:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.08 on epoch=309
05/20/2022 18:13:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.33 on epoch=312
05/20/2022 18:13:48 - INFO - __main__ - Global step 1250 Train loss 1.25 Classification-F1 0.13130252100840337 on epoch=312
05/20/2022 18:13:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.29 on epoch=314
05/20/2022 18:13:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=317
05/20/2022 18:13:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.37 on epoch=319
05/20/2022 18:13:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.11 on epoch=322
05/20/2022 18:13:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.09 on epoch=324
05/20/2022 18:13:55 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.14560439560439564 on epoch=324
05/20/2022 18:13:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.11 on epoch=327
05/20/2022 18:13:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.12 on epoch=329
05/20/2022 18:14:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.25 on epoch=332
05/20/2022 18:14:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.31 on epoch=334
05/20/2022 18:14:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.18 on epoch=337
05/20/2022 18:14:03 - INFO - __main__ - Global step 1350 Train loss 1.19 Classification-F1 0.14107142857142857 on epoch=337
05/20/2022 18:14:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/20/2022 18:14:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.13 on epoch=342
05/20/2022 18:14:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.14 on epoch=344
05/20/2022 18:14:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.26 on epoch=347
05/20/2022 18:14:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/20/2022 18:14:10 - INFO - __main__ - Global step 1400 Train loss 1.18 Classification-F1 0.1 on epoch=349
05/20/2022 18:14:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.18 on epoch=352
05/20/2022 18:14:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.19 on epoch=354
05/20/2022 18:14:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.18 on epoch=357
05/20/2022 18:14:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.22 on epoch=359
05/20/2022 18:14:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
05/20/2022 18:14:18 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.1581196581196581 on epoch=362
05/20/2022 18:14:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.08 on epoch=364
05/20/2022 18:14:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.23 on epoch=367
05/20/2022 18:14:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
05/20/2022 18:14:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.18 on epoch=372
05/20/2022 18:14:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.28 on epoch=374
05/20/2022 18:14:25 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=374
05/20/2022 18:14:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.14 on epoch=377
05/20/2022 18:14:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.25 on epoch=379
05/20/2022 18:14:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.21 on epoch=382
05/20/2022 18:14:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.26 on epoch=384
05/20/2022 18:14:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
05/20/2022 18:14:33 - INFO - __main__ - Global step 1550 Train loss 1.22 Classification-F1 0.1318181818181818 on epoch=387
05/20/2022 18:14:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.05 on epoch=389
05/20/2022 18:14:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.25 on epoch=392
05/20/2022 18:14:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.27 on epoch=394
05/20/2022 18:14:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.07 on epoch=397
05/20/2022 18:14:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.22 on epoch=399
05/20/2022 18:14:40 - INFO - __main__ - Global step 1600 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=399
05/20/2022 18:14:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.11 on epoch=402
05/20/2022 18:14:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.05 on epoch=404
05/20/2022 18:14:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.20 on epoch=407
05/20/2022 18:14:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.03 on epoch=409
05/20/2022 18:14:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.13 on epoch=412
05/20/2022 18:14:48 - INFO - __main__ - Global step 1650 Train loss 1.10 Classification-F1 0.1 on epoch=412
05/20/2022 18:14:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.10 on epoch=414
05/20/2022 18:14:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.19 on epoch=417
05/20/2022 18:14:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.12 on epoch=419
05/20/2022 18:14:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.22 on epoch=422
05/20/2022 18:14:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
05/20/2022 18:14:55 - INFO - __main__ - Global step 1700 Train loss 1.16 Classification-F1 0.1 on epoch=424
05/20/2022 18:14:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.06 on epoch=427
05/20/2022 18:14:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.02 on epoch=429
05/20/2022 18:14:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.02 on epoch=432
05/20/2022 18:15:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.13 on epoch=434
05/20/2022 18:15:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.08 on epoch=437
05/20/2022 18:15:03 - INFO - __main__ - Global step 1750 Train loss 1.06 Classification-F1 0.10126582278481013 on epoch=437
05/20/2022 18:15:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.04 on epoch=439
05/20/2022 18:15:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.14 on epoch=442
05/20/2022 18:15:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.31 on epoch=444
05/20/2022 18:15:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.17 on epoch=447
05/20/2022 18:15:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=449
05/20/2022 18:15:10 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.1 on epoch=449
05/20/2022 18:15:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.07 on epoch=452
05/20/2022 18:15:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.06 on epoch=454
05/20/2022 18:15:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.11 on epoch=457
05/20/2022 18:15:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.18 on epoch=459
05/20/2022 18:15:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.00 on epoch=462
05/20/2022 18:15:18 - INFO - __main__ - Global step 1850 Train loss 1.08 Classification-F1 0.1 on epoch=462
05/20/2022 18:15:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.07 on epoch=464
05/20/2022 18:15:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.13 on epoch=467
05/20/2022 18:15:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.04 on epoch=469
05/20/2022 18:15:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
05/20/2022 18:15:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/20/2022 18:15:26 - INFO - __main__ - Global step 1900 Train loss 1.08 Classification-F1 0.203125 on epoch=474
05/20/2022 18:15:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/20/2022 18:15:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.03 on epoch=479
05/20/2022 18:15:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
05/20/2022 18:15:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=484
05/20/2022 18:15:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.09 on epoch=487
05/20/2022 18:15:33 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.18847006651884698 on epoch=487
05/20/2022 18:15:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.07 on epoch=489
05/20/2022 18:15:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/20/2022 18:15:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.03 on epoch=494
05/20/2022 18:15:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.10 on epoch=497
05/20/2022 18:15:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.97 on epoch=499
05/20/2022 18:15:40 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.16433566433566432 on epoch=499
05/20/2022 18:15:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/20/2022 18:15:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.10 on epoch=504
05/20/2022 18:15:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
05/20/2022 18:15:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.97 on epoch=509
05/20/2022 18:15:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.00 on epoch=512
05/20/2022 18:15:48 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.12407862407862408 on epoch=512
05/20/2022 18:15:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
05/20/2022 18:15:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
05/20/2022 18:15:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.03 on epoch=519
05/20/2022 18:15:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
05/20/2022 18:15:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/20/2022 18:15:56 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.18172268907563027 on epoch=524
05/20/2022 18:15:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.09 on epoch=527
05/20/2022 18:15:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.01 on epoch=529
05/20/2022 18:16:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/20/2022 18:16:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.95 on epoch=534
05/20/2022 18:16:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.93 on epoch=537
05/20/2022 18:16:03 - INFO - __main__ - Global step 2150 Train loss 0.99 Classification-F1 0.21596452328159646 on epoch=537
05/20/2022 18:16:03 - INFO - __main__ - Saving model with best Classification-F1: 0.20833333333333334 -> 0.21596452328159646 on epoch=537, global_step=2150
05/20/2022 18:16:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.11 on epoch=539
05/20/2022 18:16:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.14 on epoch=542
05/20/2022 18:16:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/20/2022 18:16:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.11 on epoch=547
05/20/2022 18:16:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.08 on epoch=549
05/20/2022 18:16:11 - INFO - __main__ - Global step 2200 Train loss 1.09 Classification-F1 0.1642512077294686 on epoch=549
05/20/2022 18:16:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.06 on epoch=552
05/20/2022 18:16:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/20/2022 18:16:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.09 on epoch=557
05/20/2022 18:16:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.04 on epoch=559
05/20/2022 18:16:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/20/2022 18:16:18 - INFO - __main__ - Global step 2250 Train loss 1.06 Classification-F1 0.21323866239120476 on epoch=562
05/20/2022 18:16:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.06 on epoch=564
05/20/2022 18:16:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.02 on epoch=567
05/20/2022 18:16:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.06 on epoch=569
05/20/2022 18:16:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.01 on epoch=572
05/20/2022 18:16:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/20/2022 18:16:26 - INFO - __main__ - Global step 2300 Train loss 1.02 Classification-F1 0.11923076923076922 on epoch=574
05/20/2022 18:16:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.03 on epoch=577
05/20/2022 18:16:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
05/20/2022 18:16:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=582
05/20/2022 18:16:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/20/2022 18:16:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=587
05/20/2022 18:16:34 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.15735226752175901 on epoch=587
05/20/2022 18:16:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
05/20/2022 18:16:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.04 on epoch=592
05/20/2022 18:16:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.00 on epoch=594
05/20/2022 18:16:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
05/20/2022 18:16:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/20/2022 18:16:42 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.16608695652173913 on epoch=599
05/20/2022 18:16:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/20/2022 18:16:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.99 on epoch=604
05/20/2022 18:16:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/20/2022 18:16:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
05/20/2022 18:16:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.11 on epoch=612
05/20/2022 18:16:49 - INFO - __main__ - Global step 2450 Train loss 1.04 Classification-F1 0.10256410256410256 on epoch=612
05/20/2022 18:16:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.08 on epoch=614
05/20/2022 18:16:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.05 on epoch=617
05/20/2022 18:16:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/20/2022 18:16:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.02 on epoch=622
05/20/2022 18:16:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.02 on epoch=624
05/20/2022 18:16:57 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=624
05/20/2022 18:16:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.00 on epoch=627
05/20/2022 18:17:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.98 on epoch=629
05/20/2022 18:17:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
05/20/2022 18:17:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.99 on epoch=634
05/20/2022 18:17:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.07 on epoch=637
05/20/2022 18:17:05 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.14947089947089948 on epoch=637
05/20/2022 18:17:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
05/20/2022 18:17:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.96 on epoch=642
05/20/2022 18:17:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/20/2022 18:17:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/20/2022 18:17:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.85 on epoch=649
05/20/2022 18:17:13 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.22916666666666669 on epoch=649
05/20/2022 18:17:13 - INFO - __main__ - Saving model with best Classification-F1: 0.21596452328159646 -> 0.22916666666666669 on epoch=649, global_step=2600
05/20/2022 18:17:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.11 on epoch=652
05/20/2022 18:17:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.95 on epoch=654
05/20/2022 18:17:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
05/20/2022 18:17:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/20/2022 18:17:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.09 on epoch=662
05/20/2022 18:17:21 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.14242424242424243 on epoch=662
05/20/2022 18:17:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.95 on epoch=664
05/20/2022 18:17:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.97 on epoch=667
05/20/2022 18:17:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.92 on epoch=669
05/20/2022 18:17:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.97 on epoch=672
05/20/2022 18:17:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/20/2022 18:17:29 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.1851689337428697 on epoch=674
05/20/2022 18:17:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/20/2022 18:17:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.99 on epoch=679
05/20/2022 18:17:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.92 on epoch=682
05/20/2022 18:17:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
05/20/2022 18:17:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.01 on epoch=687
05/20/2022 18:17:37 - INFO - __main__ - Global step 2750 Train loss 0.97 Classification-F1 0.19869565217391305 on epoch=687
05/20/2022 18:17:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=689
05/20/2022 18:17:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.00 on epoch=692
05/20/2022 18:17:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/20/2022 18:17:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.99 on epoch=697
05/20/2022 18:17:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.98 on epoch=699
05/20/2022 18:17:45 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.2300653594771242 on epoch=699
05/20/2022 18:17:45 - INFO - __main__ - Saving model with best Classification-F1: 0.22916666666666669 -> 0.2300653594771242 on epoch=699, global_step=2800
05/20/2022 18:17:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.88 on epoch=702
05/20/2022 18:17:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
05/20/2022 18:17:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.00 on epoch=707
05/20/2022 18:17:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/20/2022 18:17:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/20/2022 18:17:53 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.140625 on epoch=712
05/20/2022 18:17:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/20/2022 18:17:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.92 on epoch=717
05/20/2022 18:17:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.97 on epoch=719
05/20/2022 18:17:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.03 on epoch=722
05/20/2022 18:18:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.99 on epoch=724
05/20/2022 18:18:01 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.19735128093790708 on epoch=724
05/20/2022 18:18:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.91 on epoch=727
05/20/2022 18:18:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.99 on epoch=729
05/20/2022 18:18:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.05 on epoch=732
05/20/2022 18:18:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
05/20/2022 18:18:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.06 on epoch=737
05/20/2022 18:18:08 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.1056338028169014 on epoch=737
05/20/2022 18:18:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/20/2022 18:18:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/20/2022 18:18:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
05/20/2022 18:18:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.94 on epoch=747
05/20/2022 18:18:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
05/20/2022 18:18:15 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.17344312918167784 on epoch=749
05/20/2022 18:18:15 - INFO - __main__ - save last model!
05/20/2022 18:18:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 18:18:15 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 18:18:15 - INFO - __main__ - Printing 3 examples
05/20/2022 18:18:15 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 18:18:15 - INFO - __main__ - ['others']
05/20/2022 18:18:15 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 18:18:15 - INFO - __main__ - ['others']
05/20/2022 18:18:15 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 18:18:15 - INFO - __main__ - ['others']
05/20/2022 18:18:15 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:18:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:18:15 - INFO - __main__ - Printing 3 examples
05/20/2022 18:18:15 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 18:18:15 - INFO - __main__ - ['sad']
05/20/2022 18:18:15 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 18:18:15 - INFO - __main__ - ['sad']
05/20/2022 18:18:15 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 18:18:15 - INFO - __main__ - ['sad']
05/20/2022 18:18:15 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:18:15 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:18:15 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:18:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:18:15 - INFO - __main__ - Printing 3 examples
05/20/2022 18:18:15 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 18:18:15 - INFO - __main__ - ['sad']
05/20/2022 18:18:15 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 18:18:15 - INFO - __main__ - ['sad']
05/20/2022 18:18:15 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 18:18:15 - INFO - __main__ - ['sad']
05/20/2022 18:18:15 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:18:16 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:18:16 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:18:17 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:18:21 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:18:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:18:22 - INFO - __main__ - Starting training!
05/20/2022 18:18:23 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 18:19:06 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.3_8_predictions.txt
05/20/2022 18:19:06 - INFO - __main__ - Classification-F1 on test data: 0.0488
05/20/2022 18:19:06 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.2300653594771242, test_performance=0.048775773564390404
05/20/2022 18:19:06 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
05/20/2022 18:19:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:19:07 - INFO - __main__ - Printing 3 examples
05/20/2022 18:19:07 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/20/2022 18:19:07 - INFO - __main__ - ['sad']
05/20/2022 18:19:07 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/20/2022 18:19:07 - INFO - __main__ - ['sad']
05/20/2022 18:19:07 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/20/2022 18:19:07 - INFO - __main__ - ['sad']
05/20/2022 18:19:07 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:19:07 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:19:07 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:19:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:19:07 - INFO - __main__ - Printing 3 examples
05/20/2022 18:19:07 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/20/2022 18:19:07 - INFO - __main__ - ['sad']
05/20/2022 18:19:07 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/20/2022 18:19:07 - INFO - __main__ - ['sad']
05/20/2022 18:19:07 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/20/2022 18:19:07 - INFO - __main__ - ['sad']
05/20/2022 18:19:07 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:19:07 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:19:08 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:19:13 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:19:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:19:14 - INFO - __main__ - Starting training!
05/20/2022 18:19:15 - INFO - __main__ - Step 10 Global step 10 Train loss 6.63 on epoch=2
05/20/2022 18:19:17 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/20/2022 18:19:18 - INFO - __main__ - Step 30 Global step 30 Train loss 6.47 on epoch=7
05/20/2022 18:19:19 - INFO - __main__ - Step 40 Global step 40 Train loss 6.37 on epoch=9
05/20/2022 18:19:21 - INFO - __main__ - Step 50 Global step 50 Train loss 6.39 on epoch=12
05/20/2022 18:19:29 - INFO - __main__ - Global step 50 Train loss 6.49 Classification-F1 0.0 on epoch=12
05/20/2022 18:19:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 18:19:31 - INFO - __main__ - Step 60 Global step 60 Train loss 6.23 on epoch=14
05/20/2022 18:19:32 - INFO - __main__ - Step 70 Global step 70 Train loss 6.18 on epoch=17
05/20/2022 18:19:33 - INFO - __main__ - Step 80 Global step 80 Train loss 6.03 on epoch=19
05/20/2022 18:19:35 - INFO - __main__ - Step 90 Global step 90 Train loss 5.92 on epoch=22
05/20/2022 18:19:36 - INFO - __main__ - Step 100 Global step 100 Train loss 5.77 on epoch=24
05/20/2022 18:19:40 - INFO - __main__ - Global step 100 Train loss 6.03 Classification-F1 0.0 on epoch=24
05/20/2022 18:19:41 - INFO - __main__ - Step 110 Global step 110 Train loss 5.71 on epoch=27
05/20/2022 18:19:43 - INFO - __main__ - Step 120 Global step 120 Train loss 5.59 on epoch=29
05/20/2022 18:19:44 - INFO - __main__ - Step 130 Global step 130 Train loss 5.60 on epoch=32
05/20/2022 18:19:45 - INFO - __main__ - Step 140 Global step 140 Train loss 5.30 on epoch=34
05/20/2022 18:19:47 - INFO - __main__ - Step 150 Global step 150 Train loss 5.41 on epoch=37
05/20/2022 18:19:49 - INFO - __main__ - Global step 150 Train loss 5.52 Classification-F1 0.0 on epoch=37
05/20/2022 18:19:51 - INFO - __main__ - Step 160 Global step 160 Train loss 5.11 on epoch=39
05/20/2022 18:19:52 - INFO - __main__ - Step 170 Global step 170 Train loss 5.18 on epoch=42
05/20/2022 18:19:53 - INFO - __main__ - Step 180 Global step 180 Train loss 4.92 on epoch=44
05/20/2022 18:19:55 - INFO - __main__ - Step 190 Global step 190 Train loss 4.86 on epoch=47
05/20/2022 18:19:56 - INFO - __main__ - Step 200 Global step 200 Train loss 4.88 on epoch=49
05/20/2022 18:19:58 - INFO - __main__ - Global step 200 Train loss 4.99 Classification-F1 0.0 on epoch=49
05/20/2022 18:19:59 - INFO - __main__ - Step 210 Global step 210 Train loss 4.57 on epoch=52
05/20/2022 18:20:00 - INFO - __main__ - Step 220 Global step 220 Train loss 4.41 on epoch=54
05/20/2022 18:20:02 - INFO - __main__ - Step 230 Global step 230 Train loss 4.41 on epoch=57
05/20/2022 18:20:03 - INFO - __main__ - Step 240 Global step 240 Train loss 4.40 on epoch=59
05/20/2022 18:20:04 - INFO - __main__ - Step 250 Global step 250 Train loss 4.29 on epoch=62
05/20/2022 18:20:06 - INFO - __main__ - Global step 250 Train loss 4.41 Classification-F1 0.10126582278481013 on epoch=62
05/20/2022 18:20:06 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.10126582278481013 on epoch=62, global_step=250
05/20/2022 18:20:07 - INFO - __main__ - Step 260 Global step 260 Train loss 4.02 on epoch=64
05/20/2022 18:20:08 - INFO - __main__ - Step 270 Global step 270 Train loss 4.14 on epoch=67
05/20/2022 18:20:10 - INFO - __main__ - Step 280 Global step 280 Train loss 3.83 on epoch=69
05/20/2022 18:20:11 - INFO - __main__ - Step 290 Global step 290 Train loss 3.90 on epoch=72
05/20/2022 18:20:13 - INFO - __main__ - Step 300 Global step 300 Train loss 3.79 on epoch=74
05/20/2022 18:20:13 - INFO - __main__ - Global step 300 Train loss 3.94 Classification-F1 0.11710526315789474 on epoch=74
05/20/2022 18:20:13 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.11710526315789474 on epoch=74, global_step=300
05/20/2022 18:20:15 - INFO - __main__ - Step 310 Global step 310 Train loss 3.87 on epoch=77
05/20/2022 18:20:16 - INFO - __main__ - Step 320 Global step 320 Train loss 3.65 on epoch=79
05/20/2022 18:20:17 - INFO - __main__ - Step 330 Global step 330 Train loss 3.66 on epoch=82
05/20/2022 18:20:19 - INFO - __main__ - Step 340 Global step 340 Train loss 3.60 on epoch=84
05/20/2022 18:20:20 - INFO - __main__ - Step 350 Global step 350 Train loss 3.44 on epoch=87
05/20/2022 18:20:21 - INFO - __main__ - Global step 350 Train loss 3.64 Classification-F1 0.16277641277641278 on epoch=87
05/20/2022 18:20:21 - INFO - __main__ - Saving model with best Classification-F1: 0.11710526315789474 -> 0.16277641277641278 on epoch=87, global_step=350
05/20/2022 18:20:22 - INFO - __main__ - Step 360 Global step 360 Train loss 3.42 on epoch=89
05/20/2022 18:20:24 - INFO - __main__ - Step 370 Global step 370 Train loss 3.49 on epoch=92
05/20/2022 18:20:25 - INFO - __main__ - Step 380 Global step 380 Train loss 3.31 on epoch=94
05/20/2022 18:20:26 - INFO - __main__ - Step 390 Global step 390 Train loss 3.42 on epoch=97
05/20/2022 18:20:28 - INFO - __main__ - Step 400 Global step 400 Train loss 3.17 on epoch=99
05/20/2022 18:20:28 - INFO - __main__ - Global step 400 Train loss 3.36 Classification-F1 0.15498891352549887 on epoch=99
05/20/2022 18:20:30 - INFO - __main__ - Step 410 Global step 410 Train loss 3.33 on epoch=102
05/20/2022 18:20:31 - INFO - __main__ - Step 420 Global step 420 Train loss 3.19 on epoch=104
05/20/2022 18:20:33 - INFO - __main__ - Step 430 Global step 430 Train loss 3.25 on epoch=107
05/20/2022 18:20:35 - INFO - __main__ - Step 440 Global step 440 Train loss 3.13 on epoch=109
05/20/2022 18:20:36 - INFO - __main__ - Step 450 Global step 450 Train loss 3.04 on epoch=112
05/20/2022 18:20:37 - INFO - __main__ - Global step 450 Train loss 3.19 Classification-F1 0.1 on epoch=112
05/20/2022 18:20:38 - INFO - __main__ - Step 460 Global step 460 Train loss 2.99 on epoch=114
05/20/2022 18:20:40 - INFO - __main__ - Step 470 Global step 470 Train loss 3.13 on epoch=117
05/20/2022 18:20:42 - INFO - __main__ - Step 480 Global step 480 Train loss 2.92 on epoch=119
05/20/2022 18:20:43 - INFO - __main__ - Step 490 Global step 490 Train loss 3.01 on epoch=122
05/20/2022 18:20:45 - INFO - __main__ - Step 500 Global step 500 Train loss 2.85 on epoch=124
05/20/2022 18:20:46 - INFO - __main__ - Global step 500 Train loss 2.98 Classification-F1 0.10126582278481013 on epoch=124
05/20/2022 18:20:47 - INFO - __main__ - Step 510 Global step 510 Train loss 2.89 on epoch=127
05/20/2022 18:20:49 - INFO - __main__ - Step 520 Global step 520 Train loss 2.62 on epoch=129
05/20/2022 18:20:51 - INFO - __main__ - Step 530 Global step 530 Train loss 2.80 on epoch=132
05/20/2022 18:20:52 - INFO - __main__ - Step 540 Global step 540 Train loss 2.81 on epoch=134
05/20/2022 18:20:54 - INFO - __main__ - Step 550 Global step 550 Train loss 2.61 on epoch=137
05/20/2022 18:20:54 - INFO - __main__ - Global step 550 Train loss 2.75 Classification-F1 0.1 on epoch=137
05/20/2022 18:20:56 - INFO - __main__ - Step 560 Global step 560 Train loss 2.60 on epoch=139
05/20/2022 18:20:58 - INFO - __main__ - Step 570 Global step 570 Train loss 2.73 on epoch=142
05/20/2022 18:20:59 - INFO - __main__ - Step 580 Global step 580 Train loss 2.42 on epoch=144
05/20/2022 18:21:01 - INFO - __main__ - Step 590 Global step 590 Train loss 2.67 on epoch=147
05/20/2022 18:21:03 - INFO - __main__ - Step 600 Global step 600 Train loss 2.49 on epoch=149
05/20/2022 18:21:03 - INFO - __main__ - Global step 600 Train loss 2.58 Classification-F1 0.1 on epoch=149
05/20/2022 18:21:05 - INFO - __main__ - Step 610 Global step 610 Train loss 2.47 on epoch=152
05/20/2022 18:21:06 - INFO - __main__ - Step 620 Global step 620 Train loss 2.51 on epoch=154
05/20/2022 18:21:08 - INFO - __main__ - Step 630 Global step 630 Train loss 2.62 on epoch=157
05/20/2022 18:21:09 - INFO - __main__ - Step 640 Global step 640 Train loss 2.37 on epoch=159
05/20/2022 18:21:10 - INFO - __main__ - Step 650 Global step 650 Train loss 2.42 on epoch=162
05/20/2022 18:21:11 - INFO - __main__ - Global step 650 Train loss 2.48 Classification-F1 0.09493670886075949 on epoch=162
05/20/2022 18:21:12 - INFO - __main__ - Step 660 Global step 660 Train loss 2.38 on epoch=164
05/20/2022 18:21:14 - INFO - __main__ - Step 670 Global step 670 Train loss 2.42 on epoch=167
05/20/2022 18:21:15 - INFO - __main__ - Step 680 Global step 680 Train loss 2.33 on epoch=169
05/20/2022 18:21:17 - INFO - __main__ - Step 690 Global step 690 Train loss 2.39 on epoch=172
05/20/2022 18:21:18 - INFO - __main__ - Step 700 Global step 700 Train loss 2.19 on epoch=174
05/20/2022 18:21:18 - INFO - __main__ - Global step 700 Train loss 2.34 Classification-F1 0.10126582278481013 on epoch=174
05/20/2022 18:21:20 - INFO - __main__ - Step 710 Global step 710 Train loss 2.30 on epoch=177
05/20/2022 18:21:21 - INFO - __main__ - Step 720 Global step 720 Train loss 2.07 on epoch=179
05/20/2022 18:21:23 - INFO - __main__ - Step 730 Global step 730 Train loss 2.34 on epoch=182
05/20/2022 18:21:24 - INFO - __main__ - Step 740 Global step 740 Train loss 2.20 on epoch=184
05/20/2022 18:21:25 - INFO - __main__ - Step 750 Global step 750 Train loss 2.29 on epoch=187
05/20/2022 18:21:26 - INFO - __main__ - Global step 750 Train loss 2.24 Classification-F1 0.11078022632519356 on epoch=187
05/20/2022 18:21:27 - INFO - __main__ - Step 760 Global step 760 Train loss 2.04 on epoch=189
05/20/2022 18:21:28 - INFO - __main__ - Step 770 Global step 770 Train loss 2.31 on epoch=192
05/20/2022 18:21:30 - INFO - __main__ - Step 780 Global step 780 Train loss 1.99 on epoch=194
05/20/2022 18:21:31 - INFO - __main__ - Step 790 Global step 790 Train loss 2.14 on epoch=197
05/20/2022 18:21:33 - INFO - __main__ - Step 800 Global step 800 Train loss 1.93 on epoch=199
05/20/2022 18:21:33 - INFO - __main__ - Global step 800 Train loss 2.08 Classification-F1 0.13123993558776167 on epoch=199
05/20/2022 18:21:34 - INFO - __main__ - Step 810 Global step 810 Train loss 1.98 on epoch=202
05/20/2022 18:21:36 - INFO - __main__ - Step 820 Global step 820 Train loss 2.02 on epoch=204
05/20/2022 18:21:37 - INFO - __main__ - Step 830 Global step 830 Train loss 2.06 on epoch=207
05/20/2022 18:21:38 - INFO - __main__ - Step 840 Global step 840 Train loss 1.93 on epoch=209
05/20/2022 18:21:40 - INFO - __main__ - Step 850 Global step 850 Train loss 1.86 on epoch=212
05/20/2022 18:21:40 - INFO - __main__ - Global step 850 Train loss 1.97 Classification-F1 0.08440555841482245 on epoch=212
05/20/2022 18:21:42 - INFO - __main__ - Step 860 Global step 860 Train loss 1.94 on epoch=214
05/20/2022 18:21:43 - INFO - __main__ - Step 870 Global step 870 Train loss 1.90 on epoch=217
05/20/2022 18:21:45 - INFO - __main__ - Step 880 Global step 880 Train loss 1.93 on epoch=219
05/20/2022 18:21:46 - INFO - __main__ - Step 890 Global step 890 Train loss 2.00 on epoch=222
05/20/2022 18:21:47 - INFO - __main__ - Step 900 Global step 900 Train loss 1.96 on epoch=224
05/20/2022 18:21:48 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.09210526315789473 on epoch=224
05/20/2022 18:21:49 - INFO - __main__ - Step 910 Global step 910 Train loss 1.94 on epoch=227
05/20/2022 18:21:51 - INFO - __main__ - Step 920 Global step 920 Train loss 1.82 on epoch=229
05/20/2022 18:21:52 - INFO - __main__ - Step 930 Global step 930 Train loss 1.80 on epoch=232
05/20/2022 18:21:54 - INFO - __main__ - Step 940 Global step 940 Train loss 1.77 on epoch=234
05/20/2022 18:21:55 - INFO - __main__ - Step 950 Global step 950 Train loss 1.92 on epoch=237
05/20/2022 18:21:55 - INFO - __main__ - Global step 950 Train loss 1.85 Classification-F1 0.11607142857142856 on epoch=237
05/20/2022 18:21:57 - INFO - __main__ - Step 960 Global step 960 Train loss 1.80 on epoch=239
05/20/2022 18:21:58 - INFO - __main__ - Step 970 Global step 970 Train loss 1.71 on epoch=242
05/20/2022 18:21:59 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
05/20/2022 18:22:01 - INFO - __main__ - Step 990 Global step 990 Train loss 1.84 on epoch=247
05/20/2022 18:22:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.70 on epoch=249
05/20/2022 18:22:03 - INFO - __main__ - Global step 1000 Train loss 1.75 Classification-F1 0.10969141755062681 on epoch=249
05/20/2022 18:22:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.69 on epoch=252
05/20/2022 18:22:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.71 on epoch=254
05/20/2022 18:22:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.76 on epoch=257
05/20/2022 18:22:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.63 on epoch=259
05/20/2022 18:22:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.73 on epoch=262
05/20/2022 18:22:10 - INFO - __main__ - Global step 1050 Train loss 1.70 Classification-F1 0.15535714285714286 on epoch=262
05/20/2022 18:22:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.68 on epoch=264
05/20/2022 18:22:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.65 on epoch=267
05/20/2022 18:22:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.49 on epoch=269
05/20/2022 18:22:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.64 on epoch=272
05/20/2022 18:22:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.52 on epoch=274
05/20/2022 18:22:18 - INFO - __main__ - Global step 1100 Train loss 1.60 Classification-F1 0.09822866344605476 on epoch=274
05/20/2022 18:22:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.67 on epoch=277
05/20/2022 18:22:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.57 on epoch=279
05/20/2022 18:22:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.79 on epoch=282
05/20/2022 18:22:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.57 on epoch=284
05/20/2022 18:22:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.53 on epoch=287
05/20/2022 18:22:25 - INFO - __main__ - Global step 1150 Train loss 1.63 Classification-F1 0.09615384615384615 on epoch=287
05/20/2022 18:22:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.62 on epoch=289
05/20/2022 18:22:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.61 on epoch=292
05/20/2022 18:22:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.32 on epoch=294
05/20/2022 18:22:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.53 on epoch=297
05/20/2022 18:22:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.57 on epoch=299
05/20/2022 18:22:32 - INFO - __main__ - Global step 1200 Train loss 1.53 Classification-F1 0.12819829424307036 on epoch=299
05/20/2022 18:22:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.45 on epoch=302
05/20/2022 18:22:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.43 on epoch=304
05/20/2022 18:22:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.41 on epoch=307
05/20/2022 18:22:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.45 on epoch=309
05/20/2022 18:22:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.44 on epoch=312
05/20/2022 18:22:39 - INFO - __main__ - Global step 1250 Train loss 1.43 Classification-F1 0.14222873900293254 on epoch=312
05/20/2022 18:22:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.28 on epoch=314
05/20/2022 18:22:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.45 on epoch=317
05/20/2022 18:22:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.34 on epoch=319
05/20/2022 18:22:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.39 on epoch=322
05/20/2022 18:22:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.35 on epoch=324
05/20/2022 18:22:46 - INFO - __main__ - Global step 1300 Train loss 1.36 Classification-F1 0.08904109589041095 on epoch=324
05/20/2022 18:22:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.42 on epoch=327
05/20/2022 18:22:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.37 on epoch=329
05/20/2022 18:22:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.41 on epoch=332
05/20/2022 18:22:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.43 on epoch=334
05/20/2022 18:22:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.28 on epoch=337
05/20/2022 18:22:54 - INFO - __main__ - Global step 1350 Train loss 1.38 Classification-F1 0.1468058968058968 on epoch=337
05/20/2022 18:22:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.27 on epoch=339
05/20/2022 18:22:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.32 on epoch=342
05/20/2022 18:22:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.31 on epoch=344
05/20/2022 18:22:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.33 on epoch=347
05/20/2022 18:23:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
05/20/2022 18:23:01 - INFO - __main__ - Global step 1400 Train loss 1.29 Classification-F1 0.1406926406926407 on epoch=349
05/20/2022 18:23:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/20/2022 18:23:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.33 on epoch=354
05/20/2022 18:23:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.28 on epoch=357
05/20/2022 18:23:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.36 on epoch=359
05/20/2022 18:23:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.30 on epoch=362
05/20/2022 18:23:08 - INFO - __main__ - Global step 1450 Train loss 1.30 Classification-F1 0.08783783783783784 on epoch=362
05/20/2022 18:23:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.29 on epoch=364
05/20/2022 18:23:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.29 on epoch=367
05/20/2022 18:23:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.16 on epoch=369
05/20/2022 18:23:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/20/2022 18:23:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=374
05/20/2022 18:23:15 - INFO - __main__ - Global step 1500 Train loss 1.24 Classification-F1 0.08904109589041095 on epoch=374
05/20/2022 18:23:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.14 on epoch=377
05/20/2022 18:23:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.28 on epoch=379
05/20/2022 18:23:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.35 on epoch=382
05/20/2022 18:23:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.21 on epoch=384
05/20/2022 18:23:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
05/20/2022 18:23:23 - INFO - __main__ - Global step 1550 Train loss 1.24 Classification-F1 0.10389610389610389 on epoch=387
05/20/2022 18:23:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.21 on epoch=389
05/20/2022 18:23:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=392
05/20/2022 18:23:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
05/20/2022 18:23:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.15 on epoch=397
05/20/2022 18:23:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.26 on epoch=399
05/20/2022 18:23:30 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.1487390633041688 on epoch=399
05/20/2022 18:23:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
05/20/2022 18:23:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.19 on epoch=404
05/20/2022 18:23:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.25 on epoch=407
05/20/2022 18:23:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.20 on epoch=409
05/20/2022 18:23:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.15 on epoch=412
05/20/2022 18:23:37 - INFO - __main__ - Global step 1650 Train loss 1.18 Classification-F1 0.1 on epoch=412
05/20/2022 18:23:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.20 on epoch=414
05/20/2022 18:23:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
05/20/2022 18:23:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.99 on epoch=419
05/20/2022 18:23:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.26 on epoch=422
05/20/2022 18:23:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.18 on epoch=424
05/20/2022 18:23:45 - INFO - __main__ - Global step 1700 Train loss 1.17 Classification-F1 0.1785345717234262 on epoch=424
05/20/2022 18:23:45 - INFO - __main__ - Saving model with best Classification-F1: 0.16277641277641278 -> 0.1785345717234262 on epoch=424, global_step=1700
05/20/2022 18:23:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.18 on epoch=427
05/20/2022 18:23:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.07 on epoch=429
05/20/2022 18:23:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.24 on epoch=432
05/20/2022 18:23:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.10 on epoch=434
05/20/2022 18:23:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.12 on epoch=437
05/20/2022 18:23:52 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.13430127041742287 on epoch=437
05/20/2022 18:23:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.23 on epoch=439
05/20/2022 18:23:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.18 on epoch=442
05/20/2022 18:23:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.18 on epoch=444
05/20/2022 18:23:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.19 on epoch=447
05/20/2022 18:23:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/20/2022 18:23:59 - INFO - __main__ - Global step 1800 Train loss 1.18 Classification-F1 0.13482414242292662 on epoch=449
05/20/2022 18:24:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.28 on epoch=452
05/20/2022 18:24:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/20/2022 18:24:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.22 on epoch=457
05/20/2022 18:24:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.22 on epoch=459
05/20/2022 18:24:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.18 on epoch=462
05/20/2022 18:24:06 - INFO - __main__ - Global step 1850 Train loss 1.21 Classification-F1 0.11616161616161616 on epoch=462
05/20/2022 18:24:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.06 on epoch=464
05/20/2022 18:24:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.26 on epoch=467
05/20/2022 18:24:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
05/20/2022 18:24:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.01 on epoch=472
05/20/2022 18:24:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/20/2022 18:24:14 - INFO - __main__ - Global step 1900 Train loss 1.14 Classification-F1 0.09999999999999999 on epoch=474
05/20/2022 18:24:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.14 on epoch=477
05/20/2022 18:24:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.00 on epoch=479
05/20/2022 18:24:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
05/20/2022 18:24:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.18 on epoch=484
05/20/2022 18:24:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.16 on epoch=487
05/20/2022 18:24:21 - INFO - __main__ - Global step 1950 Train loss 1.12 Classification-F1 0.18847006651884698 on epoch=487
05/20/2022 18:24:21 - INFO - __main__ - Saving model with best Classification-F1: 0.1785345717234262 -> 0.18847006651884698 on epoch=487, global_step=1950
05/20/2022 18:24:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.08 on epoch=489
05/20/2022 18:24:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.17 on epoch=492
05/20/2022 18:24:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.10 on epoch=494
05/20/2022 18:24:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.18 on epoch=497
05/20/2022 18:24:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.01 on epoch=499
05/20/2022 18:24:30 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.1769449715370019 on epoch=499
05/20/2022 18:24:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.20 on epoch=502
05/20/2022 18:24:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.22 on epoch=504
05/20/2022 18:24:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.10 on epoch=507
05/20/2022 18:24:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.06 on epoch=509
05/20/2022 18:24:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.22 on epoch=512
05/20/2022 18:24:37 - INFO - __main__ - Global step 2050 Train loss 1.16 Classification-F1 0.21964285714285714 on epoch=512
05/20/2022 18:24:37 - INFO - __main__ - Saving model with best Classification-F1: 0.18847006651884698 -> 0.21964285714285714 on epoch=512, global_step=2050
05/20/2022 18:24:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.01 on epoch=514
05/20/2022 18:24:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.21 on epoch=517
05/20/2022 18:24:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.15 on epoch=519
05/20/2022 18:24:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
05/20/2022 18:24:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.14 on epoch=524
05/20/2022 18:24:45 - INFO - __main__ - Global step 2100 Train loss 1.12 Classification-F1 0.1 on epoch=524
05/20/2022 18:24:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.09 on epoch=527
05/20/2022 18:24:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.18 on epoch=529
05/20/2022 18:24:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.11 on epoch=532
05/20/2022 18:24:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.08 on epoch=534
05/20/2022 18:24:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.17 on epoch=537
05/20/2022 18:24:52 - INFO - __main__ - Global step 2150 Train loss 1.12 Classification-F1 0.1 on epoch=537
05/20/2022 18:24:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.14 on epoch=539
05/20/2022 18:24:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=542
05/20/2022 18:24:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.11 on epoch=544
05/20/2022 18:24:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.06 on epoch=547
05/20/2022 18:24:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.11 on epoch=549
05/20/2022 18:25:00 - INFO - __main__ - Global step 2200 Train loss 1.11 Classification-F1 0.18172268907563027 on epoch=549
05/20/2022 18:25:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/20/2022 18:25:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.08 on epoch=554
05/20/2022 18:25:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.10 on epoch=557
05/20/2022 18:25:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/20/2022 18:25:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.03 on epoch=562
05/20/2022 18:25:07 - INFO - __main__ - Global step 2250 Train loss 1.05 Classification-F1 0.11859154929577466 on epoch=562
05/20/2022 18:25:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/20/2022 18:25:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=567
05/20/2022 18:25:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.14 on epoch=569
05/20/2022 18:25:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.10 on epoch=572
05/20/2022 18:25:14 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.02 on epoch=574
05/20/2022 18:25:15 - INFO - __main__ - Global step 2300 Train loss 1.08 Classification-F1 0.16563380281690143 on epoch=574
05/20/2022 18:25:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/20/2022 18:25:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.00 on epoch=579
05/20/2022 18:25:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/20/2022 18:25:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.07 on epoch=584
05/20/2022 18:25:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=587
05/20/2022 18:25:23 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.18055555555555552 on epoch=587
05/20/2022 18:25:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.06 on epoch=589
05/20/2022 18:25:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.07 on epoch=592
05/20/2022 18:25:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.99 on epoch=594
05/20/2022 18:25:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
05/20/2022 18:25:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=599
05/20/2022 18:25:30 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.19807311222361285 on epoch=599
05/20/2022 18:25:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.04 on epoch=602
05/20/2022 18:25:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/20/2022 18:25:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.05 on epoch=607
05/20/2022 18:25:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
05/20/2022 18:25:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.94 on epoch=612
05/20/2022 18:25:38 - INFO - __main__ - Global step 2450 Train loss 0.99 Classification-F1 0.18783068783068785 on epoch=612
05/20/2022 18:25:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.08 on epoch=614
05/20/2022 18:25:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=617
05/20/2022 18:25:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
05/20/2022 18:25:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.09 on epoch=622
05/20/2022 18:25:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
05/20/2022 18:25:45 - INFO - __main__ - Global step 2500 Train loss 1.06 Classification-F1 0.109375 on epoch=624
05/20/2022 18:25:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.05 on epoch=627
05/20/2022 18:25:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.97 on epoch=629
05/20/2022 18:25:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
05/20/2022 18:25:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.01 on epoch=634
05/20/2022 18:25:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/20/2022 18:25:53 - INFO - __main__ - Global step 2550 Train loss 1.02 Classification-F1 0.1527777777777778 on epoch=637
05/20/2022 18:25:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.10 on epoch=639
05/20/2022 18:25:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.02 on epoch=642
05/20/2022 18:25:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.04 on epoch=644
05/20/2022 18:25:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/20/2022 18:26:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.10 on epoch=649
05/20/2022 18:26:01 - INFO - __main__ - Global step 2600 Train loss 1.06 Classification-F1 0.19836065573770492 on epoch=649
05/20/2022 18:26:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.13 on epoch=652
05/20/2022 18:26:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.15 on epoch=654
05/20/2022 18:26:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
05/20/2022 18:26:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/20/2022 18:26:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.07 on epoch=662
05/20/2022 18:26:08 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.13067758749069247 on epoch=662
05/20/2022 18:26:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.00 on epoch=664
05/20/2022 18:26:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.05 on epoch=667
05/20/2022 18:26:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.03 on epoch=669
05/20/2022 18:26:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.14 on epoch=672
05/20/2022 18:26:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.03 on epoch=674
05/20/2022 18:26:15 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.1 on epoch=674
05/20/2022 18:26:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.13 on epoch=677
05/20/2022 18:26:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.00 on epoch=679
05/20/2022 18:26:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.87 on epoch=682
05/20/2022 18:26:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/20/2022 18:26:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.05 on epoch=687
05/20/2022 18:26:23 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=687
05/20/2022 18:26:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.11 on epoch=689
05/20/2022 18:26:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.04 on epoch=692
05/20/2022 18:26:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/20/2022 18:26:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.02 on epoch=697
05/20/2022 18:26:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.02 on epoch=699
05/20/2022 18:26:31 - INFO - __main__ - Global step 2800 Train loss 1.02 Classification-F1 0.22478991596638653 on epoch=699
05/20/2022 18:26:31 - INFO - __main__ - Saving model with best Classification-F1: 0.21964285714285714 -> 0.22478991596638653 on epoch=699, global_step=2800
05/20/2022 18:26:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.08 on epoch=702
05/20/2022 18:26:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.19 on epoch=704
05/20/2022 18:26:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.08 on epoch=707
05/20/2022 18:26:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/20/2022 18:26:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
05/20/2022 18:26:38 - INFO - __main__ - Global step 2850 Train loss 1.09 Classification-F1 0.1 on epoch=712
05/20/2022 18:26:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.89 on epoch=714
05/20/2022 18:26:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.02 on epoch=717
05/20/2022 18:26:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/20/2022 18:26:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.00 on epoch=722
05/20/2022 18:26:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/20/2022 18:26:46 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.11065943992773261 on epoch=724
05/20/2022 18:26:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.09 on epoch=727
05/20/2022 18:26:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.95 on epoch=729
05/20/2022 18:26:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.97 on epoch=732
05/20/2022 18:26:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
05/20/2022 18:26:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.88 on epoch=737
05/20/2022 18:26:53 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.19310511089681776 on epoch=737
05/20/2022 18:26:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.92 on epoch=739
05/20/2022 18:26:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.03 on epoch=742
05/20/2022 18:26:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.00 on epoch=744
05/20/2022 18:26:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/20/2022 18:27:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.04 on epoch=749
05/20/2022 18:27:01 - INFO - __main__ - Global step 3000 Train loss 1.00 Classification-F1 0.1488095238095238 on epoch=749
05/20/2022 18:27:01 - INFO - __main__ - save last model!
05/20/2022 18:27:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 18:27:01 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 18:27:01 - INFO - __main__ - Printing 3 examples
05/20/2022 18:27:01 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 18:27:01 - INFO - __main__ - ['others']
05/20/2022 18:27:01 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 18:27:01 - INFO - __main__ - ['others']
05/20/2022 18:27:01 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 18:27:01 - INFO - __main__ - ['others']
05/20/2022 18:27:01 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:27:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:27:02 - INFO - __main__ - Printing 3 examples
05/20/2022 18:27:02 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:27:02 - INFO - __main__ - ['happy']
05/20/2022 18:27:02 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:27:02 - INFO - __main__ - ['happy']
05/20/2022 18:27:02 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:27:02 - INFO - __main__ - ['happy']
05/20/2022 18:27:02 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:27:02 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:27:02 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:27:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:27:02 - INFO - __main__ - Printing 3 examples
05/20/2022 18:27:02 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:27:02 - INFO - __main__ - ['happy']
05/20/2022 18:27:02 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:27:02 - INFO - __main__ - ['happy']
05/20/2022 18:27:02 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:27:02 - INFO - __main__ - ['happy']
05/20/2022 18:27:02 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:27:02 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:27:02 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:27:04 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:27:08 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:27:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:27:08 - INFO - __main__ - Starting training!
05/20/2022 18:27:10 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 18:27:58 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.2_8_predictions.txt
05/20/2022 18:27:58 - INFO - __main__ - Classification-F1 on test data: 0.0428
05/20/2022 18:27:58 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.22478991596638653, test_performance=0.0428240268843188
05/20/2022 18:27:58 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
05/20/2022 18:27:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:27:59 - INFO - __main__ - Printing 3 examples
05/20/2022 18:27:59 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:27:59 - INFO - __main__ - ['happy']
05/20/2022 18:27:59 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:27:59 - INFO - __main__ - ['happy']
05/20/2022 18:27:59 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:27:59 - INFO - __main__ - ['happy']
05/20/2022 18:27:59 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:27:59 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:27:59 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:27:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:27:59 - INFO - __main__ - Printing 3 examples
05/20/2022 18:27:59 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:27:59 - INFO - __main__ - ['happy']
05/20/2022 18:27:59 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:27:59 - INFO - __main__ - ['happy']
05/20/2022 18:27:59 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:27:59 - INFO - __main__ - ['happy']
05/20/2022 18:27:59 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:27:59 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:27:59 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:28:06 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:28:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:28:07 - INFO - __main__ - Starting training!
05/20/2022 18:28:08 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=2
05/20/2022 18:28:09 - INFO - __main__ - Step 20 Global step 20 Train loss 6.48 on epoch=4
05/20/2022 18:28:11 - INFO - __main__ - Step 30 Global step 30 Train loss 6.08 on epoch=7
05/20/2022 18:28:12 - INFO - __main__ - Step 40 Global step 40 Train loss 5.84 on epoch=9
05/20/2022 18:28:13 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=12
05/20/2022 18:28:18 - INFO - __main__ - Global step 50 Train loss 6.13 Classification-F1 0.0 on epoch=12
05/20/2022 18:28:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 18:28:20 - INFO - __main__ - Step 60 Global step 60 Train loss 5.38 on epoch=14
05/20/2022 18:28:21 - INFO - __main__ - Step 70 Global step 70 Train loss 5.24 on epoch=17
05/20/2022 18:28:22 - INFO - __main__ - Step 80 Global step 80 Train loss 5.02 on epoch=19
05/20/2022 18:28:24 - INFO - __main__ - Step 90 Global step 90 Train loss 4.63 on epoch=22
05/20/2022 18:28:25 - INFO - __main__ - Step 100 Global step 100 Train loss 4.76 on epoch=24
05/20/2022 18:28:27 - INFO - __main__ - Global step 100 Train loss 5.01 Classification-F1 0.03240740740740741 on epoch=24
05/20/2022 18:28:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03240740740740741 on epoch=24, global_step=100
05/20/2022 18:28:28 - INFO - __main__ - Step 110 Global step 110 Train loss 4.42 on epoch=27
05/20/2022 18:28:30 - INFO - __main__ - Step 120 Global step 120 Train loss 4.43 on epoch=29
05/20/2022 18:28:31 - INFO - __main__ - Step 130 Global step 130 Train loss 4.34 on epoch=32
05/20/2022 18:28:32 - INFO - __main__ - Step 140 Global step 140 Train loss 4.21 on epoch=34
05/20/2022 18:28:34 - INFO - __main__ - Step 150 Global step 150 Train loss 4.07 on epoch=37
05/20/2022 18:28:35 - INFO - __main__ - Global step 150 Train loss 4.29 Classification-F1 0.0810126582278481 on epoch=37
05/20/2022 18:28:35 - INFO - __main__ - Saving model with best Classification-F1: 0.03240740740740741 -> 0.0810126582278481 on epoch=37, global_step=150
05/20/2022 18:28:36 - INFO - __main__ - Step 160 Global step 160 Train loss 4.01 on epoch=39
05/20/2022 18:28:38 - INFO - __main__ - Step 170 Global step 170 Train loss 3.60 on epoch=42
05/20/2022 18:28:39 - INFO - __main__ - Step 180 Global step 180 Train loss 3.72 on epoch=44
05/20/2022 18:28:41 - INFO - __main__ - Step 190 Global step 190 Train loss 3.54 on epoch=47
05/20/2022 18:28:42 - INFO - __main__ - Step 200 Global step 200 Train loss 3.49 on epoch=49
05/20/2022 18:28:43 - INFO - __main__ - Global step 200 Train loss 3.68 Classification-F1 0.09615384615384615 on epoch=49
05/20/2022 18:28:43 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.09615384615384615 on epoch=49, global_step=200
05/20/2022 18:28:44 - INFO - __main__ - Step 210 Global step 210 Train loss 3.38 on epoch=52
05/20/2022 18:28:45 - INFO - __main__ - Step 220 Global step 220 Train loss 3.22 on epoch=54
05/20/2022 18:28:47 - INFO - __main__ - Step 230 Global step 230 Train loss 2.98 on epoch=57
05/20/2022 18:28:48 - INFO - __main__ - Step 240 Global step 240 Train loss 3.02 on epoch=59
05/20/2022 18:28:50 - INFO - __main__ - Step 250 Global step 250 Train loss 2.91 on epoch=62
05/20/2022 18:28:50 - INFO - __main__ - Global step 250 Train loss 3.10 Classification-F1 0.07594936708860758 on epoch=62
05/20/2022 18:28:51 - INFO - __main__ - Step 260 Global step 260 Train loss 2.92 on epoch=64
05/20/2022 18:28:53 - INFO - __main__ - Step 270 Global step 270 Train loss 2.86 on epoch=67
05/20/2022 18:28:54 - INFO - __main__ - Step 280 Global step 280 Train loss 2.92 on epoch=69
05/20/2022 18:28:56 - INFO - __main__ - Step 290 Global step 290 Train loss 2.66 on epoch=72
05/20/2022 18:28:57 - INFO - __main__ - Step 300 Global step 300 Train loss 2.77 on epoch=74
05/20/2022 18:28:58 - INFO - __main__ - Global step 300 Train loss 2.83 Classification-F1 0.1 on epoch=74
05/20/2022 18:28:58 - INFO - __main__ - Saving model with best Classification-F1: 0.09615384615384615 -> 0.1 on epoch=74, global_step=300
05/20/2022 18:28:59 - INFO - __main__ - Step 310 Global step 310 Train loss 2.63 on epoch=77
05/20/2022 18:29:00 - INFO - __main__ - Step 320 Global step 320 Train loss 2.64 on epoch=79
05/20/2022 18:29:02 - INFO - __main__ - Step 330 Global step 330 Train loss 2.38 on epoch=82
05/20/2022 18:29:03 - INFO - __main__ - Step 340 Global step 340 Train loss 2.53 on epoch=84
05/20/2022 18:29:04 - INFO - __main__ - Step 350 Global step 350 Train loss 2.43 on epoch=87
05/20/2022 18:29:05 - INFO - __main__ - Global step 350 Train loss 2.52 Classification-F1 0.1118421052631579 on epoch=87
05/20/2022 18:29:05 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1118421052631579 on epoch=87, global_step=350
05/20/2022 18:29:06 - INFO - __main__ - Step 360 Global step 360 Train loss 2.44 on epoch=89
05/20/2022 18:29:08 - INFO - __main__ - Step 370 Global step 370 Train loss 2.32 on epoch=92
05/20/2022 18:29:09 - INFO - __main__ - Step 380 Global step 380 Train loss 2.39 on epoch=94
05/20/2022 18:29:10 - INFO - __main__ - Step 390 Global step 390 Train loss 2.27 on epoch=97
05/20/2022 18:29:12 - INFO - __main__ - Step 400 Global step 400 Train loss 2.31 on epoch=99
05/20/2022 18:29:12 - INFO - __main__ - Global step 400 Train loss 2.35 Classification-F1 0.11714285714285715 on epoch=99
05/20/2022 18:29:12 - INFO - __main__ - Saving model with best Classification-F1: 0.1118421052631579 -> 0.11714285714285715 on epoch=99, global_step=400
05/20/2022 18:29:13 - INFO - __main__ - Step 410 Global step 410 Train loss 2.25 on epoch=102
05/20/2022 18:29:15 - INFO - __main__ - Step 420 Global step 420 Train loss 2.12 on epoch=104
05/20/2022 18:29:16 - INFO - __main__ - Step 430 Global step 430 Train loss 2.30 on epoch=107
05/20/2022 18:29:17 - INFO - __main__ - Step 440 Global step 440 Train loss 2.07 on epoch=109
05/20/2022 18:29:19 - INFO - __main__ - Step 450 Global step 450 Train loss 2.13 on epoch=112
05/20/2022 18:29:19 - INFO - __main__ - Global step 450 Train loss 2.17 Classification-F1 0.1646076146076146 on epoch=112
05/20/2022 18:29:19 - INFO - __main__ - Saving model with best Classification-F1: 0.11714285714285715 -> 0.1646076146076146 on epoch=112, global_step=450
05/20/2022 18:29:21 - INFO - __main__ - Step 460 Global step 460 Train loss 1.98 on epoch=114
05/20/2022 18:29:22 - INFO - __main__ - Step 470 Global step 470 Train loss 1.92 on epoch=117
05/20/2022 18:29:23 - INFO - __main__ - Step 480 Global step 480 Train loss 2.01 on epoch=119
05/20/2022 18:29:24 - INFO - __main__ - Step 490 Global step 490 Train loss 1.65 on epoch=122
05/20/2022 18:29:26 - INFO - __main__ - Step 500 Global step 500 Train loss 1.68 on epoch=124
05/20/2022 18:29:26 - INFO - __main__ - Global step 500 Train loss 1.85 Classification-F1 0.17436974789915968 on epoch=124
05/20/2022 18:29:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1646076146076146 -> 0.17436974789915968 on epoch=124, global_step=500
05/20/2022 18:29:28 - INFO - __main__ - Step 510 Global step 510 Train loss 1.80 on epoch=127
05/20/2022 18:29:29 - INFO - __main__ - Step 520 Global step 520 Train loss 1.71 on epoch=129
05/20/2022 18:29:31 - INFO - __main__ - Step 530 Global step 530 Train loss 1.77 on epoch=132
05/20/2022 18:29:32 - INFO - __main__ - Step 540 Global step 540 Train loss 1.67 on epoch=134
05/20/2022 18:29:34 - INFO - __main__ - Step 550 Global step 550 Train loss 1.77 on epoch=137
05/20/2022 18:29:34 - INFO - __main__ - Global step 550 Train loss 1.74 Classification-F1 0.16785714285714287 on epoch=137
05/20/2022 18:29:35 - INFO - __main__ - Step 560 Global step 560 Train loss 1.63 on epoch=139
05/20/2022 18:29:37 - INFO - __main__ - Step 570 Global step 570 Train loss 1.56 on epoch=142
05/20/2022 18:29:38 - INFO - __main__ - Step 580 Global step 580 Train loss 1.51 on epoch=144
05/20/2022 18:29:40 - INFO - __main__ - Step 590 Global step 590 Train loss 1.51 on epoch=147
05/20/2022 18:29:41 - INFO - __main__ - Step 600 Global step 600 Train loss 1.47 on epoch=149
05/20/2022 18:29:42 - INFO - __main__ - Global step 600 Train loss 1.53 Classification-F1 0.17368421052631577 on epoch=149
05/20/2022 18:29:43 - INFO - __main__ - Step 610 Global step 610 Train loss 1.63 on epoch=152
05/20/2022 18:29:44 - INFO - __main__ - Step 620 Global step 620 Train loss 1.65 on epoch=154
05/20/2022 18:29:45 - INFO - __main__ - Step 630 Global step 630 Train loss 1.34 on epoch=157
05/20/2022 18:29:47 - INFO - __main__ - Step 640 Global step 640 Train loss 1.45 on epoch=159
05/20/2022 18:29:48 - INFO - __main__ - Step 650 Global step 650 Train loss 1.36 on epoch=162
05/20/2022 18:29:49 - INFO - __main__ - Global step 650 Train loss 1.49 Classification-F1 0.1 on epoch=162
05/20/2022 18:29:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.49 on epoch=164
05/20/2022 18:29:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.48 on epoch=167
05/20/2022 18:29:53 - INFO - __main__ - Step 680 Global step 680 Train loss 1.48 on epoch=169
05/20/2022 18:29:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.34 on epoch=172
05/20/2022 18:29:55 - INFO - __main__ - Step 700 Global step 700 Train loss 1.50 on epoch=174
05/20/2022 18:29:56 - INFO - __main__ - Global step 700 Train loss 1.46 Classification-F1 0.1 on epoch=174
05/20/2022 18:29:57 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=177
05/20/2022 18:29:58 - INFO - __main__ - Step 720 Global step 720 Train loss 1.33 on epoch=179
05/20/2022 18:30:00 - INFO - __main__ - Step 730 Global step 730 Train loss 1.33 on epoch=182
05/20/2022 18:30:01 - INFO - __main__ - Step 740 Global step 740 Train loss 1.20 on epoch=184
05/20/2022 18:30:03 - INFO - __main__ - Step 750 Global step 750 Train loss 1.23 on epoch=187
05/20/2022 18:30:03 - INFO - __main__ - Global step 750 Train loss 1.28 Classification-F1 0.1 on epoch=187
05/20/2022 18:30:04 - INFO - __main__ - Step 760 Global step 760 Train loss 1.35 on epoch=189
05/20/2022 18:30:06 - INFO - __main__ - Step 770 Global step 770 Train loss 1.32 on epoch=192
05/20/2022 18:30:07 - INFO - __main__ - Step 780 Global step 780 Train loss 1.23 on epoch=194
05/20/2022 18:30:09 - INFO - __main__ - Step 790 Global step 790 Train loss 1.25 on epoch=197
05/20/2022 18:30:10 - INFO - __main__ - Step 800 Global step 800 Train loss 1.27 on epoch=199
05/20/2022 18:30:11 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.1 on epoch=199
05/20/2022 18:30:12 - INFO - __main__ - Step 810 Global step 810 Train loss 1.35 on epoch=202
05/20/2022 18:30:14 - INFO - __main__ - Step 820 Global step 820 Train loss 1.34 on epoch=204
05/20/2022 18:30:15 - INFO - __main__ - Step 830 Global step 830 Train loss 1.13 on epoch=207
05/20/2022 18:30:16 - INFO - __main__ - Step 840 Global step 840 Train loss 1.30 on epoch=209
05/20/2022 18:30:18 - INFO - __main__ - Step 850 Global step 850 Train loss 1.25 on epoch=212
05/20/2022 18:30:18 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.16666666666666666 on epoch=212
05/20/2022 18:30:20 - INFO - __main__ - Step 860 Global step 860 Train loss 1.30 on epoch=214
05/20/2022 18:30:21 - INFO - __main__ - Step 870 Global step 870 Train loss 1.29 on epoch=217
05/20/2022 18:30:22 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
05/20/2022 18:30:24 - INFO - __main__ - Step 890 Global step 890 Train loss 1.29 on epoch=222
05/20/2022 18:30:25 - INFO - __main__ - Step 900 Global step 900 Train loss 1.21 on epoch=224
05/20/2022 18:30:26 - INFO - __main__ - Global step 900 Train loss 1.28 Classification-F1 0.1 on epoch=224
05/20/2022 18:30:27 - INFO - __main__ - Step 910 Global step 910 Train loss 1.34 on epoch=227
05/20/2022 18:30:28 - INFO - __main__ - Step 920 Global step 920 Train loss 1.19 on epoch=229
05/20/2022 18:30:30 - INFO - __main__ - Step 930 Global step 930 Train loss 1.21 on epoch=232
05/20/2022 18:30:31 - INFO - __main__ - Step 940 Global step 940 Train loss 1.36 on epoch=234
05/20/2022 18:30:33 - INFO - __main__ - Step 950 Global step 950 Train loss 1.29 on epoch=237
05/20/2022 18:30:33 - INFO - __main__ - Global step 950 Train loss 1.28 Classification-F1 0.13034188034188032 on epoch=237
05/20/2022 18:30:35 - INFO - __main__ - Step 960 Global step 960 Train loss 1.04 on epoch=239
05/20/2022 18:30:36 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=242
05/20/2022 18:30:37 - INFO - __main__ - Step 980 Global step 980 Train loss 1.20 on epoch=244
05/20/2022 18:30:39 - INFO - __main__ - Step 990 Global step 990 Train loss 1.20 on epoch=247
05/20/2022 18:30:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.11 on epoch=249
05/20/2022 18:30:41 - INFO - __main__ - Global step 1000 Train loss 1.15 Classification-F1 0.2097902097902098 on epoch=249
05/20/2022 18:30:41 - INFO - __main__ - Saving model with best Classification-F1: 0.17436974789915968 -> 0.2097902097902098 on epoch=249, global_step=1000
05/20/2022 18:30:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.08 on epoch=252
05/20/2022 18:30:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.17 on epoch=254
05/20/2022 18:30:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/20/2022 18:30:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.23 on epoch=259
05/20/2022 18:30:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.04 on epoch=262
05/20/2022 18:30:49 - INFO - __main__ - Global step 1050 Train loss 1.12 Classification-F1 0.21717171717171715 on epoch=262
05/20/2022 18:30:49 - INFO - __main__ - Saving model with best Classification-F1: 0.2097902097902098 -> 0.21717171717171715 on epoch=262, global_step=1050
05/20/2022 18:30:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
05/20/2022 18:30:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.99 on epoch=267
05/20/2022 18:30:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.95 on epoch=269
05/20/2022 18:30:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.14 on epoch=272
05/20/2022 18:30:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.15 on epoch=274
05/20/2022 18:30:56 - INFO - __main__ - Global step 1100 Train loss 1.06 Classification-F1 0.1638655462184874 on epoch=274
05/20/2022 18:30:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.23 on epoch=277
05/20/2022 18:30:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.20 on epoch=279
05/20/2022 18:31:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
05/20/2022 18:31:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.17 on epoch=284
05/20/2022 18:31:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.94 on epoch=287
05/20/2022 18:31:04 - INFO - __main__ - Global step 1150 Train loss 1.14 Classification-F1 0.12912912912912913 on epoch=287
05/20/2022 18:31:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
05/20/2022 18:31:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.04 on epoch=292
05/20/2022 18:31:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.08 on epoch=294
05/20/2022 18:31:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.07 on epoch=297
05/20/2022 18:31:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.15 on epoch=299
05/20/2022 18:31:11 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.1 on epoch=299
05/20/2022 18:31:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.06 on epoch=302
05/20/2022 18:31:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=304
05/20/2022 18:31:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.99 on epoch=307
05/20/2022 18:31:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/20/2022 18:31:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.03 on epoch=312
05/20/2022 18:31:18 - INFO - __main__ - Global step 1250 Train loss 1.05 Classification-F1 0.197603121516165 on epoch=312
05/20/2022 18:31:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.11 on epoch=314
05/20/2022 18:31:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=317
05/20/2022 18:31:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.12 on epoch=319
05/20/2022 18:31:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.13 on epoch=322
05/20/2022 18:31:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.05 on epoch=324
05/20/2022 18:31:26 - INFO - __main__ - Global step 1300 Train loss 1.12 Classification-F1 0.17811480585078396 on epoch=324
05/20/2022 18:31:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.06 on epoch=327
05/20/2022 18:31:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.97 on epoch=329
05/20/2022 18:31:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.00 on epoch=332
05/20/2022 18:31:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.01 on epoch=334
05/20/2022 18:31:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.14 on epoch=337
05/20/2022 18:31:33 - INFO - __main__ - Global step 1350 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=337
05/20/2022 18:31:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.18 on epoch=339
05/20/2022 18:31:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=342
05/20/2022 18:31:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=344
05/20/2022 18:31:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.01 on epoch=347
05/20/2022 18:31:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.13 on epoch=349
05/20/2022 18:31:40 - INFO - __main__ - Global step 1400 Train loss 1.10 Classification-F1 0.1527777777777778 on epoch=349
05/20/2022 18:31:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.17 on epoch=352
05/20/2022 18:31:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.09 on epoch=354
05/20/2022 18:31:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.14 on epoch=357
05/20/2022 18:31:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.06 on epoch=359
05/20/2022 18:31:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.05 on epoch=362
05/20/2022 18:31:47 - INFO - __main__ - Global step 1450 Train loss 1.10 Classification-F1 0.10966810966810966 on epoch=362
05/20/2022 18:31:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.10 on epoch=364
05/20/2022 18:31:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.16 on epoch=367
05/20/2022 18:31:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.10 on epoch=369
05/20/2022 18:31:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=372
05/20/2022 18:31:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.02 on epoch=374
05/20/2022 18:31:54 - INFO - __main__ - Global step 1500 Train loss 1.07 Classification-F1 0.15606060606060607 on epoch=374
05/20/2022 18:31:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.96 on epoch=377
05/20/2022 18:31:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/20/2022 18:31:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.04 on epoch=382
05/20/2022 18:31:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
05/20/2022 18:32:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.97 on epoch=387
05/20/2022 18:32:01 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.09868421052631579 on epoch=387
05/20/2022 18:32:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.04 on epoch=389
05/20/2022 18:32:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.09 on epoch=392
05/20/2022 18:32:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.98 on epoch=394
05/20/2022 18:32:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.02 on epoch=397
05/20/2022 18:32:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
05/20/2022 18:32:08 - INFO - __main__ - Global step 1600 Train loss 1.05 Classification-F1 0.0974025974025974 on epoch=399
05/20/2022 18:32:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.04 on epoch=402
05/20/2022 18:32:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=404
05/20/2022 18:32:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.03 on epoch=407
05/20/2022 18:32:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
05/20/2022 18:32:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.99 on epoch=412
05/20/2022 18:32:15 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.2011385199240987 on epoch=412
05/20/2022 18:32:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.95 on epoch=414
05/20/2022 18:32:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.96 on epoch=417
05/20/2022 18:32:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.95 on epoch=419
05/20/2022 18:32:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/20/2022 18:32:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.01 on epoch=424
05/20/2022 18:32:22 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.2011926367643246 on epoch=424
05/20/2022 18:32:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.09 on epoch=427
05/20/2022 18:32:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.88 on epoch=429
05/20/2022 18:32:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.05 on epoch=432
05/20/2022 18:32:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.04 on epoch=434
05/20/2022 18:32:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.02 on epoch=437
05/20/2022 18:32:28 - INFO - __main__ - Global step 1750 Train loss 1.02 Classification-F1 0.10126582278481013 on epoch=437
05/20/2022 18:32:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
05/20/2022 18:32:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/20/2022 18:32:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.98 on epoch=444
05/20/2022 18:32:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.01 on epoch=447
05/20/2022 18:32:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
05/20/2022 18:32:35 - INFO - __main__ - Global step 1800 Train loss 1.00 Classification-F1 0.1767857142857143 on epoch=449
05/20/2022 18:32:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.00 on epoch=452
05/20/2022 18:32:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
05/20/2022 18:32:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.02 on epoch=457
05/20/2022 18:32:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=459
05/20/2022 18:32:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.97 on epoch=462
05/20/2022 18:32:42 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.13157894736842107 on epoch=462
05/20/2022 18:32:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.00 on epoch=464
05/20/2022 18:32:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.96 on epoch=467
05/20/2022 18:32:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.93 on epoch=469
05/20/2022 18:32:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/20/2022 18:32:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=474
05/20/2022 18:32:49 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.1 on epoch=474
05/20/2022 18:32:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.98 on epoch=477
05/20/2022 18:32:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.94 on epoch=479
05/20/2022 18:32:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.93 on epoch=482
05/20/2022 18:32:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.00 on epoch=484
05/20/2022 18:32:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.99 on epoch=487
05/20/2022 18:32:55 - INFO - __main__ - Global step 1950 Train loss 0.97 Classification-F1 0.19537815126050417 on epoch=487
05/20/2022 18:32:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.02 on epoch=489
05/20/2022 18:32:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.91 on epoch=492
05/20/2022 18:32:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.08 on epoch=494
05/20/2022 18:33:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.99 on epoch=497
05/20/2022 18:33:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/20/2022 18:33:02 - INFO - __main__ - Global step 2000 Train loss 0.99 Classification-F1 0.27645590314598795 on epoch=499
05/20/2022 18:33:02 - INFO - __main__ - Saving model with best Classification-F1: 0.21717171717171715 -> 0.27645590314598795 on epoch=499, global_step=2000
05/20/2022 18:33:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/20/2022 18:33:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
05/20/2022 18:33:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.00 on epoch=507
05/20/2022 18:33:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.96 on epoch=509
05/20/2022 18:33:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.10 on epoch=512
05/20/2022 18:33:09 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.1388888888888889 on epoch=512
05/20/2022 18:33:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.00 on epoch=514
05/20/2022 18:33:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/20/2022 18:33:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.95 on epoch=519
05/20/2022 18:33:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.02 on epoch=522
05/20/2022 18:33:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.04 on epoch=524
05/20/2022 18:33:16 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.3629129129129129 on epoch=524
05/20/2022 18:33:16 - INFO - __main__ - Saving model with best Classification-F1: 0.27645590314598795 -> 0.3629129129129129 on epoch=524, global_step=2100
05/20/2022 18:33:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/20/2022 18:33:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.05 on epoch=529
05/20/2022 18:33:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.97 on epoch=532
05/20/2022 18:33:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.92 on epoch=534
05/20/2022 18:33:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.07 on epoch=537
05/20/2022 18:33:23 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.25918367346938775 on epoch=537
05/20/2022 18:33:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.04 on epoch=539
05/20/2022 18:33:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.02 on epoch=542
05/20/2022 18:33:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/20/2022 18:33:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/20/2022 18:33:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.96 on epoch=549
05/20/2022 18:33:29 - INFO - __main__ - Global step 2200 Train loss 1.01 Classification-F1 0.11732186732186733 on epoch=549
05/20/2022 18:33:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/20/2022 18:33:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.99 on epoch=554
05/20/2022 18:33:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.11 on epoch=557
05/20/2022 18:33:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.09 on epoch=559
05/20/2022 18:33:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
05/20/2022 18:33:36 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.2032315020119898 on epoch=562
05/20/2022 18:33:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/20/2022 18:33:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.00 on epoch=567
05/20/2022 18:33:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.96 on epoch=569
05/20/2022 18:33:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/20/2022 18:33:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/20/2022 18:33:43 - INFO - __main__ - Global step 2300 Train loss 0.98 Classification-F1 0.27036679536679536 on epoch=574
05/20/2022 18:33:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/20/2022 18:33:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.00 on epoch=579
05/20/2022 18:33:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
05/20/2022 18:33:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.04 on epoch=584
05/20/2022 18:33:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/20/2022 18:33:50 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.15587044534412953 on epoch=587
05/20/2022 18:33:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/20/2022 18:33:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.11 on epoch=592
05/20/2022 18:33:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/20/2022 18:33:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
05/20/2022 18:33:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.04 on epoch=599
05/20/2022 18:33:56 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.09528130671506352 on epoch=599
05/20/2022 18:33:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/20/2022 18:33:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/20/2022 18:34:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/20/2022 18:34:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.88 on epoch=609
05/20/2022 18:34:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.98 on epoch=612
05/20/2022 18:34:03 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.15714285714285717 on epoch=612
05/20/2022 18:34:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.93 on epoch=614
05/20/2022 18:34:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.90 on epoch=617
05/20/2022 18:34:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/20/2022 18:34:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/20/2022 18:34:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.94 on epoch=624
05/20/2022 18:34:10 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.1774628879892038 on epoch=624
05/20/2022 18:34:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/20/2022 18:34:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.04 on epoch=629
05/20/2022 18:34:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.99 on epoch=632
05/20/2022 18:34:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.05 on epoch=634
05/20/2022 18:34:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.97 on epoch=637
05/20/2022 18:34:17 - INFO - __main__ - Global step 2550 Train loss 1.01 Classification-F1 0.18385416666666665 on epoch=637
05/20/2022 18:34:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
05/20/2022 18:34:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.98 on epoch=642
05/20/2022 18:34:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.99 on epoch=644
05/20/2022 18:34:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/20/2022 18:34:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.98 on epoch=649
05/20/2022 18:34:24 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.17813655142422266 on epoch=649
05/20/2022 18:34:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.87 on epoch=652
05/20/2022 18:34:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
05/20/2022 18:34:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.91 on epoch=657
05/20/2022 18:34:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.90 on epoch=659
05/20/2022 18:34:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/20/2022 18:34:31 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.1698691172375383 on epoch=662
05/20/2022 18:34:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.92 on epoch=664
05/20/2022 18:34:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.00 on epoch=667
05/20/2022 18:34:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/20/2022 18:34:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.05 on epoch=672
05/20/2022 18:34:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/20/2022 18:34:38 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.14583504477121498 on epoch=674
05/20/2022 18:34:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.05 on epoch=677
05/20/2022 18:34:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.89 on epoch=679
05/20/2022 18:34:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/20/2022 18:34:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/20/2022 18:34:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.97 on epoch=687
05/20/2022 18:34:45 - INFO - __main__ - Global step 2750 Train loss 0.96 Classification-F1 0.19811563763176665 on epoch=687
05/20/2022 18:34:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.01 on epoch=689
05/20/2022 18:34:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
05/20/2022 18:34:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.92 on epoch=694
05/20/2022 18:34:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.02 on epoch=697
05/20/2022 18:34:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.90 on epoch=699
05/20/2022 18:34:52 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.07971014492753624 on epoch=699
05/20/2022 18:34:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.91 on epoch=702
05/20/2022 18:34:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.09 on epoch=704
05/20/2022 18:34:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.95 on epoch=707
05/20/2022 18:34:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/20/2022 18:34:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
05/20/2022 18:34:59 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.1865079365079365 on epoch=712
05/20/2022 18:35:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/20/2022 18:35:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
05/20/2022 18:35:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.02 on epoch=719
05/20/2022 18:35:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/20/2022 18:35:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/20/2022 18:35:06 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.16091269841269842 on epoch=724
05/20/2022 18:35:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/20/2022 18:35:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
05/20/2022 18:35:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.93 on epoch=732
05/20/2022 18:35:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/20/2022 18:35:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.91 on epoch=737
05/20/2022 18:35:13 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.22316451664277753 on epoch=737
05/20/2022 18:35:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/20/2022 18:35:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.99 on epoch=742
05/20/2022 18:35:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/20/2022 18:35:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.92 on epoch=747
05/20/2022 18:35:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
05/20/2022 18:35:20 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.20094080338266385 on epoch=749
05/20/2022 18:35:20 - INFO - __main__ - save last model!
05/20/2022 18:35:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 18:35:20 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 18:35:20 - INFO - __main__ - Printing 3 examples
05/20/2022 18:35:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 18:35:20 - INFO - __main__ - ['others']
05/20/2022 18:35:20 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 18:35:20 - INFO - __main__ - ['others']
05/20/2022 18:35:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 18:35:20 - INFO - __main__ - ['others']
05/20/2022 18:35:20 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:35:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:35:22 - INFO - __main__ - Printing 3 examples
05/20/2022 18:35:22 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:35:22 - INFO - __main__ - ['happy']
05/20/2022 18:35:22 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:35:22 - INFO - __main__ - ['happy']
05/20/2022 18:35:22 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:35:22 - INFO - __main__ - ['happy']
05/20/2022 18:35:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:35:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:35:22 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:35:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:35:22 - INFO - __main__ - Printing 3 examples
05/20/2022 18:35:22 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:35:22 - INFO - __main__ - ['happy']
05/20/2022 18:35:22 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:35:22 - INFO - __main__ - ['happy']
05/20/2022 18:35:22 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:35:22 - INFO - __main__ - ['happy']
05/20/2022 18:35:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:35:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:35:22 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:35:23 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:35:28 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 18:35:28 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:35:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:35:28 - INFO - __main__ - Starting training!
05/20/2022 18:36:11 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.5_8_predictions.txt
05/20/2022 18:36:11 - INFO - __main__ - Classification-F1 on test data: 0.0681
05/20/2022 18:36:11 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.3629129129129129, test_performance=0.06813091170116173
05/20/2022 18:36:11 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
05/20/2022 18:36:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:36:12 - INFO - __main__ - Printing 3 examples
05/20/2022 18:36:12 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:36:12 - INFO - __main__ - ['happy']
05/20/2022 18:36:12 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:36:12 - INFO - __main__ - ['happy']
05/20/2022 18:36:12 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:36:12 - INFO - __main__ - ['happy']
05/20/2022 18:36:12 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:36:12 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:36:12 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:36:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:36:12 - INFO - __main__ - Printing 3 examples
05/20/2022 18:36:12 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:36:12 - INFO - __main__ - ['happy']
05/20/2022 18:36:12 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:36:12 - INFO - __main__ - ['happy']
05/20/2022 18:36:12 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:36:12 - INFO - __main__ - ['happy']
05/20/2022 18:36:12 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:36:12 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:36:12 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:36:18 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:36:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:36:19 - INFO - __main__ - Starting training!
05/20/2022 18:36:21 - INFO - __main__ - Step 10 Global step 10 Train loss 6.66 on epoch=2
05/20/2022 18:36:22 - INFO - __main__ - Step 20 Global step 20 Train loss 6.37 on epoch=4
05/20/2022 18:36:24 - INFO - __main__ - Step 30 Global step 30 Train loss 6.08 on epoch=7
05/20/2022 18:36:25 - INFO - __main__ - Step 40 Global step 40 Train loss 5.91 on epoch=9
05/20/2022 18:36:27 - INFO - __main__ - Step 50 Global step 50 Train loss 5.70 on epoch=12
05/20/2022 18:36:28 - INFO - __main__ - Global step 50 Train loss 6.14 Classification-F1 0.0 on epoch=12
05/20/2022 18:36:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 18:36:30 - INFO - __main__ - Step 60 Global step 60 Train loss 5.34 on epoch=14
05/20/2022 18:36:31 - INFO - __main__ - Step 70 Global step 70 Train loss 5.08 on epoch=17
05/20/2022 18:36:33 - INFO - __main__ - Step 80 Global step 80 Train loss 4.97 on epoch=19
05/20/2022 18:36:34 - INFO - __main__ - Step 90 Global step 90 Train loss 4.78 on epoch=22
05/20/2022 18:36:35 - INFO - __main__ - Step 100 Global step 100 Train loss 4.71 on epoch=24
05/20/2022 18:36:38 - INFO - __main__ - Global step 100 Train loss 4.98 Classification-F1 0.0 on epoch=24
05/20/2022 18:36:40 - INFO - __main__ - Step 110 Global step 110 Train loss 4.32 on epoch=27
05/20/2022 18:36:41 - INFO - __main__ - Step 120 Global step 120 Train loss 4.31 on epoch=29
05/20/2022 18:36:42 - INFO - __main__ - Step 130 Global step 130 Train loss 4.12 on epoch=32
05/20/2022 18:36:44 - INFO - __main__ - Step 140 Global step 140 Train loss 4.08 on epoch=34
05/20/2022 18:36:45 - INFO - __main__ - Step 150 Global step 150 Train loss 3.97 on epoch=37
05/20/2022 18:36:46 - INFO - __main__ - Global step 150 Train loss 4.16 Classification-F1 0.13624338624338622 on epoch=37
05/20/2022 18:36:46 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.13624338624338622 on epoch=37, global_step=150
05/20/2022 18:36:47 - INFO - __main__ - Step 160 Global step 160 Train loss 3.87 on epoch=39
05/20/2022 18:36:49 - INFO - __main__ - Step 170 Global step 170 Train loss 3.62 on epoch=42
05/20/2022 18:36:50 - INFO - __main__ - Step 180 Global step 180 Train loss 3.45 on epoch=44
05/20/2022 18:36:51 - INFO - __main__ - Step 190 Global step 190 Train loss 3.36 on epoch=47
05/20/2022 18:36:53 - INFO - __main__ - Step 200 Global step 200 Train loss 3.45 on epoch=49
05/20/2022 18:36:53 - INFO - __main__ - Global step 200 Train loss 3.55 Classification-F1 0.1565276828434723 on epoch=49
05/20/2022 18:36:53 - INFO - __main__ - Saving model with best Classification-F1: 0.13624338624338622 -> 0.1565276828434723 on epoch=49, global_step=200
05/20/2022 18:36:55 - INFO - __main__ - Step 210 Global step 210 Train loss 3.20 on epoch=52
05/20/2022 18:36:56 - INFO - __main__ - Step 220 Global step 220 Train loss 3.27 on epoch=54
05/20/2022 18:36:57 - INFO - __main__ - Step 230 Global step 230 Train loss 2.92 on epoch=57
05/20/2022 18:36:59 - INFO - __main__ - Step 240 Global step 240 Train loss 3.12 on epoch=59
05/20/2022 18:37:00 - INFO - __main__ - Step 250 Global step 250 Train loss 2.99 on epoch=62
05/20/2022 18:37:01 - INFO - __main__ - Global step 250 Train loss 3.10 Classification-F1 0.12568058076225044 on epoch=62
05/20/2022 18:37:02 - INFO - __main__ - Step 260 Global step 260 Train loss 3.07 on epoch=64
05/20/2022 18:37:03 - INFO - __main__ - Step 270 Global step 270 Train loss 2.78 on epoch=67
05/20/2022 18:37:05 - INFO - __main__ - Step 280 Global step 280 Train loss 2.87 on epoch=69
05/20/2022 18:37:06 - INFO - __main__ - Step 290 Global step 290 Train loss 2.64 on epoch=72
05/20/2022 18:37:07 - INFO - __main__ - Step 300 Global step 300 Train loss 2.77 on epoch=74
05/20/2022 18:37:08 - INFO - __main__ - Global step 300 Train loss 2.83 Classification-F1 0.13347763347763347 on epoch=74
05/20/2022 18:37:09 - INFO - __main__ - Step 310 Global step 310 Train loss 2.53 on epoch=77
05/20/2022 18:37:11 - INFO - __main__ - Step 320 Global step 320 Train loss 2.54 on epoch=79
05/20/2022 18:37:12 - INFO - __main__ - Step 330 Global step 330 Train loss 2.50 on epoch=82
05/20/2022 18:37:13 - INFO - __main__ - Step 340 Global step 340 Train loss 2.28 on epoch=84
05/20/2022 18:37:15 - INFO - __main__ - Step 350 Global step 350 Train loss 2.42 on epoch=87
05/20/2022 18:37:15 - INFO - __main__ - Global step 350 Train loss 2.45 Classification-F1 0.1659804426145136 on epoch=87
05/20/2022 18:37:15 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.1659804426145136 on epoch=87, global_step=350
05/20/2022 18:37:17 - INFO - __main__ - Step 360 Global step 360 Train loss 2.36 on epoch=89
05/20/2022 18:37:18 - INFO - __main__ - Step 370 Global step 370 Train loss 2.36 on epoch=92
05/20/2022 18:37:19 - INFO - __main__ - Step 380 Global step 380 Train loss 2.44 on epoch=94
05/20/2022 18:37:21 - INFO - __main__ - Step 390 Global step 390 Train loss 2.11 on epoch=97
05/20/2022 18:37:22 - INFO - __main__ - Step 400 Global step 400 Train loss 2.42 on epoch=99
05/20/2022 18:37:22 - INFO - __main__ - Global step 400 Train loss 2.34 Classification-F1 0.13034188034188032 on epoch=99
05/20/2022 18:37:24 - INFO - __main__ - Step 410 Global step 410 Train loss 2.21 on epoch=102
05/20/2022 18:37:25 - INFO - __main__ - Step 420 Global step 420 Train loss 2.29 on epoch=104
05/20/2022 18:37:27 - INFO - __main__ - Step 430 Global step 430 Train loss 2.11 on epoch=107
05/20/2022 18:37:28 - INFO - __main__ - Step 440 Global step 440 Train loss 2.18 on epoch=109
05/20/2022 18:37:29 - INFO - __main__ - Step 450 Global step 450 Train loss 1.90 on epoch=112
05/20/2022 18:37:30 - INFO - __main__ - Global step 450 Train loss 2.14 Classification-F1 0.1576923076923077 on epoch=112
05/20/2022 18:37:31 - INFO - __main__ - Step 460 Global step 460 Train loss 2.14 on epoch=114
05/20/2022 18:37:33 - INFO - __main__ - Step 470 Global step 470 Train loss 1.90 on epoch=117
05/20/2022 18:37:34 - INFO - __main__ - Step 480 Global step 480 Train loss 1.96 on epoch=119
05/20/2022 18:37:35 - INFO - __main__ - Step 490 Global step 490 Train loss 1.71 on epoch=122
05/20/2022 18:37:36 - INFO - __main__ - Step 500 Global step 500 Train loss 1.92 on epoch=124
05/20/2022 18:37:37 - INFO - __main__ - Global step 500 Train loss 1.93 Classification-F1 0.13067758749069247 on epoch=124
05/20/2022 18:37:38 - INFO - __main__ - Step 510 Global step 510 Train loss 1.66 on epoch=127
05/20/2022 18:37:40 - INFO - __main__ - Step 520 Global step 520 Train loss 1.67 on epoch=129
05/20/2022 18:37:41 - INFO - __main__ - Step 530 Global step 530 Train loss 1.61 on epoch=132
05/20/2022 18:37:42 - INFO - __main__ - Step 540 Global step 540 Train loss 1.78 on epoch=134
05/20/2022 18:37:44 - INFO - __main__ - Step 550 Global step 550 Train loss 1.53 on epoch=137
05/20/2022 18:37:44 - INFO - __main__ - Global step 550 Train loss 1.65 Classification-F1 0.14915966386554622 on epoch=137
05/20/2022 18:37:46 - INFO - __main__ - Step 560 Global step 560 Train loss 1.57 on epoch=139
05/20/2022 18:37:47 - INFO - __main__ - Step 570 Global step 570 Train loss 1.67 on epoch=142
05/20/2022 18:37:48 - INFO - __main__ - Step 580 Global step 580 Train loss 1.52 on epoch=144
05/20/2022 18:37:50 - INFO - __main__ - Step 590 Global step 590 Train loss 1.51 on epoch=147
05/20/2022 18:37:51 - INFO - __main__ - Step 600 Global step 600 Train loss 1.46 on epoch=149
05/20/2022 18:37:52 - INFO - __main__ - Global step 600 Train loss 1.55 Classification-F1 0.16377171215880895 on epoch=149
05/20/2022 18:37:53 - INFO - __main__ - Step 610 Global step 610 Train loss 1.51 on epoch=152
05/20/2022 18:37:54 - INFO - __main__ - Step 620 Global step 620 Train loss 1.49 on epoch=154
05/20/2022 18:37:56 - INFO - __main__ - Step 630 Global step 630 Train loss 1.63 on epoch=157
05/20/2022 18:37:57 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=159
05/20/2022 18:37:59 - INFO - __main__ - Step 650 Global step 650 Train loss 1.55 on epoch=162
05/20/2022 18:37:59 - INFO - __main__ - Global step 650 Train loss 1.52 Classification-F1 0.13275613275613274 on epoch=162
05/20/2022 18:38:00 - INFO - __main__ - Step 660 Global step 660 Train loss 1.56 on epoch=164
05/20/2022 18:38:02 - INFO - __main__ - Step 670 Global step 670 Train loss 1.48 on epoch=167
05/20/2022 18:38:03 - INFO - __main__ - Step 680 Global step 680 Train loss 1.50 on epoch=169
05/20/2022 18:38:04 - INFO - __main__ - Step 690 Global step 690 Train loss 1.49 on epoch=172
05/20/2022 18:38:05 - INFO - __main__ - Step 700 Global step 700 Train loss 1.45 on epoch=174
05/20/2022 18:38:06 - INFO - __main__ - Global step 700 Train loss 1.50 Classification-F1 0.13936867182846935 on epoch=174
05/20/2022 18:38:07 - INFO - __main__ - Step 710 Global step 710 Train loss 1.37 on epoch=177
05/20/2022 18:38:09 - INFO - __main__ - Step 720 Global step 720 Train loss 1.45 on epoch=179
05/20/2022 18:38:10 - INFO - __main__ - Step 730 Global step 730 Train loss 1.50 on epoch=182
05/20/2022 18:38:11 - INFO - __main__ - Step 740 Global step 740 Train loss 1.48 on epoch=184
05/20/2022 18:38:13 - INFO - __main__ - Step 750 Global step 750 Train loss 1.46 on epoch=187
05/20/2022 18:38:13 - INFO - __main__ - Global step 750 Train loss 1.45 Classification-F1 0.1 on epoch=187
05/20/2022 18:38:14 - INFO - __main__ - Step 760 Global step 760 Train loss 1.44 on epoch=189
05/20/2022 18:38:16 - INFO - __main__ - Step 770 Global step 770 Train loss 1.62 on epoch=192
05/20/2022 18:38:17 - INFO - __main__ - Step 780 Global step 780 Train loss 1.52 on epoch=194
05/20/2022 18:38:18 - INFO - __main__ - Step 790 Global step 790 Train loss 1.41 on epoch=197
05/20/2022 18:38:20 - INFO - __main__ - Step 800 Global step 800 Train loss 1.38 on epoch=199
05/20/2022 18:38:20 - INFO - __main__ - Global step 800 Train loss 1.47 Classification-F1 0.15607940446650126 on epoch=199
05/20/2022 18:38:21 - INFO - __main__ - Step 810 Global step 810 Train loss 1.44 on epoch=202
05/20/2022 18:38:23 - INFO - __main__ - Step 820 Global step 820 Train loss 1.48 on epoch=204
05/20/2022 18:38:25 - INFO - __main__ - Step 830 Global step 830 Train loss 1.39 on epoch=207
05/20/2022 18:38:26 - INFO - __main__ - Step 840 Global step 840 Train loss 1.37 on epoch=209
05/20/2022 18:38:27 - INFO - __main__ - Step 850 Global step 850 Train loss 1.23 on epoch=212
05/20/2022 18:38:28 - INFO - __main__ - Global step 850 Train loss 1.38 Classification-F1 0.12194223401119952 on epoch=212
05/20/2022 18:38:29 - INFO - __main__ - Step 860 Global step 860 Train loss 1.27 on epoch=214
05/20/2022 18:38:31 - INFO - __main__ - Step 870 Global step 870 Train loss 1.34 on epoch=217
05/20/2022 18:38:32 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
05/20/2022 18:38:34 - INFO - __main__ - Step 890 Global step 890 Train loss 1.31 on epoch=222
05/20/2022 18:38:36 - INFO - __main__ - Step 900 Global step 900 Train loss 1.45 on epoch=224
05/20/2022 18:38:36 - INFO - __main__ - Global step 900 Train loss 1.34 Classification-F1 0.14179439381386358 on epoch=224
05/20/2022 18:38:38 - INFO - __main__ - Step 910 Global step 910 Train loss 1.30 on epoch=227
05/20/2022 18:38:39 - INFO - __main__ - Step 920 Global step 920 Train loss 1.29 on epoch=229
05/20/2022 18:38:40 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
05/20/2022 18:38:42 - INFO - __main__ - Step 940 Global step 940 Train loss 1.23 on epoch=234
05/20/2022 18:38:43 - INFO - __main__ - Step 950 Global step 950 Train loss 1.26 on epoch=237
05/20/2022 18:38:44 - INFO - __main__ - Global step 950 Train loss 1.29 Classification-F1 0.18161263800798685 on epoch=237
05/20/2022 18:38:44 - INFO - __main__ - Saving model with best Classification-F1: 0.1659804426145136 -> 0.18161263800798685 on epoch=237, global_step=950
05/20/2022 18:38:45 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/20/2022 18:38:46 - INFO - __main__ - Step 970 Global step 970 Train loss 1.17 on epoch=242
05/20/2022 18:38:48 - INFO - __main__ - Step 980 Global step 980 Train loss 1.37 on epoch=244
05/20/2022 18:38:49 - INFO - __main__ - Step 990 Global step 990 Train loss 1.29 on epoch=247
05/20/2022 18:38:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.33 on epoch=249
05/20/2022 18:38:51 - INFO - __main__ - Global step 1000 Train loss 1.29 Classification-F1 0.13034188034188032 on epoch=249
05/20/2022 18:38:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.31 on epoch=252
05/20/2022 18:38:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.26 on epoch=254
05/20/2022 18:38:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.30 on epoch=257
05/20/2022 18:38:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.30 on epoch=259
05/20/2022 18:38:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.15 on epoch=262
05/20/2022 18:38:59 - INFO - __main__ - Global step 1050 Train loss 1.26 Classification-F1 0.1715492957746479 on epoch=262
05/20/2022 18:39:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.27 on epoch=264
05/20/2022 18:39:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.13 on epoch=267
05/20/2022 18:39:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=269
05/20/2022 18:39:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.15 on epoch=272
05/20/2022 18:39:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
05/20/2022 18:39:06 - INFO - __main__ - Global step 1100 Train loss 1.17 Classification-F1 0.18166666666666667 on epoch=274
05/20/2022 18:39:06 - INFO - __main__ - Saving model with best Classification-F1: 0.18161263800798685 -> 0.18166666666666667 on epoch=274, global_step=1100
05/20/2022 18:39:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.22 on epoch=277
05/20/2022 18:39:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.30 on epoch=279
05/20/2022 18:39:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
05/20/2022 18:39:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.25 on epoch=284
05/20/2022 18:39:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.25 on epoch=287
05/20/2022 18:39:14 - INFO - __main__ - Global step 1150 Train loss 1.23 Classification-F1 0.1970899470899471 on epoch=287
05/20/2022 18:39:14 - INFO - __main__ - Saving model with best Classification-F1: 0.18166666666666667 -> 0.1970899470899471 on epoch=287, global_step=1150
05/20/2022 18:39:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.21 on epoch=289
05/20/2022 18:39:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.13 on epoch=292
05/20/2022 18:39:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.23 on epoch=294
05/20/2022 18:39:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.08 on epoch=297
05/20/2022 18:39:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.27 on epoch=299
05/20/2022 18:39:21 - INFO - __main__ - Global step 1200 Train loss 1.19 Classification-F1 0.15625 on epoch=299
05/20/2022 18:39:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.23 on epoch=302
05/20/2022 18:39:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.20 on epoch=304
05/20/2022 18:39:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.13 on epoch=307
05/20/2022 18:39:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.14 on epoch=309
05/20/2022 18:39:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.22 on epoch=312
05/20/2022 18:39:28 - INFO - __main__ - Global step 1250 Train loss 1.18 Classification-F1 0.1527777777777778 on epoch=312
05/20/2022 18:39:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.23 on epoch=314
05/20/2022 18:39:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.26 on epoch=317
05/20/2022 18:39:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
05/20/2022 18:39:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.16 on epoch=322
05/20/2022 18:39:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.05 on epoch=324
05/20/2022 18:39:36 - INFO - __main__ - Global step 1300 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=324
05/20/2022 18:39:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
05/20/2022 18:39:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.11 on epoch=329
05/20/2022 18:39:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.19 on epoch=332
05/20/2022 18:39:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.22 on epoch=334
05/20/2022 18:39:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.24 on epoch=337
05/20/2022 18:39:43 - INFO - __main__ - Global step 1350 Train loss 1.16 Classification-F1 0.1 on epoch=337
05/20/2022 18:39:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.13 on epoch=339
05/20/2022 18:39:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.19 on epoch=342
05/20/2022 18:39:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.24 on epoch=344
05/20/2022 18:39:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.26 on epoch=347
05/20/2022 18:39:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.99 on epoch=349
05/20/2022 18:39:51 - INFO - __main__ - Global step 1400 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=349
05/20/2022 18:39:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.06 on epoch=352
05/20/2022 18:39:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/20/2022 18:39:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/20/2022 18:39:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=359
05/20/2022 18:39:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=362
05/20/2022 18:39:58 - INFO - __main__ - Global step 1450 Train loss 1.06 Classification-F1 0.10256410256410256 on epoch=362
05/20/2022 18:39:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/20/2022 18:40:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
05/20/2022 18:40:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.16 on epoch=369
05/20/2022 18:40:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=372
05/20/2022 18:40:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=374
05/20/2022 18:40:05 - INFO - __main__ - Global step 1500 Train loss 1.15 Classification-F1 0.20842474769635805 on epoch=374
05/20/2022 18:40:05 - INFO - __main__ - Saving model with best Classification-F1: 0.1970899470899471 -> 0.20842474769635805 on epoch=374, global_step=1500
05/20/2022 18:40:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.03 on epoch=377
05/20/2022 18:40:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.13 on epoch=379
05/20/2022 18:40:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.10 on epoch=382
05/20/2022 18:40:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.02 on epoch=384
05/20/2022 18:40:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.00 on epoch=387
05/20/2022 18:40:13 - INFO - __main__ - Global step 1550 Train loss 1.06 Classification-F1 0.1875 on epoch=387
05/20/2022 18:40:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.11 on epoch=389
05/20/2022 18:40:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.08 on epoch=392
05/20/2022 18:40:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.02 on epoch=394
05/20/2022 18:40:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.06 on epoch=397
05/20/2022 18:40:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.01 on epoch=399
05/20/2022 18:40:20 - INFO - __main__ - Global step 1600 Train loss 1.06 Classification-F1 0.17341430499325233 on epoch=399
05/20/2022 18:40:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.07 on epoch=402
05/20/2022 18:40:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.10 on epoch=404
05/20/2022 18:40:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.88 on epoch=407
05/20/2022 18:40:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
05/20/2022 18:40:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.05 on epoch=412
05/20/2022 18:40:28 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.21765734265734268 on epoch=412
05/20/2022 18:40:28 - INFO - __main__ - Saving model with best Classification-F1: 0.20842474769635805 -> 0.21765734265734268 on epoch=412, global_step=1650
05/20/2022 18:40:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.16 on epoch=414
05/20/2022 18:40:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/20/2022 18:40:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.01 on epoch=419
05/20/2022 18:40:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.09 on epoch=422
05/20/2022 18:40:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.09 on epoch=424
05/20/2022 18:40:36 - INFO - __main__ - Global step 1700 Train loss 1.08 Classification-F1 0.11710526315789474 on epoch=424
05/20/2022 18:40:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
05/20/2022 18:40:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.10 on epoch=429
05/20/2022 18:40:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.10 on epoch=432
05/20/2022 18:40:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.02 on epoch=434
05/20/2022 18:40:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.03 on epoch=437
05/20/2022 18:40:44 - INFO - __main__ - Global step 1750 Train loss 1.06 Classification-F1 0.1 on epoch=437
05/20/2022 18:40:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.07 on epoch=439
05/20/2022 18:40:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
05/20/2022 18:40:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/20/2022 18:40:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.01 on epoch=447
05/20/2022 18:40:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
05/20/2022 18:40:52 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.1 on epoch=449
05/20/2022 18:40:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
05/20/2022 18:40:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/20/2022 18:40:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.89 on epoch=457
05/20/2022 18:40:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.06 on epoch=459
05/20/2022 18:40:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.08 on epoch=462
05/20/2022 18:41:00 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.14004914004914004 on epoch=462
05/20/2022 18:41:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.07 on epoch=464
05/20/2022 18:41:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.99 on epoch=467
05/20/2022 18:41:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.95 on epoch=469
05/20/2022 18:41:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/20/2022 18:41:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.02 on epoch=474
05/20/2022 18:41:07 - INFO - __main__ - Global step 1900 Train loss 1.00 Classification-F1 0.1 on epoch=474
05/20/2022 18:41:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/20/2022 18:41:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
05/20/2022 18:41:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=482
05/20/2022 18:41:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.15 on epoch=484
05/20/2022 18:41:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.14 on epoch=487
05/20/2022 18:41:15 - INFO - __main__ - Global step 1950 Train loss 1.07 Classification-F1 0.1843681917211329 on epoch=487
05/20/2022 18:41:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.99 on epoch=489
05/20/2022 18:41:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.98 on epoch=492
05/20/2022 18:41:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.92 on epoch=494
05/20/2022 18:41:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.05 on epoch=497
05/20/2022 18:41:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.97 on epoch=499
05/20/2022 18:41:22 - INFO - __main__ - Global step 2000 Train loss 0.98 Classification-F1 0.13047619047619047 on epoch=499
05/20/2022 18:41:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.05 on epoch=502
05/20/2022 18:41:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.04 on epoch=504
05/20/2022 18:41:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
05/20/2022 18:41:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.92 on epoch=509
05/20/2022 18:41:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.20 on epoch=512
05/20/2022 18:41:29 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.1 on epoch=512
05/20/2022 18:41:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
05/20/2022 18:41:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/20/2022 18:41:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.92 on epoch=519
05/20/2022 18:41:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.06 on epoch=522
05/20/2022 18:41:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.97 on epoch=524
05/20/2022 18:41:36 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.15054945054945054 on epoch=524
05/20/2022 18:41:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
05/20/2022 18:41:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.08 on epoch=529
05/20/2022 18:41:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.04 on epoch=532
05/20/2022 18:41:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.94 on epoch=534
05/20/2022 18:41:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.05 on epoch=537
05/20/2022 18:41:44 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.14621798689696247 on epoch=537
05/20/2022 18:41:45 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.94 on epoch=539
05/20/2022 18:41:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.20 on epoch=542
05/20/2022 18:41:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
05/20/2022 18:41:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.08 on epoch=547
05/20/2022 18:41:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
05/20/2022 18:41:51 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.16061705989110708 on epoch=549
05/20/2022 18:41:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/20/2022 18:41:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=554
05/20/2022 18:41:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/20/2022 18:41:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/20/2022 18:41:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/20/2022 18:41:59 - INFO - __main__ - Global step 2250 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=562
05/20/2022 18:42:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/20/2022 18:42:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.96 on epoch=567
05/20/2022 18:42:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.04 on epoch=569
05/20/2022 18:42:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.03 on epoch=572
05/20/2022 18:42:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/20/2022 18:42:06 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=574
05/20/2022 18:42:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.04 on epoch=577
05/20/2022 18:42:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=579
05/20/2022 18:42:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.01 on epoch=582
05/20/2022 18:42:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.91 on epoch=584
05/20/2022 18:42:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/20/2022 18:42:13 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.14791288566243194 on epoch=587
05/20/2022 18:42:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.89 on epoch=589
05/20/2022 18:42:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.90 on epoch=592
05/20/2022 18:42:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.92 on epoch=594
05/20/2022 18:42:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.09 on epoch=597
05/20/2022 18:42:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/20/2022 18:42:21 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.1 on epoch=599
05/20/2022 18:42:22 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.92 on epoch=602
05/20/2022 18:42:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/20/2022 18:42:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.95 on epoch=607
05/20/2022 18:42:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/20/2022 18:42:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/20/2022 18:42:28 - INFO - __main__ - Global step 2450 Train loss 0.99 Classification-F1 0.10135135135135136 on epoch=612
05/20/2022 18:42:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=614
05/20/2022 18:42:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.99 on epoch=617
05/20/2022 18:42:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/20/2022 18:42:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/20/2022 18:42:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.01 on epoch=624
05/20/2022 18:42:35 - INFO - __main__ - Global step 2500 Train loss 1.00 Classification-F1 0.18407494145199066 on epoch=624
05/20/2022 18:42:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.97 on epoch=627
05/20/2022 18:42:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.96 on epoch=629
05/20/2022 18:42:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.99 on epoch=632
05/20/2022 18:42:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.87 on epoch=634
05/20/2022 18:42:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.90 on epoch=637
05/20/2022 18:42:43 - INFO - __main__ - Global step 2550 Train loss 0.94 Classification-F1 0.1774628879892038 on epoch=637
05/20/2022 18:42:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.08 on epoch=639
05/20/2022 18:42:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.99 on epoch=642
05/20/2022 18:42:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.98 on epoch=644
05/20/2022 18:42:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
05/20/2022 18:42:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/20/2022 18:42:50 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.1 on epoch=649
05/20/2022 18:42:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.93 on epoch=652
05/20/2022 18:42:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
05/20/2022 18:42:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
05/20/2022 18:42:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/20/2022 18:42:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.85 on epoch=662
05/20/2022 18:42:57 - INFO - __main__ - Global step 2650 Train loss 0.94 Classification-F1 0.1 on epoch=662
05/20/2022 18:42:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.99 on epoch=664
05/20/2022 18:43:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.99 on epoch=667
05/20/2022 18:43:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.95 on epoch=669
05/20/2022 18:43:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.94 on epoch=672
05/20/2022 18:43:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
05/20/2022 18:43:04 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
05/20/2022 18:43:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/20/2022 18:43:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.96 on epoch=679
05/20/2022 18:43:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/20/2022 18:43:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=684
05/20/2022 18:43:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.94 on epoch=687
05/20/2022 18:43:11 - INFO - __main__ - Global step 2750 Train loss 0.96 Classification-F1 0.09090909090909091 on epoch=687
05/20/2022 18:43:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.04 on epoch=689
05/20/2022 18:43:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
05/20/2022 18:43:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.04 on epoch=694
05/20/2022 18:43:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.01 on epoch=697
05/20/2022 18:43:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
05/20/2022 18:43:19 - INFO - __main__ - Global step 2800 Train loss 1.02 Classification-F1 0.12368421052631579 on epoch=699
05/20/2022 18:43:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.06 on epoch=702
05/20/2022 18:43:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/20/2022 18:43:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.86 on epoch=707
05/20/2022 18:43:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/20/2022 18:43:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.03 on epoch=712
05/20/2022 18:43:26 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.10389610389610389 on epoch=712
05/20/2022 18:43:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/20/2022 18:43:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.94 on epoch=717
05/20/2022 18:43:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/20/2022 18:43:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.99 on epoch=722
05/20/2022 18:43:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/20/2022 18:43:33 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.09493670886075949 on epoch=724
05/20/2022 18:43:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.85 on epoch=727
05/20/2022 18:43:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/20/2022 18:43:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
05/20/2022 18:43:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/20/2022 18:43:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/20/2022 18:43:40 - INFO - __main__ - Global step 2950 Train loss 0.93 Classification-F1 0.1 on epoch=737
05/20/2022 18:43:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.90 on epoch=739
05/20/2022 18:43:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.94 on epoch=742
05/20/2022 18:43:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.00 on epoch=744
05/20/2022 18:43:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/20/2022 18:43:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/20/2022 18:43:47 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.1 on epoch=749
05/20/2022 18:43:47 - INFO - __main__ - save last model!
05/20/2022 18:43:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 18:43:48 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 18:43:48 - INFO - __main__ - Printing 3 examples
05/20/2022 18:43:48 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 18:43:48 - INFO - __main__ - ['others']
05/20/2022 18:43:48 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 18:43:48 - INFO - __main__ - ['others']
05/20/2022 18:43:48 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 18:43:48 - INFO - __main__ - ['others']
05/20/2022 18:43:48 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:43:48 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:43:48 - INFO - __main__ - Printing 3 examples
05/20/2022 18:43:48 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:43:48 - INFO - __main__ - ['happy']
05/20/2022 18:43:48 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:43:48 - INFO - __main__ - ['happy']
05/20/2022 18:43:48 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:43:48 - INFO - __main__ - ['happy']
05/20/2022 18:43:48 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:43:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:43:49 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:43:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:43:49 - INFO - __main__ - Printing 3 examples
05/20/2022 18:43:49 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:43:49 - INFO - __main__ - ['happy']
05/20/2022 18:43:49 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:43:49 - INFO - __main__ - ['happy']
05/20/2022 18:43:49 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:43:49 - INFO - __main__ - ['happy']
05/20/2022 18:43:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:43:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:43:49 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:43:50 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:43:54 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:43:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:43:55 - INFO - __main__ - Starting training!
05/20/2022 18:43:55 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 18:44:38 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.4_8_predictions.txt
05/20/2022 18:44:38 - INFO - __main__ - Classification-F1 on test data: 0.0332
05/20/2022 18:44:38 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.21765734265734268, test_performance=0.03324837737583468
05/20/2022 18:44:38 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
05/20/2022 18:44:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:44:39 - INFO - __main__ - Printing 3 examples
05/20/2022 18:44:39 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:44:39 - INFO - __main__ - ['happy']
05/20/2022 18:44:39 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:44:39 - INFO - __main__ - ['happy']
05/20/2022 18:44:39 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:44:39 - INFO - __main__ - ['happy']
05/20/2022 18:44:39 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:44:39 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:44:39 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:44:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:44:39 - INFO - __main__ - Printing 3 examples
05/20/2022 18:44:39 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:44:39 - INFO - __main__ - ['happy']
05/20/2022 18:44:39 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:44:39 - INFO - __main__ - ['happy']
05/20/2022 18:44:39 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:44:39 - INFO - __main__ - ['happy']
05/20/2022 18:44:39 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:44:39 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:44:39 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:44:46 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:44:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:44:46 - INFO - __main__ - Starting training!
05/20/2022 18:44:51 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=2
05/20/2022 18:44:52 - INFO - __main__ - Step 20 Global step 20 Train loss 6.42 on epoch=4
05/20/2022 18:44:54 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=7
05/20/2022 18:44:55 - INFO - __main__ - Step 40 Global step 40 Train loss 6.17 on epoch=9
05/20/2022 18:44:57 - INFO - __main__ - Step 50 Global step 50 Train loss 6.12 on epoch=12
05/20/2022 18:45:01 - INFO - __main__ - Global step 50 Train loss 6.37 Classification-F1 0.0 on epoch=12
05/20/2022 18:45:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 18:45:02 - INFO - __main__ - Step 60 Global step 60 Train loss 5.97 on epoch=14
05/20/2022 18:45:04 - INFO - __main__ - Step 70 Global step 70 Train loss 5.74 on epoch=17
05/20/2022 18:45:05 - INFO - __main__ - Step 80 Global step 80 Train loss 5.52 on epoch=19
05/20/2022 18:45:06 - INFO - __main__ - Step 90 Global step 90 Train loss 5.44 on epoch=22
05/20/2022 18:45:08 - INFO - __main__ - Step 100 Global step 100 Train loss 5.18 on epoch=24
05/20/2022 18:45:09 - INFO - __main__ - Global step 100 Train loss 5.57 Classification-F1 0.0 on epoch=24
05/20/2022 18:45:11 - INFO - __main__ - Step 110 Global step 110 Train loss 5.20 on epoch=27
05/20/2022 18:45:12 - INFO - __main__ - Step 120 Global step 120 Train loss 4.90 on epoch=29
05/20/2022 18:45:13 - INFO - __main__ - Step 130 Global step 130 Train loss 4.80 on epoch=32
05/20/2022 18:45:15 - INFO - __main__ - Step 140 Global step 140 Train loss 4.58 on epoch=34
05/20/2022 18:45:16 - INFO - __main__ - Step 150 Global step 150 Train loss 4.52 on epoch=37
05/20/2022 18:45:17 - INFO - __main__ - Global step 150 Train loss 4.80 Classification-F1 0.02886002886002886 on epoch=37
05/20/2022 18:45:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.02886002886002886 on epoch=37, global_step=150
05/20/2022 18:45:19 - INFO - __main__ - Step 160 Global step 160 Train loss 4.26 on epoch=39
05/20/2022 18:45:20 - INFO - __main__ - Step 170 Global step 170 Train loss 4.23 on epoch=42
05/20/2022 18:45:21 - INFO - __main__ - Step 180 Global step 180 Train loss 4.15 on epoch=44
05/20/2022 18:45:23 - INFO - __main__ - Step 190 Global step 190 Train loss 4.00 on epoch=47
05/20/2022 18:45:24 - INFO - __main__ - Step 200 Global step 200 Train loss 3.90 on epoch=49
05/20/2022 18:45:25 - INFO - __main__ - Global step 200 Train loss 4.11 Classification-F1 0.07792207792207792 on epoch=49
05/20/2022 18:45:25 - INFO - __main__ - Saving model with best Classification-F1: 0.02886002886002886 -> 0.07792207792207792 on epoch=49, global_step=200
05/20/2022 18:45:26 - INFO - __main__ - Step 210 Global step 210 Train loss 3.61 on epoch=52
05/20/2022 18:45:28 - INFO - __main__ - Step 220 Global step 220 Train loss 3.62 on epoch=54
05/20/2022 18:45:29 - INFO - __main__ - Step 230 Global step 230 Train loss 3.43 on epoch=57
05/20/2022 18:45:30 - INFO - __main__ - Step 240 Global step 240 Train loss 3.45 on epoch=59
05/20/2022 18:45:32 - INFO - __main__ - Step 250 Global step 250 Train loss 3.14 on epoch=62
05/20/2022 18:45:32 - INFO - __main__ - Global step 250 Train loss 3.45 Classification-F1 0.17344312918167784 on epoch=62
05/20/2022 18:45:32 - INFO - __main__ - Saving model with best Classification-F1: 0.07792207792207792 -> 0.17344312918167784 on epoch=62, global_step=250
05/20/2022 18:45:34 - INFO - __main__ - Step 260 Global step 260 Train loss 3.21 on epoch=64
05/20/2022 18:45:35 - INFO - __main__ - Step 270 Global step 270 Train loss 3.26 on epoch=67
05/20/2022 18:45:37 - INFO - __main__ - Step 280 Global step 280 Train loss 3.07 on epoch=69
05/20/2022 18:45:38 - INFO - __main__ - Step 290 Global step 290 Train loss 3.02 on epoch=72
05/20/2022 18:45:39 - INFO - __main__ - Step 300 Global step 300 Train loss 3.02 on epoch=74
05/20/2022 18:45:40 - INFO - __main__ - Global step 300 Train loss 3.11 Classification-F1 0.1 on epoch=74
05/20/2022 18:45:41 - INFO - __main__ - Step 310 Global step 310 Train loss 2.81 on epoch=77
05/20/2022 18:45:43 - INFO - __main__ - Step 320 Global step 320 Train loss 2.90 on epoch=79
05/20/2022 18:45:44 - INFO - __main__ - Step 330 Global step 330 Train loss 2.69 on epoch=82
05/20/2022 18:45:45 - INFO - __main__ - Step 340 Global step 340 Train loss 2.80 on epoch=84
05/20/2022 18:45:47 - INFO - __main__ - Step 350 Global step 350 Train loss 2.67 on epoch=87
05/20/2022 18:45:47 - INFO - __main__ - Global step 350 Train loss 2.77 Classification-F1 0.1468058968058968 on epoch=87
05/20/2022 18:45:49 - INFO - __main__ - Step 360 Global step 360 Train loss 2.69 on epoch=89
05/20/2022 18:45:50 - INFO - __main__ - Step 370 Global step 370 Train loss 2.63 on epoch=92
05/20/2022 18:45:52 - INFO - __main__ - Step 380 Global step 380 Train loss 2.80 on epoch=94
05/20/2022 18:45:53 - INFO - __main__ - Step 390 Global step 390 Train loss 2.21 on epoch=97
05/20/2022 18:45:54 - INFO - __main__ - Step 400 Global step 400 Train loss 2.62 on epoch=99
05/20/2022 18:45:55 - INFO - __main__ - Global step 400 Train loss 2.59 Classification-F1 0.16483516483516486 on epoch=99
05/20/2022 18:45:56 - INFO - __main__ - Step 410 Global step 410 Train loss 2.41 on epoch=102
05/20/2022 18:45:58 - INFO - __main__ - Step 420 Global step 420 Train loss 2.40 on epoch=104
05/20/2022 18:45:59 - INFO - __main__ - Step 430 Global step 430 Train loss 2.27 on epoch=107
05/20/2022 18:46:00 - INFO - __main__ - Step 440 Global step 440 Train loss 2.39 on epoch=109
05/20/2022 18:46:02 - INFO - __main__ - Step 450 Global step 450 Train loss 2.44 on epoch=112
05/20/2022 18:46:02 - INFO - __main__ - Global step 450 Train loss 2.38 Classification-F1 0.15682382133995038 on epoch=112
05/20/2022 18:46:04 - INFO - __main__ - Step 460 Global step 460 Train loss 2.49 on epoch=114
05/20/2022 18:46:05 - INFO - __main__ - Step 470 Global step 470 Train loss 2.40 on epoch=117
05/20/2022 18:46:06 - INFO - __main__ - Step 480 Global step 480 Train loss 2.34 on epoch=119
05/20/2022 18:46:08 - INFO - __main__ - Step 490 Global step 490 Train loss 2.20 on epoch=122
05/20/2022 18:46:09 - INFO - __main__ - Step 500 Global step 500 Train loss 2.17 on epoch=124
05/20/2022 18:46:10 - INFO - __main__ - Global step 500 Train loss 2.32 Classification-F1 0.17317073170731706 on epoch=124
05/20/2022 18:46:11 - INFO - __main__ - Step 510 Global step 510 Train loss 2.39 on epoch=127
05/20/2022 18:46:12 - INFO - __main__ - Step 520 Global step 520 Train loss 2.21 on epoch=129
05/20/2022 18:46:14 - INFO - __main__ - Step 530 Global step 530 Train loss 2.10 on epoch=132
05/20/2022 18:46:15 - INFO - __main__ - Step 540 Global step 540 Train loss 2.25 on epoch=134
05/20/2022 18:46:17 - INFO - __main__ - Step 550 Global step 550 Train loss 1.81 on epoch=137
05/20/2022 18:46:17 - INFO - __main__ - Global step 550 Train loss 2.15 Classification-F1 0.15559772296015179 on epoch=137
05/20/2022 18:46:19 - INFO - __main__ - Step 560 Global step 560 Train loss 2.09 on epoch=139
05/20/2022 18:46:20 - INFO - __main__ - Step 570 Global step 570 Train loss 2.03 on epoch=142
05/20/2022 18:46:21 - INFO - __main__ - Step 580 Global step 580 Train loss 2.17 on epoch=144
05/20/2022 18:46:23 - INFO - __main__ - Step 590 Global step 590 Train loss 2.10 on epoch=147
05/20/2022 18:46:24 - INFO - __main__ - Step 600 Global step 600 Train loss 2.06 on epoch=149
05/20/2022 18:46:25 - INFO - __main__ - Global step 600 Train loss 2.09 Classification-F1 0.17372070779531323 on epoch=149
05/20/2022 18:46:25 - INFO - __main__ - Saving model with best Classification-F1: 0.17344312918167784 -> 0.17372070779531323 on epoch=149, global_step=600
05/20/2022 18:46:26 - INFO - __main__ - Step 610 Global step 610 Train loss 2.01 on epoch=152
05/20/2022 18:46:28 - INFO - __main__ - Step 620 Global step 620 Train loss 2.13 on epoch=154
05/20/2022 18:46:29 - INFO - __main__ - Step 630 Global step 630 Train loss 1.87 on epoch=157
05/20/2022 18:46:31 - INFO - __main__ - Step 640 Global step 640 Train loss 2.07 on epoch=159
05/20/2022 18:46:32 - INFO - __main__ - Step 650 Global step 650 Train loss 1.93 on epoch=162
05/20/2022 18:46:32 - INFO - __main__ - Global step 650 Train loss 2.00 Classification-F1 0.18026315789473685 on epoch=162
05/20/2022 18:46:32 - INFO - __main__ - Saving model with best Classification-F1: 0.17372070779531323 -> 0.18026315789473685 on epoch=162, global_step=650
05/20/2022 18:46:34 - INFO - __main__ - Step 660 Global step 660 Train loss 1.93 on epoch=164
05/20/2022 18:46:35 - INFO - __main__ - Step 670 Global step 670 Train loss 1.94 on epoch=167
05/20/2022 18:46:37 - INFO - __main__ - Step 680 Global step 680 Train loss 2.06 on epoch=169
05/20/2022 18:46:38 - INFO - __main__ - Step 690 Global step 690 Train loss 1.77 on epoch=172
05/20/2022 18:46:40 - INFO - __main__ - Step 700 Global step 700 Train loss 1.81 on epoch=174
05/20/2022 18:46:40 - INFO - __main__ - Global step 700 Train loss 1.90 Classification-F1 0.15339578454332553 on epoch=174
05/20/2022 18:46:42 - INFO - __main__ - Step 710 Global step 710 Train loss 1.67 on epoch=177
05/20/2022 18:46:43 - INFO - __main__ - Step 720 Global step 720 Train loss 1.73 on epoch=179
05/20/2022 18:46:44 - INFO - __main__ - Step 730 Global step 730 Train loss 1.70 on epoch=182
05/20/2022 18:46:46 - INFO - __main__ - Step 740 Global step 740 Train loss 1.76 on epoch=184
05/20/2022 18:46:47 - INFO - __main__ - Step 750 Global step 750 Train loss 1.60 on epoch=187
05/20/2022 18:46:48 - INFO - __main__ - Global step 750 Train loss 1.69 Classification-F1 0.1 on epoch=187
05/20/2022 18:46:49 - INFO - __main__ - Step 760 Global step 760 Train loss 1.73 on epoch=189
05/20/2022 18:46:51 - INFO - __main__ - Step 770 Global step 770 Train loss 1.61 on epoch=192
05/20/2022 18:46:52 - INFO - __main__ - Step 780 Global step 780 Train loss 1.60 on epoch=194
05/20/2022 18:46:53 - INFO - __main__ - Step 790 Global step 790 Train loss 1.39 on epoch=197
05/20/2022 18:46:55 - INFO - __main__ - Step 800 Global step 800 Train loss 1.55 on epoch=199
05/20/2022 18:46:55 - INFO - __main__ - Global step 800 Train loss 1.58 Classification-F1 0.1237183868762816 on epoch=199
05/20/2022 18:46:57 - INFO - __main__ - Step 810 Global step 810 Train loss 1.38 on epoch=202
05/20/2022 18:46:58 - INFO - __main__ - Step 820 Global step 820 Train loss 1.63 on epoch=204
05/20/2022 18:46:59 - INFO - __main__ - Step 830 Global step 830 Train loss 1.60 on epoch=207
05/20/2022 18:47:01 - INFO - __main__ - Step 840 Global step 840 Train loss 1.49 on epoch=209
05/20/2022 18:47:02 - INFO - __main__ - Step 850 Global step 850 Train loss 1.41 on epoch=212
05/20/2022 18:47:03 - INFO - __main__ - Global step 850 Train loss 1.50 Classification-F1 0.10126582278481013 on epoch=212
05/20/2022 18:47:04 - INFO - __main__ - Step 860 Global step 860 Train loss 1.57 on epoch=214
05/20/2022 18:47:05 - INFO - __main__ - Step 870 Global step 870 Train loss 1.52 on epoch=217
05/20/2022 18:47:07 - INFO - __main__ - Step 880 Global step 880 Train loss 1.38 on epoch=219
05/20/2022 18:47:08 - INFO - __main__ - Step 890 Global step 890 Train loss 1.32 on epoch=222
05/20/2022 18:47:10 - INFO - __main__ - Step 900 Global step 900 Train loss 1.32 on epoch=224
05/20/2022 18:47:10 - INFO - __main__ - Global step 900 Train loss 1.42 Classification-F1 0.0974025974025974 on epoch=224
05/20/2022 18:47:12 - INFO - __main__ - Step 910 Global step 910 Train loss 1.31 on epoch=227
05/20/2022 18:47:13 - INFO - __main__ - Step 920 Global step 920 Train loss 1.47 on epoch=229
05/20/2022 18:47:14 - INFO - __main__ - Step 930 Global step 930 Train loss 1.34 on epoch=232
05/20/2022 18:47:16 - INFO - __main__ - Step 940 Global step 940 Train loss 1.47 on epoch=234
05/20/2022 18:47:17 - INFO - __main__ - Step 950 Global step 950 Train loss 1.34 on epoch=237
05/20/2022 18:47:18 - INFO - __main__ - Global step 950 Train loss 1.39 Classification-F1 0.11425630468347914 on epoch=237
05/20/2022 18:47:19 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
05/20/2022 18:47:20 - INFO - __main__ - Step 970 Global step 970 Train loss 1.41 on epoch=242
05/20/2022 18:47:21 - INFO - __main__ - Step 980 Global step 980 Train loss 1.60 on epoch=244
05/20/2022 18:47:23 - INFO - __main__ - Step 990 Global step 990 Train loss 1.22 on epoch=247
05/20/2022 18:47:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.29 on epoch=249
05/20/2022 18:47:25 - INFO - __main__ - Global step 1000 Train loss 1.38 Classification-F1 0.1 on epoch=249
05/20/2022 18:47:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/20/2022 18:47:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.17 on epoch=254
05/20/2022 18:47:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.26 on epoch=257
05/20/2022 18:47:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.24 on epoch=259
05/20/2022 18:47:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.41 on epoch=262
05/20/2022 18:47:32 - INFO - __main__ - Global step 1050 Train loss 1.29 Classification-F1 0.1856338028169014 on epoch=262
05/20/2022 18:47:32 - INFO - __main__ - Saving model with best Classification-F1: 0.18026315789473685 -> 0.1856338028169014 on epoch=262, global_step=1050
05/20/2022 18:47:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.47 on epoch=264
05/20/2022 18:47:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.27 on epoch=267
05/20/2022 18:47:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/20/2022 18:47:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.26 on epoch=272
05/20/2022 18:47:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.31 on epoch=274
05/20/2022 18:47:40 - INFO - __main__ - Global step 1100 Train loss 1.31 Classification-F1 0.1081081081081081 on epoch=274
05/20/2022 18:47:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.38 on epoch=277
05/20/2022 18:47:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.25 on epoch=279
05/20/2022 18:47:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.30 on epoch=282
05/20/2022 18:47:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.51 on epoch=284
05/20/2022 18:47:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.19 on epoch=287
05/20/2022 18:47:48 - INFO - __main__ - Global step 1150 Train loss 1.33 Classification-F1 0.1 on epoch=287
05/20/2022 18:47:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.16 on epoch=289
05/20/2022 18:47:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.24 on epoch=292
05/20/2022 18:47:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.24 on epoch=294
05/20/2022 18:47:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.41 on epoch=297
05/20/2022 18:47:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.44 on epoch=299
05/20/2022 18:47:55 - INFO - __main__ - Global step 1200 Train loss 1.30 Classification-F1 0.10126582278481013 on epoch=299
05/20/2022 18:47:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.27 on epoch=302
05/20/2022 18:47:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.35 on epoch=304
05/20/2022 18:48:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.27 on epoch=307
05/20/2022 18:48:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.16 on epoch=309
05/20/2022 18:48:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.27 on epoch=312
05/20/2022 18:48:03 - INFO - __main__ - Global step 1250 Train loss 1.26 Classification-F1 0.16110780226325194 on epoch=312
05/20/2022 18:48:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
05/20/2022 18:48:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.28 on epoch=317
05/20/2022 18:48:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.27 on epoch=319
05/20/2022 18:48:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.30 on epoch=322
05/20/2022 18:48:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.20 on epoch=324
05/20/2022 18:48:11 - INFO - __main__ - Global step 1300 Train loss 1.27 Classification-F1 0.1 on epoch=324
05/20/2022 18:48:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.13 on epoch=327
05/20/2022 18:48:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.16 on epoch=329
05/20/2022 18:48:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=332
05/20/2022 18:48:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.29 on epoch=334
05/20/2022 18:48:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.21 on epoch=337
05/20/2022 18:48:19 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.1 on epoch=337
05/20/2022 18:48:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/20/2022 18:48:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
05/20/2022 18:48:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=344
05/20/2022 18:48:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
05/20/2022 18:48:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/20/2022 18:48:27 - INFO - __main__ - Global step 1400 Train loss 1.13 Classification-F1 0.14560439560439564 on epoch=349
05/20/2022 18:48:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.25 on epoch=352
05/20/2022 18:48:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.22 on epoch=354
05/20/2022 18:48:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.13 on epoch=357
05/20/2022 18:48:33 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.10 on epoch=359
05/20/2022 18:48:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.18 on epoch=362
05/20/2022 18:48:35 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.1 on epoch=362
05/20/2022 18:48:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.11 on epoch=364
05/20/2022 18:48:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.31 on epoch=367
05/20/2022 18:48:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/20/2022 18:48:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.03 on epoch=372
05/20/2022 18:48:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.20 on epoch=374
05/20/2022 18:48:43 - INFO - __main__ - Global step 1500 Train loss 1.16 Classification-F1 0.1 on epoch=374
05/20/2022 18:48:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.09 on epoch=377
05/20/2022 18:48:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.21 on epoch=379
05/20/2022 18:48:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.10 on epoch=382
05/20/2022 18:48:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.09 on epoch=384
05/20/2022 18:48:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.09 on epoch=387
05/20/2022 18:48:51 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.13067758749069247 on epoch=387
05/20/2022 18:48:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.03 on epoch=389
05/20/2022 18:48:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.06 on epoch=392
05/20/2022 18:48:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
05/20/2022 18:48:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.17 on epoch=397
05/20/2022 18:48:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=399
05/20/2022 18:48:58 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.10126582278481013 on epoch=399
05/20/2022 18:49:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.07 on epoch=402
05/20/2022 18:49:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.06 on epoch=404
05/20/2022 18:49:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.21 on epoch=407
05/20/2022 18:49:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/20/2022 18:49:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.04 on epoch=412
05/20/2022 18:49:06 - INFO - __main__ - Global step 1650 Train loss 1.08 Classification-F1 0.1 on epoch=412
05/20/2022 18:49:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.08 on epoch=414
05/20/2022 18:49:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.99 on epoch=417
05/20/2022 18:49:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.07 on epoch=419
05/20/2022 18:49:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.15 on epoch=422
05/20/2022 18:49:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.99 on epoch=424
05/20/2022 18:49:13 - INFO - __main__ - Global step 1700 Train loss 1.05 Classification-F1 0.15306730196545562 on epoch=424
05/20/2022 18:49:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.16 on epoch=427
05/20/2022 18:49:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.96 on epoch=429
05/20/2022 18:49:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.98 on epoch=432
05/20/2022 18:49:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.97 on epoch=434
05/20/2022 18:49:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.18 on epoch=437
05/20/2022 18:49:20 - INFO - __main__ - Global step 1750 Train loss 1.05 Classification-F1 0.1 on epoch=437
05/20/2022 18:49:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.14 on epoch=439
05/20/2022 18:49:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.10 on epoch=442
05/20/2022 18:49:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
05/20/2022 18:49:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.24 on epoch=447
05/20/2022 18:49:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
05/20/2022 18:49:28 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.17737733391228833 on epoch=449
05/20/2022 18:49:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
05/20/2022 18:49:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/20/2022 18:49:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.05 on epoch=457
05/20/2022 18:49:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.24 on epoch=459
05/20/2022 18:49:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.11 on epoch=462
05/20/2022 18:49:35 - INFO - __main__ - Global step 1850 Train loss 1.11 Classification-F1 0.1782106782106782 on epoch=462
05/20/2022 18:49:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.14 on epoch=464
05/20/2022 18:49:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.19 on epoch=467
05/20/2022 18:49:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.10 on epoch=469
05/20/2022 18:49:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
05/20/2022 18:49:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=474
05/20/2022 18:49:43 - INFO - __main__ - Global step 1900 Train loss 1.10 Classification-F1 0.1762899262899263 on epoch=474
05/20/2022 18:49:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.02 on epoch=477
05/20/2022 18:49:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.09 on epoch=479
05/20/2022 18:49:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.02 on epoch=482
05/20/2022 18:49:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.19 on epoch=484
05/20/2022 18:49:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.13 on epoch=487
05/20/2022 18:49:50 - INFO - __main__ - Global step 1950 Train loss 1.09 Classification-F1 0.13333333333333333 on epoch=487
05/20/2022 18:49:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.07 on epoch=489
05/20/2022 18:49:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=492
05/20/2022 18:49:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.09 on epoch=494
05/20/2022 18:49:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
05/20/2022 18:49:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.99 on epoch=499
05/20/2022 18:49:58 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.1 on epoch=499
05/20/2022 18:49:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.07 on epoch=502
05/20/2022 18:50:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.07 on epoch=504
05/20/2022 18:50:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
05/20/2022 18:50:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.16 on epoch=509
05/20/2022 18:50:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.98 on epoch=512
05/20/2022 18:50:05 - INFO - __main__ - Global step 2050 Train loss 1.06 Classification-F1 0.14004914004914004 on epoch=512
05/20/2022 18:50:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.07 on epoch=514
05/20/2022 18:50:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/20/2022 18:50:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.12 on epoch=519
05/20/2022 18:50:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.07 on epoch=522
05/20/2022 18:50:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
05/20/2022 18:50:13 - INFO - __main__ - Global step 2100 Train loss 1.08 Classification-F1 0.1527777777777778 on epoch=524
05/20/2022 18:50:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.96 on epoch=527
05/20/2022 18:50:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.06 on epoch=529
05/20/2022 18:50:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.14 on epoch=532
05/20/2022 18:50:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.07 on epoch=534
05/20/2022 18:50:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.11 on epoch=537
05/20/2022 18:50:20 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.1576923076923077 on epoch=537
05/20/2022 18:50:22 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.01 on epoch=539
05/20/2022 18:50:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.02 on epoch=542
05/20/2022 18:50:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.97 on epoch=544
05/20/2022 18:50:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=547
05/20/2022 18:50:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.99 on epoch=549
05/20/2022 18:50:28 - INFO - __main__ - Global step 2200 Train loss 1.00 Classification-F1 0.1402116402116402 on epoch=549
05/20/2022 18:50:29 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/20/2022 18:50:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/20/2022 18:50:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.07 on epoch=557
05/20/2022 18:50:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
05/20/2022 18:50:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
05/20/2022 18:50:35 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.20219168748580513 on epoch=562
05/20/2022 18:50:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1856338028169014 -> 0.20219168748580513 on epoch=562, global_step=2250
05/20/2022 18:50:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/20/2022 18:50:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.98 on epoch=567
05/20/2022 18:50:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/20/2022 18:50:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/20/2022 18:50:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.00 on epoch=574
05/20/2022 18:50:42 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.12077294685990338 on epoch=574
05/20/2022 18:50:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/20/2022 18:50:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/20/2022 18:50:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.92 on epoch=582
05/20/2022 18:50:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/20/2022 18:50:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/20/2022 18:50:50 - INFO - __main__ - Global step 2350 Train loss 0.96 Classification-F1 0.13445378151260504 on epoch=587
05/20/2022 18:50:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.98 on epoch=589
05/20/2022 18:50:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=592
05/20/2022 18:50:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.05 on epoch=594
05/20/2022 18:50:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/20/2022 18:50:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=599
05/20/2022 18:50:57 - INFO - __main__ - Global step 2400 Train loss 0.99 Classification-F1 0.06060606060606061 on epoch=599
05/20/2022 18:50:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
05/20/2022 18:51:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/20/2022 18:51:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
05/20/2022 18:51:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.02 on epoch=609
05/20/2022 18:51:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.05 on epoch=612
05/20/2022 18:51:05 - INFO - __main__ - Global step 2450 Train loss 1.01 Classification-F1 0.22004608294930872 on epoch=612
05/20/2022 18:51:05 - INFO - __main__ - Saving model with best Classification-F1: 0.20219168748580513 -> 0.22004608294930872 on epoch=612, global_step=2450
05/20/2022 18:51:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
05/20/2022 18:51:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.04 on epoch=617
05/20/2022 18:51:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/20/2022 18:51:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/20/2022 18:51:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
05/20/2022 18:51:12 - INFO - __main__ - Global step 2500 Train loss 1.07 Classification-F1 0.10256410256410256 on epoch=624
05/20/2022 18:51:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.05 on epoch=627
05/20/2022 18:51:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.12 on epoch=629
05/20/2022 18:51:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.07 on epoch=632
05/20/2022 18:51:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.94 on epoch=634
05/20/2022 18:51:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/20/2022 18:51:20 - INFO - __main__ - Global step 2550 Train loss 1.04 Classification-F1 0.1 on epoch=637
05/20/2022 18:51:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.05 on epoch=639
05/20/2022 18:51:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.92 on epoch=642
05/20/2022 18:51:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.11 on epoch=644
05/20/2022 18:51:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.05 on epoch=647
05/20/2022 18:51:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/20/2022 18:51:27 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.12681436210847974 on epoch=649
05/20/2022 18:51:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.07 on epoch=652
05/20/2022 18:51:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.01 on epoch=654
05/20/2022 18:51:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
05/20/2022 18:51:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.02 on epoch=659
05/20/2022 18:51:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.06 on epoch=662
05/20/2022 18:51:35 - INFO - __main__ - Global step 2650 Train loss 1.04 Classification-F1 0.1 on epoch=662
05/20/2022 18:51:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.00 on epoch=664
05/20/2022 18:51:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
05/20/2022 18:51:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
05/20/2022 18:51:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.90 on epoch=672
05/20/2022 18:51:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
05/20/2022 18:51:42 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
05/20/2022 18:51:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/20/2022 18:51:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.07 on epoch=679
05/20/2022 18:51:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.98 on epoch=682
05/20/2022 18:51:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.90 on epoch=684
05/20/2022 18:51:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/20/2022 18:51:50 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.09493670886075949 on epoch=687
05/20/2022 18:51:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.05 on epoch=689
05/20/2022 18:51:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/20/2022 18:51:54 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.07 on epoch=694
05/20/2022 18:51:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
05/20/2022 18:51:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.05 on epoch=699
05/20/2022 18:51:57 - INFO - __main__ - Global step 2800 Train loss 1.03 Classification-F1 0.17028824833702882 on epoch=699
05/20/2022 18:51:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.97 on epoch=702
05/20/2022 18:51:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.11 on epoch=704
05/20/2022 18:52:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/20/2022 18:52:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/20/2022 18:52:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
05/20/2022 18:52:04 - INFO - __main__ - Global step 2850 Train loss 0.99 Classification-F1 0.17798594847775173 on epoch=712
05/20/2022 18:52:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
05/20/2022 18:52:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.93 on epoch=717
05/20/2022 18:52:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/20/2022 18:52:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.99 on epoch=722
05/20/2022 18:52:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/20/2022 18:52:12 - INFO - __main__ - Global step 2900 Train loss 0.96 Classification-F1 0.11094819159335288 on epoch=724
05/20/2022 18:52:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/20/2022 18:52:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.96 on epoch=729
05/20/2022 18:52:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
05/20/2022 18:52:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
05/20/2022 18:52:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.02 on epoch=737
05/20/2022 18:52:19 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.14915966386554622 on epoch=737
05/20/2022 18:52:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/20/2022 18:52:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.05 on epoch=742
05/20/2022 18:52:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
05/20/2022 18:52:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
05/20/2022 18:52:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.01 on epoch=749
05/20/2022 18:52:27 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.11732186732186733 on epoch=749
05/20/2022 18:52:27 - INFO - __main__ - save last model!
05/20/2022 18:52:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 18:52:27 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 18:52:27 - INFO - __main__ - Printing 3 examples
05/20/2022 18:52:27 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 18:52:27 - INFO - __main__ - ['others']
05/20/2022 18:52:27 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 18:52:27 - INFO - __main__ - ['others']
05/20/2022 18:52:27 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 18:52:27 - INFO - __main__ - ['others']
05/20/2022 18:52:27 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:52:27 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:52:27 - INFO - __main__ - Printing 3 examples
05/20/2022 18:52:27 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:52:27 - INFO - __main__ - ['happy']
05/20/2022 18:52:27 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:52:27 - INFO - __main__ - ['happy']
05/20/2022 18:52:27 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:52:27 - INFO - __main__ - ['happy']
05/20/2022 18:52:27 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:52:27 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:52:27 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:52:27 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:52:27 - INFO - __main__ - Printing 3 examples
05/20/2022 18:52:27 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:52:27 - INFO - __main__ - ['happy']
05/20/2022 18:52:27 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:52:27 - INFO - __main__ - ['happy']
05/20/2022 18:52:27 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:52:27 - INFO - __main__ - ['happy']
05/20/2022 18:52:27 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:52:27 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:52:27 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:52:29 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:52:33 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:52:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:52:33 - INFO - __main__ - Starting training!
05/20/2022 18:52:35 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 18:53:21 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.3_8_predictions.txt
05/20/2022 18:53:21 - INFO - __main__ - Classification-F1 on test data: 0.0404
05/20/2022 18:53:21 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.22004608294930872, test_performance=0.04041940527737243
05/20/2022 18:53:21 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
05/20/2022 18:53:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:53:22 - INFO - __main__ - Printing 3 examples
05/20/2022 18:53:22 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/20/2022 18:53:22 - INFO - __main__ - ['happy']
05/20/2022 18:53:22 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/20/2022 18:53:22 - INFO - __main__ - ['happy']
05/20/2022 18:53:22 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/20/2022 18:53:22 - INFO - __main__ - ['happy']
05/20/2022 18:53:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:53:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:53:22 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 18:53:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 18:53:22 - INFO - __main__ - Printing 3 examples
05/20/2022 18:53:22 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/20/2022 18:53:22 - INFO - __main__ - ['happy']
05/20/2022 18:53:22 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/20/2022 18:53:22 - INFO - __main__ - ['happy']
05/20/2022 18:53:22 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/20/2022 18:53:22 - INFO - __main__ - ['happy']
05/20/2022 18:53:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 18:53:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 18:53:22 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 18:53:28 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 18:53:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 18:53:28 - INFO - __main__ - Starting training!
05/20/2022 18:53:30 - INFO - __main__ - Step 10 Global step 10 Train loss 6.63 on epoch=2
05/20/2022 18:53:31 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/20/2022 18:53:33 - INFO - __main__ - Step 30 Global step 30 Train loss 6.55 on epoch=7
05/20/2022 18:53:34 - INFO - __main__ - Step 40 Global step 40 Train loss 6.37 on epoch=9
05/20/2022 18:53:35 - INFO - __main__ - Step 50 Global step 50 Train loss 6.17 on epoch=12
05/20/2022 18:53:44 - INFO - __main__ - Global step 50 Train loss 6.46 Classification-F1 0.0 on epoch=12
05/20/2022 18:53:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 18:53:46 - INFO - __main__ - Step 60 Global step 60 Train loss 6.25 on epoch=14
05/20/2022 18:53:47 - INFO - __main__ - Step 70 Global step 70 Train loss 6.01 on epoch=17
05/20/2022 18:53:48 - INFO - __main__ - Step 80 Global step 80 Train loss 5.95 on epoch=19
05/20/2022 18:53:50 - INFO - __main__ - Step 90 Global step 90 Train loss 5.85 on epoch=22
05/20/2022 18:53:51 - INFO - __main__ - Step 100 Global step 100 Train loss 5.68 on epoch=24
05/20/2022 18:53:53 - INFO - __main__ - Global step 100 Train loss 5.95 Classification-F1 0.0 on epoch=24
05/20/2022 18:53:54 - INFO - __main__ - Step 110 Global step 110 Train loss 5.65 on epoch=27
05/20/2022 18:53:56 - INFO - __main__ - Step 120 Global step 120 Train loss 5.60 on epoch=29
05/20/2022 18:53:57 - INFO - __main__ - Step 130 Global step 130 Train loss 5.51 on epoch=32
05/20/2022 18:53:58 - INFO - __main__ - Step 140 Global step 140 Train loss 5.45 on epoch=34
05/20/2022 18:54:00 - INFO - __main__ - Step 150 Global step 150 Train loss 5.33 on epoch=37
05/20/2022 18:54:01 - INFO - __main__ - Global step 150 Train loss 5.51 Classification-F1 0.0 on epoch=37
05/20/2022 18:54:02 - INFO - __main__ - Step 160 Global step 160 Train loss 5.24 on epoch=39
05/20/2022 18:54:04 - INFO - __main__ - Step 170 Global step 170 Train loss 5.27 on epoch=42
05/20/2022 18:54:05 - INFO - __main__ - Step 180 Global step 180 Train loss 4.89 on epoch=44
05/20/2022 18:54:07 - INFO - __main__ - Step 190 Global step 190 Train loss 4.88 on epoch=47
05/20/2022 18:54:08 - INFO - __main__ - Step 200 Global step 200 Train loss 4.81 on epoch=49
05/20/2022 18:54:10 - INFO - __main__ - Global step 200 Train loss 5.02 Classification-F1 0.0 on epoch=49
05/20/2022 18:54:11 - INFO - __main__ - Step 210 Global step 210 Train loss 4.58 on epoch=52
05/20/2022 18:54:12 - INFO - __main__ - Step 220 Global step 220 Train loss 4.68 on epoch=54
05/20/2022 18:54:14 - INFO - __main__ - Step 230 Global step 230 Train loss 4.25 on epoch=57
05/20/2022 18:54:15 - INFO - __main__ - Step 240 Global step 240 Train loss 4.46 on epoch=59
05/20/2022 18:54:16 - INFO - __main__ - Step 250 Global step 250 Train loss 4.29 on epoch=62
05/20/2022 18:54:17 - INFO - __main__ - Global step 250 Train loss 4.45 Classification-F1 0.0810126582278481 on epoch=62
05/20/2022 18:54:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0810126582278481 on epoch=62, global_step=250
05/20/2022 18:54:18 - INFO - __main__ - Step 260 Global step 260 Train loss 4.21 on epoch=64
05/20/2022 18:54:20 - INFO - __main__ - Step 270 Global step 270 Train loss 4.04 on epoch=67
05/20/2022 18:54:21 - INFO - __main__ - Step 280 Global step 280 Train loss 4.07 on epoch=69
05/20/2022 18:54:23 - INFO - __main__ - Step 290 Global step 290 Train loss 3.94 on epoch=72
05/20/2022 18:54:24 - INFO - __main__ - Step 300 Global step 300 Train loss 3.88 on epoch=74
05/20/2022 18:54:24 - INFO - __main__ - Global step 300 Train loss 4.03 Classification-F1 0.10199240986717267 on epoch=74
05/20/2022 18:54:24 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.10199240986717267 on epoch=74, global_step=300
05/20/2022 18:54:26 - INFO - __main__ - Step 310 Global step 310 Train loss 3.59 on epoch=77
05/20/2022 18:54:27 - INFO - __main__ - Step 320 Global step 320 Train loss 3.75 on epoch=79
05/20/2022 18:54:29 - INFO - __main__ - Step 330 Global step 330 Train loss 3.76 on epoch=82
05/20/2022 18:54:30 - INFO - __main__ - Step 340 Global step 340 Train loss 3.76 on epoch=84
05/20/2022 18:54:31 - INFO - __main__ - Step 350 Global step 350 Train loss 3.48 on epoch=87
05/20/2022 18:54:32 - INFO - __main__ - Global step 350 Train loss 3.67 Classification-F1 0.11300097751710654 on epoch=87
05/20/2022 18:54:32 - INFO - __main__ - Saving model with best Classification-F1: 0.10199240986717267 -> 0.11300097751710654 on epoch=87, global_step=350
05/20/2022 18:54:33 - INFO - __main__ - Step 360 Global step 360 Train loss 3.56 on epoch=89
05/20/2022 18:54:35 - INFO - __main__ - Step 370 Global step 370 Train loss 3.37 on epoch=92
05/20/2022 18:54:36 - INFO - __main__ - Step 380 Global step 380 Train loss 3.41 on epoch=94
05/20/2022 18:54:37 - INFO - __main__ - Step 390 Global step 390 Train loss 3.23 on epoch=97
05/20/2022 18:54:39 - INFO - __main__ - Step 400 Global step 400 Train loss 3.38 on epoch=99
05/20/2022 18:54:39 - INFO - __main__ - Global step 400 Train loss 3.39 Classification-F1 0.07733847637415622 on epoch=99
05/20/2022 18:54:41 - INFO - __main__ - Step 410 Global step 410 Train loss 3.25 on epoch=102
05/20/2022 18:54:42 - INFO - __main__ - Step 420 Global step 420 Train loss 3.24 on epoch=104
05/20/2022 18:54:43 - INFO - __main__ - Step 430 Global step 430 Train loss 3.06 on epoch=107
05/20/2022 18:54:45 - INFO - __main__ - Step 440 Global step 440 Train loss 3.18 on epoch=109
05/20/2022 18:54:46 - INFO - __main__ - Step 450 Global step 450 Train loss 2.97 on epoch=112
05/20/2022 18:54:47 - INFO - __main__ - Global step 450 Train loss 3.14 Classification-F1 0.14505347593582887 on epoch=112
05/20/2022 18:54:47 - INFO - __main__ - Saving model with best Classification-F1: 0.11300097751710654 -> 0.14505347593582887 on epoch=112, global_step=450
05/20/2022 18:54:48 - INFO - __main__ - Step 460 Global step 460 Train loss 3.10 on epoch=114
05/20/2022 18:54:50 - INFO - __main__ - Step 470 Global step 470 Train loss 2.85 on epoch=117
05/20/2022 18:54:51 - INFO - __main__ - Step 480 Global step 480 Train loss 2.89 on epoch=119
05/20/2022 18:54:52 - INFO - __main__ - Step 490 Global step 490 Train loss 2.67 on epoch=122
05/20/2022 18:54:54 - INFO - __main__ - Step 500 Global step 500 Train loss 2.87 on epoch=124
05/20/2022 18:54:54 - INFO - __main__ - Global step 500 Train loss 2.88 Classification-F1 0.10483870967741937 on epoch=124
05/20/2022 18:54:56 - INFO - __main__ - Step 510 Global step 510 Train loss 2.67 on epoch=127
05/20/2022 18:54:57 - INFO - __main__ - Step 520 Global step 520 Train loss 2.71 on epoch=129
05/20/2022 18:54:59 - INFO - __main__ - Step 530 Global step 530 Train loss 2.72 on epoch=132
05/20/2022 18:55:00 - INFO - __main__ - Step 540 Global step 540 Train loss 2.72 on epoch=134
05/20/2022 18:55:01 - INFO - __main__ - Step 550 Global step 550 Train loss 2.59 on epoch=137
05/20/2022 18:55:02 - INFO - __main__ - Global step 550 Train loss 2.68 Classification-F1 0.1 on epoch=137
05/20/2022 18:55:03 - INFO - __main__ - Step 560 Global step 560 Train loss 2.64 on epoch=139
05/20/2022 18:55:05 - INFO - __main__ - Step 570 Global step 570 Train loss 2.57 on epoch=142
05/20/2022 18:55:06 - INFO - __main__ - Step 580 Global step 580 Train loss 2.51 on epoch=144
05/20/2022 18:55:07 - INFO - __main__ - Step 590 Global step 590 Train loss 2.39 on epoch=147
05/20/2022 18:55:09 - INFO - __main__ - Step 600 Global step 600 Train loss 2.55 on epoch=149
05/20/2022 18:55:09 - INFO - __main__ - Global step 600 Train loss 2.53 Classification-F1 0.1 on epoch=149
05/20/2022 18:55:11 - INFO - __main__ - Step 610 Global step 610 Train loss 2.27 on epoch=152
05/20/2022 18:55:12 - INFO - __main__ - Step 620 Global step 620 Train loss 2.51 on epoch=154
05/20/2022 18:55:14 - INFO - __main__ - Step 630 Global step 630 Train loss 2.29 on epoch=157
05/20/2022 18:55:15 - INFO - __main__ - Step 640 Global step 640 Train loss 2.34 on epoch=159
05/20/2022 18:55:16 - INFO - __main__ - Step 650 Global step 650 Train loss 2.20 on epoch=162
05/20/2022 18:55:17 - INFO - __main__ - Global step 650 Train loss 2.32 Classification-F1 0.1 on epoch=162
05/20/2022 18:55:18 - INFO - __main__ - Step 660 Global step 660 Train loss 2.53 on epoch=164
05/20/2022 18:55:20 - INFO - __main__ - Step 670 Global step 670 Train loss 2.15 on epoch=167
05/20/2022 18:55:21 - INFO - __main__ - Step 680 Global step 680 Train loss 2.27 on epoch=169
05/20/2022 18:55:22 - INFO - __main__ - Step 690 Global step 690 Train loss 2.10 on epoch=172
05/20/2022 18:55:24 - INFO - __main__ - Step 700 Global step 700 Train loss 2.08 on epoch=174
05/20/2022 18:55:24 - INFO - __main__ - Global step 700 Train loss 2.23 Classification-F1 0.1 on epoch=174
05/20/2022 18:55:26 - INFO - __main__ - Step 710 Global step 710 Train loss 2.07 on epoch=177
05/20/2022 18:55:27 - INFO - __main__ - Step 720 Global step 720 Train loss 2.18 on epoch=179
05/20/2022 18:55:29 - INFO - __main__ - Step 730 Global step 730 Train loss 2.05 on epoch=182
05/20/2022 18:55:30 - INFO - __main__ - Step 740 Global step 740 Train loss 2.17 on epoch=184
05/20/2022 18:55:31 - INFO - __main__ - Step 750 Global step 750 Train loss 2.07 on epoch=187
05/20/2022 18:55:32 - INFO - __main__ - Global step 750 Train loss 2.11 Classification-F1 0.1 on epoch=187
05/20/2022 18:55:34 - INFO - __main__ - Step 760 Global step 760 Train loss 2.09 on epoch=189
05/20/2022 18:55:35 - INFO - __main__ - Step 770 Global step 770 Train loss 2.25 on epoch=192
05/20/2022 18:55:36 - INFO - __main__ - Step 780 Global step 780 Train loss 2.14 on epoch=194
05/20/2022 18:55:38 - INFO - __main__ - Step 790 Global step 790 Train loss 2.08 on epoch=197
05/20/2022 18:55:39 - INFO - __main__ - Step 800 Global step 800 Train loss 2.22 on epoch=199
05/20/2022 18:55:40 - INFO - __main__ - Global step 800 Train loss 2.16 Classification-F1 0.1 on epoch=199
05/20/2022 18:55:41 - INFO - __main__ - Step 810 Global step 810 Train loss 1.92 on epoch=202
05/20/2022 18:55:42 - INFO - __main__ - Step 820 Global step 820 Train loss 2.04 on epoch=204
05/20/2022 18:55:44 - INFO - __main__ - Step 830 Global step 830 Train loss 1.96 on epoch=207
05/20/2022 18:55:45 - INFO - __main__ - Step 840 Global step 840 Train loss 2.01 on epoch=209
05/20/2022 18:55:46 - INFO - __main__ - Step 850 Global step 850 Train loss 1.82 on epoch=212
05/20/2022 18:55:47 - INFO - __main__ - Global step 850 Train loss 1.95 Classification-F1 0.1 on epoch=212
05/20/2022 18:55:48 - INFO - __main__ - Step 860 Global step 860 Train loss 1.86 on epoch=214
05/20/2022 18:55:50 - INFO - __main__ - Step 870 Global step 870 Train loss 1.94 on epoch=217
05/20/2022 18:55:51 - INFO - __main__ - Step 880 Global step 880 Train loss 1.99 on epoch=219
05/20/2022 18:55:53 - INFO - __main__ - Step 890 Global step 890 Train loss 1.84 on epoch=222
05/20/2022 18:55:54 - INFO - __main__ - Step 900 Global step 900 Train loss 1.82 on epoch=224
05/20/2022 18:55:55 - INFO - __main__ - Global step 900 Train loss 1.89 Classification-F1 0.1 on epoch=224
05/20/2022 18:55:56 - INFO - __main__ - Step 910 Global step 910 Train loss 1.83 on epoch=227
05/20/2022 18:55:57 - INFO - __main__ - Step 920 Global step 920 Train loss 1.99 on epoch=229
05/20/2022 18:55:59 - INFO - __main__ - Step 930 Global step 930 Train loss 1.74 on epoch=232
05/20/2022 18:56:00 - INFO - __main__ - Step 940 Global step 940 Train loss 1.91 on epoch=234
05/20/2022 18:56:02 - INFO - __main__ - Step 950 Global step 950 Train loss 1.81 on epoch=237
05/20/2022 18:56:02 - INFO - __main__ - Global step 950 Train loss 1.85 Classification-F1 0.1 on epoch=237
05/20/2022 18:56:03 - INFO - __main__ - Step 960 Global step 960 Train loss 1.73 on epoch=239
05/20/2022 18:56:05 - INFO - __main__ - Step 970 Global step 970 Train loss 1.88 on epoch=242
05/20/2022 18:56:06 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
05/20/2022 18:56:08 - INFO - __main__ - Step 990 Global step 990 Train loss 1.84 on epoch=247
05/20/2022 18:56:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.78 on epoch=249
05/20/2022 18:56:10 - INFO - __main__ - Global step 1000 Train loss 1.79 Classification-F1 0.1 on epoch=249
05/20/2022 18:56:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.74 on epoch=252
05/20/2022 18:56:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.84 on epoch=254
05/20/2022 18:56:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.66 on epoch=257
05/20/2022 18:56:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.68 on epoch=259
05/20/2022 18:56:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.84 on epoch=262
05/20/2022 18:56:17 - INFO - __main__ - Global step 1050 Train loss 1.75 Classification-F1 0.1 on epoch=262
05/20/2022 18:56:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.78 on epoch=264
05/20/2022 18:56:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.76 on epoch=267
05/20/2022 18:56:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.68 on epoch=269
05/20/2022 18:56:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.66 on epoch=272
05/20/2022 18:56:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.67 on epoch=274
05/20/2022 18:56:25 - INFO - __main__ - Global step 1100 Train loss 1.71 Classification-F1 0.1 on epoch=274
05/20/2022 18:56:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.63 on epoch=277
05/20/2022 18:56:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.69 on epoch=279
05/20/2022 18:56:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.58 on epoch=282
05/20/2022 18:56:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.59 on epoch=284
05/20/2022 18:56:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.62 on epoch=287
05/20/2022 18:56:32 - INFO - __main__ - Global step 1150 Train loss 1.62 Classification-F1 0.1 on epoch=287
05/20/2022 18:56:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.66 on epoch=289
05/20/2022 18:56:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.64 on epoch=292
05/20/2022 18:56:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.40 on epoch=294
05/20/2022 18:56:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.60 on epoch=297
05/20/2022 18:56:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.58 on epoch=299
05/20/2022 18:56:40 - INFO - __main__ - Global step 1200 Train loss 1.57 Classification-F1 0.1 on epoch=299
05/20/2022 18:56:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.60 on epoch=302
05/20/2022 18:56:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.39 on epoch=304
05/20/2022 18:56:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.47 on epoch=307
05/20/2022 18:56:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.54 on epoch=309
05/20/2022 18:56:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.53 on epoch=312
05/20/2022 18:56:47 - INFO - __main__ - Global step 1250 Train loss 1.51 Classification-F1 0.1 on epoch=312
05/20/2022 18:56:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.55 on epoch=314
05/20/2022 18:56:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.35 on epoch=317
05/20/2022 18:56:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.56 on epoch=319
05/20/2022 18:56:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.56 on epoch=322
05/20/2022 18:56:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.49 on epoch=324
05/20/2022 18:56:55 - INFO - __main__ - Global step 1300 Train loss 1.50 Classification-F1 0.1 on epoch=324
05/20/2022 18:56:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.49 on epoch=327
05/20/2022 18:56:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.50 on epoch=329
05/20/2022 18:56:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.45 on epoch=332
05/20/2022 18:57:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.55 on epoch=334
05/20/2022 18:57:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.50 on epoch=337
05/20/2022 18:57:02 - INFO - __main__ - Global step 1350 Train loss 1.50 Classification-F1 0.1 on epoch=337
05/20/2022 18:57:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.28 on epoch=339
05/20/2022 18:57:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.51 on epoch=342
05/20/2022 18:57:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.44 on epoch=344
05/20/2022 18:57:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.30 on epoch=347
05/20/2022 18:57:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.42 on epoch=349
05/20/2022 18:57:10 - INFO - __main__ - Global step 1400 Train loss 1.39 Classification-F1 0.1 on epoch=349
05/20/2022 18:57:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.34 on epoch=352
05/20/2022 18:57:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.45 on epoch=354
05/20/2022 18:57:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.50 on epoch=357
05/20/2022 18:57:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.43 on epoch=359
05/20/2022 18:57:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.47 on epoch=362
05/20/2022 18:57:17 - INFO - __main__ - Global step 1450 Train loss 1.44 Classification-F1 0.1 on epoch=362
05/20/2022 18:57:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.42 on epoch=364
05/20/2022 18:57:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.50 on epoch=367
05/20/2022 18:57:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.40 on epoch=369
05/20/2022 18:57:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.39 on epoch=372
05/20/2022 18:57:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.35 on epoch=374
05/20/2022 18:57:25 - INFO - __main__ - Global step 1500 Train loss 1.41 Classification-F1 0.1 on epoch=374
05/20/2022 18:57:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.26 on epoch=377
05/20/2022 18:57:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.43 on epoch=379
05/20/2022 18:57:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.44 on epoch=382
05/20/2022 18:57:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.36 on epoch=384
05/20/2022 18:57:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
05/20/2022 18:57:33 - INFO - __main__ - Global step 1550 Train loss 1.37 Classification-F1 0.1 on epoch=387
05/20/2022 18:57:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=389
05/20/2022 18:57:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.41 on epoch=392
05/20/2022 18:57:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=394
05/20/2022 18:57:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.28 on epoch=397
05/20/2022 18:57:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.30 on epoch=399
05/20/2022 18:57:41 - INFO - __main__ - Global step 1600 Train loss 1.28 Classification-F1 0.1 on epoch=399
05/20/2022 18:57:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.45 on epoch=402
05/20/2022 18:57:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.34 on epoch=404
05/20/2022 18:57:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.33 on epoch=407
05/20/2022 18:57:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.40 on epoch=409
05/20/2022 18:57:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.33 on epoch=412
05/20/2022 18:57:49 - INFO - __main__ - Global step 1650 Train loss 1.37 Classification-F1 0.1 on epoch=412
05/20/2022 18:57:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.43 on epoch=414
05/20/2022 18:57:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
05/20/2022 18:57:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.22 on epoch=419
05/20/2022 18:57:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.36 on epoch=422
05/20/2022 18:57:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.38 on epoch=424
05/20/2022 18:57:56 - INFO - __main__ - Global step 1700 Train loss 1.33 Classification-F1 0.1 on epoch=424
05/20/2022 18:57:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=427
05/20/2022 18:57:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.34 on epoch=429
05/20/2022 18:58:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.30 on epoch=432
05/20/2022 18:58:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.23 on epoch=434
05/20/2022 18:58:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.37 on epoch=437
05/20/2022 18:58:04 - INFO - __main__ - Global step 1750 Train loss 1.30 Classification-F1 0.1 on epoch=437
05/20/2022 18:58:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.23 on epoch=439
05/20/2022 18:58:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.16 on epoch=442
05/20/2022 18:58:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.16 on epoch=444
05/20/2022 18:58:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.34 on epoch=447
05/20/2022 18:58:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.31 on epoch=449
05/20/2022 18:58:12 - INFO - __main__ - Global step 1800 Train loss 1.24 Classification-F1 0.1 on epoch=449
05/20/2022 18:58:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.21 on epoch=452
05/20/2022 18:58:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.29 on epoch=454
05/20/2022 18:58:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.16 on epoch=457
05/20/2022 18:58:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.10 on epoch=459
05/20/2022 18:58:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.34 on epoch=462
05/20/2022 18:58:19 - INFO - __main__ - Global step 1850 Train loss 1.22 Classification-F1 0.1 on epoch=462
05/20/2022 18:58:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.09 on epoch=464
05/20/2022 18:58:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.14 on epoch=467
05/20/2022 18:58:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
05/20/2022 18:58:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.37 on epoch=472
05/20/2022 18:58:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/20/2022 18:58:27 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.1 on epoch=474
05/20/2022 18:58:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.16 on epoch=477
05/20/2022 18:58:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.16 on epoch=479
05/20/2022 18:58:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.29 on epoch=482
05/20/2022 18:58:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.22 on epoch=484
05/20/2022 18:58:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.24 on epoch=487
05/20/2022 18:58:34 - INFO - __main__ - Global step 1950 Train loss 1.21 Classification-F1 0.1 on epoch=487
05/20/2022 18:58:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.33 on epoch=489
05/20/2022 18:58:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.25 on epoch=492
05/20/2022 18:58:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.14 on epoch=494
05/20/2022 18:58:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.29 on epoch=497
05/20/2022 18:58:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.00 on epoch=499
05/20/2022 18:58:41 - INFO - __main__ - Global step 2000 Train loss 1.20 Classification-F1 0.1 on epoch=499
05/20/2022 18:58:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.08 on epoch=502
05/20/2022 18:58:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.20 on epoch=504
05/20/2022 18:58:46 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.07 on epoch=507
05/20/2022 18:58:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.28 on epoch=509
05/20/2022 18:58:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.20 on epoch=512
05/20/2022 18:58:49 - INFO - __main__ - Global step 2050 Train loss 1.17 Classification-F1 0.09493670886075949 on epoch=512
05/20/2022 18:58:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.32 on epoch=514
05/20/2022 18:58:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.18 on epoch=517
05/20/2022 18:58:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.25 on epoch=519
05/20/2022 18:58:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.01 on epoch=522
05/20/2022 18:58:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.22 on epoch=524
05/20/2022 18:58:56 - INFO - __main__ - Global step 2100 Train loss 1.19 Classification-F1 0.13034188034188032 on epoch=524
05/20/2022 18:58:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.10 on epoch=527
05/20/2022 18:58:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.21 on epoch=529
05/20/2022 18:59:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.18 on epoch=532
05/20/2022 18:59:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.19 on epoch=534
05/20/2022 18:59:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.27 on epoch=537
05/20/2022 18:59:04 - INFO - __main__ - Global step 2150 Train loss 1.19 Classification-F1 0.1 on epoch=537
05/20/2022 18:59:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.18 on epoch=539
05/20/2022 18:59:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.21 on epoch=542
05/20/2022 18:59:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.14 on epoch=544
05/20/2022 18:59:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.12 on epoch=547
05/20/2022 18:59:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.06 on epoch=549
05/20/2022 18:59:12 - INFO - __main__ - Global step 2200 Train loss 1.14 Classification-F1 0.1468058968058968 on epoch=549
05/20/2022 18:59:12 - INFO - __main__ - Saving model with best Classification-F1: 0.14505347593582887 -> 0.1468058968058968 on epoch=549, global_step=2200
05/20/2022 18:59:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.07 on epoch=552
05/20/2022 18:59:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.07 on epoch=554
05/20/2022 18:59:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.25 on epoch=557
05/20/2022 18:59:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.14 on epoch=559
05/20/2022 18:59:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.20 on epoch=562
05/20/2022 18:59:20 - INFO - __main__ - Global step 2250 Train loss 1.15 Classification-F1 0.10256410256410256 on epoch=562
05/20/2022 18:59:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.15 on epoch=564
05/20/2022 18:59:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.05 on epoch=567
05/20/2022 18:59:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.19 on epoch=569
05/20/2022 18:59:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.00 on epoch=572
05/20/2022 18:59:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.12 on epoch=574
05/20/2022 18:59:28 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.1 on epoch=574
05/20/2022 18:59:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/20/2022 18:59:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
05/20/2022 18:59:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.08 on epoch=582
05/20/2022 18:59:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.16 on epoch=584
05/20/2022 18:59:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.02 on epoch=587
05/20/2022 18:59:36 - INFO - __main__ - Global step 2350 Train loss 1.09 Classification-F1 0.1 on epoch=587
05/20/2022 18:59:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/20/2022 18:59:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/20/2022 18:59:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/20/2022 18:59:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.10 on epoch=597
05/20/2022 18:59:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.08 on epoch=599
05/20/2022 18:59:43 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.1 on epoch=599
05/20/2022 18:59:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.10 on epoch=602
05/20/2022 18:59:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/20/2022 18:59:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.15 on epoch=607
05/20/2022 18:59:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
05/20/2022 18:59:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.17 on epoch=612
05/20/2022 18:59:51 - INFO - __main__ - Global step 2450 Train loss 1.07 Classification-F1 0.1 on epoch=612
05/20/2022 18:59:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
05/20/2022 18:59:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.15 on epoch=617
05/20/2022 18:59:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.24 on epoch=619
05/20/2022 18:59:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.18 on epoch=622
05/20/2022 18:59:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.05 on epoch=624
05/20/2022 18:59:58 - INFO - __main__ - Global step 2500 Train loss 1.14 Classification-F1 0.1 on epoch=624
05/20/2022 19:00:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.12 on epoch=627
05/20/2022 19:00:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
05/20/2022 19:00:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.21 on epoch=632
05/20/2022 19:00:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.18 on epoch=634
05/20/2022 19:00:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
05/20/2022 19:00:06 - INFO - __main__ - Global step 2550 Train loss 1.14 Classification-F1 0.1 on epoch=637
05/20/2022 19:00:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.15 on epoch=639
05/20/2022 19:00:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
05/20/2022 19:00:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.16 on epoch=644
05/20/2022 19:00:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.11 on epoch=647
05/20/2022 19:00:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
05/20/2022 19:00:14 - INFO - __main__ - Global step 2600 Train loss 1.09 Classification-F1 0.1 on epoch=649
05/20/2022 19:00:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
05/20/2022 19:00:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.07 on epoch=654
05/20/2022 19:00:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.10 on epoch=657
05/20/2022 19:00:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.10 on epoch=659
05/20/2022 19:00:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.21 on epoch=662
05/20/2022 19:00:21 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.1 on epoch=662
05/20/2022 19:00:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.10 on epoch=664
05/20/2022 19:00:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.06 on epoch=667
05/20/2022 19:00:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.18 on epoch=669
05/20/2022 19:00:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.11 on epoch=672
05/20/2022 19:00:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.08 on epoch=674
05/20/2022 19:00:29 - INFO - __main__ - Global step 2700 Train loss 1.11 Classification-F1 0.1 on epoch=674
05/20/2022 19:00:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.94 on epoch=677
05/20/2022 19:00:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
05/20/2022 19:00:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.05 on epoch=682
05/20/2022 19:00:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.08 on epoch=684
05/20/2022 19:00:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.05 on epoch=687
05/20/2022 19:00:38 - INFO - __main__ - Global step 2750 Train loss 1.03 Classification-F1 0.1 on epoch=687
05/20/2022 19:00:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.18 on epoch=689
05/20/2022 19:00:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
05/20/2022 19:00:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.17 on epoch=694
05/20/2022 19:00:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.04 on epoch=697
05/20/2022 19:00:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.15 on epoch=699
05/20/2022 19:00:45 - INFO - __main__ - Global step 2800 Train loss 1.10 Classification-F1 0.1 on epoch=699
05/20/2022 19:00:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.11 on epoch=702
05/20/2022 19:00:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.08 on epoch=704
05/20/2022 19:00:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.02 on epoch=707
05/20/2022 19:00:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/20/2022 19:00:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.01 on epoch=712
05/20/2022 19:00:53 - INFO - __main__ - Global step 2850 Train loss 1.04 Classification-F1 0.1 on epoch=712
05/20/2022 19:00:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.05 on epoch=714
05/20/2022 19:00:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/20/2022 19:00:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.03 on epoch=719
05/20/2022 19:00:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.07 on epoch=722
05/20/2022 19:01:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/20/2022 19:01:00 - INFO - __main__ - Global step 2900 Train loss 1.04 Classification-F1 0.1 on epoch=724
05/20/2022 19:01:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.04 on epoch=727
05/20/2022 19:01:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.09 on epoch=729
05/20/2022 19:01:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.04 on epoch=732
05/20/2022 19:01:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.18 on epoch=734
05/20/2022 19:01:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.09 on epoch=737
05/20/2022 19:01:08 - INFO - __main__ - Global step 2950 Train loss 1.09 Classification-F1 0.1 on epoch=737
05/20/2022 19:01:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.05 on epoch=739
05/20/2022 19:01:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.04 on epoch=742
05/20/2022 19:01:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.18 on epoch=744
05/20/2022 19:01:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=747
05/20/2022 19:01:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.15 on epoch=749
05/20/2022 19:01:15 - INFO - __main__ - Global step 3000 Train loss 1.08 Classification-F1 0.1 on epoch=749
05/20/2022 19:01:15 - INFO - __main__ - save last model!
05/20/2022 19:01:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 19:01:15 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 19:01:15 - INFO - __main__ - Printing 3 examples
05/20/2022 19:01:15 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 19:01:15 - INFO - __main__ - ['others']
05/20/2022 19:01:15 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 19:01:15 - INFO - __main__ - ['others']
05/20/2022 19:01:15 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 19:01:15 - INFO - __main__ - ['others']
05/20/2022 19:01:15 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:01:16 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:01:16 - INFO - __main__ - Printing 3 examples
05/20/2022 19:01:16 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:01:16 - INFO - __main__ - ['others']
05/20/2022 19:01:16 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:01:16 - INFO - __main__ - ['others']
05/20/2022 19:01:16 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:01:16 - INFO - __main__ - ['others']
05/20/2022 19:01:16 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:01:16 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:01:16 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:01:16 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:01:16 - INFO - __main__ - Printing 3 examples
05/20/2022 19:01:16 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:01:16 - INFO - __main__ - ['others']
05/20/2022 19:01:16 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:01:16 - INFO - __main__ - ['others']
05/20/2022 19:01:16 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:01:16 - INFO - __main__ - ['others']
05/20/2022 19:01:16 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:01:16 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:01:16 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:01:18 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:01:22 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:01:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:01:23 - INFO - __main__ - Starting training!
05/20/2022 19:01:23 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 19:02:08 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.2_8_predictions.txt
05/20/2022 19:02:08 - INFO - __main__ - Classification-F1 on test data: 0.0257
05/20/2022 19:02:08 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.1468058968058968, test_performance=0.025658687790597552
05/20/2022 19:02:08 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
05/20/2022 19:02:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:02:09 - INFO - __main__ - Printing 3 examples
05/20/2022 19:02:09 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:02:09 - INFO - __main__ - ['others']
05/20/2022 19:02:09 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:02:09 - INFO - __main__ - ['others']
05/20/2022 19:02:09 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:02:09 - INFO - __main__ - ['others']
05/20/2022 19:02:09 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:02:09 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:02:09 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:02:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:02:09 - INFO - __main__ - Printing 3 examples
05/20/2022 19:02:09 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:02:09 - INFO - __main__ - ['others']
05/20/2022 19:02:09 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:02:09 - INFO - __main__ - ['others']
05/20/2022 19:02:09 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:02:09 - INFO - __main__ - ['others']
05/20/2022 19:02:09 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:02:09 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:02:09 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:02:15 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:02:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:02:15 - INFO - __main__ - Starting training!
05/20/2022 19:02:17 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=2
05/20/2022 19:02:18 - INFO - __main__ - Step 20 Global step 20 Train loss 6.61 on epoch=4
05/20/2022 19:02:20 - INFO - __main__ - Step 30 Global step 30 Train loss 6.22 on epoch=7
05/20/2022 19:02:21 - INFO - __main__ - Step 40 Global step 40 Train loss 5.81 on epoch=9
05/20/2022 19:02:22 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=12
05/20/2022 19:02:27 - INFO - __main__ - Global step 50 Train loss 6.18 Classification-F1 0.0 on epoch=12
05/20/2022 19:02:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 19:02:28 - INFO - __main__ - Step 60 Global step 60 Train loss 5.17 on epoch=14
05/20/2022 19:02:30 - INFO - __main__ - Step 70 Global step 70 Train loss 4.83 on epoch=17
05/20/2022 19:02:31 - INFO - __main__ - Step 80 Global step 80 Train loss 4.36 on epoch=19
05/20/2022 19:02:32 - INFO - __main__ - Step 90 Global step 90 Train loss 4.15 on epoch=22
05/20/2022 19:02:34 - INFO - __main__ - Step 100 Global step 100 Train loss 3.93 on epoch=24
05/20/2022 19:02:34 - INFO - __main__ - Global step 100 Train loss 4.49 Classification-F1 0.22426438296003515 on epoch=24
05/20/2022 19:02:34 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.22426438296003515 on epoch=24, global_step=100
05/20/2022 19:02:36 - INFO - __main__ - Step 110 Global step 110 Train loss 3.93 on epoch=27
05/20/2022 19:02:37 - INFO - __main__ - Step 120 Global step 120 Train loss 3.38 on epoch=29
05/20/2022 19:02:39 - INFO - __main__ - Step 130 Global step 130 Train loss 3.35 on epoch=32
05/20/2022 19:02:40 - INFO - __main__ - Step 140 Global step 140 Train loss 3.24 on epoch=34
05/20/2022 19:02:41 - INFO - __main__ - Step 150 Global step 150 Train loss 3.27 on epoch=37
05/20/2022 19:02:42 - INFO - __main__ - Global step 150 Train loss 3.44 Classification-F1 0.06507515473032714 on epoch=37
05/20/2022 19:02:43 - INFO - __main__ - Step 160 Global step 160 Train loss 2.89 on epoch=39
05/20/2022 19:02:45 - INFO - __main__ - Step 170 Global step 170 Train loss 3.02 on epoch=42
05/20/2022 19:02:46 - INFO - __main__ - Step 180 Global step 180 Train loss 2.78 on epoch=44
05/20/2022 19:02:47 - INFO - __main__ - Step 190 Global step 190 Train loss 2.83 on epoch=47
05/20/2022 19:02:49 - INFO - __main__ - Step 200 Global step 200 Train loss 2.75 on epoch=49
05/20/2022 19:02:49 - INFO - __main__ - Global step 200 Train loss 2.85 Classification-F1 0.15587044534412953 on epoch=49
05/20/2022 19:02:51 - INFO - __main__ - Step 210 Global step 210 Train loss 2.83 on epoch=52
05/20/2022 19:02:52 - INFO - __main__ - Step 220 Global step 220 Train loss 2.55 on epoch=54
05/20/2022 19:02:53 - INFO - __main__ - Step 230 Global step 230 Train loss 2.54 on epoch=57
05/20/2022 19:02:55 - INFO - __main__ - Step 240 Global step 240 Train loss 2.40 on epoch=59
05/20/2022 19:02:56 - INFO - __main__ - Step 250 Global step 250 Train loss 2.76 on epoch=62
05/20/2022 19:02:57 - INFO - __main__ - Global step 250 Train loss 2.61 Classification-F1 0.19654556283502084 on epoch=62
05/20/2022 19:02:58 - INFO - __main__ - Step 260 Global step 260 Train loss 2.53 on epoch=64
05/20/2022 19:02:59 - INFO - __main__ - Step 270 Global step 270 Train loss 2.59 on epoch=67
05/20/2022 19:03:01 - INFO - __main__ - Step 280 Global step 280 Train loss 2.35 on epoch=69
05/20/2022 19:03:02 - INFO - __main__ - Step 290 Global step 290 Train loss 2.38 on epoch=72
05/20/2022 19:03:04 - INFO - __main__ - Step 300 Global step 300 Train loss 2.10 on epoch=74
05/20/2022 19:03:04 - INFO - __main__ - Global step 300 Train loss 2.39 Classification-F1 0.13067758749069247 on epoch=74
05/20/2022 19:03:06 - INFO - __main__ - Step 310 Global step 310 Train loss 2.10 on epoch=77
05/20/2022 19:03:07 - INFO - __main__ - Step 320 Global step 320 Train loss 2.04 on epoch=79
05/20/2022 19:03:08 - INFO - __main__ - Step 330 Global step 330 Train loss 2.21 on epoch=82
05/20/2022 19:03:10 - INFO - __main__ - Step 340 Global step 340 Train loss 2.01 on epoch=84
05/20/2022 19:03:11 - INFO - __main__ - Step 350 Global step 350 Train loss 2.00 on epoch=87
05/20/2022 19:03:12 - INFO - __main__ - Global step 350 Train loss 2.07 Classification-F1 0.11722488038277512 on epoch=87
05/20/2022 19:03:13 - INFO - __main__ - Step 360 Global step 360 Train loss 1.87 on epoch=89
05/20/2022 19:03:14 - INFO - __main__ - Step 370 Global step 370 Train loss 1.90 on epoch=92
05/20/2022 19:03:15 - INFO - __main__ - Step 380 Global step 380 Train loss 1.77 on epoch=94
05/20/2022 19:03:17 - INFO - __main__ - Step 390 Global step 390 Train loss 1.89 on epoch=97
05/20/2022 19:03:18 - INFO - __main__ - Step 400 Global step 400 Train loss 1.82 on epoch=99
05/20/2022 19:03:19 - INFO - __main__ - Global step 400 Train loss 1.85 Classification-F1 0.2011385199240987 on epoch=99
05/20/2022 19:03:20 - INFO - __main__ - Step 410 Global step 410 Train loss 1.74 on epoch=102
05/20/2022 19:03:22 - INFO - __main__ - Step 420 Global step 420 Train loss 1.62 on epoch=104
05/20/2022 19:03:23 - INFO - __main__ - Step 430 Global step 430 Train loss 1.73 on epoch=107
05/20/2022 19:03:24 - INFO - __main__ - Step 440 Global step 440 Train loss 1.67 on epoch=109
05/20/2022 19:03:26 - INFO - __main__ - Step 450 Global step 450 Train loss 1.74 on epoch=112
05/20/2022 19:03:26 - INFO - __main__ - Global step 450 Train loss 1.70 Classification-F1 0.09615384615384615 on epoch=112
05/20/2022 19:03:28 - INFO - __main__ - Step 460 Global step 460 Train loss 1.55 on epoch=114
05/20/2022 19:03:29 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=117
05/20/2022 19:03:30 - INFO - __main__ - Step 480 Global step 480 Train loss 1.46 on epoch=119
05/20/2022 19:03:32 - INFO - __main__ - Step 490 Global step 490 Train loss 1.53 on epoch=122
05/20/2022 19:03:33 - INFO - __main__ - Step 500 Global step 500 Train loss 1.41 on epoch=124
05/20/2022 19:03:34 - INFO - __main__ - Global step 500 Train loss 1.54 Classification-F1 0.15526315789473685 on epoch=124
05/20/2022 19:03:35 - INFO - __main__ - Step 510 Global step 510 Train loss 1.52 on epoch=127
05/20/2022 19:03:36 - INFO - __main__ - Step 520 Global step 520 Train loss 1.44 on epoch=129
05/20/2022 19:03:38 - INFO - __main__ - Step 530 Global step 530 Train loss 1.49 on epoch=132
05/20/2022 19:03:39 - INFO - __main__ - Step 540 Global step 540 Train loss 1.50 on epoch=134
05/20/2022 19:03:40 - INFO - __main__ - Step 550 Global step 550 Train loss 1.40 on epoch=137
05/20/2022 19:03:41 - INFO - __main__ - Global step 550 Train loss 1.47 Classification-F1 0.13026315789473686 on epoch=137
05/20/2022 19:03:42 - INFO - __main__ - Step 560 Global step 560 Train loss 1.33 on epoch=139
05/20/2022 19:03:44 - INFO - __main__ - Step 570 Global step 570 Train loss 1.35 on epoch=142
05/20/2022 19:03:45 - INFO - __main__ - Step 580 Global step 580 Train loss 1.29 on epoch=144
05/20/2022 19:03:46 - INFO - __main__ - Step 590 Global step 590 Train loss 1.46 on epoch=147
05/20/2022 19:03:48 - INFO - __main__ - Step 600 Global step 600 Train loss 1.38 on epoch=149
05/20/2022 19:03:48 - INFO - __main__ - Global step 600 Train loss 1.36 Classification-F1 0.13034188034188032 on epoch=149
05/20/2022 19:03:50 - INFO - __main__ - Step 610 Global step 610 Train loss 1.27 on epoch=152
05/20/2022 19:03:51 - INFO - __main__ - Step 620 Global step 620 Train loss 1.26 on epoch=154
05/20/2022 19:03:52 - INFO - __main__ - Step 630 Global step 630 Train loss 1.23 on epoch=157
05/20/2022 19:03:54 - INFO - __main__ - Step 640 Global step 640 Train loss 1.32 on epoch=159
05/20/2022 19:03:55 - INFO - __main__ - Step 650 Global step 650 Train loss 1.19 on epoch=162
05/20/2022 19:03:56 - INFO - __main__ - Global step 650 Train loss 1.25 Classification-F1 0.16926248282180484 on epoch=162
05/20/2022 19:03:57 - INFO - __main__ - Step 660 Global step 660 Train loss 1.26 on epoch=164
05/20/2022 19:03:58 - INFO - __main__ - Step 670 Global step 670 Train loss 1.36 on epoch=167
05/20/2022 19:04:00 - INFO - __main__ - Step 680 Global step 680 Train loss 1.22 on epoch=169
05/20/2022 19:04:01 - INFO - __main__ - Step 690 Global step 690 Train loss 1.10 on epoch=172
05/20/2022 19:04:03 - INFO - __main__ - Step 700 Global step 700 Train loss 1.16 on epoch=174
05/20/2022 19:04:03 - INFO - __main__ - Global step 700 Train loss 1.22 Classification-F1 0.10126582278481013 on epoch=174
05/20/2022 19:04:05 - INFO - __main__ - Step 710 Global step 710 Train loss 1.10 on epoch=177
05/20/2022 19:04:06 - INFO - __main__ - Step 720 Global step 720 Train loss 1.17 on epoch=179
05/20/2022 19:04:07 - INFO - __main__ - Step 730 Global step 730 Train loss 1.10 on epoch=182
05/20/2022 19:04:09 - INFO - __main__ - Step 740 Global step 740 Train loss 1.02 on epoch=184
05/20/2022 19:04:10 - INFO - __main__ - Step 750 Global step 750 Train loss 1.14 on epoch=187
05/20/2022 19:04:11 - INFO - __main__ - Global step 750 Train loss 1.11 Classification-F1 0.1 on epoch=187
05/20/2022 19:04:12 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=189
05/20/2022 19:04:13 - INFO - __main__ - Step 770 Global step 770 Train loss 1.19 on epoch=192
05/20/2022 19:04:15 - INFO - __main__ - Step 780 Global step 780 Train loss 1.15 on epoch=194
05/20/2022 19:04:16 - INFO - __main__ - Step 790 Global step 790 Train loss 1.15 on epoch=197
05/20/2022 19:04:17 - INFO - __main__ - Step 800 Global step 800 Train loss 1.04 on epoch=199
05/20/2022 19:04:18 - INFO - __main__ - Global step 800 Train loss 1.15 Classification-F1 0.13541666666666669 on epoch=199
05/20/2022 19:04:19 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=202
05/20/2022 19:04:21 - INFO - __main__ - Step 820 Global step 820 Train loss 1.14 on epoch=204
05/20/2022 19:04:22 - INFO - __main__ - Step 830 Global step 830 Train loss 1.09 on epoch=207
05/20/2022 19:04:24 - INFO - __main__ - Step 840 Global step 840 Train loss 1.01 on epoch=209
05/20/2022 19:04:25 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=212
05/20/2022 19:04:26 - INFO - __main__ - Global step 850 Train loss 1.11 Classification-F1 0.15535714285714286 on epoch=212
05/20/2022 19:04:27 - INFO - __main__ - Step 860 Global step 860 Train loss 1.21 on epoch=214
05/20/2022 19:04:29 - INFO - __main__ - Step 870 Global step 870 Train loss 1.13 on epoch=217
05/20/2022 19:04:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.18 on epoch=219
05/20/2022 19:04:31 - INFO - __main__ - Step 890 Global step 890 Train loss 1.28 on epoch=222
05/20/2022 19:04:33 - INFO - __main__ - Step 900 Global step 900 Train loss 1.21 on epoch=224
05/20/2022 19:04:33 - INFO - __main__ - Global step 900 Train loss 1.20 Classification-F1 0.18014375561545376 on epoch=224
05/20/2022 19:04:35 - INFO - __main__ - Step 910 Global step 910 Train loss 1.19 on epoch=227
05/20/2022 19:04:36 - INFO - __main__ - Step 920 Global step 920 Train loss 1.09 on epoch=229
05/20/2022 19:04:37 - INFO - __main__ - Step 930 Global step 930 Train loss 1.08 on epoch=232
05/20/2022 19:04:39 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=234
05/20/2022 19:04:40 - INFO - __main__ - Step 950 Global step 950 Train loss 1.04 on epoch=237
05/20/2022 19:04:41 - INFO - __main__ - Global step 950 Train loss 1.11 Classification-F1 0.1484375 on epoch=237
05/20/2022 19:04:42 - INFO - __main__ - Step 960 Global step 960 Train loss 1.05 on epoch=239
05/20/2022 19:04:43 - INFO - __main__ - Step 970 Global step 970 Train loss 1.12 on epoch=242
05/20/2022 19:04:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.08 on epoch=244
05/20/2022 19:04:46 - INFO - __main__ - Step 990 Global step 990 Train loss 1.04 on epoch=247
05/20/2022 19:04:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.03 on epoch=249
05/20/2022 19:04:48 - INFO - __main__ - Global step 1000 Train loss 1.07 Classification-F1 0.12333965844402277 on epoch=249
05/20/2022 19:04:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
05/20/2022 19:04:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.15 on epoch=254
05/20/2022 19:04:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/20/2022 19:04:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.10 on epoch=259
05/20/2022 19:04:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=262
05/20/2022 19:04:55 - INFO - __main__ - Global step 1050 Train loss 1.10 Classification-F1 0.1875 on epoch=262
05/20/2022 19:04:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
05/20/2022 19:04:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.02 on epoch=267
05/20/2022 19:04:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.97 on epoch=269
05/20/2022 19:05:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.04 on epoch=272
05/20/2022 19:05:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.02 on epoch=274
05/20/2022 19:05:03 - INFO - __main__ - Global step 1100 Train loss 1.02 Classification-F1 0.15607940446650126 on epoch=274
05/20/2022 19:05:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.00 on epoch=277
05/20/2022 19:05:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.07 on epoch=279
05/20/2022 19:05:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=282
05/20/2022 19:05:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.02 on epoch=284
05/20/2022 19:05:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.08 on epoch=287
05/20/2022 19:05:10 - INFO - __main__ - Global step 1150 Train loss 1.03 Classification-F1 0.12368421052631579 on epoch=287
05/20/2022 19:05:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.05 on epoch=289
05/20/2022 19:05:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=292
05/20/2022 19:05:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.08 on epoch=294
05/20/2022 19:05:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.19 on epoch=297
05/20/2022 19:05:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.13 on epoch=299
05/20/2022 19:05:18 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.1565349544072948 on epoch=299
05/20/2022 19:05:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.03 on epoch=302
05/20/2022 19:05:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.10 on epoch=304
05/20/2022 19:05:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.16 on epoch=307
05/20/2022 19:05:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.01 on epoch=309
05/20/2022 19:05:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.04 on epoch=312
05/20/2022 19:05:25 - INFO - __main__ - Global step 1250 Train loss 1.07 Classification-F1 0.1 on epoch=312
05/20/2022 19:05:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=314
05/20/2022 19:05:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.02 on epoch=317
05/20/2022 19:05:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.08 on epoch=319
05/20/2022 19:05:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.06 on epoch=322
05/20/2022 19:05:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.08 on epoch=324
05/20/2022 19:05:33 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.20417422867513613 on epoch=324
05/20/2022 19:05:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.13 on epoch=327
05/20/2022 19:05:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.06 on epoch=329
05/20/2022 19:05:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.99 on epoch=332
05/20/2022 19:05:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.06 on epoch=334
05/20/2022 19:05:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.98 on epoch=337
05/20/2022 19:05:40 - INFO - __main__ - Global step 1350 Train loss 1.04 Classification-F1 0.09090909090909091 on epoch=337
05/20/2022 19:05:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/20/2022 19:05:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.96 on epoch=342
05/20/2022 19:05:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/20/2022 19:05:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.98 on epoch=347
05/20/2022 19:05:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.95 on epoch=349
05/20/2022 19:05:48 - INFO - __main__ - Global step 1400 Train loss 1.00 Classification-F1 0.09305210918114144 on epoch=349
05/20/2022 19:05:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.97 on epoch=352
05/20/2022 19:05:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/20/2022 19:05:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.95 on epoch=357
05/20/2022 19:05:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.96 on epoch=359
05/20/2022 19:05:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.93 on epoch=362
05/20/2022 19:05:55 - INFO - __main__ - Global step 1450 Train loss 0.96 Classification-F1 0.11687344913151365 on epoch=362
05/20/2022 19:05:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.90 on epoch=364
05/20/2022 19:05:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.02 on epoch=367
05/20/2022 19:05:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/20/2022 19:06:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.93 on epoch=372
05/20/2022 19:06:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.88 on epoch=374
05/20/2022 19:06:03 - INFO - __main__ - Global step 1500 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=374
05/20/2022 19:06:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
05/20/2022 19:06:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=379
05/20/2022 19:06:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.89 on epoch=382
05/20/2022 19:06:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.86 on epoch=384
05/20/2022 19:06:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.01 on epoch=387
05/20/2022 19:06:10 - INFO - __main__ - Global step 1550 Train loss 0.97 Classification-F1 0.1 on epoch=387
05/20/2022 19:06:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.89 on epoch=389
05/20/2022 19:06:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.95 on epoch=392
05/20/2022 19:06:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.00 on epoch=394
05/20/2022 19:06:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.88 on epoch=397
05/20/2022 19:06:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
05/20/2022 19:06:18 - INFO - __main__ - Global step 1600 Train loss 0.94 Classification-F1 0.1 on epoch=399
05/20/2022 19:06:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.05 on epoch=402
05/20/2022 19:06:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.93 on epoch=404
05/20/2022 19:06:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.92 on epoch=407
05/20/2022 19:06:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.00 on epoch=409
05/20/2022 19:06:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.99 on epoch=412
05/20/2022 19:06:25 - INFO - __main__ - Global step 1650 Train loss 0.98 Classification-F1 0.17408906882591094 on epoch=412
05/20/2022 19:06:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.00 on epoch=414
05/20/2022 19:06:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/20/2022 19:06:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.98 on epoch=419
05/20/2022 19:06:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.96 on epoch=422
05/20/2022 19:06:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.94 on epoch=424
05/20/2022 19:06:32 - INFO - __main__ - Global step 1700 Train loss 0.99 Classification-F1 0.1 on epoch=424
05/20/2022 19:06:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.95 on epoch=427
05/20/2022 19:06:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/20/2022 19:06:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.97 on epoch=432
05/20/2022 19:06:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.90 on epoch=434
05/20/2022 19:06:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.94 on epoch=437
05/20/2022 19:06:39 - INFO - __main__ - Global step 1750 Train loss 0.95 Classification-F1 0.1 on epoch=437
05/20/2022 19:06:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.96 on epoch=439
05/20/2022 19:06:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/20/2022 19:06:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=444
05/20/2022 19:06:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.95 on epoch=447
05/20/2022 19:06:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=449
05/20/2022 19:06:47 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.1 on epoch=449
05/20/2022 19:06:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.06 on epoch=452
05/20/2022 19:06:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.10 on epoch=454
05/20/2022 19:06:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.90 on epoch=457
05/20/2022 19:06:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.92 on epoch=459
05/20/2022 19:06:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.91 on epoch=462
05/20/2022 19:06:54 - INFO - __main__ - Global step 1850 Train loss 0.98 Classification-F1 0.1488888888888889 on epoch=462
05/20/2022 19:06:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.93 on epoch=464
05/20/2022 19:06:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.86 on epoch=467
05/20/2022 19:06:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.96 on epoch=469
05/20/2022 19:06:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.87 on epoch=472
05/20/2022 19:07:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.89 on epoch=474
05/20/2022 19:07:01 - INFO - __main__ - Global step 1900 Train loss 0.90 Classification-F1 0.1238095238095238 on epoch=474
05/20/2022 19:07:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.06 on epoch=477
05/20/2022 19:07:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.95 on epoch=479
05/20/2022 19:07:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
05/20/2022 19:07:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=484
05/20/2022 19:07:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.00 on epoch=487
05/20/2022 19:07:08 - INFO - __main__ - Global step 1950 Train loss 0.98 Classification-F1 0.13067758749069247 on epoch=487
05/20/2022 19:07:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=489
05/20/2022 19:07:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=492
05/20/2022 19:07:12 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.98 on epoch=494
05/20/2022 19:07:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.98 on epoch=497
05/20/2022 19:07:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/20/2022 19:07:16 - INFO - __main__ - Global step 2000 Train loss 0.96 Classification-F1 0.1980392156862745 on epoch=499
05/20/2022 19:07:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.88 on epoch=502
05/20/2022 19:07:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.89 on epoch=504
05/20/2022 19:07:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=507
05/20/2022 19:07:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.86 on epoch=509
05/20/2022 19:07:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.94 on epoch=512
05/20/2022 19:07:23 - INFO - __main__ - Global step 2050 Train loss 0.91 Classification-F1 0.12447885646217988 on epoch=512
05/20/2022 19:07:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.94 on epoch=514
05/20/2022 19:07:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.91 on epoch=517
05/20/2022 19:07:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
05/20/2022 19:07:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.87 on epoch=522
05/20/2022 19:07:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.93 on epoch=524
05/20/2022 19:07:30 - INFO - __main__ - Global step 2100 Train loss 0.92 Classification-F1 0.12391774891774893 on epoch=524
05/20/2022 19:07:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.88 on epoch=527
05/20/2022 19:07:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
05/20/2022 19:07:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/20/2022 19:07:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/20/2022 19:07:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.03 on epoch=537
05/20/2022 19:07:37 - INFO - __main__ - Global step 2150 Train loss 0.99 Classification-F1 0.13034188034188032 on epoch=537
05/20/2022 19:07:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.93 on epoch=539
05/20/2022 19:07:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.03 on epoch=542
05/20/2022 19:07:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.86 on epoch=544
05/20/2022 19:07:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.03 on epoch=547
05/20/2022 19:07:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.94 on epoch=549
05/20/2022 19:07:45 - INFO - __main__ - Global step 2200 Train loss 0.96 Classification-F1 0.12439024390243902 on epoch=549
05/20/2022 19:07:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.93 on epoch=552
05/20/2022 19:07:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.90 on epoch=554
05/20/2022 19:07:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/20/2022 19:07:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.91 on epoch=559
05/20/2022 19:07:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
05/20/2022 19:07:52 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.18674449412154331 on epoch=562
05/20/2022 19:07:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.89 on epoch=564
05/20/2022 19:07:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.07 on epoch=567
05/20/2022 19:07:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.99 on epoch=569
05/20/2022 19:07:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
05/20/2022 19:07:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.96 on epoch=574
05/20/2022 19:08:00 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.10987903225806452 on epoch=574
05/20/2022 19:08:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.90 on epoch=577
05/20/2022 19:08:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.03 on epoch=579
05/20/2022 19:08:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/20/2022 19:08:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.97 on epoch=584
05/20/2022 19:08:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.99 on epoch=587
05/20/2022 19:08:07 - INFO - __main__ - Global step 2350 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=587
05/20/2022 19:08:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.93 on epoch=589
05/20/2022 19:08:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.98 on epoch=592
05/20/2022 19:08:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.98 on epoch=594
05/20/2022 19:08:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.93 on epoch=597
05/20/2022 19:08:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.06 on epoch=599
05/20/2022 19:08:15 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.13865546218487396 on epoch=599
05/20/2022 19:08:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.03 on epoch=602
05/20/2022 19:08:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.90 on epoch=604
05/20/2022 19:08:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.01 on epoch=607
05/20/2022 19:08:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
05/20/2022 19:08:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.93 on epoch=612
05/20/2022 19:08:22 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.2440667318162781 on epoch=612
05/20/2022 19:08:22 - INFO - __main__ - Saving model with best Classification-F1: 0.22426438296003515 -> 0.2440667318162781 on epoch=612, global_step=2450
05/20/2022 19:08:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.85 on epoch=614
05/20/2022 19:08:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.92 on epoch=617
05/20/2022 19:08:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/20/2022 19:08:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
05/20/2022 19:08:29 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/20/2022 19:08:30 - INFO - __main__ - Global step 2500 Train loss 0.94 Classification-F1 0.1 on epoch=624
05/20/2022 19:08:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/20/2022 19:08:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.96 on epoch=629
05/20/2022 19:08:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
05/20/2022 19:08:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
05/20/2022 19:08:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.96 on epoch=637
05/20/2022 19:08:37 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.17893217893217894 on epoch=637
05/20/2022 19:08:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.84 on epoch=639
05/20/2022 19:08:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
05/20/2022 19:08:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.05 on epoch=644
05/20/2022 19:08:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.02 on epoch=647
05/20/2022 19:08:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.96 on epoch=649
05/20/2022 19:08:44 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.10666666666666667 on epoch=649
05/20/2022 19:08:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.84 on epoch=652
05/20/2022 19:08:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.86 on epoch=654
05/20/2022 19:08:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/20/2022 19:08:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.98 on epoch=659
05/20/2022 19:08:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.94 on epoch=662
05/20/2022 19:08:51 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.10677083333333333 on epoch=662
05/20/2022 19:08:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.87 on epoch=664
05/20/2022 19:08:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/20/2022 19:08:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/20/2022 19:08:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.92 on epoch=672
05/20/2022 19:08:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=674
05/20/2022 19:08:59 - INFO - __main__ - Global step 2700 Train loss 0.91 Classification-F1 0.1 on epoch=674
05/20/2022 19:09:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/20/2022 19:09:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
05/20/2022 19:09:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
05/20/2022 19:09:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/20/2022 19:09:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/20/2022 19:09:06 - INFO - __main__ - Global step 2750 Train loss 0.91 Classification-F1 0.09333333333333334 on epoch=687
05/20/2022 19:09:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/20/2022 19:09:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/20/2022 19:09:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.96 on epoch=694
05/20/2022 19:09:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
05/20/2022 19:09:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
05/20/2022 19:09:14 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.13167388167388167 on epoch=699
05/20/2022 19:09:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=702
05/20/2022 19:09:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/20/2022 19:09:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
05/20/2022 19:09:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.84 on epoch=709
05/20/2022 19:09:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=712
05/20/2022 19:09:22 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.18276972624798712 on epoch=712
05/20/2022 19:09:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/20/2022 19:09:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.91 on epoch=717
05/20/2022 19:09:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.78 on epoch=719
05/20/2022 19:09:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.86 on epoch=722
05/20/2022 19:09:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.88 on epoch=724
05/20/2022 19:09:29 - INFO - __main__ - Global step 2900 Train loss 0.88 Classification-F1 0.202020202020202 on epoch=724
05/20/2022 19:09:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.90 on epoch=727
05/20/2022 19:09:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.88 on epoch=729
05/20/2022 19:09:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.99 on epoch=732
05/20/2022 19:09:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.88 on epoch=734
05/20/2022 19:09:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
05/20/2022 19:09:36 - INFO - __main__ - Global step 2950 Train loss 0.92 Classification-F1 0.16071428571428573 on epoch=737
05/20/2022 19:09:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.95 on epoch=739
05/20/2022 19:09:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.93 on epoch=742
05/20/2022 19:09:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.86 on epoch=744
05/20/2022 19:09:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/20/2022 19:09:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/20/2022 19:09:44 - INFO - __main__ - Global step 3000 Train loss 0.93 Classification-F1 0.21354166666666669 on epoch=749
05/20/2022 19:09:44 - INFO - __main__ - save last model!
05/20/2022 19:09:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 19:09:44 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 19:09:44 - INFO - __main__ - Printing 3 examples
05/20/2022 19:09:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 19:09:44 - INFO - __main__ - ['others']
05/20/2022 19:09:44 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 19:09:44 - INFO - __main__ - ['others']
05/20/2022 19:09:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 19:09:44 - INFO - __main__ - ['others']
05/20/2022 19:09:44 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:09:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:09:45 - INFO - __main__ - Printing 3 examples
05/20/2022 19:09:45 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:09:45 - INFO - __main__ - ['others']
05/20/2022 19:09:45 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:09:45 - INFO - __main__ - ['others']
05/20/2022 19:09:45 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:09:45 - INFO - __main__ - ['others']
05/20/2022 19:09:45 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:09:45 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:09:45 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:09:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:09:45 - INFO - __main__ - Printing 3 examples
05/20/2022 19:09:45 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:09:45 - INFO - __main__ - ['others']
05/20/2022 19:09:45 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:09:45 - INFO - __main__ - ['others']
05/20/2022 19:09:45 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:09:45 - INFO - __main__ - ['others']
05/20/2022 19:09:45 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:09:45 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:09:45 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:09:47 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:09:51 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:09:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:09:51 - INFO - __main__ - Starting training!
05/20/2022 19:09:54 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 19:10:40 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.5_8_predictions.txt
05/20/2022 19:10:40 - INFO - __main__ - Classification-F1 on test data: 0.0580
05/20/2022 19:10:40 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.2440667318162781, test_performance=0.057998635256980235
05/20/2022 19:10:40 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
05/20/2022 19:10:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:10:41 - INFO - __main__ - Printing 3 examples
05/20/2022 19:10:41 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:10:41 - INFO - __main__ - ['others']
05/20/2022 19:10:41 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:10:41 - INFO - __main__ - ['others']
05/20/2022 19:10:41 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:10:41 - INFO - __main__ - ['others']
05/20/2022 19:10:41 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:10:41 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:10:41 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:10:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:10:41 - INFO - __main__ - Printing 3 examples
05/20/2022 19:10:41 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:10:41 - INFO - __main__ - ['others']
05/20/2022 19:10:41 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:10:41 - INFO - __main__ - ['others']
05/20/2022 19:10:41 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:10:41 - INFO - __main__ - ['others']
05/20/2022 19:10:41 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:10:41 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:10:41 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:10:47 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:10:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:10:47 - INFO - __main__ - Starting training!
05/20/2022 19:10:51 - INFO - __main__ - Step 10 Global step 10 Train loss 6.82 on epoch=2
05/20/2022 19:10:52 - INFO - __main__ - Step 20 Global step 20 Train loss 6.60 on epoch=4
05/20/2022 19:10:53 - INFO - __main__ - Step 30 Global step 30 Train loss 6.18 on epoch=7
05/20/2022 19:10:55 - INFO - __main__ - Step 40 Global step 40 Train loss 6.08 on epoch=9
05/20/2022 19:10:56 - INFO - __main__ - Step 50 Global step 50 Train loss 5.78 on epoch=12
05/20/2022 19:10:57 - INFO - __main__ - Global step 50 Train loss 6.29 Classification-F1 0.0 on epoch=12
05/20/2022 19:10:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 19:10:59 - INFO - __main__ - Step 60 Global step 60 Train loss 5.61 on epoch=14
05/20/2022 19:11:00 - INFO - __main__ - Step 70 Global step 70 Train loss 5.57 on epoch=17
05/20/2022 19:11:02 - INFO - __main__ - Step 80 Global step 80 Train loss 5.11 on epoch=19
05/20/2022 19:11:03 - INFO - __main__ - Step 90 Global step 90 Train loss 5.12 on epoch=22
05/20/2022 19:11:04 - INFO - __main__ - Step 100 Global step 100 Train loss 4.93 on epoch=24
05/20/2022 19:11:06 - INFO - __main__ - Global step 100 Train loss 5.27 Classification-F1 0.0 on epoch=24
05/20/2022 19:11:07 - INFO - __main__ - Step 110 Global step 110 Train loss 4.90 on epoch=27
05/20/2022 19:11:08 - INFO - __main__ - Step 120 Global step 120 Train loss 4.72 on epoch=29
05/20/2022 19:11:10 - INFO - __main__ - Step 130 Global step 130 Train loss 4.67 on epoch=32
05/20/2022 19:11:11 - INFO - __main__ - Step 140 Global step 140 Train loss 4.26 on epoch=34
05/20/2022 19:11:12 - INFO - __main__ - Step 150 Global step 150 Train loss 4.33 on epoch=37
05/20/2022 19:11:13 - INFO - __main__ - Global step 150 Train loss 4.58 Classification-F1 0.1 on epoch=37
05/20/2022 19:11:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.1 on epoch=37, global_step=150
05/20/2022 19:11:14 - INFO - __main__ - Step 160 Global step 160 Train loss 4.06 on epoch=39
05/20/2022 19:11:16 - INFO - __main__ - Step 170 Global step 170 Train loss 4.02 on epoch=42
05/20/2022 19:11:17 - INFO - __main__ - Step 180 Global step 180 Train loss 3.65 on epoch=44
05/20/2022 19:11:18 - INFO - __main__ - Step 190 Global step 190 Train loss 3.83 on epoch=47
05/20/2022 19:11:20 - INFO - __main__ - Step 200 Global step 200 Train loss 3.45 on epoch=49
05/20/2022 19:11:20 - INFO - __main__ - Global step 200 Train loss 3.80 Classification-F1 0.1778115501519757 on epoch=49
05/20/2022 19:11:20 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1778115501519757 on epoch=49, global_step=200
05/20/2022 19:11:22 - INFO - __main__ - Step 210 Global step 210 Train loss 3.38 on epoch=52
05/20/2022 19:11:23 - INFO - __main__ - Step 220 Global step 220 Train loss 3.39 on epoch=54
05/20/2022 19:11:25 - INFO - __main__ - Step 230 Global step 230 Train loss 3.31 on epoch=57
05/20/2022 19:11:26 - INFO - __main__ - Step 240 Global step 240 Train loss 3.15 on epoch=59
05/20/2022 19:11:27 - INFO - __main__ - Step 250 Global step 250 Train loss 3.27 on epoch=62
05/20/2022 19:11:28 - INFO - __main__ - Global step 250 Train loss 3.30 Classification-F1 0.09154929577464789 on epoch=62
05/20/2022 19:11:29 - INFO - __main__ - Step 260 Global step 260 Train loss 2.91 on epoch=64
05/20/2022 19:11:31 - INFO - __main__ - Step 270 Global step 270 Train loss 2.81 on epoch=67
05/20/2022 19:11:32 - INFO - __main__ - Step 280 Global step 280 Train loss 2.67 on epoch=69
05/20/2022 19:11:34 - INFO - __main__ - Step 290 Global step 290 Train loss 2.74 on epoch=72
05/20/2022 19:11:35 - INFO - __main__ - Step 300 Global step 300 Train loss 2.58 on epoch=74
05/20/2022 19:11:36 - INFO - __main__ - Global step 300 Train loss 2.74 Classification-F1 0.13123993558776167 on epoch=74
05/20/2022 19:11:37 - INFO - __main__ - Step 310 Global step 310 Train loss 2.78 on epoch=77
05/20/2022 19:11:39 - INFO - __main__ - Step 320 Global step 320 Train loss 2.45 on epoch=79
05/20/2022 19:11:40 - INFO - __main__ - Step 330 Global step 330 Train loss 2.46 on epoch=82
05/20/2022 19:11:42 - INFO - __main__ - Step 340 Global step 340 Train loss 2.44 on epoch=84
05/20/2022 19:11:43 - INFO - __main__ - Step 350 Global step 350 Train loss 2.39 on epoch=87
05/20/2022 19:11:44 - INFO - __main__ - Global step 350 Train loss 2.50 Classification-F1 0.14509803921568626 on epoch=87
05/20/2022 19:11:45 - INFO - __main__ - Step 360 Global step 360 Train loss 2.24 on epoch=89
05/20/2022 19:11:47 - INFO - __main__ - Step 370 Global step 370 Train loss 2.31 on epoch=92
05/20/2022 19:11:48 - INFO - __main__ - Step 380 Global step 380 Train loss 2.29 on epoch=94
05/20/2022 19:11:50 - INFO - __main__ - Step 390 Global step 390 Train loss 2.29 on epoch=97
05/20/2022 19:11:51 - INFO - __main__ - Step 400 Global step 400 Train loss 2.15 on epoch=99
05/20/2022 19:11:51 - INFO - __main__ - Global step 400 Train loss 2.26 Classification-F1 0.1486842105263158 on epoch=99
05/20/2022 19:11:53 - INFO - __main__ - Step 410 Global step 410 Train loss 2.10 on epoch=102
05/20/2022 19:11:54 - INFO - __main__ - Step 420 Global step 420 Train loss 2.10 on epoch=104
05/20/2022 19:11:56 - INFO - __main__ - Step 430 Global step 430 Train loss 2.00 on epoch=107
05/20/2022 19:11:57 - INFO - __main__ - Step 440 Global step 440 Train loss 1.97 on epoch=109
05/20/2022 19:11:58 - INFO - __main__ - Step 450 Global step 450 Train loss 2.04 on epoch=112
05/20/2022 19:11:59 - INFO - __main__ - Global step 450 Train loss 2.04 Classification-F1 0.1 on epoch=112
05/20/2022 19:12:00 - INFO - __main__ - Step 460 Global step 460 Train loss 2.01 on epoch=114
05/20/2022 19:12:02 - INFO - __main__ - Step 470 Global step 470 Train loss 1.99 on epoch=117
05/20/2022 19:12:03 - INFO - __main__ - Step 480 Global step 480 Train loss 1.97 on epoch=119
05/20/2022 19:12:04 - INFO - __main__ - Step 490 Global step 490 Train loss 1.92 on epoch=122
05/20/2022 19:12:06 - INFO - __main__ - Step 500 Global step 500 Train loss 1.84 on epoch=124
05/20/2022 19:12:06 - INFO - __main__ - Global step 500 Train loss 1.95 Classification-F1 0.1 on epoch=124
05/20/2022 19:12:08 - INFO - __main__ - Step 510 Global step 510 Train loss 1.93 on epoch=127
05/20/2022 19:12:09 - INFO - __main__ - Step 520 Global step 520 Train loss 1.64 on epoch=129
05/20/2022 19:12:10 - INFO - __main__ - Step 530 Global step 530 Train loss 1.88 on epoch=132
05/20/2022 19:12:12 - INFO - __main__ - Step 540 Global step 540 Train loss 1.63 on epoch=134
05/20/2022 19:12:13 - INFO - __main__ - Step 550 Global step 550 Train loss 1.72 on epoch=137
05/20/2022 19:12:14 - INFO - __main__ - Global step 550 Train loss 1.76 Classification-F1 0.1 on epoch=137
05/20/2022 19:12:15 - INFO - __main__ - Step 560 Global step 560 Train loss 1.75 on epoch=139
05/20/2022 19:12:16 - INFO - __main__ - Step 570 Global step 570 Train loss 1.79 on epoch=142
05/20/2022 19:12:18 - INFO - __main__ - Step 580 Global step 580 Train loss 1.78 on epoch=144
05/20/2022 19:12:19 - INFO - __main__ - Step 590 Global step 590 Train loss 1.65 on epoch=147
05/20/2022 19:12:21 - INFO - __main__ - Step 600 Global step 600 Train loss 1.59 on epoch=149
05/20/2022 19:12:21 - INFO - __main__ - Global step 600 Train loss 1.71 Classification-F1 0.15782608695652173 on epoch=149
05/20/2022 19:12:23 - INFO - __main__ - Step 610 Global step 610 Train loss 1.63 on epoch=152
05/20/2022 19:12:24 - INFO - __main__ - Step 620 Global step 620 Train loss 1.61 on epoch=154
05/20/2022 19:12:25 - INFO - __main__ - Step 630 Global step 630 Train loss 1.57 on epoch=157
05/20/2022 19:12:27 - INFO - __main__ - Step 640 Global step 640 Train loss 1.60 on epoch=159
05/20/2022 19:12:28 - INFO - __main__ - Step 650 Global step 650 Train loss 1.53 on epoch=162
05/20/2022 19:12:29 - INFO - __main__ - Global step 650 Train loss 1.59 Classification-F1 0.13067758749069247 on epoch=162
05/20/2022 19:12:30 - INFO - __main__ - Step 660 Global step 660 Train loss 1.48 on epoch=164
05/20/2022 19:12:31 - INFO - __main__ - Step 670 Global step 670 Train loss 1.57 on epoch=167
05/20/2022 19:12:33 - INFO - __main__ - Step 680 Global step 680 Train loss 1.46 on epoch=169
05/20/2022 19:12:34 - INFO - __main__ - Step 690 Global step 690 Train loss 1.50 on epoch=172
05/20/2022 19:12:35 - INFO - __main__ - Step 700 Global step 700 Train loss 1.30 on epoch=174
05/20/2022 19:12:36 - INFO - __main__ - Global step 700 Train loss 1.46 Classification-F1 0.1 on epoch=174
05/20/2022 19:12:37 - INFO - __main__ - Step 710 Global step 710 Train loss 1.37 on epoch=177
05/20/2022 19:12:39 - INFO - __main__ - Step 720 Global step 720 Train loss 1.31 on epoch=179
05/20/2022 19:12:40 - INFO - __main__ - Step 730 Global step 730 Train loss 1.37 on epoch=182
05/20/2022 19:12:42 - INFO - __main__ - Step 740 Global step 740 Train loss 1.35 on epoch=184
05/20/2022 19:12:43 - INFO - __main__ - Step 750 Global step 750 Train loss 1.47 on epoch=187
05/20/2022 19:12:44 - INFO - __main__ - Global step 750 Train loss 1.38 Classification-F1 0.1 on epoch=187
05/20/2022 19:12:45 - INFO - __main__ - Step 760 Global step 760 Train loss 1.32 on epoch=189
05/20/2022 19:12:47 - INFO - __main__ - Step 770 Global step 770 Train loss 1.41 on epoch=192
05/20/2022 19:12:48 - INFO - __main__ - Step 780 Global step 780 Train loss 1.34 on epoch=194
05/20/2022 19:12:49 - INFO - __main__ - Step 790 Global step 790 Train loss 1.43 on epoch=197
05/20/2022 19:12:51 - INFO - __main__ - Step 800 Global step 800 Train loss 1.29 on epoch=199
05/20/2022 19:12:51 - INFO - __main__ - Global step 800 Train loss 1.36 Classification-F1 0.1 on epoch=199
05/20/2022 19:12:53 - INFO - __main__ - Step 810 Global step 810 Train loss 1.31 on epoch=202
05/20/2022 19:12:54 - INFO - __main__ - Step 820 Global step 820 Train loss 1.37 on epoch=204
05/20/2022 19:12:56 - INFO - __main__ - Step 830 Global step 830 Train loss 1.23 on epoch=207
05/20/2022 19:12:57 - INFO - __main__ - Step 840 Global step 840 Train loss 1.31 on epoch=209
05/20/2022 19:12:58 - INFO - __main__ - Step 850 Global step 850 Train loss 1.20 on epoch=212
05/20/2022 19:12:59 - INFO - __main__ - Global step 850 Train loss 1.28 Classification-F1 0.1 on epoch=212
05/20/2022 19:13:00 - INFO - __main__ - Step 860 Global step 860 Train loss 1.19 on epoch=214
05/20/2022 19:13:02 - INFO - __main__ - Step 870 Global step 870 Train loss 1.11 on epoch=217
05/20/2022 19:13:03 - INFO - __main__ - Step 880 Global step 880 Train loss 1.09 on epoch=219
05/20/2022 19:13:04 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
05/20/2022 19:13:06 - INFO - __main__ - Step 900 Global step 900 Train loss 1.23 on epoch=224
05/20/2022 19:13:06 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.1 on epoch=224
05/20/2022 19:13:08 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/20/2022 19:13:09 - INFO - __main__ - Step 920 Global step 920 Train loss 1.14 on epoch=229
05/20/2022 19:13:10 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=232
05/20/2022 19:13:12 - INFO - __main__ - Step 940 Global step 940 Train loss 1.13 on epoch=234
05/20/2022 19:13:13 - INFO - __main__ - Step 950 Global step 950 Train loss 1.12 on epoch=237
05/20/2022 19:13:14 - INFO - __main__ - Global step 950 Train loss 1.17 Classification-F1 0.1 on epoch=237
05/20/2022 19:13:15 - INFO - __main__ - Step 960 Global step 960 Train loss 1.27 on epoch=239
05/20/2022 19:13:17 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=242
05/20/2022 19:13:18 - INFO - __main__ - Step 980 Global step 980 Train loss 1.14 on epoch=244
05/20/2022 19:13:19 - INFO - __main__ - Step 990 Global step 990 Train loss 1.21 on epoch=247
05/20/2022 19:13:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.22 on epoch=249
05/20/2022 19:13:21 - INFO - __main__ - Global step 1000 Train loss 1.20 Classification-F1 0.1 on epoch=249
05/20/2022 19:13:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.10 on epoch=252
05/20/2022 19:13:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.98 on epoch=254
05/20/2022 19:13:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.29 on epoch=257
05/20/2022 19:13:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.19 on epoch=259
05/20/2022 19:13:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.20 on epoch=262
05/20/2022 19:13:29 - INFO - __main__ - Global step 1050 Train loss 1.15 Classification-F1 0.09493670886075949 on epoch=262
05/20/2022 19:13:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.09 on epoch=264
05/20/2022 19:13:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.00 on epoch=267
05/20/2022 19:13:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.06 on epoch=269
05/20/2022 19:13:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.22 on epoch=272
05/20/2022 19:13:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.98 on epoch=274
05/20/2022 19:13:36 - INFO - __main__ - Global step 1100 Train loss 1.07 Classification-F1 0.1 on epoch=274
05/20/2022 19:13:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.04 on epoch=277
05/20/2022 19:13:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.08 on epoch=279
05/20/2022 19:13:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.04 on epoch=282
05/20/2022 19:13:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.08 on epoch=284
05/20/2022 19:13:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.02 on epoch=287
05/20/2022 19:13:44 - INFO - __main__ - Global step 1150 Train loss 1.05 Classification-F1 0.1 on epoch=287
05/20/2022 19:13:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.07 on epoch=289
05/20/2022 19:13:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.14 on epoch=292
05/20/2022 19:13:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.10 on epoch=294
05/20/2022 19:13:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.07 on epoch=297
05/20/2022 19:13:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.07 on epoch=299
05/20/2022 19:13:51 - INFO - __main__ - Global step 1200 Train loss 1.09 Classification-F1 0.1 on epoch=299
05/20/2022 19:13:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
05/20/2022 19:13:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.91 on epoch=304
05/20/2022 19:13:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.10 on epoch=307
05/20/2022 19:13:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/20/2022 19:13:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
05/20/2022 19:13:59 - INFO - __main__ - Global step 1250 Train loss 1.09 Classification-F1 0.1 on epoch=312
05/20/2022 19:14:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=314
05/20/2022 19:14:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.07 on epoch=317
05/20/2022 19:14:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.01 on epoch=319
05/20/2022 19:14:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.94 on epoch=322
05/20/2022 19:14:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.99 on epoch=324
05/20/2022 19:14:06 - INFO - __main__ - Global step 1300 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=324
05/20/2022 19:14:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.12 on epoch=327
05/20/2022 19:14:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.96 on epoch=329
05/20/2022 19:14:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.05 on epoch=332
05/20/2022 19:14:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.02 on epoch=334
05/20/2022 19:14:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.11 on epoch=337
05/20/2022 19:14:14 - INFO - __main__ - Global step 1350 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=337
05/20/2022 19:14:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.06 on epoch=339
05/20/2022 19:14:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/20/2022 19:14:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.99 on epoch=344
05/20/2022 19:14:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.12 on epoch=347
05/20/2022 19:14:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
05/20/2022 19:14:21 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.15441176470588236 on epoch=349
05/20/2022 19:14:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.03 on epoch=352
05/20/2022 19:14:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/20/2022 19:14:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.99 on epoch=357
05/20/2022 19:14:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.93 on epoch=359
05/20/2022 19:14:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.02 on epoch=362
05/20/2022 19:14:29 - INFO - __main__ - Global step 1450 Train loss 1.00 Classification-F1 0.1 on epoch=362
05/20/2022 19:14:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.05 on epoch=364
05/20/2022 19:14:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.99 on epoch=367
05/20/2022 19:14:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.11 on epoch=369
05/20/2022 19:14:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.04 on epoch=372
05/20/2022 19:14:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.04 on epoch=374
05/20/2022 19:14:36 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=374
05/20/2022 19:14:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.00 on epoch=377
05/20/2022 19:14:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.01 on epoch=379
05/20/2022 19:14:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.91 on epoch=382
05/20/2022 19:14:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
05/20/2022 19:14:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.95 on epoch=387
05/20/2022 19:14:43 - INFO - __main__ - Global step 1550 Train loss 0.99 Classification-F1 0.1 on epoch=387
05/20/2022 19:14:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.03 on epoch=389
05/20/2022 19:14:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.00 on epoch=392
05/20/2022 19:14:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.97 on epoch=394
05/20/2022 19:14:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.04 on epoch=397
05/20/2022 19:14:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
05/20/2022 19:14:51 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.1302118933697881 on epoch=399
05/20/2022 19:14:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.01 on epoch=402
05/20/2022 19:14:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/20/2022 19:14:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.04 on epoch=407
05/20/2022 19:14:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.99 on epoch=409
05/20/2022 19:14:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.09 on epoch=412
05/20/2022 19:14:58 - INFO - __main__ - Global step 1650 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=412
05/20/2022 19:15:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.08 on epoch=414
05/20/2022 19:15:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.04 on epoch=417
05/20/2022 19:15:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
05/20/2022 19:15:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.03 on epoch=422
05/20/2022 19:15:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=424
05/20/2022 19:15:06 - INFO - __main__ - Global step 1700 Train loss 1.05 Classification-F1 0.2120826259196378 on epoch=424
05/20/2022 19:15:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1778115501519757 -> 0.2120826259196378 on epoch=424, global_step=1700
05/20/2022 19:15:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.96 on epoch=427
05/20/2022 19:15:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/20/2022 19:15:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.90 on epoch=432
05/20/2022 19:15:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.05 on epoch=434
05/20/2022 19:15:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.91 on epoch=437
05/20/2022 19:15:14 - INFO - __main__ - Global step 1750 Train loss 0.97 Classification-F1 0.1850282485875706 on epoch=437
05/20/2022 19:15:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=439
05/20/2022 19:15:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.98 on epoch=442
05/20/2022 19:15:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/20/2022 19:15:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.99 on epoch=447
05/20/2022 19:15:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.01 on epoch=449
05/20/2022 19:15:21 - INFO - __main__ - Global step 1800 Train loss 0.98 Classification-F1 0.13904109589041097 on epoch=449
05/20/2022 19:15:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/20/2022 19:15:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
05/20/2022 19:15:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.99 on epoch=457
05/20/2022 19:15:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.98 on epoch=459
05/20/2022 19:15:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=462
05/20/2022 19:15:29 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.10869565217391305 on epoch=462
05/20/2022 19:15:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.06 on epoch=464
05/20/2022 19:15:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.02 on epoch=467
05/20/2022 19:15:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.02 on epoch=469
05/20/2022 19:15:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.10 on epoch=472
05/20/2022 19:15:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.98 on epoch=474
05/20/2022 19:15:38 - INFO - __main__ - Global step 1900 Train loss 1.03 Classification-F1 0.09493670886075949 on epoch=474
05/20/2022 19:15:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
05/20/2022 19:15:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
05/20/2022 19:15:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.00 on epoch=482
05/20/2022 19:15:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/20/2022 19:15:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.92 on epoch=487
05/20/2022 19:15:46 - INFO - __main__ - Global step 1950 Train loss 0.96 Classification-F1 0.09090909090909091 on epoch=487
05/20/2022 19:15:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.83 on epoch=489
05/20/2022 19:15:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/20/2022 19:15:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.98 on epoch=494
05/20/2022 19:15:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.98 on epoch=497
05/20/2022 19:15:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.93 on epoch=499
05/20/2022 19:15:54 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.0945945945945946 on epoch=499
05/20/2022 19:15:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.93 on epoch=502
05/20/2022 19:15:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.95 on epoch=504
05/20/2022 19:15:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.95 on epoch=507
05/20/2022 19:15:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.04 on epoch=509
05/20/2022 19:16:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.87 on epoch=512
05/20/2022 19:16:01 - INFO - __main__ - Global step 2050 Train loss 0.95 Classification-F1 0.15555555555555556 on epoch=512
05/20/2022 19:16:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=514
05/20/2022 19:16:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.90 on epoch=517
05/20/2022 19:16:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.97 on epoch=519
05/20/2022 19:16:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
05/20/2022 19:16:08 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.91 on epoch=524
05/20/2022 19:16:09 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.10380835380835382 on epoch=524
05/20/2022 19:16:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.00 on epoch=527
05/20/2022 19:16:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.03 on epoch=529
05/20/2022 19:16:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/20/2022 19:16:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.87 on epoch=534
05/20/2022 19:16:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.86 on epoch=537
05/20/2022 19:16:16 - INFO - __main__ - Global step 2150 Train loss 0.95 Classification-F1 0.1 on epoch=537
05/20/2022 19:16:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.79 on epoch=539
05/20/2022 19:16:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.96 on epoch=542
05/20/2022 19:16:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.95 on epoch=544
05/20/2022 19:16:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.95 on epoch=547
05/20/2022 19:16:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=549
05/20/2022 19:16:24 - INFO - __main__ - Global step 2200 Train loss 0.91 Classification-F1 0.1388888888888889 on epoch=549
05/20/2022 19:16:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.97 on epoch=552
05/20/2022 19:16:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.87 on epoch=554
05/20/2022 19:16:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.94 on epoch=557
05/20/2022 19:16:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/20/2022 19:16:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
05/20/2022 19:16:32 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.09615384615384615 on epoch=562
05/20/2022 19:16:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.88 on epoch=564
05/20/2022 19:16:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
05/20/2022 19:16:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.96 on epoch=569
05/20/2022 19:16:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
05/20/2022 19:16:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.93 on epoch=574
05/20/2022 19:16:39 - INFO - __main__ - Global step 2300 Train loss 0.94 Classification-F1 0.1503587736464449 on epoch=574
05/20/2022 19:16:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.94 on epoch=577
05/20/2022 19:16:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/20/2022 19:16:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.94 on epoch=582
05/20/2022 19:16:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.89 on epoch=584
05/20/2022 19:16:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.90 on epoch=587
05/20/2022 19:16:46 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.09493670886075949 on epoch=587
05/20/2022 19:16:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.03 on epoch=589
05/20/2022 19:16:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.91 on epoch=592
05/20/2022 19:16:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.89 on epoch=594
05/20/2022 19:16:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
05/20/2022 19:16:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.81 on epoch=599
05/20/2022 19:16:54 - INFO - __main__ - Global step 2400 Train loss 0.92 Classification-F1 0.1 on epoch=599
05/20/2022 19:16:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
05/20/2022 19:16:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/20/2022 19:16:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.92 on epoch=607
05/20/2022 19:16:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.93 on epoch=609
05/20/2022 19:17:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
05/20/2022 19:17:01 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1 on epoch=612
05/20/2022 19:17:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.86 on epoch=614
05/20/2022 19:17:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.91 on epoch=617
05/20/2022 19:17:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.97 on epoch=619
05/20/2022 19:17:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/20/2022 19:17:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/20/2022 19:17:09 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.14095238095238094 on epoch=624
05/20/2022 19:17:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.94 on epoch=627
05/20/2022 19:17:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.95 on epoch=629
05/20/2022 19:17:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=632
05/20/2022 19:17:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/20/2022 19:17:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/20/2022 19:17:16 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.0974025974025974 on epoch=637
05/20/2022 19:17:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
05/20/2022 19:17:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.88 on epoch=642
05/20/2022 19:17:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.96 on epoch=644
05/20/2022 19:17:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.90 on epoch=647
05/20/2022 19:17:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.01 on epoch=649
05/20/2022 19:17:24 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.10126582278481013 on epoch=649
05/20/2022 19:17:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/20/2022 19:17:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/20/2022 19:17:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.99 on epoch=657
05/20/2022 19:17:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
05/20/2022 19:17:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.98 on epoch=662
05/20/2022 19:17:31 - INFO - __main__ - Global step 2650 Train loss 0.96 Classification-F1 0.11710526315789474 on epoch=662
05/20/2022 19:17:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.91 on epoch=664
05/20/2022 19:17:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
05/20/2022 19:17:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=669
05/20/2022 19:17:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=672
05/20/2022 19:17:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.89 on epoch=674
05/20/2022 19:17:39 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.14095238095238094 on epoch=674
05/20/2022 19:17:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.94 on epoch=677
05/20/2022 19:17:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
05/20/2022 19:17:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
05/20/2022 19:17:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.88 on epoch=684
05/20/2022 19:17:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.87 on epoch=687
05/20/2022 19:17:46 - INFO - __main__ - Global step 2750 Train loss 0.89 Classification-F1 0.1 on epoch=687
05/20/2022 19:17:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
05/20/2022 19:17:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
05/20/2022 19:17:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/20/2022 19:17:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
05/20/2022 19:17:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.87 on epoch=699
05/20/2022 19:17:54 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.10256410256410256 on epoch=699
05/20/2022 19:17:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.85 on epoch=702
05/20/2022 19:17:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
05/20/2022 19:17:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.87 on epoch=707
05/20/2022 19:18:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/20/2022 19:18:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
05/20/2022 19:18:02 - INFO - __main__ - Global step 2850 Train loss 0.90 Classification-F1 0.1 on epoch=712
05/20/2022 19:18:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.94 on epoch=714
05/20/2022 19:18:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.03 on epoch=717
05/20/2022 19:18:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/20/2022 19:18:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
05/20/2022 19:18:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.93 on epoch=724
05/20/2022 19:18:09 - INFO - __main__ - Global step 2900 Train loss 0.95 Classification-F1 0.11722488038277512 on epoch=724
05/20/2022 19:18:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.88 on epoch=727
05/20/2022 19:18:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/20/2022 19:18:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.87 on epoch=732
05/20/2022 19:18:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.89 on epoch=734
05/20/2022 19:18:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.82 on epoch=737
05/20/2022 19:18:16 - INFO - __main__ - Global step 2950 Train loss 0.88 Classification-F1 0.1565276828434723 on epoch=737
05/20/2022 19:18:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.88 on epoch=739
05/20/2022 19:18:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.88 on epoch=742
05/20/2022 19:18:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.93 on epoch=744
05/20/2022 19:18:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.88 on epoch=747
05/20/2022 19:18:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
05/20/2022 19:18:24 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.1 on epoch=749
05/20/2022 19:18:24 - INFO - __main__ - save last model!
05/20/2022 19:18:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 19:18:24 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 19:18:24 - INFO - __main__ - Printing 3 examples
05/20/2022 19:18:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 19:18:24 - INFO - __main__ - ['others']
05/20/2022 19:18:24 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 19:18:24 - INFO - __main__ - ['others']
05/20/2022 19:18:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 19:18:24 - INFO - __main__ - ['others']
05/20/2022 19:18:24 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:18:25 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:18:25 - INFO - __main__ - Printing 3 examples
05/20/2022 19:18:25 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:18:25 - INFO - __main__ - ['others']
05/20/2022 19:18:25 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:18:25 - INFO - __main__ - ['others']
05/20/2022 19:18:25 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:18:25 - INFO - __main__ - ['others']
05/20/2022 19:18:25 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:18:25 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:18:25 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:18:25 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:18:25 - INFO - __main__ - Printing 3 examples
05/20/2022 19:18:25 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:18:25 - INFO - __main__ - ['others']
05/20/2022 19:18:25 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:18:25 - INFO - __main__ - ['others']
05/20/2022 19:18:25 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:18:25 - INFO - __main__ - ['others']
05/20/2022 19:18:25 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:18:25 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:18:25 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:18:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:18:31 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:18:31 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 19:18:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:18:32 - INFO - __main__ - Starting training!
05/20/2022 19:19:14 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.4_8_predictions.txt
05/20/2022 19:19:14 - INFO - __main__ - Classification-F1 on test data: 0.0276
05/20/2022 19:19:14 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.2120826259196378, test_performance=0.027648234964029166
05/20/2022 19:19:14 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
05/20/2022 19:19:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:19:15 - INFO - __main__ - Printing 3 examples
05/20/2022 19:19:15 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:19:15 - INFO - __main__ - ['others']
05/20/2022 19:19:15 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:19:15 - INFO - __main__ - ['others']
05/20/2022 19:19:15 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:19:15 - INFO - __main__ - ['others']
05/20/2022 19:19:15 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:19:15 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:19:15 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:19:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:19:15 - INFO - __main__ - Printing 3 examples
05/20/2022 19:19:15 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:19:15 - INFO - __main__ - ['others']
05/20/2022 19:19:15 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:19:15 - INFO - __main__ - ['others']
05/20/2022 19:19:15 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:19:15 - INFO - __main__ - ['others']
05/20/2022 19:19:15 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:19:15 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:19:15 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:19:21 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:19:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:19:21 - INFO - __main__ - Starting training!
05/20/2022 19:19:23 - INFO - __main__ - Step 10 Global step 10 Train loss 6.65 on epoch=2
05/20/2022 19:19:24 - INFO - __main__ - Step 20 Global step 20 Train loss 6.64 on epoch=4
05/20/2022 19:19:25 - INFO - __main__ - Step 30 Global step 30 Train loss 6.49 on epoch=7
05/20/2022 19:19:27 - INFO - __main__ - Step 40 Global step 40 Train loss 6.36 on epoch=9
05/20/2022 19:19:28 - INFO - __main__ - Step 50 Global step 50 Train loss 6.12 on epoch=12
05/20/2022 19:19:32 - INFO - __main__ - Global step 50 Train loss 6.45 Classification-F1 0.0 on epoch=12
05/20/2022 19:19:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 19:19:33 - INFO - __main__ - Step 60 Global step 60 Train loss 6.00 on epoch=14
05/20/2022 19:19:34 - INFO - __main__ - Step 70 Global step 70 Train loss 5.87 on epoch=17
05/20/2022 19:19:36 - INFO - __main__ - Step 80 Global step 80 Train loss 5.81 on epoch=19
05/20/2022 19:19:37 - INFO - __main__ - Step 90 Global step 90 Train loss 5.79 on epoch=22
05/20/2022 19:19:38 - INFO - __main__ - Step 100 Global step 100 Train loss 5.52 on epoch=24
05/20/2022 19:19:41 - INFO - __main__ - Global step 100 Train loss 5.79 Classification-F1 0.0 on epoch=24
05/20/2022 19:19:42 - INFO - __main__ - Step 110 Global step 110 Train loss 5.57 on epoch=27
05/20/2022 19:19:43 - INFO - __main__ - Step 120 Global step 120 Train loss 5.34 on epoch=29
05/20/2022 19:19:45 - INFO - __main__ - Step 130 Global step 130 Train loss 5.23 on epoch=32
05/20/2022 19:19:46 - INFO - __main__ - Step 140 Global step 140 Train loss 5.11 on epoch=34
05/20/2022 19:19:47 - INFO - __main__ - Step 150 Global step 150 Train loss 4.98 on epoch=37
05/20/2022 19:19:49 - INFO - __main__ - Global step 150 Train loss 5.25 Classification-F1 0.0 on epoch=37
05/20/2022 19:19:51 - INFO - __main__ - Step 160 Global step 160 Train loss 4.78 on epoch=39
05/20/2022 19:19:52 - INFO - __main__ - Step 170 Global step 170 Train loss 4.76 on epoch=42
05/20/2022 19:19:53 - INFO - __main__ - Step 180 Global step 180 Train loss 4.63 on epoch=44
05/20/2022 19:19:55 - INFO - __main__ - Step 190 Global step 190 Train loss 4.63 on epoch=47
05/20/2022 19:19:56 - INFO - __main__ - Step 200 Global step 200 Train loss 4.50 on epoch=49
05/20/2022 19:19:57 - INFO - __main__ - Global step 200 Train loss 4.66 Classification-F1 0.1 on epoch=49
05/20/2022 19:19:57 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.1 on epoch=49, global_step=200
05/20/2022 19:19:58 - INFO - __main__ - Step 210 Global step 210 Train loss 4.33 on epoch=52
05/20/2022 19:20:00 - INFO - __main__ - Step 220 Global step 220 Train loss 4.18 on epoch=54
05/20/2022 19:20:01 - INFO - __main__ - Step 230 Global step 230 Train loss 4.09 on epoch=57
05/20/2022 19:20:02 - INFO - __main__ - Step 240 Global step 240 Train loss 4.11 on epoch=59
05/20/2022 19:20:04 - INFO - __main__ - Step 250 Global step 250 Train loss 3.99 on epoch=62
05/20/2022 19:20:04 - INFO - __main__ - Global step 250 Train loss 4.14 Classification-F1 0.19865392965696915 on epoch=62
05/20/2022 19:20:04 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.19865392965696915 on epoch=62, global_step=250
05/20/2022 19:20:06 - INFO - __main__ - Step 260 Global step 260 Train loss 3.74 on epoch=64
05/20/2022 19:20:07 - INFO - __main__ - Step 270 Global step 270 Train loss 3.61 on epoch=67
05/20/2022 19:20:09 - INFO - __main__ - Step 280 Global step 280 Train loss 3.54 on epoch=69
05/20/2022 19:20:10 - INFO - __main__ - Step 290 Global step 290 Train loss 3.41 on epoch=72
05/20/2022 19:20:11 - INFO - __main__ - Step 300 Global step 300 Train loss 3.35 on epoch=74
05/20/2022 19:20:12 - INFO - __main__ - Global step 300 Train loss 3.53 Classification-F1 0.09126984126984126 on epoch=74
05/20/2022 19:20:13 - INFO - __main__ - Step 310 Global step 310 Train loss 3.38 on epoch=77
05/20/2022 19:20:14 - INFO - __main__ - Step 320 Global step 320 Train loss 3.20 on epoch=79
05/20/2022 19:20:16 - INFO - __main__ - Step 330 Global step 330 Train loss 3.11 on epoch=82
05/20/2022 19:20:17 - INFO - __main__ - Step 340 Global step 340 Train loss 2.97 on epoch=84
05/20/2022 19:20:19 - INFO - __main__ - Step 350 Global step 350 Train loss 3.16 on epoch=87
05/20/2022 19:20:19 - INFO - __main__ - Global step 350 Train loss 3.16 Classification-F1 0.12368421052631579 on epoch=87
05/20/2022 19:20:20 - INFO - __main__ - Step 360 Global step 360 Train loss 2.98 on epoch=89
05/20/2022 19:20:22 - INFO - __main__ - Step 370 Global step 370 Train loss 3.17 on epoch=92
05/20/2022 19:20:23 - INFO - __main__ - Step 380 Global step 380 Train loss 2.83 on epoch=94
05/20/2022 19:20:25 - INFO - __main__ - Step 390 Global step 390 Train loss 2.92 on epoch=97
05/20/2022 19:20:26 - INFO - __main__ - Step 400 Global step 400 Train loss 2.84 on epoch=99
05/20/2022 19:20:27 - INFO - __main__ - Global step 400 Train loss 2.95 Classification-F1 0.1238095238095238 on epoch=99
05/20/2022 19:20:28 - INFO - __main__ - Step 410 Global step 410 Train loss 2.79 on epoch=102
05/20/2022 19:20:29 - INFO - __main__ - Step 420 Global step 420 Train loss 2.67 on epoch=104
05/20/2022 19:20:31 - INFO - __main__ - Step 430 Global step 430 Train loss 2.74 on epoch=107
05/20/2022 19:20:32 - INFO - __main__ - Step 440 Global step 440 Train loss 2.57 on epoch=109
05/20/2022 19:20:33 - INFO - __main__ - Step 450 Global step 450 Train loss 2.61 on epoch=112
05/20/2022 19:20:34 - INFO - __main__ - Global step 450 Train loss 2.68 Classification-F1 0.1 on epoch=112
05/20/2022 19:20:35 - INFO - __main__ - Step 460 Global step 460 Train loss 2.50 on epoch=114
05/20/2022 19:20:37 - INFO - __main__ - Step 470 Global step 470 Train loss 2.54 on epoch=117
05/20/2022 19:20:38 - INFO - __main__ - Step 480 Global step 480 Train loss 2.53 on epoch=119
05/20/2022 19:20:39 - INFO - __main__ - Step 490 Global step 490 Train loss 2.69 on epoch=122
05/20/2022 19:20:41 - INFO - __main__ - Step 500 Global step 500 Train loss 2.50 on epoch=124
05/20/2022 19:20:41 - INFO - __main__ - Global step 500 Train loss 2.55 Classification-F1 0.1 on epoch=124
05/20/2022 19:20:43 - INFO - __main__ - Step 510 Global step 510 Train loss 2.38 on epoch=127
05/20/2022 19:20:44 - INFO - __main__ - Step 520 Global step 520 Train loss 2.27 on epoch=129
05/20/2022 19:20:46 - INFO - __main__ - Step 530 Global step 530 Train loss 2.30 on epoch=132
05/20/2022 19:20:47 - INFO - __main__ - Step 540 Global step 540 Train loss 2.09 on epoch=134
05/20/2022 19:20:48 - INFO - __main__ - Step 550 Global step 550 Train loss 2.21 on epoch=137
05/20/2022 19:20:49 - INFO - __main__ - Global step 550 Train loss 2.25 Classification-F1 0.18284347231715653 on epoch=137
05/20/2022 19:20:50 - INFO - __main__ - Step 560 Global step 560 Train loss 2.14 on epoch=139
05/20/2022 19:20:52 - INFO - __main__ - Step 570 Global step 570 Train loss 2.19 on epoch=142
05/20/2022 19:20:53 - INFO - __main__ - Step 580 Global step 580 Train loss 2.10 on epoch=144
05/20/2022 19:20:54 - INFO - __main__ - Step 590 Global step 590 Train loss 2.08 on epoch=147
05/20/2022 19:20:56 - INFO - __main__ - Step 600 Global step 600 Train loss 1.99 on epoch=149
05/20/2022 19:20:56 - INFO - __main__ - Global step 600 Train loss 2.10 Classification-F1 0.1715492957746479 on epoch=149
05/20/2022 19:20:58 - INFO - __main__ - Step 610 Global step 610 Train loss 2.11 on epoch=152
05/20/2022 19:20:59 - INFO - __main__ - Step 620 Global step 620 Train loss 2.06 on epoch=154
05/20/2022 19:21:00 - INFO - __main__ - Step 630 Global step 630 Train loss 2.03 on epoch=157
05/20/2022 19:21:02 - INFO - __main__ - Step 640 Global step 640 Train loss 1.95 on epoch=159
05/20/2022 19:21:03 - INFO - __main__ - Step 650 Global step 650 Train loss 2.04 on epoch=162
05/20/2022 19:21:04 - INFO - __main__ - Global step 650 Train loss 2.04 Classification-F1 0.11439888164026094 on epoch=162
05/20/2022 19:21:05 - INFO - __main__ - Step 660 Global step 660 Train loss 2.00 on epoch=164
05/20/2022 19:21:07 - INFO - __main__ - Step 670 Global step 670 Train loss 2.06 on epoch=167
05/20/2022 19:21:08 - INFO - __main__ - Step 680 Global step 680 Train loss 1.92 on epoch=169
05/20/2022 19:21:10 - INFO - __main__ - Step 690 Global step 690 Train loss 1.95 on epoch=172
05/20/2022 19:21:11 - INFO - __main__ - Step 700 Global step 700 Train loss 2.01 on epoch=174
05/20/2022 19:21:12 - INFO - __main__ - Global step 700 Train loss 1.99 Classification-F1 0.08658008658008658 on epoch=174
05/20/2022 19:21:13 - INFO - __main__ - Step 710 Global step 710 Train loss 2.13 on epoch=177
05/20/2022 19:21:15 - INFO - __main__ - Step 720 Global step 720 Train loss 1.90 on epoch=179
05/20/2022 19:21:16 - INFO - __main__ - Step 730 Global step 730 Train loss 1.87 on epoch=182
05/20/2022 19:21:17 - INFO - __main__ - Step 740 Global step 740 Train loss 1.89 on epoch=184
05/20/2022 19:21:19 - INFO - __main__ - Step 750 Global step 750 Train loss 1.86 on epoch=187
05/20/2022 19:21:19 - INFO - __main__ - Global step 750 Train loss 1.93 Classification-F1 0.15339578454332553 on epoch=187
05/20/2022 19:21:21 - INFO - __main__ - Step 760 Global step 760 Train loss 1.88 on epoch=189
05/20/2022 19:21:22 - INFO - __main__ - Step 770 Global step 770 Train loss 1.76 on epoch=192
05/20/2022 19:21:23 - INFO - __main__ - Step 780 Global step 780 Train loss 1.60 on epoch=194
05/20/2022 19:21:25 - INFO - __main__ - Step 790 Global step 790 Train loss 1.70 on epoch=197
05/20/2022 19:21:26 - INFO - __main__ - Step 800 Global step 800 Train loss 1.73 on epoch=199
05/20/2022 19:21:27 - INFO - __main__ - Global step 800 Train loss 1.74 Classification-F1 0.17368421052631577 on epoch=199
05/20/2022 19:21:28 - INFO - __main__ - Step 810 Global step 810 Train loss 1.79 on epoch=202
05/20/2022 19:21:29 - INFO - __main__ - Step 820 Global step 820 Train loss 1.68 on epoch=204
05/20/2022 19:21:31 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/20/2022 19:21:32 - INFO - __main__ - Step 840 Global step 840 Train loss 1.62 on epoch=209
05/20/2022 19:21:34 - INFO - __main__ - Step 850 Global step 850 Train loss 1.69 on epoch=212
05/20/2022 19:21:34 - INFO - __main__ - Global step 850 Train loss 1.69 Classification-F1 0.14621798689696247 on epoch=212
05/20/2022 19:21:35 - INFO - __main__ - Step 860 Global step 860 Train loss 1.69 on epoch=214
05/20/2022 19:21:37 - INFO - __main__ - Step 870 Global step 870 Train loss 1.85 on epoch=217
05/20/2022 19:21:38 - INFO - __main__ - Step 880 Global step 880 Train loss 1.42 on epoch=219
05/20/2022 19:21:40 - INFO - __main__ - Step 890 Global step 890 Train loss 1.81 on epoch=222
05/20/2022 19:21:41 - INFO - __main__ - Step 900 Global step 900 Train loss 1.64 on epoch=224
05/20/2022 19:21:42 - INFO - __main__ - Global step 900 Train loss 1.68 Classification-F1 0.13067758749069247 on epoch=224
05/20/2022 19:21:43 - INFO - __main__ - Step 910 Global step 910 Train loss 1.66 on epoch=227
05/20/2022 19:21:44 - INFO - __main__ - Step 920 Global step 920 Train loss 1.57 on epoch=229
05/20/2022 19:21:46 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=232
05/20/2022 19:21:47 - INFO - __main__ - Step 940 Global step 940 Train loss 1.48 on epoch=234
05/20/2022 19:21:48 - INFO - __main__ - Step 950 Global step 950 Train loss 1.48 on epoch=237
05/20/2022 19:21:49 - INFO - __main__ - Global step 950 Train loss 1.54 Classification-F1 0.1458980044345898 on epoch=237
05/20/2022 19:21:50 - INFO - __main__ - Step 960 Global step 960 Train loss 1.45 on epoch=239
05/20/2022 19:21:52 - INFO - __main__ - Step 970 Global step 970 Train loss 1.52 on epoch=242
05/20/2022 19:21:53 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
05/20/2022 19:21:55 - INFO - __main__ - Step 990 Global step 990 Train loss 1.48 on epoch=247
05/20/2022 19:21:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.39 on epoch=249
05/20/2022 19:21:57 - INFO - __main__ - Global step 1000 Train loss 1.43 Classification-F1 0.1115492957746479 on epoch=249
05/20/2022 19:21:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.54 on epoch=252
05/20/2022 19:21:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.50 on epoch=254
05/20/2022 19:22:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.42 on epoch=257
05/20/2022 19:22:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.58 on epoch=259
05/20/2022 19:22:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.40 on epoch=262
05/20/2022 19:22:04 - INFO - __main__ - Global step 1050 Train loss 1.49 Classification-F1 0.16059379217273953 on epoch=262
05/20/2022 19:22:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.37 on epoch=264
05/20/2022 19:22:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.40 on epoch=267
05/20/2022 19:22:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.31 on epoch=269
05/20/2022 19:22:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.38 on epoch=272
05/20/2022 19:22:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.36 on epoch=274
05/20/2022 19:22:12 - INFO - __main__ - Global step 1100 Train loss 1.36 Classification-F1 0.1 on epoch=274
05/20/2022 19:22:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.29 on epoch=277
05/20/2022 19:22:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.36 on epoch=279
05/20/2022 19:22:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.25 on epoch=282
05/20/2022 19:22:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.42 on epoch=284
05/20/2022 19:22:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.28 on epoch=287
05/20/2022 19:22:20 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.10389610389610389 on epoch=287
05/20/2022 19:22:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
05/20/2022 19:22:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.39 on epoch=292
05/20/2022 19:22:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.36 on epoch=294
05/20/2022 19:22:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.35 on epoch=297
05/20/2022 19:22:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.30 on epoch=299
05/20/2022 19:22:27 - INFO - __main__ - Global step 1200 Train loss 1.32 Classification-F1 0.1360774818401937 on epoch=299
05/20/2022 19:22:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.38 on epoch=302
05/20/2022 19:22:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.32 on epoch=304
05/20/2022 19:22:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.34 on epoch=307
05/20/2022 19:22:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.28 on epoch=309
05/20/2022 19:22:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.35 on epoch=312
05/20/2022 19:22:35 - INFO - __main__ - Global step 1250 Train loss 1.33 Classification-F1 0.13514173998044965 on epoch=312
05/20/2022 19:22:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.15 on epoch=314
05/20/2022 19:22:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.25 on epoch=317
05/20/2022 19:22:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.36 on epoch=319
05/20/2022 19:22:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.25 on epoch=322
05/20/2022 19:22:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.25 on epoch=324
05/20/2022 19:22:42 - INFO - __main__ - Global step 1300 Train loss 1.25 Classification-F1 0.1 on epoch=324
05/20/2022 19:22:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.28 on epoch=327
05/20/2022 19:22:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.15 on epoch=329
05/20/2022 19:22:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=332
05/20/2022 19:22:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.24 on epoch=334
05/20/2022 19:22:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.22 on epoch=337
05/20/2022 19:22:49 - INFO - __main__ - Global step 1350 Train loss 1.22 Classification-F1 0.10126582278481013 on epoch=337
05/20/2022 19:22:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.34 on epoch=339
05/20/2022 19:22:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.35 on epoch=342
05/20/2022 19:22:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.18 on epoch=344
05/20/2022 19:22:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.29 on epoch=347
05/20/2022 19:22:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
05/20/2022 19:22:57 - INFO - __main__ - Global step 1400 Train loss 1.25 Classification-F1 0.14004914004914004 on epoch=349
05/20/2022 19:22:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.33 on epoch=352
05/20/2022 19:23:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.08 on epoch=354
05/20/2022 19:23:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.26 on epoch=357
05/20/2022 19:23:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.29 on epoch=359
05/20/2022 19:23:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.28 on epoch=362
05/20/2022 19:23:04 - INFO - __main__ - Global step 1450 Train loss 1.25 Classification-F1 0.12393162393162392 on epoch=362
05/20/2022 19:23:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/20/2022 19:23:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.29 on epoch=367
05/20/2022 19:23:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.30 on epoch=369
05/20/2022 19:23:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/20/2022 19:23:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.26 on epoch=374
05/20/2022 19:23:12 - INFO - __main__ - Global step 1500 Train loss 1.25 Classification-F1 0.09868421052631579 on epoch=374
05/20/2022 19:23:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.05 on epoch=377
05/20/2022 19:23:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.39 on epoch=379
05/20/2022 19:23:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/20/2022 19:23:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.12 on epoch=384
05/20/2022 19:23:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.19 on epoch=387
05/20/2022 19:23:19 - INFO - __main__ - Global step 1550 Train loss 1.17 Classification-F1 0.14248366013071895 on epoch=387
05/20/2022 19:23:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.16 on epoch=389
05/20/2022 19:23:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.18 on epoch=392
05/20/2022 19:23:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.16 on epoch=394
05/20/2022 19:23:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.09 on epoch=397
05/20/2022 19:23:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.07 on epoch=399
05/20/2022 19:23:27 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.11657231085949563 on epoch=399
05/20/2022 19:23:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.03 on epoch=402
05/20/2022 19:23:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.17 on epoch=404
05/20/2022 19:23:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.16 on epoch=407
05/20/2022 19:23:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/20/2022 19:23:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/20/2022 19:23:35 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.09708159618820728 on epoch=412
05/20/2022 19:23:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.20 on epoch=414
05/20/2022 19:23:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.12 on epoch=417
05/20/2022 19:23:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=419
05/20/2022 19:23:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=422
05/20/2022 19:23:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.01 on epoch=424
05/20/2022 19:23:42 - INFO - __main__ - Global step 1700 Train loss 1.10 Classification-F1 0.0880952380952381 on epoch=424
05/20/2022 19:23:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.12 on epoch=427
05/20/2022 19:23:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.04 on epoch=429
05/20/2022 19:23:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.01 on epoch=432
05/20/2022 19:23:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=434
05/20/2022 19:23:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.07 on epoch=437
05/20/2022 19:23:50 - INFO - __main__ - Global step 1750 Train loss 1.08 Classification-F1 0.1237183868762816 on epoch=437
05/20/2022 19:23:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
05/20/2022 19:23:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
05/20/2022 19:23:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/20/2022 19:23:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.08 on epoch=447
05/20/2022 19:23:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
05/20/2022 19:23:58 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.13067758749069247 on epoch=449
05/20/2022 19:23:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.10 on epoch=452
05/20/2022 19:24:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.21 on epoch=454
05/20/2022 19:24:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.18 on epoch=457
05/20/2022 19:24:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.11 on epoch=459
05/20/2022 19:24:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.13 on epoch=462
05/20/2022 19:24:05 - INFO - __main__ - Global step 1850 Train loss 1.15 Classification-F1 0.1796875 on epoch=462
05/20/2022 19:24:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.04 on epoch=464
05/20/2022 19:24:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.04 on epoch=467
05/20/2022 19:24:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.06 on epoch=469
05/20/2022 19:24:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.97 on epoch=472
05/20/2022 19:24:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.98 on epoch=474
05/20/2022 19:24:13 - INFO - __main__ - Global step 1900 Train loss 1.02 Classification-F1 0.17569930069930068 on epoch=474
05/20/2022 19:24:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.97 on epoch=477
05/20/2022 19:24:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=479
05/20/2022 19:24:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.11 on epoch=482
05/20/2022 19:24:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.24 on epoch=484
05/20/2022 19:24:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.15 on epoch=487
05/20/2022 19:24:20 - INFO - __main__ - Global step 1950 Train loss 1.10 Classification-F1 0.14814814814814814 on epoch=487
05/20/2022 19:24:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.09 on epoch=489
05/20/2022 19:24:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.00 on epoch=492
05/20/2022 19:24:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.00 on epoch=494
05/20/2022 19:24:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.14 on epoch=497
05/20/2022 19:24:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/20/2022 19:24:28 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.1145104895104895 on epoch=499
05/20/2022 19:24:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/20/2022 19:24:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.13 on epoch=504
05/20/2022 19:24:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.03 on epoch=507
05/20/2022 19:24:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/20/2022 19:24:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.26 on epoch=512
05/20/2022 19:24:35 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.09493670886075949 on epoch=512
05/20/2022 19:24:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/20/2022 19:24:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.93 on epoch=517
05/20/2022 19:24:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.88 on epoch=519
05/20/2022 19:24:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
05/20/2022 19:24:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
05/20/2022 19:24:43 - INFO - __main__ - Global step 2100 Train loss 0.99 Classification-F1 0.1451990632318501 on epoch=524
05/20/2022 19:24:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/20/2022 19:24:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.12 on epoch=529
05/20/2022 19:24:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.06 on epoch=532
05/20/2022 19:24:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/20/2022 19:24:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
05/20/2022 19:24:50 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.09868421052631579 on epoch=537
05/20/2022 19:24:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
05/20/2022 19:24:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
05/20/2022 19:24:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/20/2022 19:24:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.07 on epoch=547
05/20/2022 19:24:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.11 on epoch=549
05/20/2022 19:24:58 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.13149768399382397 on epoch=549
05/20/2022 19:25:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.11 on epoch=552
05/20/2022 19:25:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.03 on epoch=554
05/20/2022 19:25:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.03 on epoch=557
05/20/2022 19:25:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/20/2022 19:25:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/20/2022 19:25:06 - INFO - __main__ - Global step 2250 Train loss 1.05 Classification-F1 0.16261904761904764 on epoch=562
05/20/2022 19:25:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.97 on epoch=564
05/20/2022 19:25:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.94 on epoch=567
05/20/2022 19:25:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/20/2022 19:25:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
05/20/2022 19:25:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.92 on epoch=574
05/20/2022 19:25:13 - INFO - __main__ - Global step 2300 Train loss 0.96 Classification-F1 0.18356374807987713 on epoch=574
05/20/2022 19:25:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/20/2022 19:25:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.01 on epoch=579
05/20/2022 19:25:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
05/20/2022 19:25:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.97 on epoch=584
05/20/2022 19:25:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/20/2022 19:25:21 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.140625 on epoch=587
05/20/2022 19:25:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/20/2022 19:25:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
05/20/2022 19:25:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.06 on epoch=594
05/20/2022 19:25:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.95 on epoch=597
05/20/2022 19:25:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/20/2022 19:25:29 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.17712418300653593 on epoch=599
05/20/2022 19:25:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.92 on epoch=602
05/20/2022 19:25:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
05/20/2022 19:25:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.96 on epoch=607
05/20/2022 19:25:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.90 on epoch=609
05/20/2022 19:25:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.94 on epoch=612
05/20/2022 19:25:36 - INFO - __main__ - Global step 2450 Train loss 0.95 Classification-F1 0.19408369408369408 on epoch=612
05/20/2022 19:25:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.02 on epoch=614
05/20/2022 19:25:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=617
05/20/2022 19:25:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/20/2022 19:25:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/20/2022 19:25:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
05/20/2022 19:25:44 - INFO - __main__ - Global step 2500 Train loss 0.97 Classification-F1 0.1 on epoch=624
05/20/2022 19:25:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.98 on epoch=627
05/20/2022 19:25:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.88 on epoch=629
05/20/2022 19:25:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.06 on epoch=632
05/20/2022 19:25:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.05 on epoch=634
05/20/2022 19:25:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
05/20/2022 19:25:51 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.1408918406072106 on epoch=637
05/20/2022 19:25:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.08 on epoch=639
05/20/2022 19:25:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.00 on epoch=642
05/20/2022 19:25:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.99 on epoch=644
05/20/2022 19:25:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.96 on epoch=647
05/20/2022 19:25:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/20/2022 19:25:59 - INFO - __main__ - Global step 2600 Train loss 1.01 Classification-F1 0.0998185117967332 on epoch=649
05/20/2022 19:26:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
05/20/2022 19:26:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/20/2022 19:26:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.03 on epoch=657
05/20/2022 19:26:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.00 on epoch=659
05/20/2022 19:26:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
05/20/2022 19:26:06 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.1115492957746479 on epoch=662
05/20/2022 19:26:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.93 on epoch=664
05/20/2022 19:26:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.90 on epoch=667
05/20/2022 19:26:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/20/2022 19:26:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.91 on epoch=672
05/20/2022 19:26:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.98 on epoch=674
05/20/2022 19:26:14 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.18782608695652175 on epoch=674
05/20/2022 19:26:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/20/2022 19:26:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.11 on epoch=679
05/20/2022 19:26:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/20/2022 19:26:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.93 on epoch=684
05/20/2022 19:26:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.03 on epoch=687
05/20/2022 19:26:22 - INFO - __main__ - Global step 2750 Train loss 1.04 Classification-F1 0.15285714285714286 on epoch=687
05/20/2022 19:26:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=689
05/20/2022 19:26:24 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.06 on epoch=692
05/20/2022 19:26:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.02 on epoch=694
05/20/2022 19:26:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.89 on epoch=697
05/20/2022 19:26:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
05/20/2022 19:26:29 - INFO - __main__ - Global step 2800 Train loss 0.97 Classification-F1 0.17798594847775173 on epoch=699
05/20/2022 19:26:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.92 on epoch=702
05/20/2022 19:26:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.93 on epoch=704
05/20/2022 19:26:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
05/20/2022 19:26:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.90 on epoch=709
05/20/2022 19:26:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.98 on epoch=712
05/20/2022 19:26:37 - INFO - __main__ - Global step 2850 Train loss 0.94 Classification-F1 0.10256410256410256 on epoch=712
05/20/2022 19:26:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.83 on epoch=714
05/20/2022 19:26:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.92 on epoch=717
05/20/2022 19:26:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.97 on epoch=719
05/20/2022 19:26:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/20/2022 19:26:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.92 on epoch=724
05/20/2022 19:26:44 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.08552631578947369 on epoch=724
05/20/2022 19:26:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.03 on epoch=727
05/20/2022 19:26:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/20/2022 19:26:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.01 on epoch=732
05/20/2022 19:26:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/20/2022 19:26:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.01 on epoch=737
05/20/2022 19:26:52 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.1 on epoch=737
05/20/2022 19:26:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.91 on epoch=739
05/20/2022 19:26:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/20/2022 19:26:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.91 on epoch=744
05/20/2022 19:26:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.03 on epoch=747
05/20/2022 19:26:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.96 on epoch=749
05/20/2022 19:26:59 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.1697802197802198 on epoch=749
05/20/2022 19:26:59 - INFO - __main__ - save last model!
05/20/2022 19:26:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 19:26:59 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 19:26:59 - INFO - __main__ - Printing 3 examples
05/20/2022 19:26:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 19:26:59 - INFO - __main__ - ['others']
05/20/2022 19:26:59 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 19:26:59 - INFO - __main__ - ['others']
05/20/2022 19:26:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 19:26:59 - INFO - __main__ - ['others']
05/20/2022 19:26:59 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:27:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:27:00 - INFO - __main__ - Printing 3 examples
05/20/2022 19:27:00 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:27:00 - INFO - __main__ - ['others']
05/20/2022 19:27:00 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:27:00 - INFO - __main__ - ['others']
05/20/2022 19:27:00 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:27:00 - INFO - __main__ - ['others']
05/20/2022 19:27:00 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:27:00 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:27:00 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:27:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:27:00 - INFO - __main__ - Printing 3 examples
05/20/2022 19:27:00 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:27:00 - INFO - __main__ - ['others']
05/20/2022 19:27:00 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:27:00 - INFO - __main__ - ['others']
05/20/2022 19:27:00 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:27:00 - INFO - __main__ - ['others']
05/20/2022 19:27:00 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:27:00 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:27:00 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:27:02 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:27:06 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:27:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:27:06 - INFO - __main__ - Starting training!
05/20/2022 19:27:07 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 19:27:51 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.3_8_predictions.txt
05/20/2022 19:27:51 - INFO - __main__ - Classification-F1 on test data: 0.0553
05/20/2022 19:27:51 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.19865392965696915, test_performance=0.05534399999455197
05/20/2022 19:27:51 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
05/20/2022 19:27:52 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:27:52 - INFO - __main__ - Printing 3 examples
05/20/2022 19:27:52 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/20/2022 19:27:52 - INFO - __main__ - ['others']
05/20/2022 19:27:52 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/20/2022 19:27:52 - INFO - __main__ - ['others']
05/20/2022 19:27:52 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/20/2022 19:27:52 - INFO - __main__ - ['others']
05/20/2022 19:27:52 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:27:52 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:27:52 - INFO - __main__ - Loaded 64 examples from train data
05/20/2022 19:27:52 - INFO - __main__ - Start tokenizing ... 64 instances
05/20/2022 19:27:52 - INFO - __main__ - Printing 3 examples
05/20/2022 19:27:52 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/20/2022 19:27:52 - INFO - __main__ - ['others']
05/20/2022 19:27:52 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/20/2022 19:27:52 - INFO - __main__ - ['others']
05/20/2022 19:27:52 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/20/2022 19:27:52 - INFO - __main__ - ['others']
05/20/2022 19:27:52 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:27:52 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:27:52 - INFO - __main__ - Loaded 64 examples from dev data
05/20/2022 19:27:59 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 19:27:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 19:27:59 - INFO - __main__ - Starting training!
05/20/2022 19:28:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.84 on epoch=2
05/20/2022 19:28:03 - INFO - __main__ - Step 20 Global step 20 Train loss 6.57 on epoch=4
05/20/2022 19:28:04 - INFO - __main__ - Step 30 Global step 30 Train loss 6.60 on epoch=7
05/20/2022 19:28:06 - INFO - __main__ - Step 40 Global step 40 Train loss 6.46 on epoch=9
05/20/2022 19:28:07 - INFO - __main__ - Step 50 Global step 50 Train loss 6.27 on epoch=12
05/20/2022 19:28:16 - INFO - __main__ - Global step 50 Train loss 6.55 Classification-F1 0.0 on epoch=12
05/20/2022 19:28:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/20/2022 19:28:17 - INFO - __main__ - Step 60 Global step 60 Train loss 6.06 on epoch=14
05/20/2022 19:28:18 - INFO - __main__ - Step 70 Global step 70 Train loss 5.98 on epoch=17
05/20/2022 19:28:20 - INFO - __main__ - Step 80 Global step 80 Train loss 5.76 on epoch=19
05/20/2022 19:28:21 - INFO - __main__ - Step 90 Global step 90 Train loss 5.75 on epoch=22
05/20/2022 19:28:22 - INFO - __main__ - Step 100 Global step 100 Train loss 5.76 on epoch=24
05/20/2022 19:28:25 - INFO - __main__ - Global step 100 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/20/2022 19:28:26 - INFO - __main__ - Step 110 Global step 110 Train loss 5.68 on epoch=27
05/20/2022 19:28:27 - INFO - __main__ - Step 120 Global step 120 Train loss 5.44 on epoch=29
05/20/2022 19:28:29 - INFO - __main__ - Step 130 Global step 130 Train loss 5.37 on epoch=32
05/20/2022 19:28:30 - INFO - __main__ - Step 140 Global step 140 Train loss 5.39 on epoch=34
05/20/2022 19:28:31 - INFO - __main__ - Step 150 Global step 150 Train loss 5.14 on epoch=37
05/20/2022 19:28:33 - INFO - __main__ - Global step 150 Train loss 5.41 Classification-F1 0.0 on epoch=37
05/20/2022 19:28:35 - INFO - __main__ - Step 160 Global step 160 Train loss 5.15 on epoch=39
05/20/2022 19:28:36 - INFO - __main__ - Step 170 Global step 170 Train loss 5.11 on epoch=42
05/20/2022 19:28:38 - INFO - __main__ - Step 180 Global step 180 Train loss 4.87 on epoch=44
05/20/2022 19:28:39 - INFO - __main__ - Step 190 Global step 190 Train loss 5.11 on epoch=47
05/20/2022 19:28:40 - INFO - __main__ - Step 200 Global step 200 Train loss 4.70 on epoch=49
05/20/2022 19:28:43 - INFO - __main__ - Global step 200 Train loss 4.99 Classification-F1 0.0 on epoch=49
05/20/2022 19:28:44 - INFO - __main__ - Step 210 Global step 210 Train loss 4.63 on epoch=52
05/20/2022 19:28:46 - INFO - __main__ - Step 220 Global step 220 Train loss 4.61 on epoch=54
05/20/2022 19:28:47 - INFO - __main__ - Step 230 Global step 230 Train loss 4.47 on epoch=57
05/20/2022 19:28:48 - INFO - __main__ - Step 240 Global step 240 Train loss 4.31 on epoch=59
05/20/2022 19:28:50 - INFO - __main__ - Step 250 Global step 250 Train loss 4.22 on epoch=62
05/20/2022 19:28:50 - INFO - __main__ - Global step 250 Train loss 4.45 Classification-F1 0.08235243017851714 on epoch=62
05/20/2022 19:28:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08235243017851714 on epoch=62, global_step=250
05/20/2022 19:28:52 - INFO - __main__ - Step 260 Global step 260 Train loss 4.14 on epoch=64
05/20/2022 19:28:53 - INFO - __main__ - Step 270 Global step 270 Train loss 4.15 on epoch=67
05/20/2022 19:28:54 - INFO - __main__ - Step 280 Global step 280 Train loss 3.95 on epoch=69
05/20/2022 19:28:56 - INFO - __main__ - Step 290 Global step 290 Train loss 3.97 on epoch=72
05/20/2022 19:28:57 - INFO - __main__ - Step 300 Global step 300 Train loss 3.84 on epoch=74
05/20/2022 19:28:57 - INFO - __main__ - Global step 300 Train loss 4.01 Classification-F1 0.15141579731743665 on epoch=74
05/20/2022 19:28:57 - INFO - __main__ - Saving model with best Classification-F1: 0.08235243017851714 -> 0.15141579731743665 on epoch=74, global_step=300
05/20/2022 19:28:59 - INFO - __main__ - Step 310 Global step 310 Train loss 3.83 on epoch=77
05/20/2022 19:29:00 - INFO - __main__ - Step 320 Global step 320 Train loss 3.72 on epoch=79
05/20/2022 19:29:01 - INFO - __main__ - Step 330 Global step 330 Train loss 3.68 on epoch=82
05/20/2022 19:29:03 - INFO - __main__ - Step 340 Global step 340 Train loss 3.43 on epoch=84
05/20/2022 19:29:04 - INFO - __main__ - Step 350 Global step 350 Train loss 3.41 on epoch=87
05/20/2022 19:29:05 - INFO - __main__ - Global step 350 Train loss 3.61 Classification-F1 0.13034188034188032 on epoch=87
05/20/2022 19:29:06 - INFO - __main__ - Step 360 Global step 360 Train loss 3.28 on epoch=89
05/20/2022 19:29:07 - INFO - __main__ - Step 370 Global step 370 Train loss 3.31 on epoch=92
05/20/2022 19:29:09 - INFO - __main__ - Step 380 Global step 380 Train loss 3.03 on epoch=94
05/20/2022 19:29:10 - INFO - __main__ - Step 390 Global step 390 Train loss 3.11 on epoch=97
05/20/2022 19:29:11 - INFO - __main__ - Step 400 Global step 400 Train loss 3.11 on epoch=99
05/20/2022 19:29:12 - INFO - __main__ - Global step 400 Train loss 3.17 Classification-F1 0.1237183868762816 on epoch=99
05/20/2022 19:29:13 - INFO - __main__ - Step 410 Global step 410 Train loss 2.95 on epoch=102
05/20/2022 19:29:15 - INFO - __main__ - Step 420 Global step 420 Train loss 2.92 on epoch=104
05/20/2022 19:29:16 - INFO - __main__ - Step 430 Global step 430 Train loss 2.99 on epoch=107
05/20/2022 19:29:17 - INFO - __main__ - Step 440 Global step 440 Train loss 2.80 on epoch=109
05/20/2022 19:29:19 - INFO - __main__ - Step 450 Global step 450 Train loss 2.90 on epoch=112
05/20/2022 19:29:19 - INFO - __main__ - Global step 450 Train loss 2.91 Classification-F1 0.1 on epoch=112
05/20/2022 19:29:21 - INFO - __main__ - Step 460 Global step 460 Train loss 2.68 on epoch=114
05/20/2022 19:29:22 - INFO - __main__ - Step 470 Global step 470 Train loss 2.78 on epoch=117
05/20/2022 19:29:23 - INFO - __main__ - Step 480 Global step 480 Train loss 2.56 on epoch=119
05/20/2022 19:29:25 - INFO - __main__ - Step 490 Global step 490 Train loss 2.56 on epoch=122
05/20/2022 19:29:26 - INFO - __main__ - Step 500 Global step 500 Train loss 2.47 on epoch=124
05/20/2022 19:29:26 - INFO - __main__ - Global step 500 Train loss 2.61 Classification-F1 0.10256410256410256 on epoch=124
05/20/2022 19:29:28 - INFO - __main__ - Step 510 Global step 510 Train loss 2.58 on epoch=127
05/20/2022 19:29:29 - INFO - __main__ - Step 520 Global step 520 Train loss 2.46 on epoch=129
05/20/2022 19:29:30 - INFO - __main__ - Step 530 Global step 530 Train loss 2.52 on epoch=132
05/20/2022 19:29:32 - INFO - __main__ - Step 540 Global step 540 Train loss 2.34 on epoch=134
05/20/2022 19:29:33 - INFO - __main__ - Step 550 Global step 550 Train loss 2.48 on epoch=137
05/20/2022 19:29:34 - INFO - __main__ - Global step 550 Train loss 2.48 Classification-F1 0.19673202614379087 on epoch=137
05/20/2022 19:29:34 - INFO - __main__ - Saving model with best Classification-F1: 0.15141579731743665 -> 0.19673202614379087 on epoch=137, global_step=550
05/20/2022 19:29:35 - INFO - __main__ - Step 560 Global step 560 Train loss 2.28 on epoch=139
05/20/2022 19:29:36 - INFO - __main__ - Step 570 Global step 570 Train loss 2.36 on epoch=142
05/20/2022 19:29:38 - INFO - __main__ - Step 580 Global step 580 Train loss 2.21 on epoch=144
05/20/2022 19:29:39 - INFO - __main__ - Step 590 Global step 590 Train loss 2.26 on epoch=147
05/20/2022 19:29:40 - INFO - __main__ - Step 600 Global step 600 Train loss 2.08 on epoch=149
05/20/2022 19:29:41 - INFO - __main__ - Global step 600 Train loss 2.24 Classification-F1 0.10135135135135136 on epoch=149
05/20/2022 19:29:42 - INFO - __main__ - Step 610 Global step 610 Train loss 2.13 on epoch=152
05/20/2022 19:29:43 - INFO - __main__ - Step 620 Global step 620 Train loss 2.06 on epoch=154
05/20/2022 19:29:45 - INFO - __main__ - Step 630 Global step 630 Train loss 2.26 on epoch=157
05/20/2022 19:29:46 - INFO - __main__ - Step 640 Global step 640 Train loss 2.17 on epoch=159
05/20/2022 19:29:48 - INFO - __main__ - Step 650 Global step 650 Train loss 2.27 on epoch=162
05/20/2022 19:29:48 - INFO - __main__ - Global step 650 Train loss 2.18 Classification-F1 0.11714285714285715 on epoch=162
05/20/2022 19:29:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.90 on epoch=164
05/20/2022 19:29:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.97 on epoch=167
05/20/2022 19:29:52 - INFO - __main__ - Step 680 Global step 680 Train loss 2.01 on epoch=169
05/20/2022 19:29:54 - INFO - __main__ - Step 690 Global step 690 Train loss 2.02 on epoch=172
05/20/2022 19:29:55 - INFO - __main__ - Step 700 Global step 700 Train loss 1.98 on epoch=174
05/20/2022 19:29:56 - INFO - __main__ - Global step 700 Train loss 1.98 Classification-F1 0.10256410256410256 on epoch=174
05/20/2022 19:29:57 - INFO - __main__ - Step 710 Global step 710 Train loss 2.02 on epoch=177
05/20/2022 19:29:58 - INFO - __main__ - Step 720 Global step 720 Train loss 1.80 on epoch=179
05/20/2022 19:30:00 - INFO - __main__ - Step 730 Global step 730 Train loss 1.77 on epoch=182
05/20/2022 19:30:01 - INFO - __main__ - Step 740 Global step 740 Train loss 1.77 on epoch=184
05/20/2022 19:30:02 - INFO - __main__ - Step 750 Global step 750 Train loss 1.87 on epoch=187
05/20/2022 19:30:03 - INFO - __main__ - Global step 750 Train loss 1.85 Classification-F1 0.1 on epoch=187
05/20/2022 19:30:04 - INFO - __main__ - Step 760 Global step 760 Train loss 1.78 on epoch=189
05/20/2022 19:30:05 - INFO - __main__ - Step 770 Global step 770 Train loss 2.00 on epoch=192
05/20/2022 19:30:07 - INFO - __main__ - Step 780 Global step 780 Train loss 1.69 on epoch=194
05/20/2022 19:30:08 - INFO - __main__ - Step 790 Global step 790 Train loss 1.87 on epoch=197
05/20/2022 19:30:10 - INFO - __main__ - Step 800 Global step 800 Train loss 1.62 on epoch=199
05/20/2022 19:30:10 - INFO - __main__ - Global step 800 Train loss 1.79 Classification-F1 0.10126582278481013 on epoch=199
05/20/2022 19:30:12 - INFO - __main__ - Step 810 Global step 810 Train loss 1.84 on epoch=202
05/20/2022 19:30:13 - INFO - __main__ - Step 820 Global step 820 Train loss 1.69 on epoch=204
05/20/2022 19:30:14 - INFO - __main__ - Step 830 Global step 830 Train loss 1.85 on epoch=207
05/20/2022 19:30:16 - INFO - __main__ - Step 840 Global step 840 Train loss 1.71 on epoch=209
05/20/2022 19:30:17 - INFO - __main__ - Step 850 Global step 850 Train loss 1.52 on epoch=212
05/20/2022 19:30:18 - INFO - __main__ - Global step 850 Train loss 1.72 Classification-F1 0.1 on epoch=212
05/20/2022 19:30:19 - INFO - __main__ - Step 860 Global step 860 Train loss 1.62 on epoch=214
05/20/2022 19:30:20 - INFO - __main__ - Step 870 Global step 870 Train loss 1.58 on epoch=217
05/20/2022 19:30:22 - INFO - __main__ - Step 880 Global step 880 Train loss 1.72 on epoch=219
05/20/2022 19:30:23 - INFO - __main__ - Step 890 Global step 890 Train loss 1.67 on epoch=222
05/20/2022 19:30:24 - INFO - __main__ - Step 900 Global step 900 Train loss 1.68 on epoch=224
05/20/2022 19:30:25 - INFO - __main__ - Global step 900 Train loss 1.66 Classification-F1 0.1 on epoch=224
05/20/2022 19:30:26 - INFO - __main__ - Step 910 Global step 910 Train loss 1.67 on epoch=227
05/20/2022 19:30:27 - INFO - __main__ - Step 920 Global step 920 Train loss 1.61 on epoch=229
05/20/2022 19:30:29 - INFO - __main__ - Step 930 Global step 930 Train loss 1.49 on epoch=232
05/20/2022 19:30:30 - INFO - __main__ - Step 940 Global step 940 Train loss 1.66 on epoch=234
05/20/2022 19:30:32 - INFO - __main__ - Step 950 Global step 950 Train loss 1.63 on epoch=237
05/20/2022 19:30:32 - INFO - __main__ - Global step 950 Train loss 1.61 Classification-F1 0.1 on epoch=237
05/20/2022 19:30:33 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/20/2022 19:30:35 - INFO - __main__ - Step 970 Global step 970 Train loss 1.39 on epoch=242
05/20/2022 19:30:36 - INFO - __main__ - Step 980 Global step 980 Train loss 1.45 on epoch=244
05/20/2022 19:30:37 - INFO - __main__ - Step 990 Global step 990 Train loss 1.55 on epoch=247
05/20/2022 19:30:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.64 on epoch=249
05/20/2022 19:30:39 - INFO - __main__ - Global step 1000 Train loss 1.47 Classification-F1 0.1 on epoch=249
05/20/2022 19:30:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/20/2022 19:30:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.48 on epoch=254
05/20/2022 19:30:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.56 on epoch=257
05/20/2022 19:30:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.47 on epoch=259
05/20/2022 19:30:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.38 on epoch=262
05/20/2022 19:30:47 - INFO - __main__ - Global step 1050 Train loss 1.45 Classification-F1 0.1 on epoch=262
05/20/2022 19:30:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.39 on epoch=264
05/20/2022 19:30:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.47 on epoch=267
05/20/2022 19:30:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.50 on epoch=269
05/20/2022 19:30:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.53 on epoch=272
05/20/2022 19:30:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.47 on epoch=274
05/20/2022 19:30:54 - INFO - __main__ - Global step 1100 Train loss 1.47 Classification-F1 0.18907563025210083 on epoch=274
05/20/2022 19:30:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.53 on epoch=277
05/20/2022 19:30:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.43 on epoch=279
05/20/2022 19:30:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.37 on epoch=282
05/20/2022 19:31:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.43 on epoch=284
05/20/2022 19:31:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.42 on epoch=287
05/20/2022 19:31:01 - INFO - __main__ - Global step 1150 Train loss 1.44 Classification-F1 0.18928571428571428 on epoch=287
05/20/2022 19:31:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.42 on epoch=289
05/20/2022 19:31:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.31 on epoch=292
05/20/2022 19:31:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.32 on epoch=294
05/20/2022 19:31:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.34 on epoch=297
05/20/2022 19:31:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.32 on epoch=299
05/20/2022 19:31:09 - INFO - __main__ - Global step 1200 Train loss 1.34 Classification-F1 0.13034188034188032 on epoch=299
05/20/2022 19:31:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.39 on epoch=302
05/20/2022 19:31:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.24 on epoch=304
05/20/2022 19:31:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.39 on epoch=307
05/20/2022 19:31:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.19 on epoch=309
05/20/2022 19:31:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.25 on epoch=312
05/20/2022 19:31:16 - INFO - __main__ - Global step 1250 Train loss 1.29 Classification-F1 0.1581196581196581 on epoch=312
05/20/2022 19:31:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=314
05/20/2022 19:31:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.51 on epoch=317
05/20/2022 19:31:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.37 on epoch=319
05/20/2022 19:31:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.34 on epoch=322
05/20/2022 19:31:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.32 on epoch=324
05/20/2022 19:31:23 - INFO - __main__ - Global step 1300 Train loss 1.38 Classification-F1 0.1 on epoch=324
05/20/2022 19:31:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.40 on epoch=327
05/20/2022 19:31:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.28 on epoch=329
05/20/2022 19:31:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.32 on epoch=332
05/20/2022 19:31:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.17 on epoch=334
05/20/2022 19:31:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.28 on epoch=337
05/20/2022 19:31:31 - INFO - __main__ - Global step 1350 Train loss 1.29 Classification-F1 0.17552334943639292 on epoch=337
05/20/2022 19:31:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.25 on epoch=339
05/20/2022 19:31:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.21 on epoch=342
05/20/2022 19:31:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.23 on epoch=344
05/20/2022 19:31:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.31 on epoch=347
05/20/2022 19:31:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.16 on epoch=349
05/20/2022 19:31:38 - INFO - __main__ - Global step 1400 Train loss 1.23 Classification-F1 0.16526054590570718 on epoch=349
05/20/2022 19:31:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/20/2022 19:31:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=354
05/20/2022 19:31:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.27 on epoch=357
05/20/2022 19:31:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.13 on epoch=359
05/20/2022 19:31:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.31 on epoch=362
05/20/2022 19:31:46 - INFO - __main__ - Global step 1450 Train loss 1.24 Classification-F1 0.1238095238095238 on epoch=362
05/20/2022 19:31:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.30 on epoch=364
05/20/2022 19:31:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.27 on epoch=367
05/20/2022 19:31:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.27 on epoch=369
05/20/2022 19:31:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.12 on epoch=372
05/20/2022 19:31:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.17 on epoch=374
05/20/2022 19:31:53 - INFO - __main__ - Global step 1500 Train loss 1.22 Classification-F1 0.17809523809523808 on epoch=374
05/20/2022 19:31:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.18 on epoch=377
05/20/2022 19:31:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.31 on epoch=379
05/20/2022 19:31:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.23 on epoch=382
05/20/2022 19:31:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.23 on epoch=384
05/20/2022 19:32:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.21 on epoch=387
05/20/2022 19:32:00 - INFO - __main__ - Global step 1550 Train loss 1.23 Classification-F1 0.1 on epoch=387
05/20/2022 19:32:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=389
05/20/2022 19:32:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.21 on epoch=392
05/20/2022 19:32:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.21 on epoch=394
05/20/2022 19:32:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.10 on epoch=397
05/20/2022 19:32:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.27 on epoch=399
05/20/2022 19:32:07 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.18561872909698998 on epoch=399
05/20/2022 19:32:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
05/20/2022 19:32:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.25 on epoch=404
05/20/2022 19:32:11 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.17 on epoch=407
05/20/2022 19:32:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.33 on epoch=409
05/20/2022 19:32:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.26 on epoch=412
05/20/2022 19:32:15 - INFO - __main__ - Global step 1650 Train loss 1.23 Classification-F1 0.18406593406593408 on epoch=412
05/20/2022 19:32:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.25 on epoch=414
05/20/2022 19:32:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.25 on epoch=417
05/20/2022 19:32:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.08 on epoch=419
05/20/2022 19:32:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.16 on epoch=422
05/20/2022 19:32:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.30 on epoch=424
05/20/2022 19:32:22 - INFO - __main__ - Global step 1700 Train loss 1.21 Classification-F1 0.19267605633802815 on epoch=424
05/20/2022 19:32:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=427
05/20/2022 19:32:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
05/20/2022 19:32:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.15 on epoch=432
05/20/2022 19:32:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.25 on epoch=434
05/20/2022 19:32:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.29 on epoch=437
05/20/2022 19:32:29 - INFO - __main__ - Global step 1750 Train loss 1.21 Classification-F1 0.1313186813186813 on epoch=437
05/20/2022 19:32:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.11 on epoch=439
05/20/2022 19:32:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.21 on epoch=442
05/20/2022 19:32:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/20/2022 19:32:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.21 on epoch=447
05/20/2022 19:32:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/20/2022 19:32:36 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.17813765182186234 on epoch=449
05/20/2022 19:32:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.22 on epoch=452
05/20/2022 19:32:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/20/2022 19:32:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.20 on epoch=457
05/20/2022 19:32:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.13 on epoch=459
05/20/2022 19:32:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.20 on epoch=462
05/20/2022 19:32:44 - INFO - __main__ - Global step 1850 Train loss 1.18 Classification-F1 0.1565276828434723 on epoch=462
05/20/2022 19:32:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.18 on epoch=464
05/20/2022 19:32:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.14 on epoch=467
05/20/2022 19:32:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.16 on epoch=469
05/20/2022 19:32:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.25 on epoch=472
05/20/2022 19:32:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/20/2022 19:32:51 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.13333333333333333 on epoch=474
05/20/2022 19:32:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.11 on epoch=477
05/20/2022 19:32:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.08 on epoch=479
05/20/2022 19:32:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.18 on epoch=482
05/20/2022 19:32:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
05/20/2022 19:32:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.97 on epoch=487
05/20/2022 19:32:58 - INFO - __main__ - Global step 1950 Train loss 1.07 Classification-F1 0.1736111111111111 on epoch=487
05/20/2022 19:33:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.15 on epoch=489
05/20/2022 19:33:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.12 on epoch=492
05/20/2022 19:33:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.10 on epoch=494
05/20/2022 19:33:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=497
05/20/2022 19:33:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.10 on epoch=499
05/20/2022 19:33:05 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.15526315789473685 on epoch=499
05/20/2022 19:33:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.16 on epoch=502
05/20/2022 19:33:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
05/20/2022 19:33:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.17 on epoch=507
05/20/2022 19:33:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.09 on epoch=509
05/20/2022 19:33:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.04 on epoch=512
05/20/2022 19:33:13 - INFO - __main__ - Global step 2050 Train loss 1.09 Classification-F1 0.109375 on epoch=512
05/20/2022 19:33:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.96 on epoch=514
05/20/2022 19:33:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.17 on epoch=517
05/20/2022 19:33:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.13 on epoch=519
05/20/2022 19:33:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
05/20/2022 19:33:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
05/20/2022 19:33:21 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.2091503267973856 on epoch=524
05/20/2022 19:33:21 - INFO - __main__ - Saving model with best Classification-F1: 0.19673202614379087 -> 0.2091503267973856 on epoch=524, global_step=2100
05/20/2022 19:33:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.05 on epoch=527
05/20/2022 19:33:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.09 on epoch=529
05/20/2022 19:33:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.23 on epoch=532
05/20/2022 19:33:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.17 on epoch=534
05/20/2022 19:33:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.17 on epoch=537
05/20/2022 19:33:28 - INFO - __main__ - Global step 2150 Train loss 1.14 Classification-F1 0.18276972624798712 on epoch=537
05/20/2022 19:33:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.16 on epoch=539
05/20/2022 19:33:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.16 on epoch=542
05/20/2022 19:33:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.15 on epoch=544
05/20/2022 19:33:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.16 on epoch=547
05/20/2022 19:33:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.17 on epoch=549
05/20/2022 19:33:35 - INFO - __main__ - Global step 2200 Train loss 1.16 Classification-F1 0.1468058968058968 on epoch=549
05/20/2022 19:33:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.16 on epoch=552
05/20/2022 19:33:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=554
05/20/2022 19:33:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/20/2022 19:33:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
05/20/2022 19:33:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.07 on epoch=562
05/20/2022 19:33:43 - INFO - __main__ - Global step 2250 Train loss 1.08 Classification-F1 0.1581196581196581 on epoch=562
05/20/2022 19:33:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/20/2022 19:33:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.11 on epoch=567
05/20/2022 19:33:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.14 on epoch=569
05/20/2022 19:33:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.07 on epoch=572
05/20/2022 19:33:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.16 on epoch=574
05/20/2022 19:33:51 - INFO - __main__ - Global step 2300 Train loss 1.12 Classification-F1 0.171875 on epoch=574
05/20/2022 19:33:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/20/2022 19:33:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.18 on epoch=579
05/20/2022 19:33:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.06 on epoch=582
05/20/2022 19:33:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/20/2022 19:33:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.15 on epoch=587
05/20/2022 19:34:00 - INFO - __main__ - Global step 2350 Train loss 1.10 Classification-F1 0.180905815748842 on epoch=587
05/20/2022 19:34:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.20 on epoch=589
05/20/2022 19:34:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.04 on epoch=592
05/20/2022 19:34:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/20/2022 19:34:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=597
05/20/2022 19:34:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.16 on epoch=599
05/20/2022 19:34:07 - INFO - __main__ - Global step 2400 Train loss 1.09 Classification-F1 0.13430127041742287 on epoch=599
05/20/2022 19:34:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.08 on epoch=602
05/20/2022 19:34:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/20/2022 19:34:11 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/20/2022 19:34:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/20/2022 19:34:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.97 on epoch=612
05/20/2022 19:34:15 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.18881118881118883 on epoch=612
05/20/2022 19:34:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
05/20/2022 19:34:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/20/2022 19:34:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.96 on epoch=619
05/20/2022 19:34:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.00 on epoch=622
05/20/2022 19:34:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
05/20/2022 19:34:22 - INFO - __main__ - Global step 2500 Train loss 1.03 Classification-F1 0.16888045540796964 on epoch=624
05/20/2022 19:34:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.14 on epoch=627
05/20/2022 19:34:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.02 on epoch=629
05/20/2022 19:34:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.00 on epoch=632
05/20/2022 19:34:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.02 on epoch=634
05/20/2022 19:34:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.02 on epoch=637
05/20/2022 19:34:30 - INFO - __main__ - Global step 2550 Train loss 1.04 Classification-F1 0.1581196581196581 on epoch=637
05/20/2022 19:34:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.03 on epoch=639
05/20/2022 19:34:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
05/20/2022 19:34:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.06 on epoch=644
05/20/2022 19:34:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
05/20/2022 19:34:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.00 on epoch=649
05/20/2022 19:34:37 - INFO - __main__ - Global step 2600 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=649
05/20/2022 19:34:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.08 on epoch=652
05/20/2022 19:34:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.03 on epoch=654
05/20/2022 19:34:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.01 on epoch=657
05/20/2022 19:34:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.03 on epoch=659
05/20/2022 19:34:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/20/2022 19:34:45 - INFO - __main__ - Global step 2650 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=662
05/20/2022 19:34:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.09 on epoch=664
05/20/2022 19:34:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.10 on epoch=667
05/20/2022 19:34:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.05 on epoch=669
05/20/2022 19:34:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/20/2022 19:34:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.06 on epoch=674
05/20/2022 19:34:52 - INFO - __main__ - Global step 2700 Train loss 1.06 Classification-F1 0.13067758749069247 on epoch=674
05/20/2022 19:34:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/20/2022 19:34:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.03 on epoch=679
05/20/2022 19:34:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.16 on epoch=682
05/20/2022 19:34:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.03 on epoch=684
05/20/2022 19:34:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.02 on epoch=687
05/20/2022 19:34:59 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.1 on epoch=687
05/20/2022 19:35:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.05 on epoch=689
05/20/2022 19:35:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.08 on epoch=692
05/20/2022 19:35:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.06 on epoch=694
05/20/2022 19:35:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.03 on epoch=697
05/20/2022 19:35:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.04 on epoch=699
05/20/2022 19:35:07 - INFO - __main__ - Global step 2800 Train loss 1.05 Classification-F1 0.13067758749069247 on epoch=699
05/20/2022 19:35:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.09 on epoch=702
05/20/2022 19:35:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.96 on epoch=704
05/20/2022 19:35:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.07 on epoch=707
05/20/2022 19:35:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.15 on epoch=709
05/20/2022 19:35:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.02 on epoch=712
05/20/2022 19:35:16 - INFO - __main__ - Global step 2850 Train loss 1.06 Classification-F1 0.09493670886075949 on epoch=712
05/20/2022 19:35:17 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.11 on epoch=714
05/20/2022 19:35:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.12 on epoch=717
05/20/2022 19:35:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.96 on epoch=719
05/20/2022 19:35:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.15 on epoch=722
05/20/2022 19:35:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
05/20/2022 19:35:24 - INFO - __main__ - Global step 2900 Train loss 1.06 Classification-F1 0.13026315789473686 on epoch=724
05/20/2022 19:35:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.01 on epoch=727
05/20/2022 19:35:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
05/20/2022 19:35:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.06 on epoch=732
05/20/2022 19:35:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.02 on epoch=734
05/20/2022 19:35:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.07 on epoch=737
05/20/2022 19:35:31 - INFO - __main__ - Global step 2950 Train loss 1.03 Classification-F1 0.1 on epoch=737
05/20/2022 19:35:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.05 on epoch=739
05/20/2022 19:35:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.12 on epoch=742
05/20/2022 19:35:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.13 on epoch=744
05/20/2022 19:35:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.07 on epoch=747
05/20/2022 19:35:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.97 on epoch=749
05/20/2022 19:35:39 - INFO - __main__ - Global step 3000 Train loss 1.07 Classification-F1 0.18276972624798712 on epoch=749
05/20/2022 19:35:39 - INFO - __main__ - save last model!
05/20/2022 19:35:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 19:35:39 - INFO - __main__ - Start tokenizing ... 5509 instances
05/20/2022 19:35:39 - INFO - __main__ - Printing 3 examples
05/20/2022 19:35:39 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/20/2022 19:35:39 - INFO - __main__ - ['others']
05/20/2022 19:35:39 - INFO - __main__ -  [emo] what you like very little things ok
05/20/2022 19:35:39 - INFO - __main__ - ['others']
05/20/2022 19:35:39 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/20/2022 19:35:39 - INFO - __main__ - ['others']
05/20/2022 19:35:39 - INFO - __main__ - Tokenizing Input ...
05/20/2022 19:35:41 - INFO - __main__ - Tokenizing Output ...
05/20/2022 19:35:47 - INFO - __main__ - Loaded 5509 examples from test data
05/20/2022 19:36:31 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.2_8_predictions.txt
05/20/2022 19:36:31 - INFO - __main__ - Classification-F1 on test data: 0.0428
05/20/2022 19:36:32 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.2091503267973856, test_performance=0.04281145790239352
05/30/2022 00:44:58 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/30/2022 00:44:58 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo
05/30/2022 00:44:58 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/30/2022 00:44:58 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo
05/30/2022 00:44:59 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/30/2022 00:44:59 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/30/2022 00:44:59 - INFO - __main__ - args.device: cuda:0
05/30/2022 00:44:59 - INFO - __main__ - Using 2 gpus
05/30/2022 00:44:59 - INFO - __main__ - args.device: cuda:1
05/30/2022 00:44:59 - INFO - __main__ - Using 2 gpus
05/30/2022 00:44:59 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/30/2022 00:44:59 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/30/2022 00:45:03 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
05/30/2022 00:45:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:45:04 - INFO - __main__ - Printing 3 examples
05/30/2022 00:45:04 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:45:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:45:04 - INFO - __main__ - Printing 3 examples
05/30/2022 00:45:04 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:45:04 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 00:45:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:45:04 - INFO - __main__ - Printing 3 examples
05/30/2022 00:45:04 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:45:04 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 00:45:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:45:04 - INFO - __main__ - Printing 3 examples
05/30/2022 00:45:04 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 00:45:04 - INFO - __main__ - ['others']
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:45:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:45:04 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 00:45:04 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 00:45:10 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 00:45:10 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 00:45:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 00:45:11 - INFO - __main__ - Starting training!
05/30/2022 00:45:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 00:45:16 - INFO - __main__ - Starting training!
05/30/2022 00:45:17 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=2
05/30/2022 00:45:19 - INFO - __main__ - Step 20 Global step 20 Train loss 6.44 on epoch=4
05/30/2022 00:45:20 - INFO - __main__ - Step 30 Global step 30 Train loss 6.36 on epoch=7
05/30/2022 00:45:21 - INFO - __main__ - Step 40 Global step 40 Train loss 5.90 on epoch=9
05/30/2022 00:45:22 - INFO - __main__ - Step 50 Global step 50 Train loss 5.57 on epoch=12
05/30/2022 00:45:24 - INFO - __main__ - Global step 50 Train loss 6.19 Classification-F1 0.0 on epoch=12
05/30/2022 00:45:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 00:45:25 - INFO - __main__ - Step 60 Global step 60 Train loss 5.52 on epoch=14
05/30/2022 00:45:27 - INFO - __main__ - Step 70 Global step 70 Train loss 5.19 on epoch=17
05/30/2022 00:45:28 - INFO - __main__ - Step 80 Global step 80 Train loss 4.85 on epoch=19
05/30/2022 00:45:29 - INFO - __main__ - Step 90 Global step 90 Train loss 4.60 on epoch=22
05/30/2022 00:45:30 - INFO - __main__ - Step 100 Global step 100 Train loss 4.31 on epoch=24
05/30/2022 00:45:31 - INFO - __main__ - Global step 100 Train loss 4.90 Classification-F1 0.06015037593984963 on epoch=24
05/30/2022 00:45:31 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06015037593984963 on epoch=24, global_step=100
05/30/2022 00:45:32 - INFO - __main__ - Step 110 Global step 110 Train loss 4.12 on epoch=27
05/30/2022 00:45:34 - INFO - __main__ - Step 120 Global step 120 Train loss 3.90 on epoch=29
05/30/2022 00:45:35 - INFO - __main__ - Step 130 Global step 130 Train loss 3.71 on epoch=32
05/30/2022 00:45:36 - INFO - __main__ - Step 140 Global step 140 Train loss 3.49 on epoch=34
05/30/2022 00:45:37 - INFO - __main__ - Step 150 Global step 150 Train loss 3.28 on epoch=37
05/30/2022 00:45:39 - INFO - __main__ - Global step 150 Train loss 3.70 Classification-F1 0.13660130718954247 on epoch=37
05/30/2022 00:45:39 - INFO - __main__ - Saving model with best Classification-F1: 0.06015037593984963 -> 0.13660130718954247 on epoch=37, global_step=150
05/30/2022 00:45:41 - INFO - __main__ - Step 160 Global step 160 Train loss 3.03 on epoch=39
05/30/2022 00:45:42 - INFO - __main__ - Step 170 Global step 170 Train loss 3.15 on epoch=42
05/30/2022 00:45:43 - INFO - __main__ - Step 180 Global step 180 Train loss 2.93 on epoch=44
05/30/2022 00:45:44 - INFO - __main__ - Step 190 Global step 190 Train loss 3.09 on epoch=47
05/30/2022 00:45:45 - INFO - __main__ - Step 200 Global step 200 Train loss 2.84 on epoch=49
05/30/2022 00:45:46 - INFO - __main__ - Global step 200 Train loss 3.01 Classification-F1 0.1 on epoch=49
05/30/2022 00:45:47 - INFO - __main__ - Step 210 Global step 210 Train loss 2.91 on epoch=52
05/30/2022 00:45:48 - INFO - __main__ - Step 220 Global step 220 Train loss 2.73 on epoch=54
05/30/2022 00:45:49 - INFO - __main__ - Step 230 Global step 230 Train loss 2.77 on epoch=57
05/30/2022 00:45:51 - INFO - __main__ - Step 240 Global step 240 Train loss 2.52 on epoch=59
05/30/2022 00:45:52 - INFO - __main__ - Step 250 Global step 250 Train loss 2.65 on epoch=62
05/30/2022 00:45:52 - INFO - __main__ - Global step 250 Train loss 2.71 Classification-F1 0.12417582417582418 on epoch=62
05/30/2022 00:45:54 - INFO - __main__ - Step 260 Global step 260 Train loss 2.42 on epoch=64
05/30/2022 00:45:55 - INFO - __main__ - Step 270 Global step 270 Train loss 2.36 on epoch=67
05/30/2022 00:45:56 - INFO - __main__ - Step 280 Global step 280 Train loss 2.39 on epoch=69
05/30/2022 00:45:57 - INFO - __main__ - Step 290 Global step 290 Train loss 2.35 on epoch=72
05/30/2022 00:45:58 - INFO - __main__ - Step 300 Global step 300 Train loss 2.16 on epoch=74
05/30/2022 00:45:59 - INFO - __main__ - Global step 300 Train loss 2.34 Classification-F1 0.0974025974025974 on epoch=74
05/30/2022 00:46:00 - INFO - __main__ - Step 310 Global step 310 Train loss 2.39 on epoch=77
05/30/2022 00:46:01 - INFO - __main__ - Step 320 Global step 320 Train loss 2.10 on epoch=79
05/30/2022 00:46:02 - INFO - __main__ - Step 330 Global step 330 Train loss 2.25 on epoch=82
05/30/2022 00:46:04 - INFO - __main__ - Step 340 Global step 340 Train loss 2.02 on epoch=84
05/30/2022 00:46:05 - INFO - __main__ - Step 350 Global step 350 Train loss 2.20 on epoch=87
05/30/2022 00:46:05 - INFO - __main__ - Global step 350 Train loss 2.19 Classification-F1 0.1 on epoch=87
05/30/2022 00:46:07 - INFO - __main__ - Step 360 Global step 360 Train loss 2.10 on epoch=89
05/30/2022 00:46:08 - INFO - __main__ - Step 370 Global step 370 Train loss 2.05 on epoch=92
05/30/2022 00:46:09 - INFO - __main__ - Step 380 Global step 380 Train loss 1.96 on epoch=94
05/30/2022 00:46:10 - INFO - __main__ - Step 390 Global step 390 Train loss 2.09 on epoch=97
05/30/2022 00:46:11 - INFO - __main__ - Step 400 Global step 400 Train loss 1.87 on epoch=99
05/30/2022 00:46:12 - INFO - __main__ - Global step 400 Train loss 2.02 Classification-F1 0.10126582278481013 on epoch=99
05/30/2022 00:46:13 - INFO - __main__ - Step 410 Global step 410 Train loss 1.81 on epoch=102
05/30/2022 00:46:14 - INFO - __main__ - Step 420 Global step 420 Train loss 1.91 on epoch=104
05/30/2022 00:46:16 - INFO - __main__ - Step 430 Global step 430 Train loss 1.91 on epoch=107
05/30/2022 00:46:17 - INFO - __main__ - Step 440 Global step 440 Train loss 1.69 on epoch=109
05/30/2022 00:46:18 - INFO - __main__ - Step 450 Global step 450 Train loss 1.74 on epoch=112
05/30/2022 00:46:19 - INFO - __main__ - Global step 450 Train loss 1.81 Classification-F1 0.10126582278481013 on epoch=112
05/30/2022 00:46:20 - INFO - __main__ - Step 460 Global step 460 Train loss 1.59 on epoch=114
05/30/2022 00:46:21 - INFO - __main__ - Step 470 Global step 470 Train loss 1.95 on epoch=117
05/30/2022 00:46:23 - INFO - __main__ - Step 480 Global step 480 Train loss 1.76 on epoch=119
05/30/2022 00:46:24 - INFO - __main__ - Step 490 Global step 490 Train loss 1.80 on epoch=122
05/30/2022 00:46:25 - INFO - __main__ - Step 500 Global step 500 Train loss 1.84 on epoch=124
05/30/2022 00:46:26 - INFO - __main__ - Global step 500 Train loss 1.79 Classification-F1 0.1 on epoch=124
05/30/2022 00:46:27 - INFO - __main__ - Step 510 Global step 510 Train loss 1.64 on epoch=127
05/30/2022 00:46:28 - INFO - __main__ - Step 520 Global step 520 Train loss 1.49 on epoch=129
05/30/2022 00:46:29 - INFO - __main__ - Step 530 Global step 530 Train loss 1.70 on epoch=132
05/30/2022 00:46:31 - INFO - __main__ - Step 540 Global step 540 Train loss 1.49 on epoch=134
05/30/2022 00:46:32 - INFO - __main__ - Step 550 Global step 550 Train loss 1.51 on epoch=137
05/30/2022 00:46:32 - INFO - __main__ - Global step 550 Train loss 1.56 Classification-F1 0.10126582278481013 on epoch=137
05/30/2022 00:46:34 - INFO - __main__ - Step 560 Global step 560 Train loss 1.48 on epoch=139
05/30/2022 00:46:35 - INFO - __main__ - Step 570 Global step 570 Train loss 1.52 on epoch=142
05/30/2022 00:46:36 - INFO - __main__ - Step 580 Global step 580 Train loss 1.44 on epoch=144
05/30/2022 00:46:37 - INFO - __main__ - Step 590 Global step 590 Train loss 1.45 on epoch=147
05/30/2022 00:46:39 - INFO - __main__ - Step 600 Global step 600 Train loss 1.31 on epoch=149
05/30/2022 00:46:39 - INFO - __main__ - Global step 600 Train loss 1.44 Classification-F1 0.21944444444444447 on epoch=149
05/30/2022 00:46:39 - INFO - __main__ - Saving model with best Classification-F1: 0.13660130718954247 -> 0.21944444444444447 on epoch=149, global_step=600
05/30/2022 00:46:40 - INFO - __main__ - Step 610 Global step 610 Train loss 1.45 on epoch=152
05/30/2022 00:46:42 - INFO - __main__ - Step 620 Global step 620 Train loss 1.43 on epoch=154
05/30/2022 00:46:43 - INFO - __main__ - Step 630 Global step 630 Train loss 1.46 on epoch=157
05/30/2022 00:46:44 - INFO - __main__ - Step 640 Global step 640 Train loss 1.44 on epoch=159
05/30/2022 00:46:45 - INFO - __main__ - Step 650 Global step 650 Train loss 1.39 on epoch=162
05/30/2022 00:46:46 - INFO - __main__ - Global step 650 Train loss 1.43 Classification-F1 0.18284936479128855 on epoch=162
05/30/2022 00:46:47 - INFO - __main__ - Step 660 Global step 660 Train loss 1.50 on epoch=164
05/30/2022 00:46:48 - INFO - __main__ - Step 670 Global step 670 Train loss 1.31 on epoch=167
05/30/2022 00:46:50 - INFO - __main__ - Step 680 Global step 680 Train loss 1.28 on epoch=169
05/30/2022 00:46:51 - INFO - __main__ - Step 690 Global step 690 Train loss 1.42 on epoch=172
05/30/2022 00:46:52 - INFO - __main__ - Step 700 Global step 700 Train loss 1.35 on epoch=174
05/30/2022 00:46:53 - INFO - __main__ - Global step 700 Train loss 1.37 Classification-F1 0.1 on epoch=174
05/30/2022 00:46:54 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=177
05/30/2022 00:46:55 - INFO - __main__ - Step 720 Global step 720 Train loss 1.22 on epoch=179
05/30/2022 00:46:56 - INFO - __main__ - Step 730 Global step 730 Train loss 1.28 on epoch=182
05/30/2022 00:46:58 - INFO - __main__ - Step 740 Global step 740 Train loss 1.32 on epoch=184
05/30/2022 00:46:59 - INFO - __main__ - Step 750 Global step 750 Train loss 1.28 on epoch=187
05/30/2022 00:47:00 - INFO - __main__ - Global step 750 Train loss 1.28 Classification-F1 0.11996779388083736 on epoch=187
05/30/2022 00:47:01 - INFO - __main__ - Step 760 Global step 760 Train loss 1.25 on epoch=189
05/30/2022 00:47:02 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=192
05/30/2022 00:47:03 - INFO - __main__ - Step 780 Global step 780 Train loss 1.29 on epoch=194
05/30/2022 00:47:05 - INFO - __main__ - Step 790 Global step 790 Train loss 1.27 on epoch=197
05/30/2022 00:47:06 - INFO - __main__ - Step 800 Global step 800 Train loss 1.17 on epoch=199
05/30/2022 00:47:06 - INFO - __main__ - Global step 800 Train loss 1.24 Classification-F1 0.19157427937915744 on epoch=199
05/30/2022 00:47:08 - INFO - __main__ - Step 810 Global step 810 Train loss 1.25 on epoch=202
05/30/2022 00:47:09 - INFO - __main__ - Step 820 Global step 820 Train loss 1.12 on epoch=204
05/30/2022 00:47:10 - INFO - __main__ - Step 830 Global step 830 Train loss 1.38 on epoch=207
05/30/2022 00:47:11 - INFO - __main__ - Step 840 Global step 840 Train loss 1.22 on epoch=209
05/30/2022 00:47:13 - INFO - __main__ - Step 850 Global step 850 Train loss 1.18 on epoch=212
05/30/2022 00:47:13 - INFO - __main__ - Global step 850 Train loss 1.23 Classification-F1 0.19267605633802815 on epoch=212
05/30/2022 00:47:14 - INFO - __main__ - Step 860 Global step 860 Train loss 1.25 on epoch=214
05/30/2022 00:47:15 - INFO - __main__ - Step 870 Global step 870 Train loss 1.16 on epoch=217
05/30/2022 00:47:17 - INFO - __main__ - Step 880 Global step 880 Train loss 1.17 on epoch=219
05/30/2022 00:47:18 - INFO - __main__ - Step 890 Global step 890 Train loss 1.12 on epoch=222
05/30/2022 00:47:19 - INFO - __main__ - Step 900 Global step 900 Train loss 1.24 on epoch=224
05/30/2022 00:47:20 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.09090909090909091 on epoch=224
05/30/2022 00:47:21 - INFO - __main__ - Step 910 Global step 910 Train loss 1.11 on epoch=227
05/30/2022 00:47:22 - INFO - __main__ - Step 920 Global step 920 Train loss 1.13 on epoch=229
05/30/2022 00:47:23 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
05/30/2022 00:47:24 - INFO - __main__ - Step 940 Global step 940 Train loss 1.22 on epoch=234
05/30/2022 00:47:26 - INFO - __main__ - Step 950 Global step 950 Train loss 1.12 on epoch=237
05/30/2022 00:47:26 - INFO - __main__ - Global step 950 Train loss 1.20 Classification-F1 0.1 on epoch=237
05/30/2022 00:47:27 - INFO - __main__ - Step 960 Global step 960 Train loss 1.15 on epoch=239
05/30/2022 00:47:29 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=242
05/30/2022 00:47:30 - INFO - __main__ - Step 980 Global step 980 Train loss 1.22 on epoch=244
05/30/2022 00:47:31 - INFO - __main__ - Step 990 Global step 990 Train loss 1.10 on epoch=247
05/30/2022 00:47:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.07 on epoch=249
05/30/2022 00:47:33 - INFO - __main__ - Global step 1000 Train loss 1.13 Classification-F1 0.1 on epoch=249
05/30/2022 00:47:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
05/30/2022 00:47:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.04 on epoch=254
05/30/2022 00:47:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.09 on epoch=257
05/30/2022 00:47:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.09 on epoch=259
05/30/2022 00:47:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=262
05/30/2022 00:47:39 - INFO - __main__ - Global step 1050 Train loss 1.08 Classification-F1 0.1 on epoch=262
05/30/2022 00:47:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=264
05/30/2022 00:47:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.04 on epoch=267
05/30/2022 00:47:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.05 on epoch=269
05/30/2022 00:47:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.16 on epoch=272
05/30/2022 00:47:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.12 on epoch=274
05/30/2022 00:47:46 - INFO - __main__ - Global step 1100 Train loss 1.08 Classification-F1 0.1 on epoch=274
05/30/2022 00:47:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.02 on epoch=277
05/30/2022 00:47:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.10 on epoch=279
05/30/2022 00:47:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.06 on epoch=282
05/30/2022 00:47:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.09 on epoch=284
05/30/2022 00:47:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=287
05/30/2022 00:47:53 - INFO - __main__ - Global step 1150 Train loss 1.08 Classification-F1 0.1 on epoch=287
05/30/2022 00:47:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.05 on epoch=289
05/30/2022 00:47:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.00 on epoch=292
05/30/2022 00:47:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.01 on epoch=294
05/30/2022 00:47:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.93 on epoch=297
05/30/2022 00:47:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.09 on epoch=299
05/30/2022 00:47:59 - INFO - __main__ - Global step 1200 Train loss 1.02 Classification-F1 0.18026315789473685 on epoch=299
05/30/2022 00:48:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.11 on epoch=302
05/30/2022 00:48:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.07 on epoch=304
05/30/2022 00:48:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.97 on epoch=307
05/30/2022 00:48:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.90 on epoch=309
05/30/2022 00:48:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.01 on epoch=312
05/30/2022 00:48:06 - INFO - __main__ - Global step 1250 Train loss 1.01 Classification-F1 0.12407862407862408 on epoch=312
05/30/2022 00:48:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.05 on epoch=314
05/30/2022 00:48:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.10 on epoch=317
05/30/2022 00:48:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.13 on epoch=319
05/30/2022 00:48:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.00 on epoch=322
05/30/2022 00:48:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.00 on epoch=324
05/30/2022 00:48:13 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.12447885646217988 on epoch=324
05/30/2022 00:48:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.92 on epoch=327
05/30/2022 00:48:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.04 on epoch=329
05/30/2022 00:48:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.05 on epoch=332
05/30/2022 00:48:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.06 on epoch=334
05/30/2022 00:48:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.06 on epoch=337
05/30/2022 00:48:20 - INFO - __main__ - Global step 1350 Train loss 1.03 Classification-F1 0.13482414242292662 on epoch=337
05/30/2022 00:48:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/30/2022 00:48:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.00 on epoch=342
05/30/2022 00:48:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/30/2022 00:48:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.11 on epoch=347
05/30/2022 00:48:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.93 on epoch=349
05/30/2022 00:48:26 - INFO - __main__ - Global step 1400 Train loss 1.03 Classification-F1 0.10256410256410256 on epoch=349
05/30/2022 00:48:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.04 on epoch=352
05/30/2022 00:48:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.97 on epoch=354
05/30/2022 00:48:30 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=357
05/30/2022 00:48:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.95 on epoch=359
05/30/2022 00:48:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.06 on epoch=362
05/30/2022 00:48:33 - INFO - __main__ - Global step 1450 Train loss 1.04 Classification-F1 0.19307400379506642 on epoch=362
05/30/2022 00:48:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.04 on epoch=364
05/30/2022 00:48:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.04 on epoch=367
05/30/2022 00:48:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.08 on epoch=369
05/30/2022 00:48:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=372
05/30/2022 00:48:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.92 on epoch=374
05/30/2022 00:48:40 - INFO - __main__ - Global step 1500 Train loss 1.01 Classification-F1 0.1 on epoch=374
05/30/2022 00:48:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.02 on epoch=377
05/30/2022 00:48:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.01 on epoch=379
05/30/2022 00:48:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/30/2022 00:48:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.99 on epoch=384
05/30/2022 00:48:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.96 on epoch=387
05/30/2022 00:48:46 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.2505484861781483 on epoch=387
05/30/2022 00:48:46 - INFO - __main__ - Saving model with best Classification-F1: 0.21944444444444447 -> 0.2505484861781483 on epoch=387, global_step=1550
05/30/2022 00:48:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.00 on epoch=389
05/30/2022 00:48:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
05/30/2022 00:48:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.96 on epoch=394
05/30/2022 00:48:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=397
05/30/2022 00:48:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.98 on epoch=399
05/30/2022 00:48:53 - INFO - __main__ - Global step 1600 Train loss 0.98 Classification-F1 0.1497584541062802 on epoch=399
05/30/2022 00:48:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.00 on epoch=402
05/30/2022 00:48:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/30/2022 00:48:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.96 on epoch=407
05/30/2022 00:48:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.93 on epoch=409
05/30/2022 00:48:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.01 on epoch=412
05/30/2022 00:49:00 - INFO - __main__ - Global step 1650 Train loss 0.98 Classification-F1 0.13034188034188032 on epoch=412
05/30/2022 00:49:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.02 on epoch=414
05/30/2022 00:49:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/30/2022 00:49:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.95 on epoch=419
05/30/2022 00:49:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/30/2022 00:49:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.04 on epoch=424
05/30/2022 00:49:07 - INFO - __main__ - Global step 1700 Train loss 1.02 Classification-F1 0.17809523809523808 on epoch=424
05/30/2022 00:49:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.97 on epoch=427
05/30/2022 00:49:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.87 on epoch=429
05/30/2022 00:49:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.99 on epoch=432
05/30/2022 00:49:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.98 on epoch=434
05/30/2022 00:49:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.95 on epoch=437
05/30/2022 00:49:13 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.16407982261640797 on epoch=437
05/30/2022 00:49:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=439
05/30/2022 00:49:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.97 on epoch=442
05/30/2022 00:49:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.88 on epoch=444
05/30/2022 00:49:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.98 on epoch=447
05/30/2022 00:49:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.97 on epoch=449
05/30/2022 00:49:20 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.17124542124542122 on epoch=449
05/30/2022 00:49:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.87 on epoch=452
05/30/2022 00:49:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.90 on epoch=454
05/30/2022 00:49:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.00 on epoch=457
05/30/2022 00:49:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.04 on epoch=459
05/30/2022 00:49:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.96 on epoch=462
05/30/2022 00:49:27 - INFO - __main__ - Global step 1850 Train loss 0.95 Classification-F1 0.19165085388994307 on epoch=462
05/30/2022 00:49:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/30/2022 00:49:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=467
05/30/2022 00:49:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.94 on epoch=469
05/30/2022 00:49:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.01 on epoch=472
05/30/2022 00:49:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.83 on epoch=474
05/30/2022 00:49:33 - INFO - __main__ - Global step 1900 Train loss 0.93 Classification-F1 0.11612903225806451 on epoch=474
05/30/2022 00:49:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.92 on epoch=477
05/30/2022 00:49:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
05/30/2022 00:49:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
05/30/2022 00:49:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.96 on epoch=484
05/30/2022 00:49:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.83 on epoch=487
05/30/2022 00:49:40 - INFO - __main__ - Global step 1950 Train loss 0.93 Classification-F1 0.12819829424307036 on epoch=487
05/30/2022 00:49:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.94 on epoch=489
05/30/2022 00:49:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.04 on epoch=492
05/30/2022 00:49:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.94 on epoch=494
05/30/2022 00:49:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.90 on epoch=497
05/30/2022 00:49:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.03 on epoch=499
05/30/2022 00:49:47 - INFO - __main__ - Global step 2000 Train loss 0.97 Classification-F1 0.09999999999999999 on epoch=499
05/30/2022 00:49:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.00 on epoch=502
05/30/2022 00:49:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.88 on epoch=504
05/30/2022 00:49:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.94 on epoch=507
05/30/2022 00:49:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.94 on epoch=509
05/30/2022 00:49:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.92 on epoch=512
05/30/2022 00:49:54 - INFO - __main__ - Global step 2050 Train loss 0.94 Classification-F1 0.14642857142857144 on epoch=512
05/30/2022 00:49:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.05 on epoch=514
05/30/2022 00:49:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.97 on epoch=517
05/30/2022 00:49:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.02 on epoch=519
05/30/2022 00:49:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.87 on epoch=522
05/30/2022 00:50:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.92 on epoch=524
05/30/2022 00:50:00 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.15782608695652173 on epoch=524
05/30/2022 00:50:02 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
05/30/2022 00:50:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.89 on epoch=529
05/30/2022 00:50:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.94 on epoch=532
05/30/2022 00:50:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.03 on epoch=534
05/30/2022 00:50:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.93 on epoch=537
05/30/2022 00:50:07 - INFO - __main__ - Global step 2150 Train loss 0.94 Classification-F1 0.16795711733174506 on epoch=537
05/30/2022 00:50:08 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.92 on epoch=539
05/30/2022 00:50:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.94 on epoch=542
05/30/2022 00:50:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
05/30/2022 00:50:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.96 on epoch=547
05/30/2022 00:50:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.95 on epoch=549
05/30/2022 00:50:14 - INFO - __main__ - Global step 2200 Train loss 0.95 Classification-F1 0.15306730196545562 on epoch=549
05/30/2022 00:50:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.95 on epoch=552
05/30/2022 00:50:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.95 on epoch=554
05/30/2022 00:50:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.91 on epoch=557
05/30/2022 00:50:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.91 on epoch=559
05/30/2022 00:50:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.91 on epoch=562
05/30/2022 00:50:20 - INFO - __main__ - Global step 2250 Train loss 0.93 Classification-F1 0.1565452091767881 on epoch=562
05/30/2022 00:50:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.94 on epoch=564
05/30/2022 00:50:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
05/30/2022 00:50:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.92 on epoch=569
05/30/2022 00:50:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/30/2022 00:50:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.89 on epoch=574
05/30/2022 00:50:27 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.14304993252361672 on epoch=574
05/30/2022 00:50:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.99 on epoch=577
05/30/2022 00:50:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.87 on epoch=579
05/30/2022 00:50:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/30/2022 00:50:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/30/2022 00:50:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.96 on epoch=587
05/30/2022 00:50:34 - INFO - __main__ - Global step 2350 Train loss 0.95 Classification-F1 0.22751322751322753 on epoch=587
05/30/2022 00:50:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.85 on epoch=589
05/30/2022 00:50:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.87 on epoch=592
05/30/2022 00:50:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/30/2022 00:50:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
05/30/2022 00:50:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.97 on epoch=599
05/30/2022 00:50:41 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.17489919354838712 on epoch=599
05/30/2022 00:50:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/30/2022 00:50:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/30/2022 00:50:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.99 on epoch=607
05/30/2022 00:50:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/30/2022 00:50:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.90 on epoch=612
05/30/2022 00:50:47 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.13067758749069247 on epoch=612
05/30/2022 00:50:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.94 on epoch=614
05/30/2022 00:50:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.85 on epoch=617
05/30/2022 00:50:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/30/2022 00:50:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.92 on epoch=622
05/30/2022 00:50:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.88 on epoch=624
05/30/2022 00:50:54 - INFO - __main__ - Global step 2500 Train loss 0.92 Classification-F1 0.09615384615384615 on epoch=624
05/30/2022 00:50:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.94 on epoch=627
05/30/2022 00:50:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.87 on epoch=629
05/30/2022 00:50:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.87 on epoch=632
05/30/2022 00:50:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/30/2022 00:51:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/30/2022 00:51:01 - INFO - __main__ - Global step 2550 Train loss 0.90 Classification-F1 0.1640625 on epoch=637
05/30/2022 00:51:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.89 on epoch=639
05/30/2022 00:51:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.86 on epoch=642
05/30/2022 00:51:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/30/2022 00:51:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/30/2022 00:51:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/30/2022 00:51:07 - INFO - __main__ - Global step 2600 Train loss 0.91 Classification-F1 0.15833333333333333 on epoch=649
05/30/2022 00:51:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.95 on epoch=652
05/30/2022 00:51:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/30/2022 00:51:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/30/2022 00:51:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.88 on epoch=659
05/30/2022 00:51:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.89 on epoch=662
05/30/2022 00:51:14 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.1 on epoch=662
05/30/2022 00:51:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.85 on epoch=664
05/30/2022 00:51:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
05/30/2022 00:51:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=669
05/30/2022 00:51:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.89 on epoch=672
05/30/2022 00:51:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.97 on epoch=674
05/30/2022 00:51:21 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.10126582278481013 on epoch=674
05/30/2022 00:51:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.96 on epoch=677
05/30/2022 00:51:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.95 on epoch=679
05/30/2022 00:51:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.97 on epoch=682
05/30/2022 00:51:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/30/2022 00:51:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.02 on epoch=687
05/30/2022 00:51:28 - INFO - __main__ - Global step 2750 Train loss 0.95 Classification-F1 0.1 on epoch=687
05/30/2022 00:51:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/30/2022 00:51:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.83 on epoch=692
05/30/2022 00:51:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/30/2022 00:51:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.86 on epoch=697
05/30/2022 00:51:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.85 on epoch=699
05/30/2022 00:51:34 - INFO - __main__ - Global step 2800 Train loss 0.89 Classification-F1 0.1 on epoch=699
05/30/2022 00:51:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.93 on epoch=702
05/30/2022 00:51:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/30/2022 00:51:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/30/2022 00:51:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.88 on epoch=709
05/30/2022 00:51:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/30/2022 00:51:41 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.16666666666666666 on epoch=712
05/30/2022 00:51:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.88 on epoch=714
05/30/2022 00:51:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.87 on epoch=717
05/30/2022 00:51:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/30/2022 00:51:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
05/30/2022 00:51:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
05/30/2022 00:51:48 - INFO - __main__ - Global step 2900 Train loss 0.90 Classification-F1 0.09868421052631579 on epoch=724
05/30/2022 00:51:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.93 on epoch=727
05/30/2022 00:51:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.86 on epoch=729
05/30/2022 00:51:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.82 on epoch=732
05/30/2022 00:51:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.87 on epoch=734
05/30/2022 00:51:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.88 on epoch=737
05/30/2022 00:51:55 - INFO - __main__ - Global step 2950 Train loss 0.87 Classification-F1 0.15 on epoch=737
05/30/2022 00:51:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.81 on epoch=739
05/30/2022 00:51:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.90 on epoch=742
05/30/2022 00:51:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.90 on epoch=744
05/30/2022 00:52:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.92 on epoch=747
05/30/2022 00:52:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.87 on epoch=749
05/30/2022 00:52:01 - INFO - __main__ - Global step 3000 Train loss 0.88 Classification-F1 0.17569930069930068 on epoch=749
05/30/2022 00:52:01 - INFO - __main__ - save last model!
05/30/2022 00:52:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 00:52:01 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 00:52:01 - INFO - __main__ - Printing 3 examples
05/30/2022 00:52:01 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 00:52:01 - INFO - __main__ - ['others']
05/30/2022 00:52:01 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 00:52:01 - INFO - __main__ - ['others']
05/30/2022 00:52:01 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 00:52:01 - INFO - __main__ - ['others']
05/30/2022 00:52:01 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:52:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:52:02 - INFO - __main__ - Printing 3 examples
05/30/2022 00:52:02 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 00:52:02 - INFO - __main__ - ['others']
05/30/2022 00:52:02 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 00:52:02 - INFO - __main__ - ['others']
05/30/2022 00:52:02 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 00:52:02 - INFO - __main__ - ['others']
05/30/2022 00:52:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:52:02 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:52:02 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 00:52:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:52:02 - INFO - __main__ - Printing 3 examples
05/30/2022 00:52:02 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 00:52:02 - INFO - __main__ - ['others']
05/30/2022 00:52:02 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 00:52:02 - INFO - __main__ - ['others']
05/30/2022 00:52:02 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 00:52:02 - INFO - __main__ - ['others']
05/30/2022 00:52:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:52:02 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:52:02 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 00:52:03 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:52:08 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 00:52:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 00:52:08 - INFO - __main__ - Starting training!
05/30/2022 00:52:09 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 00:52:52 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.5_8_predictions.txt
05/30/2022 00:52:52 - INFO - __main__ - Classification-F1 on test data: 0.0473
05/30/2022 00:52:52 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.2505484861781483, test_performance=0.04729741568112133
05/30/2022 00:52:52 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
05/30/2022 00:52:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:52:53 - INFO - __main__ - Printing 3 examples
05/30/2022 00:52:53 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 00:52:53 - INFO - __main__ - ['others']
05/30/2022 00:52:53 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 00:52:53 - INFO - __main__ - ['others']
05/30/2022 00:52:53 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 00:52:53 - INFO - __main__ - ['others']
05/30/2022 00:52:53 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:52:53 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:52:53 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 00:52:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:52:53 - INFO - __main__ - Printing 3 examples
05/30/2022 00:52:53 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 00:52:53 - INFO - __main__ - ['others']
05/30/2022 00:52:53 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 00:52:53 - INFO - __main__ - ['others']
05/30/2022 00:52:53 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 00:52:53 - INFO - __main__ - ['others']
05/30/2022 00:52:53 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:52:53 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:52:53 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 00:52:59 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 00:52:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 00:52:59 - INFO - __main__ - Starting training!
05/30/2022 00:53:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.76 on epoch=2
05/30/2022 00:53:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/30/2022 00:53:03 - INFO - __main__ - Step 30 Global step 30 Train loss 6.22 on epoch=7
05/30/2022 00:53:04 - INFO - __main__ - Step 40 Global step 40 Train loss 6.03 on epoch=9
05/30/2022 00:53:06 - INFO - __main__ - Step 50 Global step 50 Train loss 5.81 on epoch=12
05/30/2022 00:53:17 - INFO - __main__ - Global step 50 Train loss 6.28 Classification-F1 0.0 on epoch=12
05/30/2022 00:53:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 00:53:18 - INFO - __main__ - Step 60 Global step 60 Train loss 5.64 on epoch=14
05/30/2022 00:53:19 - INFO - __main__ - Step 70 Global step 70 Train loss 5.56 on epoch=17
05/30/2022 00:53:21 - INFO - __main__ - Step 80 Global step 80 Train loss 5.44 on epoch=19
05/30/2022 00:53:22 - INFO - __main__ - Step 90 Global step 90 Train loss 5.10 on epoch=22
05/30/2022 00:53:23 - INFO - __main__ - Step 100 Global step 100 Train loss 4.90 on epoch=24
05/30/2022 00:53:24 - INFO - __main__ - Global step 100 Train loss 5.33 Classification-F1 0.009049773755656108 on epoch=24
05/30/2022 00:53:24 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009049773755656108 on epoch=24, global_step=100
05/30/2022 00:53:26 - INFO - __main__ - Step 110 Global step 110 Train loss 4.73 on epoch=27
05/30/2022 00:53:27 - INFO - __main__ - Step 120 Global step 120 Train loss 4.50 on epoch=29
05/30/2022 00:53:28 - INFO - __main__ - Step 130 Global step 130 Train loss 4.27 on epoch=32
05/30/2022 00:53:29 - INFO - __main__ - Step 140 Global step 140 Train loss 4.05 on epoch=34
05/30/2022 00:53:31 - INFO - __main__ - Step 150 Global step 150 Train loss 3.85 on epoch=37
05/30/2022 00:53:31 - INFO - __main__ - Global step 150 Train loss 4.28 Classification-F1 0.08421052631578949 on epoch=37
05/30/2022 00:53:31 - INFO - __main__ - Saving model with best Classification-F1: 0.009049773755656108 -> 0.08421052631578949 on epoch=37, global_step=150
05/30/2022 00:53:32 - INFO - __main__ - Step 160 Global step 160 Train loss 3.71 on epoch=39
05/30/2022 00:53:34 - INFO - __main__ - Step 170 Global step 170 Train loss 3.72 on epoch=42
05/30/2022 00:53:35 - INFO - __main__ - Step 180 Global step 180 Train loss 3.40 on epoch=44
05/30/2022 00:53:36 - INFO - __main__ - Step 190 Global step 190 Train loss 3.07 on epoch=47
05/30/2022 00:53:37 - INFO - __main__ - Step 200 Global step 200 Train loss 3.10 on epoch=49
05/30/2022 00:53:38 - INFO - __main__ - Global step 200 Train loss 3.40 Classification-F1 0.1237183868762816 on epoch=49
05/30/2022 00:53:38 - INFO - __main__ - Saving model with best Classification-F1: 0.08421052631578949 -> 0.1237183868762816 on epoch=49, global_step=200
05/30/2022 00:53:39 - INFO - __main__ - Step 210 Global step 210 Train loss 2.93 on epoch=52
05/30/2022 00:53:40 - INFO - __main__ - Step 220 Global step 220 Train loss 2.85 on epoch=54
05/30/2022 00:53:42 - INFO - __main__ - Step 230 Global step 230 Train loss 2.78 on epoch=57
05/30/2022 00:53:43 - INFO - __main__ - Step 240 Global step 240 Train loss 2.58 on epoch=59
05/30/2022 00:53:44 - INFO - __main__ - Step 250 Global step 250 Train loss 2.58 on epoch=62
05/30/2022 00:53:45 - INFO - __main__ - Global step 250 Train loss 2.75 Classification-F1 0.09210526315789473 on epoch=62
05/30/2022 00:53:46 - INFO - __main__ - Step 260 Global step 260 Train loss 2.54 on epoch=64
05/30/2022 00:53:47 - INFO - __main__ - Step 270 Global step 270 Train loss 2.51 on epoch=67
05/30/2022 00:53:48 - INFO - __main__ - Step 280 Global step 280 Train loss 2.28 on epoch=69
05/30/2022 00:53:49 - INFO - __main__ - Step 290 Global step 290 Train loss 2.32 on epoch=72
05/30/2022 00:53:51 - INFO - __main__ - Step 300 Global step 300 Train loss 2.19 on epoch=74
05/30/2022 00:53:51 - INFO - __main__ - Global step 300 Train loss 2.37 Classification-F1 0.1527777777777778 on epoch=74
05/30/2022 00:53:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1237183868762816 -> 0.1527777777777778 on epoch=74, global_step=300
05/30/2022 00:53:52 - INFO - __main__ - Step 310 Global step 310 Train loss 2.51 on epoch=77
05/30/2022 00:53:54 - INFO - __main__ - Step 320 Global step 320 Train loss 2.28 on epoch=79
05/30/2022 00:53:55 - INFO - __main__ - Step 330 Global step 330 Train loss 2.18 on epoch=82
05/30/2022 00:53:56 - INFO - __main__ - Step 340 Global step 340 Train loss 2.01 on epoch=84
05/30/2022 00:53:57 - INFO - __main__ - Step 350 Global step 350 Train loss 2.17 on epoch=87
05/30/2022 00:53:58 - INFO - __main__ - Global step 350 Train loss 2.23 Classification-F1 0.1565276828434723 on epoch=87
05/30/2022 00:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1527777777777778 -> 0.1565276828434723 on epoch=87, global_step=350
05/30/2022 00:53:59 - INFO - __main__ - Step 360 Global step 360 Train loss 2.00 on epoch=89
05/30/2022 00:54:00 - INFO - __main__ - Step 370 Global step 370 Train loss 1.95 on epoch=92
05/30/2022 00:54:01 - INFO - __main__ - Step 380 Global step 380 Train loss 1.95 on epoch=94
05/30/2022 00:54:03 - INFO - __main__ - Step 390 Global step 390 Train loss 1.97 on epoch=97
05/30/2022 00:54:04 - INFO - __main__ - Step 400 Global step 400 Train loss 1.79 on epoch=99
05/30/2022 00:54:04 - INFO - __main__ - Global step 400 Train loss 1.93 Classification-F1 0.10234192037470727 on epoch=99
05/30/2022 00:54:06 - INFO - __main__ - Step 410 Global step 410 Train loss 1.96 on epoch=102
05/30/2022 00:54:07 - INFO - __main__ - Step 420 Global step 420 Train loss 1.77 on epoch=104
05/30/2022 00:54:08 - INFO - __main__ - Step 430 Global step 430 Train loss 1.88 on epoch=107
05/30/2022 00:54:09 - INFO - __main__ - Step 440 Global step 440 Train loss 1.66 on epoch=109
05/30/2022 00:54:10 - INFO - __main__ - Step 450 Global step 450 Train loss 1.73 on epoch=112
05/30/2022 00:54:11 - INFO - __main__ - Global step 450 Train loss 1.80 Classification-F1 0.16969147005444646 on epoch=112
05/30/2022 00:54:11 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.16969147005444646 on epoch=112, global_step=450
05/30/2022 00:54:12 - INFO - __main__ - Step 460 Global step 460 Train loss 1.53 on epoch=114
05/30/2022 00:54:13 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=117
05/30/2022 00:54:15 - INFO - __main__ - Step 480 Global step 480 Train loss 1.63 on epoch=119
05/30/2022 00:54:16 - INFO - __main__ - Step 490 Global step 490 Train loss 1.67 on epoch=122
05/30/2022 00:54:17 - INFO - __main__ - Step 500 Global step 500 Train loss 1.67 on epoch=124
05/30/2022 00:54:18 - INFO - __main__ - Global step 500 Train loss 1.64 Classification-F1 0.1 on epoch=124
05/30/2022 00:54:19 - INFO - __main__ - Step 510 Global step 510 Train loss 1.60 on epoch=127
05/30/2022 00:54:20 - INFO - __main__ - Step 520 Global step 520 Train loss 1.44 on epoch=129
05/30/2022 00:54:21 - INFO - __main__ - Step 530 Global step 530 Train loss 1.67 on epoch=132
05/30/2022 00:54:22 - INFO - __main__ - Step 540 Global step 540 Train loss 1.56 on epoch=134
05/30/2022 00:54:24 - INFO - __main__ - Step 550 Global step 550 Train loss 1.42 on epoch=137
05/30/2022 00:54:24 - INFO - __main__ - Global step 550 Train loss 1.54 Classification-F1 0.18643263757115752 on epoch=137
05/30/2022 00:54:24 - INFO - __main__ - Saving model with best Classification-F1: 0.16969147005444646 -> 0.18643263757115752 on epoch=137, global_step=550
05/30/2022 00:54:25 - INFO - __main__ - Step 560 Global step 560 Train loss 1.46 on epoch=139
05/30/2022 00:54:27 - INFO - __main__ - Step 570 Global step 570 Train loss 1.45 on epoch=142
05/30/2022 00:54:28 - INFO - __main__ - Step 580 Global step 580 Train loss 1.40 on epoch=144
05/30/2022 00:54:29 - INFO - __main__ - Step 590 Global step 590 Train loss 1.39 on epoch=147
05/30/2022 00:54:30 - INFO - __main__ - Step 600 Global step 600 Train loss 1.39 on epoch=149
05/30/2022 00:54:31 - INFO - __main__ - Global step 600 Train loss 1.42 Classification-F1 0.1 on epoch=149
05/30/2022 00:54:32 - INFO - __main__ - Step 610 Global step 610 Train loss 1.44 on epoch=152
05/30/2022 00:54:33 - INFO - __main__ - Step 620 Global step 620 Train loss 1.27 on epoch=154
05/30/2022 00:54:34 - INFO - __main__ - Step 630 Global step 630 Train loss 1.33 on epoch=157
05/30/2022 00:54:35 - INFO - __main__ - Step 640 Global step 640 Train loss 1.23 on epoch=159
05/30/2022 00:54:37 - INFO - __main__ - Step 650 Global step 650 Train loss 1.38 on epoch=162
05/30/2022 00:54:37 - INFO - __main__ - Global step 650 Train loss 1.33 Classification-F1 0.10126582278481013 on epoch=162
05/30/2022 00:54:38 - INFO - __main__ - Step 660 Global step 660 Train loss 1.32 on epoch=164
05/30/2022 00:54:40 - INFO - __main__ - Step 670 Global step 670 Train loss 1.29 on epoch=167
05/30/2022 00:54:41 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=169
05/30/2022 00:54:42 - INFO - __main__ - Step 690 Global step 690 Train loss 1.29 on epoch=172
05/30/2022 00:54:43 - INFO - __main__ - Step 700 Global step 700 Train loss 1.29 on epoch=174
05/30/2022 00:54:44 - INFO - __main__ - Global step 700 Train loss 1.29 Classification-F1 0.12399355877616748 on epoch=174
05/30/2022 00:54:45 - INFO - __main__ - Step 710 Global step 710 Train loss 1.35 on epoch=177
05/30/2022 00:54:46 - INFO - __main__ - Step 720 Global step 720 Train loss 1.23 on epoch=179
05/30/2022 00:54:47 - INFO - __main__ - Step 730 Global step 730 Train loss 1.19 on epoch=182
05/30/2022 00:54:48 - INFO - __main__ - Step 740 Global step 740 Train loss 1.20 on epoch=184
05/30/2022 00:54:50 - INFO - __main__ - Step 750 Global step 750 Train loss 1.22 on epoch=187
05/30/2022 00:54:50 - INFO - __main__ - Global step 750 Train loss 1.24 Classification-F1 0.177928916191312 on epoch=187
05/30/2022 00:54:51 - INFO - __main__ - Step 760 Global step 760 Train loss 1.27 on epoch=189
05/30/2022 00:54:53 - INFO - __main__ - Step 770 Global step 770 Train loss 1.29 on epoch=192
05/30/2022 00:54:54 - INFO - __main__ - Step 780 Global step 780 Train loss 1.16 on epoch=194
05/30/2022 00:54:55 - INFO - __main__ - Step 790 Global step 790 Train loss 1.06 on epoch=197
05/30/2022 00:54:56 - INFO - __main__ - Step 800 Global step 800 Train loss 1.19 on epoch=199
05/30/2022 00:54:57 - INFO - __main__ - Global step 800 Train loss 1.19 Classification-F1 0.09999999999999999 on epoch=199
05/30/2022 00:54:58 - INFO - __main__ - Step 810 Global step 810 Train loss 1.18 on epoch=202
05/30/2022 00:54:59 - INFO - __main__ - Step 820 Global step 820 Train loss 1.18 on epoch=204
05/30/2022 00:55:00 - INFO - __main__ - Step 830 Global step 830 Train loss 1.11 on epoch=207
05/30/2022 00:55:01 - INFO - __main__ - Step 840 Global step 840 Train loss 1.14 on epoch=209
05/30/2022 00:55:03 - INFO - __main__ - Step 850 Global step 850 Train loss 1.17 on epoch=212
05/30/2022 00:55:03 - INFO - __main__ - Global step 850 Train loss 1.16 Classification-F1 0.08571428571428572 on epoch=212
05/30/2022 00:55:04 - INFO - __main__ - Step 860 Global step 860 Train loss 1.02 on epoch=214
05/30/2022 00:55:06 - INFO - __main__ - Step 870 Global step 870 Train loss 1.36 on epoch=217
05/30/2022 00:55:07 - INFO - __main__ - Step 880 Global step 880 Train loss 1.14 on epoch=219
05/30/2022 00:55:08 - INFO - __main__ - Step 890 Global step 890 Train loss 1.23 on epoch=222
05/30/2022 00:55:09 - INFO - __main__ - Step 900 Global step 900 Train loss 1.16 on epoch=224
05/30/2022 00:55:10 - INFO - __main__ - Global step 900 Train loss 1.18 Classification-F1 0.13333333333333333 on epoch=224
05/30/2022 00:55:11 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/30/2022 00:55:12 - INFO - __main__ - Step 920 Global step 920 Train loss 1.10 on epoch=229
05/30/2022 00:55:14 - INFO - __main__ - Step 930 Global step 930 Train loss 1.17 on epoch=232
05/30/2022 00:55:15 - INFO - __main__ - Step 940 Global step 940 Train loss 1.17 on epoch=234
05/30/2022 00:55:16 - INFO - __main__ - Step 950 Global step 950 Train loss 1.25 on epoch=237
05/30/2022 00:55:17 - INFO - __main__ - Global step 950 Train loss 1.18 Classification-F1 0.2277777777777778 on epoch=237
05/30/2022 00:55:17 - INFO - __main__ - Saving model with best Classification-F1: 0.18643263757115752 -> 0.2277777777777778 on epoch=237, global_step=950
05/30/2022 00:55:18 - INFO - __main__ - Step 960 Global step 960 Train loss 1.08 on epoch=239
05/30/2022 00:55:19 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=242
05/30/2022 00:55:20 - INFO - __main__ - Step 980 Global step 980 Train loss 1.21 on epoch=244
05/30/2022 00:55:22 - INFO - __main__ - Step 990 Global step 990 Train loss 1.04 on epoch=247
05/30/2022 00:55:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.06 on epoch=249
05/30/2022 00:55:23 - INFO - __main__ - Global step 1000 Train loss 1.11 Classification-F1 0.09493670886075949 on epoch=249
05/30/2022 00:55:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.07 on epoch=252
05/30/2022 00:55:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.10 on epoch=254
05/30/2022 00:55:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/30/2022 00:55:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=259
05/30/2022 00:55:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.10 on epoch=262
05/30/2022 00:55:30 - INFO - __main__ - Global step 1050 Train loss 1.09 Classification-F1 0.1575757575757576 on epoch=262
05/30/2022 00:55:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.10 on epoch=264
05/30/2022 00:55:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=267
05/30/2022 00:55:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/30/2022 00:55:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.21 on epoch=272
05/30/2022 00:55:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
05/30/2022 00:55:36 - INFO - __main__ - Global step 1100 Train loss 1.14 Classification-F1 0.12447885646217988 on epoch=274
05/30/2022 00:55:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.12 on epoch=277
05/30/2022 00:55:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.98 on epoch=279
05/30/2022 00:55:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=282
05/30/2022 00:55:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.10 on epoch=284
05/30/2022 00:55:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.09 on epoch=287
05/30/2022 00:55:43 - INFO - __main__ - Global step 1150 Train loss 1.06 Classification-F1 0.13427800269905532 on epoch=287
05/30/2022 00:55:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.11 on epoch=289
05/30/2022 00:55:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.20 on epoch=292
05/30/2022 00:55:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/30/2022 00:55:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.12 on epoch=297
05/30/2022 00:55:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.05 on epoch=299
05/30/2022 00:55:50 - INFO - __main__ - Global step 1200 Train loss 1.13 Classification-F1 0.1 on epoch=299
05/30/2022 00:55:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.18 on epoch=302
05/30/2022 00:55:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.05 on epoch=304
05/30/2022 00:55:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.10 on epoch=307
05/30/2022 00:55:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
05/30/2022 00:55:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=312
05/30/2022 00:55:56 - INFO - __main__ - Global step 1250 Train loss 1.10 Classification-F1 0.1 on epoch=312
05/30/2022 00:55:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.11 on epoch=314
05/30/2022 00:55:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.17 on epoch=317
05/30/2022 00:56:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.01 on epoch=319
05/30/2022 00:56:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.01 on epoch=322
05/30/2022 00:56:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.14 on epoch=324
05/30/2022 00:56:03 - INFO - __main__ - Global step 1300 Train loss 1.09 Classification-F1 0.13154929577464788 on epoch=324
05/30/2022 00:56:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
05/30/2022 00:56:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.12 on epoch=329
05/30/2022 00:56:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.08 on epoch=332
05/30/2022 00:56:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.95 on epoch=334
05/30/2022 00:56:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.08 on epoch=337
05/30/2022 00:56:09 - INFO - __main__ - Global step 1350 Train loss 1.05 Classification-F1 0.19821428571428573 on epoch=337
05/30/2022 00:56:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.10 on epoch=339
05/30/2022 00:56:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.07 on epoch=342
05/30/2022 00:56:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.02 on epoch=344
05/30/2022 00:56:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
05/30/2022 00:56:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.90 on epoch=349
05/30/2022 00:56:16 - INFO - __main__ - Global step 1400 Train loss 1.05 Classification-F1 0.1774628879892038 on epoch=349
05/30/2022 00:56:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.13 on epoch=352
05/30/2022 00:56:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.94 on epoch=354
05/30/2022 00:56:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.97 on epoch=357
05/30/2022 00:56:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.05 on epoch=359
05/30/2022 00:56:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.07 on epoch=362
05/30/2022 00:56:22 - INFO - __main__ - Global step 1450 Train loss 1.03 Classification-F1 0.14913151364764268 on epoch=362
05/30/2022 00:56:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=364
05/30/2022 00:56:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.98 on epoch=367
05/30/2022 00:56:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
05/30/2022 00:56:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.96 on epoch=372
05/30/2022 00:56:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.06 on epoch=374
05/30/2022 00:56:29 - INFO - __main__ - Global step 1500 Train loss 1.01 Classification-F1 0.13123993558776167 on epoch=374
05/30/2022 00:56:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
05/30/2022 00:56:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/30/2022 00:56:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.04 on epoch=382
05/30/2022 00:56:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.97 on epoch=384
05/30/2022 00:56:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.99 on epoch=387
05/30/2022 00:56:36 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.13482414242292662 on epoch=387
05/30/2022 00:56:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.07 on epoch=389
05/30/2022 00:56:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.01 on epoch=392
05/30/2022 00:56:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.06 on epoch=394
05/30/2022 00:56:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.01 on epoch=397
05/30/2022 00:56:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.97 on epoch=399
05/30/2022 00:56:42 - INFO - __main__ - Global step 1600 Train loss 1.02 Classification-F1 0.16563380281690143 on epoch=399
05/30/2022 00:56:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=402
05/30/2022 00:56:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.89 on epoch=404
05/30/2022 00:56:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.12 on epoch=407
05/30/2022 00:56:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.00 on epoch=409
05/30/2022 00:56:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.03 on epoch=412
05/30/2022 00:56:49 - INFO - __main__ - Global step 1650 Train loss 1.01 Classification-F1 0.17712418300653593 on epoch=412
05/30/2022 00:56:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.89 on epoch=414
05/30/2022 00:56:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.91 on epoch=417
05/30/2022 00:56:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.10 on epoch=419
05/30/2022 00:56:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.94 on epoch=422
05/30/2022 00:56:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.06 on epoch=424
05/30/2022 00:56:55 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.14600840336134455 on epoch=424
05/30/2022 00:56:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.02 on epoch=427
05/30/2022 00:56:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.85 on epoch=429
05/30/2022 00:56:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.03 on epoch=432
05/30/2022 00:57:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.97 on epoch=434
05/30/2022 00:57:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.98 on epoch=437
05/30/2022 00:57:02 - INFO - __main__ - Global step 1750 Train loss 0.97 Classification-F1 0.16137566137566137 on epoch=437
05/30/2022 00:57:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.99 on epoch=439
05/30/2022 00:57:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/30/2022 00:57:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.86 on epoch=444
05/30/2022 00:57:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.93 on epoch=447
05/30/2022 00:57:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
05/30/2022 00:57:08 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.15587044534412953 on epoch=449
05/30/2022 00:57:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.02 on epoch=452
05/30/2022 00:57:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.02 on epoch=454
05/30/2022 00:57:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.98 on epoch=457
05/30/2022 00:57:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=459
05/30/2022 00:57:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/30/2022 00:57:15 - INFO - __main__ - Global step 1850 Train loss 1.02 Classification-F1 0.15682382133995038 on epoch=462
05/30/2022 00:57:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/30/2022 00:57:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=467
05/30/2022 00:57:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=469
05/30/2022 00:57:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/30/2022 00:57:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.95 on epoch=474
05/30/2022 00:57:22 - INFO - __main__ - Global step 1900 Train loss 0.95 Classification-F1 0.12447885646217988 on epoch=474
05/30/2022 00:57:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/30/2022 00:57:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.08 on epoch=479
05/30/2022 00:57:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.95 on epoch=482
05/30/2022 00:57:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/30/2022 00:57:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.09 on epoch=487
05/30/2022 00:57:28 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.20833333333333331 on epoch=487
05/30/2022 00:57:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.89 on epoch=489
05/30/2022 00:57:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=492
05/30/2022 00:57:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.96 on epoch=494
05/30/2022 00:57:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.01 on epoch=497
05/30/2022 00:57:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.91 on epoch=499
05/30/2022 00:57:35 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.13034188034188032 on epoch=499
05/30/2022 00:57:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.90 on epoch=502
05/30/2022 00:57:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.99 on epoch=504
05/30/2022 00:57:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.08 on epoch=507
05/30/2022 00:57:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.92 on epoch=509
05/30/2022 00:57:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.09 on epoch=512
05/30/2022 00:57:41 - INFO - __main__ - Global step 2050 Train loss 1.00 Classification-F1 0.09333333333333334 on epoch=512
05/30/2022 00:57:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.04 on epoch=514
05/30/2022 00:57:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.98 on epoch=517
05/30/2022 00:57:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.94 on epoch=519
05/30/2022 00:57:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.92 on epoch=522
05/30/2022 00:57:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/30/2022 00:57:48 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.09482363719651855 on epoch=524
05/30/2022 00:57:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.86 on epoch=527
05/30/2022 00:57:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
05/30/2022 00:57:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/30/2022 00:57:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.90 on epoch=534
05/30/2022 00:57:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.95 on epoch=537
05/30/2022 00:57:54 - INFO - __main__ - Global step 2150 Train loss 0.94 Classification-F1 0.10126582278481013 on epoch=537
05/30/2022 00:57:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
05/30/2022 00:57:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.87 on epoch=542
05/30/2022 00:57:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.92 on epoch=544
05/30/2022 00:57:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.95 on epoch=547
05/30/2022 00:58:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.03 on epoch=549
05/30/2022 00:58:01 - INFO - __main__ - Global step 2200 Train loss 0.94 Classification-F1 0.09615384615384615 on epoch=549
05/30/2022 00:58:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.04 on epoch=552
05/30/2022 00:58:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.89 on epoch=554
05/30/2022 00:58:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=557
05/30/2022 00:58:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.95 on epoch=559
05/30/2022 00:58:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.04 on epoch=562
05/30/2022 00:58:07 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.13251935675997617 on epoch=562
05/30/2022 00:58:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.86 on epoch=564
05/30/2022 00:58:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.91 on epoch=567
05/30/2022 00:58:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/30/2022 00:58:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
05/30/2022 00:58:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.03 on epoch=574
05/30/2022 00:58:14 - INFO - __main__ - Global step 2300 Train loss 0.95 Classification-F1 0.09391534391534392 on epoch=574
05/30/2022 00:58:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/30/2022 00:58:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.92 on epoch=579
05/30/2022 00:58:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.04 on epoch=582
05/30/2022 00:58:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/30/2022 00:58:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.05 on epoch=587
05/30/2022 00:58:20 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.18614718614718614 on epoch=587
05/30/2022 00:58:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.91 on epoch=589
05/30/2022 00:58:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/30/2022 00:58:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.93 on epoch=594
05/30/2022 00:58:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.01 on epoch=597
05/30/2022 00:58:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.84 on epoch=599
05/30/2022 00:58:27 - INFO - __main__ - Global step 2400 Train loss 0.93 Classification-F1 0.15188470066518847 on epoch=599
05/30/2022 00:58:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/30/2022 00:58:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/30/2022 00:58:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.98 on epoch=607
05/30/2022 00:58:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.94 on epoch=609
05/30/2022 00:58:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.95 on epoch=612
05/30/2022 00:58:34 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.15306730196545562 on epoch=612
05/30/2022 00:58:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.90 on epoch=614
05/30/2022 00:58:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/30/2022 00:58:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.91 on epoch=619
05/30/2022 00:58:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.91 on epoch=622
05/30/2022 00:58:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.90 on epoch=624
05/30/2022 00:58:40 - INFO - __main__ - Global step 2500 Train loss 0.93 Classification-F1 0.09493670886075949 on epoch=624
05/30/2022 00:58:41 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=627
05/30/2022 00:58:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.93 on epoch=629
05/30/2022 00:58:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.92 on epoch=632
05/30/2022 00:58:45 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.90 on epoch=634
05/30/2022 00:58:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
05/30/2022 00:58:47 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.1486842105263158 on epoch=637
05/30/2022 00:58:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.86 on epoch=639
05/30/2022 00:58:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.84 on epoch=642
05/30/2022 00:58:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.86 on epoch=644
05/30/2022 00:58:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/30/2022 00:58:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.88 on epoch=649
05/30/2022 00:58:53 - INFO - __main__ - Global step 2600 Train loss 0.89 Classification-F1 0.09285714285714285 on epoch=649
05/30/2022 00:58:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.07 on epoch=652
05/30/2022 00:58:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.87 on epoch=654
05/30/2022 00:58:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.87 on epoch=657
05/30/2022 00:58:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.93 on epoch=659
05/30/2022 00:59:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/30/2022 00:59:00 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.15306730196545562 on epoch=662
05/30/2022 00:59:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.08 on epoch=664
05/30/2022 00:59:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/30/2022 00:59:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
05/30/2022 00:59:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.99 on epoch=672
05/30/2022 00:59:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/30/2022 00:59:07 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.1458966565349544 on epoch=674
05/30/2022 00:59:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/30/2022 00:59:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.86 on epoch=679
05/30/2022 00:59:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/30/2022 00:59:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.91 on epoch=684
05/30/2022 00:59:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.92 on epoch=687
05/30/2022 00:59:13 - INFO - __main__ - Global step 2750 Train loss 0.91 Classification-F1 0.18623481781376516 on epoch=687
05/30/2022 00:59:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
05/30/2022 00:59:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
05/30/2022 00:59:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.86 on epoch=694
05/30/2022 00:59:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
05/30/2022 00:59:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.86 on epoch=699
05/30/2022 00:59:20 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.10023419203747073 on epoch=699
05/30/2022 00:59:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.86 on epoch=702
05/30/2022 00:59:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/30/2022 00:59:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.05 on epoch=707
05/30/2022 00:59:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.84 on epoch=709
05/30/2022 00:59:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=712
05/30/2022 00:59:26 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.13859154929577466 on epoch=712
05/30/2022 00:59:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.92 on epoch=714
05/30/2022 00:59:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.97 on epoch=717
05/30/2022 00:59:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/30/2022 00:59:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.91 on epoch=722
05/30/2022 00:59:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
05/30/2022 00:59:33 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.16923774954627951 on epoch=724
05/30/2022 00:59:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.96 on epoch=727
05/30/2022 00:59:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.97 on epoch=729
05/30/2022 00:59:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
05/30/2022 00:59:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.00 on epoch=734
05/30/2022 00:59:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.79 on epoch=737
05/30/2022 00:59:40 - INFO - __main__ - Global step 2950 Train loss 0.92 Classification-F1 0.11805555555555555 on epoch=737
05/30/2022 00:59:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.06 on epoch=739
05/30/2022 00:59:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.85 on epoch=742
05/30/2022 00:59:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.92 on epoch=744
05/30/2022 00:59:45 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.87 on epoch=747
05/30/2022 00:59:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.81 on epoch=749
05/30/2022 00:59:47 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.12521739130434784 on epoch=749
05/30/2022 00:59:47 - INFO - __main__ - save last model!
05/30/2022 00:59:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 00:59:47 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 00:59:47 - INFO - __main__ - Printing 3 examples
05/30/2022 00:59:47 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:59:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:59:47 - INFO - __main__ - Printing 3 examples
05/30/2022 00:59:47 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:59:47 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:59:47 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 00:59:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 00:59:47 - INFO - __main__ - Printing 3 examples
05/30/2022 00:59:47 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 00:59:47 - INFO - __main__ - ['others']
05/30/2022 00:59:47 - INFO - __main__ - Tokenizing Input ...
05/30/2022 00:59:47 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:59:47 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 00:59:49 - INFO - __main__ - Tokenizing Output ...
05/30/2022 00:59:53 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 00:59:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 00:59:54 - INFO - __main__ - Starting training!
05/30/2022 00:59:54 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:00:37 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.4_8_predictions.txt
05/30/2022 01:00:37 - INFO - __main__ - Classification-F1 on test data: 0.0438
05/30/2022 01:00:37 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.2277777777777778, test_performance=0.043761291883696464
05/30/2022 01:00:37 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
05/30/2022 01:00:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:00:38 - INFO - __main__ - Printing 3 examples
05/30/2022 01:00:38 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 01:00:38 - INFO - __main__ - ['others']
05/30/2022 01:00:38 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 01:00:38 - INFO - __main__ - ['others']
05/30/2022 01:00:38 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 01:00:38 - INFO - __main__ - ['others']
05/30/2022 01:00:38 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:00:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:00:38 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:00:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:00:38 - INFO - __main__ - Printing 3 examples
05/30/2022 01:00:38 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 01:00:38 - INFO - __main__ - ['others']
05/30/2022 01:00:38 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 01:00:38 - INFO - __main__ - ['others']
05/30/2022 01:00:38 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 01:00:38 - INFO - __main__ - ['others']
05/30/2022 01:00:38 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:00:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:00:39 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:00:44 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:00:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:00:44 - INFO - __main__ - Starting training!
05/30/2022 01:00:46 - INFO - __main__ - Step 10 Global step 10 Train loss 6.95 on epoch=2
05/30/2022 01:00:47 - INFO - __main__ - Step 20 Global step 20 Train loss 6.55 on epoch=4
05/30/2022 01:00:48 - INFO - __main__ - Step 30 Global step 30 Train loss 6.14 on epoch=7
05/30/2022 01:00:49 - INFO - __main__ - Step 40 Global step 40 Train loss 6.17 on epoch=9
05/30/2022 01:00:51 - INFO - __main__ - Step 50 Global step 50 Train loss 5.94 on epoch=12
05/30/2022 01:00:52 - INFO - __main__ - Global step 50 Train loss 6.35 Classification-F1 0.0 on epoch=12
05/30/2022 01:00:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:00:53 - INFO - __main__ - Step 60 Global step 60 Train loss 5.78 on epoch=14
05/30/2022 01:00:55 - INFO - __main__ - Step 70 Global step 70 Train loss 5.65 on epoch=17
05/30/2022 01:00:56 - INFO - __main__ - Step 80 Global step 80 Train loss 5.50 on epoch=19
05/30/2022 01:00:57 - INFO - __main__ - Step 90 Global step 90 Train loss 5.36 on epoch=22
05/30/2022 01:00:58 - INFO - __main__ - Step 100 Global step 100 Train loss 5.17 on epoch=24
05/30/2022 01:01:00 - INFO - __main__ - Global step 100 Train loss 5.49 Classification-F1 0.0 on epoch=24
05/30/2022 01:01:01 - INFO - __main__ - Step 110 Global step 110 Train loss 5.02 on epoch=27
05/30/2022 01:01:02 - INFO - __main__ - Step 120 Global step 120 Train loss 5.06 on epoch=29
05/30/2022 01:01:04 - INFO - __main__ - Step 130 Global step 130 Train loss 4.80 on epoch=32
05/30/2022 01:01:05 - INFO - __main__ - Step 140 Global step 140 Train loss 4.65 on epoch=34
05/30/2022 01:01:06 - INFO - __main__ - Step 150 Global step 150 Train loss 4.62 on epoch=37
05/30/2022 01:01:07 - INFO - __main__ - Global step 150 Train loss 4.83 Classification-F1 0.03214285714285714 on epoch=37
05/30/2022 01:01:07 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03214285714285714 on epoch=37, global_step=150
05/30/2022 01:01:08 - INFO - __main__ - Step 160 Global step 160 Train loss 4.34 on epoch=39
05/30/2022 01:01:09 - INFO - __main__ - Step 170 Global step 170 Train loss 4.31 on epoch=42
05/30/2022 01:01:11 - INFO - __main__ - Step 180 Global step 180 Train loss 4.13 on epoch=44
05/30/2022 01:01:12 - INFO - __main__ - Step 190 Global step 190 Train loss 4.19 on epoch=47
05/30/2022 01:01:13 - INFO - __main__ - Step 200 Global step 200 Train loss 4.07 on epoch=49
05/30/2022 01:01:14 - INFO - __main__ - Global step 200 Train loss 4.21 Classification-F1 0.16666666666666666 on epoch=49
05/30/2022 01:01:14 - INFO - __main__ - Saving model with best Classification-F1: 0.03214285714285714 -> 0.16666666666666666 on epoch=49, global_step=200
05/30/2022 01:01:15 - INFO - __main__ - Step 210 Global step 210 Train loss 4.01 on epoch=52
05/30/2022 01:01:16 - INFO - __main__ - Step 220 Global step 220 Train loss 3.76 on epoch=54
05/30/2022 01:01:17 - INFO - __main__ - Step 230 Global step 230 Train loss 3.65 on epoch=57
05/30/2022 01:01:18 - INFO - __main__ - Step 240 Global step 240 Train loss 3.55 on epoch=59
05/30/2022 01:01:20 - INFO - __main__ - Step 250 Global step 250 Train loss 3.40 on epoch=62
05/30/2022 01:01:20 - INFO - __main__ - Global step 250 Train loss 3.67 Classification-F1 0.09333333333333334 on epoch=62
05/30/2022 01:01:21 - INFO - __main__ - Step 260 Global step 260 Train loss 3.50 on epoch=64
05/30/2022 01:01:23 - INFO - __main__ - Step 270 Global step 270 Train loss 3.47 on epoch=67
05/30/2022 01:01:24 - INFO - __main__ - Step 280 Global step 280 Train loss 3.13 on epoch=69
05/30/2022 01:01:25 - INFO - __main__ - Step 290 Global step 290 Train loss 3.28 on epoch=72
05/30/2022 01:01:26 - INFO - __main__ - Step 300 Global step 300 Train loss 3.00 on epoch=74
05/30/2022 01:01:27 - INFO - __main__ - Global step 300 Train loss 3.28 Classification-F1 0.11507936507936507 on epoch=74
05/30/2022 01:01:28 - INFO - __main__ - Step 310 Global step 310 Train loss 3.09 on epoch=77
05/30/2022 01:01:29 - INFO - __main__ - Step 320 Global step 320 Train loss 2.96 on epoch=79
05/30/2022 01:01:30 - INFO - __main__ - Step 330 Global step 330 Train loss 3.06 on epoch=82
05/30/2022 01:01:32 - INFO - __main__ - Step 340 Global step 340 Train loss 2.88 on epoch=84
05/30/2022 01:01:33 - INFO - __main__ - Step 350 Global step 350 Train loss 2.76 on epoch=87
05/30/2022 01:01:33 - INFO - __main__ - Global step 350 Train loss 2.95 Classification-F1 0.14383875400824553 on epoch=87
05/30/2022 01:01:34 - INFO - __main__ - Step 360 Global step 360 Train loss 2.76 on epoch=89
05/30/2022 01:01:36 - INFO - __main__ - Step 370 Global step 370 Train loss 2.83 on epoch=92
05/30/2022 01:01:37 - INFO - __main__ - Step 380 Global step 380 Train loss 2.71 on epoch=94
05/30/2022 01:01:38 - INFO - __main__ - Step 390 Global step 390 Train loss 2.70 on epoch=97
05/30/2022 01:01:39 - INFO - __main__ - Step 400 Global step 400 Train loss 2.60 on epoch=99
05/30/2022 01:01:40 - INFO - __main__ - Global step 400 Train loss 2.72 Classification-F1 0.1 on epoch=99
05/30/2022 01:01:41 - INFO - __main__ - Step 410 Global step 410 Train loss 2.69 on epoch=102
05/30/2022 01:01:42 - INFO - __main__ - Step 420 Global step 420 Train loss 2.57 on epoch=104
05/30/2022 01:01:43 - INFO - __main__ - Step 430 Global step 430 Train loss 2.54 on epoch=107
05/30/2022 01:01:45 - INFO - __main__ - Step 440 Global step 440 Train loss 2.25 on epoch=109
05/30/2022 01:01:46 - INFO - __main__ - Step 450 Global step 450 Train loss 2.34 on epoch=112
05/30/2022 01:01:46 - INFO - __main__ - Global step 450 Train loss 2.48 Classification-F1 0.1 on epoch=112
05/30/2022 01:01:47 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=114
05/30/2022 01:01:49 - INFO - __main__ - Step 470 Global step 470 Train loss 2.38 on epoch=117
05/30/2022 01:01:50 - INFO - __main__ - Step 480 Global step 480 Train loss 2.24 on epoch=119
05/30/2022 01:01:51 - INFO - __main__ - Step 490 Global step 490 Train loss 2.23 on epoch=122
05/30/2022 01:01:52 - INFO - __main__ - Step 500 Global step 500 Train loss 2.16 on epoch=124
05/30/2022 01:01:53 - INFO - __main__ - Global step 500 Train loss 2.27 Classification-F1 0.1238095238095238 on epoch=124
05/30/2022 01:01:54 - INFO - __main__ - Step 510 Global step 510 Train loss 2.07 on epoch=127
05/30/2022 01:01:55 - INFO - __main__ - Step 520 Global step 520 Train loss 2.16 on epoch=129
05/30/2022 01:01:57 - INFO - __main__ - Step 530 Global step 530 Train loss 2.05 on epoch=132
05/30/2022 01:01:58 - INFO - __main__ - Step 540 Global step 540 Train loss 2.00 on epoch=134
05/30/2022 01:01:59 - INFO - __main__ - Step 550 Global step 550 Train loss 2.13 on epoch=137
05/30/2022 01:02:00 - INFO - __main__ - Global step 550 Train loss 2.08 Classification-F1 0.18614718614718614 on epoch=137
05/30/2022 01:02:00 - INFO - __main__ - Saving model with best Classification-F1: 0.16666666666666666 -> 0.18614718614718614 on epoch=137, global_step=550
05/30/2022 01:02:01 - INFO - __main__ - Step 560 Global step 560 Train loss 1.98 on epoch=139
05/30/2022 01:02:02 - INFO - __main__ - Step 570 Global step 570 Train loss 1.98 on epoch=142
05/30/2022 01:02:03 - INFO - __main__ - Step 580 Global step 580 Train loss 1.89 on epoch=144
05/30/2022 01:02:04 - INFO - __main__ - Step 590 Global step 590 Train loss 1.89 on epoch=147
05/30/2022 01:02:06 - INFO - __main__ - Step 600 Global step 600 Train loss 1.86 on epoch=149
05/30/2022 01:02:06 - INFO - __main__ - Global step 600 Train loss 1.92 Classification-F1 0.1 on epoch=149
05/30/2022 01:02:07 - INFO - __main__ - Step 610 Global step 610 Train loss 2.11 on epoch=152
05/30/2022 01:02:09 - INFO - __main__ - Step 620 Global step 620 Train loss 1.94 on epoch=154
05/30/2022 01:02:10 - INFO - __main__ - Step 630 Global step 630 Train loss 1.99 on epoch=157
05/30/2022 01:02:11 - INFO - __main__ - Step 640 Global step 640 Train loss 1.79 on epoch=159
05/30/2022 01:02:12 - INFO - __main__ - Step 650 Global step 650 Train loss 1.75 on epoch=162
05/30/2022 01:02:13 - INFO - __main__ - Global step 650 Train loss 1.91 Classification-F1 0.189010989010989 on epoch=162
05/30/2022 01:02:13 - INFO - __main__ - Saving model with best Classification-F1: 0.18614718614718614 -> 0.189010989010989 on epoch=162, global_step=650
05/30/2022 01:02:14 - INFO - __main__ - Step 660 Global step 660 Train loss 1.75 on epoch=164
05/30/2022 01:02:15 - INFO - __main__ - Step 670 Global step 670 Train loss 1.67 on epoch=167
05/30/2022 01:02:16 - INFO - __main__ - Step 680 Global step 680 Train loss 1.65 on epoch=169
05/30/2022 01:02:18 - INFO - __main__ - Step 690 Global step 690 Train loss 1.77 on epoch=172
05/30/2022 01:02:19 - INFO - __main__ - Step 700 Global step 700 Train loss 1.75 on epoch=174
05/30/2022 01:02:19 - INFO - __main__ - Global step 700 Train loss 1.72 Classification-F1 0.09493670886075949 on epoch=174
05/30/2022 01:02:20 - INFO - __main__ - Step 710 Global step 710 Train loss 1.71 on epoch=177
05/30/2022 01:02:22 - INFO - __main__ - Step 720 Global step 720 Train loss 1.50 on epoch=179
05/30/2022 01:02:23 - INFO - __main__ - Step 730 Global step 730 Train loss 1.57 on epoch=182
05/30/2022 01:02:24 - INFO - __main__ - Step 740 Global step 740 Train loss 1.64 on epoch=184
05/30/2022 01:02:25 - INFO - __main__ - Step 750 Global step 750 Train loss 1.60 on epoch=187
05/30/2022 01:02:26 - INFO - __main__ - Global step 750 Train loss 1.60 Classification-F1 0.16223908918406071 on epoch=187
05/30/2022 01:02:27 - INFO - __main__ - Step 760 Global step 760 Train loss 1.51 on epoch=189
05/30/2022 01:02:28 - INFO - __main__ - Step 770 Global step 770 Train loss 1.46 on epoch=192
05/30/2022 01:02:29 - INFO - __main__ - Step 780 Global step 780 Train loss 1.47 on epoch=194
05/30/2022 01:02:31 - INFO - __main__ - Step 790 Global step 790 Train loss 1.57 on epoch=197
05/30/2022 01:02:32 - INFO - __main__ - Step 800 Global step 800 Train loss 1.50 on epoch=199
05/30/2022 01:02:32 - INFO - __main__ - Global step 800 Train loss 1.50 Classification-F1 0.20714285714285713 on epoch=199
05/30/2022 01:02:32 - INFO - __main__ - Saving model with best Classification-F1: 0.189010989010989 -> 0.20714285714285713 on epoch=199, global_step=800
05/30/2022 01:02:34 - INFO - __main__ - Step 810 Global step 810 Train loss 1.48 on epoch=202
05/30/2022 01:02:35 - INFO - __main__ - Step 820 Global step 820 Train loss 1.52 on epoch=204
05/30/2022 01:02:36 - INFO - __main__ - Step 830 Global step 830 Train loss 1.43 on epoch=207
05/30/2022 01:02:37 - INFO - __main__ - Step 840 Global step 840 Train loss 1.39 on epoch=209
05/30/2022 01:02:38 - INFO - __main__ - Step 850 Global step 850 Train loss 1.47 on epoch=212
05/30/2022 01:02:39 - INFO - __main__ - Global step 850 Train loss 1.46 Classification-F1 0.19270833333333334 on epoch=212
05/30/2022 01:02:40 - INFO - __main__ - Step 860 Global step 860 Train loss 1.25 on epoch=214
05/30/2022 01:02:41 - INFO - __main__ - Step 870 Global step 870 Train loss 1.53 on epoch=217
05/30/2022 01:02:43 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
05/30/2022 01:02:44 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
05/30/2022 01:02:45 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
05/30/2022 01:02:45 - INFO - __main__ - Global step 900 Train loss 1.39 Classification-F1 0.13067758749069247 on epoch=224
05/30/2022 01:02:47 - INFO - __main__ - Step 910 Global step 910 Train loss 1.41 on epoch=227
05/30/2022 01:02:48 - INFO - __main__ - Step 920 Global step 920 Train loss 1.32 on epoch=229
05/30/2022 01:02:49 - INFO - __main__ - Step 930 Global step 930 Train loss 1.30 on epoch=232
05/30/2022 01:02:50 - INFO - __main__ - Step 940 Global step 940 Train loss 1.23 on epoch=234
05/30/2022 01:02:51 - INFO - __main__ - Step 950 Global step 950 Train loss 1.39 on epoch=237
05/30/2022 01:02:52 - INFO - __main__ - Global step 950 Train loss 1.33 Classification-F1 0.1 on epoch=237
05/30/2022 01:02:53 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/30/2022 01:02:54 - INFO - __main__ - Step 970 Global step 970 Train loss 1.39 on epoch=242
05/30/2022 01:02:56 - INFO - __main__ - Step 980 Global step 980 Train loss 1.37 on epoch=244
05/30/2022 01:02:57 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=247
05/30/2022 01:02:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.30 on epoch=249
05/30/2022 01:02:58 - INFO - __main__ - Global step 1000 Train loss 1.33 Classification-F1 0.18318622882517405 on epoch=249
05/30/2022 01:03:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.44 on epoch=252
05/30/2022 01:03:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.44 on epoch=254
05/30/2022 01:03:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.33 on epoch=257
05/30/2022 01:03:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.32 on epoch=259
05/30/2022 01:03:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.31 on epoch=262
05/30/2022 01:03:05 - INFO - __main__ - Global step 1050 Train loss 1.36 Classification-F1 0.13936867182846935 on epoch=262
05/30/2022 01:03:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.23 on epoch=264
05/30/2022 01:03:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.19 on epoch=267
05/30/2022 01:03:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.33 on epoch=269
05/30/2022 01:03:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.30 on epoch=272
05/30/2022 01:03:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.24 on epoch=274
05/30/2022 01:03:12 - INFO - __main__ - Global step 1100 Train loss 1.26 Classification-F1 0.1 on epoch=274
05/30/2022 01:03:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/30/2022 01:03:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.37 on epoch=279
05/30/2022 01:03:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.29 on epoch=282
05/30/2022 01:03:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.34 on epoch=284
05/30/2022 01:03:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.27 on epoch=287
05/30/2022 01:03:18 - INFO - __main__ - Global step 1150 Train loss 1.30 Classification-F1 0.1 on epoch=287
05/30/2022 01:03:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.32 on epoch=289
05/30/2022 01:03:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.18 on epoch=292
05/30/2022 01:03:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.17 on epoch=294
05/30/2022 01:03:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.20 on epoch=297
05/30/2022 01:03:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.25 on epoch=299
05/30/2022 01:03:25 - INFO - __main__ - Global step 1200 Train loss 1.22 Classification-F1 0.1 on epoch=299
05/30/2022 01:03:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.19 on epoch=302
05/30/2022 01:03:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.22 on epoch=304
05/30/2022 01:03:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.23 on epoch=307
05/30/2022 01:03:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/30/2022 01:03:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.13 on epoch=312
05/30/2022 01:03:31 - INFO - __main__ - Global step 1250 Train loss 1.19 Classification-F1 0.1 on epoch=312
05/30/2022 01:03:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.22 on epoch=314
05/30/2022 01:03:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.12 on epoch=317
05/30/2022 01:03:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.02 on epoch=319
05/30/2022 01:03:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.37 on epoch=322
05/30/2022 01:03:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.14 on epoch=324
05/30/2022 01:03:38 - INFO - __main__ - Global step 1300 Train loss 1.17 Classification-F1 0.1 on epoch=324
05/30/2022 01:03:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.09 on epoch=327
05/30/2022 01:03:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.21 on epoch=329
05/30/2022 01:03:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=332
05/30/2022 01:03:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.12 on epoch=334
05/30/2022 01:03:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.18 on epoch=337
05/30/2022 01:03:44 - INFO - __main__ - Global step 1350 Train loss 1.16 Classification-F1 0.1 on epoch=337
05/30/2022 01:03:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.09 on epoch=339
05/30/2022 01:03:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.23 on epoch=342
05/30/2022 01:03:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/30/2022 01:03:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.05 on epoch=347
05/30/2022 01:03:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.10 on epoch=349
05/30/2022 01:03:51 - INFO - __main__ - Global step 1400 Train loss 1.11 Classification-F1 0.1 on epoch=349
05/30/2022 01:03:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.08 on epoch=352
05/30/2022 01:03:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.12 on epoch=354
05/30/2022 01:03:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.30 on epoch=357
05/30/2022 01:03:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.14 on epoch=359
05/30/2022 01:03:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.20 on epoch=362
05/30/2022 01:03:57 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.13034188034188032 on epoch=362
05/30/2022 01:03:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.03 on epoch=364
05/30/2022 01:04:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.12 on epoch=367
05/30/2022 01:04:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.00 on epoch=369
05/30/2022 01:04:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.21 on epoch=372
05/30/2022 01:04:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.11 on epoch=374
05/30/2022 01:04:04 - INFO - __main__ - Global step 1500 Train loss 1.09 Classification-F1 0.13197586726998492 on epoch=374
05/30/2022 01:04:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.18 on epoch=377
05/30/2022 01:04:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
05/30/2022 01:04:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
05/30/2022 01:04:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
05/30/2022 01:04:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=387
05/30/2022 01:04:10 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.1581196581196581 on epoch=387
05/30/2022 01:04:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.10 on epoch=389
05/30/2022 01:04:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=392
05/30/2022 01:04:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.05 on epoch=394
05/30/2022 01:04:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
05/30/2022 01:04:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.11 on epoch=399
05/30/2022 01:04:17 - INFO - __main__ - Global step 1600 Train loss 1.11 Classification-F1 0.23552022689953725 on epoch=399
05/30/2022 01:04:17 - INFO - __main__ - Saving model with best Classification-F1: 0.20714285714285713 -> 0.23552022689953725 on epoch=399, global_step=1600
05/30/2022 01:04:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=402
05/30/2022 01:04:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/30/2022 01:04:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.12 on epoch=407
05/30/2022 01:04:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.21 on epoch=409
05/30/2022 01:04:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/30/2022 01:04:23 - INFO - __main__ - Global step 1650 Train loss 1.10 Classification-F1 0.1 on epoch=412
05/30/2022 01:04:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.06 on epoch=414
05/30/2022 01:04:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.16 on epoch=417
05/30/2022 01:04:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
05/30/2022 01:04:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/30/2022 01:04:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.00 on epoch=424
05/30/2022 01:04:30 - INFO - __main__ - Global step 1700 Train loss 1.06 Classification-F1 0.08783783783783784 on epoch=424
05/30/2022 01:04:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.13 on epoch=427
05/30/2022 01:04:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
05/30/2022 01:04:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.13 on epoch=432
05/30/2022 01:04:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=434
05/30/2022 01:04:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.14 on epoch=437
05/30/2022 01:04:36 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.07857142857142856 on epoch=437
05/30/2022 01:04:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.98 on epoch=439
05/30/2022 01:04:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.05 on epoch=442
05/30/2022 01:04:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.05 on epoch=444
05/30/2022 01:04:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/30/2022 01:04:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.95 on epoch=449
05/30/2022 01:04:43 - INFO - __main__ - Global step 1800 Train loss 1.02 Classification-F1 0.14304519526107942 on epoch=449
05/30/2022 01:04:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.08 on epoch=452
05/30/2022 01:04:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.10 on epoch=454
05/30/2022 01:04:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.09 on epoch=457
05/30/2022 01:04:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.01 on epoch=459
05/30/2022 01:04:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=462
05/30/2022 01:04:49 - INFO - __main__ - Global step 1850 Train loss 1.05 Classification-F1 0.1575934721714773 on epoch=462
05/30/2022 01:04:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.02 on epoch=464
05/30/2022 01:04:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.18 on epoch=467
05/30/2022 01:04:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.08 on epoch=469
05/30/2022 01:04:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.03 on epoch=472
05/30/2022 01:04:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.06 on epoch=474
05/30/2022 01:04:56 - INFO - __main__ - Global step 1900 Train loss 1.07 Classification-F1 0.10126582278481013 on epoch=474
05/30/2022 01:04:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.04 on epoch=477
05/30/2022 01:04:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.00 on epoch=479
05/30/2022 01:05:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.03 on epoch=482
05/30/2022 01:05:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/30/2022 01:05:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.96 on epoch=487
05/30/2022 01:05:03 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.1 on epoch=487
05/30/2022 01:05:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=489
05/30/2022 01:05:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=492
05/30/2022 01:05:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.93 on epoch=494
05/30/2022 01:05:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
05/30/2022 01:05:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.99 on epoch=499
05/30/2022 01:05:09 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.1 on epoch=499
05/30/2022 01:05:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.09 on epoch=502
05/30/2022 01:05:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.96 on epoch=504
05/30/2022 01:05:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.06 on epoch=507
05/30/2022 01:05:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/30/2022 01:05:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.05 on epoch=512
05/30/2022 01:05:16 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.1 on epoch=512
05/30/2022 01:05:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/30/2022 01:05:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/30/2022 01:05:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.08 on epoch=519
05/30/2022 01:05:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
05/30/2022 01:05:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.02 on epoch=524
05/30/2022 01:05:22 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.1 on epoch=524
05/30/2022 01:05:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.99 on epoch=527
05/30/2022 01:05:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.99 on epoch=529
05/30/2022 01:05:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.09 on epoch=532
05/30/2022 01:05:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=534
05/30/2022 01:05:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.02 on epoch=537
05/30/2022 01:05:29 - INFO - __main__ - Global step 2150 Train loss 1.03 Classification-F1 0.14621798689696247 on epoch=537
05/30/2022 01:05:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.97 on epoch=539
05/30/2022 01:05:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.98 on epoch=542
05/30/2022 01:05:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.98 on epoch=544
05/30/2022 01:05:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/30/2022 01:05:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.01 on epoch=549
05/30/2022 01:05:35 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.1595890410958904 on epoch=549
05/30/2022 01:05:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/30/2022 01:05:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.93 on epoch=554
05/30/2022 01:05:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/30/2022 01:05:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/30/2022 01:05:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.94 on epoch=562
05/30/2022 01:05:42 - INFO - __main__ - Global step 2250 Train loss 0.97 Classification-F1 0.15328054298642532 on epoch=562
05/30/2022 01:05:43 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.97 on epoch=564
05/30/2022 01:05:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.92 on epoch=567
05/30/2022 01:05:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.08 on epoch=569
05/30/2022 01:05:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
05/30/2022 01:05:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/30/2022 01:05:48 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.12393162393162392 on epoch=574
05/30/2022 01:05:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.01 on epoch=577
05/30/2022 01:05:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/30/2022 01:05:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.96 on epoch=582
05/30/2022 01:05:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/30/2022 01:05:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/30/2022 01:05:55 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=587
05/30/2022 01:05:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.99 on epoch=589
05/30/2022 01:05:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/30/2022 01:05:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
05/30/2022 01:06:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.05 on epoch=597
05/30/2022 01:06:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.06 on epoch=599
05/30/2022 01:06:02 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.11710526315789474 on epoch=599
05/30/2022 01:06:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/30/2022 01:06:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.01 on epoch=604
05/30/2022 01:06:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
05/30/2022 01:06:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/30/2022 01:06:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.02 on epoch=612
05/30/2022 01:06:08 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=612
05/30/2022 01:06:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.04 on epoch=614
05/30/2022 01:06:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=617
05/30/2022 01:06:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/30/2022 01:06:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.06 on epoch=622
05/30/2022 01:06:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.92 on epoch=624
05/30/2022 01:06:15 - INFO - __main__ - Global step 2500 Train loss 1.01 Classification-F1 0.1238095238095238 on epoch=624
05/30/2022 01:06:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.20 on epoch=627
05/30/2022 01:06:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.87 on epoch=629
05/30/2022 01:06:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.04 on epoch=632
05/30/2022 01:06:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/30/2022 01:06:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=637
05/30/2022 01:06:21 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.13047619047619047 on epoch=637
05/30/2022 01:06:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
05/30/2022 01:06:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
05/30/2022 01:06:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/30/2022 01:06:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
05/30/2022 01:06:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
05/30/2022 01:06:28 - INFO - __main__ - Global step 2600 Train loss 1.00 Classification-F1 0.1554709658157934 on epoch=649
05/30/2022 01:06:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/30/2022 01:06:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
05/30/2022 01:06:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/30/2022 01:06:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/30/2022 01:06:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.01 on epoch=662
05/30/2022 01:06:34 - INFO - __main__ - Global step 2650 Train loss 0.99 Classification-F1 0.17220843672456576 on epoch=662
05/30/2022 01:06:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.97 on epoch=664
05/30/2022 01:06:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.92 on epoch=667
05/30/2022 01:06:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
05/30/2022 01:06:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=672
05/30/2022 01:06:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/30/2022 01:06:41 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.1255656108597285 on epoch=674
05/30/2022 01:06:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.95 on epoch=677
05/30/2022 01:06:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.02 on epoch=679
05/30/2022 01:06:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.93 on epoch=682
05/30/2022 01:06:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=684
05/30/2022 01:06:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=687
05/30/2022 01:06:48 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.13067758749069247 on epoch=687
05/30/2022 01:06:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.96 on epoch=689
05/30/2022 01:06:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.88 on epoch=692
05/30/2022 01:06:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.03 on epoch=694
05/30/2022 01:06:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.04 on epoch=697
05/30/2022 01:06:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.99 on epoch=699
05/30/2022 01:06:54 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.1468058968058968 on epoch=699
05/30/2022 01:06:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.02 on epoch=702
05/30/2022 01:06:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/30/2022 01:06:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.96 on epoch=707
05/30/2022 01:06:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.91 on epoch=709
05/30/2022 01:07:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
05/30/2022 01:07:01 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.1 on epoch=712
05/30/2022 01:07:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.95 on epoch=714
05/30/2022 01:07:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.05 on epoch=717
05/30/2022 01:07:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.87 on epoch=719
05/30/2022 01:07:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.92 on epoch=722
05/30/2022 01:07:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/30/2022 01:07:07 - INFO - __main__ - Global step 2900 Train loss 0.96 Classification-F1 0.16795711733174506 on epoch=724
05/30/2022 01:07:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.02 on epoch=727
05/30/2022 01:07:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.92 on epoch=729
05/30/2022 01:07:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.93 on epoch=732
05/30/2022 01:07:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/30/2022 01:07:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.96 on epoch=737
05/30/2022 01:07:14 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.1 on epoch=737
05/30/2022 01:07:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.89 on epoch=739
05/30/2022 01:07:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.92 on epoch=742
05/30/2022 01:07:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.02 on epoch=744
05/30/2022 01:07:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/30/2022 01:07:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.82 on epoch=749
05/30/2022 01:07:20 - INFO - __main__ - Global step 3000 Train loss 0.93 Classification-F1 0.13067758749069247 on epoch=749
05/30/2022 01:07:20 - INFO - __main__ - save last model!
05/30/2022 01:07:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 01:07:20 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 01:07:20 - INFO - __main__ - Printing 3 examples
05/30/2022 01:07:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 01:07:20 - INFO - __main__ - ['others']
05/30/2022 01:07:20 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 01:07:20 - INFO - __main__ - ['others']
05/30/2022 01:07:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 01:07:20 - INFO - __main__ - ['others']
05/30/2022 01:07:20 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:07:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:07:21 - INFO - __main__ - Printing 3 examples
05/30/2022 01:07:21 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 01:07:21 - INFO - __main__ - ['others']
05/30/2022 01:07:21 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 01:07:21 - INFO - __main__ - ['others']
05/30/2022 01:07:21 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 01:07:21 - INFO - __main__ - ['others']
05/30/2022 01:07:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:07:21 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:07:21 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:07:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:07:21 - INFO - __main__ - Printing 3 examples
05/30/2022 01:07:21 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 01:07:21 - INFO - __main__ - ['others']
05/30/2022 01:07:21 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 01:07:21 - INFO - __main__ - ['others']
05/30/2022 01:07:21 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 01:07:21 - INFO - __main__ - ['others']
05/30/2022 01:07:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:07:21 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:07:21 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:07:22 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:07:27 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:07:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:07:27 - INFO - __main__ - Starting training!
05/30/2022 01:07:28 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:08:11 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.3_8_predictions.txt
05/30/2022 01:08:11 - INFO - __main__ - Classification-F1 on test data: 0.0343
05/30/2022 01:08:11 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.23552022689953725, test_performance=0.03427363395026725
05/30/2022 01:08:11 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
05/30/2022 01:08:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:08:12 - INFO - __main__ - Printing 3 examples
05/30/2022 01:08:12 - INFO - __main__ -  [emo] how cause yes am listening
05/30/2022 01:08:12 - INFO - __main__ - ['others']
05/30/2022 01:08:12 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/30/2022 01:08:12 - INFO - __main__ - ['others']
05/30/2022 01:08:12 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/30/2022 01:08:12 - INFO - __main__ - ['others']
05/30/2022 01:08:12 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:08:12 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:08:12 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:08:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:08:12 - INFO - __main__ - Printing 3 examples
05/30/2022 01:08:12 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/30/2022 01:08:12 - INFO - __main__ - ['others']
05/30/2022 01:08:12 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/30/2022 01:08:12 - INFO - __main__ - ['others']
05/30/2022 01:08:12 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/30/2022 01:08:12 - INFO - __main__ - ['others']
05/30/2022 01:08:12 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:08:12 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:08:13 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:08:18 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:08:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:08:18 - INFO - __main__ - Starting training!
05/30/2022 01:08:19 - INFO - __main__ - Step 10 Global step 10 Train loss 6.77 on epoch=2
05/30/2022 01:08:21 - INFO - __main__ - Step 20 Global step 20 Train loss 6.71 on epoch=4
05/30/2022 01:08:22 - INFO - __main__ - Step 30 Global step 30 Train loss 6.51 on epoch=7
05/30/2022 01:08:23 - INFO - __main__ - Step 40 Global step 40 Train loss 6.45 on epoch=9
05/30/2022 01:08:24 - INFO - __main__ - Step 50 Global step 50 Train loss 6.20 on epoch=12
05/30/2022 01:08:28 - INFO - __main__ - Global step 50 Train loss 6.53 Classification-F1 0.0 on epoch=12
05/30/2022 01:08:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:08:30 - INFO - __main__ - Step 60 Global step 60 Train loss 6.13 on epoch=14
05/30/2022 01:08:31 - INFO - __main__ - Step 70 Global step 70 Train loss 6.18 on epoch=17
05/30/2022 01:08:32 - INFO - __main__ - Step 80 Global step 80 Train loss 6.06 on epoch=19
05/30/2022 01:08:33 - INFO - __main__ - Step 90 Global step 90 Train loss 5.79 on epoch=22
05/30/2022 01:08:34 - INFO - __main__ - Step 100 Global step 100 Train loss 5.63 on epoch=24
05/30/2022 01:08:37 - INFO - __main__ - Global step 100 Train loss 5.96 Classification-F1 0.0 on epoch=24
05/30/2022 01:08:38 - INFO - __main__ - Step 110 Global step 110 Train loss 5.50 on epoch=27
05/30/2022 01:08:39 - INFO - __main__ - Step 120 Global step 120 Train loss 5.51 on epoch=29
05/30/2022 01:08:40 - INFO - __main__ - Step 130 Global step 130 Train loss 5.35 on epoch=32
05/30/2022 01:08:42 - INFO - __main__ - Step 140 Global step 140 Train loss 5.23 on epoch=34
05/30/2022 01:08:43 - INFO - __main__ - Step 150 Global step 150 Train loss 5.16 on epoch=37
05/30/2022 01:08:44 - INFO - __main__ - Global step 150 Train loss 5.35 Classification-F1 0.0 on epoch=37
05/30/2022 01:08:46 - INFO - __main__ - Step 160 Global step 160 Train loss 4.96 on epoch=39
05/30/2022 01:08:47 - INFO - __main__ - Step 170 Global step 170 Train loss 4.82 on epoch=42
05/30/2022 01:08:48 - INFO - __main__ - Step 180 Global step 180 Train loss 4.84 on epoch=44
05/30/2022 01:08:49 - INFO - __main__ - Step 190 Global step 190 Train loss 4.62 on epoch=47
05/30/2022 01:08:50 - INFO - __main__ - Step 200 Global step 200 Train loss 4.73 on epoch=49
05/30/2022 01:08:53 - INFO - __main__ - Global step 200 Train loss 4.79 Classification-F1 0.0 on epoch=49
05/30/2022 01:08:55 - INFO - __main__ - Step 210 Global step 210 Train loss 4.56 on epoch=52
05/30/2022 01:08:56 - INFO - __main__ - Step 220 Global step 220 Train loss 4.47 on epoch=54
05/30/2022 01:08:57 - INFO - __main__ - Step 230 Global step 230 Train loss 4.43 on epoch=57
05/30/2022 01:08:58 - INFO - __main__ - Step 240 Global step 240 Train loss 4.29 on epoch=59
05/30/2022 01:08:59 - INFO - __main__ - Step 250 Global step 250 Train loss 4.30 on epoch=62
05/30/2022 01:09:00 - INFO - __main__ - Global step 250 Train loss 4.41 Classification-F1 0.06111801242236026 on epoch=62
05/30/2022 01:09:00 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06111801242236026 on epoch=62, global_step=250
05/30/2022 01:09:01 - INFO - __main__ - Step 260 Global step 260 Train loss 4.22 on epoch=64
05/30/2022 01:09:03 - INFO - __main__ - Step 270 Global step 270 Train loss 4.17 on epoch=67
05/30/2022 01:09:04 - INFO - __main__ - Step 280 Global step 280 Train loss 4.00 on epoch=69
05/30/2022 01:09:05 - INFO - __main__ - Step 290 Global step 290 Train loss 4.01 on epoch=72
05/30/2022 01:09:06 - INFO - __main__ - Step 300 Global step 300 Train loss 4.05 on epoch=74
05/30/2022 01:09:07 - INFO - __main__ - Global step 300 Train loss 4.09 Classification-F1 0.08206896551724137 on epoch=74
05/30/2022 01:09:07 - INFO - __main__ - Saving model with best Classification-F1: 0.06111801242236026 -> 0.08206896551724137 on epoch=74, global_step=300
05/30/2022 01:09:08 - INFO - __main__ - Step 310 Global step 310 Train loss 3.81 on epoch=77
05/30/2022 01:09:09 - INFO - __main__ - Step 320 Global step 320 Train loss 3.74 on epoch=79
05/30/2022 01:09:11 - INFO - __main__ - Step 330 Global step 330 Train loss 3.89 on epoch=82
05/30/2022 01:09:12 - INFO - __main__ - Step 340 Global step 340 Train loss 3.60 on epoch=84
05/30/2022 01:09:13 - INFO - __main__ - Step 350 Global step 350 Train loss 3.72 on epoch=87
05/30/2022 01:09:13 - INFO - __main__ - Global step 350 Train loss 3.75 Classification-F1 0.1081904761904762 on epoch=87
05/30/2022 01:09:13 - INFO - __main__ - Saving model with best Classification-F1: 0.08206896551724137 -> 0.1081904761904762 on epoch=87, global_step=350
05/30/2022 01:09:15 - INFO - __main__ - Step 360 Global step 360 Train loss 3.51 on epoch=89
05/30/2022 01:09:16 - INFO - __main__ - Step 370 Global step 370 Train loss 3.51 on epoch=92
05/30/2022 01:09:17 - INFO - __main__ - Step 380 Global step 380 Train loss 3.49 on epoch=94
05/30/2022 01:09:18 - INFO - __main__ - Step 390 Global step 390 Train loss 3.69 on epoch=97
05/30/2022 01:09:19 - INFO - __main__ - Step 400 Global step 400 Train loss 3.47 on epoch=99
05/30/2022 01:09:21 - INFO - __main__ - Global step 400 Train loss 3.53 Classification-F1 0.07344632768361581 on epoch=99
05/30/2022 01:09:22 - INFO - __main__ - Step 410 Global step 410 Train loss 3.42 on epoch=102
05/30/2022 01:09:23 - INFO - __main__ - Step 420 Global step 420 Train loss 3.36 on epoch=104
05/30/2022 01:09:24 - INFO - __main__ - Step 430 Global step 430 Train loss 3.29 on epoch=107
05/30/2022 01:09:26 - INFO - __main__ - Step 440 Global step 440 Train loss 2.97 on epoch=109
05/30/2022 01:09:27 - INFO - __main__ - Step 450 Global step 450 Train loss 3.31 on epoch=112
05/30/2022 01:09:27 - INFO - __main__ - Global step 450 Train loss 3.27 Classification-F1 0.05555555555555556 on epoch=112
05/30/2022 01:09:28 - INFO - __main__ - Step 460 Global step 460 Train loss 3.15 on epoch=114
05/30/2022 01:09:30 - INFO - __main__ - Step 470 Global step 470 Train loss 3.19 on epoch=117
05/30/2022 01:09:31 - INFO - __main__ - Step 480 Global step 480 Train loss 3.02 on epoch=119
05/30/2022 01:09:32 - INFO - __main__ - Step 490 Global step 490 Train loss 3.00 on epoch=122
05/30/2022 01:09:33 - INFO - __main__ - Step 500 Global step 500 Train loss 2.94 on epoch=124
05/30/2022 01:09:34 - INFO - __main__ - Global step 500 Train loss 3.06 Classification-F1 0.1 on epoch=124
05/30/2022 01:09:35 - INFO - __main__ - Step 510 Global step 510 Train loss 3.08 on epoch=127
05/30/2022 01:09:36 - INFO - __main__ - Step 520 Global step 520 Train loss 3.01 on epoch=129
05/30/2022 01:09:37 - INFO - __main__ - Step 530 Global step 530 Train loss 2.99 on epoch=132
05/30/2022 01:09:39 - INFO - __main__ - Step 540 Global step 540 Train loss 2.85 on epoch=134
05/30/2022 01:09:40 - INFO - __main__ - Step 550 Global step 550 Train loss 2.99 on epoch=137
05/30/2022 01:09:40 - INFO - __main__ - Global step 550 Train loss 2.98 Classification-F1 0.13026315789473686 on epoch=137
05/30/2022 01:09:40 - INFO - __main__ - Saving model with best Classification-F1: 0.1081904761904762 -> 0.13026315789473686 on epoch=137, global_step=550
05/30/2022 01:09:42 - INFO - __main__ - Step 560 Global step 560 Train loss 2.76 on epoch=139
05/30/2022 01:09:43 - INFO - __main__ - Step 570 Global step 570 Train loss 2.90 on epoch=142
05/30/2022 01:09:44 - INFO - __main__ - Step 580 Global step 580 Train loss 2.78 on epoch=144
05/30/2022 01:09:45 - INFO - __main__ - Step 590 Global step 590 Train loss 2.66 on epoch=147
05/30/2022 01:09:46 - INFO - __main__ - Step 600 Global step 600 Train loss 2.80 on epoch=149
05/30/2022 01:09:47 - INFO - __main__ - Global step 600 Train loss 2.78 Classification-F1 0.1 on epoch=149
05/30/2022 01:09:48 - INFO - __main__ - Step 610 Global step 610 Train loss 2.74 on epoch=152
05/30/2022 01:09:49 - INFO - __main__ - Step 620 Global step 620 Train loss 2.49 on epoch=154
05/30/2022 01:09:50 - INFO - __main__ - Step 630 Global step 630 Train loss 2.53 on epoch=157
05/30/2022 01:09:52 - INFO - __main__ - Step 640 Global step 640 Train loss 2.58 on epoch=159
05/30/2022 01:09:53 - INFO - __main__ - Step 650 Global step 650 Train loss 2.59 on epoch=162
05/30/2022 01:09:53 - INFO - __main__ - Global step 650 Train loss 2.59 Classification-F1 0.13034188034188032 on epoch=162
05/30/2022 01:09:53 - INFO - __main__ - Saving model with best Classification-F1: 0.13026315789473686 -> 0.13034188034188032 on epoch=162, global_step=650
05/30/2022 01:09:54 - INFO - __main__ - Step 660 Global step 660 Train loss 2.47 on epoch=164
05/30/2022 01:09:56 - INFO - __main__ - Step 670 Global step 670 Train loss 2.79 on epoch=167
05/30/2022 01:09:57 - INFO - __main__ - Step 680 Global step 680 Train loss 2.38 on epoch=169
05/30/2022 01:09:58 - INFO - __main__ - Step 690 Global step 690 Train loss 2.66 on epoch=172
05/30/2022 01:09:59 - INFO - __main__ - Step 700 Global step 700 Train loss 2.45 on epoch=174
05/30/2022 01:10:00 - INFO - __main__ - Global step 700 Train loss 2.55 Classification-F1 0.1 on epoch=174
05/30/2022 01:10:01 - INFO - __main__ - Step 710 Global step 710 Train loss 2.56 on epoch=177
05/30/2022 01:10:02 - INFO - __main__ - Step 720 Global step 720 Train loss 2.49 on epoch=179
05/30/2022 01:10:03 - INFO - __main__ - Step 730 Global step 730 Train loss 2.46 on epoch=182
05/30/2022 01:10:05 - INFO - __main__ - Step 740 Global step 740 Train loss 2.25 on epoch=184
05/30/2022 01:10:06 - INFO - __main__ - Step 750 Global step 750 Train loss 2.37 on epoch=187
05/30/2022 01:10:06 - INFO - __main__ - Global step 750 Train loss 2.43 Classification-F1 0.10256410256410256 on epoch=187
05/30/2022 01:10:08 - INFO - __main__ - Step 760 Global step 760 Train loss 2.43 on epoch=189
05/30/2022 01:10:09 - INFO - __main__ - Step 770 Global step 770 Train loss 2.34 on epoch=192
05/30/2022 01:10:10 - INFO - __main__ - Step 780 Global step 780 Train loss 2.30 on epoch=194
05/30/2022 01:10:11 - INFO - __main__ - Step 790 Global step 790 Train loss 2.35 on epoch=197
05/30/2022 01:10:12 - INFO - __main__ - Step 800 Global step 800 Train loss 2.28 on epoch=199
05/30/2022 01:10:13 - INFO - __main__ - Global step 800 Train loss 2.34 Classification-F1 0.16695652173913045 on epoch=199
05/30/2022 01:10:13 - INFO - __main__ - Saving model with best Classification-F1: 0.13034188034188032 -> 0.16695652173913045 on epoch=199, global_step=800
05/30/2022 01:10:14 - INFO - __main__ - Step 810 Global step 810 Train loss 2.09 on epoch=202
05/30/2022 01:10:15 - INFO - __main__ - Step 820 Global step 820 Train loss 2.19 on epoch=204
05/30/2022 01:10:16 - INFO - __main__ - Step 830 Global step 830 Train loss 2.27 on epoch=207
05/30/2022 01:10:18 - INFO - __main__ - Step 840 Global step 840 Train loss 2.23 on epoch=209
05/30/2022 01:10:19 - INFO - __main__ - Step 850 Global step 850 Train loss 2.28 on epoch=212
05/30/2022 01:10:19 - INFO - __main__ - Global step 850 Train loss 2.21 Classification-F1 0.15339578454332553 on epoch=212
05/30/2022 01:10:21 - INFO - __main__ - Step 860 Global step 860 Train loss 2.08 on epoch=214
05/30/2022 01:10:22 - INFO - __main__ - Step 870 Global step 870 Train loss 2.21 on epoch=217
05/30/2022 01:10:23 - INFO - __main__ - Step 880 Global step 880 Train loss 2.05 on epoch=219
05/30/2022 01:10:24 - INFO - __main__ - Step 890 Global step 890 Train loss 2.09 on epoch=222
05/30/2022 01:10:25 - INFO - __main__ - Step 900 Global step 900 Train loss 2.08 on epoch=224
05/30/2022 01:10:26 - INFO - __main__ - Global step 900 Train loss 2.10 Classification-F1 0.18623481781376516 on epoch=224
05/30/2022 01:10:26 - INFO - __main__ - Saving model with best Classification-F1: 0.16695652173913045 -> 0.18623481781376516 on epoch=224, global_step=900
05/30/2022 01:10:27 - INFO - __main__ - Step 910 Global step 910 Train loss 2.09 on epoch=227
05/30/2022 01:10:28 - INFO - __main__ - Step 920 Global step 920 Train loss 2.04 on epoch=229
05/30/2022 01:10:30 - INFO - __main__ - Step 930 Global step 930 Train loss 2.14 on epoch=232
05/30/2022 01:10:31 - INFO - __main__ - Step 940 Global step 940 Train loss 2.06 on epoch=234
05/30/2022 01:10:32 - INFO - __main__ - Step 950 Global step 950 Train loss 2.12 on epoch=237
05/30/2022 01:10:32 - INFO - __main__ - Global step 950 Train loss 2.09 Classification-F1 0.217858709960509 on epoch=237
05/30/2022 01:10:33 - INFO - __main__ - Saving model with best Classification-F1: 0.18623481781376516 -> 0.217858709960509 on epoch=237, global_step=950
05/30/2022 01:10:34 - INFO - __main__ - Step 960 Global step 960 Train loss 2.09 on epoch=239
05/30/2022 01:10:35 - INFO - __main__ - Step 970 Global step 970 Train loss 2.11 on epoch=242
05/30/2022 01:10:36 - INFO - __main__ - Step 980 Global step 980 Train loss 1.91 on epoch=244
05/30/2022 01:10:37 - INFO - __main__ - Step 990 Global step 990 Train loss 1.83 on epoch=247
05/30/2022 01:10:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.96 on epoch=249
05/30/2022 01:10:39 - INFO - __main__ - Global step 1000 Train loss 1.98 Classification-F1 0.16464237516869096 on epoch=249
05/30/2022 01:10:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.83 on epoch=252
05/30/2022 01:10:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.84 on epoch=254
05/30/2022 01:10:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.93 on epoch=257
05/30/2022 01:10:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.88 on epoch=259
05/30/2022 01:10:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.82 on epoch=262
05/30/2022 01:10:46 - INFO - __main__ - Global step 1050 Train loss 1.86 Classification-F1 0.17267605633802818 on epoch=262
05/30/2022 01:10:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.73 on epoch=264
05/30/2022 01:10:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.95 on epoch=267
05/30/2022 01:10:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.77 on epoch=269
05/30/2022 01:10:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.94 on epoch=272
05/30/2022 01:10:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.71 on epoch=274
05/30/2022 01:10:52 - INFO - __main__ - Global step 1100 Train loss 1.82 Classification-F1 0.13225806451612904 on epoch=274
05/30/2022 01:10:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.81 on epoch=277
05/30/2022 01:10:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.78 on epoch=279
05/30/2022 01:10:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.88 on epoch=282
05/30/2022 01:10:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.72 on epoch=284
05/30/2022 01:10:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.72 on epoch=287
05/30/2022 01:10:59 - INFO - __main__ - Global step 1150 Train loss 1.78 Classification-F1 0.1302118933697881 on epoch=287
05/30/2022 01:11:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.51 on epoch=289
05/30/2022 01:11:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.64 on epoch=292
05/30/2022 01:11:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.47 on epoch=294
05/30/2022 01:11:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.58 on epoch=297
05/30/2022 01:11:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.59 on epoch=299
05/30/2022 01:11:06 - INFO - __main__ - Global step 1200 Train loss 1.56 Classification-F1 0.2000907441016334 on epoch=299
05/30/2022 01:11:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.82 on epoch=302
05/30/2022 01:11:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.66 on epoch=304
05/30/2022 01:11:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.63 on epoch=307
05/30/2022 01:11:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.68 on epoch=309
05/30/2022 01:11:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.52 on epoch=312
05/30/2022 01:11:12 - INFO - __main__ - Global step 1250 Train loss 1.66 Classification-F1 0.171875 on epoch=312
05/30/2022 01:11:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.49 on epoch=314
05/30/2022 01:11:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.57 on epoch=317
05/30/2022 01:11:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.51 on epoch=319
05/30/2022 01:11:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.58 on epoch=322
05/30/2022 01:11:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.52 on epoch=324
05/30/2022 01:11:19 - INFO - __main__ - Global step 1300 Train loss 1.53 Classification-F1 0.1523109243697479 on epoch=324
05/30/2022 01:11:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.57 on epoch=327
05/30/2022 01:11:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.65 on epoch=329
05/30/2022 01:11:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.43 on epoch=332
05/30/2022 01:11:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.51 on epoch=334
05/30/2022 01:11:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.48 on epoch=337
05/30/2022 01:11:25 - INFO - __main__ - Global step 1350 Train loss 1.53 Classification-F1 0.17377495462794917 on epoch=337
05/30/2022 01:11:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.37 on epoch=339
05/30/2022 01:11:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.53 on epoch=342
05/30/2022 01:11:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.43 on epoch=344
05/30/2022 01:11:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.54 on epoch=347
05/30/2022 01:11:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.38 on epoch=349
05/30/2022 01:11:32 - INFO - __main__ - Global step 1400 Train loss 1.45 Classification-F1 0.16078790655061842 on epoch=349
05/30/2022 01:11:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.35 on epoch=352
05/30/2022 01:11:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.42 on epoch=354
05/30/2022 01:11:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.43 on epoch=357
05/30/2022 01:11:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.29 on epoch=359
05/30/2022 01:11:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.38 on epoch=362
05/30/2022 01:11:39 - INFO - __main__ - Global step 1450 Train loss 1.37 Classification-F1 0.14563380281690141 on epoch=362
05/30/2022 01:11:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.26 on epoch=364
05/30/2022 01:11:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.50 on epoch=367
05/30/2022 01:11:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.39 on epoch=369
05/30/2022 01:11:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.51 on epoch=372
05/30/2022 01:11:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.28 on epoch=374
05/30/2022 01:11:45 - INFO - __main__ - Global step 1500 Train loss 1.39 Classification-F1 0.1 on epoch=374
05/30/2022 01:11:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.45 on epoch=377
05/30/2022 01:11:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.44 on epoch=379
05/30/2022 01:11:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.49 on epoch=382
05/30/2022 01:11:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.33 on epoch=384
05/30/2022 01:11:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
05/30/2022 01:11:52 - INFO - __main__ - Global step 1550 Train loss 1.42 Classification-F1 0.1869328493647913 on epoch=387
05/30/2022 01:11:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.44 on epoch=389
05/30/2022 01:11:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.37 on epoch=392
05/30/2022 01:11:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.29 on epoch=394
05/30/2022 01:11:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.29 on epoch=397
05/30/2022 01:11:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.32 on epoch=399
05/30/2022 01:11:58 - INFO - __main__ - Global step 1600 Train loss 1.34 Classification-F1 0.1 on epoch=399
05/30/2022 01:11:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.35 on epoch=402
05/30/2022 01:12:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.22 on epoch=404
05/30/2022 01:12:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.30 on epoch=407
05/30/2022 01:12:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.38 on epoch=409
05/30/2022 01:12:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.35 on epoch=412
05/30/2022 01:12:05 - INFO - __main__ - Global step 1650 Train loss 1.32 Classification-F1 0.1875814155449414 on epoch=412
05/30/2022 01:12:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.33 on epoch=414
05/30/2022 01:12:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.32 on epoch=417
05/30/2022 01:12:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.32 on epoch=419
05/30/2022 01:12:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.19 on epoch=422
05/30/2022 01:12:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.16 on epoch=424
05/30/2022 01:12:11 - INFO - __main__ - Global step 1700 Train loss 1.26 Classification-F1 0.12403499742665978 on epoch=424
05/30/2022 01:12:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.15 on epoch=427
05/30/2022 01:12:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.15 on epoch=429
05/30/2022 01:12:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.23 on epoch=432
05/30/2022 01:12:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.24 on epoch=434
05/30/2022 01:12:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=437
05/30/2022 01:12:18 - INFO - __main__ - Global step 1750 Train loss 1.20 Classification-F1 0.10126582278481013 on epoch=437
05/30/2022 01:12:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.22 on epoch=439
05/30/2022 01:12:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.36 on epoch=442
05/30/2022 01:12:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.37 on epoch=444
05/30/2022 01:12:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.29 on epoch=447
05/30/2022 01:12:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.21 on epoch=449
05/30/2022 01:12:24 - INFO - __main__ - Global step 1800 Train loss 1.29 Classification-F1 0.1 on epoch=449
05/30/2022 01:12:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.29 on epoch=452
05/30/2022 01:12:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.14 on epoch=454
05/30/2022 01:12:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.25 on epoch=457
05/30/2022 01:12:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.14 on epoch=459
05/30/2022 01:12:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.19 on epoch=462
05/30/2022 01:12:31 - INFO - __main__ - Global step 1850 Train loss 1.20 Classification-F1 0.11762954139368673 on epoch=462
05/30/2022 01:12:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.22 on epoch=464
05/30/2022 01:12:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.24 on epoch=467
05/30/2022 01:12:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.25 on epoch=469
05/30/2022 01:12:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.26 on epoch=472
05/30/2022 01:12:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.21 on epoch=474
05/30/2022 01:12:37 - INFO - __main__ - Global step 1900 Train loss 1.24 Classification-F1 0.16608695652173913 on epoch=474
05/30/2022 01:12:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.29 on epoch=477
05/30/2022 01:12:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.27 on epoch=479
05/30/2022 01:12:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.23 on epoch=482
05/30/2022 01:12:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.12 on epoch=484
05/30/2022 01:12:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.26 on epoch=487
05/30/2022 01:12:44 - INFO - __main__ - Global step 1950 Train loss 1.23 Classification-F1 0.1 on epoch=487
05/30/2022 01:12:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.24 on epoch=489
05/30/2022 01:12:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.30 on epoch=492
05/30/2022 01:12:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.18 on epoch=494
05/30/2022 01:12:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.30 on epoch=497
05/30/2022 01:12:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.17 on epoch=499
05/30/2022 01:12:50 - INFO - __main__ - Global step 2000 Train loss 1.24 Classification-F1 0.17809523809523808 on epoch=499
05/30/2022 01:12:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.20 on epoch=502
05/30/2022 01:12:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.09 on epoch=504
05/30/2022 01:12:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.19 on epoch=507
05/30/2022 01:12:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.22 on epoch=509
05/30/2022 01:12:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.24 on epoch=512
05/30/2022 01:12:57 - INFO - __main__ - Global step 2050 Train loss 1.19 Classification-F1 0.17573497147871872 on epoch=512
05/30/2022 01:12:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.19 on epoch=514
05/30/2022 01:12:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.25 on epoch=517
05/30/2022 01:13:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.13 on epoch=519
05/30/2022 01:13:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.23 on epoch=522
05/30/2022 01:13:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.16 on epoch=524
05/30/2022 01:13:03 - INFO - __main__ - Global step 2100 Train loss 1.19 Classification-F1 0.1 on epoch=524
05/30/2022 01:13:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.17 on epoch=527
05/30/2022 01:13:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.24 on epoch=529
05/30/2022 01:13:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.18 on epoch=532
05/30/2022 01:13:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.17 on epoch=534
05/30/2022 01:13:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.16 on epoch=537
05/30/2022 01:13:10 - INFO - __main__ - Global step 2150 Train loss 1.18 Classification-F1 0.12393162393162392 on epoch=537
05/30/2022 01:13:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.19 on epoch=539
05/30/2022 01:13:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.16 on epoch=542
05/30/2022 01:13:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.21 on epoch=544
05/30/2022 01:13:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.20 on epoch=547
05/30/2022 01:13:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.20 on epoch=549
05/30/2022 01:13:17 - INFO - __main__ - Global step 2200 Train loss 1.19 Classification-F1 0.1 on epoch=549
05/30/2022 01:13:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.08 on epoch=552
05/30/2022 01:13:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.09 on epoch=554
05/30/2022 01:13:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.23 on epoch=557
05/30/2022 01:13:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.01 on epoch=559
05/30/2022 01:13:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.08 on epoch=562
05/30/2022 01:13:23 - INFO - __main__ - Global step 2250 Train loss 1.10 Classification-F1 0.1 on epoch=562
05/30/2022 01:13:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.08 on epoch=564
05/30/2022 01:13:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.15 on epoch=567
05/30/2022 01:13:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.11 on epoch=569
05/30/2022 01:13:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.15 on epoch=572
05/30/2022 01:13:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.24 on epoch=574
05/30/2022 01:13:30 - INFO - __main__ - Global step 2300 Train loss 1.15 Classification-F1 0.13067758749069247 on epoch=574
05/30/2022 01:13:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.27 on epoch=577
05/30/2022 01:13:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
05/30/2022 01:13:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.20 on epoch=582
05/30/2022 01:13:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.13 on epoch=584
05/30/2022 01:13:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.16 on epoch=587
05/30/2022 01:13:36 - INFO - __main__ - Global step 2350 Train loss 1.18 Classification-F1 0.1283068783068783 on epoch=587
05/30/2022 01:13:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.12 on epoch=589
05/30/2022 01:13:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.10 on epoch=592
05/30/2022 01:13:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.04 on epoch=594
05/30/2022 01:13:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
05/30/2022 01:13:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.14 on epoch=599
05/30/2022 01:13:43 - INFO - __main__ - Global step 2400 Train loss 1.10 Classification-F1 0.14450704225352112 on epoch=599
05/30/2022 01:13:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.30 on epoch=602
05/30/2022 01:13:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.12 on epoch=604
05/30/2022 01:13:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.10 on epoch=607
05/30/2022 01:13:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
05/30/2022 01:13:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.10 on epoch=612
05/30/2022 01:13:49 - INFO - __main__ - Global step 2450 Train loss 1.12 Classification-F1 0.09493670886075949 on epoch=612
05/30/2022 01:13:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.24 on epoch=614
05/30/2022 01:13:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.10 on epoch=617
05/30/2022 01:13:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.05 on epoch=619
05/30/2022 01:13:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
05/30/2022 01:13:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.20 on epoch=624
05/30/2022 01:13:56 - INFO - __main__ - Global step 2500 Train loss 1.12 Classification-F1 0.1 on epoch=624
05/30/2022 01:13:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.15 on epoch=627
05/30/2022 01:13:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
05/30/2022 01:13:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.17 on epoch=632
05/30/2022 01:14:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.07 on epoch=634
05/30/2022 01:14:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.08 on epoch=637
05/30/2022 01:14:02 - INFO - __main__ - Global step 2550 Train loss 1.11 Classification-F1 0.1 on epoch=637
05/30/2022 01:14:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.03 on epoch=639
05/30/2022 01:14:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.05 on epoch=642
05/30/2022 01:14:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.11 on epoch=644
05/30/2022 01:14:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.07 on epoch=647
05/30/2022 01:14:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.07 on epoch=649
05/30/2022 01:14:09 - INFO - __main__ - Global step 2600 Train loss 1.07 Classification-F1 0.1 on epoch=649
05/30/2022 01:14:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/30/2022 01:14:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.15 on epoch=654
05/30/2022 01:14:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.04 on epoch=657
05/30/2022 01:14:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.18 on epoch=659
05/30/2022 01:14:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.12 on epoch=662
05/30/2022 01:14:15 - INFO - __main__ - Global step 2650 Train loss 1.09 Classification-F1 0.1434065934065934 on epoch=662
05/30/2022 01:14:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.05 on epoch=664
05/30/2022 01:14:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.04 on epoch=667
05/30/2022 01:14:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.06 on epoch=669
05/30/2022 01:14:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/30/2022 01:14:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.07 on epoch=674
05/30/2022 01:14:22 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.16515151515151516 on epoch=674
05/30/2022 01:14:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.07 on epoch=677
05/30/2022 01:14:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
05/30/2022 01:14:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.09 on epoch=682
05/30/2022 01:14:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.01 on epoch=684
05/30/2022 01:14:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.11 on epoch=687
05/30/2022 01:14:28 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.18679549114331723 on epoch=687
05/30/2022 01:14:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.16 on epoch=689
05/30/2022 01:14:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.09 on epoch=692
05/30/2022 01:14:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/30/2022 01:14:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
05/30/2022 01:14:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.08 on epoch=699
05/30/2022 01:14:35 - INFO - __main__ - Global step 2800 Train loss 1.05 Classification-F1 0.14180672268907563 on epoch=699
05/30/2022 01:14:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.03 on epoch=702
05/30/2022 01:14:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.19 on epoch=704
05/30/2022 01:14:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.05 on epoch=707
05/30/2022 01:14:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/30/2022 01:14:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
05/30/2022 01:14:42 - INFO - __main__ - Global step 2850 Train loss 1.07 Classification-F1 0.10526315789473685 on epoch=712
05/30/2022 01:14:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.93 on epoch=714
05/30/2022 01:14:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.14 on epoch=717
05/30/2022 01:14:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.20 on epoch=719
05/30/2022 01:14:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.11 on epoch=722
05/30/2022 01:14:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.21 on epoch=724
05/30/2022 01:14:48 - INFO - __main__ - Global step 2900 Train loss 1.12 Classification-F1 0.14509803921568626 on epoch=724
05/30/2022 01:14:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.06 on epoch=727
05/30/2022 01:14:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.13 on epoch=729
05/30/2022 01:14:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.96 on epoch=732
05/30/2022 01:14:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.05 on epoch=734
05/30/2022 01:14:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.99 on epoch=737
05/30/2022 01:14:55 - INFO - __main__ - Global step 2950 Train loss 1.04 Classification-F1 0.1517857142857143 on epoch=737
05/30/2022 01:14:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/30/2022 01:14:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.09 on epoch=742
05/30/2022 01:14:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.15 on epoch=744
05/30/2022 01:15:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.03 on epoch=747
05/30/2022 01:15:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.00 on epoch=749
05/30/2022 01:15:01 - INFO - __main__ - Global step 3000 Train loss 1.05 Classification-F1 0.13034188034188032 on epoch=749
05/30/2022 01:15:01 - INFO - __main__ - save last model!
05/30/2022 01:15:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 01:15:02 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 01:15:02 - INFO - __main__ - Printing 3 examples
05/30/2022 01:15:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:15:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:15:02 - INFO - __main__ - Printing 3 examples
05/30/2022 01:15:02 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:15:02 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:15:02 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:15:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:15:02 - INFO - __main__ - Printing 3 examples
05/30/2022 01:15:02 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:15:02 - INFO - __main__ - ['others']
05/30/2022 01:15:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:15:02 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:15:02 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:15:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:15:07 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:15:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:15:08 - INFO - __main__ - Starting training!
05/30/2022 01:15:09 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:15:52 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_100_0.2_8_predictions.txt
05/30/2022 01:15:52 - INFO - __main__ - Classification-F1 on test data: 0.0339
05/30/2022 01:15:52 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.217858709960509, test_performance=0.03393767675257918
05/30/2022 01:15:52 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
05/30/2022 01:15:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:15:53 - INFO - __main__ - Printing 3 examples
05/30/2022 01:15:53 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:15:53 - INFO - __main__ - ['others']
05/30/2022 01:15:53 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:15:53 - INFO - __main__ - ['others']
05/30/2022 01:15:53 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:15:53 - INFO - __main__ - ['others']
05/30/2022 01:15:53 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:15:53 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:15:54 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:15:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:15:54 - INFO - __main__ - Printing 3 examples
05/30/2022 01:15:54 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:15:54 - INFO - __main__ - ['others']
05/30/2022 01:15:54 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:15:54 - INFO - __main__ - ['others']
05/30/2022 01:15:54 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:15:54 - INFO - __main__ - ['others']
05/30/2022 01:15:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:15:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:15:54 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:15:59 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:15:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:15:59 - INFO - __main__ - Starting training!
05/30/2022 01:16:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.71 on epoch=2
05/30/2022 01:16:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.49 on epoch=4
05/30/2022 01:16:03 - INFO - __main__ - Step 30 Global step 30 Train loss 5.99 on epoch=7
05/30/2022 01:16:04 - INFO - __main__ - Step 40 Global step 40 Train loss 5.80 on epoch=9
05/30/2022 01:16:05 - INFO - __main__ - Step 50 Global step 50 Train loss 5.51 on epoch=12
05/30/2022 01:16:08 - INFO - __main__ - Global step 50 Train loss 6.10 Classification-F1 0.0 on epoch=12
05/30/2022 01:16:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:16:09 - INFO - __main__ - Step 60 Global step 60 Train loss 5.18 on epoch=14
05/30/2022 01:16:10 - INFO - __main__ - Step 70 Global step 70 Train loss 5.09 on epoch=17
05/30/2022 01:16:12 - INFO - __main__ - Step 80 Global step 80 Train loss 4.72 on epoch=19
05/30/2022 01:16:13 - INFO - __main__ - Step 90 Global step 90 Train loss 4.43 on epoch=22
05/30/2022 01:16:14 - INFO - __main__ - Step 100 Global step 100 Train loss 4.13 on epoch=24
05/30/2022 01:16:14 - INFO - __main__ - Global step 100 Train loss 4.71 Classification-F1 0.17584541062801934 on epoch=24
05/30/2022 01:16:15 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.17584541062801934 on epoch=24, global_step=100
05/30/2022 01:16:16 - INFO - __main__ - Step 110 Global step 110 Train loss 3.87 on epoch=27
05/30/2022 01:16:17 - INFO - __main__ - Step 120 Global step 120 Train loss 3.74 on epoch=29
05/30/2022 01:16:18 - INFO - __main__ - Step 130 Global step 130 Train loss 3.86 on epoch=32
05/30/2022 01:16:19 - INFO - __main__ - Step 140 Global step 140 Train loss 3.44 on epoch=34
05/30/2022 01:16:20 - INFO - __main__ - Step 150 Global step 150 Train loss 3.45 on epoch=37
05/30/2022 01:16:21 - INFO - __main__ - Global step 150 Train loss 3.67 Classification-F1 0.10404761904761906 on epoch=37
05/30/2022 01:16:22 - INFO - __main__ - Step 160 Global step 160 Train loss 3.24 on epoch=39
05/30/2022 01:16:23 - INFO - __main__ - Step 170 Global step 170 Train loss 3.20 on epoch=42
05/30/2022 01:16:25 - INFO - __main__ - Step 180 Global step 180 Train loss 3.09 on epoch=44
05/30/2022 01:16:26 - INFO - __main__ - Step 190 Global step 190 Train loss 3.04 on epoch=47
05/30/2022 01:16:27 - INFO - __main__ - Step 200 Global step 200 Train loss 2.95 on epoch=49
05/30/2022 01:16:27 - INFO - __main__ - Global step 200 Train loss 3.10 Classification-F1 0.08450704225352113 on epoch=49
05/30/2022 01:16:29 - INFO - __main__ - Step 210 Global step 210 Train loss 2.72 on epoch=52
05/30/2022 01:16:30 - INFO - __main__ - Step 220 Global step 220 Train loss 2.76 on epoch=54
05/30/2022 01:16:31 - INFO - __main__ - Step 230 Global step 230 Train loss 2.73 on epoch=57
05/30/2022 01:16:32 - INFO - __main__ - Step 240 Global step 240 Train loss 2.40 on epoch=59
05/30/2022 01:16:33 - INFO - __main__ - Step 250 Global step 250 Train loss 2.52 on epoch=62
05/30/2022 01:16:34 - INFO - __main__ - Global step 250 Train loss 2.63 Classification-F1 0.12368421052631579 on epoch=62
05/30/2022 01:16:35 - INFO - __main__ - Step 260 Global step 260 Train loss 2.59 on epoch=64
05/30/2022 01:16:36 - INFO - __main__ - Step 270 Global step 270 Train loss 2.39 on epoch=67
05/30/2022 01:16:38 - INFO - __main__ - Step 280 Global step 280 Train loss 2.14 on epoch=69
05/30/2022 01:16:39 - INFO - __main__ - Step 290 Global step 290 Train loss 2.26 on epoch=72
05/30/2022 01:16:40 - INFO - __main__ - Step 300 Global step 300 Train loss 2.05 on epoch=74
05/30/2022 01:16:40 - INFO - __main__ - Global step 300 Train loss 2.29 Classification-F1 0.1970899470899471 on epoch=74
05/30/2022 01:16:41 - INFO - __main__ - Saving model with best Classification-F1: 0.17584541062801934 -> 0.1970899470899471 on epoch=74, global_step=300
05/30/2022 01:16:42 - INFO - __main__ - Step 310 Global step 310 Train loss 2.12 on epoch=77
05/30/2022 01:16:43 - INFO - __main__ - Step 320 Global step 320 Train loss 2.14 on epoch=79
05/30/2022 01:16:44 - INFO - __main__ - Step 330 Global step 330 Train loss 1.99 on epoch=82
05/30/2022 01:16:45 - INFO - __main__ - Step 340 Global step 340 Train loss 1.88 on epoch=84
05/30/2022 01:16:47 - INFO - __main__ - Step 350 Global step 350 Train loss 1.90 on epoch=87
05/30/2022 01:16:47 - INFO - __main__ - Global step 350 Train loss 2.01 Classification-F1 0.18029871977240397 on epoch=87
05/30/2022 01:16:48 - INFO - __main__ - Step 360 Global step 360 Train loss 1.86 on epoch=89
05/30/2022 01:16:49 - INFO - __main__ - Step 370 Global step 370 Train loss 1.88 on epoch=92
05/30/2022 01:16:51 - INFO - __main__ - Step 380 Global step 380 Train loss 1.65 on epoch=94
05/30/2022 01:16:52 - INFO - __main__ - Step 390 Global step 390 Train loss 1.78 on epoch=97
05/30/2022 01:16:53 - INFO - __main__ - Step 400 Global step 400 Train loss 1.59 on epoch=99
05/30/2022 01:16:54 - INFO - __main__ - Global step 400 Train loss 1.75 Classification-F1 0.19542483660130716 on epoch=99
05/30/2022 01:16:55 - INFO - __main__ - Step 410 Global step 410 Train loss 1.66 on epoch=102
05/30/2022 01:16:56 - INFO - __main__ - Step 420 Global step 420 Train loss 1.70 on epoch=104
05/30/2022 01:16:57 - INFO - __main__ - Step 430 Global step 430 Train loss 1.73 on epoch=107
05/30/2022 01:16:58 - INFO - __main__ - Step 440 Global step 440 Train loss 1.54 on epoch=109
05/30/2022 01:17:00 - INFO - __main__ - Step 450 Global step 450 Train loss 1.57 on epoch=112
05/30/2022 01:17:00 - INFO - __main__ - Global step 450 Train loss 1.64 Classification-F1 0.142512077294686 on epoch=112
05/30/2022 01:17:01 - INFO - __main__ - Step 460 Global step 460 Train loss 1.51 on epoch=114
05/30/2022 01:17:02 - INFO - __main__ - Step 470 Global step 470 Train loss 1.51 on epoch=117
05/30/2022 01:17:04 - INFO - __main__ - Step 480 Global step 480 Train loss 1.43 on epoch=119
05/30/2022 01:17:05 - INFO - __main__ - Step 490 Global step 490 Train loss 1.36 on epoch=122
05/30/2022 01:17:06 - INFO - __main__ - Step 500 Global step 500 Train loss 1.47 on epoch=124
05/30/2022 01:17:07 - INFO - __main__ - Global step 500 Train loss 1.46 Classification-F1 0.1853146853146853 on epoch=124
05/30/2022 01:17:08 - INFO - __main__ - Step 510 Global step 510 Train loss 1.45 on epoch=127
05/30/2022 01:17:09 - INFO - __main__ - Step 520 Global step 520 Train loss 1.32 on epoch=129
05/30/2022 01:17:10 - INFO - __main__ - Step 530 Global step 530 Train loss 1.29 on epoch=132
05/30/2022 01:17:11 - INFO - __main__ - Step 540 Global step 540 Train loss 1.39 on epoch=134
05/30/2022 01:17:13 - INFO - __main__ - Step 550 Global step 550 Train loss 1.34 on epoch=137
05/30/2022 01:17:13 - INFO - __main__ - Global step 550 Train loss 1.36 Classification-F1 0.1576923076923077 on epoch=137
05/30/2022 01:17:14 - INFO - __main__ - Step 560 Global step 560 Train loss 1.32 on epoch=139
05/30/2022 01:17:15 - INFO - __main__ - Step 570 Global step 570 Train loss 1.41 on epoch=142
05/30/2022 01:17:17 - INFO - __main__ - Step 580 Global step 580 Train loss 1.25 on epoch=144
05/30/2022 01:17:18 - INFO - __main__ - Step 590 Global step 590 Train loss 1.30 on epoch=147
05/30/2022 01:17:19 - INFO - __main__ - Step 600 Global step 600 Train loss 1.22 on epoch=149
05/30/2022 01:17:20 - INFO - __main__ - Global step 600 Train loss 1.30 Classification-F1 0.09868421052631579 on epoch=149
05/30/2022 01:17:21 - INFO - __main__ - Step 610 Global step 610 Train loss 1.28 on epoch=152
05/30/2022 01:17:22 - INFO - __main__ - Step 620 Global step 620 Train loss 1.29 on epoch=154
05/30/2022 01:17:23 - INFO - __main__ - Step 630 Global step 630 Train loss 1.31 on epoch=157
05/30/2022 01:17:24 - INFO - __main__ - Step 640 Global step 640 Train loss 1.30 on epoch=159
05/30/2022 01:17:26 - INFO - __main__ - Step 650 Global step 650 Train loss 1.17 on epoch=162
05/30/2022 01:17:26 - INFO - __main__ - Global step 650 Train loss 1.27 Classification-F1 0.1 on epoch=162
05/30/2022 01:17:27 - INFO - __main__ - Step 660 Global step 660 Train loss 1.20 on epoch=164
05/30/2022 01:17:28 - INFO - __main__ - Step 670 Global step 670 Train loss 1.21 on epoch=167
05/30/2022 01:17:30 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=169
05/30/2022 01:17:31 - INFO - __main__ - Step 690 Global step 690 Train loss 1.23 on epoch=172
05/30/2022 01:17:32 - INFO - __main__ - Step 700 Global step 700 Train loss 1.21 on epoch=174
05/30/2022 01:17:33 - INFO - __main__ - Global step 700 Train loss 1.22 Classification-F1 0.15682382133995038 on epoch=174
05/30/2022 01:17:34 - INFO - __main__ - Step 710 Global step 710 Train loss 1.24 on epoch=177
05/30/2022 01:17:35 - INFO - __main__ - Step 720 Global step 720 Train loss 1.23 on epoch=179
05/30/2022 01:17:36 - INFO - __main__ - Step 730 Global step 730 Train loss 1.17 on epoch=182
05/30/2022 01:17:37 - INFO - __main__ - Step 740 Global step 740 Train loss 1.28 on epoch=184
05/30/2022 01:17:39 - INFO - __main__ - Step 750 Global step 750 Train loss 1.14 on epoch=187
05/30/2022 01:17:39 - INFO - __main__ - Global step 750 Train loss 1.21 Classification-F1 0.20277777777777778 on epoch=187
05/30/2022 01:17:39 - INFO - __main__ - Saving model with best Classification-F1: 0.1970899470899471 -> 0.20277777777777778 on epoch=187, global_step=750
05/30/2022 01:17:40 - INFO - __main__ - Step 760 Global step 760 Train loss 1.15 on epoch=189
05/30/2022 01:17:42 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=192
05/30/2022 01:17:43 - INFO - __main__ - Step 780 Global step 780 Train loss 1.19 on epoch=194
05/30/2022 01:17:44 - INFO - __main__ - Step 790 Global step 790 Train loss 1.11 on epoch=197
05/30/2022 01:17:45 - INFO - __main__ - Step 800 Global step 800 Train loss 1.29 on epoch=199
05/30/2022 01:17:46 - INFO - __main__ - Global step 800 Train loss 1.19 Classification-F1 0.0974025974025974 on epoch=199
05/30/2022 01:17:47 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=202
05/30/2022 01:17:48 - INFO - __main__ - Step 820 Global step 820 Train loss 1.16 on epoch=204
05/30/2022 01:17:49 - INFO - __main__ - Step 830 Global step 830 Train loss 1.22 on epoch=207
05/30/2022 01:17:50 - INFO - __main__ - Step 840 Global step 840 Train loss 1.14 on epoch=209
05/30/2022 01:17:52 - INFO - __main__ - Step 850 Global step 850 Train loss 1.24 on epoch=212
05/30/2022 01:17:52 - INFO - __main__ - Global step 850 Train loss 1.17 Classification-F1 0.23076923076923078 on epoch=212
05/30/2022 01:17:52 - INFO - __main__ - Saving model with best Classification-F1: 0.20277777777777778 -> 0.23076923076923078 on epoch=212, global_step=850
05/30/2022 01:17:53 - INFO - __main__ - Step 860 Global step 860 Train loss 1.10 on epoch=214
05/30/2022 01:17:55 - INFO - __main__ - Step 870 Global step 870 Train loss 1.17 on epoch=217
05/30/2022 01:17:56 - INFO - __main__ - Step 880 Global step 880 Train loss 1.19 on epoch=219
05/30/2022 01:17:57 - INFO - __main__ - Step 890 Global step 890 Train loss 1.18 on epoch=222
05/30/2022 01:17:58 - INFO - __main__ - Step 900 Global step 900 Train loss 1.18 on epoch=224
05/30/2022 01:17:59 - INFO - __main__ - Global step 900 Train loss 1.17 Classification-F1 0.1256338028169014 on epoch=224
05/30/2022 01:18:00 - INFO - __main__ - Step 910 Global step 910 Train loss 1.18 on epoch=227
05/30/2022 01:18:01 - INFO - __main__ - Step 920 Global step 920 Train loss 1.18 on epoch=229
05/30/2022 01:18:02 - INFO - __main__ - Step 930 Global step 930 Train loss 1.20 on epoch=232
05/30/2022 01:18:03 - INFO - __main__ - Step 940 Global step 940 Train loss 1.06 on epoch=234
05/30/2022 01:18:05 - INFO - __main__ - Step 950 Global step 950 Train loss 1.10 on epoch=237
05/30/2022 01:18:05 - INFO - __main__ - Global step 950 Train loss 1.14 Classification-F1 0.22059553349875932 on epoch=237
05/30/2022 01:18:06 - INFO - __main__ - Step 960 Global step 960 Train loss 1.12 on epoch=239
05/30/2022 01:18:08 - INFO - __main__ - Step 970 Global step 970 Train loss 1.06 on epoch=242
05/30/2022 01:18:09 - INFO - __main__ - Step 980 Global step 980 Train loss 1.04 on epoch=244
05/30/2022 01:18:10 - INFO - __main__ - Step 990 Global step 990 Train loss 1.12 on epoch=247
05/30/2022 01:18:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.04 on epoch=249
05/30/2022 01:18:12 - INFO - __main__ - Global step 1000 Train loss 1.08 Classification-F1 0.16666666666666666 on epoch=249
05/30/2022 01:18:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.16 on epoch=252
05/30/2022 01:18:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.03 on epoch=254
05/30/2022 01:18:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/30/2022 01:18:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.91 on epoch=259
05/30/2022 01:18:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.12 on epoch=262
05/30/2022 01:18:18 - INFO - __main__ - Global step 1050 Train loss 1.06 Classification-F1 0.21743697478991597 on epoch=262
05/30/2022 01:18:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=264
05/30/2022 01:18:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.99 on epoch=267
05/30/2022 01:18:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=269
05/30/2022 01:18:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.12 on epoch=272
05/30/2022 01:18:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.10 on epoch=274
05/30/2022 01:18:25 - INFO - __main__ - Global step 1100 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=274
05/30/2022 01:18:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.10 on epoch=277
05/30/2022 01:18:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.04 on epoch=279
05/30/2022 01:18:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.10 on epoch=282
05/30/2022 01:18:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.07 on epoch=284
05/30/2022 01:18:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.98 on epoch=287
05/30/2022 01:18:31 - INFO - __main__ - Global step 1150 Train loss 1.06 Classification-F1 0.11762954139368673 on epoch=287
05/30/2022 01:18:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.04 on epoch=289
05/30/2022 01:18:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.10 on epoch=292
05/30/2022 01:18:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.06 on epoch=294
05/30/2022 01:18:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.17 on epoch=297
05/30/2022 01:18:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.04 on epoch=299
05/30/2022 01:18:38 - INFO - __main__ - Global step 1200 Train loss 1.08 Classification-F1 0.16785714285714287 on epoch=299
05/30/2022 01:18:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.07 on epoch=302
05/30/2022 01:18:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.16 on epoch=304
05/30/2022 01:18:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.07 on epoch=307
05/30/2022 01:18:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.11 on epoch=309
05/30/2022 01:18:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.16 on epoch=312
05/30/2022 01:18:44 - INFO - __main__ - Global step 1250 Train loss 1.11 Classification-F1 0.11714285714285715 on epoch=312
05/30/2022 01:18:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.05 on epoch=314
05/30/2022 01:18:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.08 on epoch=317
05/30/2022 01:18:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.99 on epoch=319
05/30/2022 01:18:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.04 on epoch=322
05/30/2022 01:18:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.11 on epoch=324
05/30/2022 01:18:51 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.22026143790849673 on epoch=324
05/30/2022 01:18:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.04 on epoch=327
05/30/2022 01:18:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.03 on epoch=329
05/30/2022 01:18:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.95 on epoch=332
05/30/2022 01:18:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.99 on epoch=334
05/30/2022 01:18:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.02 on epoch=337
05/30/2022 01:18:57 - INFO - __main__ - Global step 1350 Train loss 1.01 Classification-F1 0.1527777777777778 on epoch=337
05/30/2022 01:18:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.02 on epoch=339
05/30/2022 01:19:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/30/2022 01:19:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.13 on epoch=344
05/30/2022 01:19:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.24 on epoch=347
05/30/2022 01:19:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.13 on epoch=349
05/30/2022 01:19:04 - INFO - __main__ - Global step 1400 Train loss 1.12 Classification-F1 0.13067758749069247 on epoch=349
05/30/2022 01:19:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.15 on epoch=352
05/30/2022 01:19:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.21 on epoch=354
05/30/2022 01:19:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.05 on epoch=357
05/30/2022 01:19:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.21 on epoch=359
05/30/2022 01:19:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=362
05/30/2022 01:19:11 - INFO - __main__ - Global step 1450 Train loss 1.14 Classification-F1 0.21827759963353183 on epoch=362
05/30/2022 01:19:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.11 on epoch=364
05/30/2022 01:19:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.17 on epoch=367
05/30/2022 01:19:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.13 on epoch=369
05/30/2022 01:19:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.10 on epoch=372
05/30/2022 01:19:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.16 on epoch=374
05/30/2022 01:19:17 - INFO - __main__ - Global step 1500 Train loss 1.13 Classification-F1 0.1873628784554629 on epoch=374
05/30/2022 01:19:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.09 on epoch=377
05/30/2022 01:19:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.05 on epoch=379
05/30/2022 01:19:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.09 on epoch=382
05/30/2022 01:19:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.18 on epoch=384
05/30/2022 01:19:23 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.02 on epoch=387
05/30/2022 01:19:24 - INFO - __main__ - Global step 1550 Train loss 1.08 Classification-F1 0.1732142857142857 on epoch=387
05/30/2022 01:19:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.00 on epoch=389
05/30/2022 01:19:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.12 on epoch=392
05/30/2022 01:19:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.02 on epoch=394
05/30/2022 01:19:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=397
05/30/2022 01:19:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=399
05/30/2022 01:19:30 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.15625 on epoch=399
05/30/2022 01:19:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.09 on epoch=402
05/30/2022 01:19:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/30/2022 01:19:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.04 on epoch=407
05/30/2022 01:19:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.90 on epoch=409
05/30/2022 01:19:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.16 on epoch=412
05/30/2022 01:19:37 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.14583333333333334 on epoch=412
05/30/2022 01:19:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.05 on epoch=414
05/30/2022 01:19:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.03 on epoch=417
05/30/2022 01:19:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.09 on epoch=419
05/30/2022 01:19:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.13 on epoch=422
05/30/2022 01:19:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=424
05/30/2022 01:19:43 - INFO - __main__ - Global step 1700 Train loss 1.07 Classification-F1 0.13067758749069247 on epoch=424
05/30/2022 01:19:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.98 on epoch=427
05/30/2022 01:19:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.03 on epoch=429
05/30/2022 01:19:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.06 on epoch=432
05/30/2022 01:19:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
05/30/2022 01:19:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.19 on epoch=437
05/30/2022 01:19:50 - INFO - __main__ - Global step 1750 Train loss 1.07 Classification-F1 0.09493670886075949 on epoch=437
05/30/2022 01:19:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
05/30/2022 01:19:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
05/30/2022 01:19:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/30/2022 01:19:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.98 on epoch=447
05/30/2022 01:19:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=449
05/30/2022 01:19:56 - INFO - __main__ - Global step 1800 Train loss 1.04 Classification-F1 0.1 on epoch=449
05/30/2022 01:19:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/30/2022 01:19:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.08 on epoch=454
05/30/2022 01:20:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.07 on epoch=457
05/30/2022 01:20:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.24 on epoch=459
05/30/2022 01:20:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.15 on epoch=462
05/30/2022 01:20:03 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.16666666666666666 on epoch=462
05/30/2022 01:20:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.05 on epoch=464
05/30/2022 01:20:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.97 on epoch=467
05/30/2022 01:20:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.08 on epoch=469
05/30/2022 01:20:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.97 on epoch=472
05/30/2022 01:20:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.00 on epoch=474
05/30/2022 01:20:09 - INFO - __main__ - Global step 1900 Train loss 1.01 Classification-F1 0.11714285714285715 on epoch=474
05/30/2022 01:20:11 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
05/30/2022 01:20:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
05/30/2022 01:20:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.93 on epoch=482
05/30/2022 01:20:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
05/30/2022 01:20:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.95 on epoch=487
05/30/2022 01:20:16 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.1 on epoch=487
05/30/2022 01:20:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.03 on epoch=489
05/30/2022 01:20:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/30/2022 01:20:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.92 on epoch=494
05/30/2022 01:20:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.11 on epoch=497
05/30/2022 01:20:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.94 on epoch=499
05/30/2022 01:20:22 - INFO - __main__ - Global step 2000 Train loss 1.00 Classification-F1 0.10256410256410256 on epoch=499
05/30/2022 01:20:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.09 on epoch=502
05/30/2022 01:20:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.93 on epoch=504
05/30/2022 01:20:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.07 on epoch=507
05/30/2022 01:20:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.04 on epoch=509
05/30/2022 01:20:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.98 on epoch=512
05/30/2022 01:20:29 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.1 on epoch=512
05/30/2022 01:20:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.08 on epoch=514
05/30/2022 01:20:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
05/30/2022 01:20:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.06 on epoch=519
05/30/2022 01:20:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.98 on epoch=522
05/30/2022 01:20:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.01 on epoch=524
05/30/2022 01:20:35 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.09493670886075949 on epoch=524
05/30/2022 01:20:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.10 on epoch=527
05/30/2022 01:20:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
05/30/2022 01:20:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
05/30/2022 01:20:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.89 on epoch=534
05/30/2022 01:20:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
05/30/2022 01:20:42 - INFO - __main__ - Global step 2150 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=537
05/30/2022 01:20:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.95 on epoch=539
05/30/2022 01:20:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.89 on epoch=542
05/30/2022 01:20:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/30/2022 01:20:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/30/2022 01:20:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
05/30/2022 01:20:49 - INFO - __main__ - Global step 2200 Train loss 0.98 Classification-F1 0.1 on epoch=549
05/30/2022 01:20:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/30/2022 01:20:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.05 on epoch=554
05/30/2022 01:20:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=557
05/30/2022 01:20:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.92 on epoch=559
05/30/2022 01:20:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/30/2022 01:20:55 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.1796875 on epoch=562
05/30/2022 01:20:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.02 on epoch=564
05/30/2022 01:20:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.04 on epoch=567
05/30/2022 01:20:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.98 on epoch=569
05/30/2022 01:21:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
05/30/2022 01:21:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/30/2022 01:21:02 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.14304993252361672 on epoch=574
05/30/2022 01:21:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.97 on epoch=577
05/30/2022 01:21:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/30/2022 01:21:05 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.91 on epoch=582
05/30/2022 01:21:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.90 on epoch=584
05/30/2022 01:21:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.92 on epoch=587
05/30/2022 01:21:08 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.1576923076923077 on epoch=587
05/30/2022 01:21:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.95 on epoch=589
05/30/2022 01:21:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.96 on epoch=592
05/30/2022 01:21:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.97 on epoch=594
05/30/2022 01:21:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.07 on epoch=597
05/30/2022 01:21:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.91 on epoch=599
05/30/2022 01:21:15 - INFO - __main__ - Global step 2400 Train loss 0.97 Classification-F1 0.1 on epoch=599
05/30/2022 01:21:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.95 on epoch=602
05/30/2022 01:21:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.92 on epoch=604
05/30/2022 01:21:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.02 on epoch=607
05/30/2022 01:21:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.86 on epoch=609
05/30/2022 01:21:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.93 on epoch=612
05/30/2022 01:21:21 - INFO - __main__ - Global step 2450 Train loss 0.94 Classification-F1 0.1 on epoch=612
05/30/2022 01:21:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.01 on epoch=614
05/30/2022 01:21:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/30/2022 01:21:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.93 on epoch=619
05/30/2022 01:21:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
05/30/2022 01:21:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.99 on epoch=624
05/30/2022 01:21:28 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.1682769726247987 on epoch=624
05/30/2022 01:21:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/30/2022 01:21:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.03 on epoch=629
05/30/2022 01:21:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.01 on epoch=632
05/30/2022 01:21:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.95 on epoch=634
05/30/2022 01:21:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.00 on epoch=637
05/30/2022 01:21:34 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=637
05/30/2022 01:21:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.07 on epoch=639
05/30/2022 01:21:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.97 on epoch=642
05/30/2022 01:21:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.86 on epoch=644
05/30/2022 01:21:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/30/2022 01:21:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.93 on epoch=649
05/30/2022 01:21:41 - INFO - __main__ - Global step 2600 Train loss 0.95 Classification-F1 0.15625 on epoch=649
05/30/2022 01:21:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.97 on epoch=652
05/30/2022 01:21:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=654
05/30/2022 01:21:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.02 on epoch=657
05/30/2022 01:21:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.09 on epoch=659
05/30/2022 01:21:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
05/30/2022 01:21:48 - INFO - __main__ - Global step 2650 Train loss 1.02 Classification-F1 0.1354895104895105 on epoch=662
05/30/2022 01:21:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.96 on epoch=664
05/30/2022 01:21:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/30/2022 01:21:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.91 on epoch=669
05/30/2022 01:21:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.07 on epoch=672
05/30/2022 01:21:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/30/2022 01:21:54 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.20980302336234538 on epoch=674
05/30/2022 01:21:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/30/2022 01:21:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.98 on epoch=679
05/30/2022 01:21:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.02 on epoch=682
05/30/2022 01:21:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.93 on epoch=684
05/30/2022 01:22:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=687
05/30/2022 01:22:01 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.1767857142857143 on epoch=687
05/30/2022 01:22:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.03 on epoch=689
05/30/2022 01:22:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
05/30/2022 01:22:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/30/2022 01:22:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.00 on epoch=697
05/30/2022 01:22:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=699
05/30/2022 01:22:07 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.10126582278481013 on epoch=699
05/30/2022 01:22:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.99 on epoch=702
05/30/2022 01:22:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.03 on epoch=704
05/30/2022 01:22:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.97 on epoch=707
05/30/2022 01:22:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/30/2022 01:22:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.99 on epoch=712
05/30/2022 01:22:14 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.10126582278481013 on epoch=712
05/30/2022 01:22:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.03 on epoch=714
05/30/2022 01:22:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.82 on epoch=717
05/30/2022 01:22:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.90 on epoch=719
05/30/2022 01:22:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/30/2022 01:22:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.97 on epoch=724
05/30/2022 01:22:20 - INFO - __main__ - Global step 2900 Train loss 0.93 Classification-F1 0.14383875400824553 on epoch=724
05/30/2022 01:22:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.93 on epoch=727
05/30/2022 01:22:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/30/2022 01:22:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.02 on epoch=732
05/30/2022 01:22:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
05/30/2022 01:22:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/30/2022 01:22:27 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.1171875 on epoch=737
05/30/2022 01:22:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/30/2022 01:22:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/30/2022 01:22:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.97 on epoch=744
05/30/2022 01:22:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/30/2022 01:22:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.00 on epoch=749
05/30/2022 01:22:33 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.14583333333333331 on epoch=749
05/30/2022 01:22:34 - INFO - __main__ - save last model!
05/30/2022 01:22:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 01:22:34 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 01:22:34 - INFO - __main__ - Printing 3 examples
05/30/2022 01:22:34 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:22:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:22:34 - INFO - __main__ - Printing 3 examples
05/30/2022 01:22:34 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:22:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:22:34 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:22:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:22:34 - INFO - __main__ - Printing 3 examples
05/30/2022 01:22:34 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:22:34 - INFO - __main__ - ['others']
05/30/2022 01:22:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:22:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:22:34 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:22:36 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:22:40 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:22:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:22:40 - INFO - __main__ - Starting training!
05/30/2022 01:22:41 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:23:24 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.5_8_predictions.txt
05/30/2022 01:23:24 - INFO - __main__ - Classification-F1 on test data: 0.0401
05/30/2022 01:23:24 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.23076923076923078, test_performance=0.04012249342932043
05/30/2022 01:23:25 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
05/30/2022 01:23:25 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:23:25 - INFO - __main__ - Printing 3 examples
05/30/2022 01:23:25 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:23:25 - INFO - __main__ - ['others']
05/30/2022 01:23:25 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:23:25 - INFO - __main__ - ['others']
05/30/2022 01:23:25 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:23:25 - INFO - __main__ - ['others']
05/30/2022 01:23:25 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:23:25 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:23:25 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:23:25 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:23:25 - INFO - __main__ - Printing 3 examples
05/30/2022 01:23:25 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:23:25 - INFO - __main__ - ['others']
05/30/2022 01:23:25 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:23:25 - INFO - __main__ - ['others']
05/30/2022 01:23:25 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:23:25 - INFO - __main__ - ['others']
05/30/2022 01:23:25 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:23:25 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:23:26 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:23:31 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:23:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:23:31 - INFO - __main__ - Starting training!
05/30/2022 01:23:32 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=2
05/30/2022 01:23:34 - INFO - __main__ - Step 20 Global step 20 Train loss 6.37 on epoch=4
05/30/2022 01:23:35 - INFO - __main__ - Step 30 Global step 30 Train loss 5.99 on epoch=7
05/30/2022 01:23:36 - INFO - __main__ - Step 40 Global step 40 Train loss 5.61 on epoch=9
05/30/2022 01:23:37 - INFO - __main__ - Step 50 Global step 50 Train loss 5.46 on epoch=12
05/30/2022 01:23:40 - INFO - __main__ - Global step 50 Train loss 6.03 Classification-F1 0.0 on epoch=12
05/30/2022 01:23:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:23:42 - INFO - __main__ - Step 60 Global step 60 Train loss 5.21 on epoch=14
05/30/2022 01:23:43 - INFO - __main__ - Step 70 Global step 70 Train loss 5.05 on epoch=17
05/30/2022 01:23:44 - INFO - __main__ - Step 80 Global step 80 Train loss 4.74 on epoch=19
05/30/2022 01:23:45 - INFO - __main__ - Step 90 Global step 90 Train loss 4.67 on epoch=22
05/30/2022 01:23:47 - INFO - __main__ - Step 100 Global step 100 Train loss 4.65 on epoch=24
05/30/2022 01:23:51 - INFO - __main__ - Global step 100 Train loss 4.86 Classification-F1 0.0101010101010101 on epoch=24
05/30/2022 01:23:51 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0101010101010101 on epoch=24, global_step=100
05/30/2022 01:23:52 - INFO - __main__ - Step 110 Global step 110 Train loss 4.50 on epoch=27
05/30/2022 01:23:53 - INFO - __main__ - Step 120 Global step 120 Train loss 4.44 on epoch=29
05/30/2022 01:23:55 - INFO - __main__ - Step 130 Global step 130 Train loss 4.29 on epoch=32
05/30/2022 01:23:56 - INFO - __main__ - Step 140 Global step 140 Train loss 3.96 on epoch=34
05/30/2022 01:23:57 - INFO - __main__ - Step 150 Global step 150 Train loss 4.11 on epoch=37
05/30/2022 01:23:58 - INFO - __main__ - Global step 150 Train loss 4.26 Classification-F1 0.1 on epoch=37
05/30/2022 01:23:58 - INFO - __main__ - Saving model with best Classification-F1: 0.0101010101010101 -> 0.1 on epoch=37, global_step=150
05/30/2022 01:23:59 - INFO - __main__ - Step 160 Global step 160 Train loss 3.78 on epoch=39
05/30/2022 01:24:00 - INFO - __main__ - Step 170 Global step 170 Train loss 3.77 on epoch=42
05/30/2022 01:24:01 - INFO - __main__ - Step 180 Global step 180 Train loss 3.47 on epoch=44
05/30/2022 01:24:02 - INFO - __main__ - Step 190 Global step 190 Train loss 3.63 on epoch=47
05/30/2022 01:24:04 - INFO - __main__ - Step 200 Global step 200 Train loss 3.36 on epoch=49
05/30/2022 01:24:04 - INFO - __main__ - Global step 200 Train loss 3.60 Classification-F1 0.1 on epoch=49
05/30/2022 01:24:05 - INFO - __main__ - Step 210 Global step 210 Train loss 3.43 on epoch=52
05/30/2022 01:24:07 - INFO - __main__ - Step 220 Global step 220 Train loss 3.09 on epoch=54
05/30/2022 01:24:08 - INFO - __main__ - Step 230 Global step 230 Train loss 3.27 on epoch=57
05/30/2022 01:24:09 - INFO - __main__ - Step 240 Global step 240 Train loss 3.16 on epoch=59
05/30/2022 01:24:10 - INFO - __main__ - Step 250 Global step 250 Train loss 3.16 on epoch=62
05/30/2022 01:24:11 - INFO - __main__ - Global step 250 Train loss 3.22 Classification-F1 0.08108108108108109 on epoch=62
05/30/2022 01:24:12 - INFO - __main__ - Step 260 Global step 260 Train loss 3.05 on epoch=64
05/30/2022 01:24:13 - INFO - __main__ - Step 270 Global step 270 Train loss 3.19 on epoch=67
05/30/2022 01:24:14 - INFO - __main__ - Step 280 Global step 280 Train loss 2.76 on epoch=69
05/30/2022 01:24:15 - INFO - __main__ - Step 290 Global step 290 Train loss 2.76 on epoch=72
05/30/2022 01:24:17 - INFO - __main__ - Step 300 Global step 300 Train loss 2.83 on epoch=74
05/30/2022 01:24:17 - INFO - __main__ - Global step 300 Train loss 2.92 Classification-F1 0.10256410256410256 on epoch=74
05/30/2022 01:24:17 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10256410256410256 on epoch=74, global_step=300
05/30/2022 01:24:18 - INFO - __main__ - Step 310 Global step 310 Train loss 2.76 on epoch=77
05/30/2022 01:24:20 - INFO - __main__ - Step 320 Global step 320 Train loss 2.60 on epoch=79
05/30/2022 01:24:21 - INFO - __main__ - Step 330 Global step 330 Train loss 2.85 on epoch=82
05/30/2022 01:24:22 - INFO - __main__ - Step 340 Global step 340 Train loss 2.52 on epoch=84
05/30/2022 01:24:23 - INFO - __main__ - Step 350 Global step 350 Train loss 2.61 on epoch=87
05/30/2022 01:24:24 - INFO - __main__ - Global step 350 Train loss 2.67 Classification-F1 0.23911070780399274 on epoch=87
05/30/2022 01:24:24 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.23911070780399274 on epoch=87, global_step=350
05/30/2022 01:24:25 - INFO - __main__ - Step 360 Global step 360 Train loss 2.34 on epoch=89
05/30/2022 01:24:26 - INFO - __main__ - Step 370 Global step 370 Train loss 2.56 on epoch=92
05/30/2022 01:24:27 - INFO - __main__ - Step 380 Global step 380 Train loss 2.29 on epoch=94
05/30/2022 01:24:29 - INFO - __main__ - Step 390 Global step 390 Train loss 2.43 on epoch=97
05/30/2022 01:24:30 - INFO - __main__ - Step 400 Global step 400 Train loss 2.16 on epoch=99
05/30/2022 01:24:30 - INFO - __main__ - Global step 400 Train loss 2.35 Classification-F1 0.1 on epoch=99
05/30/2022 01:24:31 - INFO - __main__ - Step 410 Global step 410 Train loss 2.30 on epoch=102
05/30/2022 01:24:33 - INFO - __main__ - Step 420 Global step 420 Train loss 2.06 on epoch=104
05/30/2022 01:24:34 - INFO - __main__ - Step 430 Global step 430 Train loss 2.19 on epoch=107
05/30/2022 01:24:35 - INFO - __main__ - Step 440 Global step 440 Train loss 2.25 on epoch=109
05/30/2022 01:24:36 - INFO - __main__ - Step 450 Global step 450 Train loss 2.13 on epoch=112
05/30/2022 01:24:37 - INFO - __main__ - Global step 450 Train loss 2.19 Classification-F1 0.1237183868762816 on epoch=112
05/30/2022 01:24:38 - INFO - __main__ - Step 460 Global step 460 Train loss 2.16 on epoch=114
05/30/2022 01:24:39 - INFO - __main__ - Step 470 Global step 470 Train loss 2.08 on epoch=117
05/30/2022 01:24:40 - INFO - __main__ - Step 480 Global step 480 Train loss 2.00 on epoch=119
05/30/2022 01:24:42 - INFO - __main__ - Step 490 Global step 490 Train loss 2.12 on epoch=122
05/30/2022 01:24:43 - INFO - __main__ - Step 500 Global step 500 Train loss 1.92 on epoch=124
05/30/2022 01:24:43 - INFO - __main__ - Global step 500 Train loss 2.05 Classification-F1 0.1 on epoch=124
05/30/2022 01:24:45 - INFO - __main__ - Step 510 Global step 510 Train loss 1.92 on epoch=127
05/30/2022 01:24:46 - INFO - __main__ - Step 520 Global step 520 Train loss 1.85 on epoch=129
05/30/2022 01:24:47 - INFO - __main__ - Step 530 Global step 530 Train loss 1.89 on epoch=132
05/30/2022 01:24:48 - INFO - __main__ - Step 540 Global step 540 Train loss 1.92 on epoch=134
05/30/2022 01:24:49 - INFO - __main__ - Step 550 Global step 550 Train loss 1.72 on epoch=137
05/30/2022 01:24:50 - INFO - __main__ - Global step 550 Train loss 1.86 Classification-F1 0.16666666666666666 on epoch=137
05/30/2022 01:24:51 - INFO - __main__ - Step 560 Global step 560 Train loss 1.68 on epoch=139
05/30/2022 01:24:52 - INFO - __main__ - Step 570 Global step 570 Train loss 1.83 on epoch=142
05/30/2022 01:24:53 - INFO - __main__ - Step 580 Global step 580 Train loss 1.83 on epoch=144
05/30/2022 01:24:55 - INFO - __main__ - Step 590 Global step 590 Train loss 1.77 on epoch=147
05/30/2022 01:24:56 - INFO - __main__ - Step 600 Global step 600 Train loss 1.57 on epoch=149
05/30/2022 01:24:56 - INFO - __main__ - Global step 600 Train loss 1.74 Classification-F1 0.16407982261640797 on epoch=149
05/30/2022 01:24:58 - INFO - __main__ - Step 610 Global step 610 Train loss 1.62 on epoch=152
05/30/2022 01:24:59 - INFO - __main__ - Step 620 Global step 620 Train loss 1.66 on epoch=154
05/30/2022 01:25:00 - INFO - __main__ - Step 630 Global step 630 Train loss 1.77 on epoch=157
05/30/2022 01:25:01 - INFO - __main__ - Step 640 Global step 640 Train loss 1.61 on epoch=159
05/30/2022 01:25:02 - INFO - __main__ - Step 650 Global step 650 Train loss 1.67 on epoch=162
05/30/2022 01:25:03 - INFO - __main__ - Global step 650 Train loss 1.67 Classification-F1 0.14107142857142857 on epoch=162
05/30/2022 01:25:04 - INFO - __main__ - Step 660 Global step 660 Train loss 1.63 on epoch=164
05/30/2022 01:25:05 - INFO - __main__ - Step 670 Global step 670 Train loss 1.51 on epoch=167
05/30/2022 01:25:07 - INFO - __main__ - Step 680 Global step 680 Train loss 1.46 on epoch=169
05/30/2022 01:25:08 - INFO - __main__ - Step 690 Global step 690 Train loss 1.62 on epoch=172
05/30/2022 01:25:09 - INFO - __main__ - Step 700 Global step 700 Train loss 1.48 on epoch=174
05/30/2022 01:25:10 - INFO - __main__ - Global step 700 Train loss 1.54 Classification-F1 0.08863636363636362 on epoch=174
05/30/2022 01:25:11 - INFO - __main__ - Step 710 Global step 710 Train loss 1.63 on epoch=177
05/30/2022 01:25:12 - INFO - __main__ - Step 720 Global step 720 Train loss 1.44 on epoch=179
05/30/2022 01:25:13 - INFO - __main__ - Step 730 Global step 730 Train loss 1.45 on epoch=182
05/30/2022 01:25:14 - INFO - __main__ - Step 740 Global step 740 Train loss 1.43 on epoch=184
05/30/2022 01:25:16 - INFO - __main__ - Step 750 Global step 750 Train loss 1.31 on epoch=187
05/30/2022 01:25:16 - INFO - __main__ - Global step 750 Train loss 1.45 Classification-F1 0.19149305555555554 on epoch=187
05/30/2022 01:25:17 - INFO - __main__ - Step 760 Global step 760 Train loss 1.61 on epoch=189
05/30/2022 01:25:18 - INFO - __main__ - Step 770 Global step 770 Train loss 1.30 on epoch=192
05/30/2022 01:25:20 - INFO - __main__ - Step 780 Global step 780 Train loss 1.35 on epoch=194
05/30/2022 01:25:21 - INFO - __main__ - Step 790 Global step 790 Train loss 1.46 on epoch=197
05/30/2022 01:25:22 - INFO - __main__ - Step 800 Global step 800 Train loss 1.33 on epoch=199
05/30/2022 01:25:23 - INFO - __main__ - Global step 800 Train loss 1.41 Classification-F1 0.13525835866261396 on epoch=199
05/30/2022 01:25:24 - INFO - __main__ - Step 810 Global step 810 Train loss 1.38 on epoch=202
05/30/2022 01:25:25 - INFO - __main__ - Step 820 Global step 820 Train loss 1.43 on epoch=204
05/30/2022 01:25:26 - INFO - __main__ - Step 830 Global step 830 Train loss 1.31 on epoch=207
05/30/2022 01:25:27 - INFO - __main__ - Step 840 Global step 840 Train loss 1.43 on epoch=209
05/30/2022 01:25:29 - INFO - __main__ - Step 850 Global step 850 Train loss 1.30 on epoch=212
05/30/2022 01:25:29 - INFO - __main__ - Global step 850 Train loss 1.37 Classification-F1 0.13475499092558985 on epoch=212
05/30/2022 01:25:30 - INFO - __main__ - Step 860 Global step 860 Train loss 1.23 on epoch=214
05/30/2022 01:25:32 - INFO - __main__ - Step 870 Global step 870 Train loss 1.24 on epoch=217
05/30/2022 01:25:33 - INFO - __main__ - Step 880 Global step 880 Train loss 1.38 on epoch=219
05/30/2022 01:25:34 - INFO - __main__ - Step 890 Global step 890 Train loss 1.25 on epoch=222
05/30/2022 01:25:35 - INFO - __main__ - Step 900 Global step 900 Train loss 1.24 on epoch=224
05/30/2022 01:25:36 - INFO - __main__ - Global step 900 Train loss 1.27 Classification-F1 0.13026315789473686 on epoch=224
05/30/2022 01:25:37 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/30/2022 01:25:38 - INFO - __main__ - Step 920 Global step 920 Train loss 1.27 on epoch=229
05/30/2022 01:25:39 - INFO - __main__ - Step 930 Global step 930 Train loss 1.27 on epoch=232
05/30/2022 01:25:40 - INFO - __main__ - Step 940 Global step 940 Train loss 1.15 on epoch=234
05/30/2022 01:25:42 - INFO - __main__ - Step 950 Global step 950 Train loss 1.30 on epoch=237
05/30/2022 01:25:42 - INFO - __main__ - Global step 950 Train loss 1.24 Classification-F1 0.10666666666666667 on epoch=237
05/30/2022 01:25:43 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
05/30/2022 01:25:45 - INFO - __main__ - Step 970 Global step 970 Train loss 1.27 on epoch=242
05/30/2022 01:25:46 - INFO - __main__ - Step 980 Global step 980 Train loss 1.21 on epoch=244
05/30/2022 01:25:47 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=247
05/30/2022 01:25:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.24 on epoch=249
05/30/2022 01:25:49 - INFO - __main__ - Global step 1000 Train loss 1.28 Classification-F1 0.13067758749069247 on epoch=249
05/30/2022 01:25:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.20 on epoch=252
05/30/2022 01:25:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.36 on epoch=254
05/30/2022 01:25:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.21 on epoch=257
05/30/2022 01:25:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.23 on epoch=259
05/30/2022 01:25:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.16 on epoch=262
05/30/2022 01:25:55 - INFO - __main__ - Global step 1050 Train loss 1.23 Classification-F1 0.18920361247947456 on epoch=262
05/30/2022 01:25:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.21 on epoch=264
05/30/2022 01:25:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.24 on epoch=267
05/30/2022 01:25:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
05/30/2022 01:26:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.20 on epoch=272
05/30/2022 01:26:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.07 on epoch=274
05/30/2022 01:26:02 - INFO - __main__ - Global step 1100 Train loss 1.18 Classification-F1 0.15208955223880596 on epoch=274
05/30/2022 01:26:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.00 on epoch=277
05/30/2022 01:26:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.05 on epoch=279
05/30/2022 01:26:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.21 on epoch=282
05/30/2022 01:26:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.98 on epoch=284
05/30/2022 01:26:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.27 on epoch=287
05/30/2022 01:26:08 - INFO - __main__ - Global step 1150 Train loss 1.10 Classification-F1 0.178243195475433 on epoch=287
05/30/2022 01:26:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.15 on epoch=289
05/30/2022 01:26:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.14 on epoch=292
05/30/2022 01:26:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.07 on epoch=294
05/30/2022 01:26:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.17 on epoch=297
05/30/2022 01:26:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.26 on epoch=299
05/30/2022 01:26:15 - INFO - __main__ - Global step 1200 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=299
05/30/2022 01:26:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
05/30/2022 01:26:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.08 on epoch=304
05/30/2022 01:26:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.19 on epoch=307
05/30/2022 01:26:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.16 on epoch=309
05/30/2022 01:26:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.02 on epoch=312
05/30/2022 01:26:21 - INFO - __main__ - Global step 1250 Train loss 1.12 Classification-F1 0.18860472005529771 on epoch=312
05/30/2022 01:26:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.01 on epoch=314
05/30/2022 01:26:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.07 on epoch=317
05/30/2022 01:26:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
05/30/2022 01:26:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.17 on epoch=322
05/30/2022 01:26:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.10 on epoch=324
05/30/2022 01:26:28 - INFO - __main__ - Global step 1300 Train loss 1.10 Classification-F1 0.14210526315789473 on epoch=324
05/30/2022 01:26:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.17 on epoch=327
05/30/2022 01:26:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.08 on epoch=329
05/30/2022 01:26:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=332
05/30/2022 01:26:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.10 on epoch=334
05/30/2022 01:26:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.13 on epoch=337
05/30/2022 01:26:34 - INFO - __main__ - Global step 1350 Train loss 1.14 Classification-F1 0.12407862407862408 on epoch=337
05/30/2022 01:26:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/30/2022 01:26:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/30/2022 01:26:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.07 on epoch=344
05/30/2022 01:26:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.17 on epoch=347
05/30/2022 01:26:41 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=349
05/30/2022 01:26:41 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.10666666666666667 on epoch=349
05/30/2022 01:26:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.08 on epoch=352
05/30/2022 01:26:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.04 on epoch=354
05/30/2022 01:26:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/30/2022 01:26:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.05 on epoch=359
05/30/2022 01:26:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.05 on epoch=362
05/30/2022 01:26:48 - INFO - __main__ - Global step 1450 Train loss 1.07 Classification-F1 0.15838509316770188 on epoch=362
05/30/2022 01:26:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/30/2022 01:26:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.07 on epoch=367
05/30/2022 01:26:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.08 on epoch=369
05/30/2022 01:26:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.94 on epoch=372
05/30/2022 01:26:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.01 on epoch=374
05/30/2022 01:26:55 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.1497584541062802 on epoch=374
05/30/2022 01:26:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.15 on epoch=377
05/30/2022 01:26:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=379
05/30/2022 01:26:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.19 on epoch=382
05/30/2022 01:27:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=384
05/30/2022 01:27:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.06 on epoch=387
05/30/2022 01:27:01 - INFO - __main__ - Global step 1550 Train loss 1.09 Classification-F1 0.10389610389610389 on epoch=387
05/30/2022 01:27:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.02 on epoch=389
05/30/2022 01:27:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.11 on epoch=392
05/30/2022 01:27:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.10 on epoch=394
05/30/2022 01:27:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.02 on epoch=397
05/30/2022 01:27:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.95 on epoch=399
05/30/2022 01:27:08 - INFO - __main__ - Global step 1600 Train loss 1.04 Classification-F1 0.11157407407407408 on epoch=399
05/30/2022 01:27:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
05/30/2022 01:27:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/30/2022 01:27:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.07 on epoch=407
05/30/2022 01:27:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/30/2022 01:27:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/30/2022 01:27:15 - INFO - __main__ - Global step 1650 Train loss 1.06 Classification-F1 0.20924825940892933 on epoch=412
05/30/2022 01:27:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.96 on epoch=414
05/30/2022 01:27:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.93 on epoch=417
05/30/2022 01:27:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.97 on epoch=419
05/30/2022 01:27:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.02 on epoch=422
05/30/2022 01:27:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.02 on epoch=424
05/30/2022 01:27:22 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.2109375 on epoch=424
05/30/2022 01:27:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.07 on epoch=427
05/30/2022 01:27:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.97 on epoch=429
05/30/2022 01:27:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.04 on epoch=432
05/30/2022 01:27:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.09 on epoch=434
05/30/2022 01:27:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.97 on epoch=437
05/30/2022 01:27:28 - INFO - __main__ - Global step 1750 Train loss 1.03 Classification-F1 0.1 on epoch=437
05/30/2022 01:27:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
05/30/2022 01:27:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.03 on epoch=442
05/30/2022 01:27:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/30/2022 01:27:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.00 on epoch=447
05/30/2022 01:27:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
05/30/2022 01:27:35 - INFO - __main__ - Global step 1800 Train loss 1.03 Classification-F1 0.1 on epoch=449
05/30/2022 01:27:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.95 on epoch=452
05/30/2022 01:27:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.91 on epoch=454
05/30/2022 01:27:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.12 on epoch=457
05/30/2022 01:27:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.02 on epoch=459
05/30/2022 01:27:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.00 on epoch=462
05/30/2022 01:27:42 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.20614919354838712 on epoch=462
05/30/2022 01:27:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=464
05/30/2022 01:27:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.00 on epoch=467
05/30/2022 01:27:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.90 on epoch=469
05/30/2022 01:27:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.94 on epoch=472
05/30/2022 01:27:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.13 on epoch=474
05/30/2022 01:27:49 - INFO - __main__ - Global step 1900 Train loss 0.99 Classification-F1 0.13026315789473686 on epoch=474
05/30/2022 01:27:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
05/30/2022 01:27:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.07 on epoch=479
05/30/2022 01:27:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.99 on epoch=482
05/30/2022 01:27:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.98 on epoch=484
05/30/2022 01:27:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.04 on epoch=487
05/30/2022 01:27:55 - INFO - __main__ - Global step 1950 Train loss 1.01 Classification-F1 0.13194444444444445 on epoch=487
05/30/2022 01:27:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.97 on epoch=489
05/30/2022 01:27:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=492
05/30/2022 01:27:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.05 on epoch=494
05/30/2022 01:28:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=497
05/30/2022 01:28:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.98 on epoch=499
05/30/2022 01:28:02 - INFO - __main__ - Global step 2000 Train loss 1.01 Classification-F1 0.13034188034188032 on epoch=499
05/30/2022 01:28:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/30/2022 01:28:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.06 on epoch=504
05/30/2022 01:28:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=507
05/30/2022 01:28:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.01 on epoch=509
05/30/2022 01:28:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.99 on epoch=512
05/30/2022 01:28:09 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.18948412698412698 on epoch=512
05/30/2022 01:28:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.02 on epoch=514
05/30/2022 01:28:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/30/2022 01:28:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.98 on epoch=519
05/30/2022 01:28:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.05 on epoch=522
05/30/2022 01:28:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
05/30/2022 01:28:16 - INFO - __main__ - Global step 2100 Train loss 1.04 Classification-F1 0.16666666666666669 on epoch=524
05/30/2022 01:28:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.06 on epoch=527
05/30/2022 01:28:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.05 on epoch=529
05/30/2022 01:28:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/30/2022 01:28:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.92 on epoch=534
05/30/2022 01:28:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.97 on epoch=537
05/30/2022 01:28:22 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=537
05/30/2022 01:28:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/30/2022 01:28:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
05/30/2022 01:28:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.96 on epoch=544
05/30/2022 01:28:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/30/2022 01:28:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=549
05/30/2022 01:28:29 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.13430127041742287 on epoch=549
05/30/2022 01:28:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.91 on epoch=552
05/30/2022 01:28:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.98 on epoch=554
05/30/2022 01:28:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.98 on epoch=557
05/30/2022 01:28:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.05 on epoch=559
05/30/2022 01:28:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.02 on epoch=562
05/30/2022 01:28:36 - INFO - __main__ - Global step 2250 Train loss 0.99 Classification-F1 0.2897623608830505 on epoch=562
05/30/2022 01:28:36 - INFO - __main__ - Saving model with best Classification-F1: 0.23911070780399274 -> 0.2897623608830505 on epoch=562, global_step=2250
05/30/2022 01:28:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.09 on epoch=564
05/30/2022 01:28:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.92 on epoch=567
05/30/2022 01:28:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.93 on epoch=569
05/30/2022 01:28:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.97 on epoch=572
05/30/2022 01:28:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
05/30/2022 01:28:43 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.15718418514946964 on epoch=574
05/30/2022 01:28:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.07 on epoch=577
05/30/2022 01:28:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
05/30/2022 01:28:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/30/2022 01:28:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.91 on epoch=584
05/30/2022 01:28:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.03 on epoch=587
05/30/2022 01:28:49 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.12091038406827881 on epoch=587
05/30/2022 01:28:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.92 on epoch=589
05/30/2022 01:28:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/30/2022 01:28:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.95 on epoch=594
05/30/2022 01:28:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.99 on epoch=597
05/30/2022 01:28:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.98 on epoch=599
05/30/2022 01:28:56 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.17075892857142858 on epoch=599
05/30/2022 01:28:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/30/2022 01:28:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
05/30/2022 01:29:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.94 on epoch=607
05/30/2022 01:29:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.98 on epoch=609
05/30/2022 01:29:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.92 on epoch=612
05/30/2022 01:29:03 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.19285387081997252 on epoch=612
05/30/2022 01:29:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.97 on epoch=614
05/30/2022 01:29:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.89 on epoch=617
05/30/2022 01:29:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.03 on epoch=619
05/30/2022 01:29:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.93 on epoch=622
05/30/2022 01:29:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/30/2022 01:29:10 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.09589041095890412 on epoch=624
05/30/2022 01:29:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.00 on epoch=627
05/30/2022 01:29:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=629
05/30/2022 01:29:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.88 on epoch=632
05/30/2022 01:29:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/30/2022 01:29:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.94 on epoch=637
05/30/2022 01:29:16 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.16666666666666666 on epoch=637
05/30/2022 01:29:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.04 on epoch=639
05/30/2022 01:29:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.89 on epoch=642
05/30/2022 01:29:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.01 on epoch=644
05/30/2022 01:29:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.97 on epoch=647
05/30/2022 01:29:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.90 on epoch=649
05/30/2022 01:29:23 - INFO - __main__ - Global step 2600 Train loss 0.96 Classification-F1 0.23394278135657448 on epoch=649
05/30/2022 01:29:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.91 on epoch=652
05/30/2022 01:29:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
05/30/2022 01:29:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.90 on epoch=657
05/30/2022 01:29:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.99 on epoch=659
05/30/2022 01:29:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/30/2022 01:29:30 - INFO - __main__ - Global step 2650 Train loss 0.93 Classification-F1 0.09333333333333334 on epoch=662
05/30/2022 01:29:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.02 on epoch=664
05/30/2022 01:29:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.96 on epoch=667
05/30/2022 01:29:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.90 on epoch=669
05/30/2022 01:29:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=672
05/30/2022 01:29:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.00 on epoch=674
05/30/2022 01:29:37 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.20380692599620492 on epoch=674
05/30/2022 01:29:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/30/2022 01:29:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.91 on epoch=679
05/30/2022 01:29:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.88 on epoch=682
05/30/2022 01:29:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/30/2022 01:29:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.89 on epoch=687
05/30/2022 01:29:43 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.1015625 on epoch=687
05/30/2022 01:29:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.11 on epoch=689
05/30/2022 01:29:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.96 on epoch=692
05/30/2022 01:29:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.03 on epoch=694
05/30/2022 01:29:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.90 on epoch=697
05/30/2022 01:29:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.00 on epoch=699
05/30/2022 01:29:50 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.12400635930047696 on epoch=699
05/30/2022 01:29:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.95 on epoch=702
05/30/2022 01:29:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.05 on epoch=704
05/30/2022 01:29:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.94 on epoch=707
05/30/2022 01:29:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/30/2022 01:29:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.92 on epoch=712
05/30/2022 01:29:57 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=712
05/30/2022 01:29:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.93 on epoch=714
05/30/2022 01:29:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.00 on epoch=717
05/30/2022 01:30:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.00 on epoch=719
05/30/2022 01:30:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/30/2022 01:30:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/30/2022 01:30:03 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.15521739130434786 on epoch=724
05/30/2022 01:30:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.92 on epoch=727
05/30/2022 01:30:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.99 on epoch=729
05/30/2022 01:30:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
05/30/2022 01:30:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/30/2022 01:30:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
05/30/2022 01:30:10 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.12228260869565218 on epoch=737
05/30/2022 01:30:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.08 on epoch=739
05/30/2022 01:30:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.96 on epoch=742
05/30/2022 01:30:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/30/2022 01:30:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.90 on epoch=747
05/30/2022 01:30:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.91 on epoch=749
05/30/2022 01:30:17 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.1 on epoch=749
05/30/2022 01:30:17 - INFO - __main__ - save last model!
05/30/2022 01:30:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 01:30:17 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 01:30:17 - INFO - __main__ - Printing 3 examples
05/30/2022 01:30:17 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:30:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:30:17 - INFO - __main__ - Printing 3 examples
05/30/2022 01:30:17 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:30:17 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:30:17 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:30:17 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:30:17 - INFO - __main__ - Printing 3 examples
05/30/2022 01:30:17 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:30:17 - INFO - __main__ - ['others']
05/30/2022 01:30:17 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:30:17 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:30:17 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:30:19 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:30:23 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:30:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:30:23 - INFO - __main__ - Starting training!
05/30/2022 01:30:24 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:31:08 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.4_8_predictions.txt
05/30/2022 01:31:08 - INFO - __main__ - Classification-F1 on test data: 0.0315
05/30/2022 01:31:08 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.2897623608830505, test_performance=0.03154834166311928
05/30/2022 01:31:08 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
05/30/2022 01:31:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:31:09 - INFO - __main__ - Printing 3 examples
05/30/2022 01:31:09 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:31:09 - INFO - __main__ - ['others']
05/30/2022 01:31:09 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:31:09 - INFO - __main__ - ['others']
05/30/2022 01:31:09 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:31:09 - INFO - __main__ - ['others']
05/30/2022 01:31:09 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:31:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:31:09 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:31:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:31:09 - INFO - __main__ - Printing 3 examples
05/30/2022 01:31:09 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:31:09 - INFO - __main__ - ['others']
05/30/2022 01:31:09 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:31:09 - INFO - __main__ - ['others']
05/30/2022 01:31:09 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:31:09 - INFO - __main__ - ['others']
05/30/2022 01:31:09 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:31:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:31:09 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:31:14 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:31:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:31:14 - INFO - __main__ - Starting training!
05/30/2022 01:31:16 - INFO - __main__ - Step 10 Global step 10 Train loss 6.67 on epoch=2
05/30/2022 01:31:17 - INFO - __main__ - Step 20 Global step 20 Train loss 6.58 on epoch=4
05/30/2022 01:31:18 - INFO - __main__ - Step 30 Global step 30 Train loss 6.29 on epoch=7
05/30/2022 01:31:19 - INFO - __main__ - Step 40 Global step 40 Train loss 6.15 on epoch=9
05/30/2022 01:31:20 - INFO - __main__ - Step 50 Global step 50 Train loss 5.94 on epoch=12
05/30/2022 01:31:29 - INFO - __main__ - Global step 50 Train loss 6.32 Classification-F1 0.0 on epoch=12
05/30/2022 01:31:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:31:30 - INFO - __main__ - Step 60 Global step 60 Train loss 5.72 on epoch=14
05/30/2022 01:31:31 - INFO - __main__ - Step 70 Global step 70 Train loss 5.55 on epoch=17
05/30/2022 01:31:32 - INFO - __main__ - Step 80 Global step 80 Train loss 5.44 on epoch=19
05/30/2022 01:31:33 - INFO - __main__ - Step 90 Global step 90 Train loss 5.28 on epoch=22
05/30/2022 01:31:35 - INFO - __main__ - Step 100 Global step 100 Train loss 5.08 on epoch=24
05/30/2022 01:31:36 - INFO - __main__ - Global step 100 Train loss 5.41 Classification-F1 0.0 on epoch=24
05/30/2022 01:31:37 - INFO - __main__ - Step 110 Global step 110 Train loss 4.88 on epoch=27
05/30/2022 01:31:39 - INFO - __main__ - Step 120 Global step 120 Train loss 4.79 on epoch=29
05/30/2022 01:31:40 - INFO - __main__ - Step 130 Global step 130 Train loss 4.51 on epoch=32
05/30/2022 01:31:41 - INFO - __main__ - Step 140 Global step 140 Train loss 4.47 on epoch=34
05/30/2022 01:31:42 - INFO - __main__ - Step 150 Global step 150 Train loss 4.41 on epoch=37
05/30/2022 01:31:43 - INFO - __main__ - Global step 150 Train loss 4.61 Classification-F1 0.07915893630179342 on epoch=37
05/30/2022 01:31:43 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07915893630179342 on epoch=37, global_step=150
05/30/2022 01:31:44 - INFO - __main__ - Step 160 Global step 160 Train loss 4.15 on epoch=39
05/30/2022 01:31:46 - INFO - __main__ - Step 170 Global step 170 Train loss 4.13 on epoch=42
05/30/2022 01:31:47 - INFO - __main__ - Step 180 Global step 180 Train loss 3.93 on epoch=44
05/30/2022 01:31:48 - INFO - __main__ - Step 190 Global step 190 Train loss 3.80 on epoch=47
05/30/2022 01:31:49 - INFO - __main__ - Step 200 Global step 200 Train loss 3.82 on epoch=49
05/30/2022 01:31:50 - INFO - __main__ - Global step 200 Train loss 3.96 Classification-F1 0.09477124183006536 on epoch=49
05/30/2022 01:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.07915893630179342 -> 0.09477124183006536 on epoch=49, global_step=200
05/30/2022 01:31:51 - INFO - __main__ - Step 210 Global step 210 Train loss 3.67 on epoch=52
05/30/2022 01:31:52 - INFO - __main__ - Step 220 Global step 220 Train loss 3.40 on epoch=54
05/30/2022 01:31:53 - INFO - __main__ - Step 230 Global step 230 Train loss 3.49 on epoch=57
05/30/2022 01:31:54 - INFO - __main__ - Step 240 Global step 240 Train loss 3.20 on epoch=59
05/30/2022 01:31:56 - INFO - __main__ - Step 250 Global step 250 Train loss 3.30 on epoch=62
05/30/2022 01:31:56 - INFO - __main__ - Global step 250 Train loss 3.41 Classification-F1 0.16084656084656085 on epoch=62
05/30/2022 01:31:56 - INFO - __main__ - Saving model with best Classification-F1: 0.09477124183006536 -> 0.16084656084656085 on epoch=62, global_step=250
05/30/2022 01:31:57 - INFO - __main__ - Step 260 Global step 260 Train loss 3.37 on epoch=64
05/30/2022 01:31:59 - INFO - __main__ - Step 270 Global step 270 Train loss 3.17 on epoch=67
05/30/2022 01:32:00 - INFO - __main__ - Step 280 Global step 280 Train loss 3.02 on epoch=69
05/30/2022 01:32:01 - INFO - __main__ - Step 290 Global step 290 Train loss 3.09 on epoch=72
05/30/2022 01:32:02 - INFO - __main__ - Step 300 Global step 300 Train loss 2.82 on epoch=74
05/30/2022 01:32:03 - INFO - __main__ - Global step 300 Train loss 3.09 Classification-F1 0.13198653198653199 on epoch=74
05/30/2022 01:32:04 - INFO - __main__ - Step 310 Global step 310 Train loss 3.05 on epoch=77
05/30/2022 01:32:05 - INFO - __main__ - Step 320 Global step 320 Train loss 2.66 on epoch=79
05/30/2022 01:32:06 - INFO - __main__ - Step 330 Global step 330 Train loss 2.89 on epoch=82
05/30/2022 01:32:08 - INFO - __main__ - Step 340 Global step 340 Train loss 2.62 on epoch=84
05/30/2022 01:32:09 - INFO - __main__ - Step 350 Global step 350 Train loss 2.79 on epoch=87
05/30/2022 01:32:09 - INFO - __main__ - Global step 350 Train loss 2.80 Classification-F1 0.13034188034188032 on epoch=87
05/30/2022 01:32:11 - INFO - __main__ - Step 360 Global step 360 Train loss 2.62 on epoch=89
05/30/2022 01:32:12 - INFO - __main__ - Step 370 Global step 370 Train loss 2.69 on epoch=92
05/30/2022 01:32:13 - INFO - __main__ - Step 380 Global step 380 Train loss 2.48 on epoch=94
05/30/2022 01:32:14 - INFO - __main__ - Step 390 Global step 390 Train loss 2.57 on epoch=97
05/30/2022 01:32:15 - INFO - __main__ - Step 400 Global step 400 Train loss 2.47 on epoch=99
05/30/2022 01:32:16 - INFO - __main__ - Global step 400 Train loss 2.57 Classification-F1 0.20804195804195807 on epoch=99
05/30/2022 01:32:16 - INFO - __main__ - Saving model with best Classification-F1: 0.16084656084656085 -> 0.20804195804195807 on epoch=99, global_step=400
05/30/2022 01:32:17 - INFO - __main__ - Step 410 Global step 410 Train loss 2.71 on epoch=102
05/30/2022 01:32:18 - INFO - __main__ - Step 420 Global step 420 Train loss 2.31 on epoch=104
05/30/2022 01:32:20 - INFO - __main__ - Step 430 Global step 430 Train loss 2.44 on epoch=107
05/30/2022 01:32:21 - INFO - __main__ - Step 440 Global step 440 Train loss 2.37 on epoch=109
05/30/2022 01:32:22 - INFO - __main__ - Step 450 Global step 450 Train loss 2.66 on epoch=112
05/30/2022 01:32:23 - INFO - __main__ - Global step 450 Train loss 2.50 Classification-F1 0.14242424242424243 on epoch=112
05/30/2022 01:32:24 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=114
05/30/2022 01:32:25 - INFO - __main__ - Step 470 Global step 470 Train loss 2.43 on epoch=117
05/30/2022 01:32:26 - INFO - __main__ - Step 480 Global step 480 Train loss 2.24 on epoch=119
05/30/2022 01:32:27 - INFO - __main__ - Step 490 Global step 490 Train loss 2.50 on epoch=122
05/30/2022 01:32:29 - INFO - __main__ - Step 500 Global step 500 Train loss 2.10 on epoch=124
05/30/2022 01:32:29 - INFO - __main__ - Global step 500 Train loss 2.32 Classification-F1 0.1565276828434723 on epoch=124
05/30/2022 01:32:30 - INFO - __main__ - Step 510 Global step 510 Train loss 2.22 on epoch=127
05/30/2022 01:32:32 - INFO - __main__ - Step 520 Global step 520 Train loss 2.08 on epoch=129
05/30/2022 01:32:33 - INFO - __main__ - Step 530 Global step 530 Train loss 2.27 on epoch=132
05/30/2022 01:32:34 - INFO - __main__ - Step 540 Global step 540 Train loss 2.01 on epoch=134
05/30/2022 01:32:35 - INFO - __main__ - Step 550 Global step 550 Train loss 2.14 on epoch=137
05/30/2022 01:32:36 - INFO - __main__ - Global step 550 Train loss 2.14 Classification-F1 0.1105263157894737 on epoch=137
05/30/2022 01:32:37 - INFO - __main__ - Step 560 Global step 560 Train loss 2.22 on epoch=139
05/30/2022 01:32:38 - INFO - __main__ - Step 570 Global step 570 Train loss 2.04 on epoch=142
05/30/2022 01:32:39 - INFO - __main__ - Step 580 Global step 580 Train loss 1.98 on epoch=144
05/30/2022 01:32:40 - INFO - __main__ - Step 590 Global step 590 Train loss 2.13 on epoch=147
05/30/2022 01:32:42 - INFO - __main__ - Step 600 Global step 600 Train loss 1.92 on epoch=149
05/30/2022 01:32:42 - INFO - __main__ - Global step 600 Train loss 2.06 Classification-F1 0.16666666666666666 on epoch=149
05/30/2022 01:32:43 - INFO - __main__ - Step 610 Global step 610 Train loss 1.98 on epoch=152
05/30/2022 01:32:45 - INFO - __main__ - Step 620 Global step 620 Train loss 1.95 on epoch=154
05/30/2022 01:32:46 - INFO - __main__ - Step 630 Global step 630 Train loss 2.00 on epoch=157
05/30/2022 01:32:47 - INFO - __main__ - Step 640 Global step 640 Train loss 1.95 on epoch=159
05/30/2022 01:32:48 - INFO - __main__ - Step 650 Global step 650 Train loss 1.96 on epoch=162
05/30/2022 01:32:49 - INFO - __main__ - Global step 650 Train loss 1.97 Classification-F1 0.18614718614718614 on epoch=162
05/30/2022 01:32:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.67 on epoch=164
05/30/2022 01:32:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.86 on epoch=167
05/30/2022 01:32:52 - INFO - __main__ - Step 680 Global step 680 Train loss 1.83 on epoch=169
05/30/2022 01:32:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.74 on epoch=172
05/30/2022 01:32:55 - INFO - __main__ - Step 700 Global step 700 Train loss 1.84 on epoch=174
05/30/2022 01:32:55 - INFO - __main__ - Global step 700 Train loss 1.79 Classification-F1 0.11710526315789474 on epoch=174
05/30/2022 01:32:57 - INFO - __main__ - Step 710 Global step 710 Train loss 1.93 on epoch=177
05/30/2022 01:32:58 - INFO - __main__ - Step 720 Global step 720 Train loss 1.64 on epoch=179
05/30/2022 01:32:59 - INFO - __main__ - Step 730 Global step 730 Train loss 1.72 on epoch=182
05/30/2022 01:33:00 - INFO - __main__ - Step 740 Global step 740 Train loss 1.83 on epoch=184
05/30/2022 01:33:01 - INFO - __main__ - Step 750 Global step 750 Train loss 1.69 on epoch=187
05/30/2022 01:33:02 - INFO - __main__ - Global step 750 Train loss 1.76 Classification-F1 0.09493670886075949 on epoch=187
05/30/2022 01:33:03 - INFO - __main__ - Step 760 Global step 760 Train loss 1.82 on epoch=189
05/30/2022 01:33:04 - INFO - __main__ - Step 770 Global step 770 Train loss 1.57 on epoch=192
05/30/2022 01:33:06 - INFO - __main__ - Step 780 Global step 780 Train loss 1.67 on epoch=194
05/30/2022 01:33:07 - INFO - __main__ - Step 790 Global step 790 Train loss 1.74 on epoch=197
05/30/2022 01:33:08 - INFO - __main__ - Step 800 Global step 800 Train loss 1.51 on epoch=199
05/30/2022 01:33:08 - INFO - __main__ - Global step 800 Train loss 1.66 Classification-F1 0.13936867182846935 on epoch=199
05/30/2022 01:33:10 - INFO - __main__ - Step 810 Global step 810 Train loss 1.65 on epoch=202
05/30/2022 01:33:11 - INFO - __main__ - Step 820 Global step 820 Train loss 1.61 on epoch=204
05/30/2022 01:33:12 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/30/2022 01:33:13 - INFO - __main__ - Step 840 Global step 840 Train loss 1.48 on epoch=209
05/30/2022 01:33:14 - INFO - __main__ - Step 850 Global step 850 Train loss 1.59 on epoch=212
05/30/2022 01:33:15 - INFO - __main__ - Global step 850 Train loss 1.60 Classification-F1 0.13624338624338622 on epoch=212
05/30/2022 01:33:16 - INFO - __main__ - Step 860 Global step 860 Train loss 1.57 on epoch=214
05/30/2022 01:33:17 - INFO - __main__ - Step 870 Global step 870 Train loss 1.42 on epoch=217
05/30/2022 01:33:19 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=219
05/30/2022 01:33:20 - INFO - __main__ - Step 890 Global step 890 Train loss 1.49 on epoch=222
05/30/2022 01:33:21 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=224
05/30/2022 01:33:21 - INFO - __main__ - Global step 900 Train loss 1.46 Classification-F1 0.19016393442622948 on epoch=224
05/30/2022 01:33:23 - INFO - __main__ - Step 910 Global step 910 Train loss 1.58 on epoch=227
05/30/2022 01:33:24 - INFO - __main__ - Step 920 Global step 920 Train loss 1.27 on epoch=229
05/30/2022 01:33:25 - INFO - __main__ - Step 930 Global step 930 Train loss 1.41 on epoch=232
05/30/2022 01:33:26 - INFO - __main__ - Step 940 Global step 940 Train loss 1.42 on epoch=234
05/30/2022 01:33:28 - INFO - __main__ - Step 950 Global step 950 Train loss 1.54 on epoch=237
05/30/2022 01:33:28 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.1576923076923077 on epoch=237
05/30/2022 01:33:29 - INFO - __main__ - Step 960 Global step 960 Train loss 1.30 on epoch=239
05/30/2022 01:33:30 - INFO - __main__ - Step 970 Global step 970 Train loss 1.56 on epoch=242
05/30/2022 01:33:32 - INFO - __main__ - Step 980 Global step 980 Train loss 1.32 on epoch=244
05/30/2022 01:33:33 - INFO - __main__ - Step 990 Global step 990 Train loss 1.37 on epoch=247
05/30/2022 01:33:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.36 on epoch=249
05/30/2022 01:33:35 - INFO - __main__ - Global step 1000 Train loss 1.38 Classification-F1 0.1302118933697881 on epoch=249
05/30/2022 01:33:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.43 on epoch=252
05/30/2022 01:33:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
05/30/2022 01:33:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.24 on epoch=257
05/30/2022 01:33:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.36 on epoch=259
05/30/2022 01:33:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.57 on epoch=262
05/30/2022 01:33:42 - INFO - __main__ - Global step 1050 Train loss 1.39 Classification-F1 0.08333333333333333 on epoch=262
05/30/2022 01:33:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.32 on epoch=264
05/30/2022 01:33:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.58 on epoch=267
05/30/2022 01:33:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.35 on epoch=269
05/30/2022 01:33:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.46 on epoch=272
05/30/2022 01:33:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
05/30/2022 01:33:48 - INFO - __main__ - Global step 1100 Train loss 1.38 Classification-F1 0.09333333333333334 on epoch=274
05/30/2022 01:33:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/30/2022 01:33:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.32 on epoch=279
05/30/2022 01:33:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.22 on epoch=282
05/30/2022 01:33:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.39 on epoch=284
05/30/2022 01:33:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.17 on epoch=287
05/30/2022 01:33:55 - INFO - __main__ - Global step 1150 Train loss 1.27 Classification-F1 0.1 on epoch=287
05/30/2022 01:33:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.21 on epoch=289
05/30/2022 01:33:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.28 on epoch=292
05/30/2022 01:33:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.20 on epoch=294
05/30/2022 01:34:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.37 on epoch=297
05/30/2022 01:34:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.27 on epoch=299
05/30/2022 01:34:02 - INFO - __main__ - Global step 1200 Train loss 1.26 Classification-F1 0.1 on epoch=299
05/30/2022 01:34:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.35 on epoch=302
05/30/2022 01:34:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.22 on epoch=304
05/30/2022 01:34:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=307
05/30/2022 01:34:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.30 on epoch=309
05/30/2022 01:34:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.24 on epoch=312
05/30/2022 01:34:09 - INFO - __main__ - Global step 1250 Train loss 1.28 Classification-F1 0.10256410256410256 on epoch=312
05/30/2022 01:34:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
05/30/2022 01:34:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.38 on epoch=317
05/30/2022 01:34:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.23 on epoch=319
05/30/2022 01:34:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.15 on epoch=322
05/30/2022 01:34:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.13 on epoch=324
05/30/2022 01:34:16 - INFO - __main__ - Global step 1300 Train loss 1.24 Classification-F1 0.1611111111111111 on epoch=324
05/30/2022 01:34:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.24 on epoch=327
05/30/2022 01:34:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.18 on epoch=329
05/30/2022 01:34:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.11 on epoch=332
05/30/2022 01:34:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.27 on epoch=334
05/30/2022 01:34:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.21 on epoch=337
05/30/2022 01:34:22 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.1658268437929455 on epoch=337
05/30/2022 01:34:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/30/2022 01:34:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.20 on epoch=342
05/30/2022 01:34:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.29 on epoch=344
05/30/2022 01:34:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.16 on epoch=347
05/30/2022 01:34:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
05/30/2022 01:34:29 - INFO - __main__ - Global step 1400 Train loss 1.21 Classification-F1 0.10126582278481013 on epoch=349
05/30/2022 01:34:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.24 on epoch=352
05/30/2022 01:34:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.28 on epoch=354
05/30/2022 01:34:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.15 on epoch=357
05/30/2022 01:34:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.21 on epoch=359
05/30/2022 01:34:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.21 on epoch=362
05/30/2022 01:34:36 - INFO - __main__ - Global step 1450 Train loss 1.22 Classification-F1 0.13034188034188032 on epoch=362
05/30/2022 01:34:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.21 on epoch=364
05/30/2022 01:34:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.26 on epoch=367
05/30/2022 01:34:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
05/30/2022 01:34:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/30/2022 01:34:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.18 on epoch=374
05/30/2022 01:34:43 - INFO - __main__ - Global step 1500 Train loss 1.19 Classification-F1 0.10126582278481013 on epoch=374
05/30/2022 01:34:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.16 on epoch=377
05/30/2022 01:34:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.18 on epoch=379
05/30/2022 01:34:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.14 on epoch=382
05/30/2022 01:34:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.14 on epoch=384
05/30/2022 01:34:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=387
05/30/2022 01:34:50 - INFO - __main__ - Global step 1550 Train loss 1.16 Classification-F1 0.0901639344262295 on epoch=387
05/30/2022 01:34:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.15 on epoch=389
05/30/2022 01:34:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.22 on epoch=392
05/30/2022 01:34:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.11 on epoch=394
05/30/2022 01:34:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.11 on epoch=397
05/30/2022 01:34:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
05/30/2022 01:34:56 - INFO - __main__ - Global step 1600 Train loss 1.14 Classification-F1 0.13846153846153847 on epoch=399
05/30/2022 01:34:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.11 on epoch=402
05/30/2022 01:34:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.24 on epoch=404
05/30/2022 01:35:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.15 on epoch=407
05/30/2022 01:35:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.07 on epoch=409
05/30/2022 01:35:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.10 on epoch=412
05/30/2022 01:35:03 - INFO - __main__ - Global step 1650 Train loss 1.13 Classification-F1 0.20555555555555555 on epoch=412
05/30/2022 01:35:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.13 on epoch=414
05/30/2022 01:35:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.25 on epoch=417
05/30/2022 01:35:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.19 on epoch=419
05/30/2022 01:35:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.18 on epoch=422
05/30/2022 01:35:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
05/30/2022 01:35:10 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.20853462157809982 on epoch=424
05/30/2022 01:35:10 - INFO - __main__ - Saving model with best Classification-F1: 0.20804195804195807 -> 0.20853462157809982 on epoch=424, global_step=1700
05/30/2022 01:35:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.23 on epoch=427
05/30/2022 01:35:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=429
05/30/2022 01:35:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.17 on epoch=432
05/30/2022 01:35:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.07 on epoch=434
05/30/2022 01:35:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.13 on epoch=437
05/30/2022 01:35:17 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.18055555555555555 on epoch=437
05/30/2022 01:35:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.01 on epoch=439
05/30/2022 01:35:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.05 on epoch=442
05/30/2022 01:35:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.99 on epoch=444
05/30/2022 01:35:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.06 on epoch=447
05/30/2022 01:35:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.11 on epoch=449
05/30/2022 01:35:24 - INFO - __main__ - Global step 1800 Train loss 1.04 Classification-F1 0.13427800269905532 on epoch=449
05/30/2022 01:35:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.12 on epoch=452
05/30/2022 01:35:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.03 on epoch=454
05/30/2022 01:35:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.17 on epoch=457
05/30/2022 01:35:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.03 on epoch=459
05/30/2022 01:35:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.22 on epoch=462
05/30/2022 01:35:30 - INFO - __main__ - Global step 1850 Train loss 1.12 Classification-F1 0.09493670886075949 on epoch=462
05/30/2022 01:35:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=464
05/30/2022 01:35:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.05 on epoch=467
05/30/2022 01:35:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.09 on epoch=469
05/30/2022 01:35:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.20 on epoch=472
05/30/2022 01:35:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/30/2022 01:35:37 - INFO - __main__ - Global step 1900 Train loss 1.11 Classification-F1 0.12575757575757576 on epoch=474
05/30/2022 01:35:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.09 on epoch=477
05/30/2022 01:35:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
05/30/2022 01:35:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.05 on epoch=482
05/30/2022 01:35:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.18 on epoch=484
05/30/2022 01:35:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.17 on epoch=487
05/30/2022 01:35:44 - INFO - __main__ - Global step 1950 Train loss 1.11 Classification-F1 0.09999999999999999 on epoch=487
05/30/2022 01:35:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=489
05/30/2022 01:35:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.07 on epoch=492
05/30/2022 01:35:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.15 on epoch=494
05/30/2022 01:35:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.03 on epoch=497
05/30/2022 01:35:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.18 on epoch=499
05/30/2022 01:35:51 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.07638888888888888 on epoch=499
05/30/2022 01:35:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.21 on epoch=502
05/30/2022 01:35:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.01 on epoch=504
05/30/2022 01:35:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.96 on epoch=507
05/30/2022 01:35:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.20 on epoch=509
05/30/2022 01:35:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.11 on epoch=512
05/30/2022 01:35:57 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.07258064516129033 on epoch=512
05/30/2022 01:35:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/30/2022 01:36:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.12 on epoch=517
05/30/2022 01:36:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.18 on epoch=519
05/30/2022 01:36:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.16 on epoch=522
05/30/2022 01:36:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.01 on epoch=524
05/30/2022 01:36:04 - INFO - __main__ - Global step 2100 Train loss 1.10 Classification-F1 0.12417582417582418 on epoch=524
05/30/2022 01:36:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.12 on epoch=527
05/30/2022 01:36:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.10 on epoch=529
05/30/2022 01:36:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.09 on epoch=532
05/30/2022 01:36:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.97 on epoch=534
05/30/2022 01:36:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.08 on epoch=537
05/30/2022 01:36:11 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.09615384615384615 on epoch=537
05/30/2022 01:36:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=539
05/30/2022 01:36:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.09 on epoch=542
05/30/2022 01:36:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.96 on epoch=544
05/30/2022 01:36:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=547
05/30/2022 01:36:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.99 on epoch=549
05/30/2022 01:36:18 - INFO - __main__ - Global step 2200 Train loss 1.02 Classification-F1 0.09615384615384615 on epoch=549
05/30/2022 01:36:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.09 on epoch=552
05/30/2022 01:36:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.17 on epoch=554
05/30/2022 01:36:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/30/2022 01:36:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.03 on epoch=559
05/30/2022 01:36:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/30/2022 01:36:25 - INFO - __main__ - Global step 2250 Train loss 1.08 Classification-F1 0.11996779388083736 on epoch=562
05/30/2022 01:36:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.16 on epoch=564
05/30/2022 01:36:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.14 on epoch=567
05/30/2022 01:36:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/30/2022 01:36:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/30/2022 01:36:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.05 on epoch=574
05/30/2022 01:36:31 - INFO - __main__ - Global step 2300 Train loss 1.08 Classification-F1 0.13154929577464788 on epoch=574
05/30/2022 01:36:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.96 on epoch=577
05/30/2022 01:36:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=579
05/30/2022 01:36:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.11 on epoch=582
05/30/2022 01:36:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.01 on epoch=584
05/30/2022 01:36:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.12 on epoch=587
05/30/2022 01:36:38 - INFO - __main__ - Global step 2350 Train loss 1.06 Classification-F1 0.1 on epoch=587
05/30/2022 01:36:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
05/30/2022 01:36:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.98 on epoch=592
05/30/2022 01:36:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/30/2022 01:36:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.03 on epoch=597
05/30/2022 01:36:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.09 on epoch=599
05/30/2022 01:36:45 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.1 on epoch=599
05/30/2022 01:36:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.06 on epoch=602
05/30/2022 01:36:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/30/2022 01:36:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.15 on epoch=607
05/30/2022 01:36:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.09 on epoch=609
05/30/2022 01:36:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.04 on epoch=612
05/30/2022 01:36:52 - INFO - __main__ - Global step 2450 Train loss 1.08 Classification-F1 0.09868421052631579 on epoch=612
05/30/2022 01:36:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.12 on epoch=614
05/30/2022 01:36:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.11 on epoch=617
05/30/2022 01:36:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.13 on epoch=619
05/30/2022 01:36:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/30/2022 01:36:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.04 on epoch=624
05/30/2022 01:36:59 - INFO - __main__ - Global step 2500 Train loss 1.09 Classification-F1 0.15490196078431373 on epoch=624
05/30/2022 01:37:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/30/2022 01:37:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=629
05/30/2022 01:37:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.10 on epoch=632
05/30/2022 01:37:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
05/30/2022 01:37:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.92 on epoch=637
05/30/2022 01:37:05 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.1 on epoch=637
05/30/2022 01:37:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.92 on epoch=639
05/30/2022 01:37:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
05/30/2022 01:37:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.03 on epoch=644
05/30/2022 01:37:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=647
05/30/2022 01:37:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.18 on epoch=649
05/30/2022 01:37:12 - INFO - __main__ - Global step 2600 Train loss 1.04 Classification-F1 0.17368421052631577 on epoch=649
05/30/2022 01:37:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.10 on epoch=652
05/30/2022 01:37:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.08 on epoch=654
05/30/2022 01:37:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.06 on epoch=657
05/30/2022 01:37:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.98 on epoch=659
05/30/2022 01:37:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/30/2022 01:37:19 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.1717171717171717 on epoch=662
05/30/2022 01:37:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.07 on epoch=664
05/30/2022 01:37:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.03 on epoch=667
05/30/2022 01:37:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.01 on epoch=669
05/30/2022 01:37:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.11 on epoch=672
05/30/2022 01:37:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.04 on epoch=674
05/30/2022 01:37:26 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.1581196581196581 on epoch=674
05/30/2022 01:37:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.08 on epoch=677
05/30/2022 01:37:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.09 on epoch=679
05/30/2022 01:37:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/30/2022 01:37:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
05/30/2022 01:37:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/30/2022 01:37:32 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.11666666666666667 on epoch=687
05/30/2022 01:37:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.04 on epoch=689
05/30/2022 01:37:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/30/2022 01:37:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/30/2022 01:37:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.12 on epoch=697
05/30/2022 01:37:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=699
05/30/2022 01:37:39 - INFO - __main__ - Global step 2800 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=699
05/30/2022 01:37:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.05 on epoch=702
05/30/2022 01:37:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/30/2022 01:37:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.14 on epoch=707
05/30/2022 01:37:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/30/2022 01:37:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
05/30/2022 01:37:46 - INFO - __main__ - Global step 2850 Train loss 1.01 Classification-F1 0.1 on epoch=712
05/30/2022 01:37:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.04 on epoch=714
05/30/2022 01:37:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/30/2022 01:37:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.05 on epoch=719
05/30/2022 01:37:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.07 on epoch=722
05/30/2022 01:37:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.14 on epoch=724
05/30/2022 01:37:53 - INFO - __main__ - Global step 2900 Train loss 1.06 Classification-F1 0.09589041095890412 on epoch=724
05/30/2022 01:37:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.95 on epoch=727
05/30/2022 01:37:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/30/2022 01:37:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.94 on epoch=732
05/30/2022 01:37:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.93 on epoch=734
05/30/2022 01:37:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.93 on epoch=737
05/30/2022 01:38:00 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.17687747035573123 on epoch=737
05/30/2022 01:38:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/30/2022 01:38:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/30/2022 01:38:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.16 on epoch=744
05/30/2022 01:38:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.94 on epoch=747
05/30/2022 01:38:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/30/2022 01:38:06 - INFO - __main__ - Global step 3000 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=749
05/30/2022 01:38:06 - INFO - __main__ - save last model!
05/30/2022 01:38:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 01:38:07 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 01:38:07 - INFO - __main__ - Printing 3 examples
05/30/2022 01:38:07 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:38:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:38:07 - INFO - __main__ - Printing 3 examples
05/30/2022 01:38:07 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:38:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:38:07 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:38:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:38:07 - INFO - __main__ - Printing 3 examples
05/30/2022 01:38:07 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:38:07 - INFO - __main__ - ['others']
05/30/2022 01:38:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:38:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:38:07 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:38:09 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:38:13 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:38:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:38:14 - INFO - __main__ - Starting training!
05/30/2022 01:38:14 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:38:57 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.3_8_predictions.txt
05/30/2022 01:38:57 - INFO - __main__ - Classification-F1 on test data: 0.0317
05/30/2022 01:38:58 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.20853462157809982, test_performance=0.03167854221146765
05/30/2022 01:38:58 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
05/30/2022 01:38:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:38:59 - INFO - __main__ - Printing 3 examples
05/30/2022 01:38:59 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/30/2022 01:38:59 - INFO - __main__ - ['others']
05/30/2022 01:38:59 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/30/2022 01:38:59 - INFO - __main__ - ['others']
05/30/2022 01:38:59 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/30/2022 01:38:59 - INFO - __main__ - ['others']
05/30/2022 01:38:59 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:38:59 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:38:59 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:38:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:38:59 - INFO - __main__ - Printing 3 examples
05/30/2022 01:38:59 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
05/30/2022 01:38:59 - INFO - __main__ - ['others']
05/30/2022 01:38:59 - INFO - __main__ -  [emo] i did ask now you did tell ms
05/30/2022 01:38:59 - INFO - __main__ - ['others']
05/30/2022 01:38:59 - INFO - __main__ -  [emo] buddy how you tell me your contact no
05/30/2022 01:38:59 - INFO - __main__ - ['others']
05/30/2022 01:38:59 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:38:59 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:38:59 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:39:05 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:39:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:39:05 - INFO - __main__ - Starting training!
05/30/2022 01:39:07 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=2
05/30/2022 01:39:08 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/30/2022 01:39:09 - INFO - __main__ - Step 30 Global step 30 Train loss 6.43 on epoch=7
05/30/2022 01:39:10 - INFO - __main__ - Step 40 Global step 40 Train loss 6.24 on epoch=9
05/30/2022 01:39:12 - INFO - __main__ - Step 50 Global step 50 Train loss 6.25 on epoch=12
05/30/2022 01:39:16 - INFO - __main__ - Global step 50 Train loss 6.45 Classification-F1 0.0 on epoch=12
05/30/2022 01:39:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:39:17 - INFO - __main__ - Step 60 Global step 60 Train loss 6.00 on epoch=14
05/30/2022 01:39:18 - INFO - __main__ - Step 70 Global step 70 Train loss 5.97 on epoch=17
05/30/2022 01:39:19 - INFO - __main__ - Step 80 Global step 80 Train loss 5.78 on epoch=19
05/30/2022 01:39:21 - INFO - __main__ - Step 90 Global step 90 Train loss 5.75 on epoch=22
05/30/2022 01:39:22 - INFO - __main__ - Step 100 Global step 100 Train loss 5.58 on epoch=24
05/30/2022 01:39:24 - INFO - __main__ - Global step 100 Train loss 5.82 Classification-F1 0.0 on epoch=24
05/30/2022 01:39:25 - INFO - __main__ - Step 110 Global step 110 Train loss 5.67 on epoch=27
05/30/2022 01:39:27 - INFO - __main__ - Step 120 Global step 120 Train loss 5.40 on epoch=29
05/30/2022 01:39:28 - INFO - __main__ - Step 130 Global step 130 Train loss 5.37 on epoch=32
05/30/2022 01:39:29 - INFO - __main__ - Step 140 Global step 140 Train loss 5.33 on epoch=34
05/30/2022 01:39:30 - INFO - __main__ - Step 150 Global step 150 Train loss 5.14 on epoch=37
05/30/2022 01:39:32 - INFO - __main__ - Global step 150 Train loss 5.38 Classification-F1 0.0 on epoch=37
05/30/2022 01:39:33 - INFO - __main__ - Step 160 Global step 160 Train loss 4.96 on epoch=39
05/30/2022 01:39:35 - INFO - __main__ - Step 170 Global step 170 Train loss 4.96 on epoch=42
05/30/2022 01:39:36 - INFO - __main__ - Step 180 Global step 180 Train loss 4.91 on epoch=44
05/30/2022 01:39:37 - INFO - __main__ - Step 190 Global step 190 Train loss 4.84 on epoch=47
05/30/2022 01:39:38 - INFO - __main__ - Step 200 Global step 200 Train loss 4.63 on epoch=49
05/30/2022 01:39:40 - INFO - __main__ - Global step 200 Train loss 4.86 Classification-F1 0.009523809523809525 on epoch=49
05/30/2022 01:39:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009523809523809525 on epoch=49, global_step=200
05/30/2022 01:39:41 - INFO - __main__ - Step 210 Global step 210 Train loss 4.58 on epoch=52
05/30/2022 01:39:43 - INFO - __main__ - Step 220 Global step 220 Train loss 4.59 on epoch=54
05/30/2022 01:39:44 - INFO - __main__ - Step 230 Global step 230 Train loss 4.45 on epoch=57
05/30/2022 01:39:45 - INFO - __main__ - Step 240 Global step 240 Train loss 4.25 on epoch=59
05/30/2022 01:39:46 - INFO - __main__ - Step 250 Global step 250 Train loss 4.13 on epoch=62
05/30/2022 01:39:47 - INFO - __main__ - Global step 250 Train loss 4.40 Classification-F1 0.15789473684210525 on epoch=62
05/30/2022 01:39:47 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809525 -> 0.15789473684210525 on epoch=62, global_step=250
05/30/2022 01:39:48 - INFO - __main__ - Step 260 Global step 260 Train loss 4.14 on epoch=64
05/30/2022 01:39:50 - INFO - __main__ - Step 270 Global step 270 Train loss 4.06 on epoch=67
05/30/2022 01:39:51 - INFO - __main__ - Step 280 Global step 280 Train loss 3.92 on epoch=69
05/30/2022 01:39:52 - INFO - __main__ - Step 290 Global step 290 Train loss 3.83 on epoch=72
05/30/2022 01:39:53 - INFO - __main__ - Step 300 Global step 300 Train loss 3.86 on epoch=74
05/30/2022 01:39:54 - INFO - __main__ - Global step 300 Train loss 3.96 Classification-F1 0.15339578454332553 on epoch=74
05/30/2022 01:39:55 - INFO - __main__ - Step 310 Global step 310 Train loss 3.81 on epoch=77
05/30/2022 01:39:56 - INFO - __main__ - Step 320 Global step 320 Train loss 3.89 on epoch=79
05/30/2022 01:39:58 - INFO - __main__ - Step 330 Global step 330 Train loss 3.81 on epoch=82
05/30/2022 01:39:59 - INFO - __main__ - Step 340 Global step 340 Train loss 3.67 on epoch=84
05/30/2022 01:40:00 - INFO - __main__ - Step 350 Global step 350 Train loss 3.62 on epoch=87
05/30/2022 01:40:01 - INFO - __main__ - Global step 350 Train loss 3.76 Classification-F1 0.11019607843137255 on epoch=87
05/30/2022 01:40:02 - INFO - __main__ - Step 360 Global step 360 Train loss 3.36 on epoch=89
05/30/2022 01:40:03 - INFO - __main__ - Step 370 Global step 370 Train loss 3.44 on epoch=92
05/30/2022 01:40:04 - INFO - __main__ - Step 380 Global step 380 Train loss 3.23 on epoch=94
05/30/2022 01:40:06 - INFO - __main__ - Step 390 Global step 390 Train loss 3.30 on epoch=97
05/30/2022 01:40:07 - INFO - __main__ - Step 400 Global step 400 Train loss 3.09 on epoch=99
05/30/2022 01:40:07 - INFO - __main__ - Global step 400 Train loss 3.28 Classification-F1 0.1570048309178744 on epoch=99
05/30/2022 01:40:09 - INFO - __main__ - Step 410 Global step 410 Train loss 3.26 on epoch=102
05/30/2022 01:40:10 - INFO - __main__ - Step 420 Global step 420 Train loss 3.12 on epoch=104
05/30/2022 01:40:11 - INFO - __main__ - Step 430 Global step 430 Train loss 3.06 on epoch=107
05/30/2022 01:40:12 - INFO - __main__ - Step 440 Global step 440 Train loss 3.00 on epoch=109
05/30/2022 01:40:14 - INFO - __main__ - Step 450 Global step 450 Train loss 3.04 on epoch=112
05/30/2022 01:40:14 - INFO - __main__ - Global step 450 Train loss 3.09 Classification-F1 0.10126582278481013 on epoch=112
05/30/2022 01:40:15 - INFO - __main__ - Step 460 Global step 460 Train loss 2.97 on epoch=114
05/30/2022 01:40:17 - INFO - __main__ - Step 470 Global step 470 Train loss 2.93 on epoch=117
05/30/2022 01:40:18 - INFO - __main__ - Step 480 Global step 480 Train loss 2.87 on epoch=119
05/30/2022 01:40:19 - INFO - __main__ - Step 490 Global step 490 Train loss 3.10 on epoch=122
05/30/2022 01:40:20 - INFO - __main__ - Step 500 Global step 500 Train loss 2.79 on epoch=124
05/30/2022 01:40:21 - INFO - __main__ - Global step 500 Train loss 2.93 Classification-F1 0.1 on epoch=124
05/30/2022 01:40:22 - INFO - __main__ - Step 510 Global step 510 Train loss 2.96 on epoch=127
05/30/2022 01:40:23 - INFO - __main__ - Step 520 Global step 520 Train loss 2.79 on epoch=129
05/30/2022 01:40:25 - INFO - __main__ - Step 530 Global step 530 Train loss 2.59 on epoch=132
05/30/2022 01:40:26 - INFO - __main__ - Step 540 Global step 540 Train loss 2.84 on epoch=134
05/30/2022 01:40:27 - INFO - __main__ - Step 550 Global step 550 Train loss 2.81 on epoch=137
05/30/2022 01:40:28 - INFO - __main__ - Global step 550 Train loss 2.80 Classification-F1 0.1 on epoch=137
05/30/2022 01:40:29 - INFO - __main__ - Step 560 Global step 560 Train loss 2.53 on epoch=139
05/30/2022 01:40:30 - INFO - __main__ - Step 570 Global step 570 Train loss 2.57 on epoch=142
05/30/2022 01:40:32 - INFO - __main__ - Step 580 Global step 580 Train loss 2.57 on epoch=144
05/30/2022 01:40:33 - INFO - __main__ - Step 590 Global step 590 Train loss 2.67 on epoch=147
05/30/2022 01:40:35 - INFO - __main__ - Step 600 Global step 600 Train loss 2.62 on epoch=149
05/30/2022 01:40:35 - INFO - __main__ - Global step 600 Train loss 2.59 Classification-F1 0.1 on epoch=149
05/30/2022 01:40:37 - INFO - __main__ - Step 610 Global step 610 Train loss 2.53 on epoch=152
05/30/2022 01:40:38 - INFO - __main__ - Step 620 Global step 620 Train loss 2.54 on epoch=154
05/30/2022 01:40:39 - INFO - __main__ - Step 630 Global step 630 Train loss 2.69 on epoch=157
05/30/2022 01:40:40 - INFO - __main__ - Step 640 Global step 640 Train loss 2.39 on epoch=159
05/30/2022 01:40:42 - INFO - __main__ - Step 650 Global step 650 Train loss 2.41 on epoch=162
05/30/2022 01:40:42 - INFO - __main__ - Global step 650 Train loss 2.51 Classification-F1 0.10256410256410256 on epoch=162
05/30/2022 01:40:44 - INFO - __main__ - Step 660 Global step 660 Train loss 2.33 on epoch=164
05/30/2022 01:40:45 - INFO - __main__ - Step 670 Global step 670 Train loss 2.54 on epoch=167
05/30/2022 01:40:46 - INFO - __main__ - Step 680 Global step 680 Train loss 2.31 on epoch=169
05/30/2022 01:40:47 - INFO - __main__ - Step 690 Global step 690 Train loss 2.33 on epoch=172
05/30/2022 01:40:49 - INFO - __main__ - Step 700 Global step 700 Train loss 2.17 on epoch=174
05/30/2022 01:40:49 - INFO - __main__ - Global step 700 Train loss 2.34 Classification-F1 0.10126582278481013 on epoch=174
05/30/2022 01:40:50 - INFO - __main__ - Step 710 Global step 710 Train loss 2.28 on epoch=177
05/30/2022 01:40:52 - INFO - __main__ - Step 720 Global step 720 Train loss 2.32 on epoch=179
05/30/2022 01:40:53 - INFO - __main__ - Step 730 Global step 730 Train loss 2.31 on epoch=182
05/30/2022 01:40:54 - INFO - __main__ - Step 740 Global step 740 Train loss 2.28 on epoch=184
05/30/2022 01:40:55 - INFO - __main__ - Step 750 Global step 750 Train loss 2.35 on epoch=187
05/30/2022 01:40:56 - INFO - __main__ - Global step 750 Train loss 2.31 Classification-F1 0.09615384615384615 on epoch=187
05/30/2022 01:40:57 - INFO - __main__ - Step 760 Global step 760 Train loss 2.13 on epoch=189
05/30/2022 01:40:58 - INFO - __main__ - Step 770 Global step 770 Train loss 2.25 on epoch=192
05/30/2022 01:41:00 - INFO - __main__ - Step 780 Global step 780 Train loss 2.11 on epoch=194
05/30/2022 01:41:01 - INFO - __main__ - Step 790 Global step 790 Train loss 2.28 on epoch=197
05/30/2022 01:41:02 - INFO - __main__ - Step 800 Global step 800 Train loss 2.12 on epoch=199
05/30/2022 01:41:03 - INFO - __main__ - Global step 800 Train loss 2.18 Classification-F1 0.1111111111111111 on epoch=199
05/30/2022 01:41:04 - INFO - __main__ - Step 810 Global step 810 Train loss 2.28 on epoch=202
05/30/2022 01:41:05 - INFO - __main__ - Step 820 Global step 820 Train loss 2.13 on epoch=204
05/30/2022 01:41:07 - INFO - __main__ - Step 830 Global step 830 Train loss 2.23 on epoch=207
05/30/2022 01:41:08 - INFO - __main__ - Step 840 Global step 840 Train loss 2.03 on epoch=209
05/30/2022 01:41:09 - INFO - __main__ - Step 850 Global step 850 Train loss 2.19 on epoch=212
05/30/2022 01:41:10 - INFO - __main__ - Global step 850 Train loss 2.17 Classification-F1 0.1476190476190476 on epoch=212
05/30/2022 01:41:11 - INFO - __main__ - Step 860 Global step 860 Train loss 1.95 on epoch=214
05/30/2022 01:41:12 - INFO - __main__ - Step 870 Global step 870 Train loss 2.08 on epoch=217
05/30/2022 01:41:13 - INFO - __main__ - Step 880 Global step 880 Train loss 1.91 on epoch=219
05/30/2022 01:41:15 - INFO - __main__ - Step 890 Global step 890 Train loss 2.01 on epoch=222
05/30/2022 01:41:16 - INFO - __main__ - Step 900 Global step 900 Train loss 1.82 on epoch=224
05/30/2022 01:41:17 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.17480643240023822 on epoch=224
05/30/2022 01:41:17 - INFO - __main__ - Saving model with best Classification-F1: 0.15789473684210525 -> 0.17480643240023822 on epoch=224, global_step=900
05/30/2022 01:41:18 - INFO - __main__ - Step 910 Global step 910 Train loss 1.94 on epoch=227
05/30/2022 01:41:19 - INFO - __main__ - Step 920 Global step 920 Train loss 1.81 on epoch=229
05/30/2022 01:41:20 - INFO - __main__ - Step 930 Global step 930 Train loss 1.96 on epoch=232
05/30/2022 01:41:22 - INFO - __main__ - Step 940 Global step 940 Train loss 1.78 on epoch=234
05/30/2022 01:41:23 - INFO - __main__ - Step 950 Global step 950 Train loss 1.96 on epoch=237
05/30/2022 01:41:23 - INFO - __main__ - Global step 950 Train loss 1.89 Classification-F1 0.18276972624798712 on epoch=237
05/30/2022 01:41:23 - INFO - __main__ - Saving model with best Classification-F1: 0.17480643240023822 -> 0.18276972624798712 on epoch=237, global_step=950
05/30/2022 01:41:25 - INFO - __main__ - Step 960 Global step 960 Train loss 1.94 on epoch=239
05/30/2022 01:41:26 - INFO - __main__ - Step 970 Global step 970 Train loss 1.95 on epoch=242
05/30/2022 01:41:27 - INFO - __main__ - Step 980 Global step 980 Train loss 1.80 on epoch=244
05/30/2022 01:41:28 - INFO - __main__ - Step 990 Global step 990 Train loss 1.86 on epoch=247
05/30/2022 01:41:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.63 on epoch=249
05/30/2022 01:41:30 - INFO - __main__ - Global step 1000 Train loss 1.84 Classification-F1 0.14563380281690141 on epoch=249
05/30/2022 01:41:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.81 on epoch=252
05/30/2022 01:41:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.61 on epoch=254
05/30/2022 01:41:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.72 on epoch=257
05/30/2022 01:41:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.78 on epoch=259
05/30/2022 01:41:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.81 on epoch=262
05/30/2022 01:41:37 - INFO - __main__ - Global step 1050 Train loss 1.75 Classification-F1 0.21743697478991597 on epoch=262
05/30/2022 01:41:37 - INFO - __main__ - Saving model with best Classification-F1: 0.18276972624798712 -> 0.21743697478991597 on epoch=262, global_step=1050
05/30/2022 01:41:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.67 on epoch=264
05/30/2022 01:41:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.63 on epoch=267
05/30/2022 01:41:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.80 on epoch=269
05/30/2022 01:41:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.65 on epoch=272
05/30/2022 01:41:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.51 on epoch=274
05/30/2022 01:41:44 - INFO - __main__ - Global step 1100 Train loss 1.65 Classification-F1 0.17552334943639292 on epoch=274
05/30/2022 01:41:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.62 on epoch=277
05/30/2022 01:41:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.60 on epoch=279
05/30/2022 01:41:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.66 on epoch=282
05/30/2022 01:41:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.60 on epoch=284
05/30/2022 01:41:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.60 on epoch=287
05/30/2022 01:41:51 - INFO - __main__ - Global step 1150 Train loss 1.61 Classification-F1 0.1302118933697881 on epoch=287
05/30/2022 01:41:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.62 on epoch=289
05/30/2022 01:41:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.69 on epoch=292
05/30/2022 01:41:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.60 on epoch=294
05/30/2022 01:41:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.61 on epoch=297
05/30/2022 01:41:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.63 on epoch=299
05/30/2022 01:41:58 - INFO - __main__ - Global step 1200 Train loss 1.63 Classification-F1 0.11746478873239438 on epoch=299
05/30/2022 01:41:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.51 on epoch=302
05/30/2022 01:42:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.57 on epoch=304
05/30/2022 01:42:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.53 on epoch=307
05/30/2022 01:42:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.51 on epoch=309
05/30/2022 01:42:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.63 on epoch=312
05/30/2022 01:42:05 - INFO - __main__ - Global step 1250 Train loss 1.55 Classification-F1 0.13154929577464788 on epoch=312
05/30/2022 01:42:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.59 on epoch=314
05/30/2022 01:42:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.53 on epoch=317
05/30/2022 01:42:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.43 on epoch=319
05/30/2022 01:42:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.47 on epoch=322
05/30/2022 01:42:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.34 on epoch=324
05/30/2022 01:42:11 - INFO - __main__ - Global step 1300 Train loss 1.47 Classification-F1 0.1640625 on epoch=324
05/30/2022 01:42:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.49 on epoch=327
05/30/2022 01:42:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.46 on epoch=329
05/30/2022 01:42:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.47 on epoch=332
05/30/2022 01:42:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.41 on epoch=334
05/30/2022 01:42:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.37 on epoch=337
05/30/2022 01:42:18 - INFO - __main__ - Global step 1350 Train loss 1.44 Classification-F1 0.1597222222222222 on epoch=337
05/30/2022 01:42:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.57 on epoch=339
05/30/2022 01:42:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.38 on epoch=342
05/30/2022 01:42:22 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.51 on epoch=344
05/30/2022 01:42:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.47 on epoch=347
05/30/2022 01:42:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.27 on epoch=349
05/30/2022 01:42:25 - INFO - __main__ - Global step 1400 Train loss 1.44 Classification-F1 0.16470588235294115 on epoch=349
05/30/2022 01:42:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.39 on epoch=352
05/30/2022 01:42:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.31 on epoch=354
05/30/2022 01:42:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.49 on epoch=357
05/30/2022 01:42:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.45 on epoch=359
05/30/2022 01:42:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.37 on epoch=362
05/30/2022 01:42:32 - INFO - __main__ - Global step 1450 Train loss 1.40 Classification-F1 0.1875 on epoch=362
05/30/2022 01:42:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.38 on epoch=364
05/30/2022 01:42:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.35 on epoch=367
05/30/2022 01:42:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.44 on epoch=369
05/30/2022 01:42:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.35 on epoch=372
05/30/2022 01:42:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.49 on epoch=374
05/30/2022 01:42:39 - INFO - __main__ - Global step 1500 Train loss 1.40 Classification-F1 0.1457326892109501 on epoch=374
05/30/2022 01:42:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.35 on epoch=377
05/30/2022 01:42:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.23 on epoch=379
05/30/2022 01:42:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.31 on epoch=382
05/30/2022 01:42:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=384
05/30/2022 01:42:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.32 on epoch=387
05/30/2022 01:42:46 - INFO - __main__ - Global step 1550 Train loss 1.29 Classification-F1 0.11485019539730784 on epoch=387
05/30/2022 01:42:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.23 on epoch=389
05/30/2022 01:42:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.26 on epoch=392
05/30/2022 01:42:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=394
05/30/2022 01:42:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.27 on epoch=397
05/30/2022 01:42:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.33 on epoch=399
05/30/2022 01:42:53 - INFO - __main__ - Global step 1600 Train loss 1.26 Classification-F1 0.13154929577464788 on epoch=399
05/30/2022 01:42:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.25 on epoch=402
05/30/2022 01:42:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.27 on epoch=404
05/30/2022 01:42:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.35 on epoch=407
05/30/2022 01:42:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.29 on epoch=409
05/30/2022 01:42:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.39 on epoch=412
05/30/2022 01:43:00 - INFO - __main__ - Global step 1650 Train loss 1.31 Classification-F1 0.13047619047619047 on epoch=412
05/30/2022 01:43:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.27 on epoch=414
05/30/2022 01:43:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.32 on epoch=417
05/30/2022 01:43:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.30 on epoch=419
05/30/2022 01:43:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.33 on epoch=422
05/30/2022 01:43:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.26 on epoch=424
05/30/2022 01:43:06 - INFO - __main__ - Global step 1700 Train loss 1.30 Classification-F1 0.15359477124183005 on epoch=424
05/30/2022 01:43:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.28 on epoch=427
05/30/2022 01:43:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.24 on epoch=429
05/30/2022 01:43:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.18 on epoch=432
05/30/2022 01:43:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.27 on epoch=434
05/30/2022 01:43:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=437
05/30/2022 01:43:13 - INFO - __main__ - Global step 1750 Train loss 1.24 Classification-F1 0.09065934065934066 on epoch=437
05/30/2022 01:43:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.19 on epoch=439
05/30/2022 01:43:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.17 on epoch=442
05/30/2022 01:43:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.18 on epoch=444
05/30/2022 01:43:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.19 on epoch=447
05/30/2022 01:43:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.24 on epoch=449
05/30/2022 01:43:20 - INFO - __main__ - Global step 1800 Train loss 1.19 Classification-F1 0.09109311740890687 on epoch=449
05/30/2022 01:43:22 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.30 on epoch=452
05/30/2022 01:43:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.22 on epoch=454
05/30/2022 01:43:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.24 on epoch=457
05/30/2022 01:43:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.29 on epoch=459
05/30/2022 01:43:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.26 on epoch=462
05/30/2022 01:43:27 - INFO - __main__ - Global step 1850 Train loss 1.26 Classification-F1 0.15071003206596426 on epoch=462
05/30/2022 01:43:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=464
05/30/2022 01:43:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.17 on epoch=467
05/30/2022 01:43:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.27 on epoch=469
05/30/2022 01:43:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.45 on epoch=472
05/30/2022 01:43:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.24 on epoch=474
05/30/2022 01:43:34 - INFO - __main__ - Global step 1900 Train loss 1.25 Classification-F1 0.1774628879892038 on epoch=474
05/30/2022 01:43:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.25 on epoch=477
05/30/2022 01:43:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.20 on epoch=479
05/30/2022 01:43:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.17 on epoch=482
05/30/2022 01:43:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.12 on epoch=484
05/30/2022 01:43:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.27 on epoch=487
05/30/2022 01:43:41 - INFO - __main__ - Global step 1950 Train loss 1.20 Classification-F1 0.09414519906323185 on epoch=487
05/30/2022 01:43:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.11 on epoch=489
05/30/2022 01:43:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.28 on epoch=492
05/30/2022 01:43:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.24 on epoch=494
05/30/2022 01:43:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.08 on epoch=497
05/30/2022 01:43:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.20 on epoch=499
05/30/2022 01:43:48 - INFO - __main__ - Global step 2000 Train loss 1.18 Classification-F1 0.11781609195402298 on epoch=499
05/30/2022 01:43:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.25 on epoch=502
05/30/2022 01:43:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.14 on epoch=504
05/30/2022 01:43:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.20 on epoch=507
05/30/2022 01:43:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.15 on epoch=509
05/30/2022 01:43:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.18 on epoch=512
05/30/2022 01:43:54 - INFO - __main__ - Global step 2050 Train loss 1.18 Classification-F1 0.16451612903225807 on epoch=512
05/30/2022 01:43:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.16 on epoch=514
05/30/2022 01:43:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.22 on epoch=517
05/30/2022 01:43:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.10 on epoch=519
05/30/2022 01:44:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.11 on epoch=522
05/30/2022 01:44:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.08 on epoch=524
05/30/2022 01:44:01 - INFO - __main__ - Global step 2100 Train loss 1.14 Classification-F1 0.14962702939885913 on epoch=524
05/30/2022 01:44:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.15 on epoch=527
05/30/2022 01:44:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.24 on epoch=529
05/30/2022 01:44:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.30 on epoch=532
05/30/2022 01:44:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.22 on epoch=534
05/30/2022 01:44:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.18 on epoch=537
05/30/2022 01:44:08 - INFO - __main__ - Global step 2150 Train loss 1.22 Classification-F1 0.17946136788048553 on epoch=537
05/30/2022 01:44:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.16 on epoch=539
05/30/2022 01:44:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=542
05/30/2022 01:44:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.17 on epoch=544
05/30/2022 01:44:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.25 on epoch=547
05/30/2022 01:44:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.14 on epoch=549
05/30/2022 01:44:15 - INFO - __main__ - Global step 2200 Train loss 1.17 Classification-F1 0.15682382133995038 on epoch=549
05/30/2022 01:44:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.10 on epoch=552
05/30/2022 01:44:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.15 on epoch=554
05/30/2022 01:44:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/30/2022 01:44:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/30/2022 01:44:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/30/2022 01:44:22 - INFO - __main__ - Global step 2250 Train loss 1.12 Classification-F1 0.09210526315789473 on epoch=562
05/30/2022 01:44:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/30/2022 01:44:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.33 on epoch=567
05/30/2022 01:44:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.07 on epoch=569
05/30/2022 01:44:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.15 on epoch=572
05/30/2022 01:44:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.09 on epoch=574
05/30/2022 01:44:29 - INFO - __main__ - Global step 2300 Train loss 1.15 Classification-F1 0.13626373626373625 on epoch=574
05/30/2022 01:44:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.09 on epoch=577
05/30/2022 01:44:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.13 on epoch=579
05/30/2022 01:44:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.18 on epoch=582
05/30/2022 01:44:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.29 on epoch=584
05/30/2022 01:44:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.11 on epoch=587
05/30/2022 01:44:35 - INFO - __main__ - Global step 2350 Train loss 1.16 Classification-F1 0.1412177985948478 on epoch=587
05/30/2022 01:44:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.07 on epoch=589
05/30/2022 01:44:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.15 on epoch=592
05/30/2022 01:44:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/30/2022 01:44:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.13 on epoch=597
05/30/2022 01:44:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.14 on epoch=599
05/30/2022 01:44:42 - INFO - __main__ - Global step 2400 Train loss 1.11 Classification-F1 0.20634920634920634 on epoch=599
05/30/2022 01:44:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.13 on epoch=602
05/30/2022 01:44:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.11 on epoch=604
05/30/2022 01:44:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.17 on epoch=607
05/30/2022 01:44:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.17 on epoch=609
05/30/2022 01:44:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.03 on epoch=612
05/30/2022 01:44:49 - INFO - __main__ - Global step 2450 Train loss 1.12 Classification-F1 0.13047619047619047 on epoch=612
05/30/2022 01:44:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.09 on epoch=614
05/30/2022 01:44:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.05 on epoch=617
05/30/2022 01:44:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.13 on epoch=619
05/30/2022 01:44:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/30/2022 01:44:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
05/30/2022 01:44:56 - INFO - __main__ - Global step 2500 Train loss 1.08 Classification-F1 0.1497584541062802 on epoch=624
05/30/2022 01:44:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.01 on epoch=627
05/30/2022 01:44:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
05/30/2022 01:45:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.20 on epoch=632
05/30/2022 01:45:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.13 on epoch=634
05/30/2022 01:45:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.21 on epoch=637
05/30/2022 01:45:03 - INFO - __main__ - Global step 2550 Train loss 1.14 Classification-F1 0.15434782608695652 on epoch=637
05/30/2022 01:45:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.12 on epoch=639
05/30/2022 01:45:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.18 on epoch=642
05/30/2022 01:45:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.12 on epoch=644
05/30/2022 01:45:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/30/2022 01:45:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/30/2022 01:45:10 - INFO - __main__ - Global step 2600 Train loss 1.10 Classification-F1 0.15587044534412953 on epoch=649
05/30/2022 01:45:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.06 on epoch=652
05/30/2022 01:45:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.16 on epoch=654
05/30/2022 01:45:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
05/30/2022 01:45:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.24 on epoch=659
05/30/2022 01:45:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.18 on epoch=662
05/30/2022 01:45:16 - INFO - __main__ - Global step 2650 Train loss 1.12 Classification-F1 0.14095238095238094 on epoch=662
05/30/2022 01:45:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.20 on epoch=664
05/30/2022 01:45:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.16 on epoch=667
05/30/2022 01:45:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.08 on epoch=669
05/30/2022 01:45:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.02 on epoch=672
05/30/2022 01:45:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/30/2022 01:45:23 - INFO - __main__ - Global step 2700 Train loss 1.10 Classification-F1 0.12541806020066892 on epoch=674
05/30/2022 01:45:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.06 on epoch=677
05/30/2022 01:45:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.13 on epoch=679
05/30/2022 01:45:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.10 on epoch=682
05/30/2022 01:45:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.08 on epoch=684
05/30/2022 01:45:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.07 on epoch=687
05/30/2022 01:45:30 - INFO - __main__ - Global step 2750 Train loss 1.09 Classification-F1 0.12564102564102564 on epoch=687
05/30/2022 01:45:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.10 on epoch=689
05/30/2022 01:45:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.13 on epoch=692
05/30/2022 01:45:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.10 on epoch=694
05/30/2022 01:45:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
05/30/2022 01:45:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.11 on epoch=699
05/30/2022 01:45:37 - INFO - __main__ - Global step 2800 Train loss 1.09 Classification-F1 0.15260416666666665 on epoch=699
05/30/2022 01:45:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.02 on epoch=702
05/30/2022 01:45:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.09 on epoch=704
05/30/2022 01:45:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.28 on epoch=707
05/30/2022 01:45:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.04 on epoch=709
05/30/2022 01:45:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.11 on epoch=712
05/30/2022 01:45:44 - INFO - __main__ - Global step 2850 Train loss 1.11 Classification-F1 0.12407862407862408 on epoch=712
05/30/2022 01:45:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.15 on epoch=714
05/30/2022 01:45:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.09 on epoch=717
05/30/2022 01:45:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/30/2022 01:45:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.20 on epoch=722
05/30/2022 01:45:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.11 on epoch=724
05/30/2022 01:45:50 - INFO - __main__ - Global step 2900 Train loss 1.11 Classification-F1 0.13430127041742287 on epoch=724
05/30/2022 01:45:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.17 on epoch=727
05/30/2022 01:45:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.20 on epoch=729
05/30/2022 01:45:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.05 on epoch=732
05/30/2022 01:45:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.06 on epoch=734
05/30/2022 01:45:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.05 on epoch=737
05/30/2022 01:45:57 - INFO - __main__ - Global step 2950 Train loss 1.10 Classification-F1 0.1875 on epoch=737
05/30/2022 01:45:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.04 on epoch=739
05/30/2022 01:46:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.10 on epoch=742
05/30/2022 01:46:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.10 on epoch=744
05/30/2022 01:46:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.09 on epoch=747
05/30/2022 01:46:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.18 on epoch=749
05/30/2022 01:46:04 - INFO - __main__ - Global step 3000 Train loss 1.10 Classification-F1 0.13251935675997617 on epoch=749
05/30/2022 01:46:04 - INFO - __main__ - save last model!
05/30/2022 01:46:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 01:46:04 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 01:46:04 - INFO - __main__ - Printing 3 examples
05/30/2022 01:46:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 01:46:04 - INFO - __main__ - ['others']
05/30/2022 01:46:04 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 01:46:04 - INFO - __main__ - ['others']
05/30/2022 01:46:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 01:46:04 - INFO - __main__ - ['others']
05/30/2022 01:46:04 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:46:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:46:04 - INFO - __main__ - Printing 3 examples
05/30/2022 01:46:04 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 01:46:04 - INFO - __main__ - ['sad']
05/30/2022 01:46:04 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 01:46:04 - INFO - __main__ - ['sad']
05/30/2022 01:46:04 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 01:46:04 - INFO - __main__ - ['sad']
05/30/2022 01:46:04 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:46:04 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:46:05 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:46:05 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:46:05 - INFO - __main__ - Printing 3 examples
05/30/2022 01:46:05 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 01:46:05 - INFO - __main__ - ['sad']
05/30/2022 01:46:05 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 01:46:05 - INFO - __main__ - ['sad']
05/30/2022 01:46:05 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 01:46:05 - INFO - __main__ - ['sad']
05/30/2022 01:46:05 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:46:05 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:46:05 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:46:06 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:46:11 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:46:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:46:11 - INFO - __main__ - Starting training!
05/30/2022 01:46:11 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:46:55 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_13_0.2_8_predictions.txt
05/30/2022 01:46:55 - INFO - __main__ - Classification-F1 on test data: 0.0383
05/30/2022 01:46:55 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.21743697478991597, test_performance=0.03826613080547574
05/30/2022 01:46:55 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
05/30/2022 01:46:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:46:56 - INFO - __main__ - Printing 3 examples
05/30/2022 01:46:56 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 01:46:56 - INFO - __main__ - ['sad']
05/30/2022 01:46:56 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 01:46:56 - INFO - __main__ - ['sad']
05/30/2022 01:46:56 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 01:46:56 - INFO - __main__ - ['sad']
05/30/2022 01:46:56 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:46:56 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:46:56 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:46:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:46:56 - INFO - __main__ - Printing 3 examples
05/30/2022 01:46:56 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 01:46:56 - INFO - __main__ - ['sad']
05/30/2022 01:46:56 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 01:46:56 - INFO - __main__ - ['sad']
05/30/2022 01:46:56 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 01:46:56 - INFO - __main__ - ['sad']
05/30/2022 01:46:56 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:46:56 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:46:56 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:47:02 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:47:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:47:03 - INFO - __main__ - Starting training!
05/30/2022 01:47:04 - INFO - __main__ - Step 10 Global step 10 Train loss 6.57 on epoch=2
05/30/2022 01:47:05 - INFO - __main__ - Step 20 Global step 20 Train loss 6.45 on epoch=4
05/30/2022 01:47:07 - INFO - __main__ - Step 30 Global step 30 Train loss 6.23 on epoch=7
05/30/2022 01:47:08 - INFO - __main__ - Step 40 Global step 40 Train loss 5.99 on epoch=9
05/30/2022 01:47:09 - INFO - __main__ - Step 50 Global step 50 Train loss 5.78 on epoch=12
05/30/2022 01:47:12 - INFO - __main__ - Global step 50 Train loss 6.21 Classification-F1 0.0 on epoch=12
05/30/2022 01:47:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:47:13 - INFO - __main__ - Step 60 Global step 60 Train loss 5.59 on epoch=14
05/30/2022 01:47:15 - INFO - __main__ - Step 70 Global step 70 Train loss 5.28 on epoch=17
05/30/2022 01:47:16 - INFO - __main__ - Step 80 Global step 80 Train loss 4.97 on epoch=19
05/30/2022 01:47:17 - INFO - __main__ - Step 90 Global step 90 Train loss 4.85 on epoch=22
05/30/2022 01:47:19 - INFO - __main__ - Step 100 Global step 100 Train loss 4.55 on epoch=24
05/30/2022 01:47:19 - INFO - __main__ - Global step 100 Train loss 5.05 Classification-F1 0.06862745098039216 on epoch=24
05/30/2022 01:47:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.06862745098039216 on epoch=24, global_step=100
05/30/2022 01:47:21 - INFO - __main__ - Step 110 Global step 110 Train loss 4.41 on epoch=27
05/30/2022 01:47:22 - INFO - __main__ - Step 120 Global step 120 Train loss 4.15 on epoch=29
05/30/2022 01:47:23 - INFO - __main__ - Step 130 Global step 130 Train loss 3.94 on epoch=32
05/30/2022 01:47:24 - INFO - __main__ - Step 140 Global step 140 Train loss 3.64 on epoch=34
05/30/2022 01:47:26 - INFO - __main__ - Step 150 Global step 150 Train loss 3.77 on epoch=37
05/30/2022 01:47:26 - INFO - __main__ - Global step 150 Train loss 3.98 Classification-F1 0.12393162393162392 on epoch=37
05/30/2022 01:47:26 - INFO - __main__ - Saving model with best Classification-F1: 0.06862745098039216 -> 0.12393162393162392 on epoch=37, global_step=150
05/30/2022 01:47:28 - INFO - __main__ - Step 160 Global step 160 Train loss 3.26 on epoch=39
05/30/2022 01:47:29 - INFO - __main__ - Step 170 Global step 170 Train loss 3.44 on epoch=42
05/30/2022 01:47:30 - INFO - __main__ - Step 180 Global step 180 Train loss 3.16 on epoch=44
05/30/2022 01:47:31 - INFO - __main__ - Step 190 Global step 190 Train loss 3.14 on epoch=47
05/30/2022 01:47:33 - INFO - __main__ - Step 200 Global step 200 Train loss 2.96 on epoch=49
05/30/2022 01:47:33 - INFO - __main__ - Global step 200 Train loss 3.19 Classification-F1 0.12145748987854252 on epoch=49
05/30/2022 01:47:34 - INFO - __main__ - Step 210 Global step 210 Train loss 3.09 on epoch=52
05/30/2022 01:47:36 - INFO - __main__ - Step 220 Global step 220 Train loss 2.88 on epoch=54
05/30/2022 01:47:37 - INFO - __main__ - Step 230 Global step 230 Train loss 3.04 on epoch=57
05/30/2022 01:47:38 - INFO - __main__ - Step 240 Global step 240 Train loss 2.77 on epoch=59
05/30/2022 01:47:40 - INFO - __main__ - Step 250 Global step 250 Train loss 2.84 on epoch=62
05/30/2022 01:47:40 - INFO - __main__ - Global step 250 Train loss 2.92 Classification-F1 0.1682769726247987 on epoch=62
05/30/2022 01:47:40 - INFO - __main__ - Saving model with best Classification-F1: 0.12393162393162392 -> 0.1682769726247987 on epoch=62, global_step=250
05/30/2022 01:47:41 - INFO - __main__ - Step 260 Global step 260 Train loss 2.77 on epoch=64
05/30/2022 01:47:43 - INFO - __main__ - Step 270 Global step 270 Train loss 2.87 on epoch=67
05/30/2022 01:47:44 - INFO - __main__ - Step 280 Global step 280 Train loss 2.46 on epoch=69
05/30/2022 01:47:45 - INFO - __main__ - Step 290 Global step 290 Train loss 2.74 on epoch=72
05/30/2022 01:47:46 - INFO - __main__ - Step 300 Global step 300 Train loss 2.60 on epoch=74
05/30/2022 01:47:47 - INFO - __main__ - Global step 300 Train loss 2.69 Classification-F1 0.1 on epoch=74
05/30/2022 01:47:48 - INFO - __main__ - Step 310 Global step 310 Train loss 2.70 on epoch=77
05/30/2022 01:47:49 - INFO - __main__ - Step 320 Global step 320 Train loss 2.42 on epoch=79
05/30/2022 01:47:51 - INFO - __main__ - Step 330 Global step 330 Train loss 2.60 on epoch=82
05/30/2022 01:47:52 - INFO - __main__ - Step 340 Global step 340 Train loss 2.40 on epoch=84
05/30/2022 01:47:53 - INFO - __main__ - Step 350 Global step 350 Train loss 2.45 on epoch=87
05/30/2022 01:47:54 - INFO - __main__ - Global step 350 Train loss 2.51 Classification-F1 0.1 on epoch=87
05/30/2022 01:47:55 - INFO - __main__ - Step 360 Global step 360 Train loss 2.09 on epoch=89
05/30/2022 01:47:56 - INFO - __main__ - Step 370 Global step 370 Train loss 2.32 on epoch=92
05/30/2022 01:47:58 - INFO - __main__ - Step 380 Global step 380 Train loss 2.28 on epoch=94
05/30/2022 01:47:59 - INFO - __main__ - Step 390 Global step 390 Train loss 2.28 on epoch=97
05/30/2022 01:48:00 - INFO - __main__ - Step 400 Global step 400 Train loss 2.20 on epoch=99
05/30/2022 01:48:01 - INFO - __main__ - Global step 400 Train loss 2.24 Classification-F1 0.09615384615384615 on epoch=99
05/30/2022 01:48:02 - INFO - __main__ - Step 410 Global step 410 Train loss 2.12 on epoch=102
05/30/2022 01:48:03 - INFO - __main__ - Step 420 Global step 420 Train loss 2.13 on epoch=104
05/30/2022 01:48:05 - INFO - __main__ - Step 430 Global step 430 Train loss 2.12 on epoch=107
05/30/2022 01:48:06 - INFO - __main__ - Step 440 Global step 440 Train loss 1.94 on epoch=109
05/30/2022 01:48:07 - INFO - __main__ - Step 450 Global step 450 Train loss 1.93 on epoch=112
05/30/2022 01:48:08 - INFO - __main__ - Global step 450 Train loss 2.05 Classification-F1 0.14915966386554622 on epoch=112
05/30/2022 01:48:09 - INFO - __main__ - Step 460 Global step 460 Train loss 1.96 on epoch=114
05/30/2022 01:48:10 - INFO - __main__ - Step 470 Global step 470 Train loss 1.91 on epoch=117
05/30/2022 01:48:12 - INFO - __main__ - Step 480 Global step 480 Train loss 1.83 on epoch=119
05/30/2022 01:48:13 - INFO - __main__ - Step 490 Global step 490 Train loss 1.76 on epoch=122
05/30/2022 01:48:14 - INFO - __main__ - Step 500 Global step 500 Train loss 1.68 on epoch=124
05/30/2022 01:48:15 - INFO - __main__ - Global step 500 Train loss 1.83 Classification-F1 0.13968957871396895 on epoch=124
05/30/2022 01:48:16 - INFO - __main__ - Step 510 Global step 510 Train loss 1.77 on epoch=127
05/30/2022 01:48:17 - INFO - __main__ - Step 520 Global step 520 Train loss 1.69 on epoch=129
05/30/2022 01:48:18 - INFO - __main__ - Step 530 Global step 530 Train loss 1.75 on epoch=132
05/30/2022 01:48:20 - INFO - __main__ - Step 540 Global step 540 Train loss 1.73 on epoch=134
05/30/2022 01:48:21 - INFO - __main__ - Step 550 Global step 550 Train loss 1.70 on epoch=137
05/30/2022 01:48:22 - INFO - __main__ - Global step 550 Train loss 1.73 Classification-F1 0.170995670995671 on epoch=137
05/30/2022 01:48:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1682769726247987 -> 0.170995670995671 on epoch=137, global_step=550
05/30/2022 01:48:23 - INFO - __main__ - Step 560 Global step 560 Train loss 1.55 on epoch=139
05/30/2022 01:48:24 - INFO - __main__ - Step 570 Global step 570 Train loss 1.57 on epoch=142
05/30/2022 01:48:25 - INFO - __main__ - Step 580 Global step 580 Train loss 1.66 on epoch=144
05/30/2022 01:48:27 - INFO - __main__ - Step 590 Global step 590 Train loss 1.61 on epoch=147
05/30/2022 01:48:28 - INFO - __main__ - Step 600 Global step 600 Train loss 1.55 on epoch=149
05/30/2022 01:48:28 - INFO - __main__ - Global step 600 Train loss 1.59 Classification-F1 0.1 on epoch=149
05/30/2022 01:48:30 - INFO - __main__ - Step 610 Global step 610 Train loss 1.51 on epoch=152
05/30/2022 01:48:31 - INFO - __main__ - Step 620 Global step 620 Train loss 1.34 on epoch=154
05/30/2022 01:48:32 - INFO - __main__ - Step 630 Global step 630 Train loss 1.44 on epoch=157
05/30/2022 01:48:33 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=159
05/30/2022 01:48:35 - INFO - __main__ - Step 650 Global step 650 Train loss 1.32 on epoch=162
05/30/2022 01:48:35 - INFO - __main__ - Global step 650 Train loss 1.41 Classification-F1 0.09493670886075949 on epoch=162
05/30/2022 01:48:37 - INFO - __main__ - Step 660 Global step 660 Train loss 1.40 on epoch=164
05/30/2022 01:48:38 - INFO - __main__ - Step 670 Global step 670 Train loss 1.46 on epoch=167
05/30/2022 01:48:39 - INFO - __main__ - Step 680 Global step 680 Train loss 1.32 on epoch=169
05/30/2022 01:48:40 - INFO - __main__ - Step 690 Global step 690 Train loss 1.43 on epoch=172
05/30/2022 01:48:42 - INFO - __main__ - Step 700 Global step 700 Train loss 1.44 on epoch=174
05/30/2022 01:48:42 - INFO - __main__ - Global step 700 Train loss 1.41 Classification-F1 0.1 on epoch=174
05/30/2022 01:48:44 - INFO - __main__ - Step 710 Global step 710 Train loss 1.45 on epoch=177
05/30/2022 01:48:45 - INFO - __main__ - Step 720 Global step 720 Train loss 1.39 on epoch=179
05/30/2022 01:48:46 - INFO - __main__ - Step 730 Global step 730 Train loss 1.31 on epoch=182
05/30/2022 01:48:47 - INFO - __main__ - Step 740 Global step 740 Train loss 1.29 on epoch=184
05/30/2022 01:48:49 - INFO - __main__ - Step 750 Global step 750 Train loss 1.34 on epoch=187
05/30/2022 01:48:49 - INFO - __main__ - Global step 750 Train loss 1.36 Classification-F1 0.09493670886075949 on epoch=187
05/30/2022 01:48:50 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=189
05/30/2022 01:48:52 - INFO - __main__ - Step 770 Global step 770 Train loss 1.30 on epoch=192
05/30/2022 01:48:53 - INFO - __main__ - Step 780 Global step 780 Train loss 1.29 on epoch=194
05/30/2022 01:48:54 - INFO - __main__ - Step 790 Global step 790 Train loss 1.26 on epoch=197
05/30/2022 01:48:56 - INFO - __main__ - Step 800 Global step 800 Train loss 1.31 on epoch=199
05/30/2022 01:48:56 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.1 on epoch=199
05/30/2022 01:48:57 - INFO - __main__ - Step 810 Global step 810 Train loss 1.44 on epoch=202
05/30/2022 01:48:59 - INFO - __main__ - Step 820 Global step 820 Train loss 1.17 on epoch=204
05/30/2022 01:49:00 - INFO - __main__ - Step 830 Global step 830 Train loss 1.25 on epoch=207
05/30/2022 01:49:01 - INFO - __main__ - Step 840 Global step 840 Train loss 1.26 on epoch=209
05/30/2022 01:49:03 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=212
05/30/2022 01:49:03 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.11732186732186733 on epoch=212
05/30/2022 01:49:04 - INFO - __main__ - Step 860 Global step 860 Train loss 1.22 on epoch=214
05/30/2022 01:49:06 - INFO - __main__ - Step 870 Global step 870 Train loss 1.21 on epoch=217
05/30/2022 01:49:07 - INFO - __main__ - Step 880 Global step 880 Train loss 1.23 on epoch=219
05/30/2022 01:49:08 - INFO - __main__ - Step 890 Global step 890 Train loss 1.14 on epoch=222
05/30/2022 01:49:10 - INFO - __main__ - Step 900 Global step 900 Train loss 1.23 on epoch=224
05/30/2022 01:49:10 - INFO - __main__ - Global step 900 Train loss 1.21 Classification-F1 0.13611111111111113 on epoch=224
05/30/2022 01:49:11 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=227
05/30/2022 01:49:13 - INFO - __main__ - Step 920 Global step 920 Train loss 1.28 on epoch=229
05/30/2022 01:49:14 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=232
05/30/2022 01:49:15 - INFO - __main__ - Step 940 Global step 940 Train loss 1.32 on epoch=234
05/30/2022 01:49:17 - INFO - __main__ - Step 950 Global step 950 Train loss 1.16 on epoch=237
05/30/2022 01:49:17 - INFO - __main__ - Global step 950 Train loss 1.26 Classification-F1 0.14915966386554622 on epoch=237
05/30/2022 01:49:18 - INFO - __main__ - Step 960 Global step 960 Train loss 1.18 on epoch=239
05/30/2022 01:49:20 - INFO - __main__ - Step 970 Global step 970 Train loss 1.04 on epoch=242
05/30/2022 01:49:21 - INFO - __main__ - Step 980 Global step 980 Train loss 1.27 on epoch=244
05/30/2022 01:49:22 - INFO - __main__ - Step 990 Global step 990 Train loss 1.06 on epoch=247
05/30/2022 01:49:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.27 on epoch=249
05/30/2022 01:49:24 - INFO - __main__ - Global step 1000 Train loss 1.16 Classification-F1 0.11762954139368673 on epoch=249
05/30/2022 01:49:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.12 on epoch=252
05/30/2022 01:49:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.16 on epoch=254
05/30/2022 01:49:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.25 on epoch=257
05/30/2022 01:49:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.21 on epoch=259
05/30/2022 01:49:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.16 on epoch=262
05/30/2022 01:49:31 - INFO - __main__ - Global step 1050 Train loss 1.18 Classification-F1 0.09615384615384615 on epoch=262
05/30/2022 01:49:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.19 on epoch=264
05/30/2022 01:49:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=267
05/30/2022 01:49:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.19 on epoch=269
05/30/2022 01:49:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.18 on epoch=272
05/30/2022 01:49:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.04 on epoch=274
05/30/2022 01:49:38 - INFO - __main__ - Global step 1100 Train loss 1.15 Classification-F1 0.11177278973889145 on epoch=274
05/30/2022 01:49:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.26 on epoch=277
05/30/2022 01:49:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.22 on epoch=279
05/30/2022 01:49:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.19 on epoch=282
05/30/2022 01:49:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.20 on epoch=284
05/30/2022 01:49:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=287
05/30/2022 01:49:45 - INFO - __main__ - Global step 1150 Train loss 1.20 Classification-F1 0.14753320683111953 on epoch=287
05/30/2022 01:49:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.12 on epoch=289
05/30/2022 01:49:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.12 on epoch=292
05/30/2022 01:49:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.12 on epoch=294
05/30/2022 01:49:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.06 on epoch=297
05/30/2022 01:49:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.21 on epoch=299
05/30/2022 01:49:52 - INFO - __main__ - Global step 1200 Train loss 1.12 Classification-F1 0.14771241830065357 on epoch=299
05/30/2022 01:49:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.12 on epoch=302
05/30/2022 01:49:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.18 on epoch=304
05/30/2022 01:49:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=307
05/30/2022 01:49:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/30/2022 01:49:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=312
05/30/2022 01:49:59 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.140625 on epoch=312
05/30/2022 01:50:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.01 on epoch=314
05/30/2022 01:50:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.98 on epoch=317
05/30/2022 01:50:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.21 on epoch=319
05/30/2022 01:50:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.09 on epoch=322
05/30/2022 01:50:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.09 on epoch=324
05/30/2022 01:50:06 - INFO - __main__ - Global step 1300 Train loss 1.08 Classification-F1 0.15356265356265356 on epoch=324
05/30/2022 01:50:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.12 on epoch=327
05/30/2022 01:50:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.19 on epoch=329
05/30/2022 01:50:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.10 on epoch=332
05/30/2022 01:50:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.13 on epoch=334
05/30/2022 01:50:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.12 on epoch=337
05/30/2022 01:50:13 - INFO - __main__ - Global step 1350 Train loss 1.13 Classification-F1 0.10126582278481013 on epoch=337
05/30/2022 01:50:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.09 on epoch=339
05/30/2022 01:50:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.02 on epoch=342
05/30/2022 01:50:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=344
05/30/2022 01:50:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.00 on epoch=347
05/30/2022 01:50:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=349
05/30/2022 01:50:20 - INFO - __main__ - Global step 1400 Train loss 1.03 Classification-F1 0.1611111111111111 on epoch=349
05/30/2022 01:50:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.02 on epoch=352
05/30/2022 01:50:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.10 on epoch=354
05/30/2022 01:50:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.09 on epoch=357
05/30/2022 01:50:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.12 on epoch=359
05/30/2022 01:50:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
05/30/2022 01:50:27 - INFO - __main__ - Global step 1450 Train loss 1.09 Classification-F1 0.10126582278481013 on epoch=362
05/30/2022 01:50:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=364
05/30/2022 01:50:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.05 on epoch=367
05/30/2022 01:50:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.93 on epoch=369
05/30/2022 01:50:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.05 on epoch=372
05/30/2022 01:50:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.13 on epoch=374
05/30/2022 01:50:34 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.1796875 on epoch=374
05/30/2022 01:50:34 - INFO - __main__ - Saving model with best Classification-F1: 0.170995670995671 -> 0.1796875 on epoch=374, global_step=1500
05/30/2022 01:50:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.11 on epoch=377
05/30/2022 01:50:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.93 on epoch=379
05/30/2022 01:50:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.01 on epoch=382
05/30/2022 01:50:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.95 on epoch=384
05/30/2022 01:50:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.07 on epoch=387
05/30/2022 01:50:41 - INFO - __main__ - Global step 1550 Train loss 1.01 Classification-F1 0.0974025974025974 on epoch=387
05/30/2022 01:50:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.94 on epoch=389
05/30/2022 01:50:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.05 on epoch=392
05/30/2022 01:50:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.01 on epoch=394
05/30/2022 01:50:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.05 on epoch=397
05/30/2022 01:50:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.03 on epoch=399
05/30/2022 01:50:47 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.12646198830409355 on epoch=399
05/30/2022 01:50:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.06 on epoch=402
05/30/2022 01:50:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.99 on epoch=404
05/30/2022 01:50:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.13 on epoch=407
05/30/2022 01:50:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.92 on epoch=409
05/30/2022 01:50:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.95 on epoch=412
05/30/2022 01:50:54 - INFO - __main__ - Global step 1650 Train loss 1.01 Classification-F1 0.11722488038277512 on epoch=412
05/30/2022 01:50:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.97 on epoch=414
05/30/2022 01:50:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.09 on epoch=417
05/30/2022 01:50:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.03 on epoch=419
05/30/2022 01:51:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.92 on epoch=422
05/30/2022 01:51:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.99 on epoch=424
05/30/2022 01:51:01 - INFO - __main__ - Global step 1700 Train loss 1.00 Classification-F1 0.12710084033613445 on epoch=424
05/30/2022 01:51:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
05/30/2022 01:51:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.86 on epoch=429
05/30/2022 01:51:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.96 on epoch=432
05/30/2022 01:51:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.00 on epoch=434
05/30/2022 01:51:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.04 on epoch=437
05/30/2022 01:51:08 - INFO - __main__ - Global step 1750 Train loss 0.98 Classification-F1 0.17369852369852368 on epoch=437
05/30/2022 01:51:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
05/30/2022 01:51:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.09 on epoch=442
05/30/2022 01:51:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.06 on epoch=444
05/30/2022 01:51:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.11 on epoch=447
05/30/2022 01:51:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.19 on epoch=449
05/30/2022 01:51:15 - INFO - __main__ - Global step 1800 Train loss 1.09 Classification-F1 0.21286031042128603 on epoch=449
05/30/2022 01:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.1796875 -> 0.21286031042128603 on epoch=449, global_step=1800
05/30/2022 01:51:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/30/2022 01:51:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.99 on epoch=454
05/30/2022 01:51:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.12 on epoch=457
05/30/2022 01:51:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.00 on epoch=459
05/30/2022 01:51:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.03 on epoch=462
05/30/2022 01:51:22 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.2034090909090909 on epoch=462
05/30/2022 01:51:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.00 on epoch=464
05/30/2022 01:51:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.98 on epoch=467
05/30/2022 01:51:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.99 on epoch=469
05/30/2022 01:51:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.95 on epoch=472
05/30/2022 01:51:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.93 on epoch=474
05/30/2022 01:51:29 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.1 on epoch=474
05/30/2022 01:51:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.00 on epoch=477
05/30/2022 01:51:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.05 on epoch=479
05/30/2022 01:51:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=482
05/30/2022 01:51:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.01 on epoch=484
05/30/2022 01:51:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.04 on epoch=487
05/30/2022 01:51:36 - INFO - __main__ - Global step 1950 Train loss 1.02 Classification-F1 0.12393162393162392 on epoch=487
05/30/2022 01:51:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.08 on epoch=489
05/30/2022 01:51:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.10 on epoch=492
05/30/2022 01:51:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.03 on epoch=494
05/30/2022 01:51:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.06 on epoch=497
05/30/2022 01:51:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.05 on epoch=499
05/30/2022 01:51:43 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.1 on epoch=499
05/30/2022 01:51:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/30/2022 01:51:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.11 on epoch=504
05/30/2022 01:51:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=507
05/30/2022 01:51:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.06 on epoch=509
05/30/2022 01:51:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.04 on epoch=512
05/30/2022 01:51:50 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.15498891352549887 on epoch=512
05/30/2022 01:51:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=514
05/30/2022 01:51:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.99 on epoch=517
05/30/2022 01:51:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
05/30/2022 01:51:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.88 on epoch=522
05/30/2022 01:51:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.96 on epoch=524
05/30/2022 01:51:57 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.10256410256410256 on epoch=524
05/30/2022 01:51:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/30/2022 01:52:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.95 on epoch=529
05/30/2022 01:52:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=532
05/30/2022 01:52:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.00 on epoch=534
05/30/2022 01:52:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.09 on epoch=537
05/30/2022 01:52:04 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.1660839160839161 on epoch=537
05/30/2022 01:52:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.05 on epoch=539
05/30/2022 01:52:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.92 on epoch=542
05/30/2022 01:52:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/30/2022 01:52:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.99 on epoch=547
05/30/2022 01:52:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.96 on epoch=549
05/30/2022 01:52:11 - INFO - __main__ - Global step 2200 Train loss 0.99 Classification-F1 0.16963260619977039 on epoch=549
05/30/2022 01:52:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.89 on epoch=552
05/30/2022 01:52:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.00 on epoch=554
05/30/2022 01:52:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.91 on epoch=557
05/30/2022 01:52:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.01 on epoch=559
05/30/2022 01:52:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=562
05/30/2022 01:52:18 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.12407862407862408 on epoch=562
05/30/2022 01:52:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/30/2022 01:52:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=567
05/30/2022 01:52:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.00 on epoch=569
05/30/2022 01:52:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/30/2022 01:52:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.98 on epoch=574
05/30/2022 01:52:25 - INFO - __main__ - Global step 2300 Train loss 1.01 Classification-F1 0.13067758749069247 on epoch=574
05/30/2022 01:52:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/30/2022 01:52:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.97 on epoch=579
05/30/2022 01:52:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.98 on epoch=582
05/30/2022 01:52:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.88 on epoch=584
05/30/2022 01:52:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=587
05/30/2022 01:52:32 - INFO - __main__ - Global step 2350 Train loss 0.94 Classification-F1 0.1437908496732026 on epoch=587
05/30/2022 01:52:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.91 on epoch=589
05/30/2022 01:52:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
05/30/2022 01:52:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.95 on epoch=594
05/30/2022 01:52:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/30/2022 01:52:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.96 on epoch=599
05/30/2022 01:52:39 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.13067758749069247 on epoch=599
05/30/2022 01:52:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.02 on epoch=602
05/30/2022 01:52:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/30/2022 01:52:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.92 on epoch=607
05/30/2022 01:52:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
05/30/2022 01:52:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
05/30/2022 01:52:46 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.23392857142857143 on epoch=612
05/30/2022 01:52:46 - INFO - __main__ - Saving model with best Classification-F1: 0.21286031042128603 -> 0.23392857142857143 on epoch=612, global_step=2450
05/30/2022 01:52:47 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.89 on epoch=614
05/30/2022 01:52:48 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=617
05/30/2022 01:52:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
05/30/2022 01:52:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.98 on epoch=622
05/30/2022 01:52:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
05/30/2022 01:52:53 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.10126582278481013 on epoch=624
05/30/2022 01:52:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/30/2022 01:52:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.99 on epoch=629
05/30/2022 01:52:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.85 on epoch=632
05/30/2022 01:52:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/30/2022 01:52:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.01 on epoch=637
05/30/2022 01:53:00 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.21869565217391307 on epoch=637
05/30/2022 01:53:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.92 on epoch=639
05/30/2022 01:53:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.84 on epoch=642
05/30/2022 01:53:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.87 on epoch=644
05/30/2022 01:53:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/30/2022 01:53:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/30/2022 01:53:07 - INFO - __main__ - Global step 2600 Train loss 0.92 Classification-F1 0.17694311767260096 on epoch=649
05/30/2022 01:53:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.08 on epoch=652
05/30/2022 01:53:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
05/30/2022 01:53:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=657
05/30/2022 01:53:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
05/30/2022 01:53:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.94 on epoch=662
05/30/2022 01:53:14 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.0974025974025974 on epoch=662
05/30/2022 01:53:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.87 on epoch=664
05/30/2022 01:53:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.99 on epoch=667
05/30/2022 01:53:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.98 on epoch=669
05/30/2022 01:53:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.95 on epoch=672
05/30/2022 01:53:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.96 on epoch=674
05/30/2022 01:53:21 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.1738412346070504 on epoch=674
05/30/2022 01:53:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.90 on epoch=677
05/30/2022 01:53:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.87 on epoch=679
05/30/2022 01:53:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.95 on epoch=682
05/30/2022 01:53:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.01 on epoch=684
05/30/2022 01:53:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.96 on epoch=687
05/30/2022 01:53:28 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.13333333333333333 on epoch=687
05/30/2022 01:53:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.89 on epoch=689
05/30/2022 01:53:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.84 on epoch=692
05/30/2022 01:53:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.94 on epoch=694
05/30/2022 01:53:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.97 on epoch=697
05/30/2022 01:53:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.87 on epoch=699
05/30/2022 01:53:35 - INFO - __main__ - Global step 2800 Train loss 0.90 Classification-F1 0.13566098081023453 on epoch=699
05/30/2022 01:53:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.94 on epoch=702
05/30/2022 01:53:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/30/2022 01:53:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.99 on epoch=707
05/30/2022 01:53:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.86 on epoch=709
05/30/2022 01:53:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.83 on epoch=712
05/30/2022 01:53:41 - INFO - __main__ - Global step 2850 Train loss 0.91 Classification-F1 0.15 on epoch=712
05/30/2022 01:53:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
05/30/2022 01:53:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.87 on epoch=717
05/30/2022 01:53:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.93 on epoch=719
05/30/2022 01:53:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.98 on epoch=722
05/30/2022 01:53:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.85 on epoch=724
05/30/2022 01:53:48 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.1 on epoch=724
05/30/2022 01:53:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.94 on epoch=727
05/30/2022 01:53:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.07 on epoch=729
05/30/2022 01:53:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=732
05/30/2022 01:53:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.92 on epoch=734
05/30/2022 01:53:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.89 on epoch=737
05/30/2022 01:53:55 - INFO - __main__ - Global step 2950 Train loss 0.95 Classification-F1 0.148970398970399 on epoch=737
05/30/2022 01:53:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=739
05/30/2022 01:53:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.88 on epoch=742
05/30/2022 01:53:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.88 on epoch=744
05/30/2022 01:54:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.91 on epoch=747
05/30/2022 01:54:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.88 on epoch=749
05/30/2022 01:54:02 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.13047619047619047 on epoch=749
05/30/2022 01:54:02 - INFO - __main__ - save last model!
05/30/2022 01:54:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 01:54:02 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 01:54:02 - INFO - __main__ - Printing 3 examples
05/30/2022 01:54:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 01:54:02 - INFO - __main__ - ['others']
05/30/2022 01:54:02 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 01:54:02 - INFO - __main__ - ['others']
05/30/2022 01:54:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 01:54:02 - INFO - __main__ - ['others']
05/30/2022 01:54:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:54:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:54:03 - INFO - __main__ - Printing 3 examples
05/30/2022 01:54:03 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 01:54:03 - INFO - __main__ - ['sad']
05/30/2022 01:54:03 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 01:54:03 - INFO - __main__ - ['sad']
05/30/2022 01:54:03 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 01:54:03 - INFO - __main__ - ['sad']
05/30/2022 01:54:03 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:54:03 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:54:03 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:54:03 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:54:03 - INFO - __main__ - Printing 3 examples
05/30/2022 01:54:03 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 01:54:03 - INFO - __main__ - ['sad']
05/30/2022 01:54:03 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 01:54:03 - INFO - __main__ - ['sad']
05/30/2022 01:54:03 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 01:54:03 - INFO - __main__ - ['sad']
05/30/2022 01:54:03 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:54:03 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:54:03 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:54:05 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:54:08 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:54:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:54:09 - INFO - __main__ - Starting training!
05/30/2022 01:54:10 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 01:54:53 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.5_8_predictions.txt
05/30/2022 01:54:53 - INFO - __main__ - Classification-F1 on test data: 0.0474
05/30/2022 01:54:53 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.23392857142857143, test_performance=0.04740650656882946
05/30/2022 01:54:53 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
05/30/2022 01:54:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:54:54 - INFO - __main__ - Printing 3 examples
05/30/2022 01:54:54 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 01:54:54 - INFO - __main__ - ['sad']
05/30/2022 01:54:54 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 01:54:54 - INFO - __main__ - ['sad']
05/30/2022 01:54:54 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 01:54:54 - INFO - __main__ - ['sad']
05/30/2022 01:54:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:54:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:54:54 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 01:54:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 01:54:54 - INFO - __main__ - Printing 3 examples
05/30/2022 01:54:54 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 01:54:54 - INFO - __main__ - ['sad']
05/30/2022 01:54:54 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 01:54:54 - INFO - __main__ - ['sad']
05/30/2022 01:54:54 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 01:54:54 - INFO - __main__ - ['sad']
05/30/2022 01:54:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 01:54:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 01:54:55 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 01:55:00 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 01:55:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 01:55:00 - INFO - __main__ - Starting training!
05/30/2022 01:55:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.72 on epoch=2
05/30/2022 01:55:03 - INFO - __main__ - Step 20 Global step 20 Train loss 6.47 on epoch=4
05/30/2022 01:55:04 - INFO - __main__ - Step 30 Global step 30 Train loss 6.25 on epoch=7
05/30/2022 01:55:05 - INFO - __main__ - Step 40 Global step 40 Train loss 6.07 on epoch=9
05/30/2022 01:55:06 - INFO - __main__ - Step 50 Global step 50 Train loss 5.90 on epoch=12
05/30/2022 01:55:09 - INFO - __main__ - Global step 50 Train loss 6.28 Classification-F1 0.0 on epoch=12
05/30/2022 01:55:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 01:55:10 - INFO - __main__ - Step 60 Global step 60 Train loss 5.66 on epoch=14
05/30/2022 01:55:11 - INFO - __main__ - Step 70 Global step 70 Train loss 5.64 on epoch=17
05/30/2022 01:55:13 - INFO - __main__ - Step 80 Global step 80 Train loss 5.40 on epoch=19
05/30/2022 01:55:14 - INFO - __main__ - Step 90 Global step 90 Train loss 5.30 on epoch=22
05/30/2022 01:55:15 - INFO - __main__ - Step 100 Global step 100 Train loss 5.06 on epoch=24
05/30/2022 01:55:16 - INFO - __main__ - Global step 100 Train loss 5.41 Classification-F1 0.0 on epoch=24
05/30/2022 01:55:18 - INFO - __main__ - Step 110 Global step 110 Train loss 5.02 on epoch=27
05/30/2022 01:55:19 - INFO - __main__ - Step 120 Global step 120 Train loss 4.77 on epoch=29
05/30/2022 01:55:20 - INFO - __main__ - Step 130 Global step 130 Train loss 4.71 on epoch=32
05/30/2022 01:55:21 - INFO - __main__ - Step 140 Global step 140 Train loss 4.55 on epoch=34
05/30/2022 01:55:22 - INFO - __main__ - Step 150 Global step 150 Train loss 4.48 on epoch=37
05/30/2022 01:55:23 - INFO - __main__ - Global step 150 Train loss 4.71 Classification-F1 0.03571428571428571 on epoch=37
05/30/2022 01:55:23 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03571428571428571 on epoch=37, global_step=150
05/30/2022 01:55:25 - INFO - __main__ - Step 160 Global step 160 Train loss 4.19 on epoch=39
05/30/2022 01:55:26 - INFO - __main__ - Step 170 Global step 170 Train loss 4.17 on epoch=42
05/30/2022 01:55:27 - INFO - __main__ - Step 180 Global step 180 Train loss 4.12 on epoch=44
05/30/2022 01:55:28 - INFO - __main__ - Step 190 Global step 190 Train loss 4.15 on epoch=47
05/30/2022 01:55:30 - INFO - __main__ - Step 200 Global step 200 Train loss 4.03 on epoch=49
05/30/2022 01:55:31 - INFO - __main__ - Global step 200 Train loss 4.13 Classification-F1 0.11805555555555555 on epoch=49
05/30/2022 01:55:31 - INFO - __main__ - Saving model with best Classification-F1: 0.03571428571428571 -> 0.11805555555555555 on epoch=49, global_step=200
05/30/2022 01:55:32 - INFO - __main__ - Step 210 Global step 210 Train loss 4.00 on epoch=52
05/30/2022 01:55:33 - INFO - __main__ - Step 220 Global step 220 Train loss 3.85 on epoch=54
05/30/2022 01:55:34 - INFO - __main__ - Step 230 Global step 230 Train loss 3.83 on epoch=57
05/30/2022 01:55:35 - INFO - __main__ - Step 240 Global step 240 Train loss 3.64 on epoch=59
05/30/2022 01:55:37 - INFO - __main__ - Step 250 Global step 250 Train loss 3.60 on epoch=62
05/30/2022 01:55:37 - INFO - __main__ - Global step 250 Train loss 3.78 Classification-F1 0.1283068783068783 on epoch=62
05/30/2022 01:55:37 - INFO - __main__ - Saving model with best Classification-F1: 0.11805555555555555 -> 0.1283068783068783 on epoch=62, global_step=250
05/30/2022 01:55:38 - INFO - __main__ - Step 260 Global step 260 Train loss 3.46 on epoch=64
05/30/2022 01:55:40 - INFO - __main__ - Step 270 Global step 270 Train loss 3.47 on epoch=67
05/30/2022 01:55:41 - INFO - __main__ - Step 280 Global step 280 Train loss 3.26 on epoch=69
05/30/2022 01:55:42 - INFO - __main__ - Step 290 Global step 290 Train loss 3.24 on epoch=72
05/30/2022 01:55:43 - INFO - __main__ - Step 300 Global step 300 Train loss 3.06 on epoch=74
05/30/2022 01:55:44 - INFO - __main__ - Global step 300 Train loss 3.30 Classification-F1 0.15526315789473685 on epoch=74
05/30/2022 01:55:44 - INFO - __main__ - Saving model with best Classification-F1: 0.1283068783068783 -> 0.15526315789473685 on epoch=74, global_step=300
05/30/2022 01:55:45 - INFO - __main__ - Step 310 Global step 310 Train loss 3.04 on epoch=77
05/30/2022 01:55:46 - INFO - __main__ - Step 320 Global step 320 Train loss 3.00 on epoch=79
05/30/2022 01:55:47 - INFO - __main__ - Step 330 Global step 330 Train loss 3.10 on epoch=82
05/30/2022 01:55:49 - INFO - __main__ - Step 340 Global step 340 Train loss 3.02 on epoch=84
05/30/2022 01:55:50 - INFO - __main__ - Step 350 Global step 350 Train loss 3.04 on epoch=87
05/30/2022 01:55:50 - INFO - __main__ - Global step 350 Train loss 3.04 Classification-F1 0.1869328493647913 on epoch=87
05/30/2022 01:55:50 - INFO - __main__ - Saving model with best Classification-F1: 0.15526315789473685 -> 0.1869328493647913 on epoch=87, global_step=350
05/30/2022 01:55:52 - INFO - __main__ - Step 360 Global step 360 Train loss 2.83 on epoch=89
05/30/2022 01:55:53 - INFO - __main__ - Step 370 Global step 370 Train loss 2.81 on epoch=92
05/30/2022 01:55:54 - INFO - __main__ - Step 380 Global step 380 Train loss 2.69 on epoch=94
05/30/2022 01:55:55 - INFO - __main__ - Step 390 Global step 390 Train loss 2.77 on epoch=97
05/30/2022 01:55:57 - INFO - __main__ - Step 400 Global step 400 Train loss 2.53 on epoch=99
05/30/2022 01:55:57 - INFO - __main__ - Global step 400 Train loss 2.73 Classification-F1 0.18888888888888888 on epoch=99
05/30/2022 01:55:57 - INFO - __main__ - Saving model with best Classification-F1: 0.1869328493647913 -> 0.18888888888888888 on epoch=99, global_step=400
05/30/2022 01:55:58 - INFO - __main__ - Step 410 Global step 410 Train loss 2.50 on epoch=102
05/30/2022 01:56:00 - INFO - __main__ - Step 420 Global step 420 Train loss 2.47 on epoch=104
05/30/2022 01:56:01 - INFO - __main__ - Step 430 Global step 430 Train loss 2.51 on epoch=107
05/30/2022 01:56:02 - INFO - __main__ - Step 440 Global step 440 Train loss 2.37 on epoch=109
05/30/2022 01:56:03 - INFO - __main__ - Step 450 Global step 450 Train loss 2.45 on epoch=112
05/30/2022 01:56:04 - INFO - __main__ - Global step 450 Train loss 2.46 Classification-F1 0.10294117647058824 on epoch=112
05/30/2022 01:56:05 - INFO - __main__ - Step 460 Global step 460 Train loss 2.45 on epoch=114
05/30/2022 01:56:06 - INFO - __main__ - Step 470 Global step 470 Train loss 2.44 on epoch=117
05/30/2022 01:56:07 - INFO - __main__ - Step 480 Global step 480 Train loss 2.41 on epoch=119
05/30/2022 01:56:09 - INFO - __main__ - Step 490 Global step 490 Train loss 2.24 on epoch=122
05/30/2022 01:56:10 - INFO - __main__ - Step 500 Global step 500 Train loss 2.29 on epoch=124
05/30/2022 01:56:10 - INFO - __main__ - Global step 500 Train loss 2.37 Classification-F1 0.1237183868762816 on epoch=124
05/30/2022 01:56:12 - INFO - __main__ - Step 510 Global step 510 Train loss 2.29 on epoch=127
05/30/2022 01:56:13 - INFO - __main__ - Step 520 Global step 520 Train loss 2.12 on epoch=129
05/30/2022 01:56:14 - INFO - __main__ - Step 530 Global step 530 Train loss 2.14 on epoch=132
05/30/2022 01:56:15 - INFO - __main__ - Step 540 Global step 540 Train loss 1.98 on epoch=134
05/30/2022 01:56:16 - INFO - __main__ - Step 550 Global step 550 Train loss 2.12 on epoch=137
05/30/2022 01:56:17 - INFO - __main__ - Global step 550 Train loss 2.13 Classification-F1 0.1 on epoch=137
05/30/2022 01:56:18 - INFO - __main__ - Step 560 Global step 560 Train loss 1.86 on epoch=139
05/30/2022 01:56:19 - INFO - __main__ - Step 570 Global step 570 Train loss 2.00 on epoch=142
05/30/2022 01:56:20 - INFO - __main__ - Step 580 Global step 580 Train loss 1.88 on epoch=144
05/30/2022 01:56:22 - INFO - __main__ - Step 590 Global step 590 Train loss 1.81 on epoch=147
05/30/2022 01:56:23 - INFO - __main__ - Step 600 Global step 600 Train loss 1.84 on epoch=149
05/30/2022 01:56:23 - INFO - __main__ - Global step 600 Train loss 1.88 Classification-F1 0.12393162393162392 on epoch=149
05/30/2022 01:56:25 - INFO - __main__ - Step 610 Global step 610 Train loss 1.89 on epoch=152
05/30/2022 01:56:26 - INFO - __main__ - Step 620 Global step 620 Train loss 1.82 on epoch=154
05/30/2022 01:56:27 - INFO - __main__ - Step 630 Global step 630 Train loss 1.91 on epoch=157
05/30/2022 01:56:28 - INFO - __main__ - Step 640 Global step 640 Train loss 1.66 on epoch=159
05/30/2022 01:56:30 - INFO - __main__ - Step 650 Global step 650 Train loss 1.80 on epoch=162
05/30/2022 01:56:30 - INFO - __main__ - Global step 650 Train loss 1.81 Classification-F1 0.11714285714285715 on epoch=162
05/30/2022 01:56:31 - INFO - __main__ - Step 660 Global step 660 Train loss 1.68 on epoch=164
05/30/2022 01:56:33 - INFO - __main__ - Step 670 Global step 670 Train loss 1.67 on epoch=167
05/30/2022 01:56:34 - INFO - __main__ - Step 680 Global step 680 Train loss 1.59 on epoch=169
05/30/2022 01:56:35 - INFO - __main__ - Step 690 Global step 690 Train loss 1.78 on epoch=172
05/30/2022 01:56:36 - INFO - __main__ - Step 700 Global step 700 Train loss 1.66 on epoch=174
05/30/2022 01:56:37 - INFO - __main__ - Global step 700 Train loss 1.67 Classification-F1 0.19016393442622948 on epoch=174
05/30/2022 01:56:37 - INFO - __main__ - Saving model with best Classification-F1: 0.18888888888888888 -> 0.19016393442622948 on epoch=174, global_step=700
05/30/2022 01:56:38 - INFO - __main__ - Step 710 Global step 710 Train loss 1.69 on epoch=177
05/30/2022 01:56:39 - INFO - __main__ - Step 720 Global step 720 Train loss 1.55 on epoch=179
05/30/2022 01:56:40 - INFO - __main__ - Step 730 Global step 730 Train loss 1.69 on epoch=182
05/30/2022 01:56:42 - INFO - __main__ - Step 740 Global step 740 Train loss 1.58 on epoch=184
05/30/2022 01:56:43 - INFO - __main__ - Step 750 Global step 750 Train loss 1.69 on epoch=187
05/30/2022 01:56:43 - INFO - __main__ - Global step 750 Train loss 1.64 Classification-F1 0.12407862407862408 on epoch=187
05/30/2022 01:56:45 - INFO - __main__ - Step 760 Global step 760 Train loss 1.50 on epoch=189
05/30/2022 01:56:46 - INFO - __main__ - Step 770 Global step 770 Train loss 1.58 on epoch=192
05/30/2022 01:56:47 - INFO - __main__ - Step 780 Global step 780 Train loss 1.49 on epoch=194
05/30/2022 01:56:48 - INFO - __main__ - Step 790 Global step 790 Train loss 1.56 on epoch=197
05/30/2022 01:56:49 - INFO - __main__ - Step 800 Global step 800 Train loss 1.46 on epoch=199
05/30/2022 01:56:50 - INFO - __main__ - Global step 800 Train loss 1.52 Classification-F1 0.13026315789473686 on epoch=199
05/30/2022 01:56:51 - INFO - __main__ - Step 810 Global step 810 Train loss 1.42 on epoch=202
05/30/2022 01:56:52 - INFO - __main__ - Step 820 Global step 820 Train loss 1.45 on epoch=204
05/30/2022 01:56:54 - INFO - __main__ - Step 830 Global step 830 Train loss 1.49 on epoch=207
05/30/2022 01:56:55 - INFO - __main__ - Step 840 Global step 840 Train loss 1.50 on epoch=209
05/30/2022 01:56:56 - INFO - __main__ - Step 850 Global step 850 Train loss 1.46 on epoch=212
05/30/2022 01:56:56 - INFO - __main__ - Global step 850 Train loss 1.46 Classification-F1 0.09333333333333334 on epoch=212
05/30/2022 01:56:58 - INFO - __main__ - Step 860 Global step 860 Train loss 1.41 on epoch=214
05/30/2022 01:56:59 - INFO - __main__ - Step 870 Global step 870 Train loss 1.40 on epoch=217
05/30/2022 01:57:00 - INFO - __main__ - Step 880 Global step 880 Train loss 1.51 on epoch=219
05/30/2022 01:57:01 - INFO - __main__ - Step 890 Global step 890 Train loss 1.37 on epoch=222
05/30/2022 01:57:02 - INFO - __main__ - Step 900 Global step 900 Train loss 1.53 on epoch=224
05/30/2022 01:57:03 - INFO - __main__ - Global step 900 Train loss 1.44 Classification-F1 0.1 on epoch=224
05/30/2022 01:57:04 - INFO - __main__ - Step 910 Global step 910 Train loss 1.41 on epoch=227
05/30/2022 01:57:05 - INFO - __main__ - Step 920 Global step 920 Train loss 1.38 on epoch=229
05/30/2022 01:57:07 - INFO - __main__ - Step 930 Global step 930 Train loss 1.35 on epoch=232
05/30/2022 01:57:08 - INFO - __main__ - Step 940 Global step 940 Train loss 1.41 on epoch=234
05/30/2022 01:57:09 - INFO - __main__ - Step 950 Global step 950 Train loss 1.43 on epoch=237
05/30/2022 01:57:10 - INFO - __main__ - Global step 950 Train loss 1.40 Classification-F1 0.12171899125064337 on epoch=237
05/30/2022 01:57:11 - INFO - __main__ - Step 960 Global step 960 Train loss 1.33 on epoch=239
05/30/2022 01:57:12 - INFO - __main__ - Step 970 Global step 970 Train loss 1.28 on epoch=242
05/30/2022 01:57:13 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
05/30/2022 01:57:14 - INFO - __main__ - Step 990 Global step 990 Train loss 1.28 on epoch=247
05/30/2022 01:57:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.29 on epoch=249
05/30/2022 01:57:16 - INFO - __main__ - Global step 1000 Train loss 1.30 Classification-F1 0.17344312918167784 on epoch=249
05/30/2022 01:57:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/30/2022 01:57:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.21 on epoch=254
05/30/2022 01:57:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.34 on epoch=257
05/30/2022 01:57:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.22 on epoch=259
05/30/2022 01:57:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.23 on epoch=262
05/30/2022 01:57:23 - INFO - __main__ - Global step 1050 Train loss 1.27 Classification-F1 0.1625874125874126 on epoch=262
05/30/2022 01:57:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.34 on epoch=264
05/30/2022 01:57:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.36 on epoch=267
05/30/2022 01:57:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.29 on epoch=269
05/30/2022 01:57:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.25 on epoch=272
05/30/2022 01:57:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.29 on epoch=274
05/30/2022 01:57:29 - INFO - __main__ - Global step 1100 Train loss 1.31 Classification-F1 0.14583333333333331 on epoch=274
05/30/2022 01:57:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.34 on epoch=277
05/30/2022 01:57:32 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.32 on epoch=279
05/30/2022 01:57:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.34 on epoch=282
05/30/2022 01:57:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.27 on epoch=284
05/30/2022 01:57:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.34 on epoch=287
05/30/2022 01:57:36 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.13034188034188032 on epoch=287
05/30/2022 01:57:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.27 on epoch=289
05/30/2022 01:57:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.21 on epoch=292
05/30/2022 01:57:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.16 on epoch=294
05/30/2022 01:57:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.13 on epoch=297
05/30/2022 01:57:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.24 on epoch=299
05/30/2022 01:57:43 - INFO - __main__ - Global step 1200 Train loss 1.20 Classification-F1 0.1565276828434723 on epoch=299
05/30/2022 01:57:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.21 on epoch=302
05/30/2022 01:57:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.17 on epoch=304
05/30/2022 01:57:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.12 on epoch=307
05/30/2022 01:57:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.18 on epoch=309
05/30/2022 01:57:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.09 on epoch=312
05/30/2022 01:57:50 - INFO - __main__ - Global step 1250 Train loss 1.15 Classification-F1 0.12407862407862408 on epoch=312
05/30/2022 01:57:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.22 on epoch=314
05/30/2022 01:57:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.32 on epoch=317
05/30/2022 01:57:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.28 on epoch=319
05/30/2022 01:57:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.12 on epoch=322
05/30/2022 01:57:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.12 on epoch=324
05/30/2022 01:57:57 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.1486842105263158 on epoch=324
05/30/2022 01:57:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.08 on epoch=327
05/30/2022 01:57:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.17 on epoch=329
05/30/2022 01:58:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.23 on epoch=332
05/30/2022 01:58:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.21 on epoch=334
05/30/2022 01:58:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=337
05/30/2022 01:58:03 - INFO - __main__ - Global step 1350 Train loss 1.18 Classification-F1 0.2109375 on epoch=337
05/30/2022 01:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.19016393442622948 -> 0.2109375 on epoch=337, global_step=1350
05/30/2022 01:58:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/30/2022 01:58:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
05/30/2022 01:58:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.17 on epoch=344
05/30/2022 01:58:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.23 on epoch=347
05/30/2022 01:58:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/30/2022 01:58:10 - INFO - __main__ - Global step 1400 Train loss 1.17 Classification-F1 0.131328171530673 on epoch=349
05/30/2022 01:58:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/30/2022 01:58:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.16 on epoch=354
05/30/2022 01:58:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.18 on epoch=357
05/30/2022 01:58:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.19 on epoch=359
05/30/2022 01:58:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.12 on epoch=362
05/30/2022 01:58:17 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.2144212523719165 on epoch=362
05/30/2022 01:58:17 - INFO - __main__ - Saving model with best Classification-F1: 0.2109375 -> 0.2144212523719165 on epoch=362, global_step=1450
05/30/2022 01:58:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.14 on epoch=364
05/30/2022 01:58:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.21 on epoch=367
05/30/2022 01:58:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/30/2022 01:58:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=372
05/30/2022 01:58:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.27 on epoch=374
05/30/2022 01:58:24 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.1 on epoch=374
05/30/2022 01:58:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.06 on epoch=377
05/30/2022 01:58:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/30/2022 01:58:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.15 on epoch=382
05/30/2022 01:58:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
05/30/2022 01:58:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.12 on epoch=387
05/30/2022 01:58:31 - INFO - __main__ - Global step 1550 Train loss 1.09 Classification-F1 0.18356643356643357 on epoch=387
05/30/2022 01:58:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.11 on epoch=389
05/30/2022 01:58:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.04 on epoch=392
05/30/2022 01:58:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.15 on epoch=394
05/30/2022 01:58:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.07 on epoch=397
05/30/2022 01:58:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.99 on epoch=399
05/30/2022 01:58:37 - INFO - __main__ - Global step 1600 Train loss 1.07 Classification-F1 0.17450980392156862 on epoch=399
05/30/2022 01:58:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.13 on epoch=402
05/30/2022 01:58:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.13 on epoch=404
05/30/2022 01:58:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.18 on epoch=407
05/30/2022 01:58:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.13 on epoch=409
05/30/2022 01:58:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.16 on epoch=412
05/30/2022 01:58:44 - INFO - __main__ - Global step 1650 Train loss 1.15 Classification-F1 0.21827759963353183 on epoch=412
05/30/2022 01:58:44 - INFO - __main__ - Saving model with best Classification-F1: 0.2144212523719165 -> 0.21827759963353183 on epoch=412, global_step=1650
05/30/2022 01:58:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.17 on epoch=414
05/30/2022 01:58:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.08 on epoch=417
05/30/2022 01:58:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.23 on epoch=419
05/30/2022 01:58:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.24 on epoch=422
05/30/2022 01:58:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.14 on epoch=424
05/30/2022 01:58:51 - INFO - __main__ - Global step 1700 Train loss 1.17 Classification-F1 0.18869565217391304 on epoch=424
05/30/2022 01:58:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.09 on epoch=427
05/30/2022 01:58:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/30/2022 01:58:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.19 on epoch=432
05/30/2022 01:58:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.11 on epoch=434
05/30/2022 01:58:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.02 on epoch=437
05/30/2022 01:58:58 - INFO - __main__ - Global step 1750 Train loss 1.08 Classification-F1 0.22832890218234186 on epoch=437
05/30/2022 01:58:58 - INFO - __main__ - Saving model with best Classification-F1: 0.21827759963353183 -> 0.22832890218234186 on epoch=437, global_step=1750
05/30/2022 01:58:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.03 on epoch=439
05/30/2022 01:59:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
05/30/2022 01:59:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/30/2022 01:59:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.97 on epoch=447
05/30/2022 01:59:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/30/2022 01:59:04 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.23446115288220554 on epoch=449
05/30/2022 01:59:04 - INFO - __main__ - Saving model with best Classification-F1: 0.22832890218234186 -> 0.23446115288220554 on epoch=449, global_step=1800
05/30/2022 01:59:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.10 on epoch=452
05/30/2022 01:59:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.05 on epoch=454
05/30/2022 01:59:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.15 on epoch=457
05/30/2022 01:59:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.10 on epoch=459
05/30/2022 01:59:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.07 on epoch=462
05/30/2022 01:59:11 - INFO - __main__ - Global step 1850 Train loss 1.10 Classification-F1 0.10606060606060605 on epoch=462
05/30/2022 01:59:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.17 on epoch=464
05/30/2022 01:59:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.12 on epoch=467
05/30/2022 01:59:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.18 on epoch=469
05/30/2022 01:59:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.12 on epoch=472
05/30/2022 01:59:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.09 on epoch=474
05/30/2022 01:59:18 - INFO - __main__ - Global step 1900 Train loss 1.14 Classification-F1 0.18928571428571428 on epoch=474
05/30/2022 01:59:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=477
05/30/2022 01:59:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.10 on epoch=479
05/30/2022 01:59:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.07 on epoch=482
05/30/2022 01:59:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=484
05/30/2022 01:59:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.97 on epoch=487
05/30/2022 01:59:25 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.17075672111933193 on epoch=487
05/30/2022 01:59:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.06 on epoch=489
05/30/2022 01:59:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.10 on epoch=492
05/30/2022 01:59:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.97 on epoch=494
05/30/2022 01:59:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.94 on epoch=497
05/30/2022 01:59:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.06 on epoch=499
05/30/2022 01:59:31 - INFO - __main__ - Global step 2000 Train loss 1.02 Classification-F1 0.11512749142601521 on epoch=499
05/30/2022 01:59:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.00 on epoch=502
05/30/2022 01:59:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.12 on epoch=504
05/30/2022 01:59:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
05/30/2022 01:59:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.10 on epoch=509
05/30/2022 01:59:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.03 on epoch=512
05/30/2022 01:59:38 - INFO - __main__ - Global step 2050 Train loss 1.06 Classification-F1 0.16953316953316955 on epoch=512
05/30/2022 01:59:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=514
05/30/2022 01:59:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.01 on epoch=517
05/30/2022 01:59:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.08 on epoch=519
05/30/2022 01:59:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.12 on epoch=522
05/30/2022 01:59:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.07 on epoch=524
05/30/2022 01:59:45 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.18714719930525403 on epoch=524
05/30/2022 01:59:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.13 on epoch=527
05/30/2022 01:59:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.04 on epoch=529
05/30/2022 01:59:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.05 on epoch=532
05/30/2022 01:59:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/30/2022 01:59:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.98 on epoch=537
05/30/2022 01:59:52 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.11840411840411841 on epoch=537
05/30/2022 01:59:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.06 on epoch=539
05/30/2022 01:59:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.01 on epoch=542
05/30/2022 01:59:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.09 on epoch=544
05/30/2022 01:59:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=547
05/30/2022 01:59:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.98 on epoch=549
05/30/2022 01:59:59 - INFO - __main__ - Global step 2200 Train loss 1.03 Classification-F1 0.10256410256410256 on epoch=549
05/30/2022 02:00:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.96 on epoch=552
05/30/2022 02:00:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.07 on epoch=554
05/30/2022 02:00:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/30/2022 02:00:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/30/2022 02:00:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=562
05/30/2022 02:00:05 - INFO - __main__ - Global step 2250 Train loss 1.00 Classification-F1 0.1 on epoch=562
05/30/2022 02:00:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/30/2022 02:00:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.03 on epoch=567
05/30/2022 02:00:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.04 on epoch=569
05/30/2022 02:00:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/30/2022 02:00:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.10 on epoch=574
05/30/2022 02:00:12 - INFO - __main__ - Global step 2300 Train loss 1.03 Classification-F1 0.1697802197802198 on epoch=574
05/30/2022 02:00:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/30/2022 02:00:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/30/2022 02:00:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=582
05/30/2022 02:00:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.96 on epoch=584
05/30/2022 02:00:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.11 on epoch=587
05/30/2022 02:00:19 - INFO - __main__ - Global step 2350 Train loss 1.00 Classification-F1 0.20053238686779057 on epoch=587
05/30/2022 02:00:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.98 on epoch=589
05/30/2022 02:00:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.01 on epoch=592
05/30/2022 02:00:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.01 on epoch=594
05/30/2022 02:00:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.13 on epoch=597
05/30/2022 02:00:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.05 on epoch=599
05/30/2022 02:00:26 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.17343358395989975 on epoch=599
05/30/2022 02:00:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.04 on epoch=602
05/30/2022 02:00:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/30/2022 02:00:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.06 on epoch=607
05/30/2022 02:00:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.07 on epoch=609
05/30/2022 02:00:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/30/2022 02:00:33 - INFO - __main__ - Global step 2450 Train loss 1.02 Classification-F1 0.11762954139368673 on epoch=612
05/30/2022 02:00:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.03 on epoch=614
05/30/2022 02:00:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.00 on epoch=617
05/30/2022 02:00:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.01 on epoch=619
05/30/2022 02:00:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.05 on epoch=622
05/30/2022 02:00:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.13 on epoch=624
05/30/2022 02:00:39 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.18969624776652771 on epoch=624
05/30/2022 02:00:41 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.09 on epoch=627
05/30/2022 02:00:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.05 on epoch=629
05/30/2022 02:00:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.00 on epoch=632
05/30/2022 02:00:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.98 on epoch=634
05/30/2022 02:00:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.02 on epoch=637
05/30/2022 02:00:46 - INFO - __main__ - Global step 2550 Train loss 1.03 Classification-F1 0.16451612903225807 on epoch=637
05/30/2022 02:00:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.97 on epoch=639
05/30/2022 02:00:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
05/30/2022 02:00:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.93 on epoch=644
05/30/2022 02:00:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.04 on epoch=647
05/30/2022 02:00:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/30/2022 02:00:53 - INFO - __main__ - Global step 2600 Train loss 0.99 Classification-F1 0.17694311767260096 on epoch=649
05/30/2022 02:00:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/30/2022 02:00:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=654
05/30/2022 02:00:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
05/30/2022 02:00:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.99 on epoch=659
05/30/2022 02:00:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.97 on epoch=662
05/30/2022 02:01:00 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.20714285714285713 on epoch=662
05/30/2022 02:01:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.05 on epoch=664
05/30/2022 02:01:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.08 on epoch=667
05/30/2022 02:01:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.01 on epoch=669
05/30/2022 02:01:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.98 on epoch=672
05/30/2022 02:01:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.94 on epoch=674
05/30/2022 02:01:06 - INFO - __main__ - Global step 2700 Train loss 1.01 Classification-F1 0.10273972602739727 on epoch=674
05/30/2022 02:01:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/30/2022 02:01:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.10 on epoch=679
05/30/2022 02:01:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.96 on epoch=682
05/30/2022 02:01:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.06 on epoch=684
05/30/2022 02:01:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.97 on epoch=687
05/30/2022 02:01:13 - INFO - __main__ - Global step 2750 Train loss 1.04 Classification-F1 0.10389610389610389 on epoch=687
05/30/2022 02:01:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.94 on epoch=689
05/30/2022 02:01:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.95 on epoch=692
05/30/2022 02:01:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.89 on epoch=694
05/30/2022 02:01:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=697
05/30/2022 02:01:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.99 on epoch=699
05/30/2022 02:01:20 - INFO - __main__ - Global step 2800 Train loss 0.94 Classification-F1 0.12393162393162392 on epoch=699
05/30/2022 02:01:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.01 on epoch=702
05/30/2022 02:01:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.00 on epoch=704
05/30/2022 02:01:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.03 on epoch=707
05/30/2022 02:01:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.95 on epoch=709
05/30/2022 02:01:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/30/2022 02:01:27 - INFO - __main__ - Global step 2850 Train loss 0.99 Classification-F1 0.1 on epoch=712
05/30/2022 02:01:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.94 on epoch=714
05/30/2022 02:01:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
05/30/2022 02:01:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.02 on epoch=719
05/30/2022 02:01:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.06 on epoch=722
05/30/2022 02:01:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/30/2022 02:01:34 - INFO - __main__ - Global step 2900 Train loss 1.00 Classification-F1 0.1576923076923077 on epoch=724
05/30/2022 02:01:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.97 on epoch=727
05/30/2022 02:01:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.00 on epoch=729
05/30/2022 02:01:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.99 on epoch=732
05/30/2022 02:01:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.03 on epoch=734
05/30/2022 02:01:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.96 on epoch=737
05/30/2022 02:01:40 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.13865730583589295 on epoch=737
05/30/2022 02:01:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/30/2022 02:01:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.99 on epoch=742
05/30/2022 02:01:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/30/2022 02:01:45 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/30/2022 02:01:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.84 on epoch=749
05/30/2022 02:01:47 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.10126582278481013 on epoch=749
05/30/2022 02:01:47 - INFO - __main__ - save last model!
05/30/2022 02:01:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:01:47 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:01:47 - INFO - __main__ - Printing 3 examples
05/30/2022 02:01:47 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:01:47 - INFO - __main__ - ['others']
05/30/2022 02:01:47 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:01:47 - INFO - __main__ - ['others']
05/30/2022 02:01:47 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:01:47 - INFO - __main__ - ['others']
05/30/2022 02:01:47 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:01:48 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:01:48 - INFO - __main__ - Printing 3 examples
05/30/2022 02:01:48 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 02:01:48 - INFO - __main__ - ['sad']
05/30/2022 02:01:48 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 02:01:48 - INFO - __main__ - ['sad']
05/30/2022 02:01:48 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 02:01:48 - INFO - __main__ - ['sad']
05/30/2022 02:01:48 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:01:48 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:01:48 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:01:48 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:01:48 - INFO - __main__ - Printing 3 examples
05/30/2022 02:01:48 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 02:01:48 - INFO - __main__ - ['sad']
05/30/2022 02:01:48 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 02:01:48 - INFO - __main__ - ['sad']
05/30/2022 02:01:48 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 02:01:48 - INFO - __main__ - ['sad']
05/30/2022 02:01:48 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:01:48 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:01:48 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:01:49 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:01:54 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:01:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:01:54 - INFO - __main__ - Starting training!
05/30/2022 02:01:55 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:02:38 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.4_8_predictions.txt
05/30/2022 02:02:38 - INFO - __main__ - Classification-F1 on test data: 0.0337
05/30/2022 02:02:38 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.23446115288220554, test_performance=0.0337088983910494
05/30/2022 02:02:38 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
05/30/2022 02:02:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:02:39 - INFO - __main__ - Printing 3 examples
05/30/2022 02:02:39 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 02:02:39 - INFO - __main__ - ['sad']
05/30/2022 02:02:39 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 02:02:39 - INFO - __main__ - ['sad']
05/30/2022 02:02:39 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 02:02:39 - INFO - __main__ - ['sad']
05/30/2022 02:02:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:02:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:02:39 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:02:39 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:02:39 - INFO - __main__ - Printing 3 examples
05/30/2022 02:02:39 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 02:02:39 - INFO - __main__ - ['sad']
05/30/2022 02:02:39 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 02:02:39 - INFO - __main__ - ['sad']
05/30/2022 02:02:39 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 02:02:39 - INFO - __main__ - ['sad']
05/30/2022 02:02:39 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:02:39 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:02:40 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:02:46 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:02:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:02:46 - INFO - __main__ - Starting training!
05/30/2022 02:02:47 - INFO - __main__ - Step 10 Global step 10 Train loss 6.61 on epoch=2
05/30/2022 02:02:49 - INFO - __main__ - Step 20 Global step 20 Train loss 6.48 on epoch=4
05/30/2022 02:02:50 - INFO - __main__ - Step 30 Global step 30 Train loss 6.42 on epoch=7
05/30/2022 02:02:51 - INFO - __main__ - Step 40 Global step 40 Train loss 6.05 on epoch=9
05/30/2022 02:02:52 - INFO - __main__ - Step 50 Global step 50 Train loss 5.98 on epoch=12
05/30/2022 02:02:55 - INFO - __main__ - Global step 50 Train loss 6.31 Classification-F1 0.0 on epoch=12
05/30/2022 02:02:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:02:56 - INFO - __main__ - Step 60 Global step 60 Train loss 6.02 on epoch=14
05/30/2022 02:02:58 - INFO - __main__ - Step 70 Global step 70 Train loss 5.82 on epoch=17
05/30/2022 02:02:59 - INFO - __main__ - Step 80 Global step 80 Train loss 5.73 on epoch=19
05/30/2022 02:03:00 - INFO - __main__ - Step 90 Global step 90 Train loss 5.63 on epoch=22
05/30/2022 02:03:02 - INFO - __main__ - Step 100 Global step 100 Train loss 5.56 on epoch=24
05/30/2022 02:03:03 - INFO - __main__ - Global step 100 Train loss 5.75 Classification-F1 0.0 on epoch=24
05/30/2022 02:03:05 - INFO - __main__ - Step 110 Global step 110 Train loss 5.49 on epoch=27
05/30/2022 02:03:06 - INFO - __main__ - Step 120 Global step 120 Train loss 5.30 on epoch=29
05/30/2022 02:03:07 - INFO - __main__ - Step 130 Global step 130 Train loss 5.17 on epoch=32
05/30/2022 02:03:08 - INFO - __main__ - Step 140 Global step 140 Train loss 5.05 on epoch=34
05/30/2022 02:03:10 - INFO - __main__ - Step 150 Global step 150 Train loss 5.09 on epoch=37
05/30/2022 02:03:11 - INFO - __main__ - Global step 150 Train loss 5.22 Classification-F1 0.0 on epoch=37
05/30/2022 02:03:12 - INFO - __main__ - Step 160 Global step 160 Train loss 4.78 on epoch=39
05/30/2022 02:03:14 - INFO - __main__ - Step 170 Global step 170 Train loss 4.75 on epoch=42
05/30/2022 02:03:15 - INFO - __main__ - Step 180 Global step 180 Train loss 4.64 on epoch=44
05/30/2022 02:03:16 - INFO - __main__ - Step 190 Global step 190 Train loss 4.70 on epoch=47
05/30/2022 02:03:17 - INFO - __main__ - Step 200 Global step 200 Train loss 4.39 on epoch=49
05/30/2022 02:03:19 - INFO - __main__ - Global step 200 Train loss 4.65 Classification-F1 0.0 on epoch=49
05/30/2022 02:03:20 - INFO - __main__ - Step 210 Global step 210 Train loss 4.32 on epoch=52
05/30/2022 02:03:21 - INFO - __main__ - Step 220 Global step 220 Train loss 4.16 on epoch=54
05/30/2022 02:03:22 - INFO - __main__ - Step 230 Global step 230 Train loss 4.15 on epoch=57
05/30/2022 02:03:24 - INFO - __main__ - Step 240 Global step 240 Train loss 4.09 on epoch=59
05/30/2022 02:03:25 - INFO - __main__ - Step 250 Global step 250 Train loss 3.98 on epoch=62
05/30/2022 02:03:25 - INFO - __main__ - Global step 250 Train loss 4.14 Classification-F1 0.19408369408369408 on epoch=62
05/30/2022 02:03:25 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.19408369408369408 on epoch=62, global_step=250
05/30/2022 02:03:27 - INFO - __main__ - Step 260 Global step 260 Train loss 3.87 on epoch=64
05/30/2022 02:03:28 - INFO - __main__ - Step 270 Global step 270 Train loss 3.81 on epoch=67
05/30/2022 02:03:29 - INFO - __main__ - Step 280 Global step 280 Train loss 3.62 on epoch=69
05/30/2022 02:03:30 - INFO - __main__ - Step 290 Global step 290 Train loss 3.67 on epoch=72
05/30/2022 02:03:32 - INFO - __main__ - Step 300 Global step 300 Train loss 3.40 on epoch=74
05/30/2022 02:03:32 - INFO - __main__ - Global step 300 Train loss 3.67 Classification-F1 0.15859154929577468 on epoch=74
05/30/2022 02:03:34 - INFO - __main__ - Step 310 Global step 310 Train loss 3.58 on epoch=77
05/30/2022 02:03:35 - INFO - __main__ - Step 320 Global step 320 Train loss 3.28 on epoch=79
05/30/2022 02:03:36 - INFO - __main__ - Step 330 Global step 330 Train loss 3.37 on epoch=82
05/30/2022 02:03:37 - INFO - __main__ - Step 340 Global step 340 Train loss 3.36 on epoch=84
05/30/2022 02:03:39 - INFO - __main__ - Step 350 Global step 350 Train loss 3.37 on epoch=87
05/30/2022 02:03:39 - INFO - __main__ - Global step 350 Train loss 3.39 Classification-F1 0.20606060606060606 on epoch=87
05/30/2022 02:03:39 - INFO - __main__ - Saving model with best Classification-F1: 0.19408369408369408 -> 0.20606060606060606 on epoch=87, global_step=350
05/30/2022 02:03:40 - INFO - __main__ - Step 360 Global step 360 Train loss 3.14 on epoch=89
05/30/2022 02:03:42 - INFO - __main__ - Step 370 Global step 370 Train loss 3.24 on epoch=92
05/30/2022 02:03:43 - INFO - __main__ - Step 380 Global step 380 Train loss 3.08 on epoch=94
05/30/2022 02:03:44 - INFO - __main__ - Step 390 Global step 390 Train loss 3.07 on epoch=97
05/30/2022 02:03:45 - INFO - __main__ - Step 400 Global step 400 Train loss 2.91 on epoch=99
05/30/2022 02:03:46 - INFO - __main__ - Global step 400 Train loss 3.09 Classification-F1 0.10126582278481013 on epoch=99
05/30/2022 02:03:47 - INFO - __main__ - Step 410 Global step 410 Train loss 3.06 on epoch=102
05/30/2022 02:03:48 - INFO - __main__ - Step 420 Global step 420 Train loss 3.05 on epoch=104
05/30/2022 02:03:50 - INFO - __main__ - Step 430 Global step 430 Train loss 2.94 on epoch=107
05/30/2022 02:03:51 - INFO - __main__ - Step 440 Global step 440 Train loss 2.66 on epoch=109
05/30/2022 02:03:52 - INFO - __main__ - Step 450 Global step 450 Train loss 2.83 on epoch=112
05/30/2022 02:03:53 - INFO - __main__ - Global step 450 Train loss 2.91 Classification-F1 0.12447885646217988 on epoch=112
05/30/2022 02:03:54 - INFO - __main__ - Step 460 Global step 460 Train loss 2.68 on epoch=114
05/30/2022 02:03:55 - INFO - __main__ - Step 470 Global step 470 Train loss 2.75 on epoch=117
05/30/2022 02:03:57 - INFO - __main__ - Step 480 Global step 480 Train loss 2.54 on epoch=119
05/30/2022 02:03:58 - INFO - __main__ - Step 490 Global step 490 Train loss 2.73 on epoch=122
05/30/2022 02:03:59 - INFO - __main__ - Step 500 Global step 500 Train loss 2.51 on epoch=124
05/30/2022 02:04:00 - INFO - __main__ - Global step 500 Train loss 2.64 Classification-F1 0.1 on epoch=124
05/30/2022 02:04:01 - INFO - __main__ - Step 510 Global step 510 Train loss 2.47 on epoch=127
05/30/2022 02:04:02 - INFO - __main__ - Step 520 Global step 520 Train loss 2.57 on epoch=129
05/30/2022 02:04:03 - INFO - __main__ - Step 530 Global step 530 Train loss 2.47 on epoch=132
05/30/2022 02:04:05 - INFO - __main__ - Step 540 Global step 540 Train loss 2.34 on epoch=134
05/30/2022 02:04:06 - INFO - __main__ - Step 550 Global step 550 Train loss 2.45 on epoch=137
05/30/2022 02:04:06 - INFO - __main__ - Global step 550 Train loss 2.46 Classification-F1 0.12368421052631579 on epoch=137
05/30/2022 02:04:08 - INFO - __main__ - Step 560 Global step 560 Train loss 2.28 on epoch=139
05/30/2022 02:04:09 - INFO - __main__ - Step 570 Global step 570 Train loss 2.35 on epoch=142
05/30/2022 02:04:10 - INFO - __main__ - Step 580 Global step 580 Train loss 2.23 on epoch=144
05/30/2022 02:04:11 - INFO - __main__ - Step 590 Global step 590 Train loss 2.30 on epoch=147
05/30/2022 02:04:13 - INFO - __main__ - Step 600 Global step 600 Train loss 2.18 on epoch=149
05/30/2022 02:04:13 - INFO - __main__ - Global step 600 Train loss 2.27 Classification-F1 0.10126582278481013 on epoch=149
05/30/2022 02:04:15 - INFO - __main__ - Step 610 Global step 610 Train loss 2.21 on epoch=152
05/30/2022 02:04:16 - INFO - __main__ - Step 620 Global step 620 Train loss 2.03 on epoch=154
05/30/2022 02:04:17 - INFO - __main__ - Step 630 Global step 630 Train loss 2.17 on epoch=157
05/30/2022 02:04:18 - INFO - __main__ - Step 640 Global step 640 Train loss 1.90 on epoch=159
05/30/2022 02:04:20 - INFO - __main__ - Step 650 Global step 650 Train loss 1.91 on epoch=162
05/30/2022 02:04:20 - INFO - __main__ - Global step 650 Train loss 2.05 Classification-F1 0.1402116402116402 on epoch=162
05/30/2022 02:04:21 - INFO - __main__ - Step 660 Global step 660 Train loss 1.83 on epoch=164
05/30/2022 02:04:23 - INFO - __main__ - Step 670 Global step 670 Train loss 1.91 on epoch=167
05/30/2022 02:04:24 - INFO - __main__ - Step 680 Global step 680 Train loss 1.77 on epoch=169
05/30/2022 02:04:25 - INFO - __main__ - Step 690 Global step 690 Train loss 1.84 on epoch=172
05/30/2022 02:04:26 - INFO - __main__ - Step 700 Global step 700 Train loss 1.77 on epoch=174
05/30/2022 02:04:27 - INFO - __main__ - Global step 700 Train loss 1.82 Classification-F1 0.10126582278481013 on epoch=174
05/30/2022 02:04:28 - INFO - __main__ - Step 710 Global step 710 Train loss 1.65 on epoch=177
05/30/2022 02:04:29 - INFO - __main__ - Step 720 Global step 720 Train loss 1.68 on epoch=179
05/30/2022 02:04:31 - INFO - __main__ - Step 730 Global step 730 Train loss 1.73 on epoch=182
05/30/2022 02:04:32 - INFO - __main__ - Step 740 Global step 740 Train loss 1.72 on epoch=184
05/30/2022 02:04:33 - INFO - __main__ - Step 750 Global step 750 Train loss 1.71 on epoch=187
05/30/2022 02:04:34 - INFO - __main__ - Global step 750 Train loss 1.70 Classification-F1 0.16666666666666666 on epoch=187
05/30/2022 02:04:35 - INFO - __main__ - Step 760 Global step 760 Train loss 1.69 on epoch=189
05/30/2022 02:04:36 - INFO - __main__ - Step 770 Global step 770 Train loss 1.65 on epoch=192
05/30/2022 02:04:37 - INFO - __main__ - Step 780 Global step 780 Train loss 1.70 on epoch=194
05/30/2022 02:04:39 - INFO - __main__ - Step 790 Global step 790 Train loss 1.62 on epoch=197
05/30/2022 02:04:40 - INFO - __main__ - Step 800 Global step 800 Train loss 1.44 on epoch=199
05/30/2022 02:04:40 - INFO - __main__ - Global step 800 Train loss 1.62 Classification-F1 0.17979127134724857 on epoch=199
05/30/2022 02:04:42 - INFO - __main__ - Step 810 Global step 810 Train loss 1.67 on epoch=202
05/30/2022 02:04:43 - INFO - __main__ - Step 820 Global step 820 Train loss 1.53 on epoch=204
05/30/2022 02:04:44 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/30/2022 02:04:46 - INFO - __main__ - Step 840 Global step 840 Train loss 1.41 on epoch=209
05/30/2022 02:04:47 - INFO - __main__ - Step 850 Global step 850 Train loss 1.58 on epoch=212
05/30/2022 02:04:47 - INFO - __main__ - Global step 850 Train loss 1.57 Classification-F1 0.20833333333333334 on epoch=212
05/30/2022 02:04:47 - INFO - __main__ - Saving model with best Classification-F1: 0.20606060606060606 -> 0.20833333333333334 on epoch=212, global_step=850
05/30/2022 02:04:49 - INFO - __main__ - Step 860 Global step 860 Train loss 1.51 on epoch=214
05/30/2022 02:04:50 - INFO - __main__ - Step 870 Global step 870 Train loss 1.54 on epoch=217
05/30/2022 02:04:51 - INFO - __main__ - Step 880 Global step 880 Train loss 1.55 on epoch=219
05/30/2022 02:04:52 - INFO - __main__ - Step 890 Global step 890 Train loss 1.51 on epoch=222
05/30/2022 02:04:54 - INFO - __main__ - Step 900 Global step 900 Train loss 1.40 on epoch=224
05/30/2022 02:04:54 - INFO - __main__ - Global step 900 Train loss 1.50 Classification-F1 0.1 on epoch=224
05/30/2022 02:04:55 - INFO - __main__ - Step 910 Global step 910 Train loss 1.50 on epoch=227
05/30/2022 02:04:57 - INFO - __main__ - Step 920 Global step 920 Train loss 1.46 on epoch=229
05/30/2022 02:04:58 - INFO - __main__ - Step 930 Global step 930 Train loss 1.43 on epoch=232
05/30/2022 02:04:59 - INFO - __main__ - Step 940 Global step 940 Train loss 1.40 on epoch=234
05/30/2022 02:05:00 - INFO - __main__ - Step 950 Global step 950 Train loss 1.42 on epoch=237
05/30/2022 02:05:01 - INFO - __main__ - Global step 950 Train loss 1.44 Classification-F1 0.16953316953316955 on epoch=237
05/30/2022 02:05:02 - INFO - __main__ - Step 960 Global step 960 Train loss 1.48 on epoch=239
05/30/2022 02:05:03 - INFO - __main__ - Step 970 Global step 970 Train loss 1.27 on epoch=242
05/30/2022 02:05:05 - INFO - __main__ - Step 980 Global step 980 Train loss 1.39 on epoch=244
05/30/2022 02:05:06 - INFO - __main__ - Step 990 Global step 990 Train loss 1.49 on epoch=247
05/30/2022 02:05:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.36 on epoch=249
05/30/2022 02:05:08 - INFO - __main__ - Global step 1000 Train loss 1.40 Classification-F1 0.17809523809523808 on epoch=249
05/30/2022 02:05:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=252
05/30/2022 02:05:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.35 on epoch=254
05/30/2022 02:05:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.39 on epoch=257
05/30/2022 02:05:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.39 on epoch=259
05/30/2022 02:05:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.29 on epoch=262
05/30/2022 02:05:15 - INFO - __main__ - Global step 1050 Train loss 1.37 Classification-F1 0.17752100840336132 on epoch=262
05/30/2022 02:05:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.18 on epoch=264
05/30/2022 02:05:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.51 on epoch=267
05/30/2022 02:05:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/30/2022 02:05:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.39 on epoch=272
05/30/2022 02:05:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.22 on epoch=274
05/30/2022 02:05:21 - INFO - __main__ - Global step 1100 Train loss 1.30 Classification-F1 0.13859154929577466 on epoch=274
05/30/2022 02:05:23 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.20 on epoch=277
05/30/2022 02:05:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.35 on epoch=279
05/30/2022 02:05:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.24 on epoch=282
05/30/2022 02:05:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=284
05/30/2022 02:05:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.26 on epoch=287
05/30/2022 02:05:28 - INFO - __main__ - Global step 1150 Train loss 1.26 Classification-F1 0.16110780226325194 on epoch=287
05/30/2022 02:05:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.33 on epoch=289
05/30/2022 02:05:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.24 on epoch=292
05/30/2022 02:05:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.14 on epoch=294
05/30/2022 02:05:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.24 on epoch=297
05/30/2022 02:05:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.41 on epoch=299
05/30/2022 02:05:35 - INFO - __main__ - Global step 1200 Train loss 1.27 Classification-F1 0.11208791208791208 on epoch=299
05/30/2022 02:05:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.24 on epoch=302
05/30/2022 02:05:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.21 on epoch=304
05/30/2022 02:05:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.41 on epoch=307
05/30/2022 02:05:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.08 on epoch=309
05/30/2022 02:05:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.33 on epoch=312
05/30/2022 02:05:42 - INFO - __main__ - Global step 1250 Train loss 1.25 Classification-F1 0.13130252100840337 on epoch=312
05/30/2022 02:05:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.29 on epoch=314
05/30/2022 02:05:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=317
05/30/2022 02:05:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.37 on epoch=319
05/30/2022 02:05:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.11 on epoch=322
05/30/2022 02:05:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.09 on epoch=324
05/30/2022 02:05:49 - INFO - __main__ - Global step 1300 Train loss 1.21 Classification-F1 0.14560439560439564 on epoch=324
05/30/2022 02:05:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.11 on epoch=327
05/30/2022 02:05:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.12 on epoch=329
05/30/2022 02:05:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.25 on epoch=332
05/30/2022 02:05:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.31 on epoch=334
05/30/2022 02:05:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.18 on epoch=337
05/30/2022 02:05:56 - INFO - __main__ - Global step 1350 Train loss 1.19 Classification-F1 0.14107142857142857 on epoch=337
05/30/2022 02:05:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/30/2022 02:05:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.13 on epoch=342
05/30/2022 02:05:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.14 on epoch=344
05/30/2022 02:06:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.26 on epoch=347
05/30/2022 02:06:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/30/2022 02:06:02 - INFO - __main__ - Global step 1400 Train loss 1.18 Classification-F1 0.1 on epoch=349
05/30/2022 02:06:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.18 on epoch=352
05/30/2022 02:06:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.19 on epoch=354
05/30/2022 02:06:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.18 on epoch=357
05/30/2022 02:06:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.22 on epoch=359
05/30/2022 02:06:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.08 on epoch=362
05/30/2022 02:06:09 - INFO - __main__ - Global step 1450 Train loss 1.17 Classification-F1 0.1581196581196581 on epoch=362
05/30/2022 02:06:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.08 on epoch=364
05/30/2022 02:06:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.23 on epoch=367
05/30/2022 02:06:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.09 on epoch=369
05/30/2022 02:06:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.18 on epoch=372
05/30/2022 02:06:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.28 on epoch=374
05/30/2022 02:06:16 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=374
05/30/2022 02:06:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.14 on epoch=377
05/30/2022 02:06:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.25 on epoch=379
05/30/2022 02:06:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.21 on epoch=382
05/30/2022 02:06:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.26 on epoch=384
05/30/2022 02:06:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
05/30/2022 02:06:23 - INFO - __main__ - Global step 1550 Train loss 1.22 Classification-F1 0.1318181818181818 on epoch=387
05/30/2022 02:06:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.05 on epoch=389
05/30/2022 02:06:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.25 on epoch=392
05/30/2022 02:06:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.27 on epoch=394
05/30/2022 02:06:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.07 on epoch=397
05/30/2022 02:06:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.22 on epoch=399
05/30/2022 02:06:30 - INFO - __main__ - Global step 1600 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=399
05/30/2022 02:06:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.11 on epoch=402
05/30/2022 02:06:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.05 on epoch=404
05/30/2022 02:06:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.20 on epoch=407
05/30/2022 02:06:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.03 on epoch=409
05/30/2022 02:06:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.13 on epoch=412
05/30/2022 02:06:37 - INFO - __main__ - Global step 1650 Train loss 1.10 Classification-F1 0.1 on epoch=412
05/30/2022 02:06:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.10 on epoch=414
05/30/2022 02:06:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.19 on epoch=417
05/30/2022 02:06:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.12 on epoch=419
05/30/2022 02:06:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.22 on epoch=422
05/30/2022 02:06:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.17 on epoch=424
05/30/2022 02:06:44 - INFO - __main__ - Global step 1700 Train loss 1.16 Classification-F1 0.1 on epoch=424
05/30/2022 02:06:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.06 on epoch=427
05/30/2022 02:06:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.02 on epoch=429
05/30/2022 02:06:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.02 on epoch=432
05/30/2022 02:06:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.13 on epoch=434
05/30/2022 02:06:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.08 on epoch=437
05/30/2022 02:06:50 - INFO - __main__ - Global step 1750 Train loss 1.06 Classification-F1 0.10126582278481013 on epoch=437
05/30/2022 02:06:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.04 on epoch=439
05/30/2022 02:06:53 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.14 on epoch=442
05/30/2022 02:06:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.31 on epoch=444
05/30/2022 02:06:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.17 on epoch=447
05/30/2022 02:06:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=449
05/30/2022 02:06:57 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.1 on epoch=449
05/30/2022 02:06:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.07 on epoch=452
05/30/2022 02:07:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.06 on epoch=454
05/30/2022 02:07:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.11 on epoch=457
05/30/2022 02:07:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.18 on epoch=459
05/30/2022 02:07:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.00 on epoch=462
05/30/2022 02:07:04 - INFO - __main__ - Global step 1850 Train loss 1.08 Classification-F1 0.1 on epoch=462
05/30/2022 02:07:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.07 on epoch=464
05/30/2022 02:07:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.13 on epoch=467
05/30/2022 02:07:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.04 on epoch=469
05/30/2022 02:07:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
05/30/2022 02:07:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/30/2022 02:07:11 - INFO - __main__ - Global step 1900 Train loss 1.08 Classification-F1 0.203125 on epoch=474
05/30/2022 02:07:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/30/2022 02:07:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.03 on epoch=479
05/30/2022 02:07:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
05/30/2022 02:07:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=484
05/30/2022 02:07:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.09 on epoch=487
05/30/2022 02:07:18 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.18847006651884698 on epoch=487
05/30/2022 02:07:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.07 on epoch=489
05/30/2022 02:07:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/30/2022 02:07:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.03 on epoch=494
05/30/2022 02:07:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.10 on epoch=497
05/30/2022 02:07:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.97 on epoch=499
05/30/2022 02:07:25 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.16433566433566432 on epoch=499
05/30/2022 02:07:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.99 on epoch=502
05/30/2022 02:07:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.10 on epoch=504
05/30/2022 02:07:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.05 on epoch=507
05/30/2022 02:07:30 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.97 on epoch=509
05/30/2022 02:07:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.00 on epoch=512
05/30/2022 02:07:32 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.12407862407862408 on epoch=512
05/30/2022 02:07:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
05/30/2022 02:07:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=517
05/30/2022 02:07:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.03 on epoch=519
05/30/2022 02:07:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
05/30/2022 02:07:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.99 on epoch=524
05/30/2022 02:07:39 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.18172268907563027 on epoch=524
05/30/2022 02:07:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.09 on epoch=527
05/30/2022 02:07:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.01 on epoch=529
05/30/2022 02:07:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/30/2022 02:07:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.95 on epoch=534
05/30/2022 02:07:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.93 on epoch=537
05/30/2022 02:07:46 - INFO - __main__ - Global step 2150 Train loss 0.99 Classification-F1 0.21596452328159646 on epoch=537
05/30/2022 02:07:46 - INFO - __main__ - Saving model with best Classification-F1: 0.20833333333333334 -> 0.21596452328159646 on epoch=537, global_step=2150
05/30/2022 02:07:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.11 on epoch=539
05/30/2022 02:07:48 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.14 on epoch=542
05/30/2022 02:07:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/30/2022 02:07:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.11 on epoch=547
05/30/2022 02:07:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.08 on epoch=549
05/30/2022 02:07:53 - INFO - __main__ - Global step 2200 Train loss 1.09 Classification-F1 0.1642512077294686 on epoch=549
05/30/2022 02:07:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.06 on epoch=552
05/30/2022 02:07:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/30/2022 02:07:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.09 on epoch=557
05/30/2022 02:07:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.04 on epoch=559
05/30/2022 02:07:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/30/2022 02:07:59 - INFO - __main__ - Global step 2250 Train loss 1.06 Classification-F1 0.21323866239120476 on epoch=562
05/30/2022 02:08:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.06 on epoch=564
05/30/2022 02:08:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.02 on epoch=567
05/30/2022 02:08:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.06 on epoch=569
05/30/2022 02:08:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.01 on epoch=572
05/30/2022 02:08:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/30/2022 02:08:06 - INFO - __main__ - Global step 2300 Train loss 1.02 Classification-F1 0.11923076923076922 on epoch=574
05/30/2022 02:08:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.03 on epoch=577
05/30/2022 02:08:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.95 on epoch=579
05/30/2022 02:08:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=582
05/30/2022 02:08:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/30/2022 02:08:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=587
05/30/2022 02:08:13 - INFO - __main__ - Global step 2350 Train loss 0.98 Classification-F1 0.15735226752175901 on epoch=587
05/30/2022 02:08:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.08 on epoch=589
05/30/2022 02:08:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.04 on epoch=592
05/30/2022 02:08:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.00 on epoch=594
05/30/2022 02:08:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
05/30/2022 02:08:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/30/2022 02:08:20 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.16608695652173913 on epoch=599
05/30/2022 02:08:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.05 on epoch=602
05/30/2022 02:08:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.99 on epoch=604
05/30/2022 02:08:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/30/2022 02:08:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.99 on epoch=609
05/30/2022 02:08:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.11 on epoch=612
05/30/2022 02:08:27 - INFO - __main__ - Global step 2450 Train loss 1.04 Classification-F1 0.10256410256410256 on epoch=612
05/30/2022 02:08:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.08 on epoch=614
05/30/2022 02:08:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.05 on epoch=617
05/30/2022 02:08:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/30/2022 02:08:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.02 on epoch=622
05/30/2022 02:08:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.02 on epoch=624
05/30/2022 02:08:33 - INFO - __main__ - Global step 2500 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=624
05/30/2022 02:08:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.00 on epoch=627
05/30/2022 02:08:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.98 on epoch=629
05/30/2022 02:08:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
05/30/2022 02:08:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.99 on epoch=634
05/30/2022 02:08:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.07 on epoch=637
05/30/2022 02:08:40 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.14947089947089948 on epoch=637
05/30/2022 02:08:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
05/30/2022 02:08:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.96 on epoch=642
05/30/2022 02:08:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.94 on epoch=644
05/30/2022 02:08:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=647
05/30/2022 02:08:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.85 on epoch=649
05/30/2022 02:08:47 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.22916666666666669 on epoch=649
05/30/2022 02:08:47 - INFO - __main__ - Saving model with best Classification-F1: 0.21596452328159646 -> 0.22916666666666669 on epoch=649, global_step=2600
05/30/2022 02:08:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.11 on epoch=652
05/30/2022 02:08:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.95 on epoch=654
05/30/2022 02:08:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=657
05/30/2022 02:08:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/30/2022 02:08:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.09 on epoch=662
05/30/2022 02:08:54 - INFO - __main__ - Global step 2650 Train loss 1.03 Classification-F1 0.14242424242424243 on epoch=662
05/30/2022 02:08:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.95 on epoch=664
05/30/2022 02:08:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.97 on epoch=667
05/30/2022 02:08:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.92 on epoch=669
05/30/2022 02:08:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.97 on epoch=672
05/30/2022 02:09:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.91 on epoch=674
05/30/2022 02:09:01 - INFO - __main__ - Global step 2700 Train loss 0.94 Classification-F1 0.1851689337428697 on epoch=674
05/30/2022 02:09:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.98 on epoch=677
05/30/2022 02:09:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.99 on epoch=679
05/30/2022 02:09:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.92 on epoch=682
05/30/2022 02:09:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.95 on epoch=684
05/30/2022 02:09:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.01 on epoch=687
05/30/2022 02:09:08 - INFO - __main__ - Global step 2750 Train loss 0.97 Classification-F1 0.19869565217391305 on epoch=687
05/30/2022 02:09:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=689
05/30/2022 02:09:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.00 on epoch=692
05/30/2022 02:09:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.97 on epoch=694
05/30/2022 02:09:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.99 on epoch=697
05/30/2022 02:09:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.98 on epoch=699
05/30/2022 02:09:14 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.2300653594771242 on epoch=699
05/30/2022 02:09:14 - INFO - __main__ - Saving model with best Classification-F1: 0.22916666666666669 -> 0.2300653594771242 on epoch=699, global_step=2800
05/30/2022 02:09:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.88 on epoch=702
05/30/2022 02:09:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
05/30/2022 02:09:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.00 on epoch=707
05/30/2022 02:09:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/30/2022 02:09:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.97 on epoch=712
05/30/2022 02:09:21 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.140625 on epoch=712
05/30/2022 02:09:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/30/2022 02:09:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.92 on epoch=717
05/30/2022 02:09:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.97 on epoch=719
05/30/2022 02:09:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.03 on epoch=722
05/30/2022 02:09:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.99 on epoch=724
05/30/2022 02:09:28 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.19735128093790708 on epoch=724
05/30/2022 02:09:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.91 on epoch=727
05/30/2022 02:09:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.99 on epoch=729
05/30/2022 02:09:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.05 on epoch=732
05/30/2022 02:09:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
05/30/2022 02:09:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.06 on epoch=737
05/30/2022 02:09:35 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.1056338028169014 on epoch=737
05/30/2022 02:09:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/30/2022 02:09:37 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/30/2022 02:09:39 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
05/30/2022 02:09:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.94 on epoch=747
05/30/2022 02:09:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
05/30/2022 02:09:42 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.17344312918167784 on epoch=749
05/30/2022 02:09:42 - INFO - __main__ - save last model!
05/30/2022 02:09:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:09:42 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:09:42 - INFO - __main__ - Printing 3 examples
05/30/2022 02:09:42 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:09:42 - INFO - __main__ - ['others']
05/30/2022 02:09:42 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:09:42 - INFO - __main__ - ['others']
05/30/2022 02:09:42 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:09:42 - INFO - __main__ - ['others']
05/30/2022 02:09:42 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:09:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:09:42 - INFO - __main__ - Printing 3 examples
05/30/2022 02:09:42 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 02:09:42 - INFO - __main__ - ['sad']
05/30/2022 02:09:42 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 02:09:42 - INFO - __main__ - ['sad']
05/30/2022 02:09:42 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 02:09:42 - INFO - __main__ - ['sad']
05/30/2022 02:09:42 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:09:42 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:09:42 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:09:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:09:42 - INFO - __main__ - Printing 3 examples
05/30/2022 02:09:42 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 02:09:42 - INFO - __main__ - ['sad']
05/30/2022 02:09:42 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 02:09:42 - INFO - __main__ - ['sad']
05/30/2022 02:09:42 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 02:09:42 - INFO - __main__ - ['sad']
05/30/2022 02:09:42 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:09:42 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:09:43 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:09:44 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:09:48 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:09:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:09:48 - INFO - __main__ - Starting training!
05/30/2022 02:09:49 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:10:33 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.3_8_predictions.txt
05/30/2022 02:10:33 - INFO - __main__ - Classification-F1 on test data: 0.0488
05/30/2022 02:10:33 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.2300653594771242, test_performance=0.048775773564390404
05/30/2022 02:10:33 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
05/30/2022 02:10:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:10:34 - INFO - __main__ - Printing 3 examples
05/30/2022 02:10:34 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/30/2022 02:10:34 - INFO - __main__ - ['sad']
05/30/2022 02:10:34 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/30/2022 02:10:34 - INFO - __main__ - ['sad']
05/30/2022 02:10:34 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/30/2022 02:10:34 - INFO - __main__ - ['sad']
05/30/2022 02:10:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:10:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:10:34 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:10:34 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:10:34 - INFO - __main__ - Printing 3 examples
05/30/2022 02:10:34 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
05/30/2022 02:10:34 - INFO - __main__ - ['sad']
05/30/2022 02:10:34 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
05/30/2022 02:10:34 - INFO - __main__ - ['sad']
05/30/2022 02:10:34 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
05/30/2022 02:10:34 - INFO - __main__ - ['sad']
05/30/2022 02:10:34 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:10:34 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:10:34 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:10:39 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:10:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:10:40 - INFO - __main__ - Starting training!
05/30/2022 02:10:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.63 on epoch=2
05/30/2022 02:10:42 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/30/2022 02:10:44 - INFO - __main__ - Step 30 Global step 30 Train loss 6.47 on epoch=7
05/30/2022 02:10:45 - INFO - __main__ - Step 40 Global step 40 Train loss 6.37 on epoch=9
05/30/2022 02:10:46 - INFO - __main__ - Step 50 Global step 50 Train loss 6.39 on epoch=12
05/30/2022 02:10:54 - INFO - __main__ - Global step 50 Train loss 6.49 Classification-F1 0.0 on epoch=12
05/30/2022 02:10:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:10:55 - INFO - __main__ - Step 60 Global step 60 Train loss 6.23 on epoch=14
05/30/2022 02:10:57 - INFO - __main__ - Step 70 Global step 70 Train loss 6.18 on epoch=17
05/30/2022 02:10:58 - INFO - __main__ - Step 80 Global step 80 Train loss 6.03 on epoch=19
05/30/2022 02:10:59 - INFO - __main__ - Step 90 Global step 90 Train loss 5.92 on epoch=22
05/30/2022 02:11:00 - INFO - __main__ - Step 100 Global step 100 Train loss 5.77 on epoch=24
05/30/2022 02:11:04 - INFO - __main__ - Global step 100 Train loss 6.03 Classification-F1 0.0 on epoch=24
05/30/2022 02:11:05 - INFO - __main__ - Step 110 Global step 110 Train loss 5.71 on epoch=27
05/30/2022 02:11:07 - INFO - __main__ - Step 120 Global step 120 Train loss 5.59 on epoch=29
05/30/2022 02:11:08 - INFO - __main__ - Step 130 Global step 130 Train loss 5.60 on epoch=32
05/30/2022 02:11:09 - INFO - __main__ - Step 140 Global step 140 Train loss 5.30 on epoch=34
05/30/2022 02:11:10 - INFO - __main__ - Step 150 Global step 150 Train loss 5.41 on epoch=37
05/30/2022 02:11:13 - INFO - __main__ - Global step 150 Train loss 5.52 Classification-F1 0.0 on epoch=37
05/30/2022 02:11:14 - INFO - __main__ - Step 160 Global step 160 Train loss 5.11 on epoch=39
05/30/2022 02:11:15 - INFO - __main__ - Step 170 Global step 170 Train loss 5.18 on epoch=42
05/30/2022 02:11:17 - INFO - __main__ - Step 180 Global step 180 Train loss 4.92 on epoch=44
05/30/2022 02:11:18 - INFO - __main__ - Step 190 Global step 190 Train loss 4.86 on epoch=47
05/30/2022 02:11:19 - INFO - __main__ - Step 200 Global step 200 Train loss 4.88 on epoch=49
05/30/2022 02:11:21 - INFO - __main__ - Global step 200 Train loss 4.99 Classification-F1 0.0 on epoch=49
05/30/2022 02:11:22 - INFO - __main__ - Step 210 Global step 210 Train loss 4.57 on epoch=52
05/30/2022 02:11:23 - INFO - __main__ - Step 220 Global step 220 Train loss 4.41 on epoch=54
05/30/2022 02:11:24 - INFO - __main__ - Step 230 Global step 230 Train loss 4.41 on epoch=57
05/30/2022 02:11:26 - INFO - __main__ - Step 240 Global step 240 Train loss 4.40 on epoch=59
05/30/2022 02:11:27 - INFO - __main__ - Step 250 Global step 250 Train loss 4.29 on epoch=62
05/30/2022 02:11:28 - INFO - __main__ - Global step 250 Train loss 4.41 Classification-F1 0.10126582278481013 on epoch=62
05/30/2022 02:11:28 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.10126582278481013 on epoch=62, global_step=250
05/30/2022 02:11:30 - INFO - __main__ - Step 260 Global step 260 Train loss 4.02 on epoch=64
05/30/2022 02:11:31 - INFO - __main__ - Step 270 Global step 270 Train loss 4.14 on epoch=67
05/30/2022 02:11:32 - INFO - __main__ - Step 280 Global step 280 Train loss 3.83 on epoch=69
05/30/2022 02:11:33 - INFO - __main__ - Step 290 Global step 290 Train loss 3.90 on epoch=72
05/30/2022 02:11:35 - INFO - __main__ - Step 300 Global step 300 Train loss 3.79 on epoch=74
05/30/2022 02:11:35 - INFO - __main__ - Global step 300 Train loss 3.94 Classification-F1 0.11710526315789474 on epoch=74
05/30/2022 02:11:35 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.11710526315789474 on epoch=74, global_step=300
05/30/2022 02:11:36 - INFO - __main__ - Step 310 Global step 310 Train loss 3.87 on epoch=77
05/30/2022 02:11:38 - INFO - __main__ - Step 320 Global step 320 Train loss 3.65 on epoch=79
05/30/2022 02:11:39 - INFO - __main__ - Step 330 Global step 330 Train loss 3.66 on epoch=82
05/30/2022 02:11:40 - INFO - __main__ - Step 340 Global step 340 Train loss 3.60 on epoch=84
05/30/2022 02:11:41 - INFO - __main__ - Step 350 Global step 350 Train loss 3.44 on epoch=87
05/30/2022 02:11:42 - INFO - __main__ - Global step 350 Train loss 3.64 Classification-F1 0.16277641277641278 on epoch=87
05/30/2022 02:11:42 - INFO - __main__ - Saving model with best Classification-F1: 0.11710526315789474 -> 0.16277641277641278 on epoch=87, global_step=350
05/30/2022 02:11:43 - INFO - __main__ - Step 360 Global step 360 Train loss 3.42 on epoch=89
05/30/2022 02:11:45 - INFO - __main__ - Step 370 Global step 370 Train loss 3.49 on epoch=92
05/30/2022 02:11:46 - INFO - __main__ - Step 380 Global step 380 Train loss 3.31 on epoch=94
05/30/2022 02:11:47 - INFO - __main__ - Step 390 Global step 390 Train loss 3.42 on epoch=97
05/30/2022 02:11:48 - INFO - __main__ - Step 400 Global step 400 Train loss 3.17 on epoch=99
05/30/2022 02:11:49 - INFO - __main__ - Global step 400 Train loss 3.36 Classification-F1 0.15498891352549887 on epoch=99
05/30/2022 02:11:50 - INFO - __main__ - Step 410 Global step 410 Train loss 3.33 on epoch=102
05/30/2022 02:11:51 - INFO - __main__ - Step 420 Global step 420 Train loss 3.19 on epoch=104
05/30/2022 02:11:53 - INFO - __main__ - Step 430 Global step 430 Train loss 3.25 on epoch=107
05/30/2022 02:11:54 - INFO - __main__ - Step 440 Global step 440 Train loss 3.13 on epoch=109
05/30/2022 02:11:55 - INFO - __main__ - Step 450 Global step 450 Train loss 3.04 on epoch=112
05/30/2022 02:11:56 - INFO - __main__ - Global step 450 Train loss 3.19 Classification-F1 0.1 on epoch=112
05/30/2022 02:11:57 - INFO - __main__ - Step 460 Global step 460 Train loss 2.99 on epoch=114
05/30/2022 02:11:58 - INFO - __main__ - Step 470 Global step 470 Train loss 3.13 on epoch=117
05/30/2022 02:12:00 - INFO - __main__ - Step 480 Global step 480 Train loss 2.92 on epoch=119
05/30/2022 02:12:01 - INFO - __main__ - Step 490 Global step 490 Train loss 3.01 on epoch=122
05/30/2022 02:12:02 - INFO - __main__ - Step 500 Global step 500 Train loss 2.85 on epoch=124
05/30/2022 02:12:03 - INFO - __main__ - Global step 500 Train loss 2.98 Classification-F1 0.10126582278481013 on epoch=124
05/30/2022 02:12:04 - INFO - __main__ - Step 510 Global step 510 Train loss 2.89 on epoch=127
05/30/2022 02:12:05 - INFO - __main__ - Step 520 Global step 520 Train loss 2.62 on epoch=129
05/30/2022 02:12:06 - INFO - __main__ - Step 530 Global step 530 Train loss 2.80 on epoch=132
05/30/2022 02:12:08 - INFO - __main__ - Step 540 Global step 540 Train loss 2.81 on epoch=134
05/30/2022 02:12:09 - INFO - __main__ - Step 550 Global step 550 Train loss 2.61 on epoch=137
05/30/2022 02:12:09 - INFO - __main__ - Global step 550 Train loss 2.75 Classification-F1 0.1 on epoch=137
05/30/2022 02:12:11 - INFO - __main__ - Step 560 Global step 560 Train loss 2.60 on epoch=139
05/30/2022 02:12:12 - INFO - __main__ - Step 570 Global step 570 Train loss 2.73 on epoch=142
05/30/2022 02:12:13 - INFO - __main__ - Step 580 Global step 580 Train loss 2.42 on epoch=144
05/30/2022 02:12:15 - INFO - __main__ - Step 590 Global step 590 Train loss 2.67 on epoch=147
05/30/2022 02:12:16 - INFO - __main__ - Step 600 Global step 600 Train loss 2.49 on epoch=149
05/30/2022 02:12:16 - INFO - __main__ - Global step 600 Train loss 2.58 Classification-F1 0.1 on epoch=149
05/30/2022 02:12:18 - INFO - __main__ - Step 610 Global step 610 Train loss 2.47 on epoch=152
05/30/2022 02:12:19 - INFO - __main__ - Step 620 Global step 620 Train loss 2.51 on epoch=154
05/30/2022 02:12:20 - INFO - __main__ - Step 630 Global step 630 Train loss 2.62 on epoch=157
05/30/2022 02:12:21 - INFO - __main__ - Step 640 Global step 640 Train loss 2.37 on epoch=159
05/30/2022 02:12:23 - INFO - __main__ - Step 650 Global step 650 Train loss 2.42 on epoch=162
05/30/2022 02:12:23 - INFO - __main__ - Global step 650 Train loss 2.48 Classification-F1 0.09493670886075949 on epoch=162
05/30/2022 02:12:24 - INFO - __main__ - Step 660 Global step 660 Train loss 2.38 on epoch=164
05/30/2022 02:12:26 - INFO - __main__ - Step 670 Global step 670 Train loss 2.42 on epoch=167
05/30/2022 02:12:27 - INFO - __main__ - Step 680 Global step 680 Train loss 2.33 on epoch=169
05/30/2022 02:12:28 - INFO - __main__ - Step 690 Global step 690 Train loss 2.39 on epoch=172
05/30/2022 02:12:29 - INFO - __main__ - Step 700 Global step 700 Train loss 2.19 on epoch=174
05/30/2022 02:12:30 - INFO - __main__ - Global step 700 Train loss 2.34 Classification-F1 0.10126582278481013 on epoch=174
05/30/2022 02:12:31 - INFO - __main__ - Step 710 Global step 710 Train loss 2.30 on epoch=177
05/30/2022 02:12:32 - INFO - __main__ - Step 720 Global step 720 Train loss 2.07 on epoch=179
05/30/2022 02:12:34 - INFO - __main__ - Step 730 Global step 730 Train loss 2.34 on epoch=182
05/30/2022 02:12:35 - INFO - __main__ - Step 740 Global step 740 Train loss 2.20 on epoch=184
05/30/2022 02:12:36 - INFO - __main__ - Step 750 Global step 750 Train loss 2.29 on epoch=187
05/30/2022 02:12:37 - INFO - __main__ - Global step 750 Train loss 2.24 Classification-F1 0.11078022632519356 on epoch=187
05/30/2022 02:12:38 - INFO - __main__ - Step 760 Global step 760 Train loss 2.04 on epoch=189
05/30/2022 02:12:39 - INFO - __main__ - Step 770 Global step 770 Train loss 2.31 on epoch=192
05/30/2022 02:12:41 - INFO - __main__ - Step 780 Global step 780 Train loss 1.99 on epoch=194
05/30/2022 02:12:42 - INFO - __main__ - Step 790 Global step 790 Train loss 2.14 on epoch=197
05/30/2022 02:12:43 - INFO - __main__ - Step 800 Global step 800 Train loss 1.93 on epoch=199
05/30/2022 02:12:44 - INFO - __main__ - Global step 800 Train loss 2.08 Classification-F1 0.13123993558776167 on epoch=199
05/30/2022 02:12:45 - INFO - __main__ - Step 810 Global step 810 Train loss 1.98 on epoch=202
05/30/2022 02:12:46 - INFO - __main__ - Step 820 Global step 820 Train loss 2.02 on epoch=204
05/30/2022 02:12:48 - INFO - __main__ - Step 830 Global step 830 Train loss 2.06 on epoch=207
05/30/2022 02:12:49 - INFO - __main__ - Step 840 Global step 840 Train loss 1.93 on epoch=209
05/30/2022 02:12:50 - INFO - __main__ - Step 850 Global step 850 Train loss 1.86 on epoch=212
05/30/2022 02:12:51 - INFO - __main__ - Global step 850 Train loss 1.97 Classification-F1 0.08440555841482245 on epoch=212
05/30/2022 02:12:52 - INFO - __main__ - Step 860 Global step 860 Train loss 1.94 on epoch=214
05/30/2022 02:12:53 - INFO - __main__ - Step 870 Global step 870 Train loss 1.90 on epoch=217
05/30/2022 02:12:54 - INFO - __main__ - Step 880 Global step 880 Train loss 1.93 on epoch=219
05/30/2022 02:12:56 - INFO - __main__ - Step 890 Global step 890 Train loss 2.00 on epoch=222
05/30/2022 02:12:57 - INFO - __main__ - Step 900 Global step 900 Train loss 1.96 on epoch=224
05/30/2022 02:12:58 - INFO - __main__ - Global step 900 Train loss 1.95 Classification-F1 0.09210526315789473 on epoch=224
05/30/2022 02:12:59 - INFO - __main__ - Step 910 Global step 910 Train loss 1.94 on epoch=227
05/30/2022 02:13:00 - INFO - __main__ - Step 920 Global step 920 Train loss 1.82 on epoch=229
05/30/2022 02:13:01 - INFO - __main__ - Step 930 Global step 930 Train loss 1.80 on epoch=232
05/30/2022 02:13:03 - INFO - __main__ - Step 940 Global step 940 Train loss 1.77 on epoch=234
05/30/2022 02:13:04 - INFO - __main__ - Step 950 Global step 950 Train loss 1.92 on epoch=237
05/30/2022 02:13:04 - INFO - __main__ - Global step 950 Train loss 1.85 Classification-F1 0.11607142857142856 on epoch=237
05/30/2022 02:13:06 - INFO - __main__ - Step 960 Global step 960 Train loss 1.80 on epoch=239
05/30/2022 02:13:07 - INFO - __main__ - Step 970 Global step 970 Train loss 1.71 on epoch=242
05/30/2022 02:13:08 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
05/30/2022 02:13:09 - INFO - __main__ - Step 990 Global step 990 Train loss 1.84 on epoch=247
05/30/2022 02:13:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.70 on epoch=249
05/30/2022 02:13:11 - INFO - __main__ - Global step 1000 Train loss 1.75 Classification-F1 0.10969141755062681 on epoch=249
05/30/2022 02:13:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.69 on epoch=252
05/30/2022 02:13:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.71 on epoch=254
05/30/2022 02:13:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.76 on epoch=257
05/30/2022 02:13:16 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.63 on epoch=259
05/30/2022 02:13:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.73 on epoch=262
05/30/2022 02:13:18 - INFO - __main__ - Global step 1050 Train loss 1.70 Classification-F1 0.15535714285714286 on epoch=262
05/30/2022 02:13:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.68 on epoch=264
05/30/2022 02:13:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.65 on epoch=267
05/30/2022 02:13:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.49 on epoch=269
05/30/2022 02:13:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.64 on epoch=272
05/30/2022 02:13:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.52 on epoch=274
05/30/2022 02:13:25 - INFO - __main__ - Global step 1100 Train loss 1.60 Classification-F1 0.09822866344605476 on epoch=274
05/30/2022 02:13:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.67 on epoch=277
05/30/2022 02:13:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.57 on epoch=279
05/30/2022 02:13:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.79 on epoch=282
05/30/2022 02:13:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.57 on epoch=284
05/30/2022 02:13:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.53 on epoch=287
05/30/2022 02:13:32 - INFO - __main__ - Global step 1150 Train loss 1.63 Classification-F1 0.09615384615384615 on epoch=287
05/30/2022 02:13:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.62 on epoch=289
05/30/2022 02:13:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.61 on epoch=292
05/30/2022 02:13:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.32 on epoch=294
05/30/2022 02:13:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.53 on epoch=297
05/30/2022 02:13:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.57 on epoch=299
05/30/2022 02:13:39 - INFO - __main__ - Global step 1200 Train loss 1.53 Classification-F1 0.12819829424307036 on epoch=299
05/30/2022 02:13:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.45 on epoch=302
05/30/2022 02:13:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.43 on epoch=304
05/30/2022 02:13:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.41 on epoch=307
05/30/2022 02:13:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.45 on epoch=309
05/30/2022 02:13:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.44 on epoch=312
05/30/2022 02:13:46 - INFO - __main__ - Global step 1250 Train loss 1.43 Classification-F1 0.14222873900293254 on epoch=312
05/30/2022 02:13:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.28 on epoch=314
05/30/2022 02:13:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.45 on epoch=317
05/30/2022 02:13:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.34 on epoch=319
05/30/2022 02:13:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.39 on epoch=322
05/30/2022 02:13:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.35 on epoch=324
05/30/2022 02:13:53 - INFO - __main__ - Global step 1300 Train loss 1.36 Classification-F1 0.08904109589041095 on epoch=324
05/30/2022 02:13:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.42 on epoch=327
05/30/2022 02:13:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.37 on epoch=329
05/30/2022 02:13:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.41 on epoch=332
05/30/2022 02:13:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.43 on epoch=334
05/30/2022 02:13:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.28 on epoch=337
05/30/2022 02:13:59 - INFO - __main__ - Global step 1350 Train loss 1.38 Classification-F1 0.1468058968058968 on epoch=337
05/30/2022 02:14:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.27 on epoch=339
05/30/2022 02:14:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.32 on epoch=342
05/30/2022 02:14:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.31 on epoch=344
05/30/2022 02:14:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.33 on epoch=347
05/30/2022 02:14:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.20 on epoch=349
05/30/2022 02:14:06 - INFO - __main__ - Global step 1400 Train loss 1.29 Classification-F1 0.1406926406926407 on epoch=349
05/30/2022 02:14:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/30/2022 02:14:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.33 on epoch=354
05/30/2022 02:14:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.28 on epoch=357
05/30/2022 02:14:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.36 on epoch=359
05/30/2022 02:14:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.30 on epoch=362
05/30/2022 02:14:13 - INFO - __main__ - Global step 1450 Train loss 1.30 Classification-F1 0.08783783783783784 on epoch=362
05/30/2022 02:14:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.29 on epoch=364
05/30/2022 02:14:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.29 on epoch=367
05/30/2022 02:14:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.16 on epoch=369
05/30/2022 02:14:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/30/2022 02:14:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=374
05/30/2022 02:14:20 - INFO - __main__ - Global step 1500 Train loss 1.24 Classification-F1 0.08904109589041095 on epoch=374
05/30/2022 02:14:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.14 on epoch=377
05/30/2022 02:14:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.28 on epoch=379
05/30/2022 02:14:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.35 on epoch=382
05/30/2022 02:14:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.21 on epoch=384
05/30/2022 02:14:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.22 on epoch=387
05/30/2022 02:14:27 - INFO - __main__ - Global step 1550 Train loss 1.24 Classification-F1 0.10389610389610389 on epoch=387
05/30/2022 02:14:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.21 on epoch=389
05/30/2022 02:14:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=392
05/30/2022 02:14:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
05/30/2022 02:14:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.15 on epoch=397
05/30/2022 02:14:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.26 on epoch=399
05/30/2022 02:14:34 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.1487390633041688 on epoch=399
05/30/2022 02:14:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.14 on epoch=402
05/30/2022 02:14:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.19 on epoch=404
05/30/2022 02:14:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.25 on epoch=407
05/30/2022 02:14:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.20 on epoch=409
05/30/2022 02:14:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.15 on epoch=412
05/30/2022 02:14:41 - INFO - __main__ - Global step 1650 Train loss 1.18 Classification-F1 0.1 on epoch=412
05/30/2022 02:14:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.20 on epoch=414
05/30/2022 02:14:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
05/30/2022 02:14:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.99 on epoch=419
05/30/2022 02:14:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.26 on epoch=422
05/30/2022 02:14:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.18 on epoch=424
05/30/2022 02:14:48 - INFO - __main__ - Global step 1700 Train loss 1.17 Classification-F1 0.1785345717234262 on epoch=424
05/30/2022 02:14:48 - INFO - __main__ - Saving model with best Classification-F1: 0.16277641277641278 -> 0.1785345717234262 on epoch=424, global_step=1700
05/30/2022 02:14:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.18 on epoch=427
05/30/2022 02:14:50 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.07 on epoch=429
05/30/2022 02:14:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.24 on epoch=432
05/30/2022 02:14:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.10 on epoch=434
05/30/2022 02:14:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.12 on epoch=437
05/30/2022 02:14:54 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.13430127041742287 on epoch=437
05/30/2022 02:14:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.23 on epoch=439
05/30/2022 02:14:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.18 on epoch=442
05/30/2022 02:14:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.18 on epoch=444
05/30/2022 02:15:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.19 on epoch=447
05/30/2022 02:15:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/30/2022 02:15:01 - INFO - __main__ - Global step 1800 Train loss 1.18 Classification-F1 0.13482414242292662 on epoch=449
05/30/2022 02:15:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.28 on epoch=452
05/30/2022 02:15:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/30/2022 02:15:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.22 on epoch=457
05/30/2022 02:15:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.22 on epoch=459
05/30/2022 02:15:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.18 on epoch=462
05/30/2022 02:15:08 - INFO - __main__ - Global step 1850 Train loss 1.21 Classification-F1 0.11616161616161616 on epoch=462
05/30/2022 02:15:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.06 on epoch=464
05/30/2022 02:15:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.26 on epoch=467
05/30/2022 02:15:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
05/30/2022 02:15:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.01 on epoch=472
05/30/2022 02:15:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/30/2022 02:15:15 - INFO - __main__ - Global step 1900 Train loss 1.14 Classification-F1 0.09999999999999999 on epoch=474
05/30/2022 02:15:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.14 on epoch=477
05/30/2022 02:15:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.00 on epoch=479
05/30/2022 02:15:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.14 on epoch=482
05/30/2022 02:15:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.18 on epoch=484
05/30/2022 02:15:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.16 on epoch=487
05/30/2022 02:15:22 - INFO - __main__ - Global step 1950 Train loss 1.12 Classification-F1 0.18847006651884698 on epoch=487
05/30/2022 02:15:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1785345717234262 -> 0.18847006651884698 on epoch=487, global_step=1950
05/30/2022 02:15:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.08 on epoch=489
05/30/2022 02:15:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.17 on epoch=492
05/30/2022 02:15:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.10 on epoch=494
05/30/2022 02:15:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.18 on epoch=497
05/30/2022 02:15:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.01 on epoch=499
05/30/2022 02:15:29 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.1769449715370019 on epoch=499
05/30/2022 02:15:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.20 on epoch=502
05/30/2022 02:15:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.22 on epoch=504
05/30/2022 02:15:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.10 on epoch=507
05/30/2022 02:15:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.06 on epoch=509
05/30/2022 02:15:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.22 on epoch=512
05/30/2022 02:15:36 - INFO - __main__ - Global step 2050 Train loss 1.16 Classification-F1 0.21964285714285714 on epoch=512
05/30/2022 02:15:36 - INFO - __main__ - Saving model with best Classification-F1: 0.18847006651884698 -> 0.21964285714285714 on epoch=512, global_step=2050
05/30/2022 02:15:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.01 on epoch=514
05/30/2022 02:15:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.21 on epoch=517
05/30/2022 02:15:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.15 on epoch=519
05/30/2022 02:15:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
05/30/2022 02:15:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.14 on epoch=524
05/30/2022 02:15:42 - INFO - __main__ - Global step 2100 Train loss 1.12 Classification-F1 0.1 on epoch=524
05/30/2022 02:15:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.09 on epoch=527
05/30/2022 02:15:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.18 on epoch=529
05/30/2022 02:15:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.11 on epoch=532
05/30/2022 02:15:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.08 on epoch=534
05/30/2022 02:15:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.17 on epoch=537
05/30/2022 02:15:49 - INFO - __main__ - Global step 2150 Train loss 1.12 Classification-F1 0.1 on epoch=537
05/30/2022 02:15:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.14 on epoch=539
05/30/2022 02:15:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=542
05/30/2022 02:15:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.11 on epoch=544
05/30/2022 02:15:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.06 on epoch=547
05/30/2022 02:15:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.11 on epoch=549
05/30/2022 02:15:56 - INFO - __main__ - Global step 2200 Train loss 1.11 Classification-F1 0.18172268907563027 on epoch=549
05/30/2022 02:15:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/30/2022 02:15:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.08 on epoch=554
05/30/2022 02:16:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.10 on epoch=557
05/30/2022 02:16:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.07 on epoch=559
05/30/2022 02:16:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.03 on epoch=562
05/30/2022 02:16:03 - INFO - __main__ - Global step 2250 Train loss 1.05 Classification-F1 0.11859154929577466 on epoch=562
05/30/2022 02:16:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/30/2022 02:16:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=567
05/30/2022 02:16:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.14 on epoch=569
05/30/2022 02:16:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.10 on epoch=572
05/30/2022 02:16:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.02 on epoch=574
05/30/2022 02:16:10 - INFO - __main__ - Global step 2300 Train loss 1.08 Classification-F1 0.16563380281690143 on epoch=574
05/30/2022 02:16:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/30/2022 02:16:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.00 on epoch=579
05/30/2022 02:16:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/30/2022 02:16:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.07 on epoch=584
05/30/2022 02:16:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=587
05/30/2022 02:16:17 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.18055555555555552 on epoch=587
05/30/2022 02:16:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.06 on epoch=589
05/30/2022 02:16:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.07 on epoch=592
05/30/2022 02:16:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.99 on epoch=594
05/30/2022 02:16:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.11 on epoch=597
05/30/2022 02:16:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=599
05/30/2022 02:16:23 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.19807311222361285 on epoch=599
05/30/2022 02:16:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.04 on epoch=602
05/30/2022 02:16:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/30/2022 02:16:27 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.05 on epoch=607
05/30/2022 02:16:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=609
05/30/2022 02:16:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.94 on epoch=612
05/30/2022 02:16:30 - INFO - __main__ - Global step 2450 Train loss 0.99 Classification-F1 0.18783068783068785 on epoch=612
05/30/2022 02:16:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.08 on epoch=614
05/30/2022 02:16:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=617
05/30/2022 02:16:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.08 on epoch=619
05/30/2022 02:16:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.09 on epoch=622
05/30/2022 02:16:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.06 on epoch=624
05/30/2022 02:16:37 - INFO - __main__ - Global step 2500 Train loss 1.06 Classification-F1 0.109375 on epoch=624
05/30/2022 02:16:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.05 on epoch=627
05/30/2022 02:16:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.97 on epoch=629
05/30/2022 02:16:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.03 on epoch=632
05/30/2022 02:16:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.01 on epoch=634
05/30/2022 02:16:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/30/2022 02:16:44 - INFO - __main__ - Global step 2550 Train loss 1.02 Classification-F1 0.1527777777777778 on epoch=637
05/30/2022 02:16:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.10 on epoch=639
05/30/2022 02:16:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.02 on epoch=642
05/30/2022 02:16:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.04 on epoch=644
05/30/2022 02:16:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.03 on epoch=647
05/30/2022 02:16:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.10 on epoch=649
05/30/2022 02:16:51 - INFO - __main__ - Global step 2600 Train loss 1.06 Classification-F1 0.19836065573770492 on epoch=649
05/30/2022 02:16:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.13 on epoch=652
05/30/2022 02:16:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.15 on epoch=654
05/30/2022 02:16:55 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
05/30/2022 02:16:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/30/2022 02:16:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.07 on epoch=662
05/30/2022 02:16:58 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.13067758749069247 on epoch=662
05/30/2022 02:16:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.00 on epoch=664
05/30/2022 02:17:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.05 on epoch=667
05/30/2022 02:17:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.03 on epoch=669
05/30/2022 02:17:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.14 on epoch=672
05/30/2022 02:17:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.03 on epoch=674
05/30/2022 02:17:05 - INFO - __main__ - Global step 2700 Train loss 1.05 Classification-F1 0.1 on epoch=674
05/30/2022 02:17:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.13 on epoch=677
05/30/2022 02:17:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.00 on epoch=679
05/30/2022 02:17:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.87 on epoch=682
05/30/2022 02:17:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.02 on epoch=684
05/30/2022 02:17:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.05 on epoch=687
05/30/2022 02:17:12 - INFO - __main__ - Global step 2750 Train loss 1.01 Classification-F1 0.10256410256410256 on epoch=687
05/30/2022 02:17:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.11 on epoch=689
05/30/2022 02:17:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.04 on epoch=692
05/30/2022 02:17:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/30/2022 02:17:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.02 on epoch=697
05/30/2022 02:17:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.02 on epoch=699
05/30/2022 02:17:18 - INFO - __main__ - Global step 2800 Train loss 1.02 Classification-F1 0.22478991596638653 on epoch=699
05/30/2022 02:17:18 - INFO - __main__ - Saving model with best Classification-F1: 0.21964285714285714 -> 0.22478991596638653 on epoch=699, global_step=2800
05/30/2022 02:17:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.08 on epoch=702
05/30/2022 02:17:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.19 on epoch=704
05/30/2022 02:17:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.08 on epoch=707
05/30/2022 02:17:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/30/2022 02:17:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.04 on epoch=712
05/30/2022 02:17:25 - INFO - __main__ - Global step 2850 Train loss 1.09 Classification-F1 0.1 on epoch=712
05/30/2022 02:17:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.89 on epoch=714
05/30/2022 02:17:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.02 on epoch=717
05/30/2022 02:17:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/30/2022 02:17:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.00 on epoch=722
05/30/2022 02:17:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/30/2022 02:17:32 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.11065943992773261 on epoch=724
05/30/2022 02:17:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.09 on epoch=727
05/30/2022 02:17:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.95 on epoch=729
05/30/2022 02:17:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.97 on epoch=732
05/30/2022 02:17:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.96 on epoch=734
05/30/2022 02:17:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.88 on epoch=737
05/30/2022 02:17:39 - INFO - __main__ - Global step 2950 Train loss 0.97 Classification-F1 0.19310511089681776 on epoch=737
05/30/2022 02:17:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.92 on epoch=739
05/30/2022 02:17:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.03 on epoch=742
05/30/2022 02:17:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.00 on epoch=744
05/30/2022 02:17:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/30/2022 02:17:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.04 on epoch=749
05/30/2022 02:17:46 - INFO - __main__ - Global step 3000 Train loss 1.00 Classification-F1 0.1488095238095238 on epoch=749
05/30/2022 02:17:46 - INFO - __main__ - save last model!
05/30/2022 02:17:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:17:46 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:17:46 - INFO - __main__ - Printing 3 examples
05/30/2022 02:17:46 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:17:46 - INFO - __main__ - ['others']
05/30/2022 02:17:46 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:17:46 - INFO - __main__ - ['others']
05/30/2022 02:17:46 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:17:46 - INFO - __main__ - ['others']
05/30/2022 02:17:46 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:17:46 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:17:46 - INFO - __main__ - Printing 3 examples
05/30/2022 02:17:46 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:17:46 - INFO - __main__ - ['happy']
05/30/2022 02:17:46 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:17:46 - INFO - __main__ - ['happy']
05/30/2022 02:17:46 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:17:46 - INFO - __main__ - ['happy']
05/30/2022 02:17:46 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:17:46 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:17:47 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:17:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:17:47 - INFO - __main__ - Printing 3 examples
05/30/2022 02:17:47 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:17:47 - INFO - __main__ - ['happy']
05/30/2022 02:17:47 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:17:47 - INFO - __main__ - ['happy']
05/30/2022 02:17:47 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:17:47 - INFO - __main__ - ['happy']
05/30/2022 02:17:47 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:17:47 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:17:47 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:17:48 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:17:52 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:17:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:17:53 - INFO - __main__ - Starting training!
05/30/2022 02:17:53 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:18:37 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_21_0.2_8_predictions.txt
05/30/2022 02:18:37 - INFO - __main__ - Classification-F1 on test data: 0.0428
05/30/2022 02:18:37 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.22478991596638653, test_performance=0.0428240268843188
05/30/2022 02:18:37 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
05/30/2022 02:18:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:18:38 - INFO - __main__ - Printing 3 examples
05/30/2022 02:18:38 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:18:38 - INFO - __main__ - ['happy']
05/30/2022 02:18:38 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:18:38 - INFO - __main__ - ['happy']
05/30/2022 02:18:38 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:18:38 - INFO - __main__ - ['happy']
05/30/2022 02:18:38 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:18:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:18:38 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:18:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:18:38 - INFO - __main__ - Printing 3 examples
05/30/2022 02:18:38 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:18:38 - INFO - __main__ - ['happy']
05/30/2022 02:18:38 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:18:38 - INFO - __main__ - ['happy']
05/30/2022 02:18:38 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:18:38 - INFO - __main__ - ['happy']
05/30/2022 02:18:38 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:18:38 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:18:38 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:18:44 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:18:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:18:44 - INFO - __main__ - Starting training!
05/30/2022 02:18:45 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=2
05/30/2022 02:18:47 - INFO - __main__ - Step 20 Global step 20 Train loss 6.48 on epoch=4
05/30/2022 02:18:48 - INFO - __main__ - Step 30 Global step 30 Train loss 6.08 on epoch=7
05/30/2022 02:18:49 - INFO - __main__ - Step 40 Global step 40 Train loss 5.84 on epoch=9
05/30/2022 02:18:51 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=12
05/30/2022 02:18:55 - INFO - __main__ - Global step 50 Train loss 6.13 Classification-F1 0.0 on epoch=12
05/30/2022 02:18:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:18:56 - INFO - __main__ - Step 60 Global step 60 Train loss 5.38 on epoch=14
05/30/2022 02:18:57 - INFO - __main__ - Step 70 Global step 70 Train loss 5.24 on epoch=17
05/30/2022 02:18:59 - INFO - __main__ - Step 80 Global step 80 Train loss 5.02 on epoch=19
05/30/2022 02:19:00 - INFO - __main__ - Step 90 Global step 90 Train loss 4.63 on epoch=22
05/30/2022 02:19:01 - INFO - __main__ - Step 100 Global step 100 Train loss 4.76 on epoch=24
05/30/2022 02:19:03 - INFO - __main__ - Global step 100 Train loss 5.01 Classification-F1 0.03240740740740741 on epoch=24
05/30/2022 02:19:03 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.03240740740740741 on epoch=24, global_step=100
05/30/2022 02:19:04 - INFO - __main__ - Step 110 Global step 110 Train loss 4.42 on epoch=27
05/30/2022 02:19:05 - INFO - __main__ - Step 120 Global step 120 Train loss 4.43 on epoch=29
05/30/2022 02:19:07 - INFO - __main__ - Step 130 Global step 130 Train loss 4.34 on epoch=32
05/30/2022 02:19:08 - INFO - __main__ - Step 140 Global step 140 Train loss 4.21 on epoch=34
05/30/2022 02:19:09 - INFO - __main__ - Step 150 Global step 150 Train loss 4.07 on epoch=37
05/30/2022 02:19:10 - INFO - __main__ - Global step 150 Train loss 4.29 Classification-F1 0.0810126582278481 on epoch=37
05/30/2022 02:19:10 - INFO - __main__ - Saving model with best Classification-F1: 0.03240740740740741 -> 0.0810126582278481 on epoch=37, global_step=150
05/30/2022 02:19:11 - INFO - __main__ - Step 160 Global step 160 Train loss 4.01 on epoch=39
05/30/2022 02:19:13 - INFO - __main__ - Step 170 Global step 170 Train loss 3.60 on epoch=42
05/30/2022 02:19:14 - INFO - __main__ - Step 180 Global step 180 Train loss 3.72 on epoch=44
05/30/2022 02:19:15 - INFO - __main__ - Step 190 Global step 190 Train loss 3.54 on epoch=47
05/30/2022 02:19:16 - INFO - __main__ - Step 200 Global step 200 Train loss 3.49 on epoch=49
05/30/2022 02:19:17 - INFO - __main__ - Global step 200 Train loss 3.68 Classification-F1 0.09615384615384615 on epoch=49
05/30/2022 02:19:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.09615384615384615 on epoch=49, global_step=200
05/30/2022 02:19:18 - INFO - __main__ - Step 210 Global step 210 Train loss 3.38 on epoch=52
05/30/2022 02:19:19 - INFO - __main__ - Step 220 Global step 220 Train loss 3.22 on epoch=54
05/30/2022 02:19:21 - INFO - __main__ - Step 230 Global step 230 Train loss 2.98 on epoch=57
05/30/2022 02:19:22 - INFO - __main__ - Step 240 Global step 240 Train loss 3.02 on epoch=59
05/30/2022 02:19:23 - INFO - __main__ - Step 250 Global step 250 Train loss 2.91 on epoch=62
05/30/2022 02:19:24 - INFO - __main__ - Global step 250 Train loss 3.10 Classification-F1 0.07594936708860758 on epoch=62
05/30/2022 02:19:25 - INFO - __main__ - Step 260 Global step 260 Train loss 2.92 on epoch=64
05/30/2022 02:19:26 - INFO - __main__ - Step 270 Global step 270 Train loss 2.86 on epoch=67
05/30/2022 02:19:28 - INFO - __main__ - Step 280 Global step 280 Train loss 2.92 on epoch=69
05/30/2022 02:19:29 - INFO - __main__ - Step 290 Global step 290 Train loss 2.66 on epoch=72
05/30/2022 02:19:30 - INFO - __main__ - Step 300 Global step 300 Train loss 2.77 on epoch=74
05/30/2022 02:19:31 - INFO - __main__ - Global step 300 Train loss 2.83 Classification-F1 0.1 on epoch=74
05/30/2022 02:19:31 - INFO - __main__ - Saving model with best Classification-F1: 0.09615384615384615 -> 0.1 on epoch=74, global_step=300
05/30/2022 02:19:32 - INFO - __main__ - Step 310 Global step 310 Train loss 2.63 on epoch=77
05/30/2022 02:19:33 - INFO - __main__ - Step 320 Global step 320 Train loss 2.64 on epoch=79
05/30/2022 02:19:34 - INFO - __main__ - Step 330 Global step 330 Train loss 2.38 on epoch=82
05/30/2022 02:19:36 - INFO - __main__ - Step 340 Global step 340 Train loss 2.53 on epoch=84
05/30/2022 02:19:37 - INFO - __main__ - Step 350 Global step 350 Train loss 2.43 on epoch=87
05/30/2022 02:19:38 - INFO - __main__ - Global step 350 Train loss 2.52 Classification-F1 0.1118421052631579 on epoch=87
05/30/2022 02:19:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1118421052631579 on epoch=87, global_step=350
05/30/2022 02:19:39 - INFO - __main__ - Step 360 Global step 360 Train loss 2.44 on epoch=89
05/30/2022 02:19:40 - INFO - __main__ - Step 370 Global step 370 Train loss 2.32 on epoch=92
05/30/2022 02:19:41 - INFO - __main__ - Step 380 Global step 380 Train loss 2.39 on epoch=94
05/30/2022 02:19:43 - INFO - __main__ - Step 390 Global step 390 Train loss 2.27 on epoch=97
05/30/2022 02:19:44 - INFO - __main__ - Step 400 Global step 400 Train loss 2.31 on epoch=99
05/30/2022 02:19:44 - INFO - __main__ - Global step 400 Train loss 2.35 Classification-F1 0.11714285714285715 on epoch=99
05/30/2022 02:19:44 - INFO - __main__ - Saving model with best Classification-F1: 0.1118421052631579 -> 0.11714285714285715 on epoch=99, global_step=400
05/30/2022 02:19:46 - INFO - __main__ - Step 410 Global step 410 Train loss 2.25 on epoch=102
05/30/2022 02:19:47 - INFO - __main__ - Step 420 Global step 420 Train loss 2.12 on epoch=104
05/30/2022 02:19:48 - INFO - __main__ - Step 430 Global step 430 Train loss 2.30 on epoch=107
05/30/2022 02:19:49 - INFO - __main__ - Step 440 Global step 440 Train loss 2.07 on epoch=109
05/30/2022 02:19:51 - INFO - __main__ - Step 450 Global step 450 Train loss 2.13 on epoch=112
05/30/2022 02:19:51 - INFO - __main__ - Global step 450 Train loss 2.17 Classification-F1 0.1646076146076146 on epoch=112
05/30/2022 02:19:51 - INFO - __main__ - Saving model with best Classification-F1: 0.11714285714285715 -> 0.1646076146076146 on epoch=112, global_step=450
05/30/2022 02:19:53 - INFO - __main__ - Step 460 Global step 460 Train loss 1.98 on epoch=114
05/30/2022 02:19:54 - INFO - __main__ - Step 470 Global step 470 Train loss 1.92 on epoch=117
05/30/2022 02:19:55 - INFO - __main__ - Step 480 Global step 480 Train loss 2.01 on epoch=119
05/30/2022 02:19:56 - INFO - __main__ - Step 490 Global step 490 Train loss 1.65 on epoch=122
05/30/2022 02:19:58 - INFO - __main__ - Step 500 Global step 500 Train loss 1.68 on epoch=124
05/30/2022 02:19:58 - INFO - __main__ - Global step 500 Train loss 1.85 Classification-F1 0.17436974789915968 on epoch=124
05/30/2022 02:19:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1646076146076146 -> 0.17436974789915968 on epoch=124, global_step=500
05/30/2022 02:19:59 - INFO - __main__ - Step 510 Global step 510 Train loss 1.80 on epoch=127
05/30/2022 02:20:01 - INFO - __main__ - Step 520 Global step 520 Train loss 1.71 on epoch=129
05/30/2022 02:20:02 - INFO - __main__ - Step 530 Global step 530 Train loss 1.77 on epoch=132
05/30/2022 02:20:03 - INFO - __main__ - Step 540 Global step 540 Train loss 1.67 on epoch=134
05/30/2022 02:20:04 - INFO - __main__ - Step 550 Global step 550 Train loss 1.77 on epoch=137
05/30/2022 02:20:05 - INFO - __main__ - Global step 550 Train loss 1.74 Classification-F1 0.16785714285714287 on epoch=137
05/30/2022 02:20:06 - INFO - __main__ - Step 560 Global step 560 Train loss 1.63 on epoch=139
05/30/2022 02:20:07 - INFO - __main__ - Step 570 Global step 570 Train loss 1.56 on epoch=142
05/30/2022 02:20:09 - INFO - __main__ - Step 580 Global step 580 Train loss 1.51 on epoch=144
05/30/2022 02:20:10 - INFO - __main__ - Step 590 Global step 590 Train loss 1.51 on epoch=147
05/30/2022 02:20:11 - INFO - __main__ - Step 600 Global step 600 Train loss 1.47 on epoch=149
05/30/2022 02:20:12 - INFO - __main__ - Global step 600 Train loss 1.53 Classification-F1 0.17368421052631577 on epoch=149
05/30/2022 02:20:13 - INFO - __main__ - Step 610 Global step 610 Train loss 1.63 on epoch=152
05/30/2022 02:20:14 - INFO - __main__ - Step 620 Global step 620 Train loss 1.65 on epoch=154
05/30/2022 02:20:16 - INFO - __main__ - Step 630 Global step 630 Train loss 1.34 on epoch=157
05/30/2022 02:20:17 - INFO - __main__ - Step 640 Global step 640 Train loss 1.45 on epoch=159
05/30/2022 02:20:18 - INFO - __main__ - Step 650 Global step 650 Train loss 1.36 on epoch=162
05/30/2022 02:20:19 - INFO - __main__ - Global step 650 Train loss 1.49 Classification-F1 0.1 on epoch=162
05/30/2022 02:20:20 - INFO - __main__ - Step 660 Global step 660 Train loss 1.49 on epoch=164
05/30/2022 02:20:21 - INFO - __main__ - Step 670 Global step 670 Train loss 1.48 on epoch=167
05/30/2022 02:20:22 - INFO - __main__ - Step 680 Global step 680 Train loss 1.48 on epoch=169
05/30/2022 02:20:24 - INFO - __main__ - Step 690 Global step 690 Train loss 1.34 on epoch=172
05/30/2022 02:20:25 - INFO - __main__ - Step 700 Global step 700 Train loss 1.50 on epoch=174
05/30/2022 02:20:25 - INFO - __main__ - Global step 700 Train loss 1.46 Classification-F1 0.1 on epoch=174
05/30/2022 02:20:27 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=177
05/30/2022 02:20:28 - INFO - __main__ - Step 720 Global step 720 Train loss 1.33 on epoch=179
05/30/2022 02:20:29 - INFO - __main__ - Step 730 Global step 730 Train loss 1.33 on epoch=182
05/30/2022 02:20:31 - INFO - __main__ - Step 740 Global step 740 Train loss 1.20 on epoch=184
05/30/2022 02:20:32 - INFO - __main__ - Step 750 Global step 750 Train loss 1.23 on epoch=187
05/30/2022 02:20:32 - INFO - __main__ - Global step 750 Train loss 1.28 Classification-F1 0.1 on epoch=187
05/30/2022 02:20:34 - INFO - __main__ - Step 760 Global step 760 Train loss 1.35 on epoch=189
05/30/2022 02:20:35 - INFO - __main__ - Step 770 Global step 770 Train loss 1.32 on epoch=192
05/30/2022 02:20:36 - INFO - __main__ - Step 780 Global step 780 Train loss 1.23 on epoch=194
05/30/2022 02:20:37 - INFO - __main__ - Step 790 Global step 790 Train loss 1.25 on epoch=197
05/30/2022 02:20:39 - INFO - __main__ - Step 800 Global step 800 Train loss 1.27 on epoch=199
05/30/2022 02:20:39 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.1 on epoch=199
05/30/2022 02:20:40 - INFO - __main__ - Step 810 Global step 810 Train loss 1.35 on epoch=202
05/30/2022 02:20:42 - INFO - __main__ - Step 820 Global step 820 Train loss 1.34 on epoch=204
05/30/2022 02:20:43 - INFO - __main__ - Step 830 Global step 830 Train loss 1.13 on epoch=207
05/30/2022 02:20:44 - INFO - __main__ - Step 840 Global step 840 Train loss 1.30 on epoch=209
05/30/2022 02:20:45 - INFO - __main__ - Step 850 Global step 850 Train loss 1.25 on epoch=212
05/30/2022 02:20:46 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.16666666666666666 on epoch=212
05/30/2022 02:20:47 - INFO - __main__ - Step 860 Global step 860 Train loss 1.30 on epoch=214
05/30/2022 02:20:49 - INFO - __main__ - Step 870 Global step 870 Train loss 1.29 on epoch=217
05/30/2022 02:20:50 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
05/30/2022 02:20:51 - INFO - __main__ - Step 890 Global step 890 Train loss 1.29 on epoch=222
05/30/2022 02:20:52 - INFO - __main__ - Step 900 Global step 900 Train loss 1.21 on epoch=224
05/30/2022 02:20:53 - INFO - __main__ - Global step 900 Train loss 1.28 Classification-F1 0.1 on epoch=224
05/30/2022 02:20:54 - INFO - __main__ - Step 910 Global step 910 Train loss 1.34 on epoch=227
05/30/2022 02:20:55 - INFO - __main__ - Step 920 Global step 920 Train loss 1.19 on epoch=229
05/30/2022 02:20:57 - INFO - __main__ - Step 930 Global step 930 Train loss 1.21 on epoch=232
05/30/2022 02:20:58 - INFO - __main__ - Step 940 Global step 940 Train loss 1.36 on epoch=234
05/30/2022 02:20:59 - INFO - __main__ - Step 950 Global step 950 Train loss 1.29 on epoch=237
05/30/2022 02:21:00 - INFO - __main__ - Global step 950 Train loss 1.28 Classification-F1 0.13034188034188032 on epoch=237
05/30/2022 02:21:01 - INFO - __main__ - Step 960 Global step 960 Train loss 1.04 on epoch=239
05/30/2022 02:21:02 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=242
05/30/2022 02:21:04 - INFO - __main__ - Step 980 Global step 980 Train loss 1.20 on epoch=244
05/30/2022 02:21:05 - INFO - __main__ - Step 990 Global step 990 Train loss 1.20 on epoch=247
05/30/2022 02:21:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.11 on epoch=249
05/30/2022 02:21:07 - INFO - __main__ - Global step 1000 Train loss 1.15 Classification-F1 0.2097902097902098 on epoch=249
05/30/2022 02:21:07 - INFO - __main__ - Saving model with best Classification-F1: 0.17436974789915968 -> 0.2097902097902098 on epoch=249, global_step=1000
05/30/2022 02:21:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.08 on epoch=252
05/30/2022 02:21:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.17 on epoch=254
05/30/2022 02:21:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/30/2022 02:21:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.23 on epoch=259
05/30/2022 02:21:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.04 on epoch=262
05/30/2022 02:21:13 - INFO - __main__ - Global step 1050 Train loss 1.12 Classification-F1 0.21717171717171715 on epoch=262
05/30/2022 02:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.2097902097902098 -> 0.21717171717171715 on epoch=262, global_step=1050
05/30/2022 02:21:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
05/30/2022 02:21:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.99 on epoch=267
05/30/2022 02:21:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.95 on epoch=269
05/30/2022 02:21:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.14 on epoch=272
05/30/2022 02:21:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.15 on epoch=274
05/30/2022 02:21:20 - INFO - __main__ - Global step 1100 Train loss 1.06 Classification-F1 0.1638655462184874 on epoch=274
05/30/2022 02:21:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.23 on epoch=277
05/30/2022 02:21:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.20 on epoch=279
05/30/2022 02:21:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
05/30/2022 02:21:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.17 on epoch=284
05/30/2022 02:21:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.94 on epoch=287
05/30/2022 02:21:27 - INFO - __main__ - Global step 1150 Train loss 1.14 Classification-F1 0.12912912912912913 on epoch=287
05/30/2022 02:21:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
05/30/2022 02:21:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.04 on epoch=292
05/30/2022 02:21:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.08 on epoch=294
05/30/2022 02:21:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.07 on epoch=297
05/30/2022 02:21:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.15 on epoch=299
05/30/2022 02:21:34 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.1 on epoch=299
05/30/2022 02:21:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.06 on epoch=302
05/30/2022 02:21:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=304
05/30/2022 02:21:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.99 on epoch=307
05/30/2022 02:21:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/30/2022 02:21:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.03 on epoch=312
05/30/2022 02:21:41 - INFO - __main__ - Global step 1250 Train loss 1.05 Classification-F1 0.197603121516165 on epoch=312
05/30/2022 02:21:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.11 on epoch=314
05/30/2022 02:21:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=317
05/30/2022 02:21:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.12 on epoch=319
05/30/2022 02:21:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.13 on epoch=322
05/30/2022 02:21:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.05 on epoch=324
05/30/2022 02:21:48 - INFO - __main__ - Global step 1300 Train loss 1.12 Classification-F1 0.17811480585078396 on epoch=324
05/30/2022 02:21:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.06 on epoch=327
05/30/2022 02:21:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.97 on epoch=329
05/30/2022 02:21:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.00 on epoch=332
05/30/2022 02:21:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.01 on epoch=334
05/30/2022 02:21:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.14 on epoch=337
05/30/2022 02:21:55 - INFO - __main__ - Global step 1350 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=337
05/30/2022 02:21:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.18 on epoch=339
05/30/2022 02:21:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=342
05/30/2022 02:21:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=344
05/30/2022 02:22:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.01 on epoch=347
05/30/2022 02:22:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.13 on epoch=349
05/30/2022 02:22:01 - INFO - __main__ - Global step 1400 Train loss 1.10 Classification-F1 0.1527777777777778 on epoch=349
05/30/2022 02:22:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.17 on epoch=352
05/30/2022 02:22:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.09 on epoch=354
05/30/2022 02:22:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.14 on epoch=357
05/30/2022 02:22:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.06 on epoch=359
05/30/2022 02:22:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.05 on epoch=362
05/30/2022 02:22:08 - INFO - __main__ - Global step 1450 Train loss 1.10 Classification-F1 0.10966810966810966 on epoch=362
05/30/2022 02:22:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.10 on epoch=364
05/30/2022 02:22:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.16 on epoch=367
05/30/2022 02:22:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.10 on epoch=369
05/30/2022 02:22:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=372
05/30/2022 02:22:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.02 on epoch=374
05/30/2022 02:22:15 - INFO - __main__ - Global step 1500 Train loss 1.07 Classification-F1 0.15606060606060607 on epoch=374
05/30/2022 02:22:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.96 on epoch=377
05/30/2022 02:22:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.04 on epoch=379
05/30/2022 02:22:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.04 on epoch=382
05/30/2022 02:22:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.11 on epoch=384
05/30/2022 02:22:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.97 on epoch=387
05/30/2022 02:22:22 - INFO - __main__ - Global step 1550 Train loss 1.02 Classification-F1 0.09868421052631579 on epoch=387
05/30/2022 02:22:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.04 on epoch=389
05/30/2022 02:22:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.09 on epoch=392
05/30/2022 02:22:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.98 on epoch=394
05/30/2022 02:22:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.02 on epoch=397
05/30/2022 02:22:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.10 on epoch=399
05/30/2022 02:22:29 - INFO - __main__ - Global step 1600 Train loss 1.05 Classification-F1 0.0974025974025974 on epoch=399
05/30/2022 02:22:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.04 on epoch=402
05/30/2022 02:22:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=404
05/30/2022 02:22:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.03 on epoch=407
05/30/2022 02:22:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
05/30/2022 02:22:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.99 on epoch=412
05/30/2022 02:22:36 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.2011385199240987 on epoch=412
05/30/2022 02:22:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.95 on epoch=414
05/30/2022 02:22:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.96 on epoch=417
05/30/2022 02:22:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.95 on epoch=419
05/30/2022 02:22:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.04 on epoch=422
05/30/2022 02:22:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.01 on epoch=424
05/30/2022 02:22:42 - INFO - __main__ - Global step 1700 Train loss 0.98 Classification-F1 0.2011926367643246 on epoch=424
05/30/2022 02:22:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.09 on epoch=427
05/30/2022 02:22:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.88 on epoch=429
05/30/2022 02:22:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.05 on epoch=432
05/30/2022 02:22:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.04 on epoch=434
05/30/2022 02:22:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.02 on epoch=437
05/30/2022 02:22:49 - INFO - __main__ - Global step 1750 Train loss 1.02 Classification-F1 0.10126582278481013 on epoch=437
05/30/2022 02:22:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.02 on epoch=439
05/30/2022 02:22:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/30/2022 02:22:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.98 on epoch=444
05/30/2022 02:22:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.01 on epoch=447
05/30/2022 02:22:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
05/30/2022 02:22:56 - INFO - __main__ - Global step 1800 Train loss 1.00 Classification-F1 0.1767857142857143 on epoch=449
05/30/2022 02:22:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.00 on epoch=452
05/30/2022 02:22:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
05/30/2022 02:23:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.02 on epoch=457
05/30/2022 02:23:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=459
05/30/2022 02:23:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.97 on epoch=462
05/30/2022 02:23:03 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.13157894736842107 on epoch=462
05/30/2022 02:23:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.00 on epoch=464
05/30/2022 02:23:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.96 on epoch=467
05/30/2022 02:23:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.93 on epoch=469
05/30/2022 02:23:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/30/2022 02:23:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=474
05/30/2022 02:23:10 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.1 on epoch=474
05/30/2022 02:23:11 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.98 on epoch=477
05/30/2022 02:23:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.94 on epoch=479
05/30/2022 02:23:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.93 on epoch=482
05/30/2022 02:23:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.00 on epoch=484
05/30/2022 02:23:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.99 on epoch=487
05/30/2022 02:23:17 - INFO - __main__ - Global step 1950 Train loss 0.97 Classification-F1 0.19537815126050417 on epoch=487
05/30/2022 02:23:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.02 on epoch=489
05/30/2022 02:23:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.91 on epoch=492
05/30/2022 02:23:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.08 on epoch=494
05/30/2022 02:23:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.99 on epoch=497
05/30/2022 02:23:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/30/2022 02:23:23 - INFO - __main__ - Global step 2000 Train loss 0.99 Classification-F1 0.27645590314598795 on epoch=499
05/30/2022 02:23:24 - INFO - __main__ - Saving model with best Classification-F1: 0.21717171717171715 -> 0.27645590314598795 on epoch=499, global_step=2000
05/30/2022 02:23:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/30/2022 02:23:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
05/30/2022 02:23:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.00 on epoch=507
05/30/2022 02:23:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.96 on epoch=509
05/30/2022 02:23:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.10 on epoch=512
05/30/2022 02:23:30 - INFO - __main__ - Global step 2050 Train loss 1.02 Classification-F1 0.1388888888888889 on epoch=512
05/30/2022 02:23:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.00 on epoch=514
05/30/2022 02:23:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/30/2022 02:23:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.95 on epoch=519
05/30/2022 02:23:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.02 on epoch=522
05/30/2022 02:23:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.04 on epoch=524
05/30/2022 02:23:37 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.3629129129129129 on epoch=524
05/30/2022 02:23:37 - INFO - __main__ - Saving model with best Classification-F1: 0.27645590314598795 -> 0.3629129129129129 on epoch=524, global_step=2100
05/30/2022 02:23:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/30/2022 02:23:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.05 on epoch=529
05/30/2022 02:23:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.97 on epoch=532
05/30/2022 02:23:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.92 on epoch=534
05/30/2022 02:23:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.07 on epoch=537
05/30/2022 02:23:44 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.25918367346938775 on epoch=537
05/30/2022 02:23:45 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.04 on epoch=539
05/30/2022 02:23:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.02 on epoch=542
05/30/2022 02:23:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.03 on epoch=544
05/30/2022 02:23:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.98 on epoch=547
05/30/2022 02:23:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.96 on epoch=549
05/30/2022 02:23:51 - INFO - __main__ - Global step 2200 Train loss 1.01 Classification-F1 0.11732186732186733 on epoch=549
05/30/2022 02:23:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/30/2022 02:23:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.99 on epoch=554
05/30/2022 02:23:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.11 on epoch=557
05/30/2022 02:23:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.09 on epoch=559
05/30/2022 02:23:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
05/30/2022 02:23:58 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.2032315020119898 on epoch=562
05/30/2022 02:23:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/30/2022 02:24:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.00 on epoch=567
05/30/2022 02:24:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.96 on epoch=569
05/30/2022 02:24:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=572
05/30/2022 02:24:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/30/2022 02:24:05 - INFO - __main__ - Global step 2300 Train loss 0.98 Classification-F1 0.27036679536679536 on epoch=574
05/30/2022 02:24:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.00 on epoch=577
05/30/2022 02:24:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.00 on epoch=579
05/30/2022 02:24:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
05/30/2022 02:24:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.04 on epoch=584
05/30/2022 02:24:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/30/2022 02:24:11 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.15587044534412953 on epoch=587
05/30/2022 02:24:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/30/2022 02:24:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.11 on epoch=592
05/30/2022 02:24:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/30/2022 02:24:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.98 on epoch=597
05/30/2022 02:24:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.04 on epoch=599
05/30/2022 02:24:18 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.09528130671506352 on epoch=599
05/30/2022 02:24:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.96 on epoch=602
05/30/2022 02:24:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/30/2022 02:24:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/30/2022 02:24:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.88 on epoch=609
05/30/2022 02:24:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.98 on epoch=612
05/30/2022 02:24:25 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.15714285714285717 on epoch=612
05/30/2022 02:24:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.93 on epoch=614
05/30/2022 02:24:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.90 on epoch=617
05/30/2022 02:24:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/30/2022 02:24:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/30/2022 02:24:31 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.94 on epoch=624
05/30/2022 02:24:32 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.1774628879892038 on epoch=624
05/30/2022 02:24:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.99 on epoch=627
05/30/2022 02:24:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.04 on epoch=629
05/30/2022 02:24:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.99 on epoch=632
05/30/2022 02:24:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.05 on epoch=634
05/30/2022 02:24:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.97 on epoch=637
05/30/2022 02:24:39 - INFO - __main__ - Global step 2550 Train loss 1.01 Classification-F1 0.18385416666666665 on epoch=637
05/30/2022 02:24:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=639
05/30/2022 02:24:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.98 on epoch=642
05/30/2022 02:24:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.99 on epoch=644
05/30/2022 02:24:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.93 on epoch=647
05/30/2022 02:24:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.98 on epoch=649
05/30/2022 02:24:45 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.17813655142422266 on epoch=649
05/30/2022 02:24:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.87 on epoch=652
05/30/2022 02:24:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.90 on epoch=654
05/30/2022 02:24:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.91 on epoch=657
05/30/2022 02:24:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.90 on epoch=659
05/30/2022 02:24:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.96 on epoch=662
05/30/2022 02:24:52 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.1698691172375383 on epoch=662
05/30/2022 02:24:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.92 on epoch=664
05/30/2022 02:24:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.00 on epoch=667
05/30/2022 02:24:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/30/2022 02:24:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.05 on epoch=672
05/30/2022 02:24:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.02 on epoch=674
05/30/2022 02:24:59 - INFO - __main__ - Global step 2700 Train loss 0.98 Classification-F1 0.14583504477121498 on epoch=674
05/30/2022 02:25:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.05 on epoch=677
05/30/2022 02:25:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.89 on epoch=679
05/30/2022 02:25:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/30/2022 02:25:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/30/2022 02:25:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.97 on epoch=687
05/30/2022 02:25:06 - INFO - __main__ - Global step 2750 Train loss 0.96 Classification-F1 0.19811563763176665 on epoch=687
05/30/2022 02:25:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.01 on epoch=689
05/30/2022 02:25:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
05/30/2022 02:25:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.92 on epoch=694
05/30/2022 02:25:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.02 on epoch=697
05/30/2022 02:25:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.90 on epoch=699
05/30/2022 02:25:13 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.07971014492753624 on epoch=699
05/30/2022 02:25:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.91 on epoch=702
05/30/2022 02:25:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.09 on epoch=704
05/30/2022 02:25:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.95 on epoch=707
05/30/2022 02:25:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.06 on epoch=709
05/30/2022 02:25:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
05/30/2022 02:25:20 - INFO - __main__ - Global step 2850 Train loss 0.98 Classification-F1 0.1865079365079365 on epoch=712
05/30/2022 02:25:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/30/2022 02:25:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.95 on epoch=717
05/30/2022 02:25:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.02 on epoch=719
05/30/2022 02:25:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/30/2022 02:25:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/30/2022 02:25:27 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.16091269841269842 on epoch=724
05/30/2022 02:25:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/30/2022 02:25:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
05/30/2022 02:25:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.93 on epoch=732
05/30/2022 02:25:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.97 on epoch=734
05/30/2022 02:25:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.91 on epoch=737
05/30/2022 02:25:34 - INFO - __main__ - Global step 2950 Train loss 0.96 Classification-F1 0.22316451664277753 on epoch=737
05/30/2022 02:25:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.97 on epoch=739
05/30/2022 02:25:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.99 on epoch=742
05/30/2022 02:25:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.01 on epoch=744
05/30/2022 02:25:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.92 on epoch=747
05/30/2022 02:25:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.98 on epoch=749
05/30/2022 02:25:40 - INFO - __main__ - Global step 3000 Train loss 0.97 Classification-F1 0.20094080338266385 on epoch=749
05/30/2022 02:25:40 - INFO - __main__ - save last model!
05/30/2022 02:25:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:25:40 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:25:40 - INFO - __main__ - Printing 3 examples
05/30/2022 02:25:40 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:25:40 - INFO - __main__ - ['others']
05/30/2022 02:25:40 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:25:40 - INFO - __main__ - ['others']
05/30/2022 02:25:40 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:25:40 - INFO - __main__ - ['others']
05/30/2022 02:25:40 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:25:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:25:41 - INFO - __main__ - Printing 3 examples
05/30/2022 02:25:41 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:25:41 - INFO - __main__ - ['happy']
05/30/2022 02:25:41 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:25:41 - INFO - __main__ - ['happy']
05/30/2022 02:25:41 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:25:41 - INFO - __main__ - ['happy']
05/30/2022 02:25:41 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:25:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:25:41 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:25:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:25:41 - INFO - __main__ - Printing 3 examples
05/30/2022 02:25:41 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:25:41 - INFO - __main__ - ['happy']
05/30/2022 02:25:41 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:25:41 - INFO - __main__ - ['happy']
05/30/2022 02:25:41 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:25:41 - INFO - __main__ - ['happy']
05/30/2022 02:25:41 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:25:41 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:25:41 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:25:43 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:25:47 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:25:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:25:47 - INFO - __main__ - Starting training!
05/30/2022 02:25:48 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:26:32 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.5_8_predictions.txt
05/30/2022 02:26:32 - INFO - __main__ - Classification-F1 on test data: 0.0681
05/30/2022 02:26:32 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.3629129129129129, test_performance=0.06813091170116173
05/30/2022 02:26:32 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
05/30/2022 02:26:33 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:26:33 - INFO - __main__ - Printing 3 examples
05/30/2022 02:26:33 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:26:33 - INFO - __main__ - ['happy']
05/30/2022 02:26:33 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:26:33 - INFO - __main__ - ['happy']
05/30/2022 02:26:33 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:26:33 - INFO - __main__ - ['happy']
05/30/2022 02:26:33 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:26:33 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:26:33 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:26:33 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:26:33 - INFO - __main__ - Printing 3 examples
05/30/2022 02:26:33 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:26:33 - INFO - __main__ - ['happy']
05/30/2022 02:26:33 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:26:33 - INFO - __main__ - ['happy']
05/30/2022 02:26:33 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:26:33 - INFO - __main__ - ['happy']
05/30/2022 02:26:33 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:26:33 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:26:33 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:26:38 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:26:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:26:38 - INFO - __main__ - Starting training!
05/30/2022 02:26:40 - INFO - __main__ - Step 10 Global step 10 Train loss 6.66 on epoch=2
05/30/2022 02:26:41 - INFO - __main__ - Step 20 Global step 20 Train loss 6.37 on epoch=4
05/30/2022 02:26:42 - INFO - __main__ - Step 30 Global step 30 Train loss 6.08 on epoch=7
05/30/2022 02:26:44 - INFO - __main__ - Step 40 Global step 40 Train loss 5.91 on epoch=9
05/30/2022 02:26:45 - INFO - __main__ - Step 50 Global step 50 Train loss 5.70 on epoch=12
05/30/2022 02:26:46 - INFO - __main__ - Global step 50 Train loss 6.14 Classification-F1 0.0 on epoch=12
05/30/2022 02:26:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:26:48 - INFO - __main__ - Step 60 Global step 60 Train loss 5.34 on epoch=14
05/30/2022 02:26:49 - INFO - __main__ - Step 70 Global step 70 Train loss 5.08 on epoch=17
05/30/2022 02:26:50 - INFO - __main__ - Step 80 Global step 80 Train loss 4.97 on epoch=19
05/30/2022 02:26:51 - INFO - __main__ - Step 90 Global step 90 Train loss 4.78 on epoch=22
05/30/2022 02:26:53 - INFO - __main__ - Step 100 Global step 100 Train loss 4.71 on epoch=24
05/30/2022 02:26:55 - INFO - __main__ - Global step 100 Train loss 4.98 Classification-F1 0.0 on epoch=24
05/30/2022 02:26:57 - INFO - __main__ - Step 110 Global step 110 Train loss 4.32 on epoch=27
05/30/2022 02:26:58 - INFO - __main__ - Step 120 Global step 120 Train loss 4.31 on epoch=29
05/30/2022 02:26:59 - INFO - __main__ - Step 130 Global step 130 Train loss 4.12 on epoch=32
05/30/2022 02:27:00 - INFO - __main__ - Step 140 Global step 140 Train loss 4.08 on epoch=34
05/30/2022 02:27:02 - INFO - __main__ - Step 150 Global step 150 Train loss 3.97 on epoch=37
05/30/2022 02:27:02 - INFO - __main__ - Global step 150 Train loss 4.16 Classification-F1 0.13624338624338622 on epoch=37
05/30/2022 02:27:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.13624338624338622 on epoch=37, global_step=150
05/30/2022 02:27:03 - INFO - __main__ - Step 160 Global step 160 Train loss 3.87 on epoch=39
05/30/2022 02:27:05 - INFO - __main__ - Step 170 Global step 170 Train loss 3.62 on epoch=42
05/30/2022 02:27:06 - INFO - __main__ - Step 180 Global step 180 Train loss 3.45 on epoch=44
05/30/2022 02:27:07 - INFO - __main__ - Step 190 Global step 190 Train loss 3.36 on epoch=47
05/30/2022 02:27:08 - INFO - __main__ - Step 200 Global step 200 Train loss 3.45 on epoch=49
05/30/2022 02:27:09 - INFO - __main__ - Global step 200 Train loss 3.55 Classification-F1 0.1565276828434723 on epoch=49
05/30/2022 02:27:09 - INFO - __main__ - Saving model with best Classification-F1: 0.13624338624338622 -> 0.1565276828434723 on epoch=49, global_step=200
05/30/2022 02:27:10 - INFO - __main__ - Step 210 Global step 210 Train loss 3.20 on epoch=52
05/30/2022 02:27:12 - INFO - __main__ - Step 220 Global step 220 Train loss 3.27 on epoch=54
05/30/2022 02:27:13 - INFO - __main__ - Step 230 Global step 230 Train loss 2.92 on epoch=57
05/30/2022 02:27:14 - INFO - __main__ - Step 240 Global step 240 Train loss 3.12 on epoch=59
05/30/2022 02:27:15 - INFO - __main__ - Step 250 Global step 250 Train loss 2.99 on epoch=62
05/30/2022 02:27:16 - INFO - __main__ - Global step 250 Train loss 3.10 Classification-F1 0.12568058076225044 on epoch=62
05/30/2022 02:27:17 - INFO - __main__ - Step 260 Global step 260 Train loss 3.07 on epoch=64
05/30/2022 02:27:18 - INFO - __main__ - Step 270 Global step 270 Train loss 2.78 on epoch=67
05/30/2022 02:27:20 - INFO - __main__ - Step 280 Global step 280 Train loss 2.87 on epoch=69
05/30/2022 02:27:21 - INFO - __main__ - Step 290 Global step 290 Train loss 2.64 on epoch=72
05/30/2022 02:27:22 - INFO - __main__ - Step 300 Global step 300 Train loss 2.77 on epoch=74
05/30/2022 02:27:23 - INFO - __main__ - Global step 300 Train loss 2.83 Classification-F1 0.13347763347763347 on epoch=74
05/30/2022 02:27:24 - INFO - __main__ - Step 310 Global step 310 Train loss 2.53 on epoch=77
05/30/2022 02:27:25 - INFO - __main__ - Step 320 Global step 320 Train loss 2.54 on epoch=79
05/30/2022 02:27:27 - INFO - __main__ - Step 330 Global step 330 Train loss 2.50 on epoch=82
05/30/2022 02:27:28 - INFO - __main__ - Step 340 Global step 340 Train loss 2.28 on epoch=84
05/30/2022 02:27:29 - INFO - __main__ - Step 350 Global step 350 Train loss 2.42 on epoch=87
05/30/2022 02:27:30 - INFO - __main__ - Global step 350 Train loss 2.45 Classification-F1 0.1659804426145136 on epoch=87
05/30/2022 02:27:30 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.1659804426145136 on epoch=87, global_step=350
05/30/2022 02:27:31 - INFO - __main__ - Step 360 Global step 360 Train loss 2.36 on epoch=89
05/30/2022 02:27:32 - INFO - __main__ - Step 370 Global step 370 Train loss 2.36 on epoch=92
05/30/2022 02:27:33 - INFO - __main__ - Step 380 Global step 380 Train loss 2.44 on epoch=94
05/30/2022 02:27:35 - INFO - __main__ - Step 390 Global step 390 Train loss 2.11 on epoch=97
05/30/2022 02:27:36 - INFO - __main__ - Step 400 Global step 400 Train loss 2.42 on epoch=99
05/30/2022 02:27:36 - INFO - __main__ - Global step 400 Train loss 2.34 Classification-F1 0.13034188034188032 on epoch=99
05/30/2022 02:27:38 - INFO - __main__ - Step 410 Global step 410 Train loss 2.21 on epoch=102
05/30/2022 02:27:39 - INFO - __main__ - Step 420 Global step 420 Train loss 2.29 on epoch=104
05/30/2022 02:27:40 - INFO - __main__ - Step 430 Global step 430 Train loss 2.11 on epoch=107
05/30/2022 02:27:41 - INFO - __main__ - Step 440 Global step 440 Train loss 2.18 on epoch=109
05/30/2022 02:27:43 - INFO - __main__ - Step 450 Global step 450 Train loss 1.90 on epoch=112
05/30/2022 02:27:43 - INFO - __main__ - Global step 450 Train loss 2.14 Classification-F1 0.1576923076923077 on epoch=112
05/30/2022 02:27:45 - INFO - __main__ - Step 460 Global step 460 Train loss 2.14 on epoch=114
05/30/2022 02:27:46 - INFO - __main__ - Step 470 Global step 470 Train loss 1.90 on epoch=117
05/30/2022 02:27:47 - INFO - __main__ - Step 480 Global step 480 Train loss 1.96 on epoch=119
05/30/2022 02:27:48 - INFO - __main__ - Step 490 Global step 490 Train loss 1.71 on epoch=122
05/30/2022 02:27:50 - INFO - __main__ - Step 500 Global step 500 Train loss 1.92 on epoch=124
05/30/2022 02:27:50 - INFO - __main__ - Global step 500 Train loss 1.93 Classification-F1 0.13067758749069247 on epoch=124
05/30/2022 02:27:51 - INFO - __main__ - Step 510 Global step 510 Train loss 1.66 on epoch=127
05/30/2022 02:27:53 - INFO - __main__ - Step 520 Global step 520 Train loss 1.67 on epoch=129
05/30/2022 02:27:54 - INFO - __main__ - Step 530 Global step 530 Train loss 1.61 on epoch=132
05/30/2022 02:27:55 - INFO - __main__ - Step 540 Global step 540 Train loss 1.78 on epoch=134
05/30/2022 02:27:56 - INFO - __main__ - Step 550 Global step 550 Train loss 1.53 on epoch=137
05/30/2022 02:27:57 - INFO - __main__ - Global step 550 Train loss 1.65 Classification-F1 0.14915966386554622 on epoch=137
05/30/2022 02:27:58 - INFO - __main__ - Step 560 Global step 560 Train loss 1.57 on epoch=139
05/30/2022 02:27:59 - INFO - __main__ - Step 570 Global step 570 Train loss 1.67 on epoch=142
05/30/2022 02:28:01 - INFO - __main__ - Step 580 Global step 580 Train loss 1.52 on epoch=144
05/30/2022 02:28:02 - INFO - __main__ - Step 590 Global step 590 Train loss 1.51 on epoch=147
05/30/2022 02:28:03 - INFO - __main__ - Step 600 Global step 600 Train loss 1.46 on epoch=149
05/30/2022 02:28:04 - INFO - __main__ - Global step 600 Train loss 1.55 Classification-F1 0.16377171215880895 on epoch=149
05/30/2022 02:28:05 - INFO - __main__ - Step 610 Global step 610 Train loss 1.51 on epoch=152
05/30/2022 02:28:06 - INFO - __main__ - Step 620 Global step 620 Train loss 1.49 on epoch=154
05/30/2022 02:28:08 - INFO - __main__ - Step 630 Global step 630 Train loss 1.63 on epoch=157
05/30/2022 02:28:09 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=159
05/30/2022 02:28:10 - INFO - __main__ - Step 650 Global step 650 Train loss 1.55 on epoch=162
05/30/2022 02:28:11 - INFO - __main__ - Global step 650 Train loss 1.52 Classification-F1 0.13275613275613274 on epoch=162
05/30/2022 02:28:12 - INFO - __main__ - Step 660 Global step 660 Train loss 1.56 on epoch=164
05/30/2022 02:28:13 - INFO - __main__ - Step 670 Global step 670 Train loss 1.48 on epoch=167
05/30/2022 02:28:15 - INFO - __main__ - Step 680 Global step 680 Train loss 1.50 on epoch=169
05/30/2022 02:28:16 - INFO - __main__ - Step 690 Global step 690 Train loss 1.49 on epoch=172
05/30/2022 02:28:17 - INFO - __main__ - Step 700 Global step 700 Train loss 1.45 on epoch=174
05/30/2022 02:28:18 - INFO - __main__ - Global step 700 Train loss 1.50 Classification-F1 0.13936867182846935 on epoch=174
05/30/2022 02:28:19 - INFO - __main__ - Step 710 Global step 710 Train loss 1.37 on epoch=177
05/30/2022 02:28:20 - INFO - __main__ - Step 720 Global step 720 Train loss 1.45 on epoch=179
05/30/2022 02:28:21 - INFO - __main__ - Step 730 Global step 730 Train loss 1.50 on epoch=182
05/30/2022 02:28:22 - INFO - __main__ - Step 740 Global step 740 Train loss 1.48 on epoch=184
05/30/2022 02:28:24 - INFO - __main__ - Step 750 Global step 750 Train loss 1.46 on epoch=187
05/30/2022 02:28:24 - INFO - __main__ - Global step 750 Train loss 1.45 Classification-F1 0.1 on epoch=187
05/30/2022 02:28:25 - INFO - __main__ - Step 760 Global step 760 Train loss 1.44 on epoch=189
05/30/2022 02:28:27 - INFO - __main__ - Step 770 Global step 770 Train loss 1.62 on epoch=192
05/30/2022 02:28:28 - INFO - __main__ - Step 780 Global step 780 Train loss 1.52 on epoch=194
05/30/2022 02:28:29 - INFO - __main__ - Step 790 Global step 790 Train loss 1.41 on epoch=197
05/30/2022 02:28:30 - INFO - __main__ - Step 800 Global step 800 Train loss 1.38 on epoch=199
05/30/2022 02:28:31 - INFO - __main__ - Global step 800 Train loss 1.47 Classification-F1 0.15607940446650126 on epoch=199
05/30/2022 02:28:32 - INFO - __main__ - Step 810 Global step 810 Train loss 1.44 on epoch=202
05/30/2022 02:28:33 - INFO - __main__ - Step 820 Global step 820 Train loss 1.48 on epoch=204
05/30/2022 02:28:35 - INFO - __main__ - Step 830 Global step 830 Train loss 1.39 on epoch=207
05/30/2022 02:28:36 - INFO - __main__ - Step 840 Global step 840 Train loss 1.37 on epoch=209
05/30/2022 02:28:37 - INFO - __main__ - Step 850 Global step 850 Train loss 1.23 on epoch=212
05/30/2022 02:28:37 - INFO - __main__ - Global step 850 Train loss 1.38 Classification-F1 0.12194223401119952 on epoch=212
05/30/2022 02:28:39 - INFO - __main__ - Step 860 Global step 860 Train loss 1.27 on epoch=214
05/30/2022 02:28:40 - INFO - __main__ - Step 870 Global step 870 Train loss 1.34 on epoch=217
05/30/2022 02:28:41 - INFO - __main__ - Step 880 Global step 880 Train loss 1.33 on epoch=219
05/30/2022 02:28:42 - INFO - __main__ - Step 890 Global step 890 Train loss 1.31 on epoch=222
05/30/2022 02:28:44 - INFO - __main__ - Step 900 Global step 900 Train loss 1.45 on epoch=224
05/30/2022 02:28:44 - INFO - __main__ - Global step 900 Train loss 1.34 Classification-F1 0.14179439381386358 on epoch=224
05/30/2022 02:28:45 - INFO - __main__ - Step 910 Global step 910 Train loss 1.30 on epoch=227
05/30/2022 02:28:47 - INFO - __main__ - Step 920 Global step 920 Train loss 1.29 on epoch=229
05/30/2022 02:28:48 - INFO - __main__ - Step 930 Global step 930 Train loss 1.40 on epoch=232
05/30/2022 02:28:49 - INFO - __main__ - Step 940 Global step 940 Train loss 1.23 on epoch=234
05/30/2022 02:28:51 - INFO - __main__ - Step 950 Global step 950 Train loss 1.26 on epoch=237
05/30/2022 02:28:51 - INFO - __main__ - Global step 950 Train loss 1.29 Classification-F1 0.18161263800798685 on epoch=237
05/30/2022 02:28:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1659804426145136 -> 0.18161263800798685 on epoch=237, global_step=950
05/30/2022 02:28:52 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/30/2022 02:28:54 - INFO - __main__ - Step 970 Global step 970 Train loss 1.17 on epoch=242
05/30/2022 02:28:55 - INFO - __main__ - Step 980 Global step 980 Train loss 1.37 on epoch=244
05/30/2022 02:28:56 - INFO - __main__ - Step 990 Global step 990 Train loss 1.29 on epoch=247
05/30/2022 02:28:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.33 on epoch=249
05/30/2022 02:28:58 - INFO - __main__ - Global step 1000 Train loss 1.29 Classification-F1 0.13034188034188032 on epoch=249
05/30/2022 02:28:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.31 on epoch=252
05/30/2022 02:29:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.26 on epoch=254
05/30/2022 02:29:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.30 on epoch=257
05/30/2022 02:29:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.30 on epoch=259
05/30/2022 02:29:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.15 on epoch=262
05/30/2022 02:29:04 - INFO - __main__ - Global step 1050 Train loss 1.26 Classification-F1 0.1715492957746479 on epoch=262
05/30/2022 02:29:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.27 on epoch=264
05/30/2022 02:29:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.13 on epoch=267
05/30/2022 02:29:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=269
05/30/2022 02:29:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.15 on epoch=272
05/30/2022 02:29:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.19 on epoch=274
05/30/2022 02:29:11 - INFO - __main__ - Global step 1100 Train loss 1.17 Classification-F1 0.18166666666666667 on epoch=274
05/30/2022 02:29:11 - INFO - __main__ - Saving model with best Classification-F1: 0.18161263800798685 -> 0.18166666666666667 on epoch=274, global_step=1100
05/30/2022 02:29:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.22 on epoch=277
05/30/2022 02:29:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.30 on epoch=279
05/30/2022 02:29:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.14 on epoch=282
05/30/2022 02:29:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.25 on epoch=284
05/30/2022 02:29:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.25 on epoch=287
05/30/2022 02:29:18 - INFO - __main__ - Global step 1150 Train loss 1.23 Classification-F1 0.1970899470899471 on epoch=287
05/30/2022 02:29:18 - INFO - __main__ - Saving model with best Classification-F1: 0.18166666666666667 -> 0.1970899470899471 on epoch=287, global_step=1150
05/30/2022 02:29:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.21 on epoch=289
05/30/2022 02:29:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.13 on epoch=292
05/30/2022 02:29:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.23 on epoch=294
05/30/2022 02:29:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.08 on epoch=297
05/30/2022 02:29:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.27 on epoch=299
05/30/2022 02:29:25 - INFO - __main__ - Global step 1200 Train loss 1.19 Classification-F1 0.15625 on epoch=299
05/30/2022 02:29:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.23 on epoch=302
05/30/2022 02:29:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.20 on epoch=304
05/30/2022 02:29:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.13 on epoch=307
05/30/2022 02:29:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.14 on epoch=309
05/30/2022 02:29:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.22 on epoch=312
05/30/2022 02:29:31 - INFO - __main__ - Global step 1250 Train loss 1.18 Classification-F1 0.1527777777777778 on epoch=312
05/30/2022 02:29:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.23 on epoch=314
05/30/2022 02:29:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.26 on epoch=317
05/30/2022 02:29:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=319
05/30/2022 02:29:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.16 on epoch=322
05/30/2022 02:29:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.05 on epoch=324
05/30/2022 02:29:38 - INFO - __main__ - Global step 1300 Train loss 1.17 Classification-F1 0.10126582278481013 on epoch=324
05/30/2022 02:29:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.03 on epoch=327
05/30/2022 02:29:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.11 on epoch=329
05/30/2022 02:29:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.19 on epoch=332
05/30/2022 02:29:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.22 on epoch=334
05/30/2022 02:29:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.24 on epoch=337
05/30/2022 02:29:45 - INFO - __main__ - Global step 1350 Train loss 1.16 Classification-F1 0.1 on epoch=337
05/30/2022 02:29:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.13 on epoch=339
05/30/2022 02:29:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.19 on epoch=342
05/30/2022 02:29:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.24 on epoch=344
05/30/2022 02:29:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.26 on epoch=347
05/30/2022 02:29:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.99 on epoch=349
05/30/2022 02:29:51 - INFO - __main__ - Global step 1400 Train loss 1.16 Classification-F1 0.13067758749069247 on epoch=349
05/30/2022 02:29:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.06 on epoch=352
05/30/2022 02:29:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/30/2022 02:29:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.12 on epoch=357
05/30/2022 02:29:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.03 on epoch=359
05/30/2022 02:29:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.09 on epoch=362
05/30/2022 02:29:58 - INFO - __main__ - Global step 1450 Train loss 1.06 Classification-F1 0.10256410256410256 on epoch=362
05/30/2022 02:29:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/30/2022 02:30:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.09 on epoch=367
05/30/2022 02:30:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.16 on epoch=369
05/30/2022 02:30:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=372
05/30/2022 02:30:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=374
05/30/2022 02:30:05 - INFO - __main__ - Global step 1500 Train loss 1.15 Classification-F1 0.20842474769635805 on epoch=374
05/30/2022 02:30:05 - INFO - __main__ - Saving model with best Classification-F1: 0.1970899470899471 -> 0.20842474769635805 on epoch=374, global_step=1500
05/30/2022 02:30:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.03 on epoch=377
05/30/2022 02:30:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.13 on epoch=379
05/30/2022 02:30:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.10 on epoch=382
05/30/2022 02:30:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.02 on epoch=384
05/30/2022 02:30:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.00 on epoch=387
05/30/2022 02:30:11 - INFO - __main__ - Global step 1550 Train loss 1.06 Classification-F1 0.1875 on epoch=387
05/30/2022 02:30:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.11 on epoch=389
05/30/2022 02:30:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.08 on epoch=392
05/30/2022 02:30:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.02 on epoch=394
05/30/2022 02:30:16 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.06 on epoch=397
05/30/2022 02:30:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.01 on epoch=399
05/30/2022 02:30:18 - INFO - __main__ - Global step 1600 Train loss 1.06 Classification-F1 0.17341430499325233 on epoch=399
05/30/2022 02:30:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.07 on epoch=402
05/30/2022 02:30:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.10 on epoch=404
05/30/2022 02:30:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.88 on epoch=407
05/30/2022 02:30:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.06 on epoch=409
05/30/2022 02:30:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.05 on epoch=412
05/30/2022 02:30:25 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.21765734265734268 on epoch=412
05/30/2022 02:30:25 - INFO - __main__ - Saving model with best Classification-F1: 0.20842474769635805 -> 0.21765734265734268 on epoch=412, global_step=1650
05/30/2022 02:30:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.16 on epoch=414
05/30/2022 02:30:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/30/2022 02:30:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.01 on epoch=419
05/30/2022 02:30:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.09 on epoch=422
05/30/2022 02:30:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.09 on epoch=424
05/30/2022 02:30:31 - INFO - __main__ - Global step 1700 Train loss 1.08 Classification-F1 0.11710526315789474 on epoch=424
05/30/2022 02:30:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.05 on epoch=427
05/30/2022 02:30:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.10 on epoch=429
05/30/2022 02:30:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.10 on epoch=432
05/30/2022 02:30:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.02 on epoch=434
05/30/2022 02:30:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.03 on epoch=437
05/30/2022 02:30:38 - INFO - __main__ - Global step 1750 Train loss 1.06 Classification-F1 0.1 on epoch=437
05/30/2022 02:30:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.07 on epoch=439
05/30/2022 02:30:40 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=442
05/30/2022 02:30:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/30/2022 02:30:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.01 on epoch=447
05/30/2022 02:30:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=449
05/30/2022 02:30:45 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.1 on epoch=449
05/30/2022 02:30:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
05/30/2022 02:30:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/30/2022 02:30:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.89 on epoch=457
05/30/2022 02:30:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.06 on epoch=459
05/30/2022 02:30:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.08 on epoch=462
05/30/2022 02:30:51 - INFO - __main__ - Global step 1850 Train loss 1.04 Classification-F1 0.14004914004914004 on epoch=462
05/30/2022 02:30:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.07 on epoch=464
05/30/2022 02:30:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.99 on epoch=467
05/30/2022 02:30:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.95 on epoch=469
05/30/2022 02:30:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.96 on epoch=472
05/30/2022 02:30:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.02 on epoch=474
05/30/2022 02:30:58 - INFO - __main__ - Global step 1900 Train loss 1.00 Classification-F1 0.1 on epoch=474
05/30/2022 02:30:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.05 on epoch=477
05/30/2022 02:31:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=479
05/30/2022 02:31:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=482
05/30/2022 02:31:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.15 on epoch=484
05/30/2022 02:31:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.14 on epoch=487
05/30/2022 02:31:05 - INFO - __main__ - Global step 1950 Train loss 1.07 Classification-F1 0.1843681917211329 on epoch=487
05/30/2022 02:31:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.99 on epoch=489
05/30/2022 02:31:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.98 on epoch=492
05/30/2022 02:31:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.92 on epoch=494
05/30/2022 02:31:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.05 on epoch=497
05/30/2022 02:31:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.97 on epoch=499
05/30/2022 02:31:11 - INFO - __main__ - Global step 2000 Train loss 0.98 Classification-F1 0.13047619047619047 on epoch=499
05/30/2022 02:31:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.05 on epoch=502
05/30/2022 02:31:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.04 on epoch=504
05/30/2022 02:31:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
05/30/2022 02:31:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.92 on epoch=509
05/30/2022 02:31:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.20 on epoch=512
05/30/2022 02:31:18 - INFO - __main__ - Global step 2050 Train loss 1.04 Classification-F1 0.1 on epoch=512
05/30/2022 02:31:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=514
05/30/2022 02:31:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=517
05/30/2022 02:31:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.92 on epoch=519
05/30/2022 02:31:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.06 on epoch=522
05/30/2022 02:31:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.97 on epoch=524
05/30/2022 02:31:25 - INFO - __main__ - Global step 2100 Train loss 1.01 Classification-F1 0.15054945054945054 on epoch=524
05/30/2022 02:31:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.92 on epoch=527
05/30/2022 02:31:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.08 on epoch=529
05/30/2022 02:31:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.04 on epoch=532
05/30/2022 02:31:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.94 on epoch=534
05/30/2022 02:31:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.05 on epoch=537
05/30/2022 02:31:32 - INFO - __main__ - Global step 2150 Train loss 1.00 Classification-F1 0.14621798689696247 on epoch=537
05/30/2022 02:31:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.94 on epoch=539
05/30/2022 02:31:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.20 on epoch=542
05/30/2022 02:31:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=544
05/30/2022 02:31:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.08 on epoch=547
05/30/2022 02:31:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=549
05/30/2022 02:31:38 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.16061705989110708 on epoch=549
05/30/2022 02:31:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.01 on epoch=552
05/30/2022 02:31:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=554
05/30/2022 02:31:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.00 on epoch=557
05/30/2022 02:31:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/30/2022 02:31:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.06 on epoch=562
05/30/2022 02:31:45 - INFO - __main__ - Global step 2250 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=562
05/30/2022 02:31:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.01 on epoch=564
05/30/2022 02:31:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.96 on epoch=567
05/30/2022 02:31:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.04 on epoch=569
05/30/2022 02:31:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.03 on epoch=572
05/30/2022 02:31:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=574
05/30/2022 02:31:52 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=574
05/30/2022 02:31:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.04 on epoch=577
05/30/2022 02:31:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=579
05/30/2022 02:31:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.01 on epoch=582
05/30/2022 02:31:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.91 on epoch=584
05/30/2022 02:31:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/30/2022 02:31:58 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.14791288566243194 on epoch=587
05/30/2022 02:32:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.89 on epoch=589
05/30/2022 02:32:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.90 on epoch=592
05/30/2022 02:32:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.92 on epoch=594
05/30/2022 02:32:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.09 on epoch=597
05/30/2022 02:32:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/30/2022 02:32:05 - INFO - __main__ - Global step 2400 Train loss 0.96 Classification-F1 0.1 on epoch=599
05/30/2022 02:32:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.92 on epoch=602
05/30/2022 02:32:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=604
05/30/2022 02:32:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.95 on epoch=607
05/30/2022 02:32:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/30/2022 02:32:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=612
05/30/2022 02:32:12 - INFO - __main__ - Global step 2450 Train loss 0.99 Classification-F1 0.10135135135135136 on epoch=612
05/30/2022 02:32:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=614
05/30/2022 02:32:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.99 on epoch=617
05/30/2022 02:32:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.00 on epoch=619
05/30/2022 02:32:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/30/2022 02:32:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.01 on epoch=624
05/30/2022 02:32:18 - INFO - __main__ - Global step 2500 Train loss 1.00 Classification-F1 0.18407494145199066 on epoch=624
05/30/2022 02:32:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.97 on epoch=627
05/30/2022 02:32:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.96 on epoch=629
05/30/2022 02:32:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.99 on epoch=632
05/30/2022 02:32:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.87 on epoch=634
05/30/2022 02:32:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.90 on epoch=637
05/30/2022 02:32:25 - INFO - __main__ - Global step 2550 Train loss 0.94 Classification-F1 0.1774628879892038 on epoch=637
05/30/2022 02:32:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.08 on epoch=639
05/30/2022 02:32:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.99 on epoch=642
05/30/2022 02:32:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.98 on epoch=644
05/30/2022 02:32:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
05/30/2022 02:32:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/30/2022 02:32:32 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.1 on epoch=649
05/30/2022 02:32:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.93 on epoch=652
05/30/2022 02:32:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.96 on epoch=654
05/30/2022 02:32:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.95 on epoch=657
05/30/2022 02:32:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.01 on epoch=659
05/30/2022 02:32:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.85 on epoch=662
05/30/2022 02:32:38 - INFO - __main__ - Global step 2650 Train loss 0.94 Classification-F1 0.1 on epoch=662
05/30/2022 02:32:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.99 on epoch=664
05/30/2022 02:32:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.99 on epoch=667
05/30/2022 02:32:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.95 on epoch=669
05/30/2022 02:32:43 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.94 on epoch=672
05/30/2022 02:32:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
05/30/2022 02:32:45 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
05/30/2022 02:32:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.93 on epoch=677
05/30/2022 02:32:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.96 on epoch=679
05/30/2022 02:32:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/30/2022 02:32:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=684
05/30/2022 02:32:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.94 on epoch=687
05/30/2022 02:32:52 - INFO - __main__ - Global step 2750 Train loss 0.96 Classification-F1 0.09090909090909091 on epoch=687
05/30/2022 02:32:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.04 on epoch=689
05/30/2022 02:32:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.01 on epoch=692
05/30/2022 02:32:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.04 on epoch=694
05/30/2022 02:32:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.01 on epoch=697
05/30/2022 02:32:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=699
05/30/2022 02:32:58 - INFO - __main__ - Global step 2800 Train loss 1.02 Classification-F1 0.12368421052631579 on epoch=699
05/30/2022 02:33:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.06 on epoch=702
05/30/2022 02:33:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.92 on epoch=704
05/30/2022 02:33:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.86 on epoch=707
05/30/2022 02:33:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/30/2022 02:33:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.03 on epoch=712
05/30/2022 02:33:05 - INFO - __main__ - Global step 2850 Train loss 0.96 Classification-F1 0.10389610389610389 on epoch=712
05/30/2022 02:33:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/30/2022 02:33:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.94 on epoch=717
05/30/2022 02:33:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.99 on epoch=719
05/30/2022 02:33:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.99 on epoch=722
05/30/2022 02:33:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.00 on epoch=724
05/30/2022 02:33:12 - INFO - __main__ - Global step 2900 Train loss 0.98 Classification-F1 0.09493670886075949 on epoch=724
05/30/2022 02:33:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.85 on epoch=727
05/30/2022 02:33:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.01 on epoch=729
05/30/2022 02:33:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=732
05/30/2022 02:33:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/30/2022 02:33:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.92 on epoch=737
05/30/2022 02:33:18 - INFO - __main__ - Global step 2950 Train loss 0.93 Classification-F1 0.1 on epoch=737
05/30/2022 02:33:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.90 on epoch=739
05/30/2022 02:33:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.94 on epoch=742
05/30/2022 02:33:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.00 on epoch=744
05/30/2022 02:33:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.01 on epoch=747
05/30/2022 02:33:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/30/2022 02:33:25 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.1 on epoch=749
05/30/2022 02:33:25 - INFO - __main__ - save last model!
05/30/2022 02:33:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:33:25 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:33:25 - INFO - __main__ - Printing 3 examples
05/30/2022 02:33:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:33:25 - INFO - __main__ - ['others']
05/30/2022 02:33:25 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:33:25 - INFO - __main__ - ['others']
05/30/2022 02:33:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:33:25 - INFO - __main__ - ['others']
05/30/2022 02:33:25 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:33:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:33:26 - INFO - __main__ - Printing 3 examples
05/30/2022 02:33:26 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:33:26 - INFO - __main__ - ['happy']
05/30/2022 02:33:26 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:33:26 - INFO - __main__ - ['happy']
05/30/2022 02:33:26 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:33:26 - INFO - __main__ - ['happy']
05/30/2022 02:33:26 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:33:26 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:33:26 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:33:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:33:26 - INFO - __main__ - Printing 3 examples
05/30/2022 02:33:26 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:33:26 - INFO - __main__ - ['happy']
05/30/2022 02:33:26 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:33:26 - INFO - __main__ - ['happy']
05/30/2022 02:33:26 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:33:26 - INFO - __main__ - ['happy']
05/30/2022 02:33:26 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:33:26 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:33:26 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:33:28 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:33:32 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:33:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:33:32 - INFO - __main__ - Starting training!
05/30/2022 02:33:33 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:34:16 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.4_8_predictions.txt
05/30/2022 02:34:16 - INFO - __main__ - Classification-F1 on test data: 0.0332
05/30/2022 02:34:17 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.21765734265734268, test_performance=0.03324837737583468
05/30/2022 02:34:17 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
05/30/2022 02:34:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:34:18 - INFO - __main__ - Printing 3 examples
05/30/2022 02:34:18 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:34:18 - INFO - __main__ - ['happy']
05/30/2022 02:34:18 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:34:18 - INFO - __main__ - ['happy']
05/30/2022 02:34:18 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:34:18 - INFO - __main__ - ['happy']
05/30/2022 02:34:18 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:34:18 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:34:18 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:34:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:34:18 - INFO - __main__ - Printing 3 examples
05/30/2022 02:34:18 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:34:18 - INFO - __main__ - ['happy']
05/30/2022 02:34:18 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:34:18 - INFO - __main__ - ['happy']
05/30/2022 02:34:18 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:34:18 - INFO - __main__ - ['happy']
05/30/2022 02:34:18 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:34:18 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:34:18 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:34:23 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:34:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:34:23 - INFO - __main__ - Starting training!
05/30/2022 02:34:25 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=2
05/30/2022 02:34:26 - INFO - __main__ - Step 20 Global step 20 Train loss 6.42 on epoch=4
05/30/2022 02:34:27 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=7
05/30/2022 02:34:28 - INFO - __main__ - Step 40 Global step 40 Train loss 6.17 on epoch=9
05/30/2022 02:34:30 - INFO - __main__ - Step 50 Global step 50 Train loss 6.12 on epoch=12
05/30/2022 02:34:34 - INFO - __main__ - Global step 50 Train loss 6.37 Classification-F1 0.0 on epoch=12
05/30/2022 02:34:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:34:35 - INFO - __main__ - Step 60 Global step 60 Train loss 5.97 on epoch=14
05/30/2022 02:34:36 - INFO - __main__ - Step 70 Global step 70 Train loss 5.74 on epoch=17
05/30/2022 02:34:37 - INFO - __main__ - Step 80 Global step 80 Train loss 5.52 on epoch=19
05/30/2022 02:34:39 - INFO - __main__ - Step 90 Global step 90 Train loss 5.44 on epoch=22
05/30/2022 02:34:40 - INFO - __main__ - Step 100 Global step 100 Train loss 5.18 on epoch=24
05/30/2022 02:34:41 - INFO - __main__ - Global step 100 Train loss 5.57 Classification-F1 0.0 on epoch=24
05/30/2022 02:34:43 - INFO - __main__ - Step 110 Global step 110 Train loss 5.20 on epoch=27
05/30/2022 02:34:44 - INFO - __main__ - Step 120 Global step 120 Train loss 4.90 on epoch=29
05/30/2022 02:34:45 - INFO - __main__ - Step 130 Global step 130 Train loss 4.80 on epoch=32
05/30/2022 02:34:46 - INFO - __main__ - Step 140 Global step 140 Train loss 4.58 on epoch=34
05/30/2022 02:34:48 - INFO - __main__ - Step 150 Global step 150 Train loss 4.52 on epoch=37
05/30/2022 02:34:49 - INFO - __main__ - Global step 150 Train loss 4.80 Classification-F1 0.02886002886002886 on epoch=37
05/30/2022 02:34:49 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.02886002886002886 on epoch=37, global_step=150
05/30/2022 02:34:50 - INFO - __main__ - Step 160 Global step 160 Train loss 4.26 on epoch=39
05/30/2022 02:34:51 - INFO - __main__ - Step 170 Global step 170 Train loss 4.23 on epoch=42
05/30/2022 02:34:53 - INFO - __main__ - Step 180 Global step 180 Train loss 4.15 on epoch=44
05/30/2022 02:34:54 - INFO - __main__ - Step 190 Global step 190 Train loss 4.00 on epoch=47
05/30/2022 02:34:55 - INFO - __main__ - Step 200 Global step 200 Train loss 3.90 on epoch=49
05/30/2022 02:34:56 - INFO - __main__ - Global step 200 Train loss 4.11 Classification-F1 0.07792207792207792 on epoch=49
05/30/2022 02:34:56 - INFO - __main__ - Saving model with best Classification-F1: 0.02886002886002886 -> 0.07792207792207792 on epoch=49, global_step=200
05/30/2022 02:34:57 - INFO - __main__ - Step 210 Global step 210 Train loss 3.61 on epoch=52
05/30/2022 02:34:58 - INFO - __main__ - Step 220 Global step 220 Train loss 3.62 on epoch=54
05/30/2022 02:34:59 - INFO - __main__ - Step 230 Global step 230 Train loss 3.43 on epoch=57
05/30/2022 02:35:01 - INFO - __main__ - Step 240 Global step 240 Train loss 3.45 on epoch=59
05/30/2022 02:35:02 - INFO - __main__ - Step 250 Global step 250 Train loss 3.14 on epoch=62
05/30/2022 02:35:03 - INFO - __main__ - Global step 250 Train loss 3.45 Classification-F1 0.17344312918167784 on epoch=62
05/30/2022 02:35:03 - INFO - __main__ - Saving model with best Classification-F1: 0.07792207792207792 -> 0.17344312918167784 on epoch=62, global_step=250
05/30/2022 02:35:04 - INFO - __main__ - Step 260 Global step 260 Train loss 3.21 on epoch=64
05/30/2022 02:35:05 - INFO - __main__ - Step 270 Global step 270 Train loss 3.26 on epoch=67
05/30/2022 02:35:06 - INFO - __main__ - Step 280 Global step 280 Train loss 3.07 on epoch=69
05/30/2022 02:35:08 - INFO - __main__ - Step 290 Global step 290 Train loss 3.02 on epoch=72
05/30/2022 02:35:09 - INFO - __main__ - Step 300 Global step 300 Train loss 3.02 on epoch=74
05/30/2022 02:35:09 - INFO - __main__ - Global step 300 Train loss 3.11 Classification-F1 0.1 on epoch=74
05/30/2022 02:35:11 - INFO - __main__ - Step 310 Global step 310 Train loss 2.81 on epoch=77
05/30/2022 02:35:12 - INFO - __main__ - Step 320 Global step 320 Train loss 2.90 on epoch=79
05/30/2022 02:35:13 - INFO - __main__ - Step 330 Global step 330 Train loss 2.69 on epoch=82
05/30/2022 02:35:15 - INFO - __main__ - Step 340 Global step 340 Train loss 2.80 on epoch=84
05/30/2022 02:35:16 - INFO - __main__ - Step 350 Global step 350 Train loss 2.67 on epoch=87
05/30/2022 02:35:16 - INFO - __main__ - Global step 350 Train loss 2.77 Classification-F1 0.1468058968058968 on epoch=87
05/30/2022 02:35:18 - INFO - __main__ - Step 360 Global step 360 Train loss 2.69 on epoch=89
05/30/2022 02:35:19 - INFO - __main__ - Step 370 Global step 370 Train loss 2.63 on epoch=92
05/30/2022 02:35:20 - INFO - __main__ - Step 380 Global step 380 Train loss 2.80 on epoch=94
05/30/2022 02:35:21 - INFO - __main__ - Step 390 Global step 390 Train loss 2.21 on epoch=97
05/30/2022 02:35:23 - INFO - __main__ - Step 400 Global step 400 Train loss 2.62 on epoch=99
05/30/2022 02:35:23 - INFO - __main__ - Global step 400 Train loss 2.59 Classification-F1 0.16483516483516486 on epoch=99
05/30/2022 02:35:24 - INFO - __main__ - Step 410 Global step 410 Train loss 2.41 on epoch=102
05/30/2022 02:35:26 - INFO - __main__ - Step 420 Global step 420 Train loss 2.40 on epoch=104
05/30/2022 02:35:27 - INFO - __main__ - Step 430 Global step 430 Train loss 2.27 on epoch=107
05/30/2022 02:35:28 - INFO - __main__ - Step 440 Global step 440 Train loss 2.39 on epoch=109
05/30/2022 02:35:30 - INFO - __main__ - Step 450 Global step 450 Train loss 2.44 on epoch=112
05/30/2022 02:35:30 - INFO - __main__ - Global step 450 Train loss 2.38 Classification-F1 0.15682382133995038 on epoch=112
05/30/2022 02:35:31 - INFO - __main__ - Step 460 Global step 460 Train loss 2.49 on epoch=114
05/30/2022 02:35:33 - INFO - __main__ - Step 470 Global step 470 Train loss 2.40 on epoch=117
05/30/2022 02:35:34 - INFO - __main__ - Step 480 Global step 480 Train loss 2.34 on epoch=119
05/30/2022 02:35:35 - INFO - __main__ - Step 490 Global step 490 Train loss 2.20 on epoch=122
05/30/2022 02:35:36 - INFO - __main__ - Step 500 Global step 500 Train loss 2.17 on epoch=124
05/30/2022 02:35:37 - INFO - __main__ - Global step 500 Train loss 2.32 Classification-F1 0.17317073170731706 on epoch=124
05/30/2022 02:35:38 - INFO - __main__ - Step 510 Global step 510 Train loss 2.39 on epoch=127
05/30/2022 02:35:39 - INFO - __main__ - Step 520 Global step 520 Train loss 2.21 on epoch=129
05/30/2022 02:35:41 - INFO - __main__ - Step 530 Global step 530 Train loss 2.10 on epoch=132
05/30/2022 02:35:42 - INFO - __main__ - Step 540 Global step 540 Train loss 2.25 on epoch=134
05/30/2022 02:35:43 - INFO - __main__ - Step 550 Global step 550 Train loss 1.81 on epoch=137
05/30/2022 02:35:44 - INFO - __main__ - Global step 550 Train loss 2.15 Classification-F1 0.15559772296015179 on epoch=137
05/30/2022 02:35:45 - INFO - __main__ - Step 560 Global step 560 Train loss 2.09 on epoch=139
05/30/2022 02:35:46 - INFO - __main__ - Step 570 Global step 570 Train loss 2.03 on epoch=142
05/30/2022 02:35:47 - INFO - __main__ - Step 580 Global step 580 Train loss 2.17 on epoch=144
05/30/2022 02:35:49 - INFO - __main__ - Step 590 Global step 590 Train loss 2.10 on epoch=147
05/30/2022 02:35:50 - INFO - __main__ - Step 600 Global step 600 Train loss 2.06 on epoch=149
05/30/2022 02:35:51 - INFO - __main__ - Global step 600 Train loss 2.09 Classification-F1 0.17372070779531323 on epoch=149
05/30/2022 02:35:51 - INFO - __main__ - Saving model with best Classification-F1: 0.17344312918167784 -> 0.17372070779531323 on epoch=149, global_step=600
05/30/2022 02:35:52 - INFO - __main__ - Step 610 Global step 610 Train loss 2.01 on epoch=152
05/30/2022 02:35:53 - INFO - __main__ - Step 620 Global step 620 Train loss 2.13 on epoch=154
05/30/2022 02:35:54 - INFO - __main__ - Step 630 Global step 630 Train loss 1.87 on epoch=157
05/30/2022 02:35:56 - INFO - __main__ - Step 640 Global step 640 Train loss 2.07 on epoch=159
05/30/2022 02:35:57 - INFO - __main__ - Step 650 Global step 650 Train loss 1.93 on epoch=162
05/30/2022 02:35:57 - INFO - __main__ - Global step 650 Train loss 2.00 Classification-F1 0.18026315789473685 on epoch=162
05/30/2022 02:35:57 - INFO - __main__ - Saving model with best Classification-F1: 0.17372070779531323 -> 0.18026315789473685 on epoch=162, global_step=650
05/30/2022 02:35:59 - INFO - __main__ - Step 660 Global step 660 Train loss 1.93 on epoch=164
05/30/2022 02:36:00 - INFO - __main__ - Step 670 Global step 670 Train loss 1.94 on epoch=167
05/30/2022 02:36:01 - INFO - __main__ - Step 680 Global step 680 Train loss 2.06 on epoch=169
05/30/2022 02:36:02 - INFO - __main__ - Step 690 Global step 690 Train loss 1.77 on epoch=172
05/30/2022 02:36:04 - INFO - __main__ - Step 700 Global step 700 Train loss 1.81 on epoch=174
05/30/2022 02:36:04 - INFO - __main__ - Global step 700 Train loss 1.90 Classification-F1 0.15339578454332553 on epoch=174
05/30/2022 02:36:05 - INFO - __main__ - Step 710 Global step 710 Train loss 1.67 on epoch=177
05/30/2022 02:36:07 - INFO - __main__ - Step 720 Global step 720 Train loss 1.73 on epoch=179
05/30/2022 02:36:08 - INFO - __main__ - Step 730 Global step 730 Train loss 1.70 on epoch=182
05/30/2022 02:36:09 - INFO - __main__ - Step 740 Global step 740 Train loss 1.76 on epoch=184
05/30/2022 02:36:11 - INFO - __main__ - Step 750 Global step 750 Train loss 1.60 on epoch=187
05/30/2022 02:36:11 - INFO - __main__ - Global step 750 Train loss 1.69 Classification-F1 0.1 on epoch=187
05/30/2022 02:36:12 - INFO - __main__ - Step 760 Global step 760 Train loss 1.73 on epoch=189
05/30/2022 02:36:14 - INFO - __main__ - Step 770 Global step 770 Train loss 1.61 on epoch=192
05/30/2022 02:36:15 - INFO - __main__ - Step 780 Global step 780 Train loss 1.60 on epoch=194
05/30/2022 02:36:16 - INFO - __main__ - Step 790 Global step 790 Train loss 1.39 on epoch=197
05/30/2022 02:36:17 - INFO - __main__ - Step 800 Global step 800 Train loss 1.55 on epoch=199
05/30/2022 02:36:18 - INFO - __main__ - Global step 800 Train loss 1.58 Classification-F1 0.1237183868762816 on epoch=199
05/30/2022 02:36:19 - INFO - __main__ - Step 810 Global step 810 Train loss 1.38 on epoch=202
05/30/2022 02:36:20 - INFO - __main__ - Step 820 Global step 820 Train loss 1.63 on epoch=204
05/30/2022 02:36:22 - INFO - __main__ - Step 830 Global step 830 Train loss 1.60 on epoch=207
05/30/2022 02:36:23 - INFO - __main__ - Step 840 Global step 840 Train loss 1.49 on epoch=209
05/30/2022 02:36:24 - INFO - __main__ - Step 850 Global step 850 Train loss 1.41 on epoch=212
05/30/2022 02:36:25 - INFO - __main__ - Global step 850 Train loss 1.50 Classification-F1 0.10126582278481013 on epoch=212
05/30/2022 02:36:26 - INFO - __main__ - Step 860 Global step 860 Train loss 1.57 on epoch=214
05/30/2022 02:36:27 - INFO - __main__ - Step 870 Global step 870 Train loss 1.52 on epoch=217
05/30/2022 02:36:29 - INFO - __main__ - Step 880 Global step 880 Train loss 1.38 on epoch=219
05/30/2022 02:36:30 - INFO - __main__ - Step 890 Global step 890 Train loss 1.32 on epoch=222
05/30/2022 02:36:31 - INFO - __main__ - Step 900 Global step 900 Train loss 1.32 on epoch=224
05/30/2022 02:36:32 - INFO - __main__ - Global step 900 Train loss 1.42 Classification-F1 0.0974025974025974 on epoch=224
05/30/2022 02:36:33 - INFO - __main__ - Step 910 Global step 910 Train loss 1.31 on epoch=227
05/30/2022 02:36:34 - INFO - __main__ - Step 920 Global step 920 Train loss 1.47 on epoch=229
05/30/2022 02:36:35 - INFO - __main__ - Step 930 Global step 930 Train loss 1.34 on epoch=232
05/30/2022 02:36:37 - INFO - __main__ - Step 940 Global step 940 Train loss 1.47 on epoch=234
05/30/2022 02:36:38 - INFO - __main__ - Step 950 Global step 950 Train loss 1.34 on epoch=237
05/30/2022 02:36:38 - INFO - __main__ - Global step 950 Train loss 1.39 Classification-F1 0.11425630468347914 on epoch=237
05/30/2022 02:36:40 - INFO - __main__ - Step 960 Global step 960 Train loss 1.37 on epoch=239
05/30/2022 02:36:41 - INFO - __main__ - Step 970 Global step 970 Train loss 1.41 on epoch=242
05/30/2022 02:36:42 - INFO - __main__ - Step 980 Global step 980 Train loss 1.60 on epoch=244
05/30/2022 02:36:43 - INFO - __main__ - Step 990 Global step 990 Train loss 1.22 on epoch=247
05/30/2022 02:36:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.29 on epoch=249
05/30/2022 02:36:45 - INFO - __main__ - Global step 1000 Train loss 1.38 Classification-F1 0.1 on epoch=249
05/30/2022 02:36:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/30/2022 02:36:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.17 on epoch=254
05/30/2022 02:36:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.26 on epoch=257
05/30/2022 02:36:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.24 on epoch=259
05/30/2022 02:36:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.41 on epoch=262
05/30/2022 02:36:52 - INFO - __main__ - Global step 1050 Train loss 1.29 Classification-F1 0.1856338028169014 on epoch=262
05/30/2022 02:36:52 - INFO - __main__ - Saving model with best Classification-F1: 0.18026315789473685 -> 0.1856338028169014 on epoch=262, global_step=1050
05/30/2022 02:36:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.47 on epoch=264
05/30/2022 02:36:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.27 on epoch=267
05/30/2022 02:36:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.22 on epoch=269
05/30/2022 02:36:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.26 on epoch=272
05/30/2022 02:36:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.31 on epoch=274
05/30/2022 02:36:59 - INFO - __main__ - Global step 1100 Train loss 1.31 Classification-F1 0.1081081081081081 on epoch=274
05/30/2022 02:37:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.38 on epoch=277
05/30/2022 02:37:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.25 on epoch=279
05/30/2022 02:37:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.30 on epoch=282
05/30/2022 02:37:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.51 on epoch=284
05/30/2022 02:37:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.19 on epoch=287
05/30/2022 02:37:06 - INFO - __main__ - Global step 1150 Train loss 1.33 Classification-F1 0.1 on epoch=287
05/30/2022 02:37:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.16 on epoch=289
05/30/2022 02:37:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.24 on epoch=292
05/30/2022 02:37:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.24 on epoch=294
05/30/2022 02:37:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.41 on epoch=297
05/30/2022 02:37:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.44 on epoch=299
05/30/2022 02:37:13 - INFO - __main__ - Global step 1200 Train loss 1.30 Classification-F1 0.10126582278481013 on epoch=299
05/30/2022 02:37:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.27 on epoch=302
05/30/2022 02:37:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.35 on epoch=304
05/30/2022 02:37:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.27 on epoch=307
05/30/2022 02:37:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.16 on epoch=309
05/30/2022 02:37:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.27 on epoch=312
05/30/2022 02:37:20 - INFO - __main__ - Global step 1250 Train loss 1.26 Classification-F1 0.16110780226325194 on epoch=312
05/30/2022 02:37:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.30 on epoch=314
05/30/2022 02:37:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.28 on epoch=317
05/30/2022 02:37:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.27 on epoch=319
05/30/2022 02:37:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.30 on epoch=322
05/30/2022 02:37:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.20 on epoch=324
05/30/2022 02:37:26 - INFO - __main__ - Global step 1300 Train loss 1.27 Classification-F1 0.1 on epoch=324
05/30/2022 02:37:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.13 on epoch=327
05/30/2022 02:37:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.16 on epoch=329
05/30/2022 02:37:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=332
05/30/2022 02:37:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.29 on epoch=334
05/30/2022 02:37:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.21 on epoch=337
05/30/2022 02:37:33 - INFO - __main__ - Global step 1350 Train loss 1.20 Classification-F1 0.1 on epoch=337
05/30/2022 02:37:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.17 on epoch=339
05/30/2022 02:37:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.11 on epoch=342
05/30/2022 02:37:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=344
05/30/2022 02:37:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=347
05/30/2022 02:37:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=349
05/30/2022 02:37:40 - INFO - __main__ - Global step 1400 Train loss 1.13 Classification-F1 0.14560439560439564 on epoch=349
05/30/2022 02:37:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.25 on epoch=352
05/30/2022 02:37:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.22 on epoch=354
05/30/2022 02:37:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.13 on epoch=357
05/30/2022 02:37:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.10 on epoch=359
05/30/2022 02:37:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.18 on epoch=362
05/30/2022 02:37:47 - INFO - __main__ - Global step 1450 Train loss 1.18 Classification-F1 0.1 on epoch=362
05/30/2022 02:37:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.11 on epoch=364
05/30/2022 02:37:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.31 on epoch=367
05/30/2022 02:37:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/30/2022 02:37:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.03 on epoch=372
05/30/2022 02:37:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.20 on epoch=374
05/30/2022 02:37:54 - INFO - __main__ - Global step 1500 Train loss 1.16 Classification-F1 0.1 on epoch=374
05/30/2022 02:37:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.09 on epoch=377
05/30/2022 02:37:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.21 on epoch=379
05/30/2022 02:37:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.10 on epoch=382
05/30/2022 02:37:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.09 on epoch=384
05/30/2022 02:38:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.09 on epoch=387
05/30/2022 02:38:01 - INFO - __main__ - Global step 1550 Train loss 1.12 Classification-F1 0.13067758749069247 on epoch=387
05/30/2022 02:38:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.03 on epoch=389
05/30/2022 02:38:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.06 on epoch=392
05/30/2022 02:38:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=394
05/30/2022 02:38:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.17 on epoch=397
05/30/2022 02:38:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=399
05/30/2022 02:38:08 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.10126582278481013 on epoch=399
05/30/2022 02:38:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.07 on epoch=402
05/30/2022 02:38:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.06 on epoch=404
05/30/2022 02:38:11 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.21 on epoch=407
05/30/2022 02:38:13 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/30/2022 02:38:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.04 on epoch=412
05/30/2022 02:38:15 - INFO - __main__ - Global step 1650 Train loss 1.08 Classification-F1 0.1 on epoch=412
05/30/2022 02:38:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.08 on epoch=414
05/30/2022 02:38:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.99 on epoch=417
05/30/2022 02:38:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.07 on epoch=419
05/30/2022 02:38:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.15 on epoch=422
05/30/2022 02:38:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.99 on epoch=424
05/30/2022 02:38:21 - INFO - __main__ - Global step 1700 Train loss 1.05 Classification-F1 0.15306730196545562 on epoch=424
05/30/2022 02:38:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.16 on epoch=427
05/30/2022 02:38:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.96 on epoch=429
05/30/2022 02:38:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.98 on epoch=432
05/30/2022 02:38:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.97 on epoch=434
05/30/2022 02:38:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.18 on epoch=437
05/30/2022 02:38:28 - INFO - __main__ - Global step 1750 Train loss 1.05 Classification-F1 0.1 on epoch=437
05/30/2022 02:38:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.14 on epoch=439
05/30/2022 02:38:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.10 on epoch=442
05/30/2022 02:38:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.10 on epoch=444
05/30/2022 02:38:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.24 on epoch=447
05/30/2022 02:38:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.05 on epoch=449
05/30/2022 02:38:35 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.17737733391228833 on epoch=449
05/30/2022 02:38:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.01 on epoch=452
05/30/2022 02:38:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/30/2022 02:38:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.05 on epoch=457
05/30/2022 02:38:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.24 on epoch=459
05/30/2022 02:38:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.11 on epoch=462
05/30/2022 02:38:42 - INFO - __main__ - Global step 1850 Train loss 1.11 Classification-F1 0.1782106782106782 on epoch=462
05/30/2022 02:38:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.14 on epoch=464
05/30/2022 02:38:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.19 on epoch=467
05/30/2022 02:38:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.10 on epoch=469
05/30/2022 02:38:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.04 on epoch=472
05/30/2022 02:38:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=474
05/30/2022 02:38:49 - INFO - __main__ - Global step 1900 Train loss 1.10 Classification-F1 0.1762899262899263 on epoch=474
05/30/2022 02:38:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.02 on epoch=477
05/30/2022 02:38:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.09 on epoch=479
05/30/2022 02:38:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.02 on epoch=482
05/30/2022 02:38:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.19 on epoch=484
05/30/2022 02:38:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.13 on epoch=487
05/30/2022 02:38:56 - INFO - __main__ - Global step 1950 Train loss 1.09 Classification-F1 0.13333333333333333 on epoch=487
05/30/2022 02:38:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.07 on epoch=489
05/30/2022 02:38:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=492
05/30/2022 02:39:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.09 on epoch=494
05/30/2022 02:39:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.07 on epoch=497
05/30/2022 02:39:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.99 on epoch=499
05/30/2022 02:39:03 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.1 on epoch=499
05/30/2022 02:39:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.07 on epoch=502
05/30/2022 02:39:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.07 on epoch=504
05/30/2022 02:39:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.01 on epoch=507
05/30/2022 02:39:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.16 on epoch=509
05/30/2022 02:39:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.98 on epoch=512
05/30/2022 02:39:10 - INFO - __main__ - Global step 2050 Train loss 1.06 Classification-F1 0.14004914004914004 on epoch=512
05/30/2022 02:39:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.07 on epoch=514
05/30/2022 02:39:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.04 on epoch=517
05/30/2022 02:39:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.12 on epoch=519
05/30/2022 02:39:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.07 on epoch=522
05/30/2022 02:39:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.11 on epoch=524
05/30/2022 02:39:17 - INFO - __main__ - Global step 2100 Train loss 1.08 Classification-F1 0.1527777777777778 on epoch=524
05/30/2022 02:39:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.96 on epoch=527
05/30/2022 02:39:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.06 on epoch=529
05/30/2022 02:39:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.14 on epoch=532
05/30/2022 02:39:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.07 on epoch=534
05/30/2022 02:39:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.11 on epoch=537
05/30/2022 02:39:23 - INFO - __main__ - Global step 2150 Train loss 1.07 Classification-F1 0.1576923076923077 on epoch=537
05/30/2022 02:39:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.01 on epoch=539
05/30/2022 02:39:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.02 on epoch=542
05/30/2022 02:39:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.97 on epoch=544
05/30/2022 02:39:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=547
05/30/2022 02:39:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.99 on epoch=549
05/30/2022 02:39:30 - INFO - __main__ - Global step 2200 Train loss 1.00 Classification-F1 0.1402116402116402 on epoch=549
05/30/2022 02:39:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.98 on epoch=552
05/30/2022 02:39:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=554
05/30/2022 02:39:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.07 on epoch=557
05/30/2022 02:39:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
05/30/2022 02:39:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
05/30/2022 02:39:37 - INFO - __main__ - Global step 2250 Train loss 1.02 Classification-F1 0.20219168748580513 on epoch=562
05/30/2022 02:39:37 - INFO - __main__ - Saving model with best Classification-F1: 0.1856338028169014 -> 0.20219168748580513 on epoch=562, global_step=2250
05/30/2022 02:39:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.99 on epoch=564
05/30/2022 02:39:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.98 on epoch=567
05/30/2022 02:39:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/30/2022 02:39:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.06 on epoch=572
05/30/2022 02:39:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.00 on epoch=574
05/30/2022 02:39:44 - INFO - __main__ - Global step 2300 Train loss 1.00 Classification-F1 0.12077294685990338 on epoch=574
05/30/2022 02:39:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=577
05/30/2022 02:39:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.02 on epoch=579
05/30/2022 02:39:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.92 on epoch=582
05/30/2022 02:39:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.93 on epoch=584
05/30/2022 02:39:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/30/2022 02:39:51 - INFO - __main__ - Global step 2350 Train loss 0.96 Classification-F1 0.13445378151260504 on epoch=587
05/30/2022 02:39:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.98 on epoch=589
05/30/2022 02:39:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=592
05/30/2022 02:39:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.05 on epoch=594
05/30/2022 02:39:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.97 on epoch=597
05/30/2022 02:39:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=599
05/30/2022 02:39:58 - INFO - __main__ - Global step 2400 Train loss 0.99 Classification-F1 0.06060606060606061 on epoch=599
05/30/2022 02:39:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
05/30/2022 02:40:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/30/2022 02:40:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.03 on epoch=607
05/30/2022 02:40:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.02 on epoch=609
05/30/2022 02:40:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.05 on epoch=612
05/30/2022 02:40:05 - INFO - __main__ - Global step 2450 Train loss 1.01 Classification-F1 0.22004608294930872 on epoch=612
05/30/2022 02:40:05 - INFO - __main__ - Saving model with best Classification-F1: 0.20219168748580513 -> 0.22004608294930872 on epoch=612, global_step=2450
05/30/2022 02:40:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
05/30/2022 02:40:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.04 on epoch=617
05/30/2022 02:40:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/30/2022 02:40:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/30/2022 02:40:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
05/30/2022 02:40:12 - INFO - __main__ - Global step 2500 Train loss 1.07 Classification-F1 0.10256410256410256 on epoch=624
05/30/2022 02:40:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.05 on epoch=627
05/30/2022 02:40:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.12 on epoch=629
05/30/2022 02:40:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.07 on epoch=632
05/30/2022 02:40:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.94 on epoch=634
05/30/2022 02:40:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.03 on epoch=637
05/30/2022 02:40:18 - INFO - __main__ - Global step 2550 Train loss 1.04 Classification-F1 0.1 on epoch=637
05/30/2022 02:40:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.05 on epoch=639
05/30/2022 02:40:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.92 on epoch=642
05/30/2022 02:40:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.11 on epoch=644
05/30/2022 02:40:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.05 on epoch=647
05/30/2022 02:40:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.95 on epoch=649
05/30/2022 02:40:25 - INFO - __main__ - Global step 2600 Train loss 1.02 Classification-F1 0.12681436210847974 on epoch=649
05/30/2022 02:40:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.07 on epoch=652
05/30/2022 02:40:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.01 on epoch=654
05/30/2022 02:40:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.05 on epoch=657
05/30/2022 02:40:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.02 on epoch=659
05/30/2022 02:40:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.06 on epoch=662
05/30/2022 02:40:32 - INFO - __main__ - Global step 2650 Train loss 1.04 Classification-F1 0.1 on epoch=662
05/30/2022 02:40:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.00 on epoch=664
05/30/2022 02:40:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
05/30/2022 02:40:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.00 on epoch=669
05/30/2022 02:40:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.90 on epoch=672
05/30/2022 02:40:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.99 on epoch=674
05/30/2022 02:40:39 - INFO - __main__ - Global step 2700 Train loss 0.97 Classification-F1 0.1 on epoch=674
05/30/2022 02:40:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/30/2022 02:40:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.07 on epoch=679
05/30/2022 02:40:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.98 on epoch=682
05/30/2022 02:40:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.90 on epoch=684
05/30/2022 02:40:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/30/2022 02:40:46 - INFO - __main__ - Global step 2750 Train loss 0.98 Classification-F1 0.09493670886075949 on epoch=687
05/30/2022 02:40:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.05 on epoch=689
05/30/2022 02:40:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/30/2022 02:40:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.07 on epoch=694
05/30/2022 02:40:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=697
05/30/2022 02:40:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.05 on epoch=699
05/30/2022 02:40:53 - INFO - __main__ - Global step 2800 Train loss 1.03 Classification-F1 0.17028824833702882 on epoch=699
05/30/2022 02:40:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.97 on epoch=702
05/30/2022 02:40:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.11 on epoch=704
05/30/2022 02:40:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=707
05/30/2022 02:40:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/30/2022 02:40:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.94 on epoch=712
05/30/2022 02:41:00 - INFO - __main__ - Global step 2850 Train loss 0.99 Classification-F1 0.17798594847775173 on epoch=712
05/30/2022 02:41:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.99 on epoch=714
05/30/2022 02:41:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.93 on epoch=717
05/30/2022 02:41:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/30/2022 02:41:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.99 on epoch=722
05/30/2022 02:41:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.02 on epoch=724
05/30/2022 02:41:07 - INFO - __main__ - Global step 2900 Train loss 0.96 Classification-F1 0.11094819159335288 on epoch=724
05/30/2022 02:41:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.00 on epoch=727
05/30/2022 02:41:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.96 on epoch=729
05/30/2022 02:41:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.00 on epoch=732
05/30/2022 02:41:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.95 on epoch=734
05/30/2022 02:41:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.02 on epoch=737
05/30/2022 02:41:14 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.14915966386554622 on epoch=737
05/30/2022 02:41:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.96 on epoch=739
05/30/2022 02:41:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.05 on epoch=742
05/30/2022 02:41:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=744
05/30/2022 02:41:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.93 on epoch=747
05/30/2022 02:41:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.01 on epoch=749
05/30/2022 02:41:20 - INFO - __main__ - Global step 3000 Train loss 0.98 Classification-F1 0.11732186732186733 on epoch=749
05/30/2022 02:41:20 - INFO - __main__ - save last model!
05/30/2022 02:41:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:41:21 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:41:21 - INFO - __main__ - Printing 3 examples
05/30/2022 02:41:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:41:21 - INFO - __main__ - ['others']
05/30/2022 02:41:21 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:41:21 - INFO - __main__ - ['others']
05/30/2022 02:41:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:41:21 - INFO - __main__ - ['others']
05/30/2022 02:41:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:41:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:41:21 - INFO - __main__ - Printing 3 examples
05/30/2022 02:41:21 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:41:21 - INFO - __main__ - ['happy']
05/30/2022 02:41:21 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:41:21 - INFO - __main__ - ['happy']
05/30/2022 02:41:21 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:41:21 - INFO - __main__ - ['happy']
05/30/2022 02:41:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:41:21 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:41:21 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:41:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:41:21 - INFO - __main__ - Printing 3 examples
05/30/2022 02:41:21 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:41:21 - INFO - __main__ - ['happy']
05/30/2022 02:41:21 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:41:21 - INFO - __main__ - ['happy']
05/30/2022 02:41:21 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:41:21 - INFO - __main__ - ['happy']
05/30/2022 02:41:21 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:41:21 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:41:21 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:41:23 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:41:27 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:41:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:41:27 - INFO - __main__ - Starting training!
05/30/2022 02:41:28 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:42:11 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.3_8_predictions.txt
05/30/2022 02:42:11 - INFO - __main__ - Classification-F1 on test data: 0.0404
05/30/2022 02:42:11 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.22004608294930872, test_performance=0.04041940527737243
05/30/2022 02:42:11 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
05/30/2022 02:42:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:42:12 - INFO - __main__ - Printing 3 examples
05/30/2022 02:42:12 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/30/2022 02:42:12 - INFO - __main__ - ['happy']
05/30/2022 02:42:12 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/30/2022 02:42:12 - INFO - __main__ - ['happy']
05/30/2022 02:42:12 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/30/2022 02:42:12 - INFO - __main__ - ['happy']
05/30/2022 02:42:12 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:42:12 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:42:12 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:42:12 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:42:12 - INFO - __main__ - Printing 3 examples
05/30/2022 02:42:12 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
05/30/2022 02:42:12 - INFO - __main__ - ['happy']
05/30/2022 02:42:12 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
05/30/2022 02:42:12 - INFO - __main__ - ['happy']
05/30/2022 02:42:12 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
05/30/2022 02:42:12 - INFO - __main__ - ['happy']
05/30/2022 02:42:12 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:42:12 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:42:12 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:42:18 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:42:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:42:18 - INFO - __main__ - Starting training!
05/30/2022 02:42:19 - INFO - __main__ - Step 10 Global step 10 Train loss 6.63 on epoch=2
05/30/2022 02:42:21 - INFO - __main__ - Step 20 Global step 20 Train loss 6.59 on epoch=4
05/30/2022 02:42:22 - INFO - __main__ - Step 30 Global step 30 Train loss 6.55 on epoch=7
05/30/2022 02:42:23 - INFO - __main__ - Step 40 Global step 40 Train loss 6.37 on epoch=9
05/30/2022 02:42:24 - INFO - __main__ - Step 50 Global step 50 Train loss 6.17 on epoch=12
05/30/2022 02:42:32 - INFO - __main__ - Global step 50 Train loss 6.46 Classification-F1 0.0 on epoch=12
05/30/2022 02:42:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:42:33 - INFO - __main__ - Step 60 Global step 60 Train loss 6.25 on epoch=14
05/30/2022 02:42:35 - INFO - __main__ - Step 70 Global step 70 Train loss 6.01 on epoch=17
05/30/2022 02:42:36 - INFO - __main__ - Step 80 Global step 80 Train loss 5.95 on epoch=19
05/30/2022 02:42:37 - INFO - __main__ - Step 90 Global step 90 Train loss 5.85 on epoch=22
05/30/2022 02:42:39 - INFO - __main__ - Step 100 Global step 100 Train loss 5.68 on epoch=24
05/30/2022 02:42:40 - INFO - __main__ - Global step 100 Train loss 5.95 Classification-F1 0.0 on epoch=24
05/30/2022 02:42:41 - INFO - __main__ - Step 110 Global step 110 Train loss 5.65 on epoch=27
05/30/2022 02:42:43 - INFO - __main__ - Step 120 Global step 120 Train loss 5.60 on epoch=29
05/30/2022 02:42:44 - INFO - __main__ - Step 130 Global step 130 Train loss 5.51 on epoch=32
05/30/2022 02:42:45 - INFO - __main__ - Step 140 Global step 140 Train loss 5.45 on epoch=34
05/30/2022 02:42:47 - INFO - __main__ - Step 150 Global step 150 Train loss 5.33 on epoch=37
05/30/2022 02:42:48 - INFO - __main__ - Global step 150 Train loss 5.51 Classification-F1 0.0 on epoch=37
05/30/2022 02:42:49 - INFO - __main__ - Step 160 Global step 160 Train loss 5.24 on epoch=39
05/30/2022 02:42:50 - INFO - __main__ - Step 170 Global step 170 Train loss 5.27 on epoch=42
05/30/2022 02:42:52 - INFO - __main__ - Step 180 Global step 180 Train loss 4.89 on epoch=44
05/30/2022 02:42:53 - INFO - __main__ - Step 190 Global step 190 Train loss 4.88 on epoch=47
05/30/2022 02:42:54 - INFO - __main__ - Step 200 Global step 200 Train loss 4.81 on epoch=49
05/30/2022 02:42:56 - INFO - __main__ - Global step 200 Train loss 5.02 Classification-F1 0.0 on epoch=49
05/30/2022 02:42:57 - INFO - __main__ - Step 210 Global step 210 Train loss 4.58 on epoch=52
05/30/2022 02:42:58 - INFO - __main__ - Step 220 Global step 220 Train loss 4.68 on epoch=54
05/30/2022 02:43:00 - INFO - __main__ - Step 230 Global step 230 Train loss 4.25 on epoch=57
05/30/2022 02:43:01 - INFO - __main__ - Step 240 Global step 240 Train loss 4.46 on epoch=59
05/30/2022 02:43:02 - INFO - __main__ - Step 250 Global step 250 Train loss 4.29 on epoch=62
05/30/2022 02:43:03 - INFO - __main__ - Global step 250 Train loss 4.45 Classification-F1 0.0810126582278481 on epoch=62
05/30/2022 02:43:03 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0810126582278481 on epoch=62, global_step=250
05/30/2022 02:43:04 - INFO - __main__ - Step 260 Global step 260 Train loss 4.21 on epoch=64
05/30/2022 02:43:05 - INFO - __main__ - Step 270 Global step 270 Train loss 4.04 on epoch=67
05/30/2022 02:43:07 - INFO - __main__ - Step 280 Global step 280 Train loss 4.07 on epoch=69
05/30/2022 02:43:08 - INFO - __main__ - Step 290 Global step 290 Train loss 3.94 on epoch=72
05/30/2022 02:43:09 - INFO - __main__ - Step 300 Global step 300 Train loss 3.88 on epoch=74
05/30/2022 02:43:10 - INFO - __main__ - Global step 300 Train loss 4.03 Classification-F1 0.10199240986717267 on epoch=74
05/30/2022 02:43:10 - INFO - __main__ - Saving model with best Classification-F1: 0.0810126582278481 -> 0.10199240986717267 on epoch=74, global_step=300
05/30/2022 02:43:11 - INFO - __main__ - Step 310 Global step 310 Train loss 3.59 on epoch=77
05/30/2022 02:43:12 - INFO - __main__ - Step 320 Global step 320 Train loss 3.75 on epoch=79
05/30/2022 02:43:13 - INFO - __main__ - Step 330 Global step 330 Train loss 3.76 on epoch=82
05/30/2022 02:43:15 - INFO - __main__ - Step 340 Global step 340 Train loss 3.76 on epoch=84
05/30/2022 02:43:16 - INFO - __main__ - Step 350 Global step 350 Train loss 3.48 on epoch=87
05/30/2022 02:43:16 - INFO - __main__ - Global step 350 Train loss 3.67 Classification-F1 0.11300097751710654 on epoch=87
05/30/2022 02:43:16 - INFO - __main__ - Saving model with best Classification-F1: 0.10199240986717267 -> 0.11300097751710654 on epoch=87, global_step=350
05/30/2022 02:43:18 - INFO - __main__ - Step 360 Global step 360 Train loss 3.56 on epoch=89
05/30/2022 02:43:19 - INFO - __main__ - Step 370 Global step 370 Train loss 3.37 on epoch=92
05/30/2022 02:43:20 - INFO - __main__ - Step 380 Global step 380 Train loss 3.41 on epoch=94
05/30/2022 02:43:21 - INFO - __main__ - Step 390 Global step 390 Train loss 3.23 on epoch=97
05/30/2022 02:43:23 - INFO - __main__ - Step 400 Global step 400 Train loss 3.38 on epoch=99
05/30/2022 02:43:23 - INFO - __main__ - Global step 400 Train loss 3.39 Classification-F1 0.07733847637415622 on epoch=99
05/30/2022 02:43:25 - INFO - __main__ - Step 410 Global step 410 Train loss 3.25 on epoch=102
05/30/2022 02:43:26 - INFO - __main__ - Step 420 Global step 420 Train loss 3.24 on epoch=104
05/30/2022 02:43:27 - INFO - __main__ - Step 430 Global step 430 Train loss 3.06 on epoch=107
05/30/2022 02:43:28 - INFO - __main__ - Step 440 Global step 440 Train loss 3.18 on epoch=109
05/30/2022 02:43:30 - INFO - __main__ - Step 450 Global step 450 Train loss 2.97 on epoch=112
05/30/2022 02:43:30 - INFO - __main__ - Global step 450 Train loss 3.14 Classification-F1 0.14505347593582887 on epoch=112
05/30/2022 02:43:30 - INFO - __main__ - Saving model with best Classification-F1: 0.11300097751710654 -> 0.14505347593582887 on epoch=112, global_step=450
05/30/2022 02:43:32 - INFO - __main__ - Step 460 Global step 460 Train loss 3.10 on epoch=114
05/30/2022 02:43:33 - INFO - __main__ - Step 470 Global step 470 Train loss 2.85 on epoch=117
05/30/2022 02:43:34 - INFO - __main__ - Step 480 Global step 480 Train loss 2.89 on epoch=119
05/30/2022 02:43:35 - INFO - __main__ - Step 490 Global step 490 Train loss 2.67 on epoch=122
05/30/2022 02:43:37 - INFO - __main__ - Step 500 Global step 500 Train loss 2.87 on epoch=124
05/30/2022 02:43:37 - INFO - __main__ - Global step 500 Train loss 2.88 Classification-F1 0.10483870967741937 on epoch=124
05/30/2022 02:43:38 - INFO - __main__ - Step 510 Global step 510 Train loss 2.67 on epoch=127
05/30/2022 02:43:40 - INFO - __main__ - Step 520 Global step 520 Train loss 2.71 on epoch=129
05/30/2022 02:43:41 - INFO - __main__ - Step 530 Global step 530 Train loss 2.72 on epoch=132
05/30/2022 02:43:42 - INFO - __main__ - Step 540 Global step 540 Train loss 2.72 on epoch=134
05/30/2022 02:43:43 - INFO - __main__ - Step 550 Global step 550 Train loss 2.59 on epoch=137
05/30/2022 02:43:44 - INFO - __main__ - Global step 550 Train loss 2.68 Classification-F1 0.1 on epoch=137
05/30/2022 02:43:45 - INFO - __main__ - Step 560 Global step 560 Train loss 2.64 on epoch=139
05/30/2022 02:43:46 - INFO - __main__ - Step 570 Global step 570 Train loss 2.57 on epoch=142
05/30/2022 02:43:48 - INFO - __main__ - Step 580 Global step 580 Train loss 2.51 on epoch=144
05/30/2022 02:43:49 - INFO - __main__ - Step 590 Global step 590 Train loss 2.39 on epoch=147
05/30/2022 02:43:50 - INFO - __main__ - Step 600 Global step 600 Train loss 2.55 on epoch=149
05/30/2022 02:43:51 - INFO - __main__ - Global step 600 Train loss 2.53 Classification-F1 0.1 on epoch=149
05/30/2022 02:43:52 - INFO - __main__ - Step 610 Global step 610 Train loss 2.27 on epoch=152
05/30/2022 02:43:53 - INFO - __main__ - Step 620 Global step 620 Train loss 2.51 on epoch=154
05/30/2022 02:43:54 - INFO - __main__ - Step 630 Global step 630 Train loss 2.29 on epoch=157
05/30/2022 02:43:56 - INFO - __main__ - Step 640 Global step 640 Train loss 2.34 on epoch=159
05/30/2022 02:43:57 - INFO - __main__ - Step 650 Global step 650 Train loss 2.20 on epoch=162
05/30/2022 02:43:58 - INFO - __main__ - Global step 650 Train loss 2.32 Classification-F1 0.1 on epoch=162
05/30/2022 02:43:59 - INFO - __main__ - Step 660 Global step 660 Train loss 2.53 on epoch=164
05/30/2022 02:44:00 - INFO - __main__ - Step 670 Global step 670 Train loss 2.15 on epoch=167
05/30/2022 02:44:01 - INFO - __main__ - Step 680 Global step 680 Train loss 2.27 on epoch=169
05/30/2022 02:44:03 - INFO - __main__ - Step 690 Global step 690 Train loss 2.10 on epoch=172
05/30/2022 02:44:04 - INFO - __main__ - Step 700 Global step 700 Train loss 2.08 on epoch=174
05/30/2022 02:44:04 - INFO - __main__ - Global step 700 Train loss 2.23 Classification-F1 0.1 on epoch=174
05/30/2022 02:44:06 - INFO - __main__ - Step 710 Global step 710 Train loss 2.07 on epoch=177
05/30/2022 02:44:07 - INFO - __main__ - Step 720 Global step 720 Train loss 2.18 on epoch=179
05/30/2022 02:44:08 - INFO - __main__ - Step 730 Global step 730 Train loss 2.05 on epoch=182
05/30/2022 02:44:09 - INFO - __main__ - Step 740 Global step 740 Train loss 2.17 on epoch=184
05/30/2022 02:44:11 - INFO - __main__ - Step 750 Global step 750 Train loss 2.07 on epoch=187
05/30/2022 02:44:11 - INFO - __main__ - Global step 750 Train loss 2.11 Classification-F1 0.1 on epoch=187
05/30/2022 02:44:12 - INFO - __main__ - Step 760 Global step 760 Train loss 2.09 on epoch=189
05/30/2022 02:44:14 - INFO - __main__ - Step 770 Global step 770 Train loss 2.25 on epoch=192
05/30/2022 02:44:15 - INFO - __main__ - Step 780 Global step 780 Train loss 2.14 on epoch=194
05/30/2022 02:44:16 - INFO - __main__ - Step 790 Global step 790 Train loss 2.08 on epoch=197
05/30/2022 02:44:18 - INFO - __main__ - Step 800 Global step 800 Train loss 2.22 on epoch=199
05/30/2022 02:44:18 - INFO - __main__ - Global step 800 Train loss 2.16 Classification-F1 0.1 on epoch=199
05/30/2022 02:44:19 - INFO - __main__ - Step 810 Global step 810 Train loss 1.92 on epoch=202
05/30/2022 02:44:21 - INFO - __main__ - Step 820 Global step 820 Train loss 2.04 on epoch=204
05/30/2022 02:44:22 - INFO - __main__ - Step 830 Global step 830 Train loss 1.96 on epoch=207
05/30/2022 02:44:23 - INFO - __main__ - Step 840 Global step 840 Train loss 2.01 on epoch=209
05/30/2022 02:44:24 - INFO - __main__ - Step 850 Global step 850 Train loss 1.82 on epoch=212
05/30/2022 02:44:25 - INFO - __main__ - Global step 850 Train loss 1.95 Classification-F1 0.1 on epoch=212
05/30/2022 02:44:26 - INFO - __main__ - Step 860 Global step 860 Train loss 1.86 on epoch=214
05/30/2022 02:44:27 - INFO - __main__ - Step 870 Global step 870 Train loss 1.94 on epoch=217
05/30/2022 02:44:29 - INFO - __main__ - Step 880 Global step 880 Train loss 1.99 on epoch=219
05/30/2022 02:44:30 - INFO - __main__ - Step 890 Global step 890 Train loss 1.84 on epoch=222
05/30/2022 02:44:31 - INFO - __main__ - Step 900 Global step 900 Train loss 1.82 on epoch=224
05/30/2022 02:44:32 - INFO - __main__ - Global step 900 Train loss 1.89 Classification-F1 0.1 on epoch=224
05/30/2022 02:44:33 - INFO - __main__ - Step 910 Global step 910 Train loss 1.83 on epoch=227
05/30/2022 02:44:34 - INFO - __main__ - Step 920 Global step 920 Train loss 1.99 on epoch=229
05/30/2022 02:44:36 - INFO - __main__ - Step 930 Global step 930 Train loss 1.74 on epoch=232
05/30/2022 02:44:37 - INFO - __main__ - Step 940 Global step 940 Train loss 1.91 on epoch=234
05/30/2022 02:44:38 - INFO - __main__ - Step 950 Global step 950 Train loss 1.81 on epoch=237
05/30/2022 02:44:39 - INFO - __main__ - Global step 950 Train loss 1.85 Classification-F1 0.1 on epoch=237
05/30/2022 02:44:40 - INFO - __main__ - Step 960 Global step 960 Train loss 1.73 on epoch=239
05/30/2022 02:44:41 - INFO - __main__ - Step 970 Global step 970 Train loss 1.88 on epoch=242
05/30/2022 02:44:42 - INFO - __main__ - Step 980 Global step 980 Train loss 1.69 on epoch=244
05/30/2022 02:44:44 - INFO - __main__ - Step 990 Global step 990 Train loss 1.84 on epoch=247
05/30/2022 02:44:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.78 on epoch=249
05/30/2022 02:44:45 - INFO - __main__ - Global step 1000 Train loss 1.79 Classification-F1 0.1 on epoch=249
05/30/2022 02:44:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.74 on epoch=252
05/30/2022 02:44:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.84 on epoch=254
05/30/2022 02:44:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.66 on epoch=257
05/30/2022 02:44:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.68 on epoch=259
05/30/2022 02:44:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.84 on epoch=262
05/30/2022 02:44:52 - INFO - __main__ - Global step 1050 Train loss 1.75 Classification-F1 0.1 on epoch=262
05/30/2022 02:44:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.78 on epoch=264
05/30/2022 02:44:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.76 on epoch=267
05/30/2022 02:44:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.68 on epoch=269
05/30/2022 02:44:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.66 on epoch=272
05/30/2022 02:44:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.67 on epoch=274
05/30/2022 02:44:59 - INFO - __main__ - Global step 1100 Train loss 1.71 Classification-F1 0.1 on epoch=274
05/30/2022 02:45:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.63 on epoch=277
05/30/2022 02:45:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.69 on epoch=279
05/30/2022 02:45:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.58 on epoch=282
05/30/2022 02:45:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.59 on epoch=284
05/30/2022 02:45:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.62 on epoch=287
05/30/2022 02:45:06 - INFO - __main__ - Global step 1150 Train loss 1.62 Classification-F1 0.1 on epoch=287
05/30/2022 02:45:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.66 on epoch=289
05/30/2022 02:45:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.64 on epoch=292
05/30/2022 02:45:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.40 on epoch=294
05/30/2022 02:45:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.60 on epoch=297
05/30/2022 02:45:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.58 on epoch=299
05/30/2022 02:45:12 - INFO - __main__ - Global step 1200 Train loss 1.57 Classification-F1 0.1 on epoch=299
05/30/2022 02:45:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.60 on epoch=302
05/30/2022 02:45:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.39 on epoch=304
05/30/2022 02:45:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.47 on epoch=307
05/30/2022 02:45:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.54 on epoch=309
05/30/2022 02:45:19 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.53 on epoch=312
05/30/2022 02:45:19 - INFO - __main__ - Global step 1250 Train loss 1.51 Classification-F1 0.1 on epoch=312
05/30/2022 02:45:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.55 on epoch=314
05/30/2022 02:45:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.35 on epoch=317
05/30/2022 02:45:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.56 on epoch=319
05/30/2022 02:45:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.56 on epoch=322
05/30/2022 02:45:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.49 on epoch=324
05/30/2022 02:45:26 - INFO - __main__ - Global step 1300 Train loss 1.50 Classification-F1 0.1 on epoch=324
05/30/2022 02:45:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.49 on epoch=327
05/30/2022 02:45:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.50 on epoch=329
05/30/2022 02:45:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.45 on epoch=332
05/30/2022 02:45:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.55 on epoch=334
05/30/2022 02:45:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.50 on epoch=337
05/30/2022 02:45:32 - INFO - __main__ - Global step 1350 Train loss 1.50 Classification-F1 0.1 on epoch=337
05/30/2022 02:45:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.28 on epoch=339
05/30/2022 02:45:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.51 on epoch=342
05/30/2022 02:45:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.44 on epoch=344
05/30/2022 02:45:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.30 on epoch=347
05/30/2022 02:45:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.42 on epoch=349
05/30/2022 02:45:39 - INFO - __main__ - Global step 1400 Train loss 1.39 Classification-F1 0.1 on epoch=349
05/30/2022 02:45:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.34 on epoch=352
05/30/2022 02:45:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.45 on epoch=354
05/30/2022 02:45:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.50 on epoch=357
05/30/2022 02:45:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.43 on epoch=359
05/30/2022 02:45:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.47 on epoch=362
05/30/2022 02:45:46 - INFO - __main__ - Global step 1450 Train loss 1.44 Classification-F1 0.1 on epoch=362
05/30/2022 02:45:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.42 on epoch=364
05/30/2022 02:45:48 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.50 on epoch=367
05/30/2022 02:45:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.40 on epoch=369
05/30/2022 02:45:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.39 on epoch=372
05/30/2022 02:45:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.35 on epoch=374
05/30/2022 02:45:52 - INFO - __main__ - Global step 1500 Train loss 1.41 Classification-F1 0.1 on epoch=374
05/30/2022 02:45:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.26 on epoch=377
05/30/2022 02:45:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.43 on epoch=379
05/30/2022 02:45:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.44 on epoch=382
05/30/2022 02:45:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.36 on epoch=384
05/30/2022 02:45:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.38 on epoch=387
05/30/2022 02:45:59 - INFO - __main__ - Global step 1550 Train loss 1.37 Classification-F1 0.1 on epoch=387
05/30/2022 02:46:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=389
05/30/2022 02:46:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.41 on epoch=392
05/30/2022 02:46:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=394
05/30/2022 02:46:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.28 on epoch=397
05/30/2022 02:46:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.30 on epoch=399
05/30/2022 02:46:06 - INFO - __main__ - Global step 1600 Train loss 1.28 Classification-F1 0.1 on epoch=399
05/30/2022 02:46:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.45 on epoch=402
05/30/2022 02:46:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.34 on epoch=404
05/30/2022 02:46:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.33 on epoch=407
05/30/2022 02:46:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.40 on epoch=409
05/30/2022 02:46:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.33 on epoch=412
05/30/2022 02:46:12 - INFO - __main__ - Global step 1650 Train loss 1.37 Classification-F1 0.1 on epoch=412
05/30/2022 02:46:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.43 on epoch=414
05/30/2022 02:46:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.23 on epoch=417
05/30/2022 02:46:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.22 on epoch=419
05/30/2022 02:46:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.36 on epoch=422
05/30/2022 02:46:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.38 on epoch=424
05/30/2022 02:46:19 - INFO - __main__ - Global step 1700 Train loss 1.33 Classification-F1 0.1 on epoch=424
05/30/2022 02:46:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=427
05/30/2022 02:46:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.34 on epoch=429
05/30/2022 02:46:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.30 on epoch=432
05/30/2022 02:46:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.23 on epoch=434
05/30/2022 02:46:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.37 on epoch=437
05/30/2022 02:46:26 - INFO - __main__ - Global step 1750 Train loss 1.30 Classification-F1 0.1 on epoch=437
05/30/2022 02:46:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.23 on epoch=439
05/30/2022 02:46:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.16 on epoch=442
05/30/2022 02:46:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.16 on epoch=444
05/30/2022 02:46:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.34 on epoch=447
05/30/2022 02:46:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.31 on epoch=449
05/30/2022 02:46:32 - INFO - __main__ - Global step 1800 Train loss 1.24 Classification-F1 0.1 on epoch=449
05/30/2022 02:46:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.21 on epoch=452
05/30/2022 02:46:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.29 on epoch=454
05/30/2022 02:46:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.16 on epoch=457
05/30/2022 02:46:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.10 on epoch=459
05/30/2022 02:46:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.34 on epoch=462
05/30/2022 02:46:39 - INFO - __main__ - Global step 1850 Train loss 1.22 Classification-F1 0.1 on epoch=462
05/30/2022 02:46:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.09 on epoch=464
05/30/2022 02:46:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.14 on epoch=467
05/30/2022 02:46:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.19 on epoch=469
05/30/2022 02:46:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.37 on epoch=472
05/30/2022 02:46:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.12 on epoch=474
05/30/2022 02:46:46 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.1 on epoch=474
05/30/2022 02:46:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.16 on epoch=477
05/30/2022 02:46:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.16 on epoch=479
05/30/2022 02:46:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.29 on epoch=482
05/30/2022 02:46:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.22 on epoch=484
05/30/2022 02:46:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.24 on epoch=487
05/30/2022 02:46:52 - INFO - __main__ - Global step 1950 Train loss 1.21 Classification-F1 0.1 on epoch=487
05/30/2022 02:46:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.33 on epoch=489
05/30/2022 02:46:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.25 on epoch=492
05/30/2022 02:46:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.14 on epoch=494
05/30/2022 02:46:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.29 on epoch=497
05/30/2022 02:46:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.00 on epoch=499
05/30/2022 02:46:59 - INFO - __main__ - Global step 2000 Train loss 1.20 Classification-F1 0.1 on epoch=499
05/30/2022 02:47:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.08 on epoch=502
05/30/2022 02:47:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.20 on epoch=504
05/30/2022 02:47:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.07 on epoch=507
05/30/2022 02:47:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.28 on epoch=509
05/30/2022 02:47:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.20 on epoch=512
05/30/2022 02:47:06 - INFO - __main__ - Global step 2050 Train loss 1.17 Classification-F1 0.09493670886075949 on epoch=512
05/30/2022 02:47:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.32 on epoch=514
05/30/2022 02:47:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.18 on epoch=517
05/30/2022 02:47:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.25 on epoch=519
05/30/2022 02:47:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.01 on epoch=522
05/30/2022 02:47:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.22 on epoch=524
05/30/2022 02:47:12 - INFO - __main__ - Global step 2100 Train loss 1.19 Classification-F1 0.13034188034188032 on epoch=524
05/30/2022 02:47:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.10 on epoch=527
05/30/2022 02:47:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.21 on epoch=529
05/30/2022 02:47:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.18 on epoch=532
05/30/2022 02:47:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.19 on epoch=534
05/30/2022 02:47:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.27 on epoch=537
05/30/2022 02:47:19 - INFO - __main__ - Global step 2150 Train loss 1.19 Classification-F1 0.1 on epoch=537
05/30/2022 02:47:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.18 on epoch=539
05/30/2022 02:47:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.21 on epoch=542
05/30/2022 02:47:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.14 on epoch=544
05/30/2022 02:47:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.12 on epoch=547
05/30/2022 02:47:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.06 on epoch=549
05/30/2022 02:47:26 - INFO - __main__ - Global step 2200 Train loss 1.14 Classification-F1 0.1468058968058968 on epoch=549
05/30/2022 02:47:26 - INFO - __main__ - Saving model with best Classification-F1: 0.14505347593582887 -> 0.1468058968058968 on epoch=549, global_step=2200
05/30/2022 02:47:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.07 on epoch=552
05/30/2022 02:47:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.07 on epoch=554
05/30/2022 02:47:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.25 on epoch=557
05/30/2022 02:47:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.14 on epoch=559
05/30/2022 02:47:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.20 on epoch=562
05/30/2022 02:47:32 - INFO - __main__ - Global step 2250 Train loss 1.15 Classification-F1 0.10256410256410256 on epoch=562
05/30/2022 02:47:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.15 on epoch=564
05/30/2022 02:47:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.05 on epoch=567
05/30/2022 02:47:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.19 on epoch=569
05/30/2022 02:47:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.00 on epoch=572
05/30/2022 02:47:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.12 on epoch=574
05/30/2022 02:47:39 - INFO - __main__ - Global step 2300 Train loss 1.10 Classification-F1 0.1 on epoch=574
05/30/2022 02:47:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/30/2022 02:47:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.11 on epoch=579
05/30/2022 02:47:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.08 on epoch=582
05/30/2022 02:47:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.16 on epoch=584
05/30/2022 02:47:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.02 on epoch=587
05/30/2022 02:47:46 - INFO - __main__ - Global step 2350 Train loss 1.09 Classification-F1 0.1 on epoch=587
05/30/2022 02:47:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/30/2022 02:47:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.97 on epoch=592
05/30/2022 02:47:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.08 on epoch=594
05/30/2022 02:47:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.10 on epoch=597
05/30/2022 02:47:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.08 on epoch=599
05/30/2022 02:47:52 - INFO - __main__ - Global step 2400 Train loss 1.05 Classification-F1 0.1 on epoch=599
05/30/2022 02:47:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.10 on epoch=602
05/30/2022 02:47:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.95 on epoch=604
05/30/2022 02:47:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.15 on epoch=607
05/30/2022 02:47:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
05/30/2022 02:47:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.17 on epoch=612
05/30/2022 02:47:59 - INFO - __main__ - Global step 2450 Train loss 1.07 Classification-F1 0.1 on epoch=612
05/30/2022 02:48:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.10 on epoch=614
05/30/2022 02:48:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.15 on epoch=617
05/30/2022 02:48:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.24 on epoch=619
05/30/2022 02:48:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.18 on epoch=622
05/30/2022 02:48:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.05 on epoch=624
05/30/2022 02:48:06 - INFO - __main__ - Global step 2500 Train loss 1.14 Classification-F1 0.1 on epoch=624
05/30/2022 02:48:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.12 on epoch=627
05/30/2022 02:48:08 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.14 on epoch=629
05/30/2022 02:48:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.21 on epoch=632
05/30/2022 02:48:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.18 on epoch=634
05/30/2022 02:48:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
05/30/2022 02:48:13 - INFO - __main__ - Global step 2550 Train loss 1.14 Classification-F1 0.1 on epoch=637
05/30/2022 02:48:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.15 on epoch=639
05/30/2022 02:48:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.01 on epoch=642
05/30/2022 02:48:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.16 on epoch=644
05/30/2022 02:48:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.11 on epoch=647
05/30/2022 02:48:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.02 on epoch=649
05/30/2022 02:48:19 - INFO - __main__ - Global step 2600 Train loss 1.09 Classification-F1 0.1 on epoch=649
05/30/2022 02:48:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
05/30/2022 02:48:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.07 on epoch=654
05/30/2022 02:48:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.10 on epoch=657
05/30/2022 02:48:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.10 on epoch=659
05/30/2022 02:48:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.21 on epoch=662
05/30/2022 02:48:26 - INFO - __main__ - Global step 2650 Train loss 1.08 Classification-F1 0.1 on epoch=662
05/30/2022 02:48:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.10 on epoch=664
05/30/2022 02:48:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.06 on epoch=667
05/30/2022 02:48:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.18 on epoch=669
05/30/2022 02:48:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.11 on epoch=672
05/30/2022 02:48:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.08 on epoch=674
05/30/2022 02:48:33 - INFO - __main__ - Global step 2700 Train loss 1.11 Classification-F1 0.1 on epoch=674
05/30/2022 02:48:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.94 on epoch=677
05/30/2022 02:48:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=679
05/30/2022 02:48:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.05 on epoch=682
05/30/2022 02:48:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.08 on epoch=684
05/30/2022 02:48:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.05 on epoch=687
05/30/2022 02:48:40 - INFO - __main__ - Global step 2750 Train loss 1.03 Classification-F1 0.1 on epoch=687
05/30/2022 02:48:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.18 on epoch=689
05/30/2022 02:48:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.97 on epoch=692
05/30/2022 02:48:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.17 on epoch=694
05/30/2022 02:48:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.04 on epoch=697
05/30/2022 02:48:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.15 on epoch=699
05/30/2022 02:48:47 - INFO - __main__ - Global step 2800 Train loss 1.10 Classification-F1 0.1 on epoch=699
05/30/2022 02:48:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.11 on epoch=702
05/30/2022 02:48:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.08 on epoch=704
05/30/2022 02:48:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.02 on epoch=707
05/30/2022 02:48:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.01 on epoch=709
05/30/2022 02:48:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.01 on epoch=712
05/30/2022 02:48:54 - INFO - __main__ - Global step 2850 Train loss 1.04 Classification-F1 0.1 on epoch=712
05/30/2022 02:48:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.05 on epoch=714
05/30/2022 02:48:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.01 on epoch=717
05/30/2022 02:48:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.03 on epoch=719
05/30/2022 02:48:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.07 on epoch=722
05/30/2022 02:49:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.03 on epoch=724
05/30/2022 02:49:01 - INFO - __main__ - Global step 2900 Train loss 1.04 Classification-F1 0.1 on epoch=724
05/30/2022 02:49:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.04 on epoch=727
05/30/2022 02:49:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.09 on epoch=729
05/30/2022 02:49:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.04 on epoch=732
05/30/2022 02:49:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.18 on epoch=734
05/30/2022 02:49:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.09 on epoch=737
05/30/2022 02:49:07 - INFO - __main__ - Global step 2950 Train loss 1.09 Classification-F1 0.1 on epoch=737
05/30/2022 02:49:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.05 on epoch=739
05/30/2022 02:49:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.04 on epoch=742
05/30/2022 02:49:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.18 on epoch=744
05/30/2022 02:49:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=747
05/30/2022 02:49:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.15 on epoch=749
05/30/2022 02:49:14 - INFO - __main__ - Global step 3000 Train loss 1.08 Classification-F1 0.1 on epoch=749
05/30/2022 02:49:14 - INFO - __main__ - save last model!
05/30/2022 02:49:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:49:14 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:49:14 - INFO - __main__ - Printing 3 examples
05/30/2022 02:49:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:49:14 - INFO - __main__ - ['others']
05/30/2022 02:49:14 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:49:14 - INFO - __main__ - ['others']
05/30/2022 02:49:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:49:14 - INFO - __main__ - ['others']
05/30/2022 02:49:14 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:49:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:49:15 - INFO - __main__ - Printing 3 examples
05/30/2022 02:49:15 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 02:49:15 - INFO - __main__ - ['others']
05/30/2022 02:49:15 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 02:49:15 - INFO - __main__ - ['others']
05/30/2022 02:49:15 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 02:49:15 - INFO - __main__ - ['others']
05/30/2022 02:49:15 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:49:15 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:49:15 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:49:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:49:15 - INFO - __main__ - Printing 3 examples
05/30/2022 02:49:15 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 02:49:15 - INFO - __main__ - ['others']
05/30/2022 02:49:15 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 02:49:15 - INFO - __main__ - ['others']
05/30/2022 02:49:15 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 02:49:15 - INFO - __main__ - ['others']
05/30/2022 02:49:15 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:49:15 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:49:15 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:49:16 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:49:21 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:49:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:49:21 - INFO - __main__ - Starting training!
05/30/2022 02:49:22 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:50:06 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_42_0.2_8_predictions.txt
05/30/2022 02:50:06 - INFO - __main__ - Classification-F1 on test data: 0.0257
05/30/2022 02:50:06 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.1468058968058968, test_performance=0.025658687790597552
05/30/2022 02:50:06 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
05/30/2022 02:50:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:50:07 - INFO - __main__ - Printing 3 examples
05/30/2022 02:50:07 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 02:50:07 - INFO - __main__ - ['others']
05/30/2022 02:50:07 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 02:50:07 - INFO - __main__ - ['others']
05/30/2022 02:50:07 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 02:50:07 - INFO - __main__ - ['others']
05/30/2022 02:50:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:50:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:50:07 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:50:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:50:07 - INFO - __main__ - Printing 3 examples
05/30/2022 02:50:07 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 02:50:07 - INFO - __main__ - ['others']
05/30/2022 02:50:07 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 02:50:07 - INFO - __main__ - ['others']
05/30/2022 02:50:07 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 02:50:07 - INFO - __main__ - ['others']
05/30/2022 02:50:07 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:50:07 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:50:07 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:50:12 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:50:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:50:12 - INFO - __main__ - Starting training!
05/30/2022 02:50:14 - INFO - __main__ - Step 10 Global step 10 Train loss 6.70 on epoch=2
05/30/2022 02:50:15 - INFO - __main__ - Step 20 Global step 20 Train loss 6.61 on epoch=4
05/30/2022 02:50:16 - INFO - __main__ - Step 30 Global step 30 Train loss 6.22 on epoch=7
05/30/2022 02:50:18 - INFO - __main__ - Step 40 Global step 40 Train loss 5.81 on epoch=9
05/30/2022 02:50:19 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=12
05/30/2022 02:50:23 - INFO - __main__ - Global step 50 Train loss 6.18 Classification-F1 0.0 on epoch=12
05/30/2022 02:50:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:50:24 - INFO - __main__ - Step 60 Global step 60 Train loss 5.17 on epoch=14
05/30/2022 02:50:25 - INFO - __main__ - Step 70 Global step 70 Train loss 4.83 on epoch=17
05/30/2022 02:50:27 - INFO - __main__ - Step 80 Global step 80 Train loss 4.36 on epoch=19
05/30/2022 02:50:28 - INFO - __main__ - Step 90 Global step 90 Train loss 4.15 on epoch=22
05/30/2022 02:50:29 - INFO - __main__ - Step 100 Global step 100 Train loss 3.93 on epoch=24
05/30/2022 02:50:30 - INFO - __main__ - Global step 100 Train loss 4.49 Classification-F1 0.22426438296003515 on epoch=24
05/30/2022 02:50:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.22426438296003515 on epoch=24, global_step=100
05/30/2022 02:50:31 - INFO - __main__ - Step 110 Global step 110 Train loss 3.93 on epoch=27
05/30/2022 02:50:32 - INFO - __main__ - Step 120 Global step 120 Train loss 3.38 on epoch=29
05/30/2022 02:50:34 - INFO - __main__ - Step 130 Global step 130 Train loss 3.35 on epoch=32
05/30/2022 02:50:35 - INFO - __main__ - Step 140 Global step 140 Train loss 3.24 on epoch=34
05/30/2022 02:50:36 - INFO - __main__ - Step 150 Global step 150 Train loss 3.27 on epoch=37
05/30/2022 02:50:37 - INFO - __main__ - Global step 150 Train loss 3.44 Classification-F1 0.06507515473032714 on epoch=37
05/30/2022 02:50:38 - INFO - __main__ - Step 160 Global step 160 Train loss 2.89 on epoch=39
05/30/2022 02:50:39 - INFO - __main__ - Step 170 Global step 170 Train loss 3.02 on epoch=42
05/30/2022 02:50:40 - INFO - __main__ - Step 180 Global step 180 Train loss 2.78 on epoch=44
05/30/2022 02:50:42 - INFO - __main__ - Step 190 Global step 190 Train loss 2.83 on epoch=47
05/30/2022 02:50:43 - INFO - __main__ - Step 200 Global step 200 Train loss 2.75 on epoch=49
05/30/2022 02:50:43 - INFO - __main__ - Global step 200 Train loss 2.85 Classification-F1 0.15587044534412953 on epoch=49
05/30/2022 02:50:45 - INFO - __main__ - Step 210 Global step 210 Train loss 2.83 on epoch=52
05/30/2022 02:50:46 - INFO - __main__ - Step 220 Global step 220 Train loss 2.55 on epoch=54
05/30/2022 02:50:47 - INFO - __main__ - Step 230 Global step 230 Train loss 2.54 on epoch=57
05/30/2022 02:50:49 - INFO - __main__ - Step 240 Global step 240 Train loss 2.40 on epoch=59
05/30/2022 02:50:50 - INFO - __main__ - Step 250 Global step 250 Train loss 2.76 on epoch=62
05/30/2022 02:50:50 - INFO - __main__ - Global step 250 Train loss 2.61 Classification-F1 0.19654556283502084 on epoch=62
05/30/2022 02:50:52 - INFO - __main__ - Step 260 Global step 260 Train loss 2.53 on epoch=64
05/30/2022 02:50:53 - INFO - __main__ - Step 270 Global step 270 Train loss 2.59 on epoch=67
05/30/2022 02:50:54 - INFO - __main__ - Step 280 Global step 280 Train loss 2.35 on epoch=69
05/30/2022 02:50:55 - INFO - __main__ - Step 290 Global step 290 Train loss 2.38 on epoch=72
05/30/2022 02:50:57 - INFO - __main__ - Step 300 Global step 300 Train loss 2.10 on epoch=74
05/30/2022 02:50:57 - INFO - __main__ - Global step 300 Train loss 2.39 Classification-F1 0.13067758749069247 on epoch=74
05/30/2022 02:50:58 - INFO - __main__ - Step 310 Global step 310 Train loss 2.10 on epoch=77
05/30/2022 02:51:00 - INFO - __main__ - Step 320 Global step 320 Train loss 2.04 on epoch=79
05/30/2022 02:51:01 - INFO - __main__ - Step 330 Global step 330 Train loss 2.21 on epoch=82
05/30/2022 02:51:02 - INFO - __main__ - Step 340 Global step 340 Train loss 2.01 on epoch=84
05/30/2022 02:51:03 - INFO - __main__ - Step 350 Global step 350 Train loss 2.00 on epoch=87
05/30/2022 02:51:04 - INFO - __main__ - Global step 350 Train loss 2.07 Classification-F1 0.11722488038277512 on epoch=87
05/30/2022 02:51:05 - INFO - __main__ - Step 360 Global step 360 Train loss 1.87 on epoch=89
05/30/2022 02:51:06 - INFO - __main__ - Step 370 Global step 370 Train loss 1.90 on epoch=92
05/30/2022 02:51:08 - INFO - __main__ - Step 380 Global step 380 Train loss 1.77 on epoch=94
05/30/2022 02:51:09 - INFO - __main__ - Step 390 Global step 390 Train loss 1.89 on epoch=97
05/30/2022 02:51:10 - INFO - __main__ - Step 400 Global step 400 Train loss 1.82 on epoch=99
05/30/2022 02:51:11 - INFO - __main__ - Global step 400 Train loss 1.85 Classification-F1 0.2011385199240987 on epoch=99
05/30/2022 02:51:12 - INFO - __main__ - Step 410 Global step 410 Train loss 1.74 on epoch=102
05/30/2022 02:51:13 - INFO - __main__ - Step 420 Global step 420 Train loss 1.62 on epoch=104
05/30/2022 02:51:15 - INFO - __main__ - Step 430 Global step 430 Train loss 1.73 on epoch=107
05/30/2022 02:51:16 - INFO - __main__ - Step 440 Global step 440 Train loss 1.67 on epoch=109
05/30/2022 02:51:18 - INFO - __main__ - Step 450 Global step 450 Train loss 1.74 on epoch=112
05/30/2022 02:51:18 - INFO - __main__ - Global step 450 Train loss 1.70 Classification-F1 0.09615384615384615 on epoch=112
05/30/2022 02:51:20 - INFO - __main__ - Step 460 Global step 460 Train loss 1.55 on epoch=114
05/30/2022 02:51:21 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=117
05/30/2022 02:51:22 - INFO - __main__ - Step 480 Global step 480 Train loss 1.46 on epoch=119
05/30/2022 02:51:24 - INFO - __main__ - Step 490 Global step 490 Train loss 1.53 on epoch=122
05/30/2022 02:51:25 - INFO - __main__ - Step 500 Global step 500 Train loss 1.41 on epoch=124
05/30/2022 02:51:25 - INFO - __main__ - Global step 500 Train loss 1.54 Classification-F1 0.15526315789473685 on epoch=124
05/30/2022 02:51:27 - INFO - __main__ - Step 510 Global step 510 Train loss 1.52 on epoch=127
05/30/2022 02:51:28 - INFO - __main__ - Step 520 Global step 520 Train loss 1.44 on epoch=129
05/30/2022 02:51:29 - INFO - __main__ - Step 530 Global step 530 Train loss 1.49 on epoch=132
05/30/2022 02:51:31 - INFO - __main__ - Step 540 Global step 540 Train loss 1.50 on epoch=134
05/30/2022 02:51:32 - INFO - __main__ - Step 550 Global step 550 Train loss 1.40 on epoch=137
05/30/2022 02:51:32 - INFO - __main__ - Global step 550 Train loss 1.47 Classification-F1 0.13026315789473686 on epoch=137
05/30/2022 02:51:34 - INFO - __main__ - Step 560 Global step 560 Train loss 1.33 on epoch=139
05/30/2022 02:51:35 - INFO - __main__ - Step 570 Global step 570 Train loss 1.35 on epoch=142
05/30/2022 02:51:36 - INFO - __main__ - Step 580 Global step 580 Train loss 1.29 on epoch=144
05/30/2022 02:51:38 - INFO - __main__ - Step 590 Global step 590 Train loss 1.46 on epoch=147
05/30/2022 02:51:39 - INFO - __main__ - Step 600 Global step 600 Train loss 1.38 on epoch=149
05/30/2022 02:51:39 - INFO - __main__ - Global step 600 Train loss 1.36 Classification-F1 0.13034188034188032 on epoch=149
05/30/2022 02:51:41 - INFO - __main__ - Step 610 Global step 610 Train loss 1.27 on epoch=152
05/30/2022 02:51:42 - INFO - __main__ - Step 620 Global step 620 Train loss 1.26 on epoch=154
05/30/2022 02:51:43 - INFO - __main__ - Step 630 Global step 630 Train loss 1.23 on epoch=157
05/30/2022 02:51:44 - INFO - __main__ - Step 640 Global step 640 Train loss 1.32 on epoch=159
05/30/2022 02:51:46 - INFO - __main__ - Step 650 Global step 650 Train loss 1.19 on epoch=162
05/30/2022 02:51:46 - INFO - __main__ - Global step 650 Train loss 1.25 Classification-F1 0.16926248282180484 on epoch=162
05/30/2022 02:51:47 - INFO - __main__ - Step 660 Global step 660 Train loss 1.26 on epoch=164
05/30/2022 02:51:49 - INFO - __main__ - Step 670 Global step 670 Train loss 1.36 on epoch=167
05/30/2022 02:51:50 - INFO - __main__ - Step 680 Global step 680 Train loss 1.22 on epoch=169
05/30/2022 02:51:51 - INFO - __main__ - Step 690 Global step 690 Train loss 1.10 on epoch=172
05/30/2022 02:51:52 - INFO - __main__ - Step 700 Global step 700 Train loss 1.16 on epoch=174
05/30/2022 02:51:53 - INFO - __main__ - Global step 700 Train loss 1.22 Classification-F1 0.10126582278481013 on epoch=174
05/30/2022 02:51:54 - INFO - __main__ - Step 710 Global step 710 Train loss 1.10 on epoch=177
05/30/2022 02:51:55 - INFO - __main__ - Step 720 Global step 720 Train loss 1.17 on epoch=179
05/30/2022 02:51:57 - INFO - __main__ - Step 730 Global step 730 Train loss 1.10 on epoch=182
05/30/2022 02:51:58 - INFO - __main__ - Step 740 Global step 740 Train loss 1.02 on epoch=184
05/30/2022 02:51:59 - INFO - __main__ - Step 750 Global step 750 Train loss 1.14 on epoch=187
05/30/2022 02:52:00 - INFO - __main__ - Global step 750 Train loss 1.11 Classification-F1 0.1 on epoch=187
05/30/2022 02:52:01 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=189
05/30/2022 02:52:02 - INFO - __main__ - Step 770 Global step 770 Train loss 1.19 on epoch=192
05/30/2022 02:52:04 - INFO - __main__ - Step 780 Global step 780 Train loss 1.15 on epoch=194
05/30/2022 02:52:05 - INFO - __main__ - Step 790 Global step 790 Train loss 1.15 on epoch=197
05/30/2022 02:52:06 - INFO - __main__ - Step 800 Global step 800 Train loss 1.04 on epoch=199
05/30/2022 02:52:07 - INFO - __main__ - Global step 800 Train loss 1.15 Classification-F1 0.13541666666666669 on epoch=199
05/30/2022 02:52:08 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=202
05/30/2022 02:52:09 - INFO - __main__ - Step 820 Global step 820 Train loss 1.14 on epoch=204
05/30/2022 02:52:10 - INFO - __main__ - Step 830 Global step 830 Train loss 1.09 on epoch=207
05/30/2022 02:52:12 - INFO - __main__ - Step 840 Global step 840 Train loss 1.01 on epoch=209
05/30/2022 02:52:13 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=212
05/30/2022 02:52:13 - INFO - __main__ - Global step 850 Train loss 1.11 Classification-F1 0.15535714285714286 on epoch=212
05/30/2022 02:52:15 - INFO - __main__ - Step 860 Global step 860 Train loss 1.21 on epoch=214
05/30/2022 02:52:16 - INFO - __main__ - Step 870 Global step 870 Train loss 1.13 on epoch=217
05/30/2022 02:52:17 - INFO - __main__ - Step 880 Global step 880 Train loss 1.18 on epoch=219
05/30/2022 02:52:18 - INFO - __main__ - Step 890 Global step 890 Train loss 1.28 on epoch=222
05/30/2022 02:52:20 - INFO - __main__ - Step 900 Global step 900 Train loss 1.21 on epoch=224
05/30/2022 02:52:20 - INFO - __main__ - Global step 900 Train loss 1.20 Classification-F1 0.18014375561545376 on epoch=224
05/30/2022 02:52:21 - INFO - __main__ - Step 910 Global step 910 Train loss 1.19 on epoch=227
05/30/2022 02:52:23 - INFO - __main__ - Step 920 Global step 920 Train loss 1.09 on epoch=229
05/30/2022 02:52:24 - INFO - __main__ - Step 930 Global step 930 Train loss 1.08 on epoch=232
05/30/2022 02:52:25 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=234
05/30/2022 02:52:26 - INFO - __main__ - Step 950 Global step 950 Train loss 1.04 on epoch=237
05/30/2022 02:52:27 - INFO - __main__ - Global step 950 Train loss 1.11 Classification-F1 0.1484375 on epoch=237
05/30/2022 02:52:28 - INFO - __main__ - Step 960 Global step 960 Train loss 1.05 on epoch=239
05/30/2022 02:52:29 - INFO - __main__ - Step 970 Global step 970 Train loss 1.12 on epoch=242
05/30/2022 02:52:31 - INFO - __main__ - Step 980 Global step 980 Train loss 1.08 on epoch=244
05/30/2022 02:52:32 - INFO - __main__ - Step 990 Global step 990 Train loss 1.04 on epoch=247
05/30/2022 02:52:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.03 on epoch=249
05/30/2022 02:52:34 - INFO - __main__ - Global step 1000 Train loss 1.07 Classification-F1 0.12333965844402277 on epoch=249
05/30/2022 02:52:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.09 on epoch=252
05/30/2022 02:52:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.15 on epoch=254
05/30/2022 02:52:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=257
05/30/2022 02:52:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.10 on epoch=259
05/30/2022 02:52:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=262
05/30/2022 02:52:41 - INFO - __main__ - Global step 1050 Train loss 1.10 Classification-F1 0.1875 on epoch=262
05/30/2022 02:52:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=264
05/30/2022 02:52:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.02 on epoch=267
05/30/2022 02:52:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.97 on epoch=269
05/30/2022 02:52:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.04 on epoch=272
05/30/2022 02:52:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.02 on epoch=274
05/30/2022 02:52:47 - INFO - __main__ - Global step 1100 Train loss 1.02 Classification-F1 0.15607940446650126 on epoch=274
05/30/2022 02:52:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.00 on epoch=277
05/30/2022 02:52:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.07 on epoch=279
05/30/2022 02:52:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=282
05/30/2022 02:52:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.02 on epoch=284
05/30/2022 02:52:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.08 on epoch=287
05/30/2022 02:52:54 - INFO - __main__ - Global step 1150 Train loss 1.03 Classification-F1 0.12368421052631579 on epoch=287
05/30/2022 02:52:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.05 on epoch=289
05/30/2022 02:52:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=292
05/30/2022 02:52:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.08 on epoch=294
05/30/2022 02:52:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.19 on epoch=297
05/30/2022 02:53:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.13 on epoch=299
05/30/2022 02:53:01 - INFO - __main__ - Global step 1200 Train loss 1.10 Classification-F1 0.1565349544072948 on epoch=299
05/30/2022 02:53:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.03 on epoch=302
05/30/2022 02:53:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.10 on epoch=304
05/30/2022 02:53:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.16 on epoch=307
05/30/2022 02:53:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.01 on epoch=309
05/30/2022 02:53:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.04 on epoch=312
05/30/2022 02:53:08 - INFO - __main__ - Global step 1250 Train loss 1.07 Classification-F1 0.1 on epoch=312
05/30/2022 02:53:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=314
05/30/2022 02:53:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.02 on epoch=317
05/30/2022 02:53:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.08 on epoch=319
05/30/2022 02:53:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.06 on epoch=322
05/30/2022 02:53:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.08 on epoch=324
05/30/2022 02:53:15 - INFO - __main__ - Global step 1300 Train loss 1.05 Classification-F1 0.20417422867513613 on epoch=324
05/30/2022 02:53:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.13 on epoch=327
05/30/2022 02:53:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.06 on epoch=329
05/30/2022 02:53:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.99 on epoch=332
05/30/2022 02:53:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.06 on epoch=334
05/30/2022 02:53:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.98 on epoch=337
05/30/2022 02:53:21 - INFO - __main__ - Global step 1350 Train loss 1.04 Classification-F1 0.09090909090909091 on epoch=337
05/30/2022 02:53:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.05 on epoch=339
05/30/2022 02:53:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.96 on epoch=342
05/30/2022 02:53:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.06 on epoch=344
05/30/2022 02:53:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.98 on epoch=347
05/30/2022 02:53:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.95 on epoch=349
05/30/2022 02:53:29 - INFO - __main__ - Global step 1400 Train loss 1.00 Classification-F1 0.09305210918114144 on epoch=349
05/30/2022 02:53:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.97 on epoch=352
05/30/2022 02:53:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/30/2022 02:53:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.95 on epoch=357
05/30/2022 02:53:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.96 on epoch=359
05/30/2022 02:53:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.93 on epoch=362
05/30/2022 02:53:36 - INFO - __main__ - Global step 1450 Train loss 0.96 Classification-F1 0.11687344913151365 on epoch=362
05/30/2022 02:53:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.90 on epoch=364
05/30/2022 02:53:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.02 on epoch=367
05/30/2022 02:53:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.12 on epoch=369
05/30/2022 02:53:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.93 on epoch=372
05/30/2022 02:53:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.88 on epoch=374
05/30/2022 02:53:44 - INFO - __main__ - Global step 1500 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=374
05/30/2022 02:53:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.07 on epoch=377
05/30/2022 02:53:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=379
05/30/2022 02:53:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.89 on epoch=382
05/30/2022 02:53:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.86 on epoch=384
05/30/2022 02:53:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.01 on epoch=387
05/30/2022 02:53:51 - INFO - __main__ - Global step 1550 Train loss 0.97 Classification-F1 0.1 on epoch=387
05/30/2022 02:53:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.89 on epoch=389
05/30/2022 02:53:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.95 on epoch=392
05/30/2022 02:53:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.00 on epoch=394
05/30/2022 02:53:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.88 on epoch=397
05/30/2022 02:53:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
05/30/2022 02:53:58 - INFO - __main__ - Global step 1600 Train loss 0.94 Classification-F1 0.1 on epoch=399
05/30/2022 02:54:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.05 on epoch=402
05/30/2022 02:54:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.93 on epoch=404
05/30/2022 02:54:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.92 on epoch=407
05/30/2022 02:54:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.00 on epoch=409
05/30/2022 02:54:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.99 on epoch=412
05/30/2022 02:54:06 - INFO - __main__ - Global step 1650 Train loss 0.98 Classification-F1 0.17408906882591094 on epoch=412
05/30/2022 02:54:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.00 on epoch=414
05/30/2022 02:54:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=417
05/30/2022 02:54:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.98 on epoch=419
05/30/2022 02:54:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.96 on epoch=422
05/30/2022 02:54:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.94 on epoch=424
05/30/2022 02:54:12 - INFO - __main__ - Global step 1700 Train loss 0.99 Classification-F1 0.1 on epoch=424
05/30/2022 02:54:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.95 on epoch=427
05/30/2022 02:54:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/30/2022 02:54:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.97 on epoch=432
05/30/2022 02:54:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.90 on epoch=434
05/30/2022 02:54:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.94 on epoch=437
05/30/2022 02:54:19 - INFO - __main__ - Global step 1750 Train loss 0.95 Classification-F1 0.1 on epoch=437
05/30/2022 02:54:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.96 on epoch=439
05/30/2022 02:54:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=442
05/30/2022 02:54:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=444
05/30/2022 02:54:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.95 on epoch=447
05/30/2022 02:54:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=449
05/30/2022 02:54:26 - INFO - __main__ - Global step 1800 Train loss 0.95 Classification-F1 0.1 on epoch=449
05/30/2022 02:54:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.06 on epoch=452
05/30/2022 02:54:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.10 on epoch=454
05/30/2022 02:54:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.90 on epoch=457
05/30/2022 02:54:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.92 on epoch=459
05/30/2022 02:54:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.91 on epoch=462
05/30/2022 02:54:33 - INFO - __main__ - Global step 1850 Train loss 0.98 Classification-F1 0.1488888888888889 on epoch=462
05/30/2022 02:54:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.93 on epoch=464
05/30/2022 02:54:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.86 on epoch=467
05/30/2022 02:54:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.96 on epoch=469
05/30/2022 02:54:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.87 on epoch=472
05/30/2022 02:54:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.89 on epoch=474
05/30/2022 02:54:40 - INFO - __main__ - Global step 1900 Train loss 0.90 Classification-F1 0.1238095238095238 on epoch=474
05/30/2022 02:54:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.06 on epoch=477
05/30/2022 02:54:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.95 on epoch=479
05/30/2022 02:54:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.97 on epoch=482
05/30/2022 02:54:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=484
05/30/2022 02:54:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.00 on epoch=487
05/30/2022 02:54:47 - INFO - __main__ - Global step 1950 Train loss 0.98 Classification-F1 0.13067758749069247 on epoch=487
05/30/2022 02:54:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=489
05/30/2022 02:54:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=492
05/30/2022 02:54:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.98 on epoch=494
05/30/2022 02:54:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.98 on epoch=497
05/30/2022 02:54:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/30/2022 02:54:53 - INFO - __main__ - Global step 2000 Train loss 0.96 Classification-F1 0.1980392156862745 on epoch=499
05/30/2022 02:54:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.88 on epoch=502
05/30/2022 02:54:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.89 on epoch=504
05/30/2022 02:54:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=507
05/30/2022 02:54:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.86 on epoch=509
05/30/2022 02:55:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.94 on epoch=512
05/30/2022 02:55:00 - INFO - __main__ - Global step 2050 Train loss 0.91 Classification-F1 0.12447885646217988 on epoch=512
05/30/2022 02:55:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.94 on epoch=514
05/30/2022 02:55:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.91 on epoch=517
05/30/2022 02:55:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.93 on epoch=519
05/30/2022 02:55:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.87 on epoch=522
05/30/2022 02:55:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.93 on epoch=524
05/30/2022 02:55:07 - INFO - __main__ - Global step 2100 Train loss 0.92 Classification-F1 0.12391774891774893 on epoch=524
05/30/2022 02:55:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.88 on epoch=527
05/30/2022 02:55:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=529
05/30/2022 02:55:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.02 on epoch=532
05/30/2022 02:55:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/30/2022 02:55:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.03 on epoch=537
05/30/2022 02:55:14 - INFO - __main__ - Global step 2150 Train loss 0.99 Classification-F1 0.13034188034188032 on epoch=537
05/30/2022 02:55:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.93 on epoch=539
05/30/2022 02:55:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.03 on epoch=542
05/30/2022 02:55:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.86 on epoch=544
05/30/2022 02:55:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.03 on epoch=547
05/30/2022 02:55:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.94 on epoch=549
05/30/2022 02:55:21 - INFO - __main__ - Global step 2200 Train loss 0.96 Classification-F1 0.12439024390243902 on epoch=549
05/30/2022 02:55:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.93 on epoch=552
05/30/2022 02:55:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.90 on epoch=554
05/30/2022 02:55:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.04 on epoch=557
05/30/2022 02:55:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.91 on epoch=559
05/30/2022 02:55:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.95 on epoch=562
05/30/2022 02:55:28 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.18674449412154331 on epoch=562
05/30/2022 02:55:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.89 on epoch=564
05/30/2022 02:55:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.07 on epoch=567
05/30/2022 02:55:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.99 on epoch=569
05/30/2022 02:55:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.02 on epoch=572
05/30/2022 02:55:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.96 on epoch=574
05/30/2022 02:55:34 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.10987903225806452 on epoch=574
05/30/2022 02:55:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.90 on epoch=577
05/30/2022 02:55:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.03 on epoch=579
05/30/2022 02:55:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=582
05/30/2022 02:55:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.97 on epoch=584
05/30/2022 02:55:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.99 on epoch=587
05/30/2022 02:55:41 - INFO - __main__ - Global step 2350 Train loss 0.97 Classification-F1 0.10126582278481013 on epoch=587
05/30/2022 02:55:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.93 on epoch=589
05/30/2022 02:55:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.98 on epoch=592
05/30/2022 02:55:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.98 on epoch=594
05/30/2022 02:55:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.93 on epoch=597
05/30/2022 02:55:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.06 on epoch=599
05/30/2022 02:55:48 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.13865546218487396 on epoch=599
05/30/2022 02:55:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.03 on epoch=602
05/30/2022 02:55:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.90 on epoch=604
05/30/2022 02:55:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.01 on epoch=607
05/30/2022 02:55:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.00 on epoch=609
05/30/2022 02:55:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.93 on epoch=612
05/30/2022 02:55:55 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.2440667318162781 on epoch=612
05/30/2022 02:55:55 - INFO - __main__ - Saving model with best Classification-F1: 0.22426438296003515 -> 0.2440667318162781 on epoch=612, global_step=2450
05/30/2022 02:55:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.85 on epoch=614
05/30/2022 02:55:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.92 on epoch=617
05/30/2022 02:55:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.98 on epoch=619
05/30/2022 02:56:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.03 on epoch=622
05/30/2022 02:56:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/30/2022 02:56:02 - INFO - __main__ - Global step 2500 Train loss 0.94 Classification-F1 0.1 on epoch=624
05/30/2022 02:56:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.90 on epoch=627
05/30/2022 02:56:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.96 on epoch=629
05/30/2022 02:56:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.95 on epoch=632
05/30/2022 02:56:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.00 on epoch=634
05/30/2022 02:56:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.96 on epoch=637
05/30/2022 02:56:08 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.17893217893217894 on epoch=637
05/30/2022 02:56:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.84 on epoch=639
05/30/2022 02:56:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.04 on epoch=642
05/30/2022 02:56:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.05 on epoch=644
05/30/2022 02:56:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.02 on epoch=647
05/30/2022 02:56:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.96 on epoch=649
05/30/2022 02:56:15 - INFO - __main__ - Global step 2600 Train loss 0.98 Classification-F1 0.10666666666666667 on epoch=649
05/30/2022 02:56:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.84 on epoch=652
05/30/2022 02:56:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.86 on epoch=654
05/30/2022 02:56:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.94 on epoch=657
05/30/2022 02:56:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.98 on epoch=659
05/30/2022 02:56:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.94 on epoch=662
05/30/2022 02:56:22 - INFO - __main__ - Global step 2650 Train loss 0.91 Classification-F1 0.10677083333333333 on epoch=662
05/30/2022 02:56:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.87 on epoch=664
05/30/2022 02:56:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=667
05/30/2022 02:56:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/30/2022 02:56:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.92 on epoch=672
05/30/2022 02:56:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=674
05/30/2022 02:56:29 - INFO - __main__ - Global step 2700 Train loss 0.91 Classification-F1 0.1 on epoch=674
05/30/2022 02:56:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.01 on epoch=677
05/30/2022 02:56:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
05/30/2022 02:56:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
05/30/2022 02:56:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=684
05/30/2022 02:56:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.93 on epoch=687
05/30/2022 02:56:36 - INFO - __main__ - Global step 2750 Train loss 0.91 Classification-F1 0.09333333333333334 on epoch=687
05/30/2022 02:56:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=689
05/30/2022 02:56:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.99 on epoch=692
05/30/2022 02:56:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.96 on epoch=694
05/30/2022 02:56:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.96 on epoch=697
05/30/2022 02:56:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
05/30/2022 02:56:43 - INFO - __main__ - Global step 2800 Train loss 0.96 Classification-F1 0.13167388167388167 on epoch=699
05/30/2022 02:56:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=702
05/30/2022 02:56:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=704
05/30/2022 02:56:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
05/30/2022 02:56:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.84 on epoch=709
05/30/2022 02:56:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=712
05/30/2022 02:56:49 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.18276972624798712 on epoch=712
05/30/2022 02:56:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.98 on epoch=714
05/30/2022 02:56:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.91 on epoch=717
05/30/2022 02:56:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.78 on epoch=719
05/30/2022 02:56:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.86 on epoch=722
05/30/2022 02:56:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.88 on epoch=724
05/30/2022 02:56:56 - INFO - __main__ - Global step 2900 Train loss 0.88 Classification-F1 0.202020202020202 on epoch=724
05/30/2022 02:56:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.90 on epoch=727
05/30/2022 02:56:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.88 on epoch=729
05/30/2022 02:57:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.99 on epoch=732
05/30/2022 02:57:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.88 on epoch=734
05/30/2022 02:57:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.94 on epoch=737
05/30/2022 02:57:03 - INFO - __main__ - Global step 2950 Train loss 0.92 Classification-F1 0.16071428571428573 on epoch=737
05/30/2022 02:57:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.95 on epoch=739
05/30/2022 02:57:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.93 on epoch=742
05/30/2022 02:57:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.86 on epoch=744
05/30/2022 02:57:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.97 on epoch=747
05/30/2022 02:57:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.95 on epoch=749
05/30/2022 02:57:10 - INFO - __main__ - Global step 3000 Train loss 0.93 Classification-F1 0.21354166666666669 on epoch=749
05/30/2022 02:57:10 - INFO - __main__ - save last model!
05/30/2022 02:57:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 02:57:10 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 02:57:10 - INFO - __main__ - Printing 3 examples
05/30/2022 02:57:10 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 02:57:10 - INFO - __main__ - ['others']
05/30/2022 02:57:10 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 02:57:10 - INFO - __main__ - ['others']
05/30/2022 02:57:10 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 02:57:10 - INFO - __main__ - ['others']
05/30/2022 02:57:10 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:57:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:57:11 - INFO - __main__ - Printing 3 examples
05/30/2022 02:57:11 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 02:57:11 - INFO - __main__ - ['others']
05/30/2022 02:57:11 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 02:57:11 - INFO - __main__ - ['others']
05/30/2022 02:57:11 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 02:57:11 - INFO - __main__ - ['others']
05/30/2022 02:57:11 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:57:11 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:57:11 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:57:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:57:11 - INFO - __main__ - Printing 3 examples
05/30/2022 02:57:11 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 02:57:11 - INFO - __main__ - ['others']
05/30/2022 02:57:11 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 02:57:11 - INFO - __main__ - ['others']
05/30/2022 02:57:11 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 02:57:11 - INFO - __main__ - ['others']
05/30/2022 02:57:11 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:57:11 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:57:11 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:57:12 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:57:16 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:57:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:57:16 - INFO - __main__ - Starting training!
05/30/2022 02:57:17 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 02:58:01 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.5_8_predictions.txt
05/30/2022 02:58:01 - INFO - __main__ - Classification-F1 on test data: 0.0580
05/30/2022 02:58:01 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.2440667318162781, test_performance=0.057998635256980235
05/30/2022 02:58:01 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
05/30/2022 02:58:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:58:02 - INFO - __main__ - Printing 3 examples
05/30/2022 02:58:02 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 02:58:02 - INFO - __main__ - ['others']
05/30/2022 02:58:02 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 02:58:02 - INFO - __main__ - ['others']
05/30/2022 02:58:02 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 02:58:02 - INFO - __main__ - ['others']
05/30/2022 02:58:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:58:02 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:58:02 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 02:58:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 02:58:02 - INFO - __main__ - Printing 3 examples
05/30/2022 02:58:02 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 02:58:02 - INFO - __main__ - ['others']
05/30/2022 02:58:02 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 02:58:02 - INFO - __main__ - ['others']
05/30/2022 02:58:02 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 02:58:02 - INFO - __main__ - ['others']
05/30/2022 02:58:02 - INFO - __main__ - Tokenizing Input ...
05/30/2022 02:58:02 - INFO - __main__ - Tokenizing Output ...
05/30/2022 02:58:02 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 02:58:08 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 02:58:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 02:58:08 - INFO - __main__ - Starting training!
05/30/2022 02:58:09 - INFO - __main__ - Step 10 Global step 10 Train loss 6.82 on epoch=2
05/30/2022 02:58:11 - INFO - __main__ - Step 20 Global step 20 Train loss 6.60 on epoch=4
05/30/2022 02:58:12 - INFO - __main__ - Step 30 Global step 30 Train loss 6.18 on epoch=7
05/30/2022 02:58:13 - INFO - __main__ - Step 40 Global step 40 Train loss 6.08 on epoch=9
05/30/2022 02:58:14 - INFO - __main__ - Step 50 Global step 50 Train loss 5.78 on epoch=12
05/30/2022 02:58:16 - INFO - __main__ - Global step 50 Train loss 6.29 Classification-F1 0.0 on epoch=12
05/30/2022 02:58:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 02:58:17 - INFO - __main__ - Step 60 Global step 60 Train loss 5.61 on epoch=14
05/30/2022 02:58:18 - INFO - __main__ - Step 70 Global step 70 Train loss 5.57 on epoch=17
05/30/2022 02:58:20 - INFO - __main__ - Step 80 Global step 80 Train loss 5.11 on epoch=19
05/30/2022 02:58:21 - INFO - __main__ - Step 90 Global step 90 Train loss 5.12 on epoch=22
05/30/2022 02:58:22 - INFO - __main__ - Step 100 Global step 100 Train loss 4.93 on epoch=24
05/30/2022 02:58:23 - INFO - __main__ - Global step 100 Train loss 5.27 Classification-F1 0.0 on epoch=24
05/30/2022 02:58:25 - INFO - __main__ - Step 110 Global step 110 Train loss 4.90 on epoch=27
05/30/2022 02:58:26 - INFO - __main__ - Step 120 Global step 120 Train loss 4.72 on epoch=29
05/30/2022 02:58:27 - INFO - __main__ - Step 130 Global step 130 Train loss 4.67 on epoch=32
05/30/2022 02:58:28 - INFO - __main__ - Step 140 Global step 140 Train loss 4.26 on epoch=34
05/30/2022 02:58:30 - INFO - __main__ - Step 150 Global step 150 Train loss 4.33 on epoch=37
05/30/2022 02:58:30 - INFO - __main__ - Global step 150 Train loss 4.58 Classification-F1 0.1 on epoch=37
05/30/2022 02:58:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.1 on epoch=37, global_step=150
05/30/2022 02:58:31 - INFO - __main__ - Step 160 Global step 160 Train loss 4.06 on epoch=39
05/30/2022 02:58:33 - INFO - __main__ - Step 170 Global step 170 Train loss 4.02 on epoch=42
05/30/2022 02:58:34 - INFO - __main__ - Step 180 Global step 180 Train loss 3.65 on epoch=44
05/30/2022 02:58:35 - INFO - __main__ - Step 190 Global step 190 Train loss 3.83 on epoch=47
05/30/2022 02:58:36 - INFO - __main__ - Step 200 Global step 200 Train loss 3.45 on epoch=49
05/30/2022 02:58:37 - INFO - __main__ - Global step 200 Train loss 3.80 Classification-F1 0.1778115501519757 on epoch=49
05/30/2022 02:58:37 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1778115501519757 on epoch=49, global_step=200
05/30/2022 02:58:38 - INFO - __main__ - Step 210 Global step 210 Train loss 3.38 on epoch=52
05/30/2022 02:58:39 - INFO - __main__ - Step 220 Global step 220 Train loss 3.39 on epoch=54
05/30/2022 02:58:41 - INFO - __main__ - Step 230 Global step 230 Train loss 3.31 on epoch=57
05/30/2022 02:58:42 - INFO - __main__ - Step 240 Global step 240 Train loss 3.15 on epoch=59
05/30/2022 02:58:43 - INFO - __main__ - Step 250 Global step 250 Train loss 3.27 on epoch=62
05/30/2022 02:58:44 - INFO - __main__ - Global step 250 Train loss 3.30 Classification-F1 0.09154929577464789 on epoch=62
05/30/2022 02:58:45 - INFO - __main__ - Step 260 Global step 260 Train loss 2.91 on epoch=64
05/30/2022 02:58:46 - INFO - __main__ - Step 270 Global step 270 Train loss 2.81 on epoch=67
05/30/2022 02:58:48 - INFO - __main__ - Step 280 Global step 280 Train loss 2.67 on epoch=69
05/30/2022 02:58:49 - INFO - __main__ - Step 290 Global step 290 Train loss 2.74 on epoch=72
05/30/2022 02:58:50 - INFO - __main__ - Step 300 Global step 300 Train loss 2.58 on epoch=74
05/30/2022 02:58:51 - INFO - __main__ - Global step 300 Train loss 2.74 Classification-F1 0.13123993558776167 on epoch=74
05/30/2022 02:58:52 - INFO - __main__ - Step 310 Global step 310 Train loss 2.78 on epoch=77
05/30/2022 02:58:53 - INFO - __main__ - Step 320 Global step 320 Train loss 2.45 on epoch=79
05/30/2022 02:58:54 - INFO - __main__ - Step 330 Global step 330 Train loss 2.46 on epoch=82
05/30/2022 02:58:56 - INFO - __main__ - Step 340 Global step 340 Train loss 2.44 on epoch=84
05/30/2022 02:58:57 - INFO - __main__ - Step 350 Global step 350 Train loss 2.39 on epoch=87
05/30/2022 02:58:57 - INFO - __main__ - Global step 350 Train loss 2.50 Classification-F1 0.14509803921568626 on epoch=87
05/30/2022 02:58:59 - INFO - __main__ - Step 360 Global step 360 Train loss 2.24 on epoch=89
05/30/2022 02:59:00 - INFO - __main__ - Step 370 Global step 370 Train loss 2.31 on epoch=92
05/30/2022 02:59:01 - INFO - __main__ - Step 380 Global step 380 Train loss 2.29 on epoch=94
05/30/2022 02:59:02 - INFO - __main__ - Step 390 Global step 390 Train loss 2.29 on epoch=97
05/30/2022 02:59:04 - INFO - __main__ - Step 400 Global step 400 Train loss 2.15 on epoch=99
05/30/2022 02:59:04 - INFO - __main__ - Global step 400 Train loss 2.26 Classification-F1 0.1486842105263158 on epoch=99
05/30/2022 02:59:05 - INFO - __main__ - Step 410 Global step 410 Train loss 2.10 on epoch=102
05/30/2022 02:59:07 - INFO - __main__ - Step 420 Global step 420 Train loss 2.10 on epoch=104
05/30/2022 02:59:08 - INFO - __main__ - Step 430 Global step 430 Train loss 2.00 on epoch=107
05/30/2022 02:59:09 - INFO - __main__ - Step 440 Global step 440 Train loss 1.97 on epoch=109
05/30/2022 02:59:10 - INFO - __main__ - Step 450 Global step 450 Train loss 2.04 on epoch=112
05/30/2022 02:59:11 - INFO - __main__ - Global step 450 Train loss 2.04 Classification-F1 0.1 on epoch=112
05/30/2022 02:59:12 - INFO - __main__ - Step 460 Global step 460 Train loss 2.01 on epoch=114
05/30/2022 02:59:13 - INFO - __main__ - Step 470 Global step 470 Train loss 1.99 on epoch=117
05/30/2022 02:59:15 - INFO - __main__ - Step 480 Global step 480 Train loss 1.97 on epoch=119
05/30/2022 02:59:16 - INFO - __main__ - Step 490 Global step 490 Train loss 1.92 on epoch=122
05/30/2022 02:59:17 - INFO - __main__ - Step 500 Global step 500 Train loss 1.84 on epoch=124
05/30/2022 02:59:18 - INFO - __main__ - Global step 500 Train loss 1.95 Classification-F1 0.1 on epoch=124
05/30/2022 02:59:19 - INFO - __main__ - Step 510 Global step 510 Train loss 1.93 on epoch=127
05/30/2022 02:59:20 - INFO - __main__ - Step 520 Global step 520 Train loss 1.64 on epoch=129
05/30/2022 02:59:22 - INFO - __main__ - Step 530 Global step 530 Train loss 1.88 on epoch=132
05/30/2022 02:59:23 - INFO - __main__ - Step 540 Global step 540 Train loss 1.63 on epoch=134
05/30/2022 02:59:24 - INFO - __main__ - Step 550 Global step 550 Train loss 1.72 on epoch=137
05/30/2022 02:59:25 - INFO - __main__ - Global step 550 Train loss 1.76 Classification-F1 0.1 on epoch=137
05/30/2022 02:59:26 - INFO - __main__ - Step 560 Global step 560 Train loss 1.75 on epoch=139
05/30/2022 02:59:27 - INFO - __main__ - Step 570 Global step 570 Train loss 1.79 on epoch=142
05/30/2022 02:59:28 - INFO - __main__ - Step 580 Global step 580 Train loss 1.78 on epoch=144
05/30/2022 02:59:30 - INFO - __main__ - Step 590 Global step 590 Train loss 1.65 on epoch=147
05/30/2022 02:59:31 - INFO - __main__ - Step 600 Global step 600 Train loss 1.59 on epoch=149
05/30/2022 02:59:31 - INFO - __main__ - Global step 600 Train loss 1.71 Classification-F1 0.15782608695652173 on epoch=149
05/30/2022 02:59:33 - INFO - __main__ - Step 610 Global step 610 Train loss 1.63 on epoch=152
05/30/2022 02:59:34 - INFO - __main__ - Step 620 Global step 620 Train loss 1.61 on epoch=154
05/30/2022 02:59:35 - INFO - __main__ - Step 630 Global step 630 Train loss 1.57 on epoch=157
05/30/2022 02:59:36 - INFO - __main__ - Step 640 Global step 640 Train loss 1.60 on epoch=159
05/30/2022 02:59:38 - INFO - __main__ - Step 650 Global step 650 Train loss 1.53 on epoch=162
05/30/2022 02:59:38 - INFO - __main__ - Global step 650 Train loss 1.59 Classification-F1 0.13067758749069247 on epoch=162
05/30/2022 02:59:39 - INFO - __main__ - Step 660 Global step 660 Train loss 1.48 on epoch=164
05/30/2022 02:59:41 - INFO - __main__ - Step 670 Global step 670 Train loss 1.57 on epoch=167
05/30/2022 02:59:42 - INFO - __main__ - Step 680 Global step 680 Train loss 1.46 on epoch=169
05/30/2022 02:59:43 - INFO - __main__ - Step 690 Global step 690 Train loss 1.50 on epoch=172
05/30/2022 02:59:44 - INFO - __main__ - Step 700 Global step 700 Train loss 1.30 on epoch=174
05/30/2022 02:59:45 - INFO - __main__ - Global step 700 Train loss 1.46 Classification-F1 0.1 on epoch=174
05/30/2022 02:59:46 - INFO - __main__ - Step 710 Global step 710 Train loss 1.37 on epoch=177
05/30/2022 02:59:47 - INFO - __main__ - Step 720 Global step 720 Train loss 1.31 on epoch=179
05/30/2022 02:59:49 - INFO - __main__ - Step 730 Global step 730 Train loss 1.37 on epoch=182
05/30/2022 02:59:50 - INFO - __main__ - Step 740 Global step 740 Train loss 1.35 on epoch=184
05/30/2022 02:59:51 - INFO - __main__ - Step 750 Global step 750 Train loss 1.47 on epoch=187
05/30/2022 02:59:52 - INFO - __main__ - Global step 750 Train loss 1.38 Classification-F1 0.1 on epoch=187
05/30/2022 02:59:53 - INFO - __main__ - Step 760 Global step 760 Train loss 1.32 on epoch=189
05/30/2022 02:59:54 - INFO - __main__ - Step 770 Global step 770 Train loss 1.41 on epoch=192
05/30/2022 02:59:55 - INFO - __main__ - Step 780 Global step 780 Train loss 1.34 on epoch=194
05/30/2022 02:59:57 - INFO - __main__ - Step 790 Global step 790 Train loss 1.43 on epoch=197
05/30/2022 02:59:58 - INFO - __main__ - Step 800 Global step 800 Train loss 1.29 on epoch=199
05/30/2022 02:59:58 - INFO - __main__ - Global step 800 Train loss 1.36 Classification-F1 0.1 on epoch=199
05/30/2022 03:00:00 - INFO - __main__ - Step 810 Global step 810 Train loss 1.31 on epoch=202
05/30/2022 03:00:01 - INFO - __main__ - Step 820 Global step 820 Train loss 1.37 on epoch=204
05/30/2022 03:00:02 - INFO - __main__ - Step 830 Global step 830 Train loss 1.23 on epoch=207
05/30/2022 03:00:03 - INFO - __main__ - Step 840 Global step 840 Train loss 1.31 on epoch=209
05/30/2022 03:00:05 - INFO - __main__ - Step 850 Global step 850 Train loss 1.20 on epoch=212
05/30/2022 03:00:05 - INFO - __main__ - Global step 850 Train loss 1.28 Classification-F1 0.1 on epoch=212
05/30/2022 03:00:06 - INFO - __main__ - Step 860 Global step 860 Train loss 1.19 on epoch=214
05/30/2022 03:00:08 - INFO - __main__ - Step 870 Global step 870 Train loss 1.11 on epoch=217
05/30/2022 03:00:09 - INFO - __main__ - Step 880 Global step 880 Train loss 1.09 on epoch=219
05/30/2022 03:00:10 - INFO - __main__ - Step 890 Global step 890 Train loss 1.33 on epoch=222
05/30/2022 03:00:11 - INFO - __main__ - Step 900 Global step 900 Train loss 1.23 on epoch=224
05/30/2022 03:00:12 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.1 on epoch=224
05/30/2022 03:00:13 - INFO - __main__ - Step 910 Global step 910 Train loss 1.22 on epoch=227
05/30/2022 03:00:15 - INFO - __main__ - Step 920 Global step 920 Train loss 1.14 on epoch=229
05/30/2022 03:00:16 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=232
05/30/2022 03:00:17 - INFO - __main__ - Step 940 Global step 940 Train loss 1.13 on epoch=234
05/30/2022 03:00:18 - INFO - __main__ - Step 950 Global step 950 Train loss 1.12 on epoch=237
05/30/2022 03:00:19 - INFO - __main__ - Global step 950 Train loss 1.17 Classification-F1 0.1 on epoch=237
05/30/2022 03:00:20 - INFO - __main__ - Step 960 Global step 960 Train loss 1.27 on epoch=239
05/30/2022 03:00:21 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=242
05/30/2022 03:00:23 - INFO - __main__ - Step 980 Global step 980 Train loss 1.14 on epoch=244
05/30/2022 03:00:24 - INFO - __main__ - Step 990 Global step 990 Train loss 1.21 on epoch=247
05/30/2022 03:00:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.22 on epoch=249
05/30/2022 03:00:26 - INFO - __main__ - Global step 1000 Train loss 1.20 Classification-F1 0.1 on epoch=249
05/30/2022 03:00:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.10 on epoch=252
05/30/2022 03:00:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.98 on epoch=254
05/30/2022 03:00:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.29 on epoch=257
05/30/2022 03:00:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.19 on epoch=259
05/30/2022 03:00:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.20 on epoch=262
05/30/2022 03:00:33 - INFO - __main__ - Global step 1050 Train loss 1.15 Classification-F1 0.09493670886075949 on epoch=262
05/30/2022 03:00:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.09 on epoch=264
05/30/2022 03:00:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.00 on epoch=267
05/30/2022 03:00:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.06 on epoch=269
05/30/2022 03:00:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.22 on epoch=272
05/30/2022 03:00:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.98 on epoch=274
05/30/2022 03:00:39 - INFO - __main__ - Global step 1100 Train loss 1.07 Classification-F1 0.1 on epoch=274
05/30/2022 03:00:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.04 on epoch=277
05/30/2022 03:00:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.08 on epoch=279
05/30/2022 03:00:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.04 on epoch=282
05/30/2022 03:00:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.08 on epoch=284
05/30/2022 03:00:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.02 on epoch=287
05/30/2022 03:00:46 - INFO - __main__ - Global step 1150 Train loss 1.05 Classification-F1 0.1 on epoch=287
05/30/2022 03:00:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.07 on epoch=289
05/30/2022 03:00:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.14 on epoch=292
05/30/2022 03:00:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.10 on epoch=294
05/30/2022 03:00:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.07 on epoch=297
05/30/2022 03:00:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.07 on epoch=299
05/30/2022 03:00:53 - INFO - __main__ - Global step 1200 Train loss 1.09 Classification-F1 0.1 on epoch=299
05/30/2022 03:00:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.15 on epoch=302
05/30/2022 03:00:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.91 on epoch=304
05/30/2022 03:00:57 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.10 on epoch=307
05/30/2022 03:00:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=309
05/30/2022 03:00:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=312
05/30/2022 03:01:00 - INFO - __main__ - Global step 1250 Train loss 1.09 Classification-F1 0.1 on epoch=312
05/30/2022 03:01:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=314
05/30/2022 03:01:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.07 on epoch=317
05/30/2022 03:01:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.01 on epoch=319
05/30/2022 03:01:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.94 on epoch=322
05/30/2022 03:01:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.99 on epoch=324
05/30/2022 03:01:06 - INFO - __main__ - Global step 1300 Train loss 1.01 Classification-F1 0.10126582278481013 on epoch=324
05/30/2022 03:01:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.12 on epoch=327
05/30/2022 03:01:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.96 on epoch=329
05/30/2022 03:01:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.05 on epoch=332
05/30/2022 03:01:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.02 on epoch=334
05/30/2022 03:01:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.11 on epoch=337
05/30/2022 03:01:13 - INFO - __main__ - Global step 1350 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=337
05/30/2022 03:01:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.06 on epoch=339
05/30/2022 03:01:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.09 on epoch=342
05/30/2022 03:01:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.99 on epoch=344
05/30/2022 03:01:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.12 on epoch=347
05/30/2022 03:01:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
05/30/2022 03:01:20 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.15441176470588236 on epoch=349
05/30/2022 03:01:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.03 on epoch=352
05/30/2022 03:01:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.01 on epoch=354
05/30/2022 03:01:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.99 on epoch=357
05/30/2022 03:01:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.93 on epoch=359
05/30/2022 03:01:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.02 on epoch=362
05/30/2022 03:01:27 - INFO - __main__ - Global step 1450 Train loss 1.00 Classification-F1 0.1 on epoch=362
05/30/2022 03:01:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.05 on epoch=364
05/30/2022 03:01:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.99 on epoch=367
05/30/2022 03:01:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.11 on epoch=369
05/30/2022 03:01:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.04 on epoch=372
05/30/2022 03:01:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.04 on epoch=374
05/30/2022 03:01:34 - INFO - __main__ - Global step 1500 Train loss 1.05 Classification-F1 0.10126582278481013 on epoch=374
05/30/2022 03:01:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.00 on epoch=377
05/30/2022 03:01:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.01 on epoch=379
05/30/2022 03:01:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.91 on epoch=382
05/30/2022 03:01:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.07 on epoch=384
05/30/2022 03:01:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.95 on epoch=387
05/30/2022 03:01:41 - INFO - __main__ - Global step 1550 Train loss 0.99 Classification-F1 0.1 on epoch=387
05/30/2022 03:01:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.03 on epoch=389
05/30/2022 03:01:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.00 on epoch=392
05/30/2022 03:01:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.97 on epoch=394
05/30/2022 03:01:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.04 on epoch=397
05/30/2022 03:01:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=399
05/30/2022 03:01:47 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.1302118933697881 on epoch=399
05/30/2022 03:01:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.01 on epoch=402
05/30/2022 03:01:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.09 on epoch=404
05/30/2022 03:01:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.04 on epoch=407
05/30/2022 03:01:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.99 on epoch=409
05/30/2022 03:01:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.09 on epoch=412
05/30/2022 03:01:54 - INFO - __main__ - Global step 1650 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=412
05/30/2022 03:01:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.08 on epoch=414
05/30/2022 03:01:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.04 on epoch=417
05/30/2022 03:01:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.05 on epoch=419
05/30/2022 03:01:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.03 on epoch=422
05/30/2022 03:02:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=424
05/30/2022 03:02:01 - INFO - __main__ - Global step 1700 Train loss 1.05 Classification-F1 0.2120826259196378 on epoch=424
05/30/2022 03:02:01 - INFO - __main__ - Saving model with best Classification-F1: 0.1778115501519757 -> 0.2120826259196378 on epoch=424, global_step=1700
05/30/2022 03:02:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.96 on epoch=427
05/30/2022 03:02:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.01 on epoch=429
05/30/2022 03:02:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.90 on epoch=432
05/30/2022 03:02:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.05 on epoch=434
05/30/2022 03:02:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.91 on epoch=437
05/30/2022 03:02:08 - INFO - __main__ - Global step 1750 Train loss 0.97 Classification-F1 0.1850282485875706 on epoch=437
05/30/2022 03:02:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=439
05/30/2022 03:02:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.98 on epoch=442
05/30/2022 03:02:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.01 on epoch=444
05/30/2022 03:02:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.99 on epoch=447
05/30/2022 03:02:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.01 on epoch=449
05/30/2022 03:02:15 - INFO - __main__ - Global step 1800 Train loss 0.98 Classification-F1 0.13904109589041097 on epoch=449
05/30/2022 03:02:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=452
05/30/2022 03:02:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.98 on epoch=454
05/30/2022 03:02:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.99 on epoch=457
05/30/2022 03:02:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.98 on epoch=459
05/30/2022 03:02:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=462
05/30/2022 03:02:21 - INFO - __main__ - Global step 1850 Train loss 1.00 Classification-F1 0.10869565217391305 on epoch=462
05/30/2022 03:02:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.06 on epoch=464
05/30/2022 03:02:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.02 on epoch=467
05/30/2022 03:02:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.02 on epoch=469
05/30/2022 03:02:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.10 on epoch=472
05/30/2022 03:02:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.98 on epoch=474
05/30/2022 03:02:28 - INFO - __main__ - Global step 1900 Train loss 1.03 Classification-F1 0.09493670886075949 on epoch=474
05/30/2022 03:02:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.96 on epoch=477
05/30/2022 03:02:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.98 on epoch=479
05/30/2022 03:02:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.00 on epoch=482
05/30/2022 03:02:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.93 on epoch=484
05/30/2022 03:02:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.92 on epoch=487
05/30/2022 03:02:35 - INFO - __main__ - Global step 1950 Train loss 0.96 Classification-F1 0.09090909090909091 on epoch=487
05/30/2022 03:02:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.83 on epoch=489
05/30/2022 03:02:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.01 on epoch=492
05/30/2022 03:02:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.98 on epoch=494
05/30/2022 03:02:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.98 on epoch=497
05/30/2022 03:02:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.93 on epoch=499
05/30/2022 03:02:42 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.0945945945945946 on epoch=499
05/30/2022 03:02:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.93 on epoch=502
05/30/2022 03:02:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.95 on epoch=504
05/30/2022 03:02:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.95 on epoch=507
05/30/2022 03:02:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.04 on epoch=509
05/30/2022 03:02:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.87 on epoch=512
05/30/2022 03:02:49 - INFO - __main__ - Global step 2050 Train loss 0.95 Classification-F1 0.15555555555555556 on epoch=512
05/30/2022 03:02:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=514
05/30/2022 03:02:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.90 on epoch=517
05/30/2022 03:02:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.97 on epoch=519
05/30/2022 03:02:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.09 on epoch=522
05/30/2022 03:02:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.91 on epoch=524
05/30/2022 03:02:55 - INFO - __main__ - Global step 2100 Train loss 0.97 Classification-F1 0.10380835380835382 on epoch=524
05/30/2022 03:02:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.00 on epoch=527
05/30/2022 03:02:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.03 on epoch=529
05/30/2022 03:02:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.99 on epoch=532
05/30/2022 03:03:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.87 on epoch=534
05/30/2022 03:03:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.86 on epoch=537
05/30/2022 03:03:02 - INFO - __main__ - Global step 2150 Train loss 0.95 Classification-F1 0.1 on epoch=537
05/30/2022 03:03:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.79 on epoch=539
05/30/2022 03:03:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.96 on epoch=542
05/30/2022 03:03:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.95 on epoch=544
05/30/2022 03:03:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.95 on epoch=547
05/30/2022 03:03:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=549
05/30/2022 03:03:09 - INFO - __main__ - Global step 2200 Train loss 0.91 Classification-F1 0.1388888888888889 on epoch=549
05/30/2022 03:03:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.97 on epoch=552
05/30/2022 03:03:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.87 on epoch=554
05/30/2022 03:03:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.94 on epoch=557
05/30/2022 03:03:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.94 on epoch=559
05/30/2022 03:03:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.97 on epoch=562
05/30/2022 03:03:16 - INFO - __main__ - Global step 2250 Train loss 0.94 Classification-F1 0.09615384615384615 on epoch=562
05/30/2022 03:03:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.88 on epoch=564
05/30/2022 03:03:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.95 on epoch=567
05/30/2022 03:03:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.96 on epoch=569
05/30/2022 03:03:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.96 on epoch=572
05/30/2022 03:03:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.93 on epoch=574
05/30/2022 03:03:23 - INFO - __main__ - Global step 2300 Train loss 0.94 Classification-F1 0.1503587736464449 on epoch=574
05/30/2022 03:03:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.94 on epoch=577
05/30/2022 03:03:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.94 on epoch=579
05/30/2022 03:03:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.94 on epoch=582
05/30/2022 03:03:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.89 on epoch=584
05/30/2022 03:03:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.90 on epoch=587
05/30/2022 03:03:30 - INFO - __main__ - Global step 2350 Train loss 0.93 Classification-F1 0.09493670886075949 on epoch=587
05/30/2022 03:03:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.03 on epoch=589
05/30/2022 03:03:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.91 on epoch=592
05/30/2022 03:03:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.89 on epoch=594
05/30/2022 03:03:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.94 on epoch=597
05/30/2022 03:03:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.81 on epoch=599
05/30/2022 03:03:36 - INFO - __main__ - Global step 2400 Train loss 0.92 Classification-F1 0.1 on epoch=599
05/30/2022 03:03:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.99 on epoch=602
05/30/2022 03:03:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.94 on epoch=604
05/30/2022 03:03:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.92 on epoch=607
05/30/2022 03:03:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.93 on epoch=609
05/30/2022 03:03:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.01 on epoch=612
05/30/2022 03:03:43 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.1 on epoch=612
05/30/2022 03:03:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.86 on epoch=614
05/30/2022 03:03:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.91 on epoch=617
05/30/2022 03:03:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.97 on epoch=619
05/30/2022 03:03:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.10 on epoch=622
05/30/2022 03:03:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.91 on epoch=624
05/30/2022 03:03:50 - INFO - __main__ - Global step 2500 Train loss 0.95 Classification-F1 0.14095238095238094 on epoch=624
05/30/2022 03:03:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.94 on epoch=627
05/30/2022 03:03:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.95 on epoch=629
05/30/2022 03:03:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=632
05/30/2022 03:03:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.92 on epoch=634
05/30/2022 03:03:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.93 on epoch=637
05/30/2022 03:03:57 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.0974025974025974 on epoch=637
05/30/2022 03:03:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=639
05/30/2022 03:03:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.88 on epoch=642
05/30/2022 03:04:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.96 on epoch=644
05/30/2022 03:04:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.90 on epoch=647
05/30/2022 03:04:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.01 on epoch=649
05/30/2022 03:04:04 - INFO - __main__ - Global step 2600 Train loss 0.94 Classification-F1 0.10126582278481013 on epoch=649
05/30/2022 03:04:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.98 on epoch=652
05/30/2022 03:04:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/30/2022 03:04:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.99 on epoch=657
05/30/2022 03:04:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.96 on epoch=659
05/30/2022 03:04:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.98 on epoch=662
05/30/2022 03:04:11 - INFO - __main__ - Global step 2650 Train loss 0.96 Classification-F1 0.11710526315789474 on epoch=662
05/30/2022 03:04:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.91 on epoch=664
05/30/2022 03:04:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.94 on epoch=667
05/30/2022 03:04:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=669
05/30/2022 03:04:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=672
05/30/2022 03:04:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.89 on epoch=674
05/30/2022 03:04:17 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.14095238095238094 on epoch=674
05/30/2022 03:04:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.94 on epoch=677
05/30/2022 03:04:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.85 on epoch=679
05/30/2022 03:04:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.91 on epoch=682
05/30/2022 03:04:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.88 on epoch=684
05/30/2022 03:04:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.87 on epoch=687
05/30/2022 03:04:24 - INFO - __main__ - Global step 2750 Train loss 0.89 Classification-F1 0.1 on epoch=687
05/30/2022 03:04:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.88 on epoch=689
05/30/2022 03:04:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.93 on epoch=692
05/30/2022 03:04:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=694
05/30/2022 03:04:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.95 on epoch=697
05/30/2022 03:04:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.87 on epoch=699
05/30/2022 03:04:31 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.10256410256410256 on epoch=699
05/30/2022 03:04:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.85 on epoch=702
05/30/2022 03:04:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.95 on epoch=704
05/30/2022 03:04:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.87 on epoch=707
05/30/2022 03:04:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.94 on epoch=709
05/30/2022 03:04:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.91 on epoch=712
05/30/2022 03:04:38 - INFO - __main__ - Global step 2850 Train loss 0.90 Classification-F1 0.1 on epoch=712
05/30/2022 03:04:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.94 on epoch=714
05/30/2022 03:04:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.03 on epoch=717
05/30/2022 03:04:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.88 on epoch=719
05/30/2022 03:04:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.95 on epoch=722
05/30/2022 03:04:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.93 on epoch=724
05/30/2022 03:04:45 - INFO - __main__ - Global step 2900 Train loss 0.95 Classification-F1 0.11722488038277512 on epoch=724
05/30/2022 03:04:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.88 on epoch=727
05/30/2022 03:04:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/30/2022 03:04:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.87 on epoch=732
05/30/2022 03:04:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.89 on epoch=734
05/30/2022 03:04:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.82 on epoch=737
05/30/2022 03:04:51 - INFO - __main__ - Global step 2950 Train loss 0.88 Classification-F1 0.1565276828434723 on epoch=737
05/30/2022 03:04:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.88 on epoch=739
05/30/2022 03:04:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.88 on epoch=742
05/30/2022 03:04:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.93 on epoch=744
05/30/2022 03:04:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.88 on epoch=747
05/30/2022 03:04:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=749
05/30/2022 03:04:58 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.1 on epoch=749
05/30/2022 03:04:58 - INFO - __main__ - save last model!
05/30/2022 03:04:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 03:04:58 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 03:04:58 - INFO - __main__ - Printing 3 examples
05/30/2022 03:04:58 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 03:04:58 - INFO - __main__ - ['others']
05/30/2022 03:04:58 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 03:04:58 - INFO - __main__ - ['others']
05/30/2022 03:04:58 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 03:04:58 - INFO - __main__ - ['others']
05/30/2022 03:04:58 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:04:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:04:59 - INFO - __main__ - Printing 3 examples
05/30/2022 03:04:59 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 03:04:59 - INFO - __main__ - ['others']
05/30/2022 03:04:59 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 03:04:59 - INFO - __main__ - ['others']
05/30/2022 03:04:59 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 03:04:59 - INFO - __main__ - ['others']
05/30/2022 03:04:59 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:04:59 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:04:59 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 03:04:59 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:04:59 - INFO - __main__ - Printing 3 examples
05/30/2022 03:04:59 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 03:04:59 - INFO - __main__ - ['others']
05/30/2022 03:04:59 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 03:04:59 - INFO - __main__ - ['others']
05/30/2022 03:04:59 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 03:04:59 - INFO - __main__ - ['others']
05/30/2022 03:04:59 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:04:59 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:04:59 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 03:05:00 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:05:04 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 03:05:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 03:05:05 - INFO - __main__ - Starting training!
05/30/2022 03:05:06 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 03:05:49 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.4_8_predictions.txt
05/30/2022 03:05:49 - INFO - __main__ - Classification-F1 on test data: 0.0276
05/30/2022 03:05:49 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.2120826259196378, test_performance=0.027648234964029166
05/30/2022 03:05:49 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
05/30/2022 03:05:50 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:05:50 - INFO - __main__ - Printing 3 examples
05/30/2022 03:05:50 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 03:05:50 - INFO - __main__ - ['others']
05/30/2022 03:05:50 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 03:05:50 - INFO - __main__ - ['others']
05/30/2022 03:05:50 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 03:05:50 - INFO - __main__ - ['others']
05/30/2022 03:05:50 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:05:50 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:05:50 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 03:05:50 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:05:50 - INFO - __main__ - Printing 3 examples
05/30/2022 03:05:50 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 03:05:50 - INFO - __main__ - ['others']
05/30/2022 03:05:50 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 03:05:50 - INFO - __main__ - ['others']
05/30/2022 03:05:50 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 03:05:50 - INFO - __main__ - ['others']
05/30/2022 03:05:50 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:05:50 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:05:51 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 03:05:56 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 03:05:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 03:05:56 - INFO - __main__ - Starting training!
05/30/2022 03:05:58 - INFO - __main__ - Step 10 Global step 10 Train loss 6.65 on epoch=2
05/30/2022 03:05:59 - INFO - __main__ - Step 20 Global step 20 Train loss 6.64 on epoch=4
05/30/2022 03:06:00 - INFO - __main__ - Step 30 Global step 30 Train loss 6.49 on epoch=7
05/30/2022 03:06:01 - INFO - __main__ - Step 40 Global step 40 Train loss 6.36 on epoch=9
05/30/2022 03:06:03 - INFO - __main__ - Step 50 Global step 50 Train loss 6.12 on epoch=12
05/30/2022 03:06:06 - INFO - __main__ - Global step 50 Train loss 6.45 Classification-F1 0.0 on epoch=12
05/30/2022 03:06:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 03:06:07 - INFO - __main__ - Step 60 Global step 60 Train loss 6.00 on epoch=14
05/30/2022 03:06:08 - INFO - __main__ - Step 70 Global step 70 Train loss 5.87 on epoch=17
05/30/2022 03:06:10 - INFO - __main__ - Step 80 Global step 80 Train loss 5.81 on epoch=19
05/30/2022 03:06:11 - INFO - __main__ - Step 90 Global step 90 Train loss 5.79 on epoch=22
05/30/2022 03:06:12 - INFO - __main__ - Step 100 Global step 100 Train loss 5.52 on epoch=24
05/30/2022 03:06:14 - INFO - __main__ - Global step 100 Train loss 5.79 Classification-F1 0.0 on epoch=24
05/30/2022 03:06:15 - INFO - __main__ - Step 110 Global step 110 Train loss 5.57 on epoch=27
05/30/2022 03:06:17 - INFO - __main__ - Step 120 Global step 120 Train loss 5.34 on epoch=29
05/30/2022 03:06:18 - INFO - __main__ - Step 130 Global step 130 Train loss 5.23 on epoch=32
05/30/2022 03:06:19 - INFO - __main__ - Step 140 Global step 140 Train loss 5.11 on epoch=34
05/30/2022 03:06:20 - INFO - __main__ - Step 150 Global step 150 Train loss 4.98 on epoch=37
05/30/2022 03:06:22 - INFO - __main__ - Global step 150 Train loss 5.25 Classification-F1 0.0 on epoch=37
05/30/2022 03:06:23 - INFO - __main__ - Step 160 Global step 160 Train loss 4.78 on epoch=39
05/30/2022 03:06:25 - INFO - __main__ - Step 170 Global step 170 Train loss 4.76 on epoch=42
05/30/2022 03:06:26 - INFO - __main__ - Step 180 Global step 180 Train loss 4.63 on epoch=44
05/30/2022 03:06:27 - INFO - __main__ - Step 190 Global step 190 Train loss 4.63 on epoch=47
05/30/2022 03:06:28 - INFO - __main__ - Step 200 Global step 200 Train loss 4.50 on epoch=49
05/30/2022 03:06:29 - INFO - __main__ - Global step 200 Train loss 4.66 Classification-F1 0.1 on epoch=49
05/30/2022 03:06:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.1 on epoch=49, global_step=200
05/30/2022 03:06:30 - INFO - __main__ - Step 210 Global step 210 Train loss 4.33 on epoch=52
05/30/2022 03:06:32 - INFO - __main__ - Step 220 Global step 220 Train loss 4.18 on epoch=54
05/30/2022 03:06:33 - INFO - __main__ - Step 230 Global step 230 Train loss 4.09 on epoch=57
05/30/2022 03:06:34 - INFO - __main__ - Step 240 Global step 240 Train loss 4.11 on epoch=59
05/30/2022 03:06:35 - INFO - __main__ - Step 250 Global step 250 Train loss 3.99 on epoch=62
05/30/2022 03:06:36 - INFO - __main__ - Global step 250 Train loss 4.14 Classification-F1 0.19865392965696915 on epoch=62
05/30/2022 03:06:36 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.19865392965696915 on epoch=62, global_step=250
05/30/2022 03:06:37 - INFO - __main__ - Step 260 Global step 260 Train loss 3.74 on epoch=64
05/30/2022 03:06:38 - INFO - __main__ - Step 270 Global step 270 Train loss 3.61 on epoch=67
05/30/2022 03:06:40 - INFO - __main__ - Step 280 Global step 280 Train loss 3.54 on epoch=69
05/30/2022 03:06:41 - INFO - __main__ - Step 290 Global step 290 Train loss 3.41 on epoch=72
05/30/2022 03:06:42 - INFO - __main__ - Step 300 Global step 300 Train loss 3.35 on epoch=74
05/30/2022 03:06:43 - INFO - __main__ - Global step 300 Train loss 3.53 Classification-F1 0.09126984126984126 on epoch=74
05/30/2022 03:06:44 - INFO - __main__ - Step 310 Global step 310 Train loss 3.38 on epoch=77
05/30/2022 03:06:45 - INFO - __main__ - Step 320 Global step 320 Train loss 3.20 on epoch=79
05/30/2022 03:06:47 - INFO - __main__ - Step 330 Global step 330 Train loss 3.11 on epoch=82
05/30/2022 03:06:48 - INFO - __main__ - Step 340 Global step 340 Train loss 2.97 on epoch=84
05/30/2022 03:06:49 - INFO - __main__ - Step 350 Global step 350 Train loss 3.16 on epoch=87
05/30/2022 03:06:50 - INFO - __main__ - Global step 350 Train loss 3.16 Classification-F1 0.12368421052631579 on epoch=87
05/30/2022 03:06:51 - INFO - __main__ - Step 360 Global step 360 Train loss 2.98 on epoch=89
05/30/2022 03:06:52 - INFO - __main__ - Step 370 Global step 370 Train loss 3.17 on epoch=92
05/30/2022 03:06:53 - INFO - __main__ - Step 380 Global step 380 Train loss 2.83 on epoch=94
05/30/2022 03:06:55 - INFO - __main__ - Step 390 Global step 390 Train loss 2.92 on epoch=97
05/30/2022 03:06:56 - INFO - __main__ - Step 400 Global step 400 Train loss 2.84 on epoch=99
05/30/2022 03:06:56 - INFO - __main__ - Global step 400 Train loss 2.95 Classification-F1 0.1238095238095238 on epoch=99
05/30/2022 03:06:58 - INFO - __main__ - Step 410 Global step 410 Train loss 2.79 on epoch=102
05/30/2022 03:06:59 - INFO - __main__ - Step 420 Global step 420 Train loss 2.67 on epoch=104
05/30/2022 03:07:00 - INFO - __main__ - Step 430 Global step 430 Train loss 2.74 on epoch=107
05/30/2022 03:07:02 - INFO - __main__ - Step 440 Global step 440 Train loss 2.57 on epoch=109
05/30/2022 03:07:03 - INFO - __main__ - Step 450 Global step 450 Train loss 2.61 on epoch=112
05/30/2022 03:07:03 - INFO - __main__ - Global step 450 Train loss 2.68 Classification-F1 0.1 on epoch=112
05/30/2022 03:07:05 - INFO - __main__ - Step 460 Global step 460 Train loss 2.50 on epoch=114
05/30/2022 03:07:06 - INFO - __main__ - Step 470 Global step 470 Train loss 2.54 on epoch=117
05/30/2022 03:07:07 - INFO - __main__ - Step 480 Global step 480 Train loss 2.53 on epoch=119
05/30/2022 03:07:08 - INFO - __main__ - Step 490 Global step 490 Train loss 2.69 on epoch=122
05/30/2022 03:07:10 - INFO - __main__ - Step 500 Global step 500 Train loss 2.50 on epoch=124
05/30/2022 03:07:10 - INFO - __main__ - Global step 500 Train loss 2.55 Classification-F1 0.1 on epoch=124
05/30/2022 03:07:11 - INFO - __main__ - Step 510 Global step 510 Train loss 2.38 on epoch=127
05/30/2022 03:07:13 - INFO - __main__ - Step 520 Global step 520 Train loss 2.27 on epoch=129
05/30/2022 03:07:14 - INFO - __main__ - Step 530 Global step 530 Train loss 2.30 on epoch=132
05/30/2022 03:07:15 - INFO - __main__ - Step 540 Global step 540 Train loss 2.09 on epoch=134
05/30/2022 03:07:17 - INFO - __main__ - Step 550 Global step 550 Train loss 2.21 on epoch=137
05/30/2022 03:07:17 - INFO - __main__ - Global step 550 Train loss 2.25 Classification-F1 0.18284347231715653 on epoch=137
05/30/2022 03:07:18 - INFO - __main__ - Step 560 Global step 560 Train loss 2.14 on epoch=139
05/30/2022 03:07:20 - INFO - __main__ - Step 570 Global step 570 Train loss 2.19 on epoch=142
05/30/2022 03:07:21 - INFO - __main__ - Step 580 Global step 580 Train loss 2.10 on epoch=144
05/30/2022 03:07:22 - INFO - __main__ - Step 590 Global step 590 Train loss 2.08 on epoch=147
05/30/2022 03:07:24 - INFO - __main__ - Step 600 Global step 600 Train loss 1.99 on epoch=149
05/30/2022 03:07:24 - INFO - __main__ - Global step 600 Train loss 2.10 Classification-F1 0.1715492957746479 on epoch=149
05/30/2022 03:07:25 - INFO - __main__ - Step 610 Global step 610 Train loss 2.11 on epoch=152
05/30/2022 03:07:27 - INFO - __main__ - Step 620 Global step 620 Train loss 2.06 on epoch=154
05/30/2022 03:07:28 - INFO - __main__ - Step 630 Global step 630 Train loss 2.03 on epoch=157
05/30/2022 03:07:29 - INFO - __main__ - Step 640 Global step 640 Train loss 1.95 on epoch=159
05/30/2022 03:07:30 - INFO - __main__ - Step 650 Global step 650 Train loss 2.04 on epoch=162
05/30/2022 03:07:31 - INFO - __main__ - Global step 650 Train loss 2.04 Classification-F1 0.11439888164026094 on epoch=162
05/30/2022 03:07:32 - INFO - __main__ - Step 660 Global step 660 Train loss 2.00 on epoch=164
05/30/2022 03:07:34 - INFO - __main__ - Step 670 Global step 670 Train loss 2.06 on epoch=167
05/30/2022 03:07:35 - INFO - __main__ - Step 680 Global step 680 Train loss 1.92 on epoch=169
05/30/2022 03:07:36 - INFO - __main__ - Step 690 Global step 690 Train loss 1.95 on epoch=172
05/30/2022 03:07:37 - INFO - __main__ - Step 700 Global step 700 Train loss 2.01 on epoch=174
05/30/2022 03:07:38 - INFO - __main__ - Global step 700 Train loss 1.99 Classification-F1 0.08658008658008658 on epoch=174
05/30/2022 03:07:39 - INFO - __main__ - Step 710 Global step 710 Train loss 2.13 on epoch=177
05/30/2022 03:07:40 - INFO - __main__ - Step 720 Global step 720 Train loss 1.90 on epoch=179
05/30/2022 03:07:42 - INFO - __main__ - Step 730 Global step 730 Train loss 1.87 on epoch=182
05/30/2022 03:07:43 - INFO - __main__ - Step 740 Global step 740 Train loss 1.89 on epoch=184
05/30/2022 03:07:44 - INFO - __main__ - Step 750 Global step 750 Train loss 1.86 on epoch=187
05/30/2022 03:07:45 - INFO - __main__ - Global step 750 Train loss 1.93 Classification-F1 0.15339578454332553 on epoch=187
05/30/2022 03:07:46 - INFO - __main__ - Step 760 Global step 760 Train loss 1.88 on epoch=189
05/30/2022 03:07:47 - INFO - __main__ - Step 770 Global step 770 Train loss 1.76 on epoch=192
05/30/2022 03:07:49 - INFO - __main__ - Step 780 Global step 780 Train loss 1.60 on epoch=194
05/30/2022 03:07:50 - INFO - __main__ - Step 790 Global step 790 Train loss 1.70 on epoch=197
05/30/2022 03:07:51 - INFO - __main__ - Step 800 Global step 800 Train loss 1.73 on epoch=199
05/30/2022 03:07:52 - INFO - __main__ - Global step 800 Train loss 1.74 Classification-F1 0.17368421052631577 on epoch=199
05/30/2022 03:07:53 - INFO - __main__ - Step 810 Global step 810 Train loss 1.79 on epoch=202
05/30/2022 03:07:54 - INFO - __main__ - Step 820 Global step 820 Train loss 1.68 on epoch=204
05/30/2022 03:07:55 - INFO - __main__ - Step 830 Global step 830 Train loss 1.66 on epoch=207
05/30/2022 03:07:57 - INFO - __main__ - Step 840 Global step 840 Train loss 1.62 on epoch=209
05/30/2022 03:07:58 - INFO - __main__ - Step 850 Global step 850 Train loss 1.69 on epoch=212
05/30/2022 03:07:59 - INFO - __main__ - Global step 850 Train loss 1.69 Classification-F1 0.14621798689696247 on epoch=212
05/30/2022 03:08:00 - INFO - __main__ - Step 860 Global step 860 Train loss 1.69 on epoch=214
05/30/2022 03:08:01 - INFO - __main__ - Step 870 Global step 870 Train loss 1.85 on epoch=217
05/30/2022 03:08:02 - INFO - __main__ - Step 880 Global step 880 Train loss 1.42 on epoch=219
05/30/2022 03:08:04 - INFO - __main__ - Step 890 Global step 890 Train loss 1.81 on epoch=222
05/30/2022 03:08:05 - INFO - __main__ - Step 900 Global step 900 Train loss 1.64 on epoch=224
05/30/2022 03:08:05 - INFO - __main__ - Global step 900 Train loss 1.68 Classification-F1 0.13067758749069247 on epoch=224
05/30/2022 03:08:07 - INFO - __main__ - Step 910 Global step 910 Train loss 1.66 on epoch=227
05/30/2022 03:08:08 - INFO - __main__ - Step 920 Global step 920 Train loss 1.57 on epoch=229
05/30/2022 03:08:09 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=232
05/30/2022 03:08:11 - INFO - __main__ - Step 940 Global step 940 Train loss 1.48 on epoch=234
05/30/2022 03:08:12 - INFO - __main__ - Step 950 Global step 950 Train loss 1.48 on epoch=237
05/30/2022 03:08:12 - INFO - __main__ - Global step 950 Train loss 1.54 Classification-F1 0.1458980044345898 on epoch=237
05/30/2022 03:08:14 - INFO - __main__ - Step 960 Global step 960 Train loss 1.45 on epoch=239
05/30/2022 03:08:15 - INFO - __main__ - Step 970 Global step 970 Train loss 1.52 on epoch=242
05/30/2022 03:08:16 - INFO - __main__ - Step 980 Global step 980 Train loss 1.31 on epoch=244
05/30/2022 03:08:17 - INFO - __main__ - Step 990 Global step 990 Train loss 1.48 on epoch=247
05/30/2022 03:08:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.39 on epoch=249
05/30/2022 03:08:19 - INFO - __main__ - Global step 1000 Train loss 1.43 Classification-F1 0.1115492957746479 on epoch=249
05/30/2022 03:08:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.54 on epoch=252
05/30/2022 03:08:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.50 on epoch=254
05/30/2022 03:08:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.42 on epoch=257
05/30/2022 03:08:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.58 on epoch=259
05/30/2022 03:08:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.40 on epoch=262
05/30/2022 03:08:26 - INFO - __main__ - Global step 1050 Train loss 1.49 Classification-F1 0.16059379217273953 on epoch=262
05/30/2022 03:08:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.37 on epoch=264
05/30/2022 03:08:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.40 on epoch=267
05/30/2022 03:08:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.31 on epoch=269
05/30/2022 03:08:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.38 on epoch=272
05/30/2022 03:08:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.36 on epoch=274
05/30/2022 03:08:33 - INFO - __main__ - Global step 1100 Train loss 1.36 Classification-F1 0.1 on epoch=274
05/30/2022 03:08:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.29 on epoch=277
05/30/2022 03:08:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.36 on epoch=279
05/30/2022 03:08:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.25 on epoch=282
05/30/2022 03:08:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.42 on epoch=284
05/30/2022 03:08:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.28 on epoch=287
05/30/2022 03:08:40 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.10389610389610389 on epoch=287
05/30/2022 03:08:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.19 on epoch=289
05/30/2022 03:08:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.39 on epoch=292
05/30/2022 03:08:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.36 on epoch=294
05/30/2022 03:08:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.35 on epoch=297
05/30/2022 03:08:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.30 on epoch=299
05/30/2022 03:08:47 - INFO - __main__ - Global step 1200 Train loss 1.32 Classification-F1 0.1360774818401937 on epoch=299
05/30/2022 03:08:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.38 on epoch=302
05/30/2022 03:08:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.32 on epoch=304
05/30/2022 03:08:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.34 on epoch=307
05/30/2022 03:08:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.28 on epoch=309
05/30/2022 03:08:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.35 on epoch=312
05/30/2022 03:08:54 - INFO - __main__ - Global step 1250 Train loss 1.33 Classification-F1 0.13514173998044965 on epoch=312
05/30/2022 03:08:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.15 on epoch=314
05/30/2022 03:08:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.25 on epoch=317
05/30/2022 03:08:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.36 on epoch=319
05/30/2022 03:08:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.25 on epoch=322
05/30/2022 03:09:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.25 on epoch=324
05/30/2022 03:09:01 - INFO - __main__ - Global step 1300 Train loss 1.25 Classification-F1 0.1 on epoch=324
05/30/2022 03:09:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.28 on epoch=327
05/30/2022 03:09:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.15 on epoch=329
05/30/2022 03:09:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=332
05/30/2022 03:09:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.24 on epoch=334
05/30/2022 03:09:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.22 on epoch=337
05/30/2022 03:09:07 - INFO - __main__ - Global step 1350 Train loss 1.22 Classification-F1 0.10126582278481013 on epoch=337
05/30/2022 03:09:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.34 on epoch=339
05/30/2022 03:09:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.35 on epoch=342
05/30/2022 03:09:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.18 on epoch=344
05/30/2022 03:09:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.29 on epoch=347
05/30/2022 03:09:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.09 on epoch=349
05/30/2022 03:09:14 - INFO - __main__ - Global step 1400 Train loss 1.25 Classification-F1 0.14004914004914004 on epoch=349
05/30/2022 03:09:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.33 on epoch=352
05/30/2022 03:09:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.08 on epoch=354
05/30/2022 03:09:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.26 on epoch=357
05/30/2022 03:09:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.29 on epoch=359
05/30/2022 03:09:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.28 on epoch=362
05/30/2022 03:09:21 - INFO - __main__ - Global step 1450 Train loss 1.25 Classification-F1 0.12393162393162392 on epoch=362
05/30/2022 03:09:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.16 on epoch=364
05/30/2022 03:09:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.29 on epoch=367
05/30/2022 03:09:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.30 on epoch=369
05/30/2022 03:09:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.24 on epoch=372
05/30/2022 03:09:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.26 on epoch=374
05/30/2022 03:09:28 - INFO - __main__ - Global step 1500 Train loss 1.25 Classification-F1 0.09868421052631579 on epoch=374
05/30/2022 03:09:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.05 on epoch=377
05/30/2022 03:09:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.39 on epoch=379
05/30/2022 03:09:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.11 on epoch=382
05/30/2022 03:09:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.12 on epoch=384
05/30/2022 03:09:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.19 on epoch=387
05/30/2022 03:09:35 - INFO - __main__ - Global step 1550 Train loss 1.17 Classification-F1 0.14248366013071895 on epoch=387
05/30/2022 03:09:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.16 on epoch=389
05/30/2022 03:09:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.18 on epoch=392
05/30/2022 03:09:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.16 on epoch=394
05/30/2022 03:09:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.09 on epoch=397
05/30/2022 03:09:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.07 on epoch=399
05/30/2022 03:09:42 - INFO - __main__ - Global step 1600 Train loss 1.13 Classification-F1 0.11657231085949563 on epoch=399
05/30/2022 03:09:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.03 on epoch=402
05/30/2022 03:09:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.17 on epoch=404
05/30/2022 03:09:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.16 on epoch=407
05/30/2022 03:09:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=409
05/30/2022 03:09:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.08 on epoch=412
05/30/2022 03:09:49 - INFO - __main__ - Global step 1650 Train loss 1.09 Classification-F1 0.09708159618820728 on epoch=412
05/30/2022 03:09:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.20 on epoch=414
05/30/2022 03:09:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.12 on epoch=417
05/30/2022 03:09:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=419
05/30/2022 03:09:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.06 on epoch=422
05/30/2022 03:09:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.01 on epoch=424
05/30/2022 03:09:55 - INFO - __main__ - Global step 1700 Train loss 1.10 Classification-F1 0.0880952380952381 on epoch=424
05/30/2022 03:09:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.12 on epoch=427
05/30/2022 03:09:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.04 on epoch=429
05/30/2022 03:09:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.01 on epoch=432
05/30/2022 03:10:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=434
05/30/2022 03:10:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.07 on epoch=437
05/30/2022 03:10:02 - INFO - __main__ - Global step 1750 Train loss 1.08 Classification-F1 0.1237183868762816 on epoch=437
05/30/2022 03:10:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.05 on epoch=439
05/30/2022 03:10:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.11 on epoch=442
05/30/2022 03:10:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/30/2022 03:10:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.08 on epoch=447
05/30/2022 03:10:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.03 on epoch=449
05/30/2022 03:10:09 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.13067758749069247 on epoch=449
05/30/2022 03:10:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.10 on epoch=452
05/30/2022 03:10:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.21 on epoch=454
05/30/2022 03:10:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.18 on epoch=457
05/30/2022 03:10:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.11 on epoch=459
05/30/2022 03:10:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.13 on epoch=462
05/30/2022 03:10:16 - INFO - __main__ - Global step 1850 Train loss 1.15 Classification-F1 0.1796875 on epoch=462
05/30/2022 03:10:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.04 on epoch=464
05/30/2022 03:10:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.04 on epoch=467
05/30/2022 03:10:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.06 on epoch=469
05/30/2022 03:10:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.97 on epoch=472
05/30/2022 03:10:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.98 on epoch=474
05/30/2022 03:10:23 - INFO - __main__ - Global step 1900 Train loss 1.02 Classification-F1 0.17569930069930068 on epoch=474
05/30/2022 03:10:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.97 on epoch=477
05/30/2022 03:10:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=479
05/30/2022 03:10:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.11 on epoch=482
05/30/2022 03:10:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.24 on epoch=484
05/30/2022 03:10:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.15 on epoch=487
05/30/2022 03:10:30 - INFO - __main__ - Global step 1950 Train loss 1.10 Classification-F1 0.14814814814814814 on epoch=487
05/30/2022 03:10:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.09 on epoch=489
05/30/2022 03:10:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.00 on epoch=492
05/30/2022 03:10:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.00 on epoch=494
05/30/2022 03:10:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.14 on epoch=497
05/30/2022 03:10:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.96 on epoch=499
05/30/2022 03:10:36 - INFO - __main__ - Global step 2000 Train loss 1.04 Classification-F1 0.1145104895104895 on epoch=499
05/30/2022 03:10:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=502
05/30/2022 03:10:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.13 on epoch=504
05/30/2022 03:10:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.03 on epoch=507
05/30/2022 03:10:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=509
05/30/2022 03:10:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.26 on epoch=512
05/30/2022 03:10:43 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.09493670886075949 on epoch=512
05/30/2022 03:10:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.03 on epoch=514
05/30/2022 03:10:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.93 on epoch=517
05/30/2022 03:10:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.88 on epoch=519
05/30/2022 03:10:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=522
05/30/2022 03:10:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
05/30/2022 03:10:50 - INFO - __main__ - Global step 2100 Train loss 0.99 Classification-F1 0.1451990632318501 on epoch=524
05/30/2022 03:10:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.97 on epoch=527
05/30/2022 03:10:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.12 on epoch=529
05/30/2022 03:10:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.06 on epoch=532
05/30/2022 03:10:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=534
05/30/2022 03:10:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.06 on epoch=537
05/30/2022 03:10:57 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.09868421052631579 on epoch=537
05/30/2022 03:10:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.96 on epoch=539
05/30/2022 03:10:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=542
05/30/2022 03:11:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.05 on epoch=544
05/30/2022 03:11:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.07 on epoch=547
05/30/2022 03:11:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.11 on epoch=549
05/30/2022 03:11:04 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.13149768399382397 on epoch=549
05/30/2022 03:11:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.11 on epoch=552
05/30/2022 03:11:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.03 on epoch=554
05/30/2022 03:11:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.03 on epoch=557
05/30/2022 03:11:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.96 on epoch=559
05/30/2022 03:11:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.10 on epoch=562
05/30/2022 03:11:10 - INFO - __main__ - Global step 2250 Train loss 1.05 Classification-F1 0.16261904761904764 on epoch=562
05/30/2022 03:11:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.97 on epoch=564
05/30/2022 03:11:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.94 on epoch=567
05/30/2022 03:11:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.97 on epoch=569
05/30/2022 03:11:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.99 on epoch=572
05/30/2022 03:11:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.92 on epoch=574
05/30/2022 03:11:17 - INFO - __main__ - Global step 2300 Train loss 0.96 Classification-F1 0.18356374807987713 on epoch=574
05/30/2022 03:11:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/30/2022 03:11:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.01 on epoch=579
05/30/2022 03:11:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.99 on epoch=582
05/30/2022 03:11:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.97 on epoch=584
05/30/2022 03:11:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.01 on epoch=587
05/30/2022 03:11:24 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.140625 on epoch=587
05/30/2022 03:11:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.05 on epoch=589
05/30/2022 03:11:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.03 on epoch=592
05/30/2022 03:11:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.06 on epoch=594
05/30/2022 03:11:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.95 on epoch=597
05/30/2022 03:11:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.00 on epoch=599
05/30/2022 03:11:31 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.17712418300653593 on epoch=599
05/30/2022 03:11:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.92 on epoch=602
05/30/2022 03:11:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.02 on epoch=604
05/30/2022 03:11:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.96 on epoch=607
05/30/2022 03:11:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.90 on epoch=609
05/30/2022 03:11:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.94 on epoch=612
05/30/2022 03:11:38 - INFO - __main__ - Global step 2450 Train loss 0.95 Classification-F1 0.19408369408369408 on epoch=612
05/30/2022 03:11:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.02 on epoch=614
05/30/2022 03:11:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=617
05/30/2022 03:11:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.02 on epoch=619
05/30/2022 03:11:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.99 on epoch=622
05/30/2022 03:11:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=624
05/30/2022 03:11:45 - INFO - __main__ - Global step 2500 Train loss 0.97 Classification-F1 0.1 on epoch=624
05/30/2022 03:11:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.98 on epoch=627
05/30/2022 03:11:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.88 on epoch=629
05/30/2022 03:11:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.06 on epoch=632
05/30/2022 03:11:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.05 on epoch=634
05/30/2022 03:11:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.04 on epoch=637
05/30/2022 03:11:51 - INFO - __main__ - Global step 2550 Train loss 1.00 Classification-F1 0.1408918406072106 on epoch=637
05/30/2022 03:11:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.08 on epoch=639
05/30/2022 03:11:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.00 on epoch=642
05/30/2022 03:11:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.99 on epoch=644
05/30/2022 03:11:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.96 on epoch=647
05/30/2022 03:11:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.04 on epoch=649
05/30/2022 03:11:58 - INFO - __main__ - Global step 2600 Train loss 1.01 Classification-F1 0.0998185117967332 on epoch=649
05/30/2022 03:12:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.94 on epoch=652
05/30/2022 03:12:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=654
05/30/2022 03:12:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.03 on epoch=657
05/30/2022 03:12:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.00 on epoch=659
05/30/2022 03:12:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.02 on epoch=662
05/30/2022 03:12:05 - INFO - __main__ - Global step 2650 Train loss 0.98 Classification-F1 0.1115492957746479 on epoch=662
05/30/2022 03:12:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.93 on epoch=664
05/30/2022 03:12:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.90 on epoch=667
05/30/2022 03:12:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.93 on epoch=669
05/30/2022 03:12:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.91 on epoch=672
05/30/2022 03:12:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.98 on epoch=674
05/30/2022 03:12:12 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.18782608695652175 on epoch=674
05/30/2022 03:12:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/30/2022 03:12:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.11 on epoch=679
05/30/2022 03:12:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.01 on epoch=682
05/30/2022 03:12:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.93 on epoch=684
05/30/2022 03:12:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.03 on epoch=687
05/30/2022 03:12:19 - INFO - __main__ - Global step 2750 Train loss 1.04 Classification-F1 0.15285714285714286 on epoch=687
05/30/2022 03:12:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=689
05/30/2022 03:12:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.06 on epoch=692
05/30/2022 03:12:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.02 on epoch=694
05/30/2022 03:12:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.89 on epoch=697
05/30/2022 03:12:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.94 on epoch=699
05/30/2022 03:12:26 - INFO - __main__ - Global step 2800 Train loss 0.97 Classification-F1 0.17798594847775173 on epoch=699
05/30/2022 03:12:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.92 on epoch=702
05/30/2022 03:12:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.93 on epoch=704
05/30/2022 03:12:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.98 on epoch=707
05/30/2022 03:12:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.90 on epoch=709
05/30/2022 03:12:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.98 on epoch=712
05/30/2022 03:12:32 - INFO - __main__ - Global step 2850 Train loss 0.94 Classification-F1 0.10256410256410256 on epoch=712
05/30/2022 03:12:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.83 on epoch=714
05/30/2022 03:12:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.92 on epoch=717
05/30/2022 03:12:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.97 on epoch=719
05/30/2022 03:12:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.94 on epoch=722
05/30/2022 03:12:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.92 on epoch=724
05/30/2022 03:12:39 - INFO - __main__ - Global step 2900 Train loss 0.92 Classification-F1 0.08552631578947369 on epoch=724
05/30/2022 03:12:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.03 on epoch=727
05/30/2022 03:12:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.93 on epoch=729
05/30/2022 03:12:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.01 on epoch=732
05/30/2022 03:12:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.98 on epoch=734
05/30/2022 03:12:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.01 on epoch=737
05/30/2022 03:12:46 - INFO - __main__ - Global step 2950 Train loss 0.99 Classification-F1 0.1 on epoch=737
05/30/2022 03:12:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.91 on epoch=739
05/30/2022 03:12:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.00 on epoch=742
05/30/2022 03:12:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.91 on epoch=744
05/30/2022 03:12:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.03 on epoch=747
05/30/2022 03:12:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.96 on epoch=749
05/30/2022 03:12:53 - INFO - __main__ - Global step 3000 Train loss 0.96 Classification-F1 0.1697802197802198 on epoch=749
05/30/2022 03:12:53 - INFO - __main__ - save last model!
05/30/2022 03:12:53 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 03:12:53 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 03:12:53 - INFO - __main__ - Printing 3 examples
05/30/2022 03:12:53 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 03:12:53 - INFO - __main__ - ['others']
05/30/2022 03:12:53 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 03:12:53 - INFO - __main__ - ['others']
05/30/2022 03:12:53 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 03:12:53 - INFO - __main__ - ['others']
05/30/2022 03:12:53 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:12:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:12:54 - INFO - __main__ - Printing 3 examples
05/30/2022 03:12:54 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 03:12:54 - INFO - __main__ - ['others']
05/30/2022 03:12:54 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 03:12:54 - INFO - __main__ - ['others']
05/30/2022 03:12:54 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 03:12:54 - INFO - __main__ - ['others']
05/30/2022 03:12:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:12:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:12:54 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 03:12:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:12:54 - INFO - __main__ - Printing 3 examples
05/30/2022 03:12:54 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 03:12:54 - INFO - __main__ - ['others']
05/30/2022 03:12:54 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 03:12:54 - INFO - __main__ - ['others']
05/30/2022 03:12:54 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 03:12:54 - INFO - __main__ - ['others']
05/30/2022 03:12:54 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:12:54 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:12:54 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 03:12:55 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:13:00 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 03:13:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 03:13:00 - INFO - __main__ - Starting training!
05/30/2022 03:13:01 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 03:13:44 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.3_8_predictions.txt
05/30/2022 03:13:44 - INFO - __main__ - Classification-F1 on test data: 0.0553
05/30/2022 03:13:44 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.19865392965696915, test_performance=0.05534399999455197
05/30/2022 03:13:44 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
05/30/2022 03:13:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:13:45 - INFO - __main__ - Printing 3 examples
05/30/2022 03:13:45 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/30/2022 03:13:45 - INFO - __main__ - ['others']
05/30/2022 03:13:45 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/30/2022 03:13:45 - INFO - __main__ - ['others']
05/30/2022 03:13:45 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/30/2022 03:13:45 - INFO - __main__ - ['others']
05/30/2022 03:13:45 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:13:45 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:13:45 - INFO - __main__ - Loaded 64 examples from train data
05/30/2022 03:13:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/30/2022 03:13:45 - INFO - __main__ - Printing 3 examples
05/30/2022 03:13:45 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
05/30/2022 03:13:45 - INFO - __main__ - ['others']
05/30/2022 03:13:45 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
05/30/2022 03:13:45 - INFO - __main__ - ['others']
05/30/2022 03:13:45 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
05/30/2022 03:13:45 - INFO - __main__ - ['others']
05/30/2022 03:13:45 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:13:45 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:13:45 - INFO - __main__ - Loaded 64 examples from dev data
05/30/2022 03:13:51 - INFO - __main__ - load prompt embedding from ckpt
05/30/2022 03:13:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/30/2022 03:13:51 - INFO - __main__ - Starting training!
05/30/2022 03:13:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.84 on epoch=2
05/30/2022 03:13:54 - INFO - __main__ - Step 20 Global step 20 Train loss 6.57 on epoch=4
05/30/2022 03:13:55 - INFO - __main__ - Step 30 Global step 30 Train loss 6.60 on epoch=7
05/30/2022 03:13:57 - INFO - __main__ - Step 40 Global step 40 Train loss 6.46 on epoch=9
05/30/2022 03:13:58 - INFO - __main__ - Step 50 Global step 50 Train loss 6.27 on epoch=12
05/30/2022 03:14:07 - INFO - __main__ - Global step 50 Train loss 6.55 Classification-F1 0.0 on epoch=12
05/30/2022 03:14:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=12, global_step=50
05/30/2022 03:14:08 - INFO - __main__ - Step 60 Global step 60 Train loss 6.06 on epoch=14
05/30/2022 03:14:10 - INFO - __main__ - Step 70 Global step 70 Train loss 5.98 on epoch=17
05/30/2022 03:14:11 - INFO - __main__ - Step 80 Global step 80 Train loss 5.76 on epoch=19
05/30/2022 03:14:13 - INFO - __main__ - Step 90 Global step 90 Train loss 5.75 on epoch=22
05/30/2022 03:14:14 - INFO - __main__ - Step 100 Global step 100 Train loss 5.76 on epoch=24
05/30/2022 03:14:16 - INFO - __main__ - Global step 100 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/30/2022 03:14:18 - INFO - __main__ - Step 110 Global step 110 Train loss 5.68 on epoch=27
05/30/2022 03:14:19 - INFO - __main__ - Step 120 Global step 120 Train loss 5.44 on epoch=29
05/30/2022 03:14:20 - INFO - __main__ - Step 130 Global step 130 Train loss 5.37 on epoch=32
05/30/2022 03:14:21 - INFO - __main__ - Step 140 Global step 140 Train loss 5.39 on epoch=34
05/30/2022 03:14:23 - INFO - __main__ - Step 150 Global step 150 Train loss 5.14 on epoch=37
05/30/2022 03:14:25 - INFO - __main__ - Global step 150 Train loss 5.41 Classification-F1 0.0 on epoch=37
05/30/2022 03:14:26 - INFO - __main__ - Step 160 Global step 160 Train loss 5.15 on epoch=39
05/30/2022 03:14:27 - INFO - __main__ - Step 170 Global step 170 Train loss 5.11 on epoch=42
05/30/2022 03:14:29 - INFO - __main__ - Step 180 Global step 180 Train loss 4.87 on epoch=44
05/30/2022 03:14:30 - INFO - __main__ - Step 190 Global step 190 Train loss 5.11 on epoch=47
05/30/2022 03:14:31 - INFO - __main__ - Step 200 Global step 200 Train loss 4.70 on epoch=49
05/30/2022 03:14:34 - INFO - __main__ - Global step 200 Train loss 4.99 Classification-F1 0.0 on epoch=49
05/30/2022 03:14:35 - INFO - __main__ - Step 210 Global step 210 Train loss 4.63 on epoch=52
05/30/2022 03:14:36 - INFO - __main__ - Step 220 Global step 220 Train loss 4.61 on epoch=54
05/30/2022 03:14:38 - INFO - __main__ - Step 230 Global step 230 Train loss 4.47 on epoch=57
05/30/2022 03:14:39 - INFO - __main__ - Step 240 Global step 240 Train loss 4.31 on epoch=59
05/30/2022 03:14:40 - INFO - __main__ - Step 250 Global step 250 Train loss 4.22 on epoch=62
05/30/2022 03:14:41 - INFO - __main__ - Global step 250 Train loss 4.45 Classification-F1 0.08235243017851714 on epoch=62
05/30/2022 03:14:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08235243017851714 on epoch=62, global_step=250
05/30/2022 03:14:42 - INFO - __main__ - Step 260 Global step 260 Train loss 4.14 on epoch=64
05/30/2022 03:14:43 - INFO - __main__ - Step 270 Global step 270 Train loss 4.15 on epoch=67
05/30/2022 03:14:45 - INFO - __main__ - Step 280 Global step 280 Train loss 3.95 on epoch=69
05/30/2022 03:14:46 - INFO - __main__ - Step 290 Global step 290 Train loss 3.97 on epoch=72
05/30/2022 03:14:47 - INFO - __main__ - Step 300 Global step 300 Train loss 3.84 on epoch=74
05/30/2022 03:14:48 - INFO - __main__ - Global step 300 Train loss 4.01 Classification-F1 0.15141579731743665 on epoch=74
05/30/2022 03:14:48 - INFO - __main__ - Saving model with best Classification-F1: 0.08235243017851714 -> 0.15141579731743665 on epoch=74, global_step=300
05/30/2022 03:14:49 - INFO - __main__ - Step 310 Global step 310 Train loss 3.83 on epoch=77
05/30/2022 03:14:50 - INFO - __main__ - Step 320 Global step 320 Train loss 3.72 on epoch=79
05/30/2022 03:14:51 - INFO - __main__ - Step 330 Global step 330 Train loss 3.68 on epoch=82
05/30/2022 03:14:53 - INFO - __main__ - Step 340 Global step 340 Train loss 3.43 on epoch=84
05/30/2022 03:14:54 - INFO - __main__ - Step 350 Global step 350 Train loss 3.41 on epoch=87
05/30/2022 03:14:54 - INFO - __main__ - Global step 350 Train loss 3.61 Classification-F1 0.13034188034188032 on epoch=87
05/30/2022 03:14:56 - INFO - __main__ - Step 360 Global step 360 Train loss 3.28 on epoch=89
05/30/2022 03:14:57 - INFO - __main__ - Step 370 Global step 370 Train loss 3.31 on epoch=92
05/30/2022 03:14:58 - INFO - __main__ - Step 380 Global step 380 Train loss 3.03 on epoch=94
05/30/2022 03:14:59 - INFO - __main__ - Step 390 Global step 390 Train loss 3.11 on epoch=97
05/30/2022 03:15:01 - INFO - __main__ - Step 400 Global step 400 Train loss 3.11 on epoch=99
05/30/2022 03:15:01 - INFO - __main__ - Global step 400 Train loss 3.17 Classification-F1 0.1237183868762816 on epoch=99
05/30/2022 03:15:02 - INFO - __main__ - Step 410 Global step 410 Train loss 2.95 on epoch=102
05/30/2022 03:15:04 - INFO - __main__ - Step 420 Global step 420 Train loss 2.92 on epoch=104
05/30/2022 03:15:05 - INFO - __main__ - Step 430 Global step 430 Train loss 2.99 on epoch=107
05/30/2022 03:15:06 - INFO - __main__ - Step 440 Global step 440 Train loss 2.80 on epoch=109
05/30/2022 03:15:08 - INFO - __main__ - Step 450 Global step 450 Train loss 2.90 on epoch=112
05/30/2022 03:15:08 - INFO - __main__ - Global step 450 Train loss 2.91 Classification-F1 0.1 on epoch=112
05/30/2022 03:15:09 - INFO - __main__ - Step 460 Global step 460 Train loss 2.68 on epoch=114
05/30/2022 03:15:11 - INFO - __main__ - Step 470 Global step 470 Train loss 2.78 on epoch=117
05/30/2022 03:15:12 - INFO - __main__ - Step 480 Global step 480 Train loss 2.56 on epoch=119
05/30/2022 03:15:13 - INFO - __main__ - Step 490 Global step 490 Train loss 2.56 on epoch=122
05/30/2022 03:15:14 - INFO - __main__ - Step 500 Global step 500 Train loss 2.47 on epoch=124
05/30/2022 03:15:15 - INFO - __main__ - Global step 500 Train loss 2.61 Classification-F1 0.10256410256410256 on epoch=124
05/30/2022 03:15:16 - INFO - __main__ - Step 510 Global step 510 Train loss 2.58 on epoch=127
05/30/2022 03:15:17 - INFO - __main__ - Step 520 Global step 520 Train loss 2.46 on epoch=129
05/30/2022 03:15:19 - INFO - __main__ - Step 530 Global step 530 Train loss 2.52 on epoch=132
05/30/2022 03:15:20 - INFO - __main__ - Step 540 Global step 540 Train loss 2.34 on epoch=134
05/30/2022 03:15:21 - INFO - __main__ - Step 550 Global step 550 Train loss 2.48 on epoch=137
05/30/2022 03:15:22 - INFO - __main__ - Global step 550 Train loss 2.48 Classification-F1 0.19673202614379087 on epoch=137
05/30/2022 03:15:22 - INFO - __main__ - Saving model with best Classification-F1: 0.15141579731743665 -> 0.19673202614379087 on epoch=137, global_step=550
05/30/2022 03:15:23 - INFO - __main__ - Step 560 Global step 560 Train loss 2.28 on epoch=139
05/30/2022 03:15:24 - INFO - __main__ - Step 570 Global step 570 Train loss 2.36 on epoch=142
05/30/2022 03:15:25 - INFO - __main__ - Step 580 Global step 580 Train loss 2.21 on epoch=144
05/30/2022 03:15:27 - INFO - __main__ - Step 590 Global step 590 Train loss 2.26 on epoch=147
05/30/2022 03:15:28 - INFO - __main__ - Step 600 Global step 600 Train loss 2.08 on epoch=149
05/30/2022 03:15:28 - INFO - __main__ - Global step 600 Train loss 2.24 Classification-F1 0.10135135135135136 on epoch=149
05/30/2022 03:15:30 - INFO - __main__ - Step 610 Global step 610 Train loss 2.13 on epoch=152
05/30/2022 03:15:31 - INFO - __main__ - Step 620 Global step 620 Train loss 2.06 on epoch=154
05/30/2022 03:15:32 - INFO - __main__ - Step 630 Global step 630 Train loss 2.26 on epoch=157
05/30/2022 03:15:34 - INFO - __main__ - Step 640 Global step 640 Train loss 2.17 on epoch=159
05/30/2022 03:15:35 - INFO - __main__ - Step 650 Global step 650 Train loss 2.27 on epoch=162
05/30/2022 03:15:35 - INFO - __main__ - Global step 650 Train loss 2.18 Classification-F1 0.11714285714285715 on epoch=162
05/30/2022 03:15:37 - INFO - __main__ - Step 660 Global step 660 Train loss 1.90 on epoch=164
05/30/2022 03:15:38 - INFO - __main__ - Step 670 Global step 670 Train loss 1.97 on epoch=167
05/30/2022 03:15:39 - INFO - __main__ - Step 680 Global step 680 Train loss 2.01 on epoch=169
05/30/2022 03:15:40 - INFO - __main__ - Step 690 Global step 690 Train loss 2.02 on epoch=172
05/30/2022 03:15:42 - INFO - __main__ - Step 700 Global step 700 Train loss 1.98 on epoch=174
05/30/2022 03:15:42 - INFO - __main__ - Global step 700 Train loss 1.98 Classification-F1 0.10256410256410256 on epoch=174
05/30/2022 03:15:43 - INFO - __main__ - Step 710 Global step 710 Train loss 2.02 on epoch=177
05/30/2022 03:15:45 - INFO - __main__ - Step 720 Global step 720 Train loss 1.80 on epoch=179
05/30/2022 03:15:46 - INFO - __main__ - Step 730 Global step 730 Train loss 1.77 on epoch=182
05/30/2022 03:15:47 - INFO - __main__ - Step 740 Global step 740 Train loss 1.77 on epoch=184
05/30/2022 03:15:48 - INFO - __main__ - Step 750 Global step 750 Train loss 1.87 on epoch=187
05/30/2022 03:15:49 - INFO - __main__ - Global step 750 Train loss 1.85 Classification-F1 0.1 on epoch=187
05/30/2022 03:15:50 - INFO - __main__ - Step 760 Global step 760 Train loss 1.78 on epoch=189
05/30/2022 03:15:51 - INFO - __main__ - Step 770 Global step 770 Train loss 2.00 on epoch=192
05/30/2022 03:15:53 - INFO - __main__ - Step 780 Global step 780 Train loss 1.69 on epoch=194
05/30/2022 03:15:54 - INFO - __main__ - Step 790 Global step 790 Train loss 1.87 on epoch=197
05/30/2022 03:15:55 - INFO - __main__ - Step 800 Global step 800 Train loss 1.62 on epoch=199
05/30/2022 03:15:56 - INFO - __main__ - Global step 800 Train loss 1.79 Classification-F1 0.10126582278481013 on epoch=199
05/30/2022 03:15:57 - INFO - __main__ - Step 810 Global step 810 Train loss 1.84 on epoch=202
05/30/2022 03:15:58 - INFO - __main__ - Step 820 Global step 820 Train loss 1.69 on epoch=204
05/30/2022 03:15:59 - INFO - __main__ - Step 830 Global step 830 Train loss 1.85 on epoch=207
05/30/2022 03:16:01 - INFO - __main__ - Step 840 Global step 840 Train loss 1.71 on epoch=209
05/30/2022 03:16:02 - INFO - __main__ - Step 850 Global step 850 Train loss 1.52 on epoch=212
05/30/2022 03:16:02 - INFO - __main__ - Global step 850 Train loss 1.72 Classification-F1 0.1 on epoch=212
05/30/2022 03:16:04 - INFO - __main__ - Step 860 Global step 860 Train loss 1.62 on epoch=214
05/30/2022 03:16:05 - INFO - __main__ - Step 870 Global step 870 Train loss 1.58 on epoch=217
05/30/2022 03:16:06 - INFO - __main__ - Step 880 Global step 880 Train loss 1.72 on epoch=219
05/30/2022 03:16:08 - INFO - __main__ - Step 890 Global step 890 Train loss 1.67 on epoch=222
05/30/2022 03:16:09 - INFO - __main__ - Step 900 Global step 900 Train loss 1.68 on epoch=224
05/30/2022 03:16:09 - INFO - __main__ - Global step 900 Train loss 1.66 Classification-F1 0.1 on epoch=224
05/30/2022 03:16:11 - INFO - __main__ - Step 910 Global step 910 Train loss 1.67 on epoch=227
05/30/2022 03:16:12 - INFO - __main__ - Step 920 Global step 920 Train loss 1.61 on epoch=229
05/30/2022 03:16:13 - INFO - __main__ - Step 930 Global step 930 Train loss 1.49 on epoch=232
05/30/2022 03:16:14 - INFO - __main__ - Step 940 Global step 940 Train loss 1.66 on epoch=234
05/30/2022 03:16:16 - INFO - __main__ - Step 950 Global step 950 Train loss 1.63 on epoch=237
05/30/2022 03:16:16 - INFO - __main__ - Global step 950 Train loss 1.61 Classification-F1 0.1 on epoch=237
05/30/2022 03:16:17 - INFO - __main__ - Step 960 Global step 960 Train loss 1.31 on epoch=239
05/30/2022 03:16:19 - INFO - __main__ - Step 970 Global step 970 Train loss 1.39 on epoch=242
05/30/2022 03:16:20 - INFO - __main__ - Step 980 Global step 980 Train loss 1.45 on epoch=244
05/30/2022 03:16:21 - INFO - __main__ - Step 990 Global step 990 Train loss 1.55 on epoch=247
05/30/2022 03:16:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.64 on epoch=249
05/30/2022 03:16:23 - INFO - __main__ - Global step 1000 Train loss 1.47 Classification-F1 0.1 on epoch=249
05/30/2022 03:16:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.38 on epoch=252
05/30/2022 03:16:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.48 on epoch=254
05/30/2022 03:16:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.56 on epoch=257
05/30/2022 03:16:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.47 on epoch=259
05/30/2022 03:16:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.38 on epoch=262
05/30/2022 03:16:30 - INFO - __main__ - Global step 1050 Train loss 1.45 Classification-F1 0.1 on epoch=262
05/30/2022 03:16:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.39 on epoch=264
05/30/2022 03:16:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.47 on epoch=267
05/30/2022 03:16:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.50 on epoch=269
05/30/2022 03:16:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.53 on epoch=272
05/30/2022 03:16:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.47 on epoch=274
05/30/2022 03:16:37 - INFO - __main__ - Global step 1100 Train loss 1.47 Classification-F1 0.18907563025210083 on epoch=274
05/30/2022 03:16:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.53 on epoch=277
05/30/2022 03:16:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.43 on epoch=279
05/30/2022 03:16:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.37 on epoch=282
05/30/2022 03:16:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.43 on epoch=284
05/30/2022 03:16:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.42 on epoch=287
05/30/2022 03:16:43 - INFO - __main__ - Global step 1150 Train loss 1.44 Classification-F1 0.18928571428571428 on epoch=287
05/30/2022 03:16:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.42 on epoch=289
05/30/2022 03:16:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.31 on epoch=292
05/30/2022 03:16:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.32 on epoch=294
05/30/2022 03:16:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.34 on epoch=297
05/30/2022 03:16:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.32 on epoch=299
05/30/2022 03:16:50 - INFO - __main__ - Global step 1200 Train loss 1.34 Classification-F1 0.13034188034188032 on epoch=299
05/30/2022 03:16:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.39 on epoch=302
05/30/2022 03:16:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.24 on epoch=304
05/30/2022 03:16:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.39 on epoch=307
05/30/2022 03:16:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.19 on epoch=309
05/30/2022 03:16:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.25 on epoch=312
05/30/2022 03:16:57 - INFO - __main__ - Global step 1250 Train loss 1.29 Classification-F1 0.1581196581196581 on epoch=312
05/30/2022 03:16:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=314
05/30/2022 03:17:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.51 on epoch=317
05/30/2022 03:17:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.37 on epoch=319
05/30/2022 03:17:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.34 on epoch=322
05/30/2022 03:17:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.32 on epoch=324
05/30/2022 03:17:04 - INFO - __main__ - Global step 1300 Train loss 1.38 Classification-F1 0.1 on epoch=324
05/30/2022 03:17:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.40 on epoch=327
05/30/2022 03:17:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.28 on epoch=329
05/30/2022 03:17:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.32 on epoch=332
05/30/2022 03:17:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.17 on epoch=334
05/30/2022 03:17:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.28 on epoch=337
05/30/2022 03:17:11 - INFO - __main__ - Global step 1350 Train loss 1.29 Classification-F1 0.17552334943639292 on epoch=337
05/30/2022 03:17:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.25 on epoch=339
05/30/2022 03:17:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.21 on epoch=342
05/30/2022 03:17:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.23 on epoch=344
05/30/2022 03:17:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.31 on epoch=347
05/30/2022 03:17:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.16 on epoch=349
05/30/2022 03:17:18 - INFO - __main__ - Global step 1400 Train loss 1.23 Classification-F1 0.16526054590570718 on epoch=349
05/30/2022 03:17:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.23 on epoch=352
05/30/2022 03:17:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=354
05/30/2022 03:17:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.27 on epoch=357
05/30/2022 03:17:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.13 on epoch=359
05/30/2022 03:17:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.31 on epoch=362
05/30/2022 03:17:25 - INFO - __main__ - Global step 1450 Train loss 1.24 Classification-F1 0.1238095238095238 on epoch=362
05/30/2022 03:17:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.30 on epoch=364
05/30/2022 03:17:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.27 on epoch=367
05/30/2022 03:17:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.27 on epoch=369
05/30/2022 03:17:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.12 on epoch=372
05/30/2022 03:17:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.17 on epoch=374
05/30/2022 03:17:32 - INFO - __main__ - Global step 1500 Train loss 1.22 Classification-F1 0.17809523809523808 on epoch=374
05/30/2022 03:17:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.18 on epoch=377
05/30/2022 03:17:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.31 on epoch=379
05/30/2022 03:17:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.23 on epoch=382
05/30/2022 03:17:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.23 on epoch=384
05/30/2022 03:17:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.21 on epoch=387
05/30/2022 03:17:39 - INFO - __main__ - Global step 1550 Train loss 1.23 Classification-F1 0.1 on epoch=387
05/30/2022 03:17:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=389
05/30/2022 03:17:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.21 on epoch=392
05/30/2022 03:17:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.21 on epoch=394
05/30/2022 03:17:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.10 on epoch=397
05/30/2022 03:17:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.27 on epoch=399
05/30/2022 03:17:46 - INFO - __main__ - Global step 1600 Train loss 1.20 Classification-F1 0.18561872909698998 on epoch=399
05/30/2022 03:17:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.17 on epoch=402
05/30/2022 03:17:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.25 on epoch=404
05/30/2022 03:17:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.17 on epoch=407
05/30/2022 03:17:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.33 on epoch=409
05/30/2022 03:17:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.26 on epoch=412
05/30/2022 03:17:53 - INFO - __main__ - Global step 1650 Train loss 1.23 Classification-F1 0.18406593406593408 on epoch=412
05/30/2022 03:17:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.25 on epoch=414
05/30/2022 03:17:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.25 on epoch=417
05/30/2022 03:17:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.08 on epoch=419
05/30/2022 03:17:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.16 on epoch=422
05/30/2022 03:17:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.30 on epoch=424
05/30/2022 03:18:00 - INFO - __main__ - Global step 1700 Train loss 1.21 Classification-F1 0.19267605633802815 on epoch=424
05/30/2022 03:18:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=427
05/30/2022 03:18:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.13 on epoch=429
05/30/2022 03:18:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.15 on epoch=432
05/30/2022 03:18:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.25 on epoch=434
05/30/2022 03:18:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.29 on epoch=437
05/30/2022 03:18:06 - INFO - __main__ - Global step 1750 Train loss 1.21 Classification-F1 0.1313186813186813 on epoch=437
05/30/2022 03:18:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.11 on epoch=439
05/30/2022 03:18:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.21 on epoch=442
05/30/2022 03:18:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.07 on epoch=444
05/30/2022 03:18:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.21 on epoch=447
05/30/2022 03:18:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.13 on epoch=449
05/30/2022 03:18:13 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.17813765182186234 on epoch=449
05/30/2022 03:18:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.22 on epoch=452
05/30/2022 03:18:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=454
05/30/2022 03:18:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.20 on epoch=457
05/30/2022 03:18:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.13 on epoch=459
05/30/2022 03:18:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.20 on epoch=462
05/30/2022 03:18:20 - INFO - __main__ - Global step 1850 Train loss 1.18 Classification-F1 0.1565276828434723 on epoch=462
05/30/2022 03:18:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.18 on epoch=464
05/30/2022 03:18:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.14 on epoch=467
05/30/2022 03:18:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.16 on epoch=469
05/30/2022 03:18:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.25 on epoch=472
05/30/2022 03:18:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.16 on epoch=474
05/30/2022 03:18:27 - INFO - __main__ - Global step 1900 Train loss 1.18 Classification-F1 0.13333333333333333 on epoch=474
05/30/2022 03:18:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.11 on epoch=477
05/30/2022 03:18:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.08 on epoch=479
05/30/2022 03:18:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.18 on epoch=482
05/30/2022 03:18:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.02 on epoch=484
05/30/2022 03:18:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.97 on epoch=487
05/30/2022 03:18:34 - INFO - __main__ - Global step 1950 Train loss 1.07 Classification-F1 0.1736111111111111 on epoch=487
05/30/2022 03:18:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.15 on epoch=489
05/30/2022 03:18:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.12 on epoch=492
05/30/2022 03:18:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.10 on epoch=494
05/30/2022 03:18:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=497
05/30/2022 03:18:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.10 on epoch=499
05/30/2022 03:18:41 - INFO - __main__ - Global step 2000 Train loss 1.11 Classification-F1 0.15526315789473685 on epoch=499
05/30/2022 03:18:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.16 on epoch=502
05/30/2022 03:18:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.00 on epoch=504
05/30/2022 03:18:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.17 on epoch=507
05/30/2022 03:18:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.09 on epoch=509
05/30/2022 03:18:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.04 on epoch=512
05/30/2022 03:18:48 - INFO - __main__ - Global step 2050 Train loss 1.09 Classification-F1 0.109375 on epoch=512
05/30/2022 03:18:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.96 on epoch=514
05/30/2022 03:18:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.17 on epoch=517
05/30/2022 03:18:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.13 on epoch=519
05/30/2022 03:18:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.10 on epoch=522
05/30/2022 03:18:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.10 on epoch=524
05/30/2022 03:18:54 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.2091503267973856 on epoch=524
05/30/2022 03:18:54 - INFO - __main__ - Saving model with best Classification-F1: 0.19673202614379087 -> 0.2091503267973856 on epoch=524, global_step=2100
05/30/2022 03:18:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.05 on epoch=527
05/30/2022 03:18:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.09 on epoch=529
05/30/2022 03:18:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.23 on epoch=532
05/30/2022 03:19:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.17 on epoch=534
05/30/2022 03:19:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.17 on epoch=537
05/30/2022 03:19:01 - INFO - __main__ - Global step 2150 Train loss 1.14 Classification-F1 0.18276972624798712 on epoch=537
05/30/2022 03:19:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.16 on epoch=539
05/30/2022 03:19:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.16 on epoch=542
05/30/2022 03:19:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.15 on epoch=544
05/30/2022 03:19:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.16 on epoch=547
05/30/2022 03:19:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.17 on epoch=549
05/30/2022 03:19:08 - INFO - __main__ - Global step 2200 Train loss 1.16 Classification-F1 0.1468058968058968 on epoch=549
05/30/2022 03:19:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.16 on epoch=552
05/30/2022 03:19:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=554
05/30/2022 03:19:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.16 on epoch=557
05/30/2022 03:19:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.02 on epoch=559
05/30/2022 03:19:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.07 on epoch=562
05/30/2022 03:19:15 - INFO - __main__ - Global step 2250 Train loss 1.08 Classification-F1 0.1581196581196581 on epoch=562
05/30/2022 03:19:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.13 on epoch=564
05/30/2022 03:19:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.11 on epoch=567
05/30/2022 03:19:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.14 on epoch=569
05/30/2022 03:19:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.07 on epoch=572
05/30/2022 03:19:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.16 on epoch=574
05/30/2022 03:19:22 - INFO - __main__ - Global step 2300 Train loss 1.12 Classification-F1 0.171875 on epoch=574
05/30/2022 03:19:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.10 on epoch=577
05/30/2022 03:19:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.18 on epoch=579
05/30/2022 03:19:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.06 on epoch=582
05/30/2022 03:19:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.03 on epoch=584
05/30/2022 03:19:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.15 on epoch=587
05/30/2022 03:19:29 - INFO - __main__ - Global step 2350 Train loss 1.10 Classification-F1 0.180905815748842 on epoch=587
05/30/2022 03:19:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.20 on epoch=589
05/30/2022 03:19:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.04 on epoch=592
05/30/2022 03:19:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=594
05/30/2022 03:19:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=597
05/30/2022 03:19:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.16 on epoch=599
05/30/2022 03:19:36 - INFO - __main__ - Global step 2400 Train loss 1.09 Classification-F1 0.13430127041742287 on epoch=599
05/30/2022 03:19:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.08 on epoch=602
05/30/2022 03:19:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=604
05/30/2022 03:19:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.09 on epoch=607
05/30/2022 03:19:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.03 on epoch=609
05/30/2022 03:19:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.97 on epoch=612
05/30/2022 03:19:43 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.18881118881118883 on epoch=612
05/30/2022 03:19:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.06 on epoch=614
05/30/2022 03:19:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=617
05/30/2022 03:19:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.96 on epoch=619
05/30/2022 03:19:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.00 on epoch=622
05/30/2022 03:19:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.10 on epoch=624
05/30/2022 03:19:50 - INFO - __main__ - Global step 2500 Train loss 1.03 Classification-F1 0.16888045540796964 on epoch=624
05/30/2022 03:19:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.14 on epoch=627
05/30/2022 03:19:52 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.02 on epoch=629
05/30/2022 03:19:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.00 on epoch=632
05/30/2022 03:19:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.02 on epoch=634
05/30/2022 03:19:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.02 on epoch=637
05/30/2022 03:19:57 - INFO - __main__ - Global step 2550 Train loss 1.04 Classification-F1 0.1581196581196581 on epoch=637
05/30/2022 03:19:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.03 on epoch=639
05/30/2022 03:19:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=642
05/30/2022 03:20:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.06 on epoch=644
05/30/2022 03:20:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=647
05/30/2022 03:20:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.00 on epoch=649
05/30/2022 03:20:03 - INFO - __main__ - Global step 2600 Train loss 1.03 Classification-F1 0.10126582278481013 on epoch=649
05/30/2022 03:20:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.08 on epoch=652
05/30/2022 03:20:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.03 on epoch=654
05/30/2022 03:20:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.01 on epoch=657
05/30/2022 03:20:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.03 on epoch=659
05/30/2022 03:20:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.03 on epoch=662
05/30/2022 03:20:10 - INFO - __main__ - Global step 2650 Train loss 1.04 Classification-F1 0.13034188034188032 on epoch=662
05/30/2022 03:20:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.09 on epoch=664
05/30/2022 03:20:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.10 on epoch=667
05/30/2022 03:20:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.05 on epoch=669
05/30/2022 03:20:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=672
05/30/2022 03:20:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.06 on epoch=674
05/30/2022 03:20:17 - INFO - __main__ - Global step 2700 Train loss 1.06 Classification-F1 0.13067758749069247 on epoch=674
05/30/2022 03:20:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.10 on epoch=677
05/30/2022 03:20:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.03 on epoch=679
05/30/2022 03:20:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.16 on epoch=682
05/30/2022 03:20:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.03 on epoch=684
05/30/2022 03:20:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.02 on epoch=687
05/30/2022 03:20:24 - INFO - __main__ - Global step 2750 Train loss 1.07 Classification-F1 0.1 on epoch=687
05/30/2022 03:20:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.05 on epoch=689
05/30/2022 03:20:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.08 on epoch=692
05/30/2022 03:20:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.06 on epoch=694
05/30/2022 03:20:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.03 on epoch=697
05/30/2022 03:20:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.04 on epoch=699
05/30/2022 03:20:31 - INFO - __main__ - Global step 2800 Train loss 1.05 Classification-F1 0.13067758749069247 on epoch=699
05/30/2022 03:20:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.09 on epoch=702
05/30/2022 03:20:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.96 on epoch=704
05/30/2022 03:20:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.07 on epoch=707
05/30/2022 03:20:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.15 on epoch=709
05/30/2022 03:20:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.02 on epoch=712
05/30/2022 03:20:38 - INFO - __main__ - Global step 2850 Train loss 1.06 Classification-F1 0.09493670886075949 on epoch=712
05/30/2022 03:20:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.11 on epoch=714
05/30/2022 03:20:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.12 on epoch=717
05/30/2022 03:20:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.96 on epoch=719
05/30/2022 03:20:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.15 on epoch=722
05/30/2022 03:20:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.94 on epoch=724
05/30/2022 03:20:45 - INFO - __main__ - Global step 2900 Train loss 1.06 Classification-F1 0.13026315789473686 on epoch=724
05/30/2022 03:20:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.01 on epoch=727
05/30/2022 03:20:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.98 on epoch=729
05/30/2022 03:20:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.06 on epoch=732
05/30/2022 03:20:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.02 on epoch=734
05/30/2022 03:20:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.07 on epoch=737
05/30/2022 03:20:52 - INFO - __main__ - Global step 2950 Train loss 1.03 Classification-F1 0.1 on epoch=737
05/30/2022 03:20:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.05 on epoch=739
05/30/2022 03:20:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.12 on epoch=742
05/30/2022 03:20:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.13 on epoch=744
05/30/2022 03:20:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.07 on epoch=747
05/30/2022 03:20:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.97 on epoch=749
05/30/2022 03:20:59 - INFO - __main__ - Global step 3000 Train loss 1.07 Classification-F1 0.18276972624798712 on epoch=749
05/30/2022 03:20:59 - INFO - __main__ - save last model!
05/30/2022 03:20:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/30/2022 03:20:59 - INFO - __main__ - Start tokenizing ... 5509 instances
05/30/2022 03:20:59 - INFO - __main__ - Printing 3 examples
05/30/2022 03:20:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/30/2022 03:20:59 - INFO - __main__ - ['others']
05/30/2022 03:20:59 - INFO - __main__ -  [emo] what you like very little things ok
05/30/2022 03:20:59 - INFO - __main__ - ['others']
05/30/2022 03:20:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/30/2022 03:20:59 - INFO - __main__ - ['others']
05/30/2022 03:20:59 - INFO - __main__ - Tokenizing Input ...
05/30/2022 03:21:01 - INFO - __main__ - Tokenizing Output ...
05/30/2022 03:21:06 - INFO - __main__ - Loaded 5509 examples from test data
05/30/2022 03:21:49 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-emo/emo_16_87_0.2_8_predictions.txt
05/30/2022 03:21:49 - INFO - __main__ - Classification-F1 on test data: 0.0428
05/30/2022 03:21:50 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.2091503267973856, test_performance=0.04281145790239352
