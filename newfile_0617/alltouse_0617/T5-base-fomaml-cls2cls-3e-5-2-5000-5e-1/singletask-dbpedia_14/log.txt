05/16/2022 06:45:57 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/16/2022 06:45:57 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
05/16/2022 06:45:57 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/16/2022 06:45:57 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
05/16/2022 06:45:58 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/16/2022 06:45:58 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/16/2022 06:45:58 - INFO - __main__ - args.device: cuda:0
05/16/2022 06:45:58 - INFO - __main__ - Using 2 gpus
05/16/2022 06:45:58 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/16/2022 06:45:58 - INFO - __main__ - args.device: cuda:1
05/16/2022 06:45:58 - INFO - __main__ - Using 2 gpus
05/16/2022 06:45:58 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/16/2022 06:46:03 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/16/2022 06:46:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 06:46:03 - INFO - __main__ - Printing 3 examples
05/16/2022 06:46:03 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 06:46:03 - INFO - __main__ - ['Animal']
05/16/2022 06:46:03 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 06:46:03 - INFO - __main__ - ['Animal']
05/16/2022 06:46:03 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 06:46:03 - INFO - __main__ - ['Animal']
05/16/2022 06:46:03 - INFO - __main__ - Tokenizing Input ...
05/16/2022 06:46:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 06:46:04 - INFO - __main__ - Printing 3 examples
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ - Tokenizing Input ...
05/16/2022 06:46:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 06:46:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 06:46:04 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 06:46:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 06:46:04 - INFO - __main__ - Printing 3 examples
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ - Tokenizing Input ...
05/16/2022 06:46:04 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 06:46:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 06:46:04 - INFO - __main__ - Printing 3 examples
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 06:46:04 - INFO - __main__ - ['Animal']
05/16/2022 06:46:04 - INFO - __main__ - Tokenizing Input ...
05/16/2022 06:46:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 06:46:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 06:46:04 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 06:46:04 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 06:46:10 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 06:46:10 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 06:46:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 06:46:11 - INFO - __main__ - Starting training!
05/16/2022 06:46:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 06:46:17 - INFO - __main__ - Starting training!
05/16/2022 06:46:22 - INFO - __main__ - Step 10 Global step 10 Train loss 7.27 on epoch=0
05/16/2022 06:46:23 - INFO - __main__ - Step 20 Global step 20 Train loss 7.27 on epoch=1
05/16/2022 06:46:24 - INFO - __main__ - Step 30 Global step 30 Train loss 6.96 on epoch=2
05/16/2022 06:46:26 - INFO - __main__ - Step 40 Global step 40 Train loss 6.94 on epoch=2
05/16/2022 06:46:27 - INFO - __main__ - Step 50 Global step 50 Train loss 6.87 on epoch=3
05/16/2022 06:47:17 - INFO - __main__ - Global step 50 Train loss 7.06 Classification-F1 0.0 on epoch=3
05/16/2022 06:47:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 06:47:19 - INFO - __main__ - Step 60 Global step 60 Train loss 6.61 on epoch=4
05/16/2022 06:47:20 - INFO - __main__ - Step 70 Global step 70 Train loss 6.73 on epoch=4
05/16/2022 06:47:21 - INFO - __main__ - Step 80 Global step 80 Train loss 6.51 on epoch=5
05/16/2022 06:47:23 - INFO - __main__ - Step 90 Global step 90 Train loss 6.22 on epoch=6
05/16/2022 06:47:24 - INFO - __main__ - Step 100 Global step 100 Train loss 6.19 on epoch=7
05/16/2022 06:48:30 - INFO - __main__ - Global step 100 Train loss 6.45 Classification-F1 0.0 on epoch=7
05/16/2022 06:48:31 - INFO - __main__ - Step 110 Global step 110 Train loss 6.21 on epoch=7
05/16/2022 06:48:33 - INFO - __main__ - Step 120 Global step 120 Train loss 6.12 on epoch=8
05/16/2022 06:48:34 - INFO - __main__ - Step 130 Global step 130 Train loss 5.88 on epoch=9
05/16/2022 06:48:35 - INFO - __main__ - Step 140 Global step 140 Train loss 6.11 on epoch=9
05/16/2022 06:48:37 - INFO - __main__ - Step 150 Global step 150 Train loss 6.02 on epoch=10
05/16/2022 06:49:09 - INFO - __main__ - Global step 150 Train loss 6.07 Classification-F1 0.0 on epoch=10
05/16/2022 06:49:11 - INFO - __main__ - Step 160 Global step 160 Train loss 5.87 on epoch=11
05/16/2022 06:49:12 - INFO - __main__ - Step 170 Global step 170 Train loss 5.65 on epoch=12
05/16/2022 06:49:14 - INFO - __main__ - Step 180 Global step 180 Train loss 5.76 on epoch=12
05/16/2022 06:49:15 - INFO - __main__ - Step 190 Global step 190 Train loss 5.65 on epoch=13
05/16/2022 06:49:17 - INFO - __main__ - Step 200 Global step 200 Train loss 5.54 on epoch=14
05/16/2022 06:50:26 - INFO - __main__ - Global step 200 Train loss 5.69 Classification-F1 0.0 on epoch=14
05/16/2022 06:50:28 - INFO - __main__ - Step 210 Global step 210 Train loss 5.63 on epoch=14
05/16/2022 06:50:29 - INFO - __main__ - Step 220 Global step 220 Train loss 5.43 on epoch=15
05/16/2022 06:50:30 - INFO - __main__ - Step 230 Global step 230 Train loss 5.51 on epoch=16
05/16/2022 06:50:32 - INFO - __main__ - Step 240 Global step 240 Train loss 5.26 on epoch=17
05/16/2022 06:50:33 - INFO - __main__ - Step 250 Global step 250 Train loss 5.33 on epoch=17
05/16/2022 06:51:10 - INFO - __main__ - Global step 250 Train loss 5.43 Classification-F1 0.0 on epoch=17
05/16/2022 06:51:11 - INFO - __main__ - Step 260 Global step 260 Train loss 5.27 on epoch=18
05/16/2022 06:51:12 - INFO - __main__ - Step 270 Global step 270 Train loss 5.16 on epoch=19
05/16/2022 06:51:13 - INFO - __main__ - Step 280 Global step 280 Train loss 5.10 on epoch=19
05/16/2022 06:51:15 - INFO - __main__ - Step 290 Global step 290 Train loss 5.18 on epoch=20
05/16/2022 06:51:16 - INFO - __main__ - Step 300 Global step 300 Train loss 5.00 on epoch=21
05/16/2022 06:51:28 - INFO - __main__ - Global step 300 Train loss 5.14 Classification-F1 0.005291005291005292 on epoch=21
05/16/2022 06:51:28 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005291005291005292 on epoch=21, global_step=300
05/16/2022 06:51:29 - INFO - __main__ - Step 310 Global step 310 Train loss 4.90 on epoch=22
05/16/2022 06:51:30 - INFO - __main__ - Step 320 Global step 320 Train loss 5.02 on epoch=22
05/16/2022 06:51:32 - INFO - __main__ - Step 330 Global step 330 Train loss 4.99 on epoch=23
05/16/2022 06:51:33 - INFO - __main__ - Step 340 Global step 340 Train loss 4.79 on epoch=24
05/16/2022 06:51:34 - INFO - __main__ - Step 350 Global step 350 Train loss 4.77 on epoch=24
05/16/2022 06:51:37 - INFO - __main__ - Global step 350 Train loss 4.90 Classification-F1 0.007352941176470587 on epoch=24
05/16/2022 06:51:37 - INFO - __main__ - Saving model with best Classification-F1: 0.005291005291005292 -> 0.007352941176470587 on epoch=24, global_step=350
05/16/2022 06:51:39 - INFO - __main__ - Step 360 Global step 360 Train loss 4.75 on epoch=25
05/16/2022 06:51:40 - INFO - __main__ - Step 370 Global step 370 Train loss 4.66 on epoch=26
05/16/2022 06:51:41 - INFO - __main__ - Step 380 Global step 380 Train loss 4.57 on epoch=27
05/16/2022 06:51:42 - INFO - __main__ - Step 390 Global step 390 Train loss 4.59 on epoch=27
05/16/2022 06:51:44 - INFO - __main__ - Step 400 Global step 400 Train loss 4.61 on epoch=28
05/16/2022 06:51:46 - INFO - __main__ - Global step 400 Train loss 4.63 Classification-F1 0.009523809523809523 on epoch=28
05/16/2022 06:51:46 - INFO - __main__ - Saving model with best Classification-F1: 0.007352941176470587 -> 0.009523809523809523 on epoch=28, global_step=400
05/16/2022 06:51:47 - INFO - __main__ - Step 410 Global step 410 Train loss 4.55 on epoch=29
05/16/2022 06:51:49 - INFO - __main__ - Step 420 Global step 420 Train loss 4.47 on epoch=29
05/16/2022 06:51:50 - INFO - __main__ - Step 430 Global step 430 Train loss 4.59 on epoch=30
05/16/2022 06:51:51 - INFO - __main__ - Step 440 Global step 440 Train loss 4.25 on epoch=31
05/16/2022 06:51:53 - INFO - __main__ - Step 450 Global step 450 Train loss 4.37 on epoch=32
05/16/2022 06:51:55 - INFO - __main__ - Global step 450 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=32
05/16/2022 06:51:56 - INFO - __main__ - Step 460 Global step 460 Train loss 4.23 on epoch=32
05/16/2022 06:51:57 - INFO - __main__ - Step 470 Global step 470 Train loss 4.23 on epoch=33
05/16/2022 06:51:59 - INFO - __main__ - Step 480 Global step 480 Train loss 4.08 on epoch=34
05/16/2022 06:52:00 - INFO - __main__ - Step 490 Global step 490 Train loss 4.17 on epoch=34
05/16/2022 06:52:01 - INFO - __main__ - Step 500 Global step 500 Train loss 4.00 on epoch=35
05/16/2022 06:52:03 - INFO - __main__ - Global step 500 Train loss 4.14 Classification-F1 0.009523809523809523 on epoch=35
05/16/2022 06:52:04 - INFO - __main__ - Step 510 Global step 510 Train loss 3.94 on epoch=36
05/16/2022 06:52:06 - INFO - __main__ - Step 520 Global step 520 Train loss 3.94 on epoch=37
05/16/2022 06:52:07 - INFO - __main__ - Step 530 Global step 530 Train loss 4.06 on epoch=37
05/16/2022 06:52:09 - INFO - __main__ - Step 540 Global step 540 Train loss 3.75 on epoch=38
05/16/2022 06:52:10 - INFO - __main__ - Step 550 Global step 550 Train loss 3.82 on epoch=39
05/16/2022 06:52:12 - INFO - __main__ - Global step 550 Train loss 3.90 Classification-F1 0.010025062656641603 on epoch=39
05/16/2022 06:52:12 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.010025062656641603 on epoch=39, global_step=550
05/16/2022 06:52:13 - INFO - __main__ - Step 560 Global step 560 Train loss 3.70 on epoch=39
05/16/2022 06:52:15 - INFO - __main__ - Step 570 Global step 570 Train loss 3.94 on epoch=40
05/16/2022 06:52:16 - INFO - __main__ - Step 580 Global step 580 Train loss 3.47 on epoch=41
05/16/2022 06:52:17 - INFO - __main__ - Step 590 Global step 590 Train loss 3.58 on epoch=42
05/16/2022 06:52:18 - INFO - __main__ - Step 600 Global step 600 Train loss 3.65 on epoch=42
05/16/2022 06:52:20 - INFO - __main__ - Global step 600 Train loss 3.67 Classification-F1 0.018887743776755988 on epoch=42
05/16/2022 06:52:20 - INFO - __main__ - Saving model with best Classification-F1: 0.010025062656641603 -> 0.018887743776755988 on epoch=42, global_step=600
05/16/2022 06:52:22 - INFO - __main__ - Step 610 Global step 610 Train loss 3.51 on epoch=43
05/16/2022 06:52:23 - INFO - __main__ - Step 620 Global step 620 Train loss 3.68 on epoch=44
05/16/2022 06:52:24 - INFO - __main__ - Step 630 Global step 630 Train loss 3.39 on epoch=44
05/16/2022 06:52:26 - INFO - __main__ - Step 640 Global step 640 Train loss 3.54 on epoch=45
05/16/2022 06:52:27 - INFO - __main__ - Step 650 Global step 650 Train loss 3.44 on epoch=46
05/16/2022 06:52:29 - INFO - __main__ - Global step 650 Train loss 3.51 Classification-F1 0.027956989247311832 on epoch=46
05/16/2022 06:52:29 - INFO - __main__ - Saving model with best Classification-F1: 0.018887743776755988 -> 0.027956989247311832 on epoch=46, global_step=650
05/16/2022 06:52:30 - INFO - __main__ - Step 660 Global step 660 Train loss 3.52 on epoch=47
05/16/2022 06:52:32 - INFO - __main__ - Step 670 Global step 670 Train loss 3.47 on epoch=47
05/16/2022 06:52:33 - INFO - __main__ - Step 680 Global step 680 Train loss 3.36 on epoch=48
05/16/2022 06:52:34 - INFO - __main__ - Step 690 Global step 690 Train loss 3.31 on epoch=49
05/16/2022 06:52:36 - INFO - __main__ - Step 700 Global step 700 Train loss 3.34 on epoch=49
05/16/2022 06:52:38 - INFO - __main__ - Global step 700 Train loss 3.40 Classification-F1 0.020337301587301588 on epoch=49
05/16/2022 06:52:39 - INFO - __main__ - Step 710 Global step 710 Train loss 3.23 on epoch=50
05/16/2022 06:52:40 - INFO - __main__ - Step 720 Global step 720 Train loss 3.26 on epoch=51
05/16/2022 06:52:42 - INFO - __main__ - Step 730 Global step 730 Train loss 3.12 on epoch=52
05/16/2022 06:52:43 - INFO - __main__ - Step 740 Global step 740 Train loss 3.50 on epoch=52
05/16/2022 06:52:44 - INFO - __main__ - Step 750 Global step 750 Train loss 3.07 on epoch=53
05/16/2022 06:52:46 - INFO - __main__ - Global step 750 Train loss 3.24 Classification-F1 0.022669796663604715 on epoch=53
05/16/2022 06:52:47 - INFO - __main__ - Step 760 Global step 760 Train loss 3.37 on epoch=54
05/16/2022 06:52:49 - INFO - __main__ - Step 770 Global step 770 Train loss 3.16 on epoch=54
05/16/2022 06:52:50 - INFO - __main__ - Step 780 Global step 780 Train loss 3.28 on epoch=55
05/16/2022 06:52:51 - INFO - __main__ - Step 790 Global step 790 Train loss 3.12 on epoch=56
05/16/2022 06:52:53 - INFO - __main__ - Step 800 Global step 800 Train loss 3.16 on epoch=57
05/16/2022 06:52:55 - INFO - __main__ - Global step 800 Train loss 3.22 Classification-F1 0.029869573672629705 on epoch=57
05/16/2022 06:52:55 - INFO - __main__ - Saving model with best Classification-F1: 0.027956989247311832 -> 0.029869573672629705 on epoch=57, global_step=800
05/16/2022 06:52:56 - INFO - __main__ - Step 810 Global step 810 Train loss 3.18 on epoch=57
05/16/2022 06:52:57 - INFO - __main__ - Step 820 Global step 820 Train loss 3.01 on epoch=58
05/16/2022 06:52:59 - INFO - __main__ - Step 830 Global step 830 Train loss 3.15 on epoch=59
05/16/2022 06:53:00 - INFO - __main__ - Step 840 Global step 840 Train loss 3.00 on epoch=59
05/16/2022 06:53:01 - INFO - __main__ - Step 850 Global step 850 Train loss 3.08 on epoch=60
05/16/2022 06:53:03 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.047294246554072286 on epoch=60
05/16/2022 06:53:03 - INFO - __main__ - Saving model with best Classification-F1: 0.029869573672629705 -> 0.047294246554072286 on epoch=60, global_step=850
05/16/2022 06:53:04 - INFO - __main__ - Step 860 Global step 860 Train loss 3.01 on epoch=61
05/16/2022 06:53:06 - INFO - __main__ - Step 870 Global step 870 Train loss 3.03 on epoch=62
05/16/2022 06:53:07 - INFO - __main__ - Step 880 Global step 880 Train loss 3.11 on epoch=62
05/16/2022 06:53:08 - INFO - __main__ - Step 890 Global step 890 Train loss 3.14 on epoch=63
05/16/2022 06:53:10 - INFO - __main__ - Step 900 Global step 900 Train loss 3.04 on epoch=64
05/16/2022 06:53:11 - INFO - __main__ - Global step 900 Train loss 3.06 Classification-F1 0.04571456323477886 on epoch=64
05/16/2022 06:53:13 - INFO - __main__ - Step 910 Global step 910 Train loss 2.88 on epoch=64
05/16/2022 06:53:14 - INFO - __main__ - Step 920 Global step 920 Train loss 3.04 on epoch=65
05/16/2022 06:53:15 - INFO - __main__ - Step 930 Global step 930 Train loss 2.85 on epoch=66
05/16/2022 06:53:17 - INFO - __main__ - Step 940 Global step 940 Train loss 2.81 on epoch=67
05/16/2022 06:53:18 - INFO - __main__ - Step 950 Global step 950 Train loss 2.92 on epoch=67
05/16/2022 06:53:20 - INFO - __main__ - Global step 950 Train loss 2.90 Classification-F1 0.05722270245125096 on epoch=67
05/16/2022 06:53:20 - INFO - __main__ - Saving model with best Classification-F1: 0.047294246554072286 -> 0.05722270245125096 on epoch=67, global_step=950
05/16/2022 06:53:21 - INFO - __main__ - Step 960 Global step 960 Train loss 2.72 on epoch=68
05/16/2022 06:53:22 - INFO - __main__ - Step 970 Global step 970 Train loss 2.97 on epoch=69
05/16/2022 06:53:24 - INFO - __main__ - Step 980 Global step 980 Train loss 2.64 on epoch=69
05/16/2022 06:53:25 - INFO - __main__ - Step 990 Global step 990 Train loss 2.87 on epoch=70
05/16/2022 06:53:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.70 on epoch=71
05/16/2022 06:53:28 - INFO - __main__ - Global step 1000 Train loss 2.78 Classification-F1 0.06777881146408957 on epoch=71
05/16/2022 06:53:28 - INFO - __main__ - Saving model with best Classification-F1: 0.05722270245125096 -> 0.06777881146408957 on epoch=71, global_step=1000
05/16/2022 06:53:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.78 on epoch=72
05/16/2022 06:53:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.69 on epoch=72
05/16/2022 06:53:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.78 on epoch=73
05/16/2022 06:53:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.80 on epoch=74
05/16/2022 06:53:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.45 on epoch=74
05/16/2022 06:53:36 - INFO - __main__ - Global step 1050 Train loss 2.70 Classification-F1 0.06117963720703446 on epoch=74
05/16/2022 06:53:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.94 on epoch=75
05/16/2022 06:53:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.56 on epoch=76
05/16/2022 06:53:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.67 on epoch=77
05/16/2022 06:53:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.87 on epoch=77
05/16/2022 06:53:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.65 on epoch=78
05/16/2022 06:53:45 - INFO - __main__ - Global step 1100 Train loss 2.74 Classification-F1 0.055416841223292844 on epoch=78
05/16/2022 06:53:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.84 on epoch=79
05/16/2022 06:53:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.63 on epoch=79
05/16/2022 06:53:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.78 on epoch=80
05/16/2022 06:53:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.62 on epoch=81
05/16/2022 06:53:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.79 on epoch=82
05/16/2022 06:53:53 - INFO - __main__ - Global step 1150 Train loss 2.73 Classification-F1 0.036294517807122846 on epoch=82
05/16/2022 06:53:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.72 on epoch=82
05/16/2022 06:53:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.59 on epoch=83
05/16/2022 06:53:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.70 on epoch=84
05/16/2022 06:53:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.60 on epoch=84
05/16/2022 06:53:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.67 on epoch=85
05/16/2022 06:54:01 - INFO - __main__ - Global step 1200 Train loss 2.66 Classification-F1 0.037661792905081495 on epoch=85
05/16/2022 06:54:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.42 on epoch=86
05/16/2022 06:54:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.53 on epoch=87
05/16/2022 06:54:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.60 on epoch=87
05/16/2022 06:54:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.52 on epoch=88
05/16/2022 06:54:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.63 on epoch=89
05/16/2022 06:54:10 - INFO - __main__ - Global step 1250 Train loss 2.54 Classification-F1 0.04100095279575462 on epoch=89
05/16/2022 06:54:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.55 on epoch=89
05/16/2022 06:54:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.38 on epoch=90
05/16/2022 06:54:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.45 on epoch=91
05/16/2022 06:54:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.38 on epoch=92
05/16/2022 06:54:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.71 on epoch=92
05/16/2022 06:54:19 - INFO - __main__ - Global step 1300 Train loss 2.49 Classification-F1 0.036953856502728685 on epoch=92
05/16/2022 06:54:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.65 on epoch=93
05/16/2022 06:54:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.64 on epoch=94
05/16/2022 06:54:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.38 on epoch=94
05/16/2022 06:54:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.45 on epoch=95
05/16/2022 06:54:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.44 on epoch=96
05/16/2022 06:54:27 - INFO - __main__ - Global step 1350 Train loss 2.51 Classification-F1 0.03842364532019704 on epoch=96
05/16/2022 06:54:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.54 on epoch=97
05/16/2022 06:54:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.56 on epoch=97
05/16/2022 06:54:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.65 on epoch=98
05/16/2022 06:54:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.56 on epoch=99
05/16/2022 06:54:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.39 on epoch=99
05/16/2022 06:54:36 - INFO - __main__ - Global step 1400 Train loss 2.54 Classification-F1 0.06573914150640493 on epoch=99
05/16/2022 06:54:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.54 on epoch=100
05/16/2022 06:54:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.48 on epoch=101
05/16/2022 06:54:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.42 on epoch=102
05/16/2022 06:54:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.46 on epoch=102
05/16/2022 06:54:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.49 on epoch=103
05/16/2022 06:54:44 - INFO - __main__ - Global step 1450 Train loss 2.48 Classification-F1 0.05746239783334139 on epoch=103
05/16/2022 06:54:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.52 on epoch=104
05/16/2022 06:54:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.30 on epoch=104
05/16/2022 06:54:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.43 on epoch=105
05/16/2022 06:54:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.34 on epoch=106
05/16/2022 06:54:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.35 on epoch=107
05/16/2022 06:54:53 - INFO - __main__ - Global step 1500 Train loss 2.39 Classification-F1 0.08818117246125592 on epoch=107
05/16/2022 06:54:53 - INFO - __main__ - Saving model with best Classification-F1: 0.06777881146408957 -> 0.08818117246125592 on epoch=107, global_step=1500
05/16/2022 06:54:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.24 on epoch=107
05/16/2022 06:54:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.29 on epoch=108
05/16/2022 06:54:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.40 on epoch=109
05/16/2022 06:54:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.20 on epoch=109
05/16/2022 06:55:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.37 on epoch=110
05/16/2022 06:55:02 - INFO - __main__ - Global step 1550 Train loss 2.30 Classification-F1 0.04395149364093463 on epoch=110
05/16/2022 06:55:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.31 on epoch=111
05/16/2022 06:55:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.30 on epoch=112
05/16/2022 06:55:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.40 on epoch=112
05/16/2022 06:55:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.30 on epoch=113
05/16/2022 06:55:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.19 on epoch=114
05/16/2022 06:55:11 - INFO - __main__ - Global step 1600 Train loss 2.30 Classification-F1 0.009563658099222952 on epoch=114
05/16/2022 06:55:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.38 on epoch=114
05/16/2022 06:55:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.20 on epoch=115
05/16/2022 06:55:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.31 on epoch=116
05/16/2022 06:55:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.20 on epoch=117
05/16/2022 06:55:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.10 on epoch=117
05/16/2022 06:55:19 - INFO - __main__ - Global step 1650 Train loss 2.24 Classification-F1 0.08235901140766592 on epoch=117
05/16/2022 06:55:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.10 on epoch=118
05/16/2022 06:55:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.16 on epoch=119
05/16/2022 06:55:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.09 on epoch=119
05/16/2022 06:55:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.21 on epoch=120
05/16/2022 06:55:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.13 on epoch=121
05/16/2022 06:55:28 - INFO - __main__ - Global step 1700 Train loss 2.14 Classification-F1 0.0758425587398516 on epoch=121
05/16/2022 06:55:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.04 on epoch=122
05/16/2022 06:55:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.14 on epoch=122
05/16/2022 06:55:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.10 on epoch=123
05/16/2022 06:55:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.25 on epoch=124
05/16/2022 06:55:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.05 on epoch=124
05/16/2022 06:55:39 - INFO - __main__ - Global step 1750 Train loss 2.12 Classification-F1 0.09199202343127434 on epoch=124
05/16/2022 06:55:39 - INFO - __main__ - Saving model with best Classification-F1: 0.08818117246125592 -> 0.09199202343127434 on epoch=124, global_step=1750
05/16/2022 06:55:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.01 on epoch=125
05/16/2022 06:55:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.96 on epoch=126
05/16/2022 06:55:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.10 on epoch=127
05/16/2022 06:55:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.10 on epoch=127
05/16/2022 06:55:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.00 on epoch=128
05/16/2022 06:55:48 - INFO - __main__ - Global step 1800 Train loss 2.03 Classification-F1 0.04276155217331688 on epoch=128
05/16/2022 06:55:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.10 on epoch=129
05/16/2022 06:55:51 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.01 on epoch=129
05/16/2022 06:55:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.16 on epoch=130
05/16/2022 06:55:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.91 on epoch=131
05/16/2022 06:55:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.09 on epoch=132
05/16/2022 06:55:57 - INFO - __main__ - Global step 1850 Train loss 2.05 Classification-F1 0.0772836966954614 on epoch=132
05/16/2022 06:55:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.00 on epoch=132
05/16/2022 06:55:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.97 on epoch=133
05/16/2022 06:56:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.93 on epoch=134
05/16/2022 06:56:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.03 on epoch=134
05/16/2022 06:56:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.08 on epoch=135
05/16/2022 06:56:06 - INFO - __main__ - Global step 1900 Train loss 2.00 Classification-F1 0.1358986016399465 on epoch=135
05/16/2022 06:56:06 - INFO - __main__ - Saving model with best Classification-F1: 0.09199202343127434 -> 0.1358986016399465 on epoch=135, global_step=1900
05/16/2022 06:56:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.02 on epoch=136
05/16/2022 06:56:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.95 on epoch=137
05/16/2022 06:56:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.95 on epoch=137
05/16/2022 06:56:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.01 on epoch=138
05/16/2022 06:56:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.00 on epoch=139
05/16/2022 06:56:14 - INFO - __main__ - Global step 1950 Train loss 1.99 Classification-F1 0.13749163350492255 on epoch=139
05/16/2022 06:56:14 - INFO - __main__ - Saving model with best Classification-F1: 0.1358986016399465 -> 0.13749163350492255 on epoch=139, global_step=1950
05/16/2022 06:56:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.90 on epoch=139
05/16/2022 06:56:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.98 on epoch=140
05/16/2022 06:56:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.00 on epoch=141
05/16/2022 06:56:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.99 on epoch=142
05/16/2022 06:56:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.97 on epoch=142
05/16/2022 06:56:23 - INFO - __main__ - Global step 2000 Train loss 1.97 Classification-F1 0.07585988360132458 on epoch=142
05/16/2022 06:56:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.94 on epoch=143
05/16/2022 06:56:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.82 on epoch=144
05/16/2022 06:56:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.91 on epoch=144
05/16/2022 06:56:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.83 on epoch=145
05/16/2022 06:56:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.84 on epoch=146
05/16/2022 06:56:32 - INFO - __main__ - Global step 2050 Train loss 1.87 Classification-F1 0.06060839360939062 on epoch=146
05/16/2022 06:56:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.76 on epoch=147
05/16/2022 06:56:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.92 on epoch=147
05/16/2022 06:56:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.84 on epoch=148
05/16/2022 06:56:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.83 on epoch=149
05/16/2022 06:56:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.92 on epoch=149
05/16/2022 06:56:41 - INFO - __main__ - Global step 2100 Train loss 1.85 Classification-F1 0.1467214031078043 on epoch=149
05/16/2022 06:56:41 - INFO - __main__ - Saving model with best Classification-F1: 0.13749163350492255 -> 0.1467214031078043 on epoch=149, global_step=2100
05/16/2022 06:56:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.81 on epoch=150
05/16/2022 06:56:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.79 on epoch=151
05/16/2022 06:56:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.70 on epoch=152
05/16/2022 06:56:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.83 on epoch=152
05/16/2022 06:56:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.75 on epoch=153
05/16/2022 06:56:50 - INFO - __main__ - Global step 2150 Train loss 1.78 Classification-F1 0.18730469328380228 on epoch=153
05/16/2022 06:56:50 - INFO - __main__ - Saving model with best Classification-F1: 0.1467214031078043 -> 0.18730469328380228 on epoch=153, global_step=2150
05/16/2022 06:56:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.84 on epoch=154
05/16/2022 06:56:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.70 on epoch=154
05/16/2022 06:56:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.90 on epoch=155
05/16/2022 06:56:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.82 on epoch=156
05/16/2022 06:56:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.78 on epoch=157
05/16/2022 06:56:59 - INFO - __main__ - Global step 2200 Train loss 1.81 Classification-F1 0.2156707433079219 on epoch=157
05/16/2022 06:56:59 - INFO - __main__ - Saving model with best Classification-F1: 0.18730469328380228 -> 0.2156707433079219 on epoch=157, global_step=2200
05/16/2022 06:57:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.76 on epoch=157
05/16/2022 06:57:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.71 on epoch=158
05/16/2022 06:57:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.81 on epoch=159
05/16/2022 06:57:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.72 on epoch=159
05/16/2022 06:57:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.89 on epoch=160
05/16/2022 06:57:08 - INFO - __main__ - Global step 2250 Train loss 1.78 Classification-F1 0.23713464290581981 on epoch=160
05/16/2022 06:57:08 - INFO - __main__ - Saving model with best Classification-F1: 0.2156707433079219 -> 0.23713464290581981 on epoch=160, global_step=2250
05/16/2022 06:57:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.75 on epoch=161
05/16/2022 06:57:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.69 on epoch=162
05/16/2022 06:57:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.57 on epoch=162
05/16/2022 06:57:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.83 on epoch=163
05/16/2022 06:57:14 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.71 on epoch=164
05/16/2022 06:57:17 - INFO - __main__ - Global step 2300 Train loss 1.71 Classification-F1 0.24540822757444516 on epoch=164
05/16/2022 06:57:17 - INFO - __main__ - Saving model with best Classification-F1: 0.23713464290581981 -> 0.24540822757444516 on epoch=164, global_step=2300
05/16/2022 06:57:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.65 on epoch=164
05/16/2022 06:57:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.67 on epoch=165
05/16/2022 06:57:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.66 on epoch=166
05/16/2022 06:57:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.71 on epoch=167
05/16/2022 06:57:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.69 on epoch=167
05/16/2022 06:57:26 - INFO - __main__ - Global step 2350 Train loss 1.67 Classification-F1 0.20157112512872594 on epoch=167
05/16/2022 06:57:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.63 on epoch=168
05/16/2022 06:57:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.71 on epoch=169
05/16/2022 06:57:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.69 on epoch=169
05/16/2022 06:57:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.72 on epoch=170
05/16/2022 06:57:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.78 on epoch=171
05/16/2022 06:57:35 - INFO - __main__ - Global step 2400 Train loss 1.70 Classification-F1 0.2670019335999158 on epoch=171
05/16/2022 06:57:35 - INFO - __main__ - Saving model with best Classification-F1: 0.24540822757444516 -> 0.2670019335999158 on epoch=171, global_step=2400
05/16/2022 06:57:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.66 on epoch=172
05/16/2022 06:57:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.57 on epoch=172
05/16/2022 06:57:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.69 on epoch=173
05/16/2022 06:57:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.49 on epoch=174
05/16/2022 06:57:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.63 on epoch=174
05/16/2022 06:57:44 - INFO - __main__ - Global step 2450 Train loss 1.61 Classification-F1 0.20804672747358435 on epoch=174
05/16/2022 06:57:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.55 on epoch=175
05/16/2022 06:57:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.55 on epoch=176
05/16/2022 06:57:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.59 on epoch=177
05/16/2022 06:57:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.58 on epoch=177
05/16/2022 06:57:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.59 on epoch=178
05/16/2022 06:57:53 - INFO - __main__ - Global step 2500 Train loss 1.57 Classification-F1 0.30142174721450904 on epoch=178
05/16/2022 06:57:53 - INFO - __main__ - Saving model with best Classification-F1: 0.2670019335999158 -> 0.30142174721450904 on epoch=178, global_step=2500
05/16/2022 06:57:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.64 on epoch=179
05/16/2022 06:57:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.51 on epoch=179
05/16/2022 06:57:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.56 on epoch=180
05/16/2022 06:57:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.71 on epoch=181
05/16/2022 06:58:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.61 on epoch=182
05/16/2022 06:58:02 - INFO - __main__ - Global step 2550 Train loss 1.60 Classification-F1 0.183016358755275 on epoch=182
05/16/2022 06:58:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.69 on epoch=182
05/16/2022 06:58:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.63 on epoch=183
05/16/2022 06:58:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.55 on epoch=184
05/16/2022 06:58:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.63 on epoch=184
05/16/2022 06:58:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.58 on epoch=185
05/16/2022 06:58:11 - INFO - __main__ - Global step 2600 Train loss 1.61 Classification-F1 0.18653851870108443 on epoch=185
05/16/2022 06:58:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.59 on epoch=186
05/16/2022 06:58:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.58 on epoch=187
05/16/2022 06:58:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.54 on epoch=187
05/16/2022 06:58:16 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.64 on epoch=188
05/16/2022 06:58:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.39 on epoch=189
05/16/2022 06:58:20 - INFO - __main__ - Global step 2650 Train loss 1.55 Classification-F1 0.28334397491229685 on epoch=189
05/16/2022 06:58:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.54 on epoch=189
05/16/2022 06:58:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.65 on epoch=190
05/16/2022 06:58:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.49 on epoch=191
05/16/2022 06:58:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.59 on epoch=192
05/16/2022 06:58:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.44 on epoch=192
05/16/2022 06:58:30 - INFO - __main__ - Global step 2700 Train loss 1.54 Classification-F1 0.25181042980421653 on epoch=192
05/16/2022 06:58:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.55 on epoch=193
05/16/2022 06:58:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.49 on epoch=194
05/16/2022 06:58:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.54 on epoch=194
05/16/2022 06:58:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.43 on epoch=195
05/16/2022 06:58:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.59 on epoch=196
05/16/2022 06:58:39 - INFO - __main__ - Global step 2750 Train loss 1.52 Classification-F1 0.24703446691735118 on epoch=196
05/16/2022 06:58:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.35 on epoch=197
05/16/2022 06:58:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.37 on epoch=197
05/16/2022 06:58:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.52 on epoch=198
05/16/2022 06:58:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.47 on epoch=199
05/16/2022 06:58:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.53 on epoch=199
05/16/2022 06:58:48 - INFO - __main__ - Global step 2800 Train loss 1.45 Classification-F1 0.2813225879160257 on epoch=199
05/16/2022 06:58:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.48 on epoch=200
05/16/2022 06:58:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.47 on epoch=201
05/16/2022 06:58:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.42 on epoch=202
05/16/2022 06:58:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.47 on epoch=202
05/16/2022 06:58:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.51 on epoch=203
05/16/2022 06:58:59 - INFO - __main__ - Global step 2850 Train loss 1.47 Classification-F1 0.3463450938633764 on epoch=203
05/16/2022 06:58:59 - INFO - __main__ - Saving model with best Classification-F1: 0.30142174721450904 -> 0.3463450938633764 on epoch=203, global_step=2850
05/16/2022 06:59:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.53 on epoch=204
05/16/2022 06:59:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.41 on epoch=204
05/16/2022 06:59:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.39 on epoch=205
05/16/2022 06:59:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.48 on epoch=206
05/16/2022 06:59:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.36 on epoch=207
05/16/2022 06:59:09 - INFO - __main__ - Global step 2900 Train loss 1.43 Classification-F1 0.37502529902529896 on epoch=207
05/16/2022 06:59:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3463450938633764 -> 0.37502529902529896 on epoch=207, global_step=2900
05/16/2022 06:59:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.33 on epoch=207
05/16/2022 06:59:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.33 on epoch=208
05/16/2022 06:59:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.38 on epoch=209
05/16/2022 06:59:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.32 on epoch=209
05/16/2022 06:59:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.36 on epoch=210
05/16/2022 06:59:19 - INFO - __main__ - Global step 2950 Train loss 1.34 Classification-F1 0.3392752506331597 on epoch=210
05/16/2022 06:59:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.40 on epoch=211
05/16/2022 06:59:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.38 on epoch=212
05/16/2022 06:59:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.29 on epoch=212
05/16/2022 06:59:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.44 on epoch=213
05/16/2022 06:59:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.39 on epoch=214
05/16/2022 06:59:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 06:59:27 - INFO - __main__ - Printing 3 examples
05/16/2022 06:59:27 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 06:59:27 - INFO - __main__ - ['Animal']
05/16/2022 06:59:27 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 06:59:27 - INFO - __main__ - ['Animal']
05/16/2022 06:59:27 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 06:59:27 - INFO - __main__ - ['Animal']
05/16/2022 06:59:27 - INFO - __main__ - Tokenizing Input ...
05/16/2022 06:59:27 - INFO - __main__ - Tokenizing Output ...
05/16/2022 06:59:27 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 06:59:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 06:59:27 - INFO - __main__ - Printing 3 examples
05/16/2022 06:59:27 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 06:59:27 - INFO - __main__ - ['Animal']
05/16/2022 06:59:27 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 06:59:27 - INFO - __main__ - ['Animal']
05/16/2022 06:59:27 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 06:59:27 - INFO - __main__ - ['Animal']
05/16/2022 06:59:27 - INFO - __main__ - Tokenizing Input ...
05/16/2022 06:59:28 - INFO - __main__ - Tokenizing Output ...
05/16/2022 06:59:28 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 06:59:29 - INFO - __main__ - Global step 3000 Train loss 1.38 Classification-F1 0.3952647899862215 on epoch=214
05/16/2022 06:59:29 - INFO - __main__ - Saving model with best Classification-F1: 0.37502529902529896 -> 0.3952647899862215 on epoch=214, global_step=3000
05/16/2022 06:59:29 - INFO - __main__ - save last model!
05/16/2022 06:59:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 06:59:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 06:59:29 - INFO - __main__ - Printing 3 examples
05/16/2022 06:59:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 06:59:29 - INFO - __main__ - ['Animal']
05/16/2022 06:59:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 06:59:29 - INFO - __main__ - ['Animal']
05/16/2022 06:59:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 06:59:29 - INFO - __main__ - ['Village']
05/16/2022 06:59:29 - INFO - __main__ - Tokenizing Input ...
05/16/2022 06:59:31 - INFO - __main__ - Tokenizing Output ...
05/16/2022 06:59:34 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 06:59:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 06:59:34 - INFO - __main__ - Starting training!
05/16/2022 06:59:35 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 07:00:33 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/16/2022 07:00:33 - INFO - __main__ - Classification-F1 on test data: 0.3192
05/16/2022 07:00:33 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.3952647899862215, test_performance=0.3192215004932146
05/16/2022 07:00:33 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/16/2022 07:00:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:00:34 - INFO - __main__ - Printing 3 examples
05/16/2022 07:00:34 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 07:00:34 - INFO - __main__ - ['Animal']
05/16/2022 07:00:34 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 07:00:34 - INFO - __main__ - ['Animal']
05/16/2022 07:00:34 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 07:00:34 - INFO - __main__ - ['Animal']
05/16/2022 07:00:34 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:00:34 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:00:34 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:00:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:00:34 - INFO - __main__ - Printing 3 examples
05/16/2022 07:00:34 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 07:00:34 - INFO - __main__ - ['Animal']
05/16/2022 07:00:34 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 07:00:34 - INFO - __main__ - ['Animal']
05/16/2022 07:00:34 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 07:00:34 - INFO - __main__ - ['Animal']
05/16/2022 07:00:34 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:00:34 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:00:35 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:00:40 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:00:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:00:40 - INFO - __main__ - Starting training!
05/16/2022 07:00:42 - INFO - __main__ - Step 10 Global step 10 Train loss 7.37 on epoch=0
05/16/2022 07:00:43 - INFO - __main__ - Step 20 Global step 20 Train loss 7.34 on epoch=1
05/16/2022 07:00:44 - INFO - __main__ - Step 30 Global step 30 Train loss 7.08 on epoch=2
05/16/2022 07:00:46 - INFO - __main__ - Step 40 Global step 40 Train loss 6.93 on epoch=2
05/16/2022 07:00:47 - INFO - __main__ - Step 50 Global step 50 Train loss 6.92 on epoch=3
05/16/2022 07:01:11 - INFO - __main__ - Global step 50 Train loss 7.13 Classification-F1 0.0 on epoch=3
05/16/2022 07:01:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 07:01:12 - INFO - __main__ - Step 60 Global step 60 Train loss 6.60 on epoch=4
05/16/2022 07:01:14 - INFO - __main__ - Step 70 Global step 70 Train loss 6.65 on epoch=4
05/16/2022 07:01:15 - INFO - __main__ - Step 80 Global step 80 Train loss 6.44 on epoch=5
05/16/2022 07:01:16 - INFO - __main__ - Step 90 Global step 90 Train loss 6.25 on epoch=6
05/16/2022 07:01:18 - INFO - __main__ - Step 100 Global step 100 Train loss 6.28 on epoch=7
05/16/2022 07:01:58 - INFO - __main__ - Global step 100 Train loss 6.45 Classification-F1 0.0 on epoch=7
05/16/2022 07:01:59 - INFO - __main__ - Step 110 Global step 110 Train loss 6.31 on epoch=7
05/16/2022 07:02:01 - INFO - __main__ - Step 120 Global step 120 Train loss 6.17 on epoch=8
05/16/2022 07:02:02 - INFO - __main__ - Step 130 Global step 130 Train loss 6.08 on epoch=9
05/16/2022 07:02:03 - INFO - __main__ - Step 140 Global step 140 Train loss 6.16 on epoch=9
05/16/2022 07:02:04 - INFO - __main__ - Step 150 Global step 150 Train loss 5.99 on epoch=10
05/16/2022 07:03:14 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/16/2022 07:03:15 - INFO - __main__ - Step 160 Global step 160 Train loss 5.96 on epoch=11
05/16/2022 07:03:17 - INFO - __main__ - Step 170 Global step 170 Train loss 5.91 on epoch=12
05/16/2022 07:03:18 - INFO - __main__ - Step 180 Global step 180 Train loss 5.74 on epoch=12
05/16/2022 07:03:19 - INFO - __main__ - Step 190 Global step 190 Train loss 5.77 on epoch=13
05/16/2022 07:03:21 - INFO - __main__ - Step 200 Global step 200 Train loss 5.56 on epoch=14
05/16/2022 07:03:56 - INFO - __main__ - Global step 200 Train loss 5.79 Classification-F1 0.0 on epoch=14
05/16/2022 07:03:57 - INFO - __main__ - Step 210 Global step 210 Train loss 5.68 on epoch=14
05/16/2022 07:03:58 - INFO - __main__ - Step 220 Global step 220 Train loss 5.52 on epoch=15
05/16/2022 07:03:59 - INFO - __main__ - Step 230 Global step 230 Train loss 5.51 on epoch=16
05/16/2022 07:04:01 - INFO - __main__ - Step 240 Global step 240 Train loss 5.38 on epoch=17
05/16/2022 07:04:02 - INFO - __main__ - Step 250 Global step 250 Train loss 5.38 on epoch=17
05/16/2022 07:04:29 - INFO - __main__ - Global step 250 Train loss 5.49 Classification-F1 0.0 on epoch=17
05/16/2022 07:04:31 - INFO - __main__ - Step 260 Global step 260 Train loss 5.32 on epoch=18
05/16/2022 07:04:32 - INFO - __main__ - Step 270 Global step 270 Train loss 5.40 on epoch=19
05/16/2022 07:04:33 - INFO - __main__ - Step 280 Global step 280 Train loss 5.25 on epoch=19
05/16/2022 07:04:34 - INFO - __main__ - Step 290 Global step 290 Train loss 5.20 on epoch=20
05/16/2022 07:04:36 - INFO - __main__ - Step 300 Global step 300 Train loss 5.13 on epoch=21
05/16/2022 07:04:56 - INFO - __main__ - Global step 300 Train loss 5.26 Classification-F1 0.0 on epoch=21
05/16/2022 07:04:57 - INFO - __main__ - Step 310 Global step 310 Train loss 4.99 on epoch=22
05/16/2022 07:04:58 - INFO - __main__ - Step 320 Global step 320 Train loss 5.00 on epoch=22
05/16/2022 07:05:00 - INFO - __main__ - Step 330 Global step 330 Train loss 4.91 on epoch=23
05/16/2022 07:05:01 - INFO - __main__ - Step 340 Global step 340 Train loss 4.90 on epoch=24
05/16/2022 07:05:02 - INFO - __main__ - Step 350 Global step 350 Train loss 5.00 on epoch=24
05/16/2022 07:05:05 - INFO - __main__ - Global step 350 Train loss 4.96 Classification-F1 0.01215277777777778 on epoch=24
05/16/2022 07:05:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.01215277777777778 on epoch=24, global_step=350
05/16/2022 07:05:06 - INFO - __main__ - Step 360 Global step 360 Train loss 4.91 on epoch=25
05/16/2022 07:05:07 - INFO - __main__ - Step 370 Global step 370 Train loss 4.87 on epoch=26
05/16/2022 07:05:09 - INFO - __main__ - Step 380 Global step 380 Train loss 4.76 on epoch=27
05/16/2022 07:05:10 - INFO - __main__ - Step 390 Global step 390 Train loss 4.75 on epoch=27
05/16/2022 07:05:11 - INFO - __main__ - Step 400 Global step 400 Train loss 4.82 on epoch=28
05/16/2022 07:05:14 - INFO - __main__ - Global step 400 Train loss 4.82 Classification-F1 0.007729468599033816 on epoch=28
05/16/2022 07:05:15 - INFO - __main__ - Step 410 Global step 410 Train loss 4.68 on epoch=29
05/16/2022 07:05:16 - INFO - __main__ - Step 420 Global step 420 Train loss 4.65 on epoch=29
05/16/2022 07:05:18 - INFO - __main__ - Step 430 Global step 430 Train loss 4.70 on epoch=30
05/16/2022 07:05:19 - INFO - __main__ - Step 440 Global step 440 Train loss 4.45 on epoch=31
05/16/2022 07:05:20 - INFO - __main__ - Step 450 Global step 450 Train loss 4.47 on epoch=32
05/16/2022 07:05:23 - INFO - __main__ - Global step 450 Train loss 4.59 Classification-F1 0.00892608089260809 on epoch=32
05/16/2022 07:05:24 - INFO - __main__ - Step 460 Global step 460 Train loss 4.58 on epoch=32
05/16/2022 07:05:25 - INFO - __main__ - Step 470 Global step 470 Train loss 4.52 on epoch=33
05/16/2022 07:05:26 - INFO - __main__ - Step 480 Global step 480 Train loss 4.45 on epoch=34
05/16/2022 07:05:28 - INFO - __main__ - Step 490 Global step 490 Train loss 4.33 on epoch=34
05/16/2022 07:05:29 - INFO - __main__ - Step 500 Global step 500 Train loss 4.47 on epoch=35
05/16/2022 07:05:31 - INFO - __main__ - Global step 500 Train loss 4.47 Classification-F1 0.009523809523809523 on epoch=35
05/16/2022 07:05:32 - INFO - __main__ - Step 510 Global step 510 Train loss 4.27 on epoch=36
05/16/2022 07:05:34 - INFO - __main__ - Step 520 Global step 520 Train loss 4.44 on epoch=37
05/16/2022 07:05:35 - INFO - __main__ - Step 530 Global step 530 Train loss 4.27 on epoch=37
05/16/2022 07:05:36 - INFO - __main__ - Step 540 Global step 540 Train loss 4.14 on epoch=38
05/16/2022 07:05:38 - INFO - __main__ - Step 550 Global step 550 Train loss 4.22 on epoch=39
05/16/2022 07:05:39 - INFO - __main__ - Global step 550 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=39
05/16/2022 07:05:41 - INFO - __main__ - Step 560 Global step 560 Train loss 4.17 on epoch=39
05/16/2022 07:05:42 - INFO - __main__ - Step 570 Global step 570 Train loss 4.06 on epoch=40
05/16/2022 07:05:43 - INFO - __main__ - Step 580 Global step 580 Train loss 3.98 on epoch=41
05/16/2022 07:05:44 - INFO - __main__ - Step 590 Global step 590 Train loss 3.99 on epoch=42
05/16/2022 07:05:46 - INFO - __main__ - Step 600 Global step 600 Train loss 4.09 on epoch=42
05/16/2022 07:05:48 - INFO - __main__ - Global step 600 Train loss 4.06 Classification-F1 0.009523809523809523 on epoch=42
05/16/2022 07:05:49 - INFO - __main__ - Step 610 Global step 610 Train loss 3.90 on epoch=43
05/16/2022 07:05:50 - INFO - __main__ - Step 620 Global step 620 Train loss 3.77 on epoch=44
05/16/2022 07:05:52 - INFO - __main__ - Step 630 Global step 630 Train loss 3.80 on epoch=44
05/16/2022 07:05:53 - INFO - __main__ - Step 640 Global step 640 Train loss 3.90 on epoch=45
05/16/2022 07:05:54 - INFO - __main__ - Step 650 Global step 650 Train loss 3.71 on epoch=46
05/16/2022 07:05:56 - INFO - __main__ - Global step 650 Train loss 3.81 Classification-F1 0.009523809523809523 on epoch=46
05/16/2022 07:05:57 - INFO - __main__ - Step 660 Global step 660 Train loss 3.63 on epoch=47
05/16/2022 07:05:59 - INFO - __main__ - Step 670 Global step 670 Train loss 3.64 on epoch=47
05/16/2022 07:06:00 - INFO - __main__ - Step 680 Global step 680 Train loss 3.67 on epoch=48
05/16/2022 07:06:01 - INFO - __main__ - Step 690 Global step 690 Train loss 3.72 on epoch=49
05/16/2022 07:06:02 - INFO - __main__ - Step 700 Global step 700 Train loss 3.55 on epoch=49
05/16/2022 07:06:04 - INFO - __main__ - Global step 700 Train loss 3.64 Classification-F1 0.024408468244084682 on epoch=49
05/16/2022 07:06:04 - INFO - __main__ - Saving model with best Classification-F1: 0.01215277777777778 -> 0.024408468244084682 on epoch=49, global_step=700
05/16/2022 07:06:05 - INFO - __main__ - Step 710 Global step 710 Train loss 3.68 on epoch=50
05/16/2022 07:06:07 - INFO - __main__ - Step 720 Global step 720 Train loss 3.56 on epoch=51
05/16/2022 07:06:08 - INFO - __main__ - Step 730 Global step 730 Train loss 3.49 on epoch=52
05/16/2022 07:06:09 - INFO - __main__ - Step 740 Global step 740 Train loss 3.46 on epoch=52
05/16/2022 07:06:11 - INFO - __main__ - Step 750 Global step 750 Train loss 3.36 on epoch=53
05/16/2022 07:06:13 - INFO - __main__ - Global step 750 Train loss 3.51 Classification-F1 0.025960798985678952 on epoch=53
05/16/2022 07:06:13 - INFO - __main__ - Saving model with best Classification-F1: 0.024408468244084682 -> 0.025960798985678952 on epoch=53, global_step=750
05/16/2022 07:06:14 - INFO - __main__ - Step 760 Global step 760 Train loss 3.37 on epoch=54
05/16/2022 07:06:15 - INFO - __main__ - Step 770 Global step 770 Train loss 3.45 on epoch=54
05/16/2022 07:06:16 - INFO - __main__ - Step 780 Global step 780 Train loss 3.50 on epoch=55
05/16/2022 07:06:18 - INFO - __main__ - Step 790 Global step 790 Train loss 3.35 on epoch=56
05/16/2022 07:06:19 - INFO - __main__ - Step 800 Global step 800 Train loss 3.30 on epoch=57
05/16/2022 07:06:21 - INFO - __main__ - Global step 800 Train loss 3.39 Classification-F1 0.028797581150674156 on epoch=57
05/16/2022 07:06:21 - INFO - __main__ - Saving model with best Classification-F1: 0.025960798985678952 -> 0.028797581150674156 on epoch=57, global_step=800
05/16/2022 07:06:22 - INFO - __main__ - Step 810 Global step 810 Train loss 3.43 on epoch=57
05/16/2022 07:06:23 - INFO - __main__ - Step 820 Global step 820 Train loss 3.23 on epoch=58
05/16/2022 07:06:25 - INFO - __main__ - Step 830 Global step 830 Train loss 3.39 on epoch=59
05/16/2022 07:06:26 - INFO - __main__ - Step 840 Global step 840 Train loss 3.34 on epoch=59
05/16/2022 07:06:28 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/16/2022 07:06:29 - INFO - __main__ - Global step 850 Train loss 3.32 Classification-F1 0.024344964816523453 on epoch=60
05/16/2022 07:06:31 - INFO - __main__ - Step 860 Global step 860 Train loss 3.15 on epoch=61
05/16/2022 07:06:32 - INFO - __main__ - Step 870 Global step 870 Train loss 3.24 on epoch=62
05/16/2022 07:06:33 - INFO - __main__ - Step 880 Global step 880 Train loss 3.32 on epoch=62
05/16/2022 07:06:35 - INFO - __main__ - Step 890 Global step 890 Train loss 3.16 on epoch=63
05/16/2022 07:06:36 - INFO - __main__ - Step 900 Global step 900 Train loss 3.35 on epoch=64
05/16/2022 07:06:38 - INFO - __main__ - Global step 900 Train loss 3.24 Classification-F1 0.009726443768996961 on epoch=64
05/16/2022 07:06:39 - INFO - __main__ - Step 910 Global step 910 Train loss 3.23 on epoch=64
05/16/2022 07:06:41 - INFO - __main__ - Step 920 Global step 920 Train loss 3.27 on epoch=65
05/16/2022 07:06:42 - INFO - __main__ - Step 930 Global step 930 Train loss 3.23 on epoch=66
05/16/2022 07:06:43 - INFO - __main__ - Step 940 Global step 940 Train loss 3.08 on epoch=67
05/16/2022 07:06:45 - INFO - __main__ - Step 950 Global step 950 Train loss 3.14 on epoch=67
05/16/2022 07:06:47 - INFO - __main__ - Global step 950 Train loss 3.19 Classification-F1 0.03988684582743989 on epoch=67
05/16/2022 07:06:47 - INFO - __main__ - Saving model with best Classification-F1: 0.028797581150674156 -> 0.03988684582743989 on epoch=67, global_step=950
05/16/2022 07:06:48 - INFO - __main__ - Step 960 Global step 960 Train loss 3.18 on epoch=68
05/16/2022 07:06:49 - INFO - __main__ - Step 970 Global step 970 Train loss 3.37 on epoch=69
05/16/2022 07:06:50 - INFO - __main__ - Step 980 Global step 980 Train loss 3.08 on epoch=69
05/16/2022 07:06:52 - INFO - __main__ - Step 990 Global step 990 Train loss 3.08 on epoch=70
05/16/2022 07:06:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.00 on epoch=71
05/16/2022 07:06:55 - INFO - __main__ - Global step 1000 Train loss 3.14 Classification-F1 0.009563658099222952 on epoch=71
05/16/2022 07:06:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.06 on epoch=72
05/16/2022 07:06:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.16 on epoch=72
05/16/2022 07:06:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.99 on epoch=73
05/16/2022 07:07:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.22 on epoch=74
05/16/2022 07:07:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.98 on epoch=74
05/16/2022 07:07:03 - INFO - __main__ - Global step 1050 Train loss 3.08 Classification-F1 0.03559501611080259 on epoch=74
05/16/2022 07:07:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.13 on epoch=75
05/16/2022 07:07:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.96 on epoch=76
05/16/2022 07:07:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.00 on epoch=77
05/16/2022 07:07:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.10 on epoch=77
05/16/2022 07:07:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.97 on epoch=78
05/16/2022 07:07:12 - INFO - __main__ - Global step 1100 Train loss 3.03 Classification-F1 0.024012158054711248 on epoch=78
05/16/2022 07:07:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.11 on epoch=79
05/16/2022 07:07:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.89 on epoch=79
05/16/2022 07:07:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.02 on epoch=80
05/16/2022 07:07:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.90 on epoch=81
05/16/2022 07:07:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.99 on epoch=82
05/16/2022 07:07:20 - INFO - __main__ - Global step 1150 Train loss 2.98 Classification-F1 0.03926738212577846 on epoch=82
05/16/2022 07:07:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.03 on epoch=82
05/16/2022 07:07:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.01 on epoch=83
05/16/2022 07:07:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.92 on epoch=84
05/16/2022 07:07:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.85 on epoch=84
05/16/2022 07:07:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.08 on epoch=85
05/16/2022 07:07:29 - INFO - __main__ - Global step 1200 Train loss 2.98 Classification-F1 0.05591070884161431 on epoch=85
05/16/2022 07:07:29 - INFO - __main__ - Saving model with best Classification-F1: 0.03988684582743989 -> 0.05591070884161431 on epoch=85, global_step=1200
05/16/2022 07:07:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.97 on epoch=86
05/16/2022 07:07:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.03 on epoch=87
05/16/2022 07:07:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.75 on epoch=87
05/16/2022 07:07:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.93 on epoch=88
05/16/2022 07:07:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.01 on epoch=89
05/16/2022 07:07:38 - INFO - __main__ - Global step 1250 Train loss 2.94 Classification-F1 0.012645502645502646 on epoch=89
05/16/2022 07:07:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.85 on epoch=89
05/16/2022 07:07:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.98 on epoch=90
05/16/2022 07:07:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.78 on epoch=91
05/16/2022 07:07:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.84 on epoch=92
05/16/2022 07:07:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.96 on epoch=92
05/16/2022 07:07:46 - INFO - __main__ - Global step 1300 Train loss 2.88 Classification-F1 0.02854864433811802 on epoch=92
05/16/2022 07:07:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.72 on epoch=93
05/16/2022 07:07:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.87 on epoch=94
05/16/2022 07:07:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.80 on epoch=94
05/16/2022 07:07:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.93 on epoch=95
05/16/2022 07:07:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.77 on epoch=96
05/16/2022 07:07:54 - INFO - __main__ - Global step 1350 Train loss 2.82 Classification-F1 0.0503467087318019 on epoch=96
05/16/2022 07:07:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.79 on epoch=97
05/16/2022 07:07:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.81 on epoch=97
05/16/2022 07:07:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.51 on epoch=98
05/16/2022 07:07:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.80 on epoch=99
05/16/2022 07:08:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.60 on epoch=99
05/16/2022 07:08:03 - INFO - __main__ - Global step 1400 Train loss 2.70 Classification-F1 0.05899651301474002 on epoch=99
05/16/2022 07:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.05591070884161431 -> 0.05899651301474002 on epoch=99, global_step=1400
05/16/2022 07:08:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.79 on epoch=100
05/16/2022 07:08:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.70 on epoch=101
05/16/2022 07:08:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.68 on epoch=102
05/16/2022 07:08:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.83 on epoch=102
05/16/2022 07:08:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.62 on epoch=103
05/16/2022 07:08:11 - INFO - __main__ - Global step 1450 Train loss 2.72 Classification-F1 0.06075578556781564 on epoch=103
05/16/2022 07:08:11 - INFO - __main__ - Saving model with best Classification-F1: 0.05899651301474002 -> 0.06075578556781564 on epoch=103, global_step=1450
05/16/2022 07:08:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.81 on epoch=104
05/16/2022 07:08:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.69 on epoch=104
05/16/2022 07:08:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.90 on epoch=105
05/16/2022 07:08:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.69 on epoch=106
05/16/2022 07:08:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.59 on epoch=107
05/16/2022 07:08:20 - INFO - __main__ - Global step 1500 Train loss 2.74 Classification-F1 0.06039103118789736 on epoch=107
05/16/2022 07:08:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.90 on epoch=107
05/16/2022 07:08:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.76 on epoch=108
05/16/2022 07:08:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.89 on epoch=109
05/16/2022 07:08:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.84 on epoch=109
05/16/2022 07:08:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.79 on epoch=110
05/16/2022 07:08:28 - INFO - __main__ - Global step 1550 Train loss 2.84 Classification-F1 0.045434429746823636 on epoch=110
05/16/2022 07:08:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.68 on epoch=111
05/16/2022 07:08:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.71 on epoch=112
05/16/2022 07:08:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.86 on epoch=112
05/16/2022 07:08:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.85 on epoch=113
05/16/2022 07:08:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.91 on epoch=114
05/16/2022 07:08:37 - INFO - __main__ - Global step 1600 Train loss 2.80 Classification-F1 0.034115464367565206 on epoch=114
05/16/2022 07:08:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.70 on epoch=114
05/16/2022 07:08:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.90 on epoch=115
05/16/2022 07:08:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.69 on epoch=116
05/16/2022 07:08:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.66 on epoch=117
05/16/2022 07:08:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.70 on epoch=117
05/16/2022 07:08:46 - INFO - __main__ - Global step 1650 Train loss 2.73 Classification-F1 0.05213988549536723 on epoch=117
05/16/2022 07:08:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.69 on epoch=118
05/16/2022 07:08:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.78 on epoch=119
05/16/2022 07:08:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.75 on epoch=119
05/16/2022 07:08:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.76 on epoch=120
05/16/2022 07:08:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.61 on epoch=121
05/16/2022 07:08:54 - INFO - __main__ - Global step 1700 Train loss 2.72 Classification-F1 0.04008525852585259 on epoch=121
05/16/2022 07:08:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.55 on epoch=122
05/16/2022 07:08:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.66 on epoch=122
05/16/2022 07:08:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.66 on epoch=123
05/16/2022 07:08:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.77 on epoch=124
05/16/2022 07:09:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.62 on epoch=124
05/16/2022 07:09:02 - INFO - __main__ - Global step 1750 Train loss 2.65 Classification-F1 0.03936439147706753 on epoch=124
05/16/2022 07:09:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.57 on epoch=125
05/16/2022 07:09:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.57 on epoch=126
05/16/2022 07:09:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.69 on epoch=127
05/16/2022 07:09:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.64 on epoch=127
05/16/2022 07:09:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.63 on epoch=128
05/16/2022 07:09:12 - INFO - __main__ - Global step 1800 Train loss 2.62 Classification-F1 0.04099675712578939 on epoch=128
05/16/2022 07:09:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.63 on epoch=129
05/16/2022 07:09:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.57 on epoch=129
05/16/2022 07:09:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.79 on epoch=130
05/16/2022 07:09:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.49 on epoch=131
05/16/2022 07:09:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.43 on epoch=132
05/16/2022 07:09:23 - INFO - __main__ - Global step 1850 Train loss 2.58 Classification-F1 0.06432599621454112 on epoch=132
05/16/2022 07:09:23 - INFO - __main__ - Saving model with best Classification-F1: 0.06075578556781564 -> 0.06432599621454112 on epoch=132, global_step=1850
05/16/2022 07:09:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.60 on epoch=132
05/16/2022 07:09:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.45 on epoch=133
05/16/2022 07:09:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.55 on epoch=134
05/16/2022 07:09:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.42 on epoch=134
05/16/2022 07:09:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.60 on epoch=135
05/16/2022 07:09:33 - INFO - __main__ - Global step 1900 Train loss 2.52 Classification-F1 0.06273607345035916 on epoch=135
05/16/2022 07:09:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.51 on epoch=136
05/16/2022 07:09:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.50 on epoch=137
05/16/2022 07:09:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.52 on epoch=137
05/16/2022 07:09:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.44 on epoch=138
05/16/2022 07:09:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.53 on epoch=139
05/16/2022 07:09:43 - INFO - __main__ - Global step 1950 Train loss 2.50 Classification-F1 0.07868985103654184 on epoch=139
05/16/2022 07:09:43 - INFO - __main__ - Saving model with best Classification-F1: 0.06432599621454112 -> 0.07868985103654184 on epoch=139, global_step=1950
05/16/2022 07:09:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.38 on epoch=139
05/16/2022 07:09:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.52 on epoch=140
05/16/2022 07:09:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.42 on epoch=141
05/16/2022 07:09:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.49 on epoch=142
05/16/2022 07:09:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.58 on epoch=142
05/16/2022 07:09:51 - INFO - __main__ - Global step 2000 Train loss 2.48 Classification-F1 0.03327922077922078 on epoch=142
05/16/2022 07:09:53 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.38 on epoch=143
05/16/2022 07:09:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.49 on epoch=144
05/16/2022 07:09:55 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.38 on epoch=144
05/16/2022 07:09:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.39 on epoch=145
05/16/2022 07:09:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.35 on epoch=146
05/16/2022 07:10:00 - INFO - __main__ - Global step 2050 Train loss 2.40 Classification-F1 0.03295707407856941 on epoch=146
05/16/2022 07:10:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.41 on epoch=147
05/16/2022 07:10:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.26 on epoch=147
05/16/2022 07:10:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.22 on epoch=148
05/16/2022 07:10:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.52 on epoch=149
05/16/2022 07:10:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.41 on epoch=149
05/16/2022 07:10:08 - INFO - __main__ - Global step 2100 Train loss 2.37 Classification-F1 0.03571428571428571 on epoch=149
05/16/2022 07:10:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.41 on epoch=150
05/16/2022 07:10:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.30 on epoch=151
05/16/2022 07:10:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.30 on epoch=152
05/16/2022 07:10:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.51 on epoch=152
05/16/2022 07:10:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.42 on epoch=153
05/16/2022 07:10:18 - INFO - __main__ - Global step 2150 Train loss 2.39 Classification-F1 0.056014266171584906 on epoch=153
05/16/2022 07:10:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.42 on epoch=154
05/16/2022 07:10:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.32 on epoch=154
05/16/2022 07:10:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.45 on epoch=155
05/16/2022 07:10:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.13 on epoch=156
05/16/2022 07:10:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.20 on epoch=157
05/16/2022 07:10:26 - INFO - __main__ - Global step 2200 Train loss 2.30 Classification-F1 0.021790041747276247 on epoch=157
05/16/2022 07:10:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.33 on epoch=157
05/16/2022 07:10:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.31 on epoch=158
05/16/2022 07:10:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.29 on epoch=159
05/16/2022 07:10:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.39 on epoch=159
05/16/2022 07:10:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.28 on epoch=160
05/16/2022 07:10:35 - INFO - __main__ - Global step 2250 Train loss 2.32 Classification-F1 0.08729050081403379 on epoch=160
05/16/2022 07:10:35 - INFO - __main__ - Saving model with best Classification-F1: 0.07868985103654184 -> 0.08729050081403379 on epoch=160, global_step=2250
05/16/2022 07:10:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.26 on epoch=161
05/16/2022 07:10:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.31 on epoch=162
05/16/2022 07:10:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.33 on epoch=162
05/16/2022 07:10:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.30 on epoch=163
05/16/2022 07:10:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.23 on epoch=164
05/16/2022 07:10:43 - INFO - __main__ - Global step 2300 Train loss 2.28 Classification-F1 0.027275864232385972 on epoch=164
05/16/2022 07:10:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.14 on epoch=164
05/16/2022 07:10:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.33 on epoch=165
05/16/2022 07:10:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.25 on epoch=166
05/16/2022 07:10:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.26 on epoch=167
05/16/2022 07:10:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.31 on epoch=167
05/16/2022 07:10:53 - INFO - __main__ - Global step 2350 Train loss 2.26 Classification-F1 0.025114283467927625 on epoch=167
05/16/2022 07:10:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.08 on epoch=168
05/16/2022 07:10:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.14 on epoch=169
05/16/2022 07:10:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.07 on epoch=169
05/16/2022 07:10:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.19 on epoch=170
05/16/2022 07:10:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.17 on epoch=171
05/16/2022 07:11:01 - INFO - __main__ - Global step 2400 Train loss 2.13 Classification-F1 0.11498029508593534 on epoch=171
05/16/2022 07:11:01 - INFO - __main__ - Saving model with best Classification-F1: 0.08729050081403379 -> 0.11498029508593534 on epoch=171, global_step=2400
05/16/2022 07:11:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.19 on epoch=172
05/16/2022 07:11:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.16 on epoch=172
05/16/2022 07:11:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.07 on epoch=173
05/16/2022 07:11:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.11 on epoch=174
05/16/2022 07:11:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.02 on epoch=174
05/16/2022 07:11:11 - INFO - __main__ - Global step 2450 Train loss 2.11 Classification-F1 0.05520253017161674 on epoch=174
05/16/2022 07:11:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.25 on epoch=175
05/16/2022 07:11:13 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.03 on epoch=176
05/16/2022 07:11:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.01 on epoch=177
05/16/2022 07:11:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.14 on epoch=177
05/16/2022 07:11:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.10 on epoch=178
05/16/2022 07:11:19 - INFO - __main__ - Global step 2500 Train loss 2.10 Classification-F1 0.07884223923683185 on epoch=178
05/16/2022 07:11:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.04 on epoch=179
05/16/2022 07:11:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.06 on epoch=179
05/16/2022 07:11:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.07 on epoch=180
05/16/2022 07:11:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.98 on epoch=181
05/16/2022 07:11:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.18 on epoch=182
05/16/2022 07:11:28 - INFO - __main__ - Global step 2550 Train loss 2.07 Classification-F1 0.07902730984867065 on epoch=182
05/16/2022 07:11:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.02 on epoch=182
05/16/2022 07:11:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.01 on epoch=183
05/16/2022 07:11:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.03 on epoch=184
05/16/2022 07:11:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.06 on epoch=184
05/16/2022 07:11:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.09 on epoch=185
05/16/2022 07:11:37 - INFO - __main__ - Global step 2600 Train loss 2.04 Classification-F1 0.038448712818460726 on epoch=185
05/16/2022 07:11:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.95 on epoch=186
05/16/2022 07:11:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.94 on epoch=187
05/16/2022 07:11:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.92 on epoch=187
05/16/2022 07:11:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.97 on epoch=188
05/16/2022 07:11:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.04 on epoch=189
05/16/2022 07:11:46 - INFO - __main__ - Global step 2650 Train loss 1.97 Classification-F1 0.03574597540879706 on epoch=189
05/16/2022 07:11:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.90 on epoch=189
05/16/2022 07:11:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.04 on epoch=190
05/16/2022 07:11:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.03 on epoch=191
05/16/2022 07:11:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.03 on epoch=192
05/16/2022 07:11:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.87 on epoch=192
05/16/2022 07:11:54 - INFO - __main__ - Global step 2700 Train loss 1.97 Classification-F1 0.04159743338627463 on epoch=192
05/16/2022 07:11:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.89 on epoch=193
05/16/2022 07:11:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.01 on epoch=194
05/16/2022 07:11:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.88 on epoch=194
05/16/2022 07:12:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.01 on epoch=195
05/16/2022 07:12:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.69 on epoch=196
05/16/2022 07:12:03 - INFO - __main__ - Global step 2750 Train loss 1.90 Classification-F1 0.07502613948805328 on epoch=196
05/16/2022 07:12:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.94 on epoch=197
05/16/2022 07:12:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.92 on epoch=197
05/16/2022 07:12:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.96 on epoch=198
05/16/2022 07:12:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.68 on epoch=199
05/16/2022 07:12:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.71 on epoch=199
05/16/2022 07:12:12 - INFO - __main__ - Global step 2800 Train loss 1.84 Classification-F1 0.04879460556152286 on epoch=199
05/16/2022 07:12:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.92 on epoch=200
05/16/2022 07:12:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.89 on epoch=201
05/16/2022 07:12:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.75 on epoch=202
05/16/2022 07:12:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.68 on epoch=202
05/16/2022 07:12:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.98 on epoch=203
05/16/2022 07:12:21 - INFO - __main__ - Global step 2850 Train loss 1.84 Classification-F1 0.07830965417019801 on epoch=203
05/16/2022 07:12:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.71 on epoch=204
05/16/2022 07:12:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.70 on epoch=204
05/16/2022 07:12:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.68 on epoch=205
05/16/2022 07:12:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.88 on epoch=206
05/16/2022 07:12:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.85 on epoch=207
05/16/2022 07:12:29 - INFO - __main__ - Global step 2900 Train loss 1.77 Classification-F1 0.08540829098120564 on epoch=207
05/16/2022 07:12:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.75 on epoch=207
05/16/2022 07:12:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.66 on epoch=208
05/16/2022 07:12:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.77 on epoch=209
05/16/2022 07:12:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.83 on epoch=209
05/16/2022 07:12:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.83 on epoch=210
05/16/2022 07:12:38 - INFO - __main__ - Global step 2950 Train loss 1.77 Classification-F1 0.05729429231733379 on epoch=210
05/16/2022 07:12:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.82 on epoch=211
05/16/2022 07:12:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.73 on epoch=212
05/16/2022 07:12:42 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.65 on epoch=212
05/16/2022 07:12:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.65 on epoch=213
05/16/2022 07:12:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.71 on epoch=214
05/16/2022 07:12:46 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:12:46 - INFO - __main__ - Printing 3 examples
05/16/2022 07:12:46 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 07:12:46 - INFO - __main__ - ['Animal']
05/16/2022 07:12:46 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 07:12:46 - INFO - __main__ - ['Animal']
05/16/2022 07:12:46 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 07:12:46 - INFO - __main__ - ['Animal']
05/16/2022 07:12:46 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:12:46 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:12:46 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:12:46 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:12:46 - INFO - __main__ - Printing 3 examples
05/16/2022 07:12:46 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 07:12:46 - INFO - __main__ - ['Animal']
05/16/2022 07:12:46 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 07:12:46 - INFO - __main__ - ['Animal']
05/16/2022 07:12:46 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 07:12:46 - INFO - __main__ - ['Animal']
05/16/2022 07:12:46 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:12:46 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:12:46 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:12:47 - INFO - __main__ - Global step 3000 Train loss 1.71 Classification-F1 0.10399315101612874 on epoch=214
05/16/2022 07:12:47 - INFO - __main__ - save last model!
05/16/2022 07:12:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 07:12:47 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 07:12:47 - INFO - __main__ - Printing 3 examples
05/16/2022 07:12:47 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 07:12:47 - INFO - __main__ - ['Animal']
05/16/2022 07:12:47 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 07:12:47 - INFO - __main__ - ['Animal']
05/16/2022 07:12:47 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 07:12:47 - INFO - __main__ - ['Village']
05/16/2022 07:12:47 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:12:49 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:12:52 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:12:52 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 07:12:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:12:52 - INFO - __main__ - Starting training!
05/16/2022 07:13:37 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/16/2022 07:13:37 - INFO - __main__ - Classification-F1 on test data: 0.0803
05/16/2022 07:13:37 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.11498029508593534, test_performance=0.08025207598044115
05/16/2022 07:13:37 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/16/2022 07:13:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:13:38 - INFO - __main__ - Printing 3 examples
05/16/2022 07:13:38 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 07:13:38 - INFO - __main__ - ['Animal']
05/16/2022 07:13:38 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 07:13:38 - INFO - __main__ - ['Animal']
05/16/2022 07:13:38 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 07:13:38 - INFO - __main__ - ['Animal']
05/16/2022 07:13:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:13:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:13:38 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:13:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:13:38 - INFO - __main__ - Printing 3 examples
05/16/2022 07:13:38 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 07:13:38 - INFO - __main__ - ['Animal']
05/16/2022 07:13:38 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 07:13:38 - INFO - __main__ - ['Animal']
05/16/2022 07:13:38 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 07:13:38 - INFO - __main__ - ['Animal']
05/16/2022 07:13:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:13:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:13:39 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:13:44 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:13:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:13:44 - INFO - __main__ - Starting training!
05/16/2022 07:13:46 - INFO - __main__ - Step 10 Global step 10 Train loss 7.34 on epoch=0
05/16/2022 07:13:48 - INFO - __main__ - Step 20 Global step 20 Train loss 7.31 on epoch=1
05/16/2022 07:13:49 - INFO - __main__ - Step 30 Global step 30 Train loss 7.12 on epoch=2
05/16/2022 07:13:51 - INFO - __main__ - Step 40 Global step 40 Train loss 7.04 on epoch=2
05/16/2022 07:13:52 - INFO - __main__ - Step 50 Global step 50 Train loss 7.03 on epoch=3
05/16/2022 07:14:14 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/16/2022 07:14:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 07:14:15 - INFO - __main__ - Step 60 Global step 60 Train loss 6.63 on epoch=4
05/16/2022 07:14:17 - INFO - __main__ - Step 70 Global step 70 Train loss 6.95 on epoch=4
05/16/2022 07:14:18 - INFO - __main__ - Step 80 Global step 80 Train loss 6.78 on epoch=5
05/16/2022 07:14:19 - INFO - __main__ - Step 90 Global step 90 Train loss 6.72 on epoch=6
05/16/2022 07:14:21 - INFO - __main__ - Step 100 Global step 100 Train loss 6.57 on epoch=7
05/16/2022 07:15:18 - INFO - __main__ - Global step 100 Train loss 6.73 Classification-F1 0.0 on epoch=7
05/16/2022 07:15:19 - INFO - __main__ - Step 110 Global step 110 Train loss 6.53 on epoch=7
05/16/2022 07:15:20 - INFO - __main__ - Step 120 Global step 120 Train loss 6.48 on epoch=8
05/16/2022 07:15:22 - INFO - __main__ - Step 130 Global step 130 Train loss 6.39 on epoch=9
05/16/2022 07:15:23 - INFO - __main__ - Step 140 Global step 140 Train loss 6.45 on epoch=9
05/16/2022 07:15:25 - INFO - __main__ - Step 150 Global step 150 Train loss 6.37 on epoch=10
05/16/2022 07:16:01 - INFO - __main__ - Global step 150 Train loss 6.45 Classification-F1 0.0 on epoch=10
05/16/2022 07:16:02 - INFO - __main__ - Step 160 Global step 160 Train loss 6.39 on epoch=11
05/16/2022 07:16:04 - INFO - __main__ - Step 170 Global step 170 Train loss 6.15 on epoch=12
05/16/2022 07:16:05 - INFO - __main__ - Step 180 Global step 180 Train loss 6.09 on epoch=12
05/16/2022 07:16:06 - INFO - __main__ - Step 190 Global step 190 Train loss 6.24 on epoch=13
05/16/2022 07:16:08 - INFO - __main__ - Step 200 Global step 200 Train loss 6.02 on epoch=14
05/16/2022 07:16:40 - INFO - __main__ - Global step 200 Train loss 6.18 Classification-F1 0.0 on epoch=14
05/16/2022 07:16:42 - INFO - __main__ - Step 210 Global step 210 Train loss 6.26 on epoch=14
05/16/2022 07:16:43 - INFO - __main__ - Step 220 Global step 220 Train loss 6.20 on epoch=15
05/16/2022 07:16:44 - INFO - __main__ - Step 230 Global step 230 Train loss 6.08 on epoch=16
05/16/2022 07:16:46 - INFO - __main__ - Step 240 Global step 240 Train loss 5.89 on epoch=17
05/16/2022 07:16:47 - INFO - __main__ - Step 250 Global step 250 Train loss 5.94 on epoch=17
05/16/2022 07:17:43 - INFO - __main__ - Global step 250 Train loss 6.07 Classification-F1 0.0 on epoch=17
05/16/2022 07:17:45 - INFO - __main__ - Step 260 Global step 260 Train loss 5.95 on epoch=18
05/16/2022 07:17:46 - INFO - __main__ - Step 270 Global step 270 Train loss 5.73 on epoch=19
05/16/2022 07:17:48 - INFO - __main__ - Step 280 Global step 280 Train loss 5.78 on epoch=19
05/16/2022 07:17:49 - INFO - __main__ - Step 290 Global step 290 Train loss 5.74 on epoch=20
05/16/2022 07:17:51 - INFO - __main__ - Step 300 Global step 300 Train loss 5.59 on epoch=21
05/16/2022 07:18:26 - INFO - __main__ - Global step 300 Train loss 5.76 Classification-F1 0.0 on epoch=21
05/16/2022 07:18:27 - INFO - __main__ - Step 310 Global step 310 Train loss 5.58 on epoch=22
05/16/2022 07:18:28 - INFO - __main__ - Step 320 Global step 320 Train loss 5.66 on epoch=22
05/16/2022 07:18:29 - INFO - __main__ - Step 330 Global step 330 Train loss 5.60 on epoch=23
05/16/2022 07:18:31 - INFO - __main__ - Step 340 Global step 340 Train loss 5.46 on epoch=24
05/16/2022 07:18:32 - INFO - __main__ - Step 350 Global step 350 Train loss 5.70 on epoch=24
05/16/2022 07:19:11 - INFO - __main__ - Global step 350 Train loss 5.60 Classification-F1 0.0 on epoch=24
05/16/2022 07:19:12 - INFO - __main__ - Step 360 Global step 360 Train loss 5.53 on epoch=25
05/16/2022 07:19:14 - INFO - __main__ - Step 370 Global step 370 Train loss 5.51 on epoch=26
05/16/2022 07:19:15 - INFO - __main__ - Step 380 Global step 380 Train loss 5.45 on epoch=27
05/16/2022 07:19:16 - INFO - __main__ - Step 390 Global step 390 Train loss 5.47 on epoch=27
05/16/2022 07:19:18 - INFO - __main__ - Step 400 Global step 400 Train loss 5.40 on epoch=28
05/16/2022 07:19:29 - INFO - __main__ - Global step 400 Train loss 5.47 Classification-F1 0.0 on epoch=28
05/16/2022 07:19:31 - INFO - __main__ - Step 410 Global step 410 Train loss 5.40 on epoch=29
05/16/2022 07:19:32 - INFO - __main__ - Step 420 Global step 420 Train loss 5.23 on epoch=29
05/16/2022 07:19:33 - INFO - __main__ - Step 430 Global step 430 Train loss 5.28 on epoch=30
05/16/2022 07:19:35 - INFO - __main__ - Step 440 Global step 440 Train loss 5.34 on epoch=31
05/16/2022 07:19:36 - INFO - __main__ - Step 450 Global step 450 Train loss 5.18 on epoch=32
05/16/2022 07:19:49 - INFO - __main__ - Global step 450 Train loss 5.28 Classification-F1 0.0 on epoch=32
05/16/2022 07:19:50 - INFO - __main__ - Step 460 Global step 460 Train loss 5.28 on epoch=32
05/16/2022 07:19:52 - INFO - __main__ - Step 470 Global step 470 Train loss 5.14 on epoch=33
05/16/2022 07:19:53 - INFO - __main__ - Step 480 Global step 480 Train loss 5.04 on epoch=34
05/16/2022 07:19:54 - INFO - __main__ - Step 490 Global step 490 Train loss 5.14 on epoch=34
05/16/2022 07:19:55 - INFO - __main__ - Step 500 Global step 500 Train loss 5.21 on epoch=35
05/16/2022 07:20:03 - INFO - __main__ - Global step 500 Train loss 5.16 Classification-F1 0.0 on epoch=35
05/16/2022 07:20:05 - INFO - __main__ - Step 510 Global step 510 Train loss 5.03 on epoch=36
05/16/2022 07:20:06 - INFO - __main__ - Step 520 Global step 520 Train loss 4.89 on epoch=37
05/16/2022 07:20:07 - INFO - __main__ - Step 530 Global step 530 Train loss 5.06 on epoch=37
05/16/2022 07:20:09 - INFO - __main__ - Step 540 Global step 540 Train loss 4.91 on epoch=38
05/16/2022 07:20:10 - INFO - __main__ - Step 550 Global step 550 Train loss 5.00 on epoch=39
05/16/2022 07:20:13 - INFO - __main__ - Global step 550 Train loss 4.98 Classification-F1 0.004166666666666667 on epoch=39
05/16/2022 07:20:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.004166666666666667 on epoch=39, global_step=550
05/16/2022 07:20:14 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/16/2022 07:20:15 - INFO - __main__ - Step 570 Global step 570 Train loss 4.90 on epoch=40
05/16/2022 07:20:17 - INFO - __main__ - Step 580 Global step 580 Train loss 4.81 on epoch=41
05/16/2022 07:20:18 - INFO - __main__ - Step 590 Global step 590 Train loss 4.81 on epoch=42
05/16/2022 07:20:19 - INFO - __main__ - Step 600 Global step 600 Train loss 4.78 on epoch=42
05/16/2022 07:20:22 - INFO - __main__ - Global step 600 Train loss 4.88 Classification-F1 0.010912698412698416 on epoch=42
05/16/2022 07:20:22 - INFO - __main__ - Saving model with best Classification-F1: 0.004166666666666667 -> 0.010912698412698416 on epoch=42, global_step=600
05/16/2022 07:20:23 - INFO - __main__ - Step 610 Global step 610 Train loss 4.85 on epoch=43
05/16/2022 07:20:25 - INFO - __main__ - Step 620 Global step 620 Train loss 4.66 on epoch=44
05/16/2022 07:20:26 - INFO - __main__ - Step 630 Global step 630 Train loss 4.94 on epoch=44
05/16/2022 07:20:27 - INFO - __main__ - Step 640 Global step 640 Train loss 4.66 on epoch=45
05/16/2022 07:20:29 - INFO - __main__ - Step 650 Global step 650 Train loss 4.70 on epoch=46
05/16/2022 07:20:31 - INFO - __main__ - Global step 650 Train loss 4.76 Classification-F1 0.007352941176470588 on epoch=46
05/16/2022 07:20:33 - INFO - __main__ - Step 660 Global step 660 Train loss 4.61 on epoch=47
05/16/2022 07:20:34 - INFO - __main__ - Step 670 Global step 670 Train loss 4.68 on epoch=47
05/16/2022 07:20:35 - INFO - __main__ - Step 680 Global step 680 Train loss 4.60 on epoch=48
05/16/2022 07:20:37 - INFO - __main__ - Step 690 Global step 690 Train loss 4.43 on epoch=49
05/16/2022 07:20:38 - INFO - __main__ - Step 700 Global step 700 Train loss 4.56 on epoch=49
05/16/2022 07:20:40 - INFO - __main__ - Global step 700 Train loss 4.58 Classification-F1 0.00903954802259887 on epoch=49
05/16/2022 07:20:42 - INFO - __main__ - Step 710 Global step 710 Train loss 4.55 on epoch=50
05/16/2022 07:20:43 - INFO - __main__ - Step 720 Global step 720 Train loss 4.33 on epoch=51
05/16/2022 07:20:44 - INFO - __main__ - Step 730 Global step 730 Train loss 4.45 on epoch=52
05/16/2022 07:20:45 - INFO - __main__ - Step 740 Global step 740 Train loss 4.42 on epoch=52
05/16/2022 07:20:47 - INFO - __main__ - Step 750 Global step 750 Train loss 4.34 on epoch=53
05/16/2022 07:20:49 - INFO - __main__ - Global step 750 Train loss 4.42 Classification-F1 0.00892608089260809 on epoch=53
05/16/2022 07:20:51 - INFO - __main__ - Step 760 Global step 760 Train loss 4.43 on epoch=54
05/16/2022 07:20:52 - INFO - __main__ - Step 770 Global step 770 Train loss 4.29 on epoch=54
05/16/2022 07:20:54 - INFO - __main__ - Step 780 Global step 780 Train loss 4.28 on epoch=55
05/16/2022 07:20:55 - INFO - __main__ - Step 790 Global step 790 Train loss 4.22 on epoch=56
05/16/2022 07:20:56 - INFO - __main__ - Step 800 Global step 800 Train loss 4.15 on epoch=57
05/16/2022 07:20:58 - INFO - __main__ - Global step 800 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 07:21:00 - INFO - __main__ - Step 810 Global step 810 Train loss 4.24 on epoch=57
05/16/2022 07:21:01 - INFO - __main__ - Step 820 Global step 820 Train loss 4.05 on epoch=58
05/16/2022 07:21:02 - INFO - __main__ - Step 830 Global step 830 Train loss 4.15 on epoch=59
05/16/2022 07:21:04 - INFO - __main__ - Step 840 Global step 840 Train loss 4.00 on epoch=59
05/16/2022 07:21:05 - INFO - __main__ - Step 850 Global step 850 Train loss 4.05 on epoch=60
05/16/2022 07:21:07 - INFO - __main__ - Global step 850 Train loss 4.10 Classification-F1 0.009523809523809523 on epoch=60
05/16/2022 07:21:08 - INFO - __main__ - Step 860 Global step 860 Train loss 4.00 on epoch=61
05/16/2022 07:21:09 - INFO - __main__ - Step 870 Global step 870 Train loss 3.88 on epoch=62
05/16/2022 07:21:11 - INFO - __main__ - Step 880 Global step 880 Train loss 3.88 on epoch=62
05/16/2022 07:21:12 - INFO - __main__ - Step 890 Global step 890 Train loss 3.89 on epoch=63
05/16/2022 07:21:13 - INFO - __main__ - Step 900 Global step 900 Train loss 3.95 on epoch=64
05/16/2022 07:21:15 - INFO - __main__ - Global step 900 Train loss 3.92 Classification-F1 0.009523809523809523 on epoch=64
05/16/2022 07:21:16 - INFO - __main__ - Step 910 Global step 910 Train loss 3.87 on epoch=64
05/16/2022 07:21:18 - INFO - __main__ - Step 920 Global step 920 Train loss 3.96 on epoch=65
05/16/2022 07:21:19 - INFO - __main__ - Step 930 Global step 930 Train loss 3.76 on epoch=66
05/16/2022 07:21:20 - INFO - __main__ - Step 940 Global step 940 Train loss 3.61 on epoch=67
05/16/2022 07:21:22 - INFO - __main__ - Step 950 Global step 950 Train loss 3.79 on epoch=67
05/16/2022 07:21:23 - INFO - __main__ - Global step 950 Train loss 3.80 Classification-F1 0.019513819513819513 on epoch=67
05/16/2022 07:21:24 - INFO - __main__ - Saving model with best Classification-F1: 0.010912698412698416 -> 0.019513819513819513 on epoch=67, global_step=950
05/16/2022 07:21:25 - INFO - __main__ - Step 960 Global step 960 Train loss 3.62 on epoch=68
05/16/2022 07:21:26 - INFO - __main__ - Step 970 Global step 970 Train loss 3.70 on epoch=69
05/16/2022 07:21:27 - INFO - __main__ - Step 980 Global step 980 Train loss 3.75 on epoch=69
05/16/2022 07:21:29 - INFO - __main__ - Step 990 Global step 990 Train loss 3.81 on epoch=70
05/16/2022 07:21:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.55 on epoch=71
05/16/2022 07:21:32 - INFO - __main__ - Global step 1000 Train loss 3.69 Classification-F1 0.02487557352826814 on epoch=71
05/16/2022 07:21:32 - INFO - __main__ - Saving model with best Classification-F1: 0.019513819513819513 -> 0.02487557352826814 on epoch=71, global_step=1000
05/16/2022 07:21:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.43 on epoch=72
05/16/2022 07:21:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.51 on epoch=72
05/16/2022 07:21:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.50 on epoch=73
05/16/2022 07:21:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.52 on epoch=74
05/16/2022 07:21:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.49 on epoch=74
05/16/2022 07:21:40 - INFO - __main__ - Global step 1050 Train loss 3.49 Classification-F1 0.029365079365079365 on epoch=74
05/16/2022 07:21:40 - INFO - __main__ - Saving model with best Classification-F1: 0.02487557352826814 -> 0.029365079365079365 on epoch=74, global_step=1050
05/16/2022 07:21:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.42 on epoch=75
05/16/2022 07:21:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.29 on epoch=76
05/16/2022 07:21:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.29 on epoch=77
05/16/2022 07:21:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.34 on epoch=77
05/16/2022 07:21:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.25 on epoch=78
05/16/2022 07:21:50 - INFO - __main__ - Global step 1100 Train loss 3.32 Classification-F1 0.029725376664152172 on epoch=78
05/16/2022 07:21:50 - INFO - __main__ - Saving model with best Classification-F1: 0.029365079365079365 -> 0.029725376664152172 on epoch=78, global_step=1100
05/16/2022 07:21:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.46 on epoch=79
05/16/2022 07:21:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.18 on epoch=79
05/16/2022 07:21:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.31 on epoch=80
05/16/2022 07:21:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.15 on epoch=81
05/16/2022 07:21:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.27 on epoch=82
05/16/2022 07:21:59 - INFO - __main__ - Global step 1150 Train loss 3.28 Classification-F1 0.05411477411477412 on epoch=82
05/16/2022 07:21:59 - INFO - __main__ - Saving model with best Classification-F1: 0.029725376664152172 -> 0.05411477411477412 on epoch=82, global_step=1150
05/16/2022 07:22:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.26 on epoch=82
05/16/2022 07:22:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.14 on epoch=83
05/16/2022 07:22:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.37 on epoch=84
05/16/2022 07:22:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.13 on epoch=84
05/16/2022 07:22:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.33 on epoch=85
05/16/2022 07:22:08 - INFO - __main__ - Global step 1200 Train loss 3.24 Classification-F1 0.03407632123584524 on epoch=85
05/16/2022 07:22:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.07 on epoch=86
05/16/2022 07:22:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.19 on epoch=87
05/16/2022 07:22:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.24 on epoch=87
05/16/2022 07:22:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.05 on epoch=88
05/16/2022 07:22:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.16 on epoch=89
05/16/2022 07:22:16 - INFO - __main__ - Global step 1250 Train loss 3.14 Classification-F1 0.009523809523809523 on epoch=89
05/16/2022 07:22:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.20 on epoch=89
05/16/2022 07:22:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.15 on epoch=90
05/16/2022 07:22:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.00 on epoch=91
05/16/2022 07:22:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.97 on epoch=92
05/16/2022 07:22:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.12 on epoch=92
05/16/2022 07:22:24 - INFO - __main__ - Global step 1300 Train loss 3.09 Classification-F1 0.025522521901082982 on epoch=92
05/16/2022 07:22:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.03 on epoch=93
05/16/2022 07:22:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.13 on epoch=94
05/16/2022 07:22:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.12 on epoch=94
05/16/2022 07:22:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.22 on epoch=95
05/16/2022 07:22:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.02 on epoch=96
05/16/2022 07:22:33 - INFO - __main__ - Global step 1350 Train loss 3.11 Classification-F1 0.03929584434002696 on epoch=96
05/16/2022 07:22:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.05 on epoch=97
05/16/2022 07:22:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.03 on epoch=97
05/16/2022 07:22:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.07 on epoch=98
05/16/2022 07:22:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.22 on epoch=99
05/16/2022 07:22:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.84 on epoch=99
05/16/2022 07:22:41 - INFO - __main__ - Global step 1400 Train loss 3.04 Classification-F1 0.04978446674098848 on epoch=99
05/16/2022 07:22:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.99 on epoch=100
05/16/2022 07:22:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.87 on epoch=101
05/16/2022 07:22:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.98 on epoch=102
05/16/2022 07:22:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.99 on epoch=102
05/16/2022 07:22:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.99 on epoch=103
05/16/2022 07:22:49 - INFO - __main__ - Global step 1450 Train loss 2.97 Classification-F1 0.04846696398715437 on epoch=103
05/16/2022 07:22:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.18 on epoch=104
05/16/2022 07:22:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.93 on epoch=104
05/16/2022 07:22:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.98 on epoch=105
05/16/2022 07:22:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.71 on epoch=106
05/16/2022 07:22:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.93 on epoch=107
05/16/2022 07:22:58 - INFO - __main__ - Global step 1500 Train loss 2.95 Classification-F1 0.08564914993196823 on epoch=107
05/16/2022 07:22:58 - INFO - __main__ - Saving model with best Classification-F1: 0.05411477411477412 -> 0.08564914993196823 on epoch=107, global_step=1500
05/16/2022 07:22:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.94 on epoch=107
05/16/2022 07:23:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.81 on epoch=108
05/16/2022 07:23:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.93 on epoch=109
05/16/2022 07:23:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.90 on epoch=109
05/16/2022 07:23:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.96 on epoch=110
05/16/2022 07:23:06 - INFO - __main__ - Global step 1550 Train loss 2.91 Classification-F1 0.07037050172601314 on epoch=110
05/16/2022 07:23:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.95 on epoch=111
05/16/2022 07:23:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.89 on epoch=112
05/16/2022 07:23:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.89 on epoch=112
05/16/2022 07:23:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.80 on epoch=113
05/16/2022 07:23:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.80 on epoch=114
05/16/2022 07:23:15 - INFO - __main__ - Global step 1600 Train loss 2.86 Classification-F1 0.05826422254269592 on epoch=114
05/16/2022 07:23:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.66 on epoch=114
05/16/2022 07:23:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.92 on epoch=115
05/16/2022 07:23:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.76 on epoch=116
05/16/2022 07:23:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.80 on epoch=117
05/16/2022 07:23:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.87 on epoch=117
05/16/2022 07:23:24 - INFO - __main__ - Global step 1650 Train loss 2.80 Classification-F1 0.025524530857245906 on epoch=117
05/16/2022 07:23:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.73 on epoch=118
05/16/2022 07:23:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.90 on epoch=119
05/16/2022 07:23:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.73 on epoch=119
05/16/2022 07:23:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.77 on epoch=120
05/16/2022 07:23:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.73 on epoch=121
05/16/2022 07:23:33 - INFO - __main__ - Global step 1700 Train loss 2.77 Classification-F1 0.00976800976800977 on epoch=121
05/16/2022 07:23:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.78 on epoch=122
05/16/2022 07:23:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.86 on epoch=122
05/16/2022 07:23:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.63 on epoch=123
05/16/2022 07:23:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.76 on epoch=124
05/16/2022 07:23:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.58 on epoch=124
05/16/2022 07:23:42 - INFO - __main__ - Global step 1750 Train loss 2.72 Classification-F1 0.01762173796072101 on epoch=124
05/16/2022 07:23:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.82 on epoch=125
05/16/2022 07:23:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.62 on epoch=126
05/16/2022 07:23:46 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.67 on epoch=127
05/16/2022 07:23:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.62 on epoch=127
05/16/2022 07:23:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.58 on epoch=128
05/16/2022 07:23:50 - INFO - __main__ - Global step 1800 Train loss 2.66 Classification-F1 0.023302308635023684 on epoch=128
05/16/2022 07:23:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.80 on epoch=129
05/16/2022 07:23:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.56 on epoch=129
05/16/2022 07:23:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.57 on epoch=130
05/16/2022 07:23:56 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.62 on epoch=131
05/16/2022 07:23:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.60 on epoch=132
05/16/2022 07:24:00 - INFO - __main__ - Global step 1850 Train loss 2.63 Classification-F1 0.043428293795023686 on epoch=132
05/16/2022 07:24:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.84 on epoch=132
05/16/2022 07:24:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.65 on epoch=133
05/16/2022 07:24:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.81 on epoch=134
05/16/2022 07:24:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.65 on epoch=134
05/16/2022 07:24:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.72 on epoch=135
05/16/2022 07:24:09 - INFO - __main__ - Global step 1900 Train loss 2.73 Classification-F1 0.06727584426591747 on epoch=135
05/16/2022 07:24:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.64 on epoch=136
05/16/2022 07:24:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.49 on epoch=137
05/16/2022 07:24:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.80 on epoch=137
05/16/2022 07:24:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.48 on epoch=138
05/16/2022 07:24:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.80 on epoch=139
05/16/2022 07:24:17 - INFO - __main__ - Global step 1950 Train loss 2.64 Classification-F1 0.06319981878900258 on epoch=139
05/16/2022 07:24:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.63 on epoch=139
05/16/2022 07:24:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.62 on epoch=140
05/16/2022 07:24:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.41 on epoch=141
05/16/2022 07:24:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.54 on epoch=142
05/16/2022 07:24:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.68 on epoch=142
05/16/2022 07:24:26 - INFO - __main__ - Global step 2000 Train loss 2.58 Classification-F1 0.04786390080507728 on epoch=142
05/16/2022 07:24:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.59 on epoch=143
05/16/2022 07:24:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.63 on epoch=144
05/16/2022 07:24:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.48 on epoch=144
05/16/2022 07:24:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.68 on epoch=145
05/16/2022 07:24:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.59 on epoch=146
05/16/2022 07:24:35 - INFO - __main__ - Global step 2050 Train loss 2.59 Classification-F1 0.06245020530734816 on epoch=146
05/16/2022 07:24:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.58 on epoch=147
05/16/2022 07:24:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.60 on epoch=147
05/16/2022 07:24:39 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.42 on epoch=148
05/16/2022 07:24:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.56 on epoch=149
05/16/2022 07:24:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.50 on epoch=149
05/16/2022 07:24:44 - INFO - __main__ - Global step 2100 Train loss 2.53 Classification-F1 0.05118303502926768 on epoch=149
05/16/2022 07:24:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.66 on epoch=150
05/16/2022 07:24:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.32 on epoch=151
05/16/2022 07:24:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.57 on epoch=152
05/16/2022 07:24:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.63 on epoch=152
05/16/2022 07:24:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.51 on epoch=153
05/16/2022 07:24:52 - INFO - __main__ - Global step 2150 Train loss 2.54 Classification-F1 0.09707065103769727 on epoch=153
05/16/2022 07:24:52 - INFO - __main__ - Saving model with best Classification-F1: 0.08564914993196823 -> 0.09707065103769727 on epoch=153, global_step=2150
05/16/2022 07:24:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.59 on epoch=154
05/16/2022 07:24:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.41 on epoch=154
05/16/2022 07:24:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.55 on epoch=155
05/16/2022 07:24:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.30 on epoch=156
05/16/2022 07:24:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.45 on epoch=157
05/16/2022 07:25:01 - INFO - __main__ - Global step 2200 Train loss 2.46 Classification-F1 0.05982916714960914 on epoch=157
05/16/2022 07:25:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.55 on epoch=157
05/16/2022 07:25:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.39 on epoch=158
05/16/2022 07:25:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.38 on epoch=159
05/16/2022 07:25:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.48 on epoch=159
05/16/2022 07:25:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.56 on epoch=160
05/16/2022 07:25:09 - INFO - __main__ - Global step 2250 Train loss 2.47 Classification-F1 0.10385655513247835 on epoch=160
05/16/2022 07:25:09 - INFO - __main__ - Saving model with best Classification-F1: 0.09707065103769727 -> 0.10385655513247835 on epoch=160, global_step=2250
05/16/2022 07:25:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.34 on epoch=161
05/16/2022 07:25:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.35 on epoch=162
05/16/2022 07:25:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.35 on epoch=162
05/16/2022 07:25:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.39 on epoch=163
05/16/2022 07:25:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.54 on epoch=164
05/16/2022 07:25:18 - INFO - __main__ - Global step 2300 Train loss 2.39 Classification-F1 0.08221492080322121 on epoch=164
05/16/2022 07:25:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.15 on epoch=164
05/16/2022 07:25:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.45 on epoch=165
05/16/2022 07:25:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.24 on epoch=166
05/16/2022 07:25:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.35 on epoch=167
05/16/2022 07:25:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.35 on epoch=167
05/16/2022 07:25:27 - INFO - __main__ - Global step 2350 Train loss 2.31 Classification-F1 0.07818671263237269 on epoch=167
05/16/2022 07:25:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.40 on epoch=168
05/16/2022 07:25:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.51 on epoch=169
05/16/2022 07:25:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.33 on epoch=169
05/16/2022 07:25:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.42 on epoch=170
05/16/2022 07:25:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.28 on epoch=171
05/16/2022 07:25:36 - INFO - __main__ - Global step 2400 Train loss 2.39 Classification-F1 0.10707891534243065 on epoch=171
05/16/2022 07:25:36 - INFO - __main__ - Saving model with best Classification-F1: 0.10385655513247835 -> 0.10707891534243065 on epoch=171, global_step=2400
05/16/2022 07:25:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.31 on epoch=172
05/16/2022 07:25:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.40 on epoch=172
05/16/2022 07:25:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.26 on epoch=173
05/16/2022 07:25:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.35 on epoch=174
05/16/2022 07:25:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.22 on epoch=174
05/16/2022 07:25:44 - INFO - __main__ - Global step 2450 Train loss 2.31 Classification-F1 0.05883116883116883 on epoch=174
05/16/2022 07:25:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.34 on epoch=175
05/16/2022 07:25:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.21 on epoch=176
05/16/2022 07:25:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.28 on epoch=177
05/16/2022 07:25:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.28 on epoch=177
05/16/2022 07:25:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.07 on epoch=178
05/16/2022 07:25:53 - INFO - __main__ - Global step 2500 Train loss 2.24 Classification-F1 0.09106216645207921 on epoch=178
05/16/2022 07:25:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.20 on epoch=179
05/16/2022 07:25:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.13 on epoch=179
05/16/2022 07:25:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.38 on epoch=180
05/16/2022 07:25:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.22 on epoch=181
05/16/2022 07:25:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.26 on epoch=182
05/16/2022 07:26:02 - INFO - __main__ - Global step 2550 Train loss 2.24 Classification-F1 0.06731175228712175 on epoch=182
05/16/2022 07:26:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.31 on epoch=182
05/16/2022 07:26:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.24 on epoch=183
05/16/2022 07:26:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.43 on epoch=184
05/16/2022 07:26:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.17 on epoch=184
05/16/2022 07:26:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.31 on epoch=185
05/16/2022 07:26:10 - INFO - __main__ - Global step 2600 Train loss 2.29 Classification-F1 0.07487822293792444 on epoch=185
05/16/2022 07:26:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.18 on epoch=186
05/16/2022 07:26:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.15 on epoch=187
05/16/2022 07:26:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.22 on epoch=187
05/16/2022 07:26:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.16 on epoch=188
05/16/2022 07:26:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.29 on epoch=189
05/16/2022 07:26:18 - INFO - __main__ - Global step 2650 Train loss 2.20 Classification-F1 0.06955624355005159 on epoch=189
05/16/2022 07:26:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.10 on epoch=189
05/16/2022 07:26:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.36 on epoch=190
05/16/2022 07:26:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.10 on epoch=191
05/16/2022 07:26:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.12 on epoch=192
05/16/2022 07:26:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.28 on epoch=192
05/16/2022 07:26:27 - INFO - __main__ - Global step 2700 Train loss 2.19 Classification-F1 0.0835267073862512 on epoch=192
05/16/2022 07:26:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.17 on epoch=193
05/16/2022 07:26:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.31 on epoch=194
05/16/2022 07:26:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.23 on epoch=194
05/16/2022 07:26:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.15 on epoch=195
05/16/2022 07:26:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.08 on epoch=196
05/16/2022 07:26:35 - INFO - __main__ - Global step 2750 Train loss 2.19 Classification-F1 0.06294671265491915 on epoch=196
05/16/2022 07:26:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.24 on epoch=197
05/16/2022 07:26:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.94 on epoch=197
05/16/2022 07:26:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.09 on epoch=198
05/16/2022 07:26:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.06 on epoch=199
05/16/2022 07:26:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.05 on epoch=199
05/16/2022 07:26:44 - INFO - __main__ - Global step 2800 Train loss 2.07 Classification-F1 0.07226724640931244 on epoch=199
05/16/2022 07:26:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.29 on epoch=200
05/16/2022 07:26:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.05 on epoch=201
05/16/2022 07:26:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.05 on epoch=202
05/16/2022 07:26:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.10 on epoch=202
05/16/2022 07:26:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.11 on epoch=203
05/16/2022 07:26:53 - INFO - __main__ - Global step 2850 Train loss 2.12 Classification-F1 0.1245345068987809 on epoch=203
05/16/2022 07:26:53 - INFO - __main__ - Saving model with best Classification-F1: 0.10707891534243065 -> 0.1245345068987809 on epoch=203, global_step=2850
05/16/2022 07:26:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.98 on epoch=204
05/16/2022 07:26:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.02 on epoch=204
05/16/2022 07:26:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.11 on epoch=205
05/16/2022 07:26:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.86 on epoch=206
05/16/2022 07:27:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.10 on epoch=207
05/16/2022 07:27:03 - INFO - __main__ - Global step 2900 Train loss 2.01 Classification-F1 0.0700057800898137 on epoch=207
05/16/2022 07:27:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.01 on epoch=207
05/16/2022 07:27:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.07 on epoch=208
05/16/2022 07:27:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.11 on epoch=209
05/16/2022 07:27:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.09 on epoch=209
05/16/2022 07:27:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.10 on epoch=210
05/16/2022 07:27:12 - INFO - __main__ - Global step 2950 Train loss 2.08 Classification-F1 0.11344172969559967 on epoch=210
05/16/2022 07:27:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.00 on epoch=211
05/16/2022 07:27:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.98 on epoch=212
05/16/2022 07:27:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.08 on epoch=212
05/16/2022 07:27:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.86 on epoch=213
05/16/2022 07:27:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.97 on epoch=214
05/16/2022 07:27:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:27:21 - INFO - __main__ - Printing 3 examples
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:27:21 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:27:21 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:27:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:27:21 - INFO - __main__ - Printing 3 examples
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:27:21 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:27:21 - INFO - __main__ - Global step 3000 Train loss 1.98 Classification-F1 0.11477437776457383 on epoch=214
05/16/2022 07:27:21 - INFO - __main__ - save last model!
05/16/2022 07:27:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 07:27:21 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 07:27:21 - INFO - __main__ - Printing 3 examples
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 07:27:21 - INFO - __main__ - ['Animal']
05/16/2022 07:27:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 07:27:21 - INFO - __main__ - ['Village']
05/16/2022 07:27:21 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:27:21 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:27:23 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:27:27 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 07:27:27 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:27:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:27:27 - INFO - __main__ - Starting training!
05/16/2022 07:28:08 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/16/2022 07:28:08 - INFO - __main__ - Classification-F1 on test data: 0.1187
05/16/2022 07:28:08 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.1245345068987809, test_performance=0.1187355508716266
05/16/2022 07:28:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/16/2022 07:28:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:28:09 - INFO - __main__ - Printing 3 examples
05/16/2022 07:28:09 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/16/2022 07:28:09 - INFO - __main__ - ['Animal']
05/16/2022 07:28:09 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/16/2022 07:28:09 - INFO - __main__ - ['Animal']
05/16/2022 07:28:09 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/16/2022 07:28:09 - INFO - __main__ - ['Animal']
05/16/2022 07:28:09 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:28:09 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:28:10 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:28:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:28:10 - INFO - __main__ - Printing 3 examples
05/16/2022 07:28:10 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/16/2022 07:28:10 - INFO - __main__ - ['Animal']
05/16/2022 07:28:10 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/16/2022 07:28:10 - INFO - __main__ - ['Animal']
05/16/2022 07:28:10 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/16/2022 07:28:10 - INFO - __main__ - ['Animal']
05/16/2022 07:28:10 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:28:10 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:28:10 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:28:15 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:28:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:28:15 - INFO - __main__ - Starting training!
05/16/2022 07:28:19 - INFO - __main__ - Step 10 Global step 10 Train loss 7.32 on epoch=0
05/16/2022 07:28:21 - INFO - __main__ - Step 20 Global step 20 Train loss 7.28 on epoch=1
05/16/2022 07:28:23 - INFO - __main__ - Step 30 Global step 30 Train loss 7.17 on epoch=2
05/16/2022 07:28:24 - INFO - __main__ - Step 40 Global step 40 Train loss 7.08 on epoch=2
05/16/2022 07:28:25 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/16/2022 07:28:41 - INFO - __main__ - Global step 50 Train loss 7.18 Classification-F1 0.0 on epoch=3
05/16/2022 07:28:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 07:28:42 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/16/2022 07:28:44 - INFO - __main__ - Step 70 Global step 70 Train loss 7.07 on epoch=4
05/16/2022 07:28:45 - INFO - __main__ - Step 80 Global step 80 Train loss 6.81 on epoch=5
05/16/2022 07:28:46 - INFO - __main__ - Step 90 Global step 90 Train loss 6.80 on epoch=6
05/16/2022 07:28:47 - INFO - __main__ - Step 100 Global step 100 Train loss 6.53 on epoch=7
05/16/2022 07:29:34 - INFO - __main__ - Global step 100 Train loss 6.79 Classification-F1 0.0 on epoch=7
05/16/2022 07:29:35 - INFO - __main__ - Step 110 Global step 110 Train loss 6.64 on epoch=7
05/16/2022 07:29:37 - INFO - __main__ - Step 120 Global step 120 Train loss 6.59 on epoch=8
05/16/2022 07:29:38 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/16/2022 07:29:39 - INFO - __main__ - Step 140 Global step 140 Train loss 6.56 on epoch=9
05/16/2022 07:29:41 - INFO - __main__ - Step 150 Global step 150 Train loss 6.49 on epoch=10
05/16/2022 07:30:37 - INFO - __main__ - Global step 150 Train loss 6.53 Classification-F1 0.0 on epoch=10
05/16/2022 07:30:38 - INFO - __main__ - Step 160 Global step 160 Train loss 6.37 on epoch=11
05/16/2022 07:30:39 - INFO - __main__ - Step 170 Global step 170 Train loss 6.26 on epoch=12
05/16/2022 07:30:41 - INFO - __main__ - Step 180 Global step 180 Train loss 6.31 on epoch=12
05/16/2022 07:30:42 - INFO - __main__ - Step 190 Global step 190 Train loss 6.25 on epoch=13
05/16/2022 07:30:43 - INFO - __main__ - Step 200 Global step 200 Train loss 6.05 on epoch=14
05/16/2022 07:31:43 - INFO - __main__ - Global step 200 Train loss 6.25 Classification-F1 0.0 on epoch=14
05/16/2022 07:31:44 - INFO - __main__ - Step 210 Global step 210 Train loss 6.32 on epoch=14
05/16/2022 07:31:46 - INFO - __main__ - Step 220 Global step 220 Train loss 6.15 on epoch=15
05/16/2022 07:31:47 - INFO - __main__ - Step 230 Global step 230 Train loss 6.10 on epoch=16
05/16/2022 07:31:48 - INFO - __main__ - Step 240 Global step 240 Train loss 6.01 on epoch=17
05/16/2022 07:31:49 - INFO - __main__ - Step 250 Global step 250 Train loss 5.84 on epoch=17
05/16/2022 07:32:38 - INFO - __main__ - Global step 250 Train loss 6.09 Classification-F1 0.0 on epoch=17
05/16/2022 07:32:39 - INFO - __main__ - Step 260 Global step 260 Train loss 5.96 on epoch=18
05/16/2022 07:32:40 - INFO - __main__ - Step 270 Global step 270 Train loss 5.82 on epoch=19
05/16/2022 07:32:41 - INFO - __main__ - Step 280 Global step 280 Train loss 5.96 on epoch=19
05/16/2022 07:32:43 - INFO - __main__ - Step 290 Global step 290 Train loss 5.99 on epoch=20
05/16/2022 07:32:44 - INFO - __main__ - Step 300 Global step 300 Train loss 5.72 on epoch=21
05/16/2022 07:33:38 - INFO - __main__ - Global step 300 Train loss 5.89 Classification-F1 0.0 on epoch=21
05/16/2022 07:33:39 - INFO - __main__ - Step 310 Global step 310 Train loss 5.87 on epoch=22
05/16/2022 07:33:41 - INFO - __main__ - Step 320 Global step 320 Train loss 5.91 on epoch=22
05/16/2022 07:33:42 - INFO - __main__ - Step 330 Global step 330 Train loss 5.85 on epoch=23
05/16/2022 07:33:43 - INFO - __main__ - Step 340 Global step 340 Train loss 5.67 on epoch=24
05/16/2022 07:33:45 - INFO - __main__ - Step 350 Global step 350 Train loss 5.80 on epoch=24
05/16/2022 07:34:15 - INFO - __main__ - Global step 350 Train loss 5.82 Classification-F1 0.0 on epoch=24
05/16/2022 07:34:16 - INFO - __main__ - Step 360 Global step 360 Train loss 5.87 on epoch=25
05/16/2022 07:34:17 - INFO - __main__ - Step 370 Global step 370 Train loss 5.68 on epoch=26
05/16/2022 07:34:19 - INFO - __main__ - Step 380 Global step 380 Train loss 5.62 on epoch=27
05/16/2022 07:34:20 - INFO - __main__ - Step 390 Global step 390 Train loss 5.56 on epoch=27
05/16/2022 07:34:21 - INFO - __main__ - Step 400 Global step 400 Train loss 5.65 on epoch=28
05/16/2022 07:35:00 - INFO - __main__ - Global step 400 Train loss 5.68 Classification-F1 0.0 on epoch=28
05/16/2022 07:35:02 - INFO - __main__ - Step 410 Global step 410 Train loss 5.55 on epoch=29
05/16/2022 07:35:03 - INFO - __main__ - Step 420 Global step 420 Train loss 5.60 on epoch=29
05/16/2022 07:35:04 - INFO - __main__ - Step 430 Global step 430 Train loss 5.55 on epoch=30
05/16/2022 07:35:05 - INFO - __main__ - Step 440 Global step 440 Train loss 5.46 on epoch=31
05/16/2022 07:35:07 - INFO - __main__ - Step 450 Global step 450 Train loss 5.49 on epoch=32
05/16/2022 07:35:45 - INFO - __main__ - Global step 450 Train loss 5.53 Classification-F1 0.0 on epoch=32
05/16/2022 07:35:46 - INFO - __main__ - Step 460 Global step 460 Train loss 5.40 on epoch=32
05/16/2022 07:35:48 - INFO - __main__ - Step 470 Global step 470 Train loss 5.31 on epoch=33
05/16/2022 07:35:49 - INFO - __main__ - Step 480 Global step 480 Train loss 5.30 on epoch=34
05/16/2022 07:35:50 - INFO - __main__ - Step 490 Global step 490 Train loss 5.41 on epoch=34
05/16/2022 07:35:52 - INFO - __main__ - Step 500 Global step 500 Train loss 5.43 on epoch=35
05/16/2022 07:36:25 - INFO - __main__ - Global step 500 Train loss 5.37 Classification-F1 0.0 on epoch=35
05/16/2022 07:36:27 - INFO - __main__ - Step 510 Global step 510 Train loss 5.32 on epoch=36
05/16/2022 07:36:28 - INFO - __main__ - Step 520 Global step 520 Train loss 5.16 on epoch=37
05/16/2022 07:36:29 - INFO - __main__ - Step 530 Global step 530 Train loss 5.29 on epoch=37
05/16/2022 07:36:31 - INFO - __main__ - Step 540 Global step 540 Train loss 5.30 on epoch=38
05/16/2022 07:36:32 - INFO - __main__ - Step 550 Global step 550 Train loss 5.10 on epoch=39
05/16/2022 07:37:10 - INFO - __main__ - Global step 550 Train loss 5.24 Classification-F1 0.0 on epoch=39
05/16/2022 07:37:12 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/16/2022 07:37:13 - INFO - __main__ - Step 570 Global step 570 Train loss 5.13 on epoch=40
05/16/2022 07:37:14 - INFO - __main__ - Step 580 Global step 580 Train loss 5.19 on epoch=41
05/16/2022 07:37:16 - INFO - __main__ - Step 590 Global step 590 Train loss 4.99 on epoch=42
05/16/2022 07:37:17 - INFO - __main__ - Step 600 Global step 600 Train loss 5.05 on epoch=42
05/16/2022 07:37:21 - INFO - __main__ - Global step 600 Train loss 5.09 Classification-F1 0.0011305822498586774 on epoch=42
05/16/2022 07:37:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0011305822498586774 on epoch=42, global_step=600
05/16/2022 07:37:22 - INFO - __main__ - Step 610 Global step 610 Train loss 5.06 on epoch=43
05/16/2022 07:37:23 - INFO - __main__ - Step 620 Global step 620 Train loss 5.01 on epoch=44
05/16/2022 07:37:25 - INFO - __main__ - Step 630 Global step 630 Train loss 5.00 on epoch=44
05/16/2022 07:37:26 - INFO - __main__ - Step 640 Global step 640 Train loss 5.13 on epoch=45
05/16/2022 07:37:27 - INFO - __main__ - Step 650 Global step 650 Train loss 4.92 on epoch=46
05/16/2022 07:37:30 - INFO - __main__ - Global step 650 Train loss 5.02 Classification-F1 0.005887681159420291 on epoch=46
05/16/2022 07:37:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0011305822498586774 -> 0.005887681159420291 on epoch=46, global_step=650
05/16/2022 07:37:31 - INFO - __main__ - Step 660 Global step 660 Train loss 4.86 on epoch=47
05/16/2022 07:37:33 - INFO - __main__ - Step 670 Global step 670 Train loss 4.80 on epoch=47
05/16/2022 07:37:34 - INFO - __main__ - Step 680 Global step 680 Train loss 4.85 on epoch=48
05/16/2022 07:37:35 - INFO - __main__ - Step 690 Global step 690 Train loss 4.76 on epoch=49
05/16/2022 07:37:37 - INFO - __main__ - Step 700 Global step 700 Train loss 4.90 on epoch=49
05/16/2022 07:37:39 - INFO - __main__ - Global step 700 Train loss 4.83 Classification-F1 0.007629947544110634 on epoch=49
05/16/2022 07:37:39 - INFO - __main__ - Saving model with best Classification-F1: 0.005887681159420291 -> 0.007629947544110634 on epoch=49, global_step=700
05/16/2022 07:37:40 - INFO - __main__ - Step 710 Global step 710 Train loss 4.86 on epoch=50
05/16/2022 07:37:42 - INFO - __main__ - Step 720 Global step 720 Train loss 4.79 on epoch=51
05/16/2022 07:37:43 - INFO - __main__ - Step 730 Global step 730 Train loss 4.71 on epoch=52
05/16/2022 07:37:44 - INFO - __main__ - Step 740 Global step 740 Train loss 4.82 on epoch=52
05/16/2022 07:37:46 - INFO - __main__ - Step 750 Global step 750 Train loss 4.77 on epoch=53
05/16/2022 07:37:48 - INFO - __main__ - Global step 750 Train loss 4.79 Classification-F1 0.009523809523809523 on epoch=53
05/16/2022 07:37:48 - INFO - __main__ - Saving model with best Classification-F1: 0.007629947544110634 -> 0.009523809523809523 on epoch=53, global_step=750
05/16/2022 07:37:50 - INFO - __main__ - Step 760 Global step 760 Train loss 4.77 on epoch=54
05/16/2022 07:37:51 - INFO - __main__ - Step 770 Global step 770 Train loss 4.86 on epoch=54
05/16/2022 07:37:52 - INFO - __main__ - Step 780 Global step 780 Train loss 4.68 on epoch=55
05/16/2022 07:37:54 - INFO - __main__ - Step 790 Global step 790 Train loss 4.62 on epoch=56
05/16/2022 07:37:55 - INFO - __main__ - Step 800 Global step 800 Train loss 4.63 on epoch=57
05/16/2022 07:37:57 - INFO - __main__ - Global step 800 Train loss 4.71 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 07:37:59 - INFO - __main__ - Step 810 Global step 810 Train loss 4.82 on epoch=57
05/16/2022 07:38:00 - INFO - __main__ - Step 820 Global step 820 Train loss 4.81 on epoch=58
05/16/2022 07:38:01 - INFO - __main__ - Step 830 Global step 830 Train loss 4.61 on epoch=59
05/16/2022 07:38:03 - INFO - __main__ - Step 840 Global step 840 Train loss 4.61 on epoch=59
05/16/2022 07:38:04 - INFO - __main__ - Step 850 Global step 850 Train loss 4.67 on epoch=60
05/16/2022 07:38:06 - INFO - __main__ - Global step 850 Train loss 4.71 Classification-F1 0.008438818565400845 on epoch=60
05/16/2022 07:38:08 - INFO - __main__ - Step 860 Global step 860 Train loss 4.56 on epoch=61
05/16/2022 07:38:09 - INFO - __main__ - Step 870 Global step 870 Train loss 4.61 on epoch=62
05/16/2022 07:38:10 - INFO - __main__ - Step 880 Global step 880 Train loss 4.58 on epoch=62
05/16/2022 07:38:12 - INFO - __main__ - Step 890 Global step 890 Train loss 4.46 on epoch=63
05/16/2022 07:38:13 - INFO - __main__ - Step 900 Global step 900 Train loss 4.52 on epoch=64
05/16/2022 07:38:15 - INFO - __main__ - Global step 900 Train loss 4.55 Classification-F1 0.009523809523809523 on epoch=64
05/16/2022 07:38:17 - INFO - __main__ - Step 910 Global step 910 Train loss 4.53 on epoch=64
05/16/2022 07:38:18 - INFO - __main__ - Step 920 Global step 920 Train loss 4.63 on epoch=65
05/16/2022 07:38:20 - INFO - __main__ - Step 930 Global step 930 Train loss 4.56 on epoch=66
05/16/2022 07:38:21 - INFO - __main__ - Step 940 Global step 940 Train loss 4.48 on epoch=67
05/16/2022 07:38:22 - INFO - __main__ - Step 950 Global step 950 Train loss 4.46 on epoch=67
05/16/2022 07:38:25 - INFO - __main__ - Global step 950 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=67
05/16/2022 07:38:26 - INFO - __main__ - Step 960 Global step 960 Train loss 4.43 on epoch=68
05/16/2022 07:38:27 - INFO - __main__ - Step 970 Global step 970 Train loss 4.49 on epoch=69
05/16/2022 07:38:29 - INFO - __main__ - Step 980 Global step 980 Train loss 4.48 on epoch=69
05/16/2022 07:38:30 - INFO - __main__ - Step 990 Global step 990 Train loss 4.42 on epoch=70
05/16/2022 07:38:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.26 on epoch=71
05/16/2022 07:38:34 - INFO - __main__ - Global step 1000 Train loss 4.42 Classification-F1 0.009523809523809523 on epoch=71
05/16/2022 07:38:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.31 on epoch=72
05/16/2022 07:38:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.35 on epoch=72
05/16/2022 07:38:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.28 on epoch=73
05/16/2022 07:38:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.38 on epoch=74
05/16/2022 07:38:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.17 on epoch=74
05/16/2022 07:38:42 - INFO - __main__ - Global step 1050 Train loss 4.30 Classification-F1 0.009523809523809523 on epoch=74
05/16/2022 07:38:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.31 on epoch=75
05/16/2022 07:38:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.21 on epoch=76
05/16/2022 07:38:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.18 on epoch=77
05/16/2022 07:38:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.20 on epoch=77
05/16/2022 07:38:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.15 on epoch=78
05/16/2022 07:38:51 - INFO - __main__ - Global step 1100 Train loss 4.21 Classification-F1 0.009523809523809523 on epoch=78
05/16/2022 07:38:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.11 on epoch=79
05/16/2022 07:38:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.23 on epoch=79
05/16/2022 07:38:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.18 on epoch=80
05/16/2022 07:38:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.09 on epoch=81
05/16/2022 07:38:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.99 on epoch=82
05/16/2022 07:38:59 - INFO - __main__ - Global step 1150 Train loss 4.12 Classification-F1 0.009523809523809523 on epoch=82
05/16/2022 07:39:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.01 on epoch=82
05/16/2022 07:39:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.09 on epoch=83
05/16/2022 07:39:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.11 on epoch=84
05/16/2022 07:39:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.93 on epoch=84
05/16/2022 07:39:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.02 on epoch=85
05/16/2022 07:39:08 - INFO - __main__ - Global step 1200 Train loss 4.03 Classification-F1 0.009523809523809523 on epoch=85
05/16/2022 07:39:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.84 on epoch=86
05/16/2022 07:39:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.89 on epoch=87
05/16/2022 07:39:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.01 on epoch=87
05/16/2022 07:39:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.76 on epoch=88
05/16/2022 07:39:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.93 on epoch=89
05/16/2022 07:39:16 - INFO - __main__ - Global step 1250 Train loss 3.89 Classification-F1 0.009523809523809523 on epoch=89
05/16/2022 07:39:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.75 on epoch=89
05/16/2022 07:39:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.81 on epoch=90
05/16/2022 07:39:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.77 on epoch=91
05/16/2022 07:39:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.71 on epoch=92
05/16/2022 07:39:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.91 on epoch=92
05/16/2022 07:39:25 - INFO - __main__ - Global step 1300 Train loss 3.79 Classification-F1 0.016529164857432336 on epoch=92
05/16/2022 07:39:25 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.016529164857432336 on epoch=92, global_step=1300
05/16/2022 07:39:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.72 on epoch=93
05/16/2022 07:39:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.93 on epoch=94
05/16/2022 07:39:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.75 on epoch=94
05/16/2022 07:39:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.70 on epoch=95
05/16/2022 07:39:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.56 on epoch=96
05/16/2022 07:39:33 - INFO - __main__ - Global step 1350 Train loss 3.73 Classification-F1 0.03280840955910984 on epoch=96
05/16/2022 07:39:33 - INFO - __main__ - Saving model with best Classification-F1: 0.016529164857432336 -> 0.03280840955910984 on epoch=96, global_step=1350
05/16/2022 07:39:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.58 on epoch=97
05/16/2022 07:39:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.68 on epoch=97
05/16/2022 07:39:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.69 on epoch=98
05/16/2022 07:39:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.60 on epoch=99
05/16/2022 07:39:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.56 on epoch=99
05/16/2022 07:39:42 - INFO - __main__ - Global step 1400 Train loss 3.62 Classification-F1 0.026693806269296183 on epoch=99
05/16/2022 07:39:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.60 on epoch=100
05/16/2022 07:39:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.58 on epoch=101
05/16/2022 07:39:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.62 on epoch=102
05/16/2022 07:39:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.70 on epoch=102
05/16/2022 07:39:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.55 on epoch=103
05/16/2022 07:39:51 - INFO - __main__ - Global step 1450 Train loss 3.61 Classification-F1 0.02290105231281702 on epoch=103
05/16/2022 07:39:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.51 on epoch=104
05/16/2022 07:39:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.61 on epoch=104
05/16/2022 07:39:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.53 on epoch=105
05/16/2022 07:39:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.37 on epoch=106
05/16/2022 07:39:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.43 on epoch=107
05/16/2022 07:39:59 - INFO - __main__ - Global step 1500 Train loss 3.49 Classification-F1 0.026546250684181722 on epoch=107
05/16/2022 07:40:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.52 on epoch=107
05/16/2022 07:40:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.43 on epoch=108
05/16/2022 07:40:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.36 on epoch=109
05/16/2022 07:40:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.41 on epoch=109
05/16/2022 07:40:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.56 on epoch=110
05/16/2022 07:40:08 - INFO - __main__ - Global step 1550 Train loss 3.46 Classification-F1 0.035238095238095235 on epoch=110
05/16/2022 07:40:08 - INFO - __main__ - Saving model with best Classification-F1: 0.03280840955910984 -> 0.035238095238095235 on epoch=110, global_step=1550
05/16/2022 07:40:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.35 on epoch=111
05/16/2022 07:40:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.43 on epoch=112
05/16/2022 07:40:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.39 on epoch=112
05/16/2022 07:40:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.37 on epoch=113
05/16/2022 07:40:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.51 on epoch=114
05/16/2022 07:40:17 - INFO - __main__ - Global step 1600 Train loss 3.41 Classification-F1 0.03236663086287146 on epoch=114
05/16/2022 07:40:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.37 on epoch=114
05/16/2022 07:40:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.43 on epoch=115
05/16/2022 07:40:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.08 on epoch=116
05/16/2022 07:40:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.24 on epoch=117
05/16/2022 07:40:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.38 on epoch=117
05/16/2022 07:40:26 - INFO - __main__ - Global step 1650 Train loss 3.30 Classification-F1 0.02875124542022761 on epoch=117
05/16/2022 07:40:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.14 on epoch=118
05/16/2022 07:40:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.39 on epoch=119
05/16/2022 07:40:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.17 on epoch=119
05/16/2022 07:40:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.29 on epoch=120
05/16/2022 07:40:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.04 on epoch=121
05/16/2022 07:40:36 - INFO - __main__ - Global step 1700 Train loss 3.21 Classification-F1 0.034864588037049685 on epoch=121
05/16/2022 07:40:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.21 on epoch=122
05/16/2022 07:40:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.37 on epoch=122
05/16/2022 07:40:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.24 on epoch=123
05/16/2022 07:40:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.22 on epoch=124
05/16/2022 07:40:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.14 on epoch=124
05/16/2022 07:40:45 - INFO - __main__ - Global step 1750 Train loss 3.23 Classification-F1 0.030305850644833692 on epoch=124
05/16/2022 07:40:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.18 on epoch=125
05/16/2022 07:40:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.15 on epoch=126
05/16/2022 07:40:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.14 on epoch=127
05/16/2022 07:40:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.07 on epoch=127
05/16/2022 07:40:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.16 on epoch=128
05/16/2022 07:40:54 - INFO - __main__ - Global step 1800 Train loss 3.14 Classification-F1 0.027354627354627355 on epoch=128
05/16/2022 07:40:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.20 on epoch=129
05/16/2022 07:40:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.06 on epoch=129
05/16/2022 07:40:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.13 on epoch=130
05/16/2022 07:40:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.07 on epoch=131
05/16/2022 07:41:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.12 on epoch=132
05/16/2022 07:41:02 - INFO - __main__ - Global step 1850 Train loss 3.12 Classification-F1 0.02105711849957374 on epoch=132
05/16/2022 07:41:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.32 on epoch=132
05/16/2022 07:41:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.11 on epoch=133
05/16/2022 07:41:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.10 on epoch=134
05/16/2022 07:41:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.06 on epoch=134
05/16/2022 07:41:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.29 on epoch=135
05/16/2022 07:41:11 - INFO - __main__ - Global step 1900 Train loss 3.17 Classification-F1 0.02007459412022817 on epoch=135
05/16/2022 07:41:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.15 on epoch=136
05/16/2022 07:41:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.20 on epoch=137
05/16/2022 07:41:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.08 on epoch=137
05/16/2022 07:41:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.04 on epoch=138
05/16/2022 07:41:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.26 on epoch=139
05/16/2022 07:41:20 - INFO - __main__ - Global step 1950 Train loss 3.15 Classification-F1 0.03648724566965637 on epoch=139
05/16/2022 07:41:20 - INFO - __main__ - Saving model with best Classification-F1: 0.035238095238095235 -> 0.03648724566965637 on epoch=139, global_step=1950
05/16/2022 07:41:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.19 on epoch=139
05/16/2022 07:41:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.10 on epoch=140
05/16/2022 07:41:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.96 on epoch=141
05/16/2022 07:41:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.98 on epoch=142
05/16/2022 07:41:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.16 on epoch=142
05/16/2022 07:41:29 - INFO - __main__ - Global step 2000 Train loss 3.08 Classification-F1 0.015692848897927776 on epoch=142
05/16/2022 07:41:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.04 on epoch=143
05/16/2022 07:41:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.11 on epoch=144
05/16/2022 07:41:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.85 on epoch=144
05/16/2022 07:41:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.15 on epoch=145
05/16/2022 07:41:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.95 on epoch=146
05/16/2022 07:41:37 - INFO - __main__ - Global step 2050 Train loss 3.02 Classification-F1 0.02801120448179272 on epoch=146
05/16/2022 07:41:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.93 on epoch=147
05/16/2022 07:41:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.03 on epoch=147
05/16/2022 07:41:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.89 on epoch=148
05/16/2022 07:41:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.04 on epoch=149
05/16/2022 07:41:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.84 on epoch=149
05/16/2022 07:41:46 - INFO - __main__ - Global step 2100 Train loss 2.94 Classification-F1 0.05282334260649523 on epoch=149
05/16/2022 07:41:46 - INFO - __main__ - Saving model with best Classification-F1: 0.03648724566965637 -> 0.05282334260649523 on epoch=149, global_step=2100
05/16/2022 07:41:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.10 on epoch=150
05/16/2022 07:41:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.04 on epoch=151
05/16/2022 07:41:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.11 on epoch=152
05/16/2022 07:41:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.11 on epoch=152
05/16/2022 07:41:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.93 on epoch=153
05/16/2022 07:41:54 - INFO - __main__ - Global step 2150 Train loss 3.06 Classification-F1 0.0335785055162676 on epoch=153
05/16/2022 07:41:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.07 on epoch=154
05/16/2022 07:41:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.82 on epoch=154
05/16/2022 07:41:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.06 on epoch=155
05/16/2022 07:42:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.82 on epoch=156
05/16/2022 07:42:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.08 on epoch=157
05/16/2022 07:42:03 - INFO - __main__ - Global step 2200 Train loss 2.97 Classification-F1 0.05222320668626014 on epoch=157
05/16/2022 07:42:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.09 on epoch=157
05/16/2022 07:42:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.00 on epoch=158
05/16/2022 07:42:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.95 on epoch=159
05/16/2022 07:42:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.78 on epoch=159
05/16/2022 07:42:09 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.88 on epoch=160
05/16/2022 07:42:11 - INFO - __main__ - Global step 2250 Train loss 2.94 Classification-F1 0.03360454275786084 on epoch=160
05/16/2022 07:42:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.92 on epoch=161
05/16/2022 07:42:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.81 on epoch=162
05/16/2022 07:42:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.94 on epoch=162
05/16/2022 07:42:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.97 on epoch=163
05/16/2022 07:42:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.00 on epoch=164
05/16/2022 07:42:20 - INFO - __main__ - Global step 2300 Train loss 2.93 Classification-F1 0.025419902474264042 on epoch=164
05/16/2022 07:42:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.94 on epoch=164
05/16/2022 07:42:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.84 on epoch=165
05/16/2022 07:42:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.81 on epoch=166
05/16/2022 07:42:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.77 on epoch=167
05/16/2022 07:42:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.94 on epoch=167
05/16/2022 07:42:29 - INFO - __main__ - Global step 2350 Train loss 2.86 Classification-F1 0.02132343846629561 on epoch=167
05/16/2022 07:42:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.72 on epoch=168
05/16/2022 07:42:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.87 on epoch=169
05/16/2022 07:42:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.75 on epoch=169
05/16/2022 07:42:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.94 on epoch=170
05/16/2022 07:42:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.83 on epoch=171
05/16/2022 07:42:38 - INFO - __main__ - Global step 2400 Train loss 2.82 Classification-F1 0.02429906542056075 on epoch=171
05/16/2022 07:42:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.76 on epoch=172
05/16/2022 07:42:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.85 on epoch=172
05/16/2022 07:42:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.74 on epoch=173
05/16/2022 07:42:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.98 on epoch=174
05/16/2022 07:42:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.78 on epoch=174
05/16/2022 07:42:47 - INFO - __main__ - Global step 2450 Train loss 2.82 Classification-F1 0.017163161067225024 on epoch=174
05/16/2022 07:42:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.94 on epoch=175
05/16/2022 07:42:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.76 on epoch=176
05/16/2022 07:42:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.86 on epoch=177
05/16/2022 07:42:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.82 on epoch=177
05/16/2022 07:42:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.76 on epoch=178
05/16/2022 07:42:56 - INFO - __main__ - Global step 2500 Train loss 2.83 Classification-F1 0.044128059656009966 on epoch=178
05/16/2022 07:42:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.86 on epoch=179
05/16/2022 07:42:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.62 on epoch=179
05/16/2022 07:43:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.88 on epoch=180
05/16/2022 07:43:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.62 on epoch=181
05/16/2022 07:43:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.77 on epoch=182
05/16/2022 07:43:04 - INFO - __main__ - Global step 2550 Train loss 2.75 Classification-F1 0.021150560680893358 on epoch=182
05/16/2022 07:43:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.90 on epoch=182
05/16/2022 07:43:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.63 on epoch=183
05/16/2022 07:43:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.94 on epoch=184
05/16/2022 07:43:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.64 on epoch=184
05/16/2022 07:43:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.75 on epoch=185
05/16/2022 07:43:13 - INFO - __main__ - Global step 2600 Train loss 2.77 Classification-F1 0.032607801184990126 on epoch=185
05/16/2022 07:43:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.86 on epoch=186
05/16/2022 07:43:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.81 on epoch=187
05/16/2022 07:43:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.82 on epoch=187
05/16/2022 07:43:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.64 on epoch=188
05/16/2022 07:43:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.88 on epoch=189
05/16/2022 07:43:22 - INFO - __main__ - Global step 2650 Train loss 2.80 Classification-F1 0.03222432312829384 on epoch=189
05/16/2022 07:43:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.72 on epoch=189
05/16/2022 07:43:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.88 on epoch=190
05/16/2022 07:43:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.76 on epoch=191
05/16/2022 07:43:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.69 on epoch=192
05/16/2022 07:43:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.88 on epoch=192
05/16/2022 07:43:30 - INFO - __main__ - Global step 2700 Train loss 2.78 Classification-F1 0.026421404682274247 on epoch=192
05/16/2022 07:43:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.68 on epoch=193
05/16/2022 07:43:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.97 on epoch=194
05/16/2022 07:43:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.55 on epoch=194
05/16/2022 07:43:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.81 on epoch=195
05/16/2022 07:43:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.61 on epoch=196
05/16/2022 07:43:39 - INFO - __main__ - Global step 2750 Train loss 2.73 Classification-F1 0.03294548588666236 on epoch=196
05/16/2022 07:43:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.68 on epoch=197
05/16/2022 07:43:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.70 on epoch=197
05/16/2022 07:43:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.67 on epoch=198
05/16/2022 07:43:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.86 on epoch=199
05/16/2022 07:43:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.63 on epoch=199
05/16/2022 07:43:47 - INFO - __main__ - Global step 2800 Train loss 2.71 Classification-F1 0.03410553410553411 on epoch=199
05/16/2022 07:43:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.76 on epoch=200
05/16/2022 07:43:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.71 on epoch=201
05/16/2022 07:43:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.75 on epoch=202
05/16/2022 07:43:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.71 on epoch=202
05/16/2022 07:43:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.74 on epoch=203
05/16/2022 07:43:56 - INFO - __main__ - Global step 2850 Train loss 2.73 Classification-F1 0.02498635347150077 on epoch=203
05/16/2022 07:43:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.86 on epoch=204
05/16/2022 07:43:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.67 on epoch=204
05/16/2022 07:44:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.83 on epoch=205
05/16/2022 07:44:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.63 on epoch=206
05/16/2022 07:44:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.63 on epoch=207
05/16/2022 07:44:04 - INFO - __main__ - Global step 2900 Train loss 2.72 Classification-F1 0.05059829687270593 on epoch=207
05/16/2022 07:44:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.84 on epoch=207
05/16/2022 07:44:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.64 on epoch=208
05/16/2022 07:44:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.70 on epoch=209
05/16/2022 07:44:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.69 on epoch=209
05/16/2022 07:44:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.75 on epoch=210
05/16/2022 07:44:13 - INFO - __main__ - Global step 2950 Train loss 2.73 Classification-F1 0.048593706488443335 on epoch=210
05/16/2022 07:44:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.62 on epoch=211
05/16/2022 07:44:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.76 on epoch=212
05/16/2022 07:44:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.69 on epoch=212
05/16/2022 07:44:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.56 on epoch=213
05/16/2022 07:44:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.80 on epoch=214
05/16/2022 07:44:22 - INFO - __main__ - Global step 3000 Train loss 2.68 Classification-F1 0.038407839624878155 on epoch=214
05/16/2022 07:44:22 - INFO - __main__ - save last model!
05/16/2022 07:44:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 07:44:22 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 07:44:22 - INFO - __main__ - Printing 3 examples
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 07:44:22 - INFO - __main__ - ['Village']
05/16/2022 07:44:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:44:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:44:22 - INFO - __main__ - Printing 3 examples
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:44:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:44:22 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:44:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:44:22 - INFO - __main__ - Printing 3 examples
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 07:44:22 - INFO - __main__ - ['Animal']
05/16/2022 07:44:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:44:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:44:23 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:44:23 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:44:27 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 07:44:28 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:44:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:44:28 - INFO - __main__ - Starting training!
05/16/2022 07:44:56 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/16/2022 07:44:56 - INFO - __main__ - Classification-F1 on test data: 0.0261
05/16/2022 07:44:57 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.05282334260649523, test_performance=0.026080949988889202
05/16/2022 07:44:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/16/2022 07:44:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:44:57 - INFO - __main__ - Printing 3 examples
05/16/2022 07:44:57 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 07:44:57 - INFO - __main__ - ['Animal']
05/16/2022 07:44:57 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 07:44:57 - INFO - __main__ - ['Animal']
05/16/2022 07:44:57 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 07:44:57 - INFO - __main__ - ['Animal']
05/16/2022 07:44:57 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:44:58 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:44:58 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:44:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:44:58 - INFO - __main__ - Printing 3 examples
05/16/2022 07:44:58 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 07:44:58 - INFO - __main__ - ['Animal']
05/16/2022 07:44:58 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 07:44:58 - INFO - __main__ - ['Animal']
05/16/2022 07:44:58 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 07:44:58 - INFO - __main__ - ['Animal']
05/16/2022 07:44:58 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:44:58 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:44:58 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:45:04 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:45:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:45:05 - INFO - __main__ - Starting training!
05/16/2022 07:45:06 - INFO - __main__ - Step 10 Global step 10 Train loss 7.31 on epoch=0
05/16/2022 07:45:08 - INFO - __main__ - Step 20 Global step 20 Train loss 7.37 on epoch=1
05/16/2022 07:45:09 - INFO - __main__ - Step 30 Global step 30 Train loss 7.08 on epoch=2
05/16/2022 07:45:10 - INFO - __main__ - Step 40 Global step 40 Train loss 6.84 on epoch=2
05/16/2022 07:45:12 - INFO - __main__ - Step 50 Global step 50 Train loss 6.81 on epoch=3
05/16/2022 07:45:33 - INFO - __main__ - Global step 50 Train loss 7.08 Classification-F1 0.0 on epoch=3
05/16/2022 07:45:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 07:45:34 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/16/2022 07:45:35 - INFO - __main__ - Step 70 Global step 70 Train loss 6.59 on epoch=4
05/16/2022 07:45:37 - INFO - __main__ - Step 80 Global step 80 Train loss 6.41 on epoch=5
05/16/2022 07:45:38 - INFO - __main__ - Step 90 Global step 90 Train loss 6.44 on epoch=6
05/16/2022 07:45:40 - INFO - __main__ - Step 100 Global step 100 Train loss 6.24 on epoch=7
05/16/2022 07:46:50 - INFO - __main__ - Global step 100 Train loss 6.49 Classification-F1 0.0 on epoch=7
05/16/2022 07:46:51 - INFO - __main__ - Step 110 Global step 110 Train loss 6.08 on epoch=7
05/16/2022 07:46:53 - INFO - __main__ - Step 120 Global step 120 Train loss 6.11 on epoch=8
05/16/2022 07:46:54 - INFO - __main__ - Step 130 Global step 130 Train loss 6.16 on epoch=9
05/16/2022 07:46:55 - INFO - __main__ - Step 140 Global step 140 Train loss 5.96 on epoch=9
05/16/2022 07:46:57 - INFO - __main__ - Step 150 Global step 150 Train loss 5.80 on epoch=10
05/16/2022 07:48:14 - INFO - __main__ - Global step 150 Train loss 6.02 Classification-F1 0.0 on epoch=10
05/16/2022 07:48:15 - INFO - __main__ - Step 160 Global step 160 Train loss 5.90 on epoch=11
05/16/2022 07:48:17 - INFO - __main__ - Step 170 Global step 170 Train loss 5.66 on epoch=12
05/16/2022 07:48:18 - INFO - __main__ - Step 180 Global step 180 Train loss 5.61 on epoch=12
05/16/2022 07:48:19 - INFO - __main__ - Step 190 Global step 190 Train loss 5.63 on epoch=13
05/16/2022 07:48:21 - INFO - __main__ - Step 200 Global step 200 Train loss 5.64 on epoch=14
05/16/2022 07:49:18 - INFO - __main__ - Global step 200 Train loss 5.69 Classification-F1 0.0 on epoch=14
05/16/2022 07:49:19 - INFO - __main__ - Step 210 Global step 210 Train loss 5.43 on epoch=14
05/16/2022 07:49:21 - INFO - __main__ - Step 220 Global step 220 Train loss 5.26 on epoch=15
05/16/2022 07:49:22 - INFO - __main__ - Step 230 Global step 230 Train loss 5.54 on epoch=16
05/16/2022 07:49:23 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=17
05/16/2022 07:49:25 - INFO - __main__ - Step 250 Global step 250 Train loss 5.43 on epoch=17
05/16/2022 07:49:56 - INFO - __main__ - Global step 250 Train loss 5.41 Classification-F1 0.0 on epoch=17
05/16/2022 07:49:57 - INFO - __main__ - Step 260 Global step 260 Train loss 5.26 on epoch=18
05/16/2022 07:49:58 - INFO - __main__ - Step 270 Global step 270 Train loss 5.33 on epoch=19
05/16/2022 07:50:00 - INFO - __main__ - Step 280 Global step 280 Train loss 5.28 on epoch=19
05/16/2022 07:50:01 - INFO - __main__ - Step 290 Global step 290 Train loss 5.01 on epoch=20
05/16/2022 07:50:02 - INFO - __main__ - Step 300 Global step 300 Train loss 5.24 on epoch=21
05/16/2022 07:50:34 - INFO - __main__ - Global step 300 Train loss 5.23 Classification-F1 0.0 on epoch=21
05/16/2022 07:50:35 - INFO - __main__ - Step 310 Global step 310 Train loss 5.03 on epoch=22
05/16/2022 07:50:37 - INFO - __main__ - Step 320 Global step 320 Train loss 4.87 on epoch=22
05/16/2022 07:50:38 - INFO - __main__ - Step 330 Global step 330 Train loss 4.94 on epoch=23
05/16/2022 07:50:39 - INFO - __main__ - Step 340 Global step 340 Train loss 4.83 on epoch=24
05/16/2022 07:50:41 - INFO - __main__ - Step 350 Global step 350 Train loss 4.96 on epoch=24
05/16/2022 07:50:47 - INFO - __main__ - Global step 350 Train loss 4.93 Classification-F1 0.007532956685499058 on epoch=24
05/16/2022 07:50:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.007532956685499058 on epoch=24, global_step=350
05/16/2022 07:50:49 - INFO - __main__ - Step 360 Global step 360 Train loss 4.66 on epoch=25
05/16/2022 07:50:50 - INFO - __main__ - Step 370 Global step 370 Train loss 4.72 on epoch=26
05/16/2022 07:50:52 - INFO - __main__ - Step 380 Global step 380 Train loss 4.74 on epoch=27
05/16/2022 07:50:53 - INFO - __main__ - Step 390 Global step 390 Train loss 4.60 on epoch=27
05/16/2022 07:50:54 - INFO - __main__ - Step 400 Global step 400 Train loss 4.66 on epoch=28
05/16/2022 07:50:57 - INFO - __main__ - Global step 400 Train loss 4.68 Classification-F1 0.00847457627118644 on epoch=28
05/16/2022 07:50:57 - INFO - __main__ - Saving model with best Classification-F1: 0.007532956685499058 -> 0.00847457627118644 on epoch=28, global_step=400
05/16/2022 07:50:58 - INFO - __main__ - Step 410 Global step 410 Train loss 4.52 on epoch=29
05/16/2022 07:51:00 - INFO - __main__ - Step 420 Global step 420 Train loss 4.52 on epoch=29
05/16/2022 07:51:01 - INFO - __main__ - Step 430 Global step 430 Train loss 4.22 on epoch=30
05/16/2022 07:51:02 - INFO - __main__ - Step 440 Global step 440 Train loss 4.39 on epoch=31
05/16/2022 07:51:04 - INFO - __main__ - Step 450 Global step 450 Train loss 4.55 on epoch=32
05/16/2022 07:51:06 - INFO - __main__ - Global step 450 Train loss 4.44 Classification-F1 0.009523809523809523 on epoch=32
05/16/2022 07:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.00847457627118644 -> 0.009523809523809523 on epoch=32, global_step=450
05/16/2022 07:51:07 - INFO - __main__ - Step 460 Global step 460 Train loss 4.33 on epoch=32
05/16/2022 07:51:09 - INFO - __main__ - Step 470 Global step 470 Train loss 4.32 on epoch=33
05/16/2022 07:51:10 - INFO - __main__ - Step 480 Global step 480 Train loss 4.36 on epoch=34
05/16/2022 07:51:11 - INFO - __main__ - Step 490 Global step 490 Train loss 4.21 on epoch=34
05/16/2022 07:51:13 - INFO - __main__ - Step 500 Global step 500 Train loss 4.22 on epoch=35
05/16/2022 07:51:15 - INFO - __main__ - Global step 500 Train loss 4.29 Classification-F1 0.00935672514619883 on epoch=35
05/16/2022 07:51:16 - INFO - __main__ - Step 510 Global step 510 Train loss 4.18 on epoch=36
05/16/2022 07:51:18 - INFO - __main__ - Step 520 Global step 520 Train loss 4.23 on epoch=37
05/16/2022 07:51:19 - INFO - __main__ - Step 530 Global step 530 Train loss 3.96 on epoch=37
05/16/2022 07:51:20 - INFO - __main__ - Step 540 Global step 540 Train loss 4.21 on epoch=38
05/16/2022 07:51:22 - INFO - __main__ - Step 550 Global step 550 Train loss 4.02 on epoch=39
05/16/2022 07:51:24 - INFO - __main__ - Global step 550 Train loss 4.12 Classification-F1 0.02746283698664651 on epoch=39
05/16/2022 07:51:24 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02746283698664651 on epoch=39, global_step=550
05/16/2022 07:51:25 - INFO - __main__ - Step 560 Global step 560 Train loss 4.02 on epoch=39
05/16/2022 07:51:26 - INFO - __main__ - Step 570 Global step 570 Train loss 4.01 on epoch=40
05/16/2022 07:51:28 - INFO - __main__ - Step 580 Global step 580 Train loss 4.00 on epoch=41
05/16/2022 07:51:29 - INFO - __main__ - Step 590 Global step 590 Train loss 4.07 on epoch=42
05/16/2022 07:51:31 - INFO - __main__ - Step 600 Global step 600 Train loss 3.84 on epoch=42
05/16/2022 07:51:32 - INFO - __main__ - Global step 600 Train loss 3.99 Classification-F1 0.0331370404158758 on epoch=42
05/16/2022 07:51:32 - INFO - __main__ - Saving model with best Classification-F1: 0.02746283698664651 -> 0.0331370404158758 on epoch=42, global_step=600
05/16/2022 07:51:34 - INFO - __main__ - Step 610 Global step 610 Train loss 3.89 on epoch=43
05/16/2022 07:51:35 - INFO - __main__ - Step 620 Global step 620 Train loss 3.92 on epoch=44
05/16/2022 07:51:37 - INFO - __main__ - Step 630 Global step 630 Train loss 3.96 on epoch=44
05/16/2022 07:51:39 - INFO - __main__ - Step 640 Global step 640 Train loss 3.82 on epoch=45
05/16/2022 07:51:40 - INFO - __main__ - Step 650 Global step 650 Train loss 3.82 on epoch=46
05/16/2022 07:51:42 - INFO - __main__ - Global step 650 Train loss 3.88 Classification-F1 0.02450451334379906 on epoch=46
05/16/2022 07:51:44 - INFO - __main__ - Step 660 Global step 660 Train loss 3.88 on epoch=47
05/16/2022 07:51:45 - INFO - __main__ - Step 670 Global step 670 Train loss 3.77 on epoch=47
05/16/2022 07:51:47 - INFO - __main__ - Step 680 Global step 680 Train loss 3.80 on epoch=48
05/16/2022 07:51:48 - INFO - __main__ - Step 690 Global step 690 Train loss 3.63 on epoch=49
05/16/2022 07:51:50 - INFO - __main__ - Step 700 Global step 700 Train loss 3.58 on epoch=49
05/16/2022 07:51:51 - INFO - __main__ - Global step 700 Train loss 3.73 Classification-F1 0.0359047619047619 on epoch=49
05/16/2022 07:51:51 - INFO - __main__ - Saving model with best Classification-F1: 0.0331370404158758 -> 0.0359047619047619 on epoch=49, global_step=700
05/16/2022 07:51:53 - INFO - __main__ - Step 710 Global step 710 Train loss 3.48 on epoch=50
05/16/2022 07:51:54 - INFO - __main__ - Step 720 Global step 720 Train loss 3.51 on epoch=51
05/16/2022 07:51:56 - INFO - __main__ - Step 730 Global step 730 Train loss 3.66 on epoch=52
05/16/2022 07:51:57 - INFO - __main__ - Step 740 Global step 740 Train loss 3.42 on epoch=52
05/16/2022 07:51:58 - INFO - __main__ - Step 750 Global step 750 Train loss 3.40 on epoch=53
05/16/2022 07:52:00 - INFO - __main__ - Global step 750 Train loss 3.50 Classification-F1 0.020648259303721488 on epoch=53
05/16/2022 07:52:01 - INFO - __main__ - Step 760 Global step 760 Train loss 3.51 on epoch=54
05/16/2022 07:52:03 - INFO - __main__ - Step 770 Global step 770 Train loss 3.58 on epoch=54
05/16/2022 07:52:04 - INFO - __main__ - Step 780 Global step 780 Train loss 3.18 on epoch=55
05/16/2022 07:52:05 - INFO - __main__ - Step 790 Global step 790 Train loss 3.34 on epoch=56
05/16/2022 07:52:07 - INFO - __main__ - Step 800 Global step 800 Train loss 3.55 on epoch=57
05/16/2022 07:52:09 - INFO - __main__ - Global step 800 Train loss 3.43 Classification-F1 0.02895090490510338 on epoch=57
05/16/2022 07:52:10 - INFO - __main__ - Step 810 Global step 810 Train loss 3.20 on epoch=57
05/16/2022 07:52:12 - INFO - __main__ - Step 820 Global step 820 Train loss 3.43 on epoch=58
05/16/2022 07:52:13 - INFO - __main__ - Step 830 Global step 830 Train loss 3.24 on epoch=59
05/16/2022 07:52:14 - INFO - __main__ - Step 840 Global step 840 Train loss 3.32 on epoch=59
05/16/2022 07:52:16 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/16/2022 07:52:18 - INFO - __main__ - Global step 850 Train loss 3.28 Classification-F1 0.03400444147124499 on epoch=60
05/16/2022 07:52:19 - INFO - __main__ - Step 860 Global step 860 Train loss 3.31 on epoch=61
05/16/2022 07:52:20 - INFO - __main__ - Step 870 Global step 870 Train loss 3.33 on epoch=62
05/16/2022 07:52:22 - INFO - __main__ - Step 880 Global step 880 Train loss 3.16 on epoch=62
05/16/2022 07:52:23 - INFO - __main__ - Step 890 Global step 890 Train loss 3.15 on epoch=63
05/16/2022 07:52:25 - INFO - __main__ - Step 900 Global step 900 Train loss 3.12 on epoch=64
05/16/2022 07:52:27 - INFO - __main__ - Global step 900 Train loss 3.21 Classification-F1 0.009563658099222952 on epoch=64
05/16/2022 07:52:28 - INFO - __main__ - Step 910 Global step 910 Train loss 3.05 on epoch=64
05/16/2022 07:52:29 - INFO - __main__ - Step 920 Global step 920 Train loss 3.01 on epoch=65
05/16/2022 07:52:31 - INFO - __main__ - Step 930 Global step 930 Train loss 3.10 on epoch=66
05/16/2022 07:52:32 - INFO - __main__ - Step 940 Global step 940 Train loss 3.20 on epoch=67
05/16/2022 07:52:34 - INFO - __main__ - Step 950 Global step 950 Train loss 3.10 on epoch=67
05/16/2022 07:52:36 - INFO - __main__ - Global step 950 Train loss 3.09 Classification-F1 0.05680868838763576 on epoch=67
05/16/2022 07:52:36 - INFO - __main__ - Saving model with best Classification-F1: 0.0359047619047619 -> 0.05680868838763576 on epoch=67, global_step=950
05/16/2022 07:52:37 - INFO - __main__ - Step 960 Global step 960 Train loss 2.94 on epoch=68
05/16/2022 07:52:39 - INFO - __main__ - Step 970 Global step 970 Train loss 3.03 on epoch=69
05/16/2022 07:52:40 - INFO - __main__ - Step 980 Global step 980 Train loss 3.03 on epoch=69
05/16/2022 07:52:41 - INFO - __main__ - Step 990 Global step 990 Train loss 2.93 on epoch=70
05/16/2022 07:52:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.06 on epoch=71
05/16/2022 07:52:45 - INFO - __main__ - Global step 1000 Train loss 3.00 Classification-F1 0.060031803579098666 on epoch=71
05/16/2022 07:52:45 - INFO - __main__ - Saving model with best Classification-F1: 0.05680868838763576 -> 0.060031803579098666 on epoch=71, global_step=1000
05/16/2022 07:52:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.02 on epoch=72
05/16/2022 07:52:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.85 on epoch=72
05/16/2022 07:52:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.75 on epoch=73
05/16/2022 07:52:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.77 on epoch=74
05/16/2022 07:52:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.94 on epoch=74
05/16/2022 07:52:54 - INFO - __main__ - Global step 1050 Train loss 2.87 Classification-F1 0.026546934865900384 on epoch=74
05/16/2022 07:52:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.83 on epoch=75
05/16/2022 07:52:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.97 on epoch=76
05/16/2022 07:52:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.98 on epoch=77
05/16/2022 07:52:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.75 on epoch=77
05/16/2022 07:53:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.79 on epoch=78
05/16/2022 07:53:03 - INFO - __main__ - Global step 1100 Train loss 2.86 Classification-F1 0.031990231990231995 on epoch=78
05/16/2022 07:53:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.87 on epoch=79
05/16/2022 07:53:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.91 on epoch=79
05/16/2022 07:53:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.81 on epoch=80
05/16/2022 07:53:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.66 on epoch=81
05/16/2022 07:53:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.96 on epoch=82
05/16/2022 07:53:11 - INFO - __main__ - Global step 1150 Train loss 2.84 Classification-F1 0.024805603752972173 on epoch=82
05/16/2022 07:53:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/16/2022 07:53:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.86 on epoch=83
05/16/2022 07:53:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.78 on epoch=84
05/16/2022 07:53:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.91 on epoch=84
05/16/2022 07:53:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.78 on epoch=85
05/16/2022 07:53:20 - INFO - __main__ - Global step 1200 Train loss 2.82 Classification-F1 0.037926169499120276 on epoch=85
05/16/2022 07:53:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.79 on epoch=86
05/16/2022 07:53:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.86 on epoch=87
05/16/2022 07:53:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.71 on epoch=87
05/16/2022 07:53:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.67 on epoch=88
05/16/2022 07:53:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.69 on epoch=89
05/16/2022 07:53:29 - INFO - __main__ - Global step 1250 Train loss 2.74 Classification-F1 0.013344472291840714 on epoch=89
05/16/2022 07:53:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.82 on epoch=89
05/16/2022 07:53:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.66 on epoch=90
05/16/2022 07:53:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.64 on epoch=91
05/16/2022 07:53:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.82 on epoch=92
05/16/2022 07:53:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.67 on epoch=92
05/16/2022 07:53:38 - INFO - __main__ - Global step 1300 Train loss 2.72 Classification-F1 0.01728680676049097 on epoch=92
05/16/2022 07:53:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.79 on epoch=93
05/16/2022 07:53:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.62 on epoch=94
05/16/2022 07:53:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.84 on epoch=94
05/16/2022 07:53:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.68 on epoch=95
05/16/2022 07:53:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.72 on epoch=96
05/16/2022 07:53:48 - INFO - __main__ - Global step 1350 Train loss 2.73 Classification-F1 0.01719986240110079 on epoch=96
05/16/2022 07:53:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.83 on epoch=97
05/16/2022 07:53:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.62 on epoch=97
05/16/2022 07:53:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.72 on epoch=98
05/16/2022 07:53:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.65 on epoch=99
05/16/2022 07:53:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.76 on epoch=99
05/16/2022 07:53:57 - INFO - __main__ - Global step 1400 Train loss 2.71 Classification-F1 0.045825946981274325 on epoch=99
05/16/2022 07:53:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.71 on epoch=100
05/16/2022 07:53:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.55 on epoch=101
05/16/2022 07:54:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.69 on epoch=102
05/16/2022 07:54:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.50 on epoch=102
05/16/2022 07:54:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.52 on epoch=103
05/16/2022 07:54:05 - INFO - __main__ - Global step 1450 Train loss 2.59 Classification-F1 0.04442200471587681 on epoch=103
05/16/2022 07:54:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.55 on epoch=104
05/16/2022 07:54:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.51 on epoch=104
05/16/2022 07:54:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.38 on epoch=105
05/16/2022 07:54:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.42 on epoch=106
05/16/2022 07:54:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.71 on epoch=107
05/16/2022 07:54:14 - INFO - __main__ - Global step 1500 Train loss 2.52 Classification-F1 0.03651726226529376 on epoch=107
05/16/2022 07:54:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.58 on epoch=107
05/16/2022 07:54:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.52 on epoch=108
05/16/2022 07:54:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.58 on epoch=109
05/16/2022 07:54:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.57 on epoch=109
05/16/2022 07:54:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.52 on epoch=110
05/16/2022 07:54:23 - INFO - __main__ - Global step 1550 Train loss 2.56 Classification-F1 0.014835973915257802 on epoch=110
05/16/2022 07:54:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.49 on epoch=111
05/16/2022 07:54:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.51 on epoch=112
05/16/2022 07:54:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.37 on epoch=112
05/16/2022 07:54:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.55 on epoch=113
05/16/2022 07:54:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.58 on epoch=114
05/16/2022 07:54:32 - INFO - __main__ - Global step 1600 Train loss 2.50 Classification-F1 0.009523809523809523 on epoch=114
05/16/2022 07:54:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.55 on epoch=114
05/16/2022 07:54:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.36 on epoch=115
05/16/2022 07:54:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.25 on epoch=116
05/16/2022 07:54:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.55 on epoch=117
05/16/2022 07:54:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.39 on epoch=117
05/16/2022 07:54:41 - INFO - __main__ - Global step 1650 Train loss 2.42 Classification-F1 0.009523809523809523 on epoch=117
05/16/2022 07:54:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.46 on epoch=118
05/16/2022 07:54:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.39 on epoch=119
05/16/2022 07:54:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.44 on epoch=119
05/16/2022 07:54:47 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.21 on epoch=120
05/16/2022 07:54:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.47 on epoch=121
05/16/2022 07:54:51 - INFO - __main__ - Global step 1700 Train loss 2.39 Classification-F1 0.009563658099222952 on epoch=121
05/16/2022 07:54:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.41 on epoch=122
05/16/2022 07:54:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.26 on epoch=122
05/16/2022 07:54:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.44 on epoch=123
05/16/2022 07:54:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.37 on epoch=124
05/16/2022 07:54:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.45 on epoch=124
05/16/2022 07:54:59 - INFO - __main__ - Global step 1750 Train loss 2.39 Classification-F1 0.029976649365859333 on epoch=124
05/16/2022 07:55:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.30 on epoch=125
05/16/2022 07:55:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.38 on epoch=126
05/16/2022 07:55:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.55 on epoch=127
05/16/2022 07:55:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.25 on epoch=127
05/16/2022 07:55:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.42 on epoch=128
05/16/2022 07:55:09 - INFO - __main__ - Global step 1800 Train loss 2.38 Classification-F1 0.021886046995217297 on epoch=128
05/16/2022 07:55:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.57 on epoch=129
05/16/2022 07:55:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.54 on epoch=129
05/16/2022 07:55:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.19 on epoch=130
05/16/2022 07:55:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.33 on epoch=131
05/16/2022 07:55:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.40 on epoch=132
05/16/2022 07:55:18 - INFO - __main__ - Global step 1850 Train loss 2.40 Classification-F1 0.042642069496289445 on epoch=132
05/16/2022 07:55:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.35 on epoch=132
05/16/2022 07:55:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.20 on epoch=133
05/16/2022 07:55:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.24 on epoch=134
05/16/2022 07:55:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.25 on epoch=134
05/16/2022 07:55:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.12 on epoch=135
05/16/2022 07:55:27 - INFO - __main__ - Global step 1900 Train loss 2.23 Classification-F1 0.03963713631905852 on epoch=135
05/16/2022 07:55:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.34 on epoch=136
05/16/2022 07:55:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.44 on epoch=137
05/16/2022 07:55:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.15 on epoch=137
05/16/2022 07:55:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.16 on epoch=138
05/16/2022 07:55:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.26 on epoch=139
05/16/2022 07:55:37 - INFO - __main__ - Global step 1950 Train loss 2.27 Classification-F1 0.01834124954329558 on epoch=139
05/16/2022 07:55:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.14 on epoch=139
05/16/2022 07:55:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.11 on epoch=140
05/16/2022 07:55:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.06 on epoch=141
05/16/2022 07:55:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.26 on epoch=142
05/16/2022 07:55:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.20 on epoch=142
05/16/2022 07:55:46 - INFO - __main__ - Global step 2000 Train loss 2.15 Classification-F1 0.027881608783864423 on epoch=142
05/16/2022 07:55:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.14 on epoch=143
05/16/2022 07:55:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.19 on epoch=144
05/16/2022 07:55:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.20 on epoch=144
05/16/2022 07:55:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.10 on epoch=145
05/16/2022 07:55:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.95 on epoch=146
05/16/2022 07:55:55 - INFO - __main__ - Global step 2050 Train loss 2.12 Classification-F1 0.02495113257445096 on epoch=146
05/16/2022 07:55:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.22 on epoch=147
05/16/2022 07:55:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.12 on epoch=147
05/16/2022 07:55:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.10 on epoch=148
05/16/2022 07:56:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.16 on epoch=149
05/16/2022 07:56:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.30 on epoch=149
05/16/2022 07:56:04 - INFO - __main__ - Global step 2100 Train loss 2.18 Classification-F1 0.024543794455298886 on epoch=149
05/16/2022 07:56:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.21 on epoch=150
05/16/2022 07:56:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.18 on epoch=151
05/16/2022 07:56:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.16 on epoch=152
05/16/2022 07:56:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.04 on epoch=152
05/16/2022 07:56:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.03 on epoch=153
05/16/2022 07:56:12 - INFO - __main__ - Global step 2150 Train loss 2.12 Classification-F1 0.009563658099222952 on epoch=153
05/16/2022 07:56:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.24 on epoch=154
05/16/2022 07:56:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.99 on epoch=154
05/16/2022 07:56:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.08 on epoch=155
05/16/2022 07:56:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.09 on epoch=156
05/16/2022 07:56:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.08 on epoch=157
05/16/2022 07:56:20 - INFO - __main__ - Global step 2200 Train loss 2.10 Classification-F1 0.029605169078853293 on epoch=157
05/16/2022 07:56:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.93 on epoch=157
05/16/2022 07:56:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.04 on epoch=158
05/16/2022 07:56:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.11 on epoch=159
05/16/2022 07:56:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.99 on epoch=159
05/16/2022 07:56:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.98 on epoch=160
05/16/2022 07:56:29 - INFO - __main__ - Global step 2250 Train loss 2.01 Classification-F1 0.02123885083526339 on epoch=160
05/16/2022 07:56:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.00 on epoch=161
05/16/2022 07:56:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.23 on epoch=162
05/16/2022 07:56:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.05 on epoch=162
05/16/2022 07:56:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.85 on epoch=163
05/16/2022 07:56:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.04 on epoch=164
05/16/2022 07:56:37 - INFO - __main__ - Global step 2300 Train loss 2.03 Classification-F1 0.009726443768996961 on epoch=164
05/16/2022 07:56:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.97 on epoch=164
05/16/2022 07:56:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.96 on epoch=165
05/16/2022 07:56:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.98 on epoch=166
05/16/2022 07:56:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.05 on epoch=167
05/16/2022 07:56:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.95 on epoch=167
05/16/2022 07:56:46 - INFO - __main__ - Global step 2350 Train loss 1.98 Classification-F1 0.009644364074743823 on epoch=167
05/16/2022 07:56:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.05 on epoch=168
05/16/2022 07:56:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.00 on epoch=169
05/16/2022 07:56:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.85 on epoch=169
05/16/2022 07:56:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.92 on epoch=170
05/16/2022 07:56:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.90 on epoch=171
05/16/2022 07:56:54 - INFO - __main__ - Global step 2400 Train loss 1.94 Classification-F1 0.009563658099222952 on epoch=171
05/16/2022 07:56:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.95 on epoch=172
05/16/2022 07:56:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.91 on epoch=172
05/16/2022 07:56:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.84 on epoch=173
05/16/2022 07:57:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.91 on epoch=174
05/16/2022 07:57:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.88 on epoch=174
05/16/2022 07:57:04 - INFO - __main__ - Global step 2450 Train loss 1.90 Classification-F1 0.031085082525517876 on epoch=174
05/16/2022 07:57:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.89 on epoch=175
05/16/2022 07:57:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.84 on epoch=176
05/16/2022 07:57:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.83 on epoch=177
05/16/2022 07:57:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.92 on epoch=177
05/16/2022 07:57:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.85 on epoch=178
05/16/2022 07:57:13 - INFO - __main__ - Global step 2500 Train loss 1.86 Classification-F1 0.024212759014521128 on epoch=178
05/16/2022 07:57:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.89 on epoch=179
05/16/2022 07:57:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.78 on epoch=179
05/16/2022 07:57:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.81 on epoch=180
05/16/2022 07:57:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.92 on epoch=181
05/16/2022 07:57:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.91 on epoch=182
05/16/2022 07:57:21 - INFO - __main__ - Global step 2550 Train loss 1.86 Classification-F1 0.027898027898027897 on epoch=182
05/16/2022 07:57:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.91 on epoch=182
05/16/2022 07:57:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.88 on epoch=183
05/16/2022 07:57:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.87 on epoch=184
05/16/2022 07:57:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.85 on epoch=184
05/16/2022 07:57:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.76 on epoch=185
05/16/2022 07:57:29 - INFO - __main__ - Global step 2600 Train loss 1.85 Classification-F1 0.02358662613981763 on epoch=185
05/16/2022 07:57:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.90 on epoch=186
05/16/2022 07:57:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.83 on epoch=187
05/16/2022 07:57:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.76 on epoch=187
05/16/2022 07:57:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.80 on epoch=188
05/16/2022 07:57:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.91 on epoch=189
05/16/2022 07:57:38 - INFO - __main__ - Global step 2650 Train loss 1.84 Classification-F1 0.024117497132662164 on epoch=189
05/16/2022 07:57:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.72 on epoch=189
05/16/2022 07:57:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.80 on epoch=190
05/16/2022 07:57:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.82 on epoch=191
05/16/2022 07:57:43 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.77 on epoch=192
05/16/2022 07:57:45 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.83 on epoch=192
05/16/2022 07:57:47 - INFO - __main__ - Global step 2700 Train loss 1.79 Classification-F1 0.016570730856445143 on epoch=192
05/16/2022 07:57:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.80 on epoch=193
05/16/2022 07:57:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.85 on epoch=194
05/16/2022 07:57:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.79 on epoch=194
05/16/2022 07:57:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.81 on epoch=195
05/16/2022 07:57:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.86 on epoch=196
05/16/2022 07:57:56 - INFO - __main__ - Global step 2750 Train loss 1.82 Classification-F1 0.009685230024213076 on epoch=196
05/16/2022 07:57:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.84 on epoch=197
05/16/2022 07:57:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.79 on epoch=197
05/16/2022 07:57:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.88 on epoch=198
05/16/2022 07:58:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.83 on epoch=199
05/16/2022 07:58:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.84 on epoch=199
05/16/2022 07:58:05 - INFO - __main__ - Global step 2800 Train loss 1.84 Classification-F1 0.00976800976800977 on epoch=199
05/16/2022 07:58:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.65 on epoch=200
05/16/2022 07:58:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.79 on epoch=201
05/16/2022 07:58:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.69 on epoch=202
05/16/2022 07:58:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.92 on epoch=202
05/16/2022 07:58:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.78 on epoch=203
05/16/2022 07:58:13 - INFO - __main__ - Global step 2850 Train loss 1.76 Classification-F1 0.025558245897228944 on epoch=203
05/16/2022 07:58:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.82 on epoch=204
05/16/2022 07:58:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.74 on epoch=204
05/16/2022 07:58:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.71 on epoch=205
05/16/2022 07:58:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.85 on epoch=206
05/16/2022 07:58:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.71 on epoch=207
05/16/2022 07:58:22 - INFO - __main__ - Global step 2900 Train loss 1.77 Classification-F1 0.01800720288115246 on epoch=207
05/16/2022 07:58:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.62 on epoch=207
05/16/2022 07:58:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.79 on epoch=208
05/16/2022 07:58:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.67 on epoch=209
05/16/2022 07:58:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.71 on epoch=209
05/16/2022 07:58:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.68 on epoch=210
05/16/2022 07:58:30 - INFO - __main__ - Global step 2950 Train loss 1.69 Classification-F1 0.04142420226812241 on epoch=210
05/16/2022 07:58:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.69 on epoch=211
05/16/2022 07:58:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.84 on epoch=212
05/16/2022 07:58:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.76 on epoch=212
05/16/2022 07:58:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.77 on epoch=213
05/16/2022 07:58:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.77 on epoch=214
05/16/2022 07:58:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:58:38 - INFO - __main__ - Printing 3 examples
05/16/2022 07:58:38 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 07:58:38 - INFO - __main__ - ['Animal']
05/16/2022 07:58:38 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 07:58:38 - INFO - __main__ - ['Animal']
05/16/2022 07:58:38 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 07:58:38 - INFO - __main__ - ['Animal']
05/16/2022 07:58:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:58:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:58:38 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:58:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:58:38 - INFO - __main__ - Printing 3 examples
05/16/2022 07:58:38 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 07:58:38 - INFO - __main__ - ['Animal']
05/16/2022 07:58:38 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 07:58:38 - INFO - __main__ - ['Animal']
05/16/2022 07:58:38 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 07:58:38 - INFO - __main__ - ['Animal']
05/16/2022 07:58:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:58:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:58:38 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:58:39 - INFO - __main__ - Global step 3000 Train loss 1.77 Classification-F1 0.01804772541928164 on epoch=214
05/16/2022 07:58:39 - INFO - __main__ - save last model!
05/16/2022 07:58:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 07:58:39 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 07:58:39 - INFO - __main__ - Printing 3 examples
05/16/2022 07:58:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 07:58:39 - INFO - __main__ - ['Animal']
05/16/2022 07:58:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 07:58:39 - INFO - __main__ - ['Animal']
05/16/2022 07:58:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 07:58:39 - INFO - __main__ - ['Village']
05/16/2022 07:58:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:58:41 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:58:44 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:58:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:58:44 - INFO - __main__ - Starting training!
05/16/2022 07:58:44 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 07:59:22 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/16/2022 07:59:22 - INFO - __main__ - Classification-F1 on test data: 0.0106
05/16/2022 07:59:23 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.060031803579098666, test_performance=0.010601200001071525
05/16/2022 07:59:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/16/2022 07:59:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:59:24 - INFO - __main__ - Printing 3 examples
05/16/2022 07:59:24 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 07:59:24 - INFO - __main__ - ['Animal']
05/16/2022 07:59:24 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 07:59:24 - INFO - __main__ - ['Animal']
05/16/2022 07:59:24 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 07:59:24 - INFO - __main__ - ['Animal']
05/16/2022 07:59:24 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:59:24 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:59:24 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 07:59:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 07:59:24 - INFO - __main__ - Printing 3 examples
05/16/2022 07:59:24 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 07:59:24 - INFO - __main__ - ['Animal']
05/16/2022 07:59:24 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 07:59:24 - INFO - __main__ - ['Animal']
05/16/2022 07:59:24 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 07:59:24 - INFO - __main__ - ['Animal']
05/16/2022 07:59:24 - INFO - __main__ - Tokenizing Input ...
05/16/2022 07:59:24 - INFO - __main__ - Tokenizing Output ...
05/16/2022 07:59:25 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 07:59:30 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 07:59:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 07:59:30 - INFO - __main__ - Starting training!
05/16/2022 07:59:32 - INFO - __main__ - Step 10 Global step 10 Train loss 7.41 on epoch=0
05/16/2022 07:59:33 - INFO - __main__ - Step 20 Global step 20 Train loss 7.46 on epoch=1
05/16/2022 07:59:34 - INFO - __main__ - Step 30 Global step 30 Train loss 7.09 on epoch=2
05/16/2022 07:59:36 - INFO - __main__ - Step 40 Global step 40 Train loss 6.98 on epoch=2
05/16/2022 07:59:37 - INFO - __main__ - Step 50 Global step 50 Train loss 6.86 on epoch=3
05/16/2022 08:00:03 - INFO - __main__ - Global step 50 Train loss 7.16 Classification-F1 0.0 on epoch=3
05/16/2022 08:00:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 08:00:04 - INFO - __main__ - Step 60 Global step 60 Train loss 6.86 on epoch=4
05/16/2022 08:00:05 - INFO - __main__ - Step 70 Global step 70 Train loss 6.79 on epoch=4
05/16/2022 08:00:07 - INFO - __main__ - Step 80 Global step 80 Train loss 6.50 on epoch=5
05/16/2022 08:00:08 - INFO - __main__ - Step 90 Global step 90 Train loss 6.58 on epoch=6
05/16/2022 08:00:09 - INFO - __main__ - Step 100 Global step 100 Train loss 6.51 on epoch=7
05/16/2022 08:01:17 - INFO - __main__ - Global step 100 Train loss 6.65 Classification-F1 0.0 on epoch=7
05/16/2022 08:01:19 - INFO - __main__ - Step 110 Global step 110 Train loss 6.40 on epoch=7
05/16/2022 08:01:20 - INFO - __main__ - Step 120 Global step 120 Train loss 6.30 on epoch=8
05/16/2022 08:01:21 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/16/2022 08:01:23 - INFO - __main__ - Step 140 Global step 140 Train loss 6.27 on epoch=9
05/16/2022 08:01:24 - INFO - __main__ - Step 150 Global step 150 Train loss 5.96 on epoch=10
05/16/2022 08:02:37 - INFO - __main__ - Global step 150 Train loss 6.26 Classification-F1 0.0 on epoch=10
05/16/2022 08:02:39 - INFO - __main__ - Step 160 Global step 160 Train loss 6.31 on epoch=11
05/16/2022 08:02:40 - INFO - __main__ - Step 170 Global step 170 Train loss 6.02 on epoch=12
05/16/2022 08:02:41 - INFO - __main__ - Step 180 Global step 180 Train loss 5.85 on epoch=12
05/16/2022 08:02:43 - INFO - __main__ - Step 190 Global step 190 Train loss 5.84 on epoch=13
05/16/2022 08:02:44 - INFO - __main__ - Step 200 Global step 200 Train loss 5.98 on epoch=14
05/16/2022 08:03:55 - INFO - __main__ - Global step 200 Train loss 6.00 Classification-F1 0.0 on epoch=14
05/16/2022 08:03:57 - INFO - __main__ - Step 210 Global step 210 Train loss 5.86 on epoch=14
05/16/2022 08:03:58 - INFO - __main__ - Step 220 Global step 220 Train loss 5.49 on epoch=15
05/16/2022 08:03:59 - INFO - __main__ - Step 230 Global step 230 Train loss 5.74 on epoch=16
05/16/2022 08:04:01 - INFO - __main__ - Step 240 Global step 240 Train loss 5.50 on epoch=17
05/16/2022 08:04:02 - INFO - __main__ - Step 250 Global step 250 Train loss 5.51 on epoch=17
05/16/2022 08:04:30 - INFO - __main__ - Global step 250 Train loss 5.62 Classification-F1 0.0019157088122605363 on epoch=17
05/16/2022 08:04:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0019157088122605363 on epoch=17, global_step=250
05/16/2022 08:04:32 - INFO - __main__ - Step 260 Global step 260 Train loss 5.37 on epoch=18
05/16/2022 08:04:33 - INFO - __main__ - Step 270 Global step 270 Train loss 5.54 on epoch=19
05/16/2022 08:04:34 - INFO - __main__ - Step 280 Global step 280 Train loss 5.62 on epoch=19
05/16/2022 08:04:36 - INFO - __main__ - Step 290 Global step 290 Train loss 5.30 on epoch=20
05/16/2022 08:04:37 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/16/2022 08:04:55 - INFO - __main__ - Global step 300 Train loss 5.45 Classification-F1 0.0037993920972644382 on epoch=21
05/16/2022 08:04:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0019157088122605363 -> 0.0037993920972644382 on epoch=21, global_step=300
05/16/2022 08:04:57 - INFO - __main__ - Step 310 Global step 310 Train loss 5.30 on epoch=22
05/16/2022 08:04:58 - INFO - __main__ - Step 320 Global step 320 Train loss 5.25 on epoch=22
05/16/2022 08:04:59 - INFO - __main__ - Step 330 Global step 330 Train loss 5.18 on epoch=23
05/16/2022 08:05:01 - INFO - __main__ - Step 340 Global step 340 Train loss 5.22 on epoch=24
05/16/2022 08:05:02 - INFO - __main__ - Step 350 Global step 350 Train loss 5.04 on epoch=24
05/16/2022 08:05:10 - INFO - __main__ - Global step 350 Train loss 5.20 Classification-F1 0.008695652173913044 on epoch=24
05/16/2022 08:05:10 - INFO - __main__ - Saving model with best Classification-F1: 0.0037993920972644382 -> 0.008695652173913044 on epoch=24, global_step=350
05/16/2022 08:05:11 - INFO - __main__ - Step 360 Global step 360 Train loss 4.77 on epoch=25
05/16/2022 08:05:12 - INFO - __main__ - Step 370 Global step 370 Train loss 5.00 on epoch=26
05/16/2022 08:05:14 - INFO - __main__ - Step 380 Global step 380 Train loss 4.96 on epoch=27
05/16/2022 08:05:15 - INFO - __main__ - Step 390 Global step 390 Train loss 4.81 on epoch=27
05/16/2022 08:05:16 - INFO - __main__ - Step 400 Global step 400 Train loss 4.80 on epoch=28
05/16/2022 08:05:24 - INFO - __main__ - Global step 400 Train loss 4.87 Classification-F1 0.008658008658008658 on epoch=28
05/16/2022 08:05:25 - INFO - __main__ - Step 410 Global step 410 Train loss 4.80 on epoch=29
05/16/2022 08:05:27 - INFO - __main__ - Step 420 Global step 420 Train loss 4.80 on epoch=29
05/16/2022 08:05:28 - INFO - __main__ - Step 430 Global step 430 Train loss 4.71 on epoch=30
05/16/2022 08:05:29 - INFO - __main__ - Step 440 Global step 440 Train loss 4.72 on epoch=31
05/16/2022 08:05:31 - INFO - __main__ - Step 450 Global step 450 Train loss 4.77 on epoch=32
05/16/2022 08:05:33 - INFO - __main__ - Global step 450 Train loss 4.76 Classification-F1 0.009523809523809523 on epoch=32
05/16/2022 08:05:33 - INFO - __main__ - Saving model with best Classification-F1: 0.008695652173913044 -> 0.009523809523809523 on epoch=32, global_step=450
05/16/2022 08:05:34 - INFO - __main__ - Step 460 Global step 460 Train loss 4.44 on epoch=32
05/16/2022 08:05:36 - INFO - __main__ - Step 470 Global step 470 Train loss 4.66 on epoch=33
05/16/2022 08:05:37 - INFO - __main__ - Step 480 Global step 480 Train loss 4.44 on epoch=34
05/16/2022 08:05:38 - INFO - __main__ - Step 490 Global step 490 Train loss 4.52 on epoch=34
05/16/2022 08:05:39 - INFO - __main__ - Step 500 Global step 500 Train loss 4.23 on epoch=35
05/16/2022 08:05:41 - INFO - __main__ - Global step 500 Train loss 4.46 Classification-F1 0.009523809523809523 on epoch=35
05/16/2022 08:05:43 - INFO - __main__ - Step 510 Global step 510 Train loss 4.35 on epoch=36
05/16/2022 08:05:44 - INFO - __main__ - Step 520 Global step 520 Train loss 4.39 on epoch=37
05/16/2022 08:05:45 - INFO - __main__ - Step 530 Global step 530 Train loss 4.21 on epoch=37
05/16/2022 08:05:47 - INFO - __main__ - Step 540 Global step 540 Train loss 4.21 on epoch=38
05/16/2022 08:05:48 - INFO - __main__ - Step 550 Global step 550 Train loss 4.08 on epoch=39
05/16/2022 08:05:50 - INFO - __main__ - Global step 550 Train loss 4.25 Classification-F1 0.013888762148104212 on epoch=39
05/16/2022 08:05:50 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.013888762148104212 on epoch=39, global_step=550
05/16/2022 08:05:51 - INFO - __main__ - Step 560 Global step 560 Train loss 4.16 on epoch=39
05/16/2022 08:05:53 - INFO - __main__ - Step 570 Global step 570 Train loss 3.98 on epoch=40
05/16/2022 08:05:54 - INFO - __main__ - Step 580 Global step 580 Train loss 3.97 on epoch=41
05/16/2022 08:05:55 - INFO - __main__ - Step 590 Global step 590 Train loss 4.03 on epoch=42
05/16/2022 08:05:57 - INFO - __main__ - Step 600 Global step 600 Train loss 3.78 on epoch=42
05/16/2022 08:05:58 - INFO - __main__ - Global step 600 Train loss 3.99 Classification-F1 0.014366007682124954 on epoch=42
05/16/2022 08:05:59 - INFO - __main__ - Saving model with best Classification-F1: 0.013888762148104212 -> 0.014366007682124954 on epoch=42, global_step=600
05/16/2022 08:06:00 - INFO - __main__ - Step 610 Global step 610 Train loss 3.96 on epoch=43
05/16/2022 08:06:01 - INFO - __main__ - Step 620 Global step 620 Train loss 3.75 on epoch=44
05/16/2022 08:06:03 - INFO - __main__ - Step 630 Global step 630 Train loss 3.87 on epoch=44
05/16/2022 08:06:04 - INFO - __main__ - Step 640 Global step 640 Train loss 3.72 on epoch=45
05/16/2022 08:06:05 - INFO - __main__ - Step 650 Global step 650 Train loss 3.85 on epoch=46
05/16/2022 08:06:07 - INFO - __main__ - Global step 650 Train loss 3.83 Classification-F1 0.01900200021054848 on epoch=46
05/16/2022 08:06:07 - INFO - __main__ - Saving model with best Classification-F1: 0.014366007682124954 -> 0.01900200021054848 on epoch=46, global_step=650
05/16/2022 08:06:09 - INFO - __main__ - Step 660 Global step 660 Train loss 3.83 on epoch=47
05/16/2022 08:06:10 - INFO - __main__ - Step 670 Global step 670 Train loss 3.52 on epoch=47
05/16/2022 08:06:12 - INFO - __main__ - Step 680 Global step 680 Train loss 3.68 on epoch=48
05/16/2022 08:06:13 - INFO - __main__ - Step 690 Global step 690 Train loss 3.69 on epoch=49
05/16/2022 08:06:14 - INFO - __main__ - Step 700 Global step 700 Train loss 3.71 on epoch=49
05/16/2022 08:06:16 - INFO - __main__ - Global step 700 Train loss 3.69 Classification-F1 0.009726443768996961 on epoch=49
05/16/2022 08:06:18 - INFO - __main__ - Step 710 Global step 710 Train loss 3.65 on epoch=50
05/16/2022 08:06:19 - INFO - __main__ - Step 720 Global step 720 Train loss 3.66 on epoch=51
05/16/2022 08:06:21 - INFO - __main__ - Step 730 Global step 730 Train loss 3.66 on epoch=52
05/16/2022 08:06:22 - INFO - __main__ - Step 740 Global step 740 Train loss 3.52 on epoch=52
05/16/2022 08:06:23 - INFO - __main__ - Step 750 Global step 750 Train loss 3.61 on epoch=53
05/16/2022 08:06:25 - INFO - __main__ - Global step 750 Train loss 3.62 Classification-F1 0.022755022755022756 on epoch=53
05/16/2022 08:06:25 - INFO - __main__ - Saving model with best Classification-F1: 0.01900200021054848 -> 0.022755022755022756 on epoch=53, global_step=750
05/16/2022 08:06:27 - INFO - __main__ - Step 760 Global step 760 Train loss 3.46 on epoch=54
05/16/2022 08:06:28 - INFO - __main__ - Step 770 Global step 770 Train loss 3.54 on epoch=54
05/16/2022 08:06:29 - INFO - __main__ - Step 780 Global step 780 Train loss 3.35 on epoch=55
05/16/2022 08:06:31 - INFO - __main__ - Step 790 Global step 790 Train loss 3.33 on epoch=56
05/16/2022 08:06:32 - INFO - __main__ - Step 800 Global step 800 Train loss 3.63 on epoch=57
05/16/2022 08:06:34 - INFO - __main__ - Global step 800 Train loss 3.46 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 08:06:35 - INFO - __main__ - Step 810 Global step 810 Train loss 3.30 on epoch=57
05/16/2022 08:06:37 - INFO - __main__ - Step 820 Global step 820 Train loss 3.34 on epoch=58
05/16/2022 08:06:38 - INFO - __main__ - Step 830 Global step 830 Train loss 3.37 on epoch=59
05/16/2022 08:06:39 - INFO - __main__ - Step 840 Global step 840 Train loss 3.28 on epoch=59
05/16/2022 08:06:41 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/16/2022 08:06:43 - INFO - __main__ - Global step 850 Train loss 3.30 Classification-F1 0.010342598577892695 on epoch=60
05/16/2022 08:06:44 - INFO - __main__ - Step 860 Global step 860 Train loss 3.17 on epoch=61
05/16/2022 08:06:45 - INFO - __main__ - Step 870 Global step 870 Train loss 3.31 on epoch=62
05/16/2022 08:06:47 - INFO - __main__ - Step 880 Global step 880 Train loss 3.21 on epoch=62
05/16/2022 08:06:48 - INFO - __main__ - Step 890 Global step 890 Train loss 3.22 on epoch=63
05/16/2022 08:06:49 - INFO - __main__ - Step 900 Global step 900 Train loss 3.25 on epoch=64
05/16/2022 08:06:51 - INFO - __main__ - Global step 900 Train loss 3.23 Classification-F1 0.027015437392795882 on epoch=64
05/16/2022 08:06:51 - INFO - __main__ - Saving model with best Classification-F1: 0.022755022755022756 -> 0.027015437392795882 on epoch=64, global_step=900
05/16/2022 08:06:53 - INFO - __main__ - Step 910 Global step 910 Train loss 3.23 on epoch=64
05/16/2022 08:06:54 - INFO - __main__ - Step 920 Global step 920 Train loss 2.98 on epoch=65
05/16/2022 08:06:55 - INFO - __main__ - Step 930 Global step 930 Train loss 3.14 on epoch=66
05/16/2022 08:06:57 - INFO - __main__ - Step 940 Global step 940 Train loss 3.43 on epoch=67
05/16/2022 08:06:58 - INFO - __main__ - Step 950 Global step 950 Train loss 3.11 on epoch=67
05/16/2022 08:07:00 - INFO - __main__ - Global step 950 Train loss 3.18 Classification-F1 0.009523809523809523 on epoch=67
05/16/2022 08:07:01 - INFO - __main__ - Step 960 Global step 960 Train loss 3.02 on epoch=68
05/16/2022 08:07:03 - INFO - __main__ - Step 970 Global step 970 Train loss 3.09 on epoch=69
05/16/2022 08:07:04 - INFO - __main__ - Step 980 Global step 980 Train loss 3.19 on epoch=69
05/16/2022 08:07:05 - INFO - __main__ - Step 990 Global step 990 Train loss 3.00 on epoch=70
05/16/2022 08:07:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.00 on epoch=71
05/16/2022 08:07:09 - INFO - __main__ - Global step 1000 Train loss 3.06 Classification-F1 0.05026372121545007 on epoch=71
05/16/2022 08:07:09 - INFO - __main__ - Saving model with best Classification-F1: 0.027015437392795882 -> 0.05026372121545007 on epoch=71, global_step=1000
05/16/2022 08:07:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.25 on epoch=72
05/16/2022 08:07:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.95 on epoch=72
05/16/2022 08:07:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.04 on epoch=73
05/16/2022 08:07:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.95 on epoch=74
05/16/2022 08:07:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.98 on epoch=74
05/16/2022 08:07:17 - INFO - __main__ - Global step 1050 Train loss 3.03 Classification-F1 0.04220175308400969 on epoch=74
05/16/2022 08:07:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.86 on epoch=75
05/16/2022 08:07:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.91 on epoch=76
05/16/2022 08:07:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.11 on epoch=77
05/16/2022 08:07:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.76 on epoch=77
05/16/2022 08:07:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.85 on epoch=78
05/16/2022 08:07:28 - INFO - __main__ - Global step 1100 Train loss 2.90 Classification-F1 0.04597517464338154 on epoch=78
05/16/2022 08:07:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.94 on epoch=79
05/16/2022 08:07:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.99 on epoch=79
05/16/2022 08:07:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.93 on epoch=80
05/16/2022 08:07:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.83 on epoch=81
05/16/2022 08:07:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.01 on epoch=82
05/16/2022 08:07:37 - INFO - __main__ - Global step 1150 Train loss 2.94 Classification-F1 0.038212094653812444 on epoch=82
05/16/2022 08:07:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.86 on epoch=82
05/16/2022 08:07:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.82 on epoch=83
05/16/2022 08:07:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.72 on epoch=84
05/16/2022 08:07:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.87 on epoch=84
05/16/2022 08:07:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.75 on epoch=85
05/16/2022 08:07:45 - INFO - __main__ - Global step 1200 Train loss 2.80 Classification-F1 0.021293236782902136 on epoch=85
05/16/2022 08:07:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.62 on epoch=86
05/16/2022 08:07:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.94 on epoch=87
05/16/2022 08:07:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.66 on epoch=87
05/16/2022 08:07:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.68 on epoch=88
05/16/2022 08:07:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.81 on epoch=89
05/16/2022 08:07:54 - INFO - __main__ - Global step 1250 Train loss 2.74 Classification-F1 0.01835419482478306 on epoch=89
05/16/2022 08:07:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.82 on epoch=89
05/16/2022 08:07:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.73 on epoch=90
05/16/2022 08:07:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.75 on epoch=91
05/16/2022 08:07:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.87 on epoch=92
05/16/2022 08:08:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.72 on epoch=92
05/16/2022 08:08:03 - INFO - __main__ - Global step 1300 Train loss 2.78 Classification-F1 0.05359660311493018 on epoch=92
05/16/2022 08:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.05026372121545007 -> 0.05359660311493018 on epoch=92, global_step=1300
05/16/2022 08:08:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.88 on epoch=93
05/16/2022 08:08:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.88 on epoch=94
05/16/2022 08:08:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.87 on epoch=94
05/16/2022 08:08:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.76 on epoch=95
05/16/2022 08:08:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.68 on epoch=96
05/16/2022 08:08:11 - INFO - __main__ - Global step 1350 Train loss 2.81 Classification-F1 0.05269536019536019 on epoch=96
05/16/2022 08:08:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.83 on epoch=97
05/16/2022 08:08:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.61 on epoch=97
05/16/2022 08:08:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.68 on epoch=98
05/16/2022 08:08:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.54 on epoch=99
05/16/2022 08:08:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.79 on epoch=99
05/16/2022 08:08:20 - INFO - __main__ - Global step 1400 Train loss 2.69 Classification-F1 0.02796451914098973 on epoch=99
05/16/2022 08:08:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.69 on epoch=100
05/16/2022 08:08:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.77 on epoch=101
05/16/2022 08:08:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.78 on epoch=102
05/16/2022 08:08:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.69 on epoch=102
05/16/2022 08:08:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.80 on epoch=103
05/16/2022 08:08:29 - INFO - __main__ - Global step 1450 Train loss 2.75 Classification-F1 0.04128609263787635 on epoch=103
05/16/2022 08:08:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.62 on epoch=104
05/16/2022 08:08:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.69 on epoch=104
05/16/2022 08:08:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.69 on epoch=105
05/16/2022 08:08:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.58 on epoch=106
05/16/2022 08:08:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.76 on epoch=107
05/16/2022 08:08:38 - INFO - __main__ - Global step 1500 Train loss 2.67 Classification-F1 0.016683433936955063 on epoch=107
05/16/2022 08:08:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.68 on epoch=107
05/16/2022 08:08:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.66 on epoch=108
05/16/2022 08:08:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.47 on epoch=109
05/16/2022 08:08:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=109
05/16/2022 08:08:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.62 on epoch=110
05/16/2022 08:08:46 - INFO - __main__ - Global step 1550 Train loss 2.60 Classification-F1 0.016495956873315364 on epoch=110
05/16/2022 08:08:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.53 on epoch=111
05/16/2022 08:08:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.50 on epoch=112
05/16/2022 08:08:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.56 on epoch=112
05/16/2022 08:08:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.67 on epoch=113
05/16/2022 08:08:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.72 on epoch=114
05/16/2022 08:08:55 - INFO - __main__ - Global step 1600 Train loss 2.60 Classification-F1 0.05855550246854594 on epoch=114
05/16/2022 08:08:55 - INFO - __main__ - Saving model with best Classification-F1: 0.05359660311493018 -> 0.05855550246854594 on epoch=114, global_step=1600
05/16/2022 08:08:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.75 on epoch=114
05/16/2022 08:08:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.41 on epoch=115
05/16/2022 08:08:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.42 on epoch=116
05/16/2022 08:09:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.52 on epoch=117
05/16/2022 08:09:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.60 on epoch=117
05/16/2022 08:09:04 - INFO - __main__ - Global step 1650 Train loss 2.54 Classification-F1 0.045989010989010995 on epoch=117
05/16/2022 08:09:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.55 on epoch=118
05/16/2022 08:09:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.63 on epoch=119
05/16/2022 08:09:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.62 on epoch=119
05/16/2022 08:09:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.48 on epoch=120
05/16/2022 08:09:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.46 on epoch=121
05/16/2022 08:09:13 - INFO - __main__ - Global step 1700 Train loss 2.55 Classification-F1 0.015653235653235655 on epoch=121
05/16/2022 08:09:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.69 on epoch=122
05/16/2022 08:09:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.42 on epoch=122
05/16/2022 08:09:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.47 on epoch=123
05/16/2022 08:09:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.45 on epoch=124
05/16/2022 08:09:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.52 on epoch=124
05/16/2022 08:09:22 - INFO - __main__ - Global step 1750 Train loss 2.51 Classification-F1 0.023436680764794295 on epoch=124
05/16/2022 08:09:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.39 on epoch=125
05/16/2022 08:09:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.63 on epoch=126
05/16/2022 08:09:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.55 on epoch=127
05/16/2022 08:09:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.65 on epoch=127
05/16/2022 08:09:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.39 on epoch=128
05/16/2022 08:09:31 - INFO - __main__ - Global step 1800 Train loss 2.52 Classification-F1 0.019892421011823997 on epoch=128
05/16/2022 08:09:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.44 on epoch=129
05/16/2022 08:09:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.54 on epoch=129
05/16/2022 08:09:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.50 on epoch=130
05/16/2022 08:09:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.29 on epoch=131
05/16/2022 08:09:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.50 on epoch=132
05/16/2022 08:09:39 - INFO - __main__ - Global step 1850 Train loss 2.45 Classification-F1 0.03524025556027518 on epoch=132
05/16/2022 08:09:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.24 on epoch=132
05/16/2022 08:09:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.30 on epoch=133
05/16/2022 08:09:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.31 on epoch=134
05/16/2022 08:09:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.41 on epoch=134
05/16/2022 08:09:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.31 on epoch=135
05/16/2022 08:09:49 - INFO - __main__ - Global step 1900 Train loss 2.32 Classification-F1 0.035707445321468724 on epoch=135
05/16/2022 08:09:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.35 on epoch=136
05/16/2022 08:09:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.47 on epoch=137
05/16/2022 08:09:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.35 on epoch=137
05/16/2022 08:09:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.49 on epoch=138
05/16/2022 08:09:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.47 on epoch=139
05/16/2022 08:09:57 - INFO - __main__ - Global step 1950 Train loss 2.43 Classification-F1 0.019965996774052926 on epoch=139
05/16/2022 08:09:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.44 on epoch=139
05/16/2022 08:10:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.33 on epoch=140
05/16/2022 08:10:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.29 on epoch=141
05/16/2022 08:10:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.38 on epoch=142
05/16/2022 08:10:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.22 on epoch=142
05/16/2022 08:10:06 - INFO - __main__ - Global step 2000 Train loss 2.33 Classification-F1 0.009523809523809523 on epoch=142
05/16/2022 08:10:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.23 on epoch=143
05/16/2022 08:10:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.41 on epoch=144
05/16/2022 08:10:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.36 on epoch=144
05/16/2022 08:10:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.39 on epoch=145
05/16/2022 08:10:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.40 on epoch=146
05/16/2022 08:10:14 - INFO - __main__ - Global step 2050 Train loss 2.36 Classification-F1 0.0401387914285009 on epoch=146
05/16/2022 08:10:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.16 on epoch=147
05/16/2022 08:10:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.26 on epoch=147
05/16/2022 08:10:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.21 on epoch=148
05/16/2022 08:10:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.30 on epoch=149
05/16/2022 08:10:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.28 on epoch=149
05/16/2022 08:10:23 - INFO - __main__ - Global step 2100 Train loss 2.24 Classification-F1 0.02457716701902748 on epoch=149
05/16/2022 08:10:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.20 on epoch=150
05/16/2022 08:10:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.19 on epoch=151
05/16/2022 08:10:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.47 on epoch=152
05/16/2022 08:10:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.40 on epoch=152
05/16/2022 08:10:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.16 on epoch=153
05/16/2022 08:10:32 - INFO - __main__ - Global step 2150 Train loss 2.28 Classification-F1 0.017371013741249674 on epoch=153
05/16/2022 08:10:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.29 on epoch=154
05/16/2022 08:10:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.26 on epoch=154
05/16/2022 08:10:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.30 on epoch=155
05/16/2022 08:10:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.26 on epoch=156
05/16/2022 08:10:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.33 on epoch=157
05/16/2022 08:10:41 - INFO - __main__ - Global step 2200 Train loss 2.29 Classification-F1 0.009852216748768473 on epoch=157
05/16/2022 08:10:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.20 on epoch=157
05/16/2022 08:10:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.24 on epoch=158
05/16/2022 08:10:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.25 on epoch=159
05/16/2022 08:10:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.30 on epoch=159
05/16/2022 08:10:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.30 on epoch=160
05/16/2022 08:10:50 - INFO - __main__ - Global step 2250 Train loss 2.26 Classification-F1 0.023715052598236166 on epoch=160
05/16/2022 08:10:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.21 on epoch=161
05/16/2022 08:10:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.30 on epoch=162
05/16/2022 08:10:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.14 on epoch=162
05/16/2022 08:10:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.17 on epoch=163
05/16/2022 08:10:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.22 on epoch=164
05/16/2022 08:11:00 - INFO - __main__ - Global step 2300 Train loss 2.21 Classification-F1 0.066307911535387 on epoch=164
05/16/2022 08:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.05855550246854594 -> 0.066307911535387 on epoch=164, global_step=2300
05/16/2022 08:11:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.35 on epoch=164
05/16/2022 08:11:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.17 on epoch=165
05/16/2022 08:11:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.18 on epoch=166
05/16/2022 08:11:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.21 on epoch=167
05/16/2022 08:11:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.00 on epoch=167
05/16/2022 08:11:09 - INFO - __main__ - Global step 2350 Train loss 2.18 Classification-F1 0.03553433630857859 on epoch=167
05/16/2022 08:11:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.10 on epoch=168
05/16/2022 08:11:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.17 on epoch=169
05/16/2022 08:11:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.14 on epoch=169
05/16/2022 08:11:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.20 on epoch=170
05/16/2022 08:11:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.96 on epoch=171
05/16/2022 08:11:18 - INFO - __main__ - Global step 2400 Train loss 2.11 Classification-F1 0.0472108710255262 on epoch=171
05/16/2022 08:11:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.24 on epoch=172
05/16/2022 08:11:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.17 on epoch=172
05/16/2022 08:11:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.18 on epoch=173
05/16/2022 08:11:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.07 on epoch=174
05/16/2022 08:11:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.16 on epoch=174
05/16/2022 08:11:27 - INFO - __main__ - Global step 2450 Train loss 2.16 Classification-F1 0.04377074341301089 on epoch=174
05/16/2022 08:11:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.01 on epoch=175
05/16/2022 08:11:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.09 on epoch=176
05/16/2022 08:11:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.08 on epoch=177
05/16/2022 08:11:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.05 on epoch=177
05/16/2022 08:11:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.20 on epoch=178
05/16/2022 08:11:36 - INFO - __main__ - Global step 2500 Train loss 2.09 Classification-F1 0.02943967060508414 on epoch=178
05/16/2022 08:11:37 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.14 on epoch=179
05/16/2022 08:11:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.15 on epoch=179
05/16/2022 08:11:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.11 on epoch=180
05/16/2022 08:11:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.05 on epoch=181
05/16/2022 08:11:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.10 on epoch=182
05/16/2022 08:11:45 - INFO - __main__ - Global step 2550 Train loss 2.11 Classification-F1 0.061005356199864205 on epoch=182
05/16/2022 08:11:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.02 on epoch=182
05/16/2022 08:11:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.06 on epoch=183
05/16/2022 08:11:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.10 on epoch=184
05/16/2022 08:11:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.10 on epoch=184
05/16/2022 08:11:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.97 on epoch=185
05/16/2022 08:11:54 - INFO - __main__ - Global step 2600 Train loss 2.05 Classification-F1 0.02266225639191847 on epoch=185
05/16/2022 08:11:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.13 on epoch=186
05/16/2022 08:11:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.23 on epoch=187
05/16/2022 08:11:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.16 on epoch=187
05/16/2022 08:12:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.08 on epoch=188
05/16/2022 08:12:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.19 on epoch=189
05/16/2022 08:12:03 - INFO - __main__ - Global step 2650 Train loss 2.16 Classification-F1 0.043887626552153045 on epoch=189
05/16/2022 08:12:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.11 on epoch=189
05/16/2022 08:12:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.91 on epoch=190
05/16/2022 08:12:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.93 on epoch=191
05/16/2022 08:12:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.00 on epoch=192
05/16/2022 08:12:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.04 on epoch=192
05/16/2022 08:12:12 - INFO - __main__ - Global step 2700 Train loss 2.00 Classification-F1 0.04007709954210692 on epoch=192
05/16/2022 08:12:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.07 on epoch=193
05/16/2022 08:12:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.04 on epoch=194
05/16/2022 08:12:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.08 on epoch=194
05/16/2022 08:12:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.97 on epoch=195
05/16/2022 08:12:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.99 on epoch=196
05/16/2022 08:12:20 - INFO - __main__ - Global step 2750 Train loss 2.03 Classification-F1 0.0347377660741716 on epoch=196
05/16/2022 08:12:22 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.12 on epoch=197
05/16/2022 08:12:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.85 on epoch=197
05/16/2022 08:12:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.03 on epoch=198
05/16/2022 08:12:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.03 on epoch=199
05/16/2022 08:12:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.09 on epoch=199
05/16/2022 08:12:29 - INFO - __main__ - Global step 2800 Train loss 2.02 Classification-F1 0.0401556097125957 on epoch=199
05/16/2022 08:12:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.95 on epoch=200
05/16/2022 08:12:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.89 on epoch=201
05/16/2022 08:12:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.07 on epoch=202
05/16/2022 08:12:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.93 on epoch=202
05/16/2022 08:12:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.92 on epoch=203
05/16/2022 08:12:38 - INFO - __main__ - Global step 2850 Train loss 1.95 Classification-F1 0.0336038961038961 on epoch=203
05/16/2022 08:12:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.90 on epoch=204
05/16/2022 08:12:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.09 on epoch=204
05/16/2022 08:12:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.03 on epoch=205
05/16/2022 08:12:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.96 on epoch=206
05/16/2022 08:12:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.85 on epoch=207
05/16/2022 08:12:47 - INFO - __main__ - Global step 2900 Train loss 1.97 Classification-F1 0.02634920634920635 on epoch=207
05/16/2022 08:12:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.00 on epoch=207
05/16/2022 08:12:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.93 on epoch=208
05/16/2022 08:12:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.90 on epoch=209
05/16/2022 08:12:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.00 on epoch=209
05/16/2022 08:12:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.03 on epoch=210
05/16/2022 08:12:56 - INFO - __main__ - Global step 2950 Train loss 1.97 Classification-F1 0.029290452037233152 on epoch=210
05/16/2022 08:12:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.86 on epoch=211
05/16/2022 08:12:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.92 on epoch=212
05/16/2022 08:13:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.85 on epoch=212
05/16/2022 08:13:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.83 on epoch=213
05/16/2022 08:13:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.99 on epoch=214
05/16/2022 08:13:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:13:04 - INFO - __main__ - Printing 3 examples
05/16/2022 08:13:04 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 08:13:04 - INFO - __main__ - ['Animal']
05/16/2022 08:13:04 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 08:13:04 - INFO - __main__ - ['Animal']
05/16/2022 08:13:04 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 08:13:04 - INFO - __main__ - ['Animal']
05/16/2022 08:13:04 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:13:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:13:04 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:13:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:13:04 - INFO - __main__ - Printing 3 examples
05/16/2022 08:13:04 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 08:13:04 - INFO - __main__ - ['Animal']
05/16/2022 08:13:04 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 08:13:04 - INFO - __main__ - ['Animal']
05/16/2022 08:13:04 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 08:13:04 - INFO - __main__ - ['Animal']
05/16/2022 08:13:04 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:13:05 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:13:05 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:13:05 - INFO - __main__ - Global step 3000 Train loss 1.89 Classification-F1 0.009726443768996961 on epoch=214
05/16/2022 08:13:05 - INFO - __main__ - save last model!
05/16/2022 08:13:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 08:13:05 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 08:13:05 - INFO - __main__ - Printing 3 examples
05/16/2022 08:13:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 08:13:05 - INFO - __main__ - ['Animal']
05/16/2022 08:13:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 08:13:05 - INFO - __main__ - ['Animal']
05/16/2022 08:13:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 08:13:05 - INFO - __main__ - ['Village']
05/16/2022 08:13:05 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:13:07 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:13:11 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 08:13:11 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:13:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:13:11 - INFO - __main__ - Starting training!
05/16/2022 08:13:43 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/16/2022 08:13:43 - INFO - __main__ - Classification-F1 on test data: 0.0160
05/16/2022 08:13:43 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.066307911535387, test_performance=0.016044697001440494
05/16/2022 08:13:43 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/16/2022 08:13:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:13:44 - INFO - __main__ - Printing 3 examples
05/16/2022 08:13:44 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 08:13:44 - INFO - __main__ - ['Animal']
05/16/2022 08:13:44 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 08:13:44 - INFO - __main__ - ['Animal']
05/16/2022 08:13:44 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 08:13:44 - INFO - __main__ - ['Animal']
05/16/2022 08:13:44 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:13:44 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:13:44 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:13:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:13:44 - INFO - __main__ - Printing 3 examples
05/16/2022 08:13:44 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 08:13:44 - INFO - __main__ - ['Animal']
05/16/2022 08:13:44 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 08:13:44 - INFO - __main__ - ['Animal']
05/16/2022 08:13:44 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 08:13:44 - INFO - __main__ - ['Animal']
05/16/2022 08:13:44 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:13:44 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:13:44 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:13:50 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:13:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:13:50 - INFO - __main__ - Starting training!
05/16/2022 08:13:52 - INFO - __main__ - Step 10 Global step 10 Train loss 7.07 on epoch=0
05/16/2022 08:13:53 - INFO - __main__ - Step 20 Global step 20 Train loss 7.55 on epoch=1
05/16/2022 08:13:54 - INFO - __main__ - Step 30 Global step 30 Train loss 7.25 on epoch=2
05/16/2022 08:13:56 - INFO - __main__ - Step 40 Global step 40 Train loss 7.14 on epoch=2
05/16/2022 08:13:57 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/16/2022 08:14:07 - INFO - __main__ - Global step 50 Train loss 7.22 Classification-F1 0.0 on epoch=3
05/16/2022 08:14:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 08:14:08 - INFO - __main__ - Step 60 Global step 60 Train loss 7.20 on epoch=4
05/16/2022 08:14:10 - INFO - __main__ - Step 70 Global step 70 Train loss 7.16 on epoch=4
05/16/2022 08:14:11 - INFO - __main__ - Step 80 Global step 80 Train loss 6.73 on epoch=5
05/16/2022 08:14:12 - INFO - __main__ - Step 90 Global step 90 Train loss 7.00 on epoch=6
05/16/2022 08:14:13 - INFO - __main__ - Step 100 Global step 100 Train loss 6.76 on epoch=7
05/16/2022 08:14:50 - INFO - __main__ - Global step 100 Train loss 6.97 Classification-F1 0.0 on epoch=7
05/16/2022 08:14:51 - INFO - __main__ - Step 110 Global step 110 Train loss 6.71 on epoch=7
05/16/2022 08:14:53 - INFO - __main__ - Step 120 Global step 120 Train loss 6.64 on epoch=8
05/16/2022 08:14:54 - INFO - __main__ - Step 130 Global step 130 Train loss 6.80 on epoch=9
05/16/2022 08:14:56 - INFO - __main__ - Step 140 Global step 140 Train loss 6.68 on epoch=9
05/16/2022 08:14:57 - INFO - __main__ - Step 150 Global step 150 Train loss 6.34 on epoch=10
05/16/2022 08:16:06 - INFO - __main__ - Global step 150 Train loss 6.63 Classification-F1 0.0 on epoch=10
05/16/2022 08:16:08 - INFO - __main__ - Step 160 Global step 160 Train loss 6.55 on epoch=11
05/16/2022 08:16:09 - INFO - __main__ - Step 170 Global step 170 Train loss 6.28 on epoch=12
05/16/2022 08:16:10 - INFO - __main__ - Step 180 Global step 180 Train loss 6.35 on epoch=12
05/16/2022 08:16:11 - INFO - __main__ - Step 190 Global step 190 Train loss 6.28 on epoch=13
05/16/2022 08:16:13 - INFO - __main__ - Step 200 Global step 200 Train loss 6.41 on epoch=14
05/16/2022 08:17:12 - INFO - __main__ - Global step 200 Train loss 6.38 Classification-F1 0.0 on epoch=14
05/16/2022 08:17:14 - INFO - __main__ - Step 210 Global step 210 Train loss 6.34 on epoch=14
05/16/2022 08:17:15 - INFO - __main__ - Step 220 Global step 220 Train loss 6.07 on epoch=15
05/16/2022 08:17:16 - INFO - __main__ - Step 230 Global step 230 Train loss 6.32 on epoch=16
05/16/2022 08:17:18 - INFO - __main__ - Step 240 Global step 240 Train loss 6.12 on epoch=17
05/16/2022 08:17:19 - INFO - __main__ - Step 250 Global step 250 Train loss 6.07 on epoch=17
05/16/2022 08:18:18 - INFO - __main__ - Global step 250 Train loss 6.18 Classification-F1 0.0 on epoch=17
05/16/2022 08:18:19 - INFO - __main__ - Step 260 Global step 260 Train loss 5.99 on epoch=18
05/16/2022 08:18:21 - INFO - __main__ - Step 270 Global step 270 Train loss 6.14 on epoch=19
05/16/2022 08:18:22 - INFO - __main__ - Step 280 Global step 280 Train loss 6.20 on epoch=19
05/16/2022 08:18:23 - INFO - __main__ - Step 290 Global step 290 Train loss 5.90 on epoch=20
05/16/2022 08:18:25 - INFO - __main__ - Step 300 Global step 300 Train loss 6.08 on epoch=21
05/16/2022 08:19:18 - INFO - __main__ - Global step 300 Train loss 6.06 Classification-F1 0.0 on epoch=21
05/16/2022 08:19:19 - INFO - __main__ - Step 310 Global step 310 Train loss 5.98 on epoch=22
05/16/2022 08:19:21 - INFO - __main__ - Step 320 Global step 320 Train loss 5.87 on epoch=22
05/16/2022 08:19:22 - INFO - __main__ - Step 330 Global step 330 Train loss 5.85 on epoch=23
05/16/2022 08:19:23 - INFO - __main__ - Step 340 Global step 340 Train loss 5.86 on epoch=24
05/16/2022 08:19:24 - INFO - __main__ - Step 350 Global step 350 Train loss 5.83 on epoch=24
05/16/2022 08:20:03 - INFO - __main__ - Global step 350 Train loss 5.88 Classification-F1 0.0 on epoch=24
05/16/2022 08:20:04 - INFO - __main__ - Step 360 Global step 360 Train loss 5.63 on epoch=25
05/16/2022 08:20:06 - INFO - __main__ - Step 370 Global step 370 Train loss 5.71 on epoch=26
05/16/2022 08:20:07 - INFO - __main__ - Step 380 Global step 380 Train loss 5.62 on epoch=27
05/16/2022 08:20:08 - INFO - __main__ - Step 390 Global step 390 Train loss 5.48 on epoch=27
05/16/2022 08:20:10 - INFO - __main__ - Step 400 Global step 400 Train loss 5.54 on epoch=28
05/16/2022 08:20:33 - INFO - __main__ - Global step 400 Train loss 5.60 Classification-F1 0.0 on epoch=28
05/16/2022 08:20:34 - INFO - __main__ - Step 410 Global step 410 Train loss 5.64 on epoch=29
05/16/2022 08:20:36 - INFO - __main__ - Step 420 Global step 420 Train loss 5.63 on epoch=29
05/16/2022 08:20:37 - INFO - __main__ - Step 430 Global step 430 Train loss 5.47 on epoch=30
05/16/2022 08:20:38 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=31
05/16/2022 08:20:39 - INFO - __main__ - Step 450 Global step 450 Train loss 5.41 on epoch=32
05/16/2022 08:20:45 - INFO - __main__ - Global step 450 Train loss 5.55 Classification-F1 0.0052417006406523005 on epoch=32
05/16/2022 08:20:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0052417006406523005 on epoch=32, global_step=450
05/16/2022 08:20:47 - INFO - __main__ - Step 460 Global step 460 Train loss 5.36 on epoch=32
05/16/2022 08:20:48 - INFO - __main__ - Step 470 Global step 470 Train loss 5.42 on epoch=33
05/16/2022 08:20:49 - INFO - __main__ - Step 480 Global step 480 Train loss 5.34 on epoch=34
05/16/2022 08:20:51 - INFO - __main__ - Step 490 Global step 490 Train loss 5.44 on epoch=34
05/16/2022 08:20:52 - INFO - __main__ - Step 500 Global step 500 Train loss 5.02 on epoch=35
05/16/2022 08:21:13 - INFO - __main__ - Global step 500 Train loss 5.32 Classification-F1 0.006913580246913581 on epoch=35
05/16/2022 08:21:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0052417006406523005 -> 0.006913580246913581 on epoch=35, global_step=500
05/16/2022 08:21:15 - INFO - __main__ - Step 510 Global step 510 Train loss 5.28 on epoch=36
05/16/2022 08:21:16 - INFO - __main__ - Step 520 Global step 520 Train loss 5.16 on epoch=37
05/16/2022 08:21:17 - INFO - __main__ - Step 530 Global step 530 Train loss 5.16 on epoch=37
05/16/2022 08:21:19 - INFO - __main__ - Step 540 Global step 540 Train loss 5.13 on epoch=38
05/16/2022 08:21:20 - INFO - __main__ - Step 550 Global step 550 Train loss 5.24 on epoch=39
05/16/2022 08:21:31 - INFO - __main__ - Global step 550 Train loss 5.19 Classification-F1 0.0071135430916552675 on epoch=39
05/16/2022 08:21:31 - INFO - __main__ - Saving model with best Classification-F1: 0.006913580246913581 -> 0.0071135430916552675 on epoch=39, global_step=550
05/16/2022 08:21:33 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/16/2022 08:21:34 - INFO - __main__ - Step 570 Global step 570 Train loss 5.01 on epoch=40
05/16/2022 08:21:35 - INFO - __main__ - Step 580 Global step 580 Train loss 4.96 on epoch=41
05/16/2022 08:21:37 - INFO - __main__ - Step 590 Global step 590 Train loss 4.89 on epoch=42
05/16/2022 08:21:38 - INFO - __main__ - Step 600 Global step 600 Train loss 4.91 on epoch=42
05/16/2022 08:21:46 - INFO - __main__ - Global step 600 Train loss 4.97 Classification-F1 0.008849557522123895 on epoch=42
05/16/2022 08:21:46 - INFO - __main__ - Saving model with best Classification-F1: 0.0071135430916552675 -> 0.008849557522123895 on epoch=42, global_step=600
05/16/2022 08:21:47 - INFO - __main__ - Step 610 Global step 610 Train loss 4.86 on epoch=43
05/16/2022 08:21:49 - INFO - __main__ - Step 620 Global step 620 Train loss 4.79 on epoch=44
05/16/2022 08:21:50 - INFO - __main__ - Step 630 Global step 630 Train loss 4.81 on epoch=44
05/16/2022 08:21:51 - INFO - __main__ - Step 640 Global step 640 Train loss 4.78 on epoch=45
05/16/2022 08:21:53 - INFO - __main__ - Step 650 Global step 650 Train loss 4.75 on epoch=46
05/16/2022 08:21:55 - INFO - __main__ - Global step 650 Train loss 4.80 Classification-F1 0.009523809523809523 on epoch=46
05/16/2022 08:21:55 - INFO - __main__ - Saving model with best Classification-F1: 0.008849557522123895 -> 0.009523809523809523 on epoch=46, global_step=650
05/16/2022 08:21:56 - INFO - __main__ - Step 660 Global step 660 Train loss 4.64 on epoch=47
05/16/2022 08:21:58 - INFO - __main__ - Step 670 Global step 670 Train loss 4.49 on epoch=47
05/16/2022 08:21:59 - INFO - __main__ - Step 680 Global step 680 Train loss 4.61 on epoch=48
05/16/2022 08:22:00 - INFO - __main__ - Step 690 Global step 690 Train loss 4.52 on epoch=49
05/16/2022 08:22:02 - INFO - __main__ - Step 700 Global step 700 Train loss 4.73 on epoch=49
05/16/2022 08:22:04 - INFO - __main__ - Global step 700 Train loss 4.60 Classification-F1 0.039432362563755166 on epoch=49
05/16/2022 08:22:04 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.039432362563755166 on epoch=49, global_step=700
05/16/2022 08:22:05 - INFO - __main__ - Step 710 Global step 710 Train loss 4.32 on epoch=50
05/16/2022 08:22:06 - INFO - __main__ - Step 720 Global step 720 Train loss 4.55 on epoch=51
05/16/2022 08:22:08 - INFO - __main__ - Step 730 Global step 730 Train loss 4.39 on epoch=52
05/16/2022 08:22:09 - INFO - __main__ - Step 740 Global step 740 Train loss 4.24 on epoch=52
05/16/2022 08:22:11 - INFO - __main__ - Step 750 Global step 750 Train loss 4.30 on epoch=53
05/16/2022 08:22:18 - INFO - __main__ - Global step 750 Train loss 4.36 Classification-F1 0.02242063492063492 on epoch=53
05/16/2022 08:22:19 - INFO - __main__ - Step 760 Global step 760 Train loss 4.25 on epoch=54
05/16/2022 08:22:21 - INFO - __main__ - Step 770 Global step 770 Train loss 4.32 on epoch=54
05/16/2022 08:22:22 - INFO - __main__ - Step 780 Global step 780 Train loss 4.30 on epoch=55
05/16/2022 08:22:24 - INFO - __main__ - Step 790 Global step 790 Train loss 4.29 on epoch=56
05/16/2022 08:22:25 - INFO - __main__ - Step 800 Global step 800 Train loss 4.27 on epoch=57
05/16/2022 08:22:27 - INFO - __main__ - Global step 800 Train loss 4.29 Classification-F1 0.03304131889356419 on epoch=57
05/16/2022 08:22:28 - INFO - __main__ - Step 810 Global step 810 Train loss 4.10 on epoch=57
05/16/2022 08:22:29 - INFO - __main__ - Step 820 Global step 820 Train loss 4.19 on epoch=58
05/16/2022 08:22:31 - INFO - __main__ - Step 830 Global step 830 Train loss 4.21 on epoch=59
05/16/2022 08:22:32 - INFO - __main__ - Step 840 Global step 840 Train loss 4.33 on epoch=59
05/16/2022 08:22:33 - INFO - __main__ - Step 850 Global step 850 Train loss 4.08 on epoch=60
05/16/2022 08:22:35 - INFO - __main__ - Global step 850 Train loss 4.18 Classification-F1 0.022795082945458883 on epoch=60
05/16/2022 08:22:37 - INFO - __main__ - Step 860 Global step 860 Train loss 4.03 on epoch=61
05/16/2022 08:22:38 - INFO - __main__ - Step 870 Global step 870 Train loss 4.10 on epoch=62
05/16/2022 08:22:39 - INFO - __main__ - Step 880 Global step 880 Train loss 4.03 on epoch=62
05/16/2022 08:22:40 - INFO - __main__ - Step 890 Global step 890 Train loss 4.21 on epoch=63
05/16/2022 08:22:42 - INFO - __main__ - Step 900 Global step 900 Train loss 4.12 on epoch=64
05/16/2022 08:22:44 - INFO - __main__ - Global step 900 Train loss 4.10 Classification-F1 0.02463023701961755 on epoch=64
05/16/2022 08:22:45 - INFO - __main__ - Step 910 Global step 910 Train loss 4.09 on epoch=64
05/16/2022 08:22:46 - INFO - __main__ - Step 920 Global step 920 Train loss 4.03 on epoch=65
05/16/2022 08:22:47 - INFO - __main__ - Step 930 Global step 930 Train loss 4.04 on epoch=66
05/16/2022 08:22:49 - INFO - __main__ - Step 940 Global step 940 Train loss 4.16 on epoch=67
05/16/2022 08:22:50 - INFO - __main__ - Step 950 Global step 950 Train loss 4.01 on epoch=67
05/16/2022 08:22:52 - INFO - __main__ - Global step 950 Train loss 4.07 Classification-F1 0.009644364074743823 on epoch=67
05/16/2022 08:22:53 - INFO - __main__ - Step 960 Global step 960 Train loss 4.06 on epoch=68
05/16/2022 08:22:55 - INFO - __main__ - Step 970 Global step 970 Train loss 4.11 on epoch=69
05/16/2022 08:22:56 - INFO - __main__ - Step 980 Global step 980 Train loss 3.87 on epoch=69
05/16/2022 08:22:58 - INFO - __main__ - Step 990 Global step 990 Train loss 3.88 on epoch=70
05/16/2022 08:22:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.97 on epoch=71
05/16/2022 08:23:01 - INFO - __main__ - Global step 1000 Train loss 3.98 Classification-F1 0.02633573323228496 on epoch=71
05/16/2022 08:23:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.91 on epoch=72
05/16/2022 08:23:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.82 on epoch=72
05/16/2022 08:23:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.05 on epoch=73
05/16/2022 08:23:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.84 on epoch=74
05/16/2022 08:23:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.83 on epoch=74
05/16/2022 08:23:10 - INFO - __main__ - Global step 1050 Train loss 3.89 Classification-F1 0.040131068134059915 on epoch=74
05/16/2022 08:23:10 - INFO - __main__ - Saving model with best Classification-F1: 0.039432362563755166 -> 0.040131068134059915 on epoch=74, global_step=1050
05/16/2022 08:23:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.83 on epoch=75
05/16/2022 08:23:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.81 on epoch=76
05/16/2022 08:23:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.85 on epoch=77
05/16/2022 08:23:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.73 on epoch=77
05/16/2022 08:23:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.75 on epoch=78
05/16/2022 08:23:19 - INFO - __main__ - Global step 1100 Train loss 3.80 Classification-F1 0.0431586552475853 on epoch=78
05/16/2022 08:23:19 - INFO - __main__ - Saving model with best Classification-F1: 0.040131068134059915 -> 0.0431586552475853 on epoch=78, global_step=1100
05/16/2022 08:23:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.76 on epoch=79
05/16/2022 08:23:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.73 on epoch=79
05/16/2022 08:23:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.64 on epoch=80
05/16/2022 08:23:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.62 on epoch=81
05/16/2022 08:23:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.89 on epoch=82
05/16/2022 08:23:28 - INFO - __main__ - Global step 1150 Train loss 3.73 Classification-F1 0.030568975790757673 on epoch=82
05/16/2022 08:23:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.76 on epoch=82
05/16/2022 08:23:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.69 on epoch=83
05/16/2022 08:23:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.56 on epoch=84
05/16/2022 08:23:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.75 on epoch=84
05/16/2022 08:23:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.59 on epoch=85
05/16/2022 08:23:36 - INFO - __main__ - Global step 1200 Train loss 3.67 Classification-F1 0.04690474137774552 on epoch=85
05/16/2022 08:23:36 - INFO - __main__ - Saving model with best Classification-F1: 0.0431586552475853 -> 0.04690474137774552 on epoch=85, global_step=1200
05/16/2022 08:23:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.54 on epoch=86
05/16/2022 08:23:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.62 on epoch=87
05/16/2022 08:23:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.52 on epoch=87
05/16/2022 08:23:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.51 on epoch=88
05/16/2022 08:23:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.77 on epoch=89
05/16/2022 08:23:45 - INFO - __main__ - Global step 1250 Train loss 3.59 Classification-F1 0.04433647900324923 on epoch=89
05/16/2022 08:23:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.52 on epoch=89
05/16/2022 08:23:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.62 on epoch=90
05/16/2022 08:23:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.37 on epoch=91
05/16/2022 08:23:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.58 on epoch=92
05/16/2022 08:23:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.38 on epoch=92
05/16/2022 08:23:54 - INFO - __main__ - Global step 1300 Train loss 3.49 Classification-F1 0.053134431705860276 on epoch=92
05/16/2022 08:23:54 - INFO - __main__ - Saving model with best Classification-F1: 0.04690474137774552 -> 0.053134431705860276 on epoch=92, global_step=1300
05/16/2022 08:23:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.52 on epoch=93
05/16/2022 08:23:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.35 on epoch=94
05/16/2022 08:23:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.30 on epoch=94
05/16/2022 08:24:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.25 on epoch=95
05/16/2022 08:24:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.20 on epoch=96
05/16/2022 08:24:03 - INFO - __main__ - Global step 1350 Train loss 3.33 Classification-F1 0.07162035412336056 on epoch=96
05/16/2022 08:24:03 - INFO - __main__ - Saving model with best Classification-F1: 0.053134431705860276 -> 0.07162035412336056 on epoch=96, global_step=1350
05/16/2022 08:24:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.31 on epoch=97
05/16/2022 08:24:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.13 on epoch=97
05/16/2022 08:24:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.42 on epoch=98
05/16/2022 08:24:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.27 on epoch=99
05/16/2022 08:24:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.28 on epoch=99
05/16/2022 08:24:12 - INFO - __main__ - Global step 1400 Train loss 3.28 Classification-F1 0.01647479158396189 on epoch=99
05/16/2022 08:24:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.29 on epoch=100
05/16/2022 08:24:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.18 on epoch=101
05/16/2022 08:24:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.41 on epoch=102
05/16/2022 08:24:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.12 on epoch=102
05/16/2022 08:24:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.31 on epoch=103
05/16/2022 08:24:21 - INFO - __main__ - Global step 1450 Train loss 3.26 Classification-F1 0.026077097505668938 on epoch=103
05/16/2022 08:24:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.26 on epoch=104
05/16/2022 08:24:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.29 on epoch=104
05/16/2022 08:24:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.21 on epoch=105
05/16/2022 08:24:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.32 on epoch=106
05/16/2022 08:24:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.33 on epoch=107
05/16/2022 08:24:29 - INFO - __main__ - Global step 1500 Train loss 3.28 Classification-F1 0.06912981755087018 on epoch=107
05/16/2022 08:24:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.22 on epoch=107
05/16/2022 08:24:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.20 on epoch=108
05/16/2022 08:24:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.18 on epoch=109
05/16/2022 08:24:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.09 on epoch=109
05/16/2022 08:24:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.93 on epoch=110
05/16/2022 08:24:38 - INFO - __main__ - Global step 1550 Train loss 3.12 Classification-F1 0.028641137380618447 on epoch=110
05/16/2022 08:24:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.16 on epoch=111
05/16/2022 08:24:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.16 on epoch=112
05/16/2022 08:24:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.14 on epoch=112
05/16/2022 08:24:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.14 on epoch=113
05/16/2022 08:24:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.05 on epoch=114
05/16/2022 08:24:47 - INFO - __main__ - Global step 1600 Train loss 3.13 Classification-F1 0.025325249463180495 on epoch=114
05/16/2022 08:24:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.07 on epoch=114
05/16/2022 08:24:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.12 on epoch=115
05/16/2022 08:24:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.05 on epoch=116
05/16/2022 08:24:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.27 on epoch=117
05/16/2022 08:24:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.99 on epoch=117
05/16/2022 08:24:55 - INFO - __main__ - Global step 1650 Train loss 3.10 Classification-F1 0.03382939524243872 on epoch=117
05/16/2022 08:24:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.07 on epoch=118
05/16/2022 08:24:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.98 on epoch=119
05/16/2022 08:24:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.05 on epoch=119
05/16/2022 08:25:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.09 on epoch=120
05/16/2022 08:25:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.01 on epoch=121
05/16/2022 08:25:04 - INFO - __main__ - Global step 1700 Train loss 3.04 Classification-F1 0.0460601205772301 on epoch=121
05/16/2022 08:25:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.06 on epoch=122
05/16/2022 08:25:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.95 on epoch=122
05/16/2022 08:25:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.00 on epoch=123
05/16/2022 08:25:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.92 on epoch=124
05/16/2022 08:25:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.08 on epoch=124
05/16/2022 08:25:13 - INFO - __main__ - Global step 1750 Train loss 3.00 Classification-F1 0.027011403230915422 on epoch=124
05/16/2022 08:25:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.00 on epoch=125
05/16/2022 08:25:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.83 on epoch=126
05/16/2022 08:25:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.13 on epoch=127
05/16/2022 08:25:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.95 on epoch=127
05/16/2022 08:25:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.11 on epoch=128
05/16/2022 08:25:22 - INFO - __main__ - Global step 1800 Train loss 3.00 Classification-F1 0.038018389173851364 on epoch=128
05/16/2022 08:25:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.94 on epoch=129
05/16/2022 08:25:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.98 on epoch=129
05/16/2022 08:25:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.90 on epoch=130
05/16/2022 08:25:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.06 on epoch=131
05/16/2022 08:25:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.94 on epoch=132
05/16/2022 08:25:31 - INFO - __main__ - Global step 1850 Train loss 2.96 Classification-F1 0.028639301206952513 on epoch=132
05/16/2022 08:25:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.82 on epoch=132
05/16/2022 08:25:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.85 on epoch=133
05/16/2022 08:25:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.05 on epoch=134
05/16/2022 08:25:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.95 on epoch=134
05/16/2022 08:25:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.91 on epoch=135
05/16/2022 08:25:41 - INFO - __main__ - Global step 1900 Train loss 2.92 Classification-F1 0.043307643326087435 on epoch=135
05/16/2022 08:25:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.84 on epoch=136
05/16/2022 08:25:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.96 on epoch=137
05/16/2022 08:25:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.74 on epoch=137
05/16/2022 08:25:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.86 on epoch=138
05/16/2022 08:25:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.87 on epoch=139
05/16/2022 08:25:50 - INFO - __main__ - Global step 1950 Train loss 2.86 Classification-F1 0.028763164033385868 on epoch=139
05/16/2022 08:25:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.80 on epoch=139
05/16/2022 08:25:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.82 on epoch=140
05/16/2022 08:25:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.76 on epoch=141
05/16/2022 08:25:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.92 on epoch=142
05/16/2022 08:25:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.87 on epoch=142
05/16/2022 08:25:59 - INFO - __main__ - Global step 2000 Train loss 2.83 Classification-F1 0.009685230024213076 on epoch=142
05/16/2022 08:26:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.74 on epoch=143
05/16/2022 08:26:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.88 on epoch=144
05/16/2022 08:26:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.90 on epoch=144
05/16/2022 08:26:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.85 on epoch=145
05/16/2022 08:26:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.93 on epoch=146
05/16/2022 08:26:08 - INFO - __main__ - Global step 2050 Train loss 2.86 Classification-F1 0.09203906713558196 on epoch=146
05/16/2022 08:26:08 - INFO - __main__ - Saving model with best Classification-F1: 0.07162035412336056 -> 0.09203906713558196 on epoch=146, global_step=2050
05/16/2022 08:26:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.05 on epoch=147
05/16/2022 08:26:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.74 on epoch=147
05/16/2022 08:26:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.95 on epoch=148
05/16/2022 08:26:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.71 on epoch=149
05/16/2022 08:26:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.93 on epoch=149
05/16/2022 08:26:17 - INFO - __main__ - Global step 2100 Train loss 2.88 Classification-F1 0.11475159985029049 on epoch=149
05/16/2022 08:26:17 - INFO - __main__ - Saving model with best Classification-F1: 0.09203906713558196 -> 0.11475159985029049 on epoch=149, global_step=2100
05/16/2022 08:26:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.90 on epoch=150
05/16/2022 08:26:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.94 on epoch=151
05/16/2022 08:26:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.89 on epoch=152
05/16/2022 08:26:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.77 on epoch=152
05/16/2022 08:26:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.86 on epoch=153
05/16/2022 08:26:26 - INFO - __main__ - Global step 2150 Train loss 2.87 Classification-F1 0.08647727892810438 on epoch=153
05/16/2022 08:26:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.83 on epoch=154
05/16/2022 08:26:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.85 on epoch=154
05/16/2022 08:26:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.84 on epoch=155
05/16/2022 08:26:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.69 on epoch=156
05/16/2022 08:26:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.72 on epoch=157
05/16/2022 08:26:36 - INFO - __main__ - Global step 2200 Train loss 2.79 Classification-F1 0.09641713589853433 on epoch=157
05/16/2022 08:26:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.76 on epoch=157
05/16/2022 08:26:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.74 on epoch=158
05/16/2022 08:26:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.84 on epoch=159
05/16/2022 08:26:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.85 on epoch=159
05/16/2022 08:26:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.72 on epoch=160
05/16/2022 08:26:44 - INFO - __main__ - Global step 2250 Train loss 2.78 Classification-F1 0.03529973862454681 on epoch=160
05/16/2022 08:26:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.80 on epoch=161
05/16/2022 08:26:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.84 on epoch=162
05/16/2022 08:26:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.71 on epoch=162
05/16/2022 08:26:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.72 on epoch=163
05/16/2022 08:26:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.84 on epoch=164
05/16/2022 08:26:53 - INFO - __main__ - Global step 2300 Train loss 2.78 Classification-F1 0.028737776778689442 on epoch=164
05/16/2022 08:26:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.78 on epoch=164
05/16/2022 08:26:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.65 on epoch=165
05/16/2022 08:26:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.59 on epoch=166
05/16/2022 08:26:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.72 on epoch=167
05/16/2022 08:27:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.76 on epoch=167
05/16/2022 08:27:02 - INFO - __main__ - Global step 2350 Train loss 2.70 Classification-F1 0.026439719397465873 on epoch=167
05/16/2022 08:27:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.71 on epoch=168
05/16/2022 08:27:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.76 on epoch=169
05/16/2022 08:27:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.74 on epoch=169
05/16/2022 08:27:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.73 on epoch=170
05/16/2022 08:27:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.69 on epoch=171
05/16/2022 08:27:11 - INFO - __main__ - Global step 2400 Train loss 2.73 Classification-F1 0.066728321763488 on epoch=171
05/16/2022 08:27:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.83 on epoch=172
05/16/2022 08:27:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.54 on epoch=172
05/16/2022 08:27:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.75 on epoch=173
05/16/2022 08:27:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.76 on epoch=174
05/16/2022 08:27:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.67 on epoch=174
05/16/2022 08:27:20 - INFO - __main__ - Global step 2450 Train loss 2.71 Classification-F1 0.03537794419525866 on epoch=174
05/16/2022 08:27:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.71 on epoch=175
05/16/2022 08:27:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.55 on epoch=176
05/16/2022 08:27:24 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.75 on epoch=177
05/16/2022 08:27:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.66 on epoch=177
05/16/2022 08:27:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.62 on epoch=178
05/16/2022 08:27:29 - INFO - __main__ - Global step 2500 Train loss 2.66 Classification-F1 0.041590329313543596 on epoch=178
05/16/2022 08:27:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.57 on epoch=179
05/16/2022 08:27:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.51 on epoch=179
05/16/2022 08:27:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.56 on epoch=180
05/16/2022 08:27:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.59 on epoch=181
05/16/2022 08:27:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.60 on epoch=182
05/16/2022 08:27:38 - INFO - __main__ - Global step 2550 Train loss 2.57 Classification-F1 0.04276572208084004 on epoch=182
05/16/2022 08:27:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.55 on epoch=182
05/16/2022 08:27:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.62 on epoch=183
05/16/2022 08:27:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.58 on epoch=184
05/16/2022 08:27:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.68 on epoch=184
05/16/2022 08:27:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.60 on epoch=185
05/16/2022 08:27:47 - INFO - __main__ - Global step 2600 Train loss 2.61 Classification-F1 0.08188048222530982 on epoch=185
05/16/2022 08:27:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.47 on epoch=186
05/16/2022 08:27:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.69 on epoch=187
05/16/2022 08:27:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.61 on epoch=187
05/16/2022 08:27:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.69 on epoch=188
05/16/2022 08:27:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.48 on epoch=189
05/16/2022 08:27:56 - INFO - __main__ - Global step 2650 Train loss 2.59 Classification-F1 0.05094296084743619 on epoch=189
05/16/2022 08:27:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.67 on epoch=189
05/16/2022 08:27:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.46 on epoch=190
05/16/2022 08:28:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.39 on epoch=191
05/16/2022 08:28:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.63 on epoch=192
05/16/2022 08:28:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.46 on epoch=192
05/16/2022 08:28:04 - INFO - __main__ - Global step 2700 Train loss 2.52 Classification-F1 0.022683702280114838 on epoch=192
05/16/2022 08:28:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.67 on epoch=193
05/16/2022 08:28:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.42 on epoch=194
05/16/2022 08:28:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.56 on epoch=194
05/16/2022 08:28:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.48 on epoch=195
05/16/2022 08:28:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.50 on epoch=196
05/16/2022 08:28:13 - INFO - __main__ - Global step 2750 Train loss 2.53 Classification-F1 0.06769773474561605 on epoch=196
05/16/2022 08:28:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.64 on epoch=197
05/16/2022 08:28:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.54 on epoch=197
05/16/2022 08:28:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.48 on epoch=198
05/16/2022 08:28:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.53 on epoch=199
05/16/2022 08:28:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.59 on epoch=199
05/16/2022 08:28:22 - INFO - __main__ - Global step 2800 Train loss 2.56 Classification-F1 0.03835345940609098 on epoch=199
05/16/2022 08:28:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.49 on epoch=200
05/16/2022 08:28:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.42 on epoch=201
05/16/2022 08:28:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.63 on epoch=202
05/16/2022 08:28:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.45 on epoch=202
05/16/2022 08:28:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.43 on epoch=203
05/16/2022 08:28:32 - INFO - __main__ - Global step 2850 Train loss 2.48 Classification-F1 0.08288145257526543 on epoch=203
05/16/2022 08:28:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.39 on epoch=204
05/16/2022 08:28:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.52 on epoch=204
05/16/2022 08:28:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.34 on epoch=205
05/16/2022 08:28:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.37 on epoch=206
05/16/2022 08:28:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.52 on epoch=207
05/16/2022 08:28:41 - INFO - __main__ - Global step 2900 Train loss 2.43 Classification-F1 0.07635537619504891 on epoch=207
05/16/2022 08:28:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.41 on epoch=207
05/16/2022 08:28:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.37 on epoch=208
05/16/2022 08:28:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.36 on epoch=209
05/16/2022 08:28:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.52 on epoch=209
05/16/2022 08:28:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.54 on epoch=210
05/16/2022 08:28:49 - INFO - __main__ - Global step 2950 Train loss 2.44 Classification-F1 0.0671126319004925 on epoch=210
05/16/2022 08:28:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.31 on epoch=211
05/16/2022 08:28:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.39 on epoch=212
05/16/2022 08:28:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.48 on epoch=212
05/16/2022 08:28:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.34 on epoch=213
05/16/2022 08:28:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.31 on epoch=214
05/16/2022 08:28:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:28:57 - INFO - __main__ - Printing 3 examples
05/16/2022 08:28:57 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 08:28:57 - INFO - __main__ - ['Animal']
05/16/2022 08:28:57 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 08:28:57 - INFO - __main__ - ['Animal']
05/16/2022 08:28:57 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 08:28:57 - INFO - __main__ - ['Animal']
05/16/2022 08:28:57 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:28:57 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:28:58 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:28:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:28:58 - INFO - __main__ - Printing 3 examples
05/16/2022 08:28:58 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 08:28:58 - INFO - __main__ - ['Animal']
05/16/2022 08:28:58 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 08:28:58 - INFO - __main__ - ['Animal']
05/16/2022 08:28:58 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 08:28:58 - INFO - __main__ - ['Animal']
05/16/2022 08:28:58 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:28:58 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:28:58 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:28:58 - INFO - __main__ - Global step 3000 Train loss 2.37 Classification-F1 0.061276374956762365 on epoch=214
05/16/2022 08:28:58 - INFO - __main__ - save last model!
05/16/2022 08:28:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 08:28:58 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 08:28:58 - INFO - __main__ - Printing 3 examples
05/16/2022 08:28:58 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 08:28:58 - INFO - __main__ - ['Animal']
05/16/2022 08:28:58 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 08:28:58 - INFO - __main__ - ['Animal']
05/16/2022 08:28:58 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 08:28:58 - INFO - __main__ - ['Village']
05/16/2022 08:28:58 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:29:00 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:29:03 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:29:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:29:04 - INFO - __main__ - Starting training!
05/16/2022 08:29:04 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 08:29:36 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/16/2022 08:29:36 - INFO - __main__ - Classification-F1 on test data: 0.0609
05/16/2022 08:29:36 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.11475159985029049, test_performance=0.060856417022197344
05/16/2022 08:29:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/16/2022 08:29:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:29:37 - INFO - __main__ - Printing 3 examples
05/16/2022 08:29:37 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/16/2022 08:29:37 - INFO - __main__ - ['Animal']
05/16/2022 08:29:37 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/16/2022 08:29:37 - INFO - __main__ - ['Animal']
05/16/2022 08:29:37 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/16/2022 08:29:37 - INFO - __main__ - ['Animal']
05/16/2022 08:29:37 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:29:37 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:29:37 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:29:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:29:37 - INFO - __main__ - Printing 3 examples
05/16/2022 08:29:37 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/16/2022 08:29:37 - INFO - __main__ - ['Animal']
05/16/2022 08:29:37 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/16/2022 08:29:37 - INFO - __main__ - ['Animal']
05/16/2022 08:29:37 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/16/2022 08:29:37 - INFO - __main__ - ['Animal']
05/16/2022 08:29:37 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:29:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:29:38 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:29:43 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:29:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:29:43 - INFO - __main__ - Starting training!
05/16/2022 08:29:45 - INFO - __main__ - Step 10 Global step 10 Train loss 7.24 on epoch=0
05/16/2022 08:29:46 - INFO - __main__ - Step 20 Global step 20 Train loss 7.52 on epoch=1
05/16/2022 08:29:47 - INFO - __main__ - Step 30 Global step 30 Train loss 7.24 on epoch=2
05/16/2022 08:29:49 - INFO - __main__ - Step 40 Global step 40 Train loss 7.26 on epoch=2
05/16/2022 08:29:50 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/16/2022 08:29:58 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/16/2022 08:29:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 08:29:59 - INFO - __main__ - Step 60 Global step 60 Train loss 7.30 on epoch=4
05/16/2022 08:30:01 - INFO - __main__ - Step 70 Global step 70 Train loss 7.12 on epoch=4
05/16/2022 08:30:02 - INFO - __main__ - Step 80 Global step 80 Train loss 6.84 on epoch=5
05/16/2022 08:30:03 - INFO - __main__ - Step 90 Global step 90 Train loss 7.03 on epoch=6
05/16/2022 08:30:04 - INFO - __main__ - Step 100 Global step 100 Train loss 6.93 on epoch=7
05/16/2022 08:30:15 - INFO - __main__ - Global step 100 Train loss 7.05 Classification-F1 0.0 on epoch=7
05/16/2022 08:30:16 - INFO - __main__ - Step 110 Global step 110 Train loss 6.84 on epoch=7
05/16/2022 08:30:17 - INFO - __main__ - Step 120 Global step 120 Train loss 6.65 on epoch=8
05/16/2022 08:30:18 - INFO - __main__ - Step 130 Global step 130 Train loss 6.90 on epoch=9
05/16/2022 08:30:20 - INFO - __main__ - Step 140 Global step 140 Train loss 6.88 on epoch=9
05/16/2022 08:30:21 - INFO - __main__ - Step 150 Global step 150 Train loss 6.53 on epoch=10
05/16/2022 08:30:39 - INFO - __main__ - Global step 150 Train loss 6.76 Classification-F1 0.0 on epoch=10
05/16/2022 08:30:40 - INFO - __main__ - Step 160 Global step 160 Train loss 6.74 on epoch=11
05/16/2022 08:30:42 - INFO - __main__ - Step 170 Global step 170 Train loss 6.51 on epoch=12
05/16/2022 08:30:43 - INFO - __main__ - Step 180 Global step 180 Train loss 6.50 on epoch=12
05/16/2022 08:30:44 - INFO - __main__ - Step 190 Global step 190 Train loss 6.41 on epoch=13
05/16/2022 08:30:46 - INFO - __main__ - Step 200 Global step 200 Train loss 6.55 on epoch=14
05/16/2022 08:31:27 - INFO - __main__ - Global step 200 Train loss 6.54 Classification-F1 0.0 on epoch=14
05/16/2022 08:31:28 - INFO - __main__ - Step 210 Global step 210 Train loss 6.39 on epoch=14
05/16/2022 08:31:30 - INFO - __main__ - Step 220 Global step 220 Train loss 6.15 on epoch=15
05/16/2022 08:31:31 - INFO - __main__ - Step 230 Global step 230 Train loss 6.46 on epoch=16
05/16/2022 08:31:32 - INFO - __main__ - Step 240 Global step 240 Train loss 6.23 on epoch=17
05/16/2022 08:31:34 - INFO - __main__ - Step 250 Global step 250 Train loss 6.14 on epoch=17
05/16/2022 08:32:27 - INFO - __main__ - Global step 250 Train loss 6.27 Classification-F1 0.0 on epoch=17
05/16/2022 08:32:28 - INFO - __main__ - Step 260 Global step 260 Train loss 5.99 on epoch=18
05/16/2022 08:32:30 - INFO - __main__ - Step 270 Global step 270 Train loss 6.31 on epoch=19
05/16/2022 08:32:31 - INFO - __main__ - Step 280 Global step 280 Train loss 6.14 on epoch=19
05/16/2022 08:32:32 - INFO - __main__ - Step 290 Global step 290 Train loss 5.88 on epoch=20
05/16/2022 08:32:33 - INFO - __main__ - Step 300 Global step 300 Train loss 5.97 on epoch=21
05/16/2022 08:33:26 - INFO - __main__ - Global step 300 Train loss 6.06 Classification-F1 0.0 on epoch=21
05/16/2022 08:33:28 - INFO - __main__ - Step 310 Global step 310 Train loss 6.01 on epoch=22
05/16/2022 08:33:29 - INFO - __main__ - Step 320 Global step 320 Train loss 5.80 on epoch=22
05/16/2022 08:33:30 - INFO - __main__ - Step 330 Global step 330 Train loss 5.82 on epoch=23
05/16/2022 08:33:32 - INFO - __main__ - Step 340 Global step 340 Train loss 5.82 on epoch=24
05/16/2022 08:33:33 - INFO - __main__ - Step 350 Global step 350 Train loss 5.83 on epoch=24
05/16/2022 08:34:21 - INFO - __main__ - Global step 350 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/16/2022 08:34:22 - INFO - __main__ - Step 360 Global step 360 Train loss 5.63 on epoch=25
05/16/2022 08:34:23 - INFO - __main__ - Step 370 Global step 370 Train loss 5.92 on epoch=26
05/16/2022 08:34:25 - INFO - __main__ - Step 380 Global step 380 Train loss 5.72 on epoch=27
05/16/2022 08:34:26 - INFO - __main__ - Step 390 Global step 390 Train loss 5.59 on epoch=27
05/16/2022 08:34:27 - INFO - __main__ - Step 400 Global step 400 Train loss 5.65 on epoch=28
05/16/2022 08:34:51 - INFO - __main__ - Global step 400 Train loss 5.70 Classification-F1 0.0 on epoch=28
05/16/2022 08:34:52 - INFO - __main__ - Step 410 Global step 410 Train loss 5.62 on epoch=29
05/16/2022 08:34:54 - INFO - __main__ - Step 420 Global step 420 Train loss 5.68 on epoch=29
05/16/2022 08:34:55 - INFO - __main__ - Step 430 Global step 430 Train loss 5.45 on epoch=30
05/16/2022 08:34:56 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=31
05/16/2022 08:34:57 - INFO - __main__ - Step 450 Global step 450 Train loss 5.49 on epoch=32
05/16/2022 08:35:27 - INFO - __main__ - Global step 450 Train loss 5.56 Classification-F1 0.0017841213202497768 on epoch=32
05/16/2022 08:35:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0017841213202497768 on epoch=32, global_step=450
05/16/2022 08:35:28 - INFO - __main__ - Step 460 Global step 460 Train loss 5.46 on epoch=32
05/16/2022 08:35:30 - INFO - __main__ - Step 470 Global step 470 Train loss 5.45 on epoch=33
05/16/2022 08:35:31 - INFO - __main__ - Step 480 Global step 480 Train loss 5.56 on epoch=34
05/16/2022 08:35:32 - INFO - __main__ - Step 490 Global step 490 Train loss 5.40 on epoch=34
05/16/2022 08:35:34 - INFO - __main__ - Step 500 Global step 500 Train loss 5.30 on epoch=35
05/16/2022 08:35:40 - INFO - __main__ - Global step 500 Train loss 5.43 Classification-F1 0.009009009009009007 on epoch=35
05/16/2022 08:35:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0017841213202497768 -> 0.009009009009009007 on epoch=35, global_step=500
05/16/2022 08:35:41 - INFO - __main__ - Step 510 Global step 510 Train loss 5.37 on epoch=36
05/16/2022 08:35:43 - INFO - __main__ - Step 520 Global step 520 Train loss 5.29 on epoch=37
05/16/2022 08:35:44 - INFO - __main__ - Step 530 Global step 530 Train loss 5.19 on epoch=37
05/16/2022 08:35:45 - INFO - __main__ - Step 540 Global step 540 Train loss 5.20 on epoch=38
05/16/2022 08:35:46 - INFO - __main__ - Step 550 Global step 550 Train loss 5.36 on epoch=39
05/16/2022 08:35:49 - INFO - __main__ - Global step 550 Train loss 5.28 Classification-F1 0.006511123168746609 on epoch=39
05/16/2022 08:35:50 - INFO - __main__ - Step 560 Global step 560 Train loss 5.41 on epoch=39
05/16/2022 08:35:51 - INFO - __main__ - Step 570 Global step 570 Train loss 5.09 on epoch=40
05/16/2022 08:35:53 - INFO - __main__ - Step 580 Global step 580 Train loss 5.23 on epoch=41
05/16/2022 08:35:54 - INFO - __main__ - Step 590 Global step 590 Train loss 5.24 on epoch=42
05/16/2022 08:35:55 - INFO - __main__ - Step 600 Global step 600 Train loss 5.00 on epoch=42
05/16/2022 08:35:59 - INFO - __main__ - Global step 600 Train loss 5.19 Classification-F1 0.006796941376380628 on epoch=42
05/16/2022 08:36:00 - INFO - __main__ - Step 610 Global step 610 Train loss 5.13 on epoch=43
05/16/2022 08:36:01 - INFO - __main__ - Step 620 Global step 620 Train loss 5.20 on epoch=44
05/16/2022 08:36:02 - INFO - __main__ - Step 630 Global step 630 Train loss 5.08 on epoch=44
05/16/2022 08:36:04 - INFO - __main__ - Step 640 Global step 640 Train loss 4.86 on epoch=45
05/16/2022 08:36:05 - INFO - __main__ - Step 650 Global step 650 Train loss 5.04 on epoch=46
05/16/2022 08:36:07 - INFO - __main__ - Global step 650 Train loss 5.06 Classification-F1 0.008403361344537816 on epoch=46
05/16/2022 08:36:09 - INFO - __main__ - Step 660 Global step 660 Train loss 4.99 on epoch=47
05/16/2022 08:36:10 - INFO - __main__ - Step 670 Global step 670 Train loss 4.98 on epoch=47
05/16/2022 08:36:11 - INFO - __main__ - Step 680 Global step 680 Train loss 4.91 on epoch=48
05/16/2022 08:36:12 - INFO - __main__ - Step 690 Global step 690 Train loss 5.03 on epoch=49
05/16/2022 08:36:14 - INFO - __main__ - Step 700 Global step 700 Train loss 5.04 on epoch=49
05/16/2022 08:36:21 - INFO - __main__ - Global step 700 Train loss 4.99 Classification-F1 0.008733624454148471 on epoch=49
05/16/2022 08:36:23 - INFO - __main__ - Step 710 Global step 710 Train loss 4.70 on epoch=50
05/16/2022 08:36:24 - INFO - __main__ - Step 720 Global step 720 Train loss 4.85 on epoch=51
05/16/2022 08:36:25 - INFO - __main__ - Step 730 Global step 730 Train loss 4.86 on epoch=52
05/16/2022 08:36:26 - INFO - __main__ - Step 740 Global step 740 Train loss 4.85 on epoch=52
05/16/2022 08:36:28 - INFO - __main__ - Step 750 Global step 750 Train loss 4.80 on epoch=53
05/16/2022 08:36:35 - INFO - __main__ - Global step 750 Train loss 4.81 Classification-F1 0.006763285024154588 on epoch=53
05/16/2022 08:36:37 - INFO - __main__ - Step 760 Global step 760 Train loss 4.87 on epoch=54
05/16/2022 08:36:38 - INFO - __main__ - Step 770 Global step 770 Train loss 4.94 on epoch=54
05/16/2022 08:36:39 - INFO - __main__ - Step 780 Global step 780 Train loss 4.58 on epoch=55
05/16/2022 08:36:41 - INFO - __main__ - Step 790 Global step 790 Train loss 4.87 on epoch=56
05/16/2022 08:36:42 - INFO - __main__ - Step 800 Global step 800 Train loss 4.77 on epoch=57
05/16/2022 08:36:44 - INFO - __main__ - Global step 800 Train loss 4.81 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 08:36:44 - INFO - __main__ - Saving model with best Classification-F1: 0.009009009009009007 -> 0.009523809523809523 on epoch=57, global_step=800
05/16/2022 08:36:45 - INFO - __main__ - Step 810 Global step 810 Train loss 4.60 on epoch=57
05/16/2022 08:36:47 - INFO - __main__ - Step 820 Global step 820 Train loss 4.76 on epoch=58
05/16/2022 08:36:48 - INFO - __main__ - Step 830 Global step 830 Train loss 4.73 on epoch=59
05/16/2022 08:36:49 - INFO - __main__ - Step 840 Global step 840 Train loss 4.73 on epoch=59
05/16/2022 08:36:51 - INFO - __main__ - Step 850 Global step 850 Train loss 4.48 on epoch=60
05/16/2022 08:36:53 - INFO - __main__ - Global step 850 Train loss 4.66 Classification-F1 0.009523809523809523 on epoch=60
05/16/2022 08:36:54 - INFO - __main__ - Step 860 Global step 860 Train loss 4.54 on epoch=61
05/16/2022 08:36:55 - INFO - __main__ - Step 870 Global step 870 Train loss 4.67 on epoch=62
05/16/2022 08:36:57 - INFO - __main__ - Step 880 Global step 880 Train loss 4.46 on epoch=62
05/16/2022 08:36:58 - INFO - __main__ - Step 890 Global step 890 Train loss 4.64 on epoch=63
05/16/2022 08:36:59 - INFO - __main__ - Step 900 Global step 900 Train loss 4.63 on epoch=64
05/16/2022 08:37:02 - INFO - __main__ - Global step 900 Train loss 4.59 Classification-F1 0.009523809523809523 on epoch=64
05/16/2022 08:37:03 - INFO - __main__ - Step 910 Global step 910 Train loss 4.55 on epoch=64
05/16/2022 08:37:04 - INFO - __main__ - Step 920 Global step 920 Train loss 4.36 on epoch=65
05/16/2022 08:37:06 - INFO - __main__ - Step 930 Global step 930 Train loss 4.51 on epoch=66
05/16/2022 08:37:07 - INFO - __main__ - Step 940 Global step 940 Train loss 4.65 on epoch=67
05/16/2022 08:37:08 - INFO - __main__ - Step 950 Global step 950 Train loss 4.33 on epoch=67
05/16/2022 08:37:10 - INFO - __main__ - Global step 950 Train loss 4.48 Classification-F1 0.009523809523809523 on epoch=67
05/16/2022 08:37:12 - INFO - __main__ - Step 960 Global step 960 Train loss 4.56 on epoch=68
05/16/2022 08:37:13 - INFO - __main__ - Step 970 Global step 970 Train loss 4.38 on epoch=69
05/16/2022 08:37:14 - INFO - __main__ - Step 980 Global step 980 Train loss 4.55 on epoch=69
05/16/2022 08:37:16 - INFO - __main__ - Step 990 Global step 990 Train loss 4.22 on epoch=70
05/16/2022 08:37:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.29 on epoch=71
05/16/2022 08:37:19 - INFO - __main__ - Global step 1000 Train loss 4.40 Classification-F1 0.009523809523809523 on epoch=71
05/16/2022 08:37:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.34 on epoch=72
05/16/2022 08:37:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.32 on epoch=72
05/16/2022 08:37:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.29 on epoch=73
05/16/2022 08:37:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.33 on epoch=74
05/16/2022 08:37:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.39 on epoch=74
05/16/2022 08:37:27 - INFO - __main__ - Global step 1050 Train loss 4.34 Classification-F1 0.009523809523809523 on epoch=74
05/16/2022 08:37:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.21 on epoch=75
05/16/2022 08:37:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.36 on epoch=76
05/16/2022 08:37:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.34 on epoch=77
05/16/2022 08:37:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.07 on epoch=77
05/16/2022 08:37:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.12 on epoch=78
05/16/2022 08:37:35 - INFO - __main__ - Global step 1100 Train loss 4.22 Classification-F1 0.009523809523809523 on epoch=78
05/16/2022 08:37:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.32 on epoch=79
05/16/2022 08:37:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.42 on epoch=79
05/16/2022 08:37:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.07 on epoch=80
05/16/2022 08:37:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.27 on epoch=81
05/16/2022 08:37:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.37 on epoch=82
05/16/2022 08:37:44 - INFO - __main__ - Global step 1150 Train loss 4.29 Classification-F1 0.009523809523809523 on epoch=82
05/16/2022 08:37:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.05 on epoch=82
05/16/2022 08:37:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.16 on epoch=83
05/16/2022 08:37:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.16 on epoch=84
05/16/2022 08:37:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.15 on epoch=84
05/16/2022 08:37:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.00 on epoch=85
05/16/2022 08:37:52 - INFO - __main__ - Global step 1200 Train loss 4.10 Classification-F1 0.009523809523809523 on epoch=85
05/16/2022 08:37:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.98 on epoch=86
05/16/2022 08:37:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.07 on epoch=87
05/16/2022 08:37:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.87 on epoch=87
05/16/2022 08:37:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.01 on epoch=88
05/16/2022 08:37:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.90 on epoch=89
05/16/2022 08:38:00 - INFO - __main__ - Global step 1250 Train loss 3.96 Classification-F1 0.024250609334642948 on epoch=89
05/16/2022 08:38:00 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024250609334642948 on epoch=89, global_step=1250
05/16/2022 08:38:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.07 on epoch=89
05/16/2022 08:38:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.74 on epoch=90
05/16/2022 08:38:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.82 on epoch=91
05/16/2022 08:38:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.02 on epoch=92
05/16/2022 08:38:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.79 on epoch=92
05/16/2022 08:38:09 - INFO - __main__ - Global step 1300 Train loss 3.89 Classification-F1 0.02283922973578146 on epoch=92
05/16/2022 08:38:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.89 on epoch=93
05/16/2022 08:38:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.80 on epoch=94
05/16/2022 08:38:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.94 on epoch=94
05/16/2022 08:38:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.78 on epoch=95
05/16/2022 08:38:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.69 on epoch=96
05/16/2022 08:38:17 - INFO - __main__ - Global step 1350 Train loss 3.82 Classification-F1 0.02564102564102564 on epoch=96
05/16/2022 08:38:17 - INFO - __main__ - Saving model with best Classification-F1: 0.024250609334642948 -> 0.02564102564102564 on epoch=96, global_step=1350
05/16/2022 08:38:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.90 on epoch=97
05/16/2022 08:38:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.68 on epoch=97
05/16/2022 08:38:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.66 on epoch=98
05/16/2022 08:38:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.63 on epoch=99
05/16/2022 08:38:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.68 on epoch=99
05/16/2022 08:38:25 - INFO - __main__ - Global step 1400 Train loss 3.71 Classification-F1 0.009523809523809523 on epoch=99
05/16/2022 08:38:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.69 on epoch=100
05/16/2022 08:38:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.69 on epoch=101
05/16/2022 08:38:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.77 on epoch=102
05/16/2022 08:38:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.59 on epoch=102
05/16/2022 08:38:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.74 on epoch=103
05/16/2022 08:38:33 - INFO - __main__ - Global step 1450 Train loss 3.70 Classification-F1 0.009603841536614645 on epoch=103
05/16/2022 08:38:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.53 on epoch=104
05/16/2022 08:38:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.70 on epoch=104
05/16/2022 08:38:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.60 on epoch=105
05/16/2022 08:38:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.49 on epoch=106
05/16/2022 08:38:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.72 on epoch=107
05/16/2022 08:38:41 - INFO - __main__ - Global step 1500 Train loss 3.61 Classification-F1 0.056913863278115144 on epoch=107
05/16/2022 08:38:41 - INFO - __main__ - Saving model with best Classification-F1: 0.02564102564102564 -> 0.056913863278115144 on epoch=107, global_step=1500
05/16/2022 08:38:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.56 on epoch=107
05/16/2022 08:38:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.65 on epoch=108
05/16/2022 08:38:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.54 on epoch=109
05/16/2022 08:38:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.61 on epoch=109
05/16/2022 08:38:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.50 on epoch=110
05/16/2022 08:38:49 - INFO - __main__ - Global step 1550 Train loss 3.57 Classification-F1 0.009523809523809523 on epoch=110
05/16/2022 08:38:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.50 on epoch=111
05/16/2022 08:38:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.73 on epoch=112
05/16/2022 08:38:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.55 on epoch=112
05/16/2022 08:38:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.51 on epoch=113
05/16/2022 08:38:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.54 on epoch=114
05/16/2022 08:38:58 - INFO - __main__ - Global step 1600 Train loss 3.57 Classification-F1 0.009685230024213076 on epoch=114
05/16/2022 08:38:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.52 on epoch=114
05/16/2022 08:39:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.50 on epoch=115
05/16/2022 08:39:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.45 on epoch=116
05/16/2022 08:39:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.55 on epoch=117
05/16/2022 08:39:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.49 on epoch=117
05/16/2022 08:39:06 - INFO - __main__ - Global step 1650 Train loss 3.50 Classification-F1 0.02079365079365079 on epoch=117
05/16/2022 08:39:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.59 on epoch=118
05/16/2022 08:39:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.40 on epoch=119
05/16/2022 08:39:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.35 on epoch=119
05/16/2022 08:39:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.31 on epoch=120
05/16/2022 08:39:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.46 on epoch=121
05/16/2022 08:39:14 - INFO - __main__ - Global step 1700 Train loss 3.42 Classification-F1 0.04756952589464906 on epoch=121
05/16/2022 08:39:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.50 on epoch=122
05/16/2022 08:39:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.18 on epoch=122
05/16/2022 08:39:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.41 on epoch=123
05/16/2022 08:39:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.34 on epoch=124
05/16/2022 08:39:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.47 on epoch=124
05/16/2022 08:39:23 - INFO - __main__ - Global step 1750 Train loss 3.38 Classification-F1 0.031830914183855356 on epoch=124
05/16/2022 08:39:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.32 on epoch=125
05/16/2022 08:39:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.21 on epoch=126
05/16/2022 08:39:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.63 on epoch=127
05/16/2022 08:39:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.17 on epoch=127
05/16/2022 08:39:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.46 on epoch=128
05/16/2022 08:39:31 - INFO - __main__ - Global step 1800 Train loss 3.36 Classification-F1 0.020149832084732627 on epoch=128
05/16/2022 08:39:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.27 on epoch=129
05/16/2022 08:39:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.28 on epoch=129
05/16/2022 08:39:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.13 on epoch=130
05/16/2022 08:39:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.23 on epoch=131
05/16/2022 08:39:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.42 on epoch=132
05/16/2022 08:39:39 - INFO - __main__ - Global step 1850 Train loss 3.26 Classification-F1 0.03038179768949 on epoch=132
05/16/2022 08:39:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.21 on epoch=132
05/16/2022 08:39:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.42 on epoch=133
05/16/2022 08:39:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.19 on epoch=134
05/16/2022 08:39:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.42 on epoch=134
05/16/2022 08:39:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.13 on epoch=135
05/16/2022 08:39:47 - INFO - __main__ - Global step 1900 Train loss 3.27 Classification-F1 0.014436821040594627 on epoch=135
05/16/2022 08:39:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.26 on epoch=136
05/16/2022 08:39:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.26 on epoch=137
05/16/2022 08:39:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.09 on epoch=137
05/16/2022 08:39:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.25 on epoch=138
05/16/2022 08:39:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.25 on epoch=139
05/16/2022 08:39:56 - INFO - __main__ - Global step 1950 Train loss 3.22 Classification-F1 0.04897682914921132 on epoch=139
05/16/2022 08:39:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.23 on epoch=139
05/16/2022 08:39:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.01 on epoch=140
05/16/2022 08:39:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.06 on epoch=141
05/16/2022 08:40:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.30 on epoch=142
05/16/2022 08:40:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.10 on epoch=142
05/16/2022 08:40:04 - INFO - __main__ - Global step 2000 Train loss 3.14 Classification-F1 0.009523809523809523 on epoch=142
05/16/2022 08:40:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.23 on epoch=143
05/16/2022 08:40:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.25 on epoch=144
05/16/2022 08:40:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.18 on epoch=144
05/16/2022 08:40:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.05 on epoch=145
05/16/2022 08:40:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.05 on epoch=146
05/16/2022 08:40:12 - INFO - __main__ - Global step 2050 Train loss 3.15 Classification-F1 0.017456685191238965 on epoch=146
05/16/2022 08:40:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.19 on epoch=147
05/16/2022 08:40:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.03 on epoch=147
05/16/2022 08:40:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.15 on epoch=148
05/16/2022 08:40:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.24 on epoch=149
05/16/2022 08:40:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.17 on epoch=149
05/16/2022 08:40:20 - INFO - __main__ - Global step 2100 Train loss 3.16 Classification-F1 0.009603841536614645 on epoch=149
05/16/2022 08:40:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.06 on epoch=150
05/16/2022 08:40:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.16 on epoch=151
05/16/2022 08:40:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.01 on epoch=152
05/16/2022 08:40:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.25 on epoch=152
05/16/2022 08:40:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.99 on epoch=153
05/16/2022 08:40:29 - INFO - __main__ - Global step 2150 Train loss 3.09 Classification-F1 0.009523809523809523 on epoch=153
05/16/2022 08:40:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.00 on epoch=154
05/16/2022 08:40:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.03 on epoch=154
05/16/2022 08:40:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.02 on epoch=155
05/16/2022 08:40:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.88 on epoch=156
05/16/2022 08:40:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.05 on epoch=157
05/16/2022 08:40:37 - INFO - __main__ - Global step 2200 Train loss 3.00 Classification-F1 0.009563658099222952 on epoch=157
05/16/2022 08:40:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.85 on epoch=157
05/16/2022 08:40:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.02 on epoch=158
05/16/2022 08:40:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.92 on epoch=159
05/16/2022 08:40:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.98 on epoch=159
05/16/2022 08:40:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.84 on epoch=160
05/16/2022 08:40:45 - INFO - __main__ - Global step 2250 Train loss 2.92 Classification-F1 0.035132841015193955 on epoch=160
05/16/2022 08:40:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.86 on epoch=161
05/16/2022 08:40:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.03 on epoch=162
05/16/2022 08:40:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.90 on epoch=162
05/16/2022 08:40:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.95 on epoch=163
05/16/2022 08:40:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.10 on epoch=164
05/16/2022 08:40:53 - INFO - __main__ - Global step 2300 Train loss 2.97 Classification-F1 0.03645958383353341 on epoch=164
05/16/2022 08:40:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.00 on epoch=164
05/16/2022 08:40:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.06 on epoch=165
05/16/2022 08:40:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.79 on epoch=166
05/16/2022 08:40:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.03 on epoch=167
05/16/2022 08:40:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.85 on epoch=167
05/16/2022 08:41:01 - INFO - __main__ - Global step 2350 Train loss 2.95 Classification-F1 0.021386655489082806 on epoch=167
05/16/2022 08:41:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.83 on epoch=168
05/16/2022 08:41:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.95 on epoch=169
05/16/2022 08:41:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.93 on epoch=169
05/16/2022 08:41:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.95 on epoch=170
05/16/2022 08:41:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.76 on epoch=171
05/16/2022 08:41:09 - INFO - __main__ - Global step 2400 Train loss 2.89 Classification-F1 0.03701404249993591 on epoch=171
05/16/2022 08:41:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.07 on epoch=172
05/16/2022 08:41:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.96 on epoch=172
05/16/2022 08:41:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.89 on epoch=173
05/16/2022 08:41:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.80 on epoch=174
05/16/2022 08:41:16 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.94 on epoch=174
05/16/2022 08:41:18 - INFO - __main__ - Global step 2450 Train loss 2.93 Classification-F1 0.03170590243333451 on epoch=174
05/16/2022 08:41:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.78 on epoch=175
05/16/2022 08:41:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.81 on epoch=176
05/16/2022 08:41:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 3.01 on epoch=177
05/16/2022 08:41:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.83 on epoch=177
05/16/2022 08:41:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.03 on epoch=178
05/16/2022 08:41:26 - INFO - __main__ - Global step 2500 Train loss 2.89 Classification-F1 0.04703336290526692 on epoch=178
05/16/2022 08:41:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.69 on epoch=179
05/16/2022 08:41:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.88 on epoch=179
05/16/2022 08:41:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.64 on epoch=180
05/16/2022 08:41:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.80 on epoch=181
05/16/2022 08:41:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.90 on epoch=182
05/16/2022 08:41:35 - INFO - __main__ - Global step 2550 Train loss 2.78 Classification-F1 0.023472527472527475 on epoch=182
05/16/2022 08:41:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.76 on epoch=182
05/16/2022 08:41:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.91 on epoch=183
05/16/2022 08:41:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.58 on epoch=184
05/16/2022 08:41:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.91 on epoch=184
05/16/2022 08:41:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.57 on epoch=185
05/16/2022 08:41:44 - INFO - __main__ - Global step 2600 Train loss 2.75 Classification-F1 0.02255701582552742 on epoch=185
05/16/2022 08:41:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.65 on epoch=186
05/16/2022 08:41:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.88 on epoch=187
05/16/2022 08:41:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.69 on epoch=187
05/16/2022 08:41:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.82 on epoch=188
05/16/2022 08:41:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.67 on epoch=189
05/16/2022 08:41:52 - INFO - __main__ - Global step 2650 Train loss 2.74 Classification-F1 0.028641801548205486 on epoch=189
05/16/2022 08:41:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.74 on epoch=189
05/16/2022 08:41:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.77 on epoch=190
05/16/2022 08:41:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.67 on epoch=191
05/16/2022 08:41:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.90 on epoch=192
05/16/2022 08:41:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.66 on epoch=192
05/16/2022 08:42:00 - INFO - __main__ - Global step 2700 Train loss 2.75 Classification-F1 0.030124594640723673 on epoch=192
05/16/2022 08:42:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.76 on epoch=193
05/16/2022 08:42:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.73 on epoch=194
05/16/2022 08:42:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.61 on epoch=194
05/16/2022 08:42:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.66 on epoch=195
05/16/2022 08:42:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.68 on epoch=196
05/16/2022 08:42:08 - INFO - __main__ - Global step 2750 Train loss 2.69 Classification-F1 0.023376623376623377 on epoch=196
05/16/2022 08:42:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.81 on epoch=197
05/16/2022 08:42:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.81 on epoch=197
05/16/2022 08:42:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.76 on epoch=198
05/16/2022 08:42:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.71 on epoch=199
05/16/2022 08:42:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.72 on epoch=199
05/16/2022 08:42:17 - INFO - __main__ - Global step 2800 Train loss 2.76 Classification-F1 0.05061488009838082 on epoch=199
05/16/2022 08:42:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.62 on epoch=200
05/16/2022 08:42:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.54 on epoch=201
05/16/2022 08:42:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.90 on epoch=202
05/16/2022 08:42:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.68 on epoch=202
05/16/2022 08:42:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.69 on epoch=203
05/16/2022 08:42:25 - INFO - __main__ - Global step 2850 Train loss 2.68 Classification-F1 0.04377715307947866 on epoch=203
05/16/2022 08:42:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.68 on epoch=204
05/16/2022 08:42:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.73 on epoch=204
05/16/2022 08:42:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.71 on epoch=205
05/16/2022 08:42:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.64 on epoch=206
05/16/2022 08:42:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.87 on epoch=207
05/16/2022 08:42:33 - INFO - __main__ - Global step 2900 Train loss 2.73 Classification-F1 0.02614048073551755 on epoch=207
05/16/2022 08:42:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.46 on epoch=207
05/16/2022 08:42:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.52 on epoch=208
05/16/2022 08:42:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.54 on epoch=209
05/16/2022 08:42:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.63 on epoch=209
05/16/2022 08:42:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.49 on epoch=210
05/16/2022 08:42:42 - INFO - __main__ - Global step 2950 Train loss 2.53 Classification-F1 0.03708272511383691 on epoch=210
05/16/2022 08:42:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.56 on epoch=211
05/16/2022 08:42:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.74 on epoch=212
05/16/2022 08:42:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.59 on epoch=212
05/16/2022 08:42:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.59 on epoch=213
05/16/2022 08:42:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.81 on epoch=214
05/16/2022 08:42:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:42:50 - INFO - __main__ - Printing 3 examples
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 08:42:50 - INFO - __main__ - ['Plant']
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 08:42:50 - INFO - __main__ - ['Plant']
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 08:42:50 - INFO - __main__ - ['Plant']
05/16/2022 08:42:50 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:42:50 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:42:50 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:42:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:42:50 - INFO - __main__ - Printing 3 examples
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 08:42:50 - INFO - __main__ - ['Plant']
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 08:42:50 - INFO - __main__ - ['Plant']
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 08:42:50 - INFO - __main__ - ['Plant']
05/16/2022 08:42:50 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:42:50 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:42:50 - INFO - __main__ - Global step 3000 Train loss 2.66 Classification-F1 0.01840291559917728 on epoch=214
05/16/2022 08:42:50 - INFO - __main__ - save last model!
05/16/2022 08:42:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 08:42:50 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 08:42:50 - INFO - __main__ - Printing 3 examples
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 08:42:50 - INFO - __main__ - ['Animal']
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 08:42:50 - INFO - __main__ - ['Animal']
05/16/2022 08:42:50 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 08:42:50 - INFO - __main__ - ['Village']
05/16/2022 08:42:50 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:42:50 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:42:52 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:42:55 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 08:42:56 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:42:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:42:56 - INFO - __main__ - Starting training!
05/16/2022 08:43:25 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/16/2022 08:43:25 - INFO - __main__ - Classification-F1 on test data: 0.0300
05/16/2022 08:43:25 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.056913863278115144, test_performance=0.029997895534535614
05/16/2022 08:43:25 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/16/2022 08:43:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:43:26 - INFO - __main__ - Printing 3 examples
05/16/2022 08:43:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 08:43:26 - INFO - __main__ - ['Plant']
05/16/2022 08:43:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 08:43:26 - INFO - __main__ - ['Plant']
05/16/2022 08:43:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 08:43:26 - INFO - __main__ - ['Plant']
05/16/2022 08:43:26 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:43:26 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:43:26 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:43:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:43:26 - INFO - __main__ - Printing 3 examples
05/16/2022 08:43:26 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 08:43:26 - INFO - __main__ - ['Plant']
05/16/2022 08:43:26 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 08:43:26 - INFO - __main__ - ['Plant']
05/16/2022 08:43:26 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 08:43:26 - INFO - __main__ - ['Plant']
05/16/2022 08:43:26 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:43:26 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:43:27 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:43:32 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:43:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:43:32 - INFO - __main__ - Starting training!
05/16/2022 08:43:34 - INFO - __main__ - Step 10 Global step 10 Train loss 7.57 on epoch=0
05/16/2022 08:43:35 - INFO - __main__ - Step 20 Global step 20 Train loss 7.39 on epoch=1
05/16/2022 08:43:36 - INFO - __main__ - Step 30 Global step 30 Train loss 7.35 on epoch=2
05/16/2022 08:43:37 - INFO - __main__ - Step 40 Global step 40 Train loss 7.42 on epoch=2
05/16/2022 08:43:39 - INFO - __main__ - Step 50 Global step 50 Train loss 7.01 on epoch=3
05/16/2022 08:44:41 - INFO - __main__ - Global step 50 Train loss 7.35 Classification-F1 0.0 on epoch=3
05/16/2022 08:44:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 08:44:42 - INFO - __main__ - Step 60 Global step 60 Train loss 6.80 on epoch=4
05/16/2022 08:44:43 - INFO - __main__ - Step 70 Global step 70 Train loss 6.79 on epoch=4
05/16/2022 08:44:45 - INFO - __main__ - Step 80 Global step 80 Train loss 6.74 on epoch=5
05/16/2022 08:44:46 - INFO - __main__ - Step 90 Global step 90 Train loss 6.38 on epoch=6
05/16/2022 08:44:47 - INFO - __main__ - Step 100 Global step 100 Train loss 6.52 on epoch=7
05/16/2022 08:45:51 - INFO - __main__ - Global step 100 Train loss 6.65 Classification-F1 0.0 on epoch=7
05/16/2022 08:45:53 - INFO - __main__ - Step 110 Global step 110 Train loss 6.41 on epoch=7
05/16/2022 08:45:54 - INFO - __main__ - Step 120 Global step 120 Train loss 6.21 on epoch=8
05/16/2022 08:45:55 - INFO - __main__ - Step 130 Global step 130 Train loss 6.10 on epoch=9
05/16/2022 08:45:57 - INFO - __main__ - Step 140 Global step 140 Train loss 5.99 on epoch=9
05/16/2022 08:45:58 - INFO - __main__ - Step 150 Global step 150 Train loss 5.98 on epoch=10
05/16/2022 08:46:42 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/16/2022 08:46:44 - INFO - __main__ - Step 160 Global step 160 Train loss 5.78 on epoch=11
05/16/2022 08:46:45 - INFO - __main__ - Step 170 Global step 170 Train loss 6.06 on epoch=12
05/16/2022 08:46:46 - INFO - __main__ - Step 180 Global step 180 Train loss 5.82 on epoch=12
05/16/2022 08:46:48 - INFO - __main__ - Step 190 Global step 190 Train loss 5.63 on epoch=13
05/16/2022 08:46:49 - INFO - __main__ - Step 200 Global step 200 Train loss 5.61 on epoch=14
05/16/2022 08:47:09 - INFO - __main__ - Global step 200 Train loss 5.78 Classification-F1 0.0027359781121751026 on epoch=14
05/16/2022 08:47:09 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0027359781121751026 on epoch=14, global_step=200
05/16/2022 08:47:10 - INFO - __main__ - Step 210 Global step 210 Train loss 5.62 on epoch=14
05/16/2022 08:47:12 - INFO - __main__ - Step 220 Global step 220 Train loss 5.50 on epoch=15
05/16/2022 08:47:13 - INFO - __main__ - Step 230 Global step 230 Train loss 5.31 on epoch=16
05/16/2022 08:47:14 - INFO - __main__ - Step 240 Global step 240 Train loss 5.31 on epoch=17
05/16/2022 08:47:16 - INFO - __main__ - Step 250 Global step 250 Train loss 5.42 on epoch=17
05/16/2022 08:47:19 - INFO - __main__ - Global step 250 Train loss 5.43 Classification-F1 0.006493506493506495 on epoch=17
05/16/2022 08:47:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0027359781121751026 -> 0.006493506493506495 on epoch=17, global_step=250
05/16/2022 08:47:21 - INFO - __main__ - Step 260 Global step 260 Train loss 5.20 on epoch=18
05/16/2022 08:47:22 - INFO - __main__ - Step 270 Global step 270 Train loss 5.26 on epoch=19
05/16/2022 08:47:23 - INFO - __main__ - Step 280 Global step 280 Train loss 5.14 on epoch=19
05/16/2022 08:47:25 - INFO - __main__ - Step 290 Global step 290 Train loss 5.04 on epoch=20
05/16/2022 08:47:26 - INFO - __main__ - Step 300 Global step 300 Train loss 5.00 on epoch=21
05/16/2022 08:47:29 - INFO - __main__ - Global step 300 Train loss 5.13 Classification-F1 0.00892608089260809 on epoch=21
05/16/2022 08:47:29 - INFO - __main__ - Saving model with best Classification-F1: 0.006493506493506495 -> 0.00892608089260809 on epoch=21, global_step=300
05/16/2022 08:47:30 - INFO - __main__ - Step 310 Global step 310 Train loss 5.13 on epoch=22
05/16/2022 08:47:32 - INFO - __main__ - Step 320 Global step 320 Train loss 5.00 on epoch=22
05/16/2022 08:47:33 - INFO - __main__ - Step 330 Global step 330 Train loss 4.83 on epoch=23
05/16/2022 08:47:34 - INFO - __main__ - Step 340 Global step 340 Train loss 4.81 on epoch=24
05/16/2022 08:47:35 - INFO - __main__ - Step 350 Global step 350 Train loss 4.57 on epoch=24
05/16/2022 08:47:38 - INFO - __main__ - Global step 350 Train loss 4.87 Classification-F1 0.009523809523809523 on epoch=24
05/16/2022 08:47:38 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=24, global_step=350
05/16/2022 08:47:39 - INFO - __main__ - Step 360 Global step 360 Train loss 4.67 on epoch=25
05/16/2022 08:47:40 - INFO - __main__ - Step 370 Global step 370 Train loss 4.46 on epoch=26
05/16/2022 08:47:42 - INFO - __main__ - Step 380 Global step 380 Train loss 4.61 on epoch=27
05/16/2022 08:47:43 - INFO - __main__ - Step 390 Global step 390 Train loss 4.61 on epoch=27
05/16/2022 08:47:44 - INFO - __main__ - Step 400 Global step 400 Train loss 4.69 on epoch=28
05/16/2022 08:47:46 - INFO - __main__ - Global step 400 Train loss 4.61 Classification-F1 0.009523809523809523 on epoch=28
05/16/2022 08:47:47 - INFO - __main__ - Step 410 Global step 410 Train loss 4.39 on epoch=29
05/16/2022 08:47:49 - INFO - __main__ - Step 420 Global step 420 Train loss 4.34 on epoch=29
05/16/2022 08:47:50 - INFO - __main__ - Step 430 Global step 430 Train loss 4.40 on epoch=30
05/16/2022 08:47:51 - INFO - __main__ - Step 440 Global step 440 Train loss 4.35 on epoch=31
05/16/2022 08:47:53 - INFO - __main__ - Step 450 Global step 450 Train loss 4.39 on epoch=32
05/16/2022 08:47:54 - INFO - __main__ - Global step 450 Train loss 4.37 Classification-F1 0.03533285516707069 on epoch=32
05/16/2022 08:47:54 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.03533285516707069 on epoch=32, global_step=450
05/16/2022 08:47:56 - INFO - __main__ - Step 460 Global step 460 Train loss 4.08 on epoch=32
05/16/2022 08:47:57 - INFO - __main__ - Step 470 Global step 470 Train loss 4.19 on epoch=33
05/16/2022 08:47:58 - INFO - __main__ - Step 480 Global step 480 Train loss 4.23 on epoch=34
05/16/2022 08:48:00 - INFO - __main__ - Step 490 Global step 490 Train loss 3.99 on epoch=34
05/16/2022 08:48:01 - INFO - __main__ - Step 500 Global step 500 Train loss 3.89 on epoch=35
05/16/2022 08:48:03 - INFO - __main__ - Global step 500 Train loss 4.08 Classification-F1 0.026969988291503193 on epoch=35
05/16/2022 08:48:04 - INFO - __main__ - Step 510 Global step 510 Train loss 3.93 on epoch=36
05/16/2022 08:48:05 - INFO - __main__ - Step 520 Global step 520 Train loss 4.00 on epoch=37
05/16/2022 08:48:07 - INFO - __main__ - Step 530 Global step 530 Train loss 3.81 on epoch=37
05/16/2022 08:48:08 - INFO - __main__ - Step 540 Global step 540 Train loss 3.95 on epoch=38
05/16/2022 08:48:09 - INFO - __main__ - Step 550 Global step 550 Train loss 3.69 on epoch=39
05/16/2022 08:48:11 - INFO - __main__ - Global step 550 Train loss 3.88 Classification-F1 0.01935875608681676 on epoch=39
05/16/2022 08:48:12 - INFO - __main__ - Step 560 Global step 560 Train loss 3.71 on epoch=39
05/16/2022 08:48:14 - INFO - __main__ - Step 570 Global step 570 Train loss 3.68 on epoch=40
05/16/2022 08:48:15 - INFO - __main__ - Step 580 Global step 580 Train loss 3.63 on epoch=41
05/16/2022 08:48:16 - INFO - __main__ - Step 590 Global step 590 Train loss 3.78 on epoch=42
05/16/2022 08:48:17 - INFO - __main__ - Step 600 Global step 600 Train loss 3.49 on epoch=42
05/16/2022 08:48:19 - INFO - __main__ - Global step 600 Train loss 3.66 Classification-F1 0.027561317052249977 on epoch=42
05/16/2022 08:48:21 - INFO - __main__ - Step 610 Global step 610 Train loss 3.62 on epoch=43
05/16/2022 08:48:22 - INFO - __main__ - Step 620 Global step 620 Train loss 3.63 on epoch=44
05/16/2022 08:48:23 - INFO - __main__ - Step 630 Global step 630 Train loss 3.50 on epoch=44
05/16/2022 08:48:24 - INFO - __main__ - Step 640 Global step 640 Train loss 3.47 on epoch=45
05/16/2022 08:48:26 - INFO - __main__ - Step 650 Global step 650 Train loss 3.53 on epoch=46
05/16/2022 08:48:28 - INFO - __main__ - Global step 650 Train loss 3.55 Classification-F1 0.020625885742164812 on epoch=46
05/16/2022 08:48:29 - INFO - __main__ - Step 660 Global step 660 Train loss 3.56 on epoch=47
05/16/2022 08:48:30 - INFO - __main__ - Step 670 Global step 670 Train loss 3.34 on epoch=47
05/16/2022 08:48:32 - INFO - __main__ - Step 680 Global step 680 Train loss 3.50 on epoch=48
05/16/2022 08:48:33 - INFO - __main__ - Step 690 Global step 690 Train loss 3.35 on epoch=49
05/16/2022 08:48:34 - INFO - __main__ - Step 700 Global step 700 Train loss 3.40 on epoch=49
05/16/2022 08:48:36 - INFO - __main__ - Global step 700 Train loss 3.43 Classification-F1 0.07079211716892876 on epoch=49
05/16/2022 08:48:36 - INFO - __main__ - Saving model with best Classification-F1: 0.03533285516707069 -> 0.07079211716892876 on epoch=49, global_step=700
05/16/2022 08:48:37 - INFO - __main__ - Step 710 Global step 710 Train loss 3.31 on epoch=50
05/16/2022 08:48:39 - INFO - __main__ - Step 720 Global step 720 Train loss 3.38 on epoch=51
05/16/2022 08:48:40 - INFO - __main__ - Step 730 Global step 730 Train loss 3.40 on epoch=52
05/16/2022 08:48:41 - INFO - __main__ - Step 740 Global step 740 Train loss 3.13 on epoch=52
05/16/2022 08:48:42 - INFO - __main__ - Step 750 Global step 750 Train loss 3.33 on epoch=53
05/16/2022 08:48:44 - INFO - __main__ - Global step 750 Train loss 3.31 Classification-F1 0.051475778947435526 on epoch=53
05/16/2022 08:48:46 - INFO - __main__ - Step 760 Global step 760 Train loss 3.29 on epoch=54
05/16/2022 08:48:47 - INFO - __main__ - Step 770 Global step 770 Train loss 3.17 on epoch=54
05/16/2022 08:48:48 - INFO - __main__ - Step 780 Global step 780 Train loss 3.23 on epoch=55
05/16/2022 08:48:49 - INFO - __main__ - Step 790 Global step 790 Train loss 3.34 on epoch=56
05/16/2022 08:48:51 - INFO - __main__ - Step 800 Global step 800 Train loss 3.25 on epoch=57
05/16/2022 08:48:53 - INFO - __main__ - Global step 800 Train loss 3.26 Classification-F1 0.032079459002535934 on epoch=57
05/16/2022 08:48:54 - INFO - __main__ - Step 810 Global step 810 Train loss 3.08 on epoch=57
05/16/2022 08:48:55 - INFO - __main__ - Step 820 Global step 820 Train loss 3.21 on epoch=58
05/16/2022 08:48:56 - INFO - __main__ - Step 830 Global step 830 Train loss 3.18 on epoch=59
05/16/2022 08:48:58 - INFO - __main__ - Step 840 Global step 840 Train loss 3.23 on epoch=59
05/16/2022 08:48:59 - INFO - __main__ - Step 850 Global step 850 Train loss 3.07 on epoch=60
05/16/2022 08:49:01 - INFO - __main__ - Global step 850 Train loss 3.15 Classification-F1 0.04134848202644813 on epoch=60
05/16/2022 08:49:02 - INFO - __main__ - Step 860 Global step 860 Train loss 3.17 on epoch=61
05/16/2022 08:49:03 - INFO - __main__ - Step 870 Global step 870 Train loss 3.26 on epoch=62
05/16/2022 08:49:05 - INFO - __main__ - Step 880 Global step 880 Train loss 2.92 on epoch=62
05/16/2022 08:49:06 - INFO - __main__ - Step 890 Global step 890 Train loss 3.12 on epoch=63
05/16/2022 08:49:07 - INFO - __main__ - Step 900 Global step 900 Train loss 3.10 on epoch=64
05/16/2022 08:49:09 - INFO - __main__ - Global step 900 Train loss 3.11 Classification-F1 0.029592629592629597 on epoch=64
05/16/2022 08:49:10 - INFO - __main__ - Step 910 Global step 910 Train loss 3.02 on epoch=64
05/16/2022 08:49:12 - INFO - __main__ - Step 920 Global step 920 Train loss 3.03 on epoch=65
05/16/2022 08:49:13 - INFO - __main__ - Step 930 Global step 930 Train loss 3.19 on epoch=66
05/16/2022 08:49:14 - INFO - __main__ - Step 940 Global step 940 Train loss 3.01 on epoch=67
05/16/2022 08:49:16 - INFO - __main__ - Step 950 Global step 950 Train loss 3.02 on epoch=67
05/16/2022 08:49:17 - INFO - __main__ - Global step 950 Train loss 3.05 Classification-F1 0.05177824467358462 on epoch=67
05/16/2022 08:49:19 - INFO - __main__ - Step 960 Global step 960 Train loss 3.10 on epoch=68
05/16/2022 08:49:20 - INFO - __main__ - Step 970 Global step 970 Train loss 2.93 on epoch=69
05/16/2022 08:49:22 - INFO - __main__ - Step 980 Global step 980 Train loss 2.98 on epoch=69
05/16/2022 08:49:23 - INFO - __main__ - Step 990 Global step 990 Train loss 2.92 on epoch=70
05/16/2022 08:49:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.02 on epoch=71
05/16/2022 08:49:26 - INFO - __main__ - Global step 1000 Train loss 2.99 Classification-F1 0.046340774654445714 on epoch=71
05/16/2022 08:49:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.11 on epoch=72
05/16/2022 08:49:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.89 on epoch=72
05/16/2022 08:49:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.02 on epoch=73
05/16/2022 08:49:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.01 on epoch=74
05/16/2022 08:49:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.95 on epoch=74
05/16/2022 08:49:34 - INFO - __main__ - Global step 1050 Train loss 3.00 Classification-F1 0.04162431256027315 on epoch=74
05/16/2022 08:49:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.79 on epoch=75
05/16/2022 08:49:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.04 on epoch=76
05/16/2022 08:49:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.95 on epoch=77
05/16/2022 08:49:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.68 on epoch=77
05/16/2022 08:49:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.77 on epoch=78
05/16/2022 08:49:42 - INFO - __main__ - Global step 1100 Train loss 2.85 Classification-F1 0.02476678251326139 on epoch=78
05/16/2022 08:49:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.94 on epoch=79
05/16/2022 08:49:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.84 on epoch=79
05/16/2022 08:49:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.65 on epoch=80
05/16/2022 08:49:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.00 on epoch=81
05/16/2022 08:49:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.91 on epoch=82
05/16/2022 08:49:51 - INFO - __main__ - Global step 1150 Train loss 2.87 Classification-F1 0.03142285566782211 on epoch=82
05/16/2022 08:49:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.74 on epoch=82
05/16/2022 08:49:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.90 on epoch=83
05/16/2022 08:49:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.73 on epoch=84
05/16/2022 08:49:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.89 on epoch=84
05/16/2022 08:49:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.72 on epoch=85
05/16/2022 08:49:59 - INFO - __main__ - Global step 1200 Train loss 2.80 Classification-F1 0.04982771652722391 on epoch=85
05/16/2022 08:50:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.77 on epoch=86
05/16/2022 08:50:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.89 on epoch=87
05/16/2022 08:50:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.78 on epoch=87
05/16/2022 08:50:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.87 on epoch=88
05/16/2022 08:50:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.67 on epoch=89
05/16/2022 08:50:07 - INFO - __main__ - Global step 1250 Train loss 2.80 Classification-F1 0.04095367420839119 on epoch=89
05/16/2022 08:50:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.83 on epoch=89
05/16/2022 08:50:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.62 on epoch=90
05/16/2022 08:50:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.79 on epoch=91
05/16/2022 08:50:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.76 on epoch=92
05/16/2022 08:50:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.59 on epoch=92
05/16/2022 08:50:16 - INFO - __main__ - Global step 1300 Train loss 2.72 Classification-F1 0.04871858668883503 on epoch=92
05/16/2022 08:50:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.69 on epoch=93
05/16/2022 08:50:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.71 on epoch=94
05/16/2022 08:50:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.62 on epoch=94
05/16/2022 08:50:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.55 on epoch=95
05/16/2022 08:50:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.89 on epoch=96
05/16/2022 08:50:24 - INFO - __main__ - Global step 1350 Train loss 2.69 Classification-F1 0.044776292583310125 on epoch=96
05/16/2022 08:50:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.63 on epoch=97
05/16/2022 08:50:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.69 on epoch=97
05/16/2022 08:50:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.57 on epoch=98
05/16/2022 08:50:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.51 on epoch=99
05/16/2022 08:50:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.55 on epoch=99
05/16/2022 08:50:32 - INFO - __main__ - Global step 1400 Train loss 2.59 Classification-F1 0.043598641305520665 on epoch=99
05/16/2022 08:50:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.34 on epoch=100
05/16/2022 08:50:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.71 on epoch=101
05/16/2022 08:50:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.55 on epoch=102
05/16/2022 08:50:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.41 on epoch=102
05/16/2022 08:50:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.56 on epoch=103
05/16/2022 08:50:41 - INFO - __main__ - Global step 1450 Train loss 2.51 Classification-F1 0.055157706978596434 on epoch=103
05/16/2022 08:50:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.55 on epoch=104
05/16/2022 08:50:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.57 on epoch=104
05/16/2022 08:50:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.45 on epoch=105
05/16/2022 08:50:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.54 on epoch=106
05/16/2022 08:50:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.46 on epoch=107
05/16/2022 08:50:49 - INFO - __main__ - Global step 1500 Train loss 2.51 Classification-F1 0.04579863376285171 on epoch=107
05/16/2022 08:50:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.39 on epoch=107
05/16/2022 08:50:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.54 on epoch=108
05/16/2022 08:50:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.57 on epoch=109
05/16/2022 08:50:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.37 on epoch=109
05/16/2022 08:50:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.42 on epoch=110
05/16/2022 08:50:57 - INFO - __main__ - Global step 1550 Train loss 2.46 Classification-F1 0.08420627340464937 on epoch=110
05/16/2022 08:50:57 - INFO - __main__ - Saving model with best Classification-F1: 0.07079211716892876 -> 0.08420627340464937 on epoch=110, global_step=1550
05/16/2022 08:50:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.57 on epoch=111
05/16/2022 08:51:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.63 on epoch=112
05/16/2022 08:51:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.33 on epoch=112
05/16/2022 08:51:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.58 on epoch=113
05/16/2022 08:51:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.52 on epoch=114
05/16/2022 08:51:05 - INFO - __main__ - Global step 1600 Train loss 2.53 Classification-F1 0.08191283506409557 on epoch=114
05/16/2022 08:51:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.47 on epoch=114
05/16/2022 08:51:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=115
05/16/2022 08:51:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.57 on epoch=116
05/16/2022 08:51:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.39 on epoch=117
05/16/2022 08:51:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.50 on epoch=117
05/16/2022 08:51:14 - INFO - __main__ - Global step 1650 Train loss 2.44 Classification-F1 0.04409073623802994 on epoch=117
05/16/2022 08:51:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.45 on epoch=118
05/16/2022 08:51:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.42 on epoch=119
05/16/2022 08:51:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.37 on epoch=119
05/16/2022 08:51:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.39 on epoch=120
05/16/2022 08:51:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.51 on epoch=121
05/16/2022 08:51:24 - INFO - __main__ - Global step 1700 Train loss 2.43 Classification-F1 0.09792532397574416 on epoch=121
05/16/2022 08:51:24 - INFO - __main__ - Saving model with best Classification-F1: 0.08420627340464937 -> 0.09792532397574416 on epoch=121, global_step=1700
05/16/2022 08:51:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.45 on epoch=122
05/16/2022 08:51:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.33 on epoch=122
05/16/2022 08:51:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.44 on epoch=123
05/16/2022 08:51:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.38 on epoch=124
05/16/2022 08:51:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.19 on epoch=124
05/16/2022 08:51:34 - INFO - __main__ - Global step 1750 Train loss 2.36 Classification-F1 0.051051999747267325 on epoch=124
05/16/2022 08:51:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.16 on epoch=125
05/16/2022 08:51:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.55 on epoch=126
05/16/2022 08:51:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.48 on epoch=127
05/16/2022 08:51:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.19 on epoch=127
05/16/2022 08:51:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.30 on epoch=128
05/16/2022 08:51:45 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.07094516594516594 on epoch=128
05/16/2022 08:51:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.32 on epoch=129
05/16/2022 08:51:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.40 on epoch=129
05/16/2022 08:51:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.29 on epoch=130
05/16/2022 08:51:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.41 on epoch=131
05/16/2022 08:51:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.31 on epoch=132
05/16/2022 08:51:54 - INFO - __main__ - Global step 1850 Train loss 2.35 Classification-F1 0.06932476694381455 on epoch=132
05/16/2022 08:51:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.19 on epoch=132
05/16/2022 08:51:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.37 on epoch=133
05/16/2022 08:51:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.32 on epoch=134
05/16/2022 08:51:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.37 on epoch=134
05/16/2022 08:52:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.26 on epoch=135
05/16/2022 08:52:02 - INFO - __main__ - Global step 1900 Train loss 2.30 Classification-F1 0.042841462619943635 on epoch=135
05/16/2022 08:52:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.33 on epoch=136
05/16/2022 08:52:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.30 on epoch=137
05/16/2022 08:52:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.14 on epoch=137
05/16/2022 08:52:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.28 on epoch=138
05/16/2022 08:52:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.36 on epoch=139
05/16/2022 08:52:11 - INFO - __main__ - Global step 1950 Train loss 2.28 Classification-F1 0.08516601421100457 on epoch=139
05/16/2022 08:52:12 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.27 on epoch=139
05/16/2022 08:52:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.04 on epoch=140
05/16/2022 08:52:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.22 on epoch=141
05/16/2022 08:52:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.20 on epoch=142
05/16/2022 08:52:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.12 on epoch=142
05/16/2022 08:52:20 - INFO - __main__ - Global step 2000 Train loss 2.17 Classification-F1 0.039463635382002725 on epoch=142
05/16/2022 08:52:21 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.20 on epoch=143
05/16/2022 08:52:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.34 on epoch=144
05/16/2022 08:52:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.10 on epoch=144
05/16/2022 08:52:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.17 on epoch=145
05/16/2022 08:52:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.15 on epoch=146
05/16/2022 08:52:28 - INFO - __main__ - Global step 2050 Train loss 2.19 Classification-F1 0.05369386108950537 on epoch=146
05/16/2022 08:52:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.30 on epoch=147
05/16/2022 08:52:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.24 on epoch=147
05/16/2022 08:52:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.22 on epoch=148
05/16/2022 08:52:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.34 on epoch=149
05/16/2022 08:52:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.16 on epoch=149
05/16/2022 08:52:37 - INFO - __main__ - Global step 2100 Train loss 2.25 Classification-F1 0.02848831840428479 on epoch=149
05/16/2022 08:52:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.16 on epoch=150
05/16/2022 08:52:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.33 on epoch=151
05/16/2022 08:52:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.07 on epoch=152
05/16/2022 08:52:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.17 on epoch=152
05/16/2022 08:52:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.14 on epoch=153
05/16/2022 08:52:46 - INFO - __main__ - Global step 2150 Train loss 2.17 Classification-F1 0.06874547612950507 on epoch=153
05/16/2022 08:52:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.23 on epoch=154
05/16/2022 08:52:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.22 on epoch=154
05/16/2022 08:52:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.18 on epoch=155
05/16/2022 08:52:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.07 on epoch=156
05/16/2022 08:52:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.19 on epoch=157
05/16/2022 08:52:54 - INFO - __main__ - Global step 2200 Train loss 2.18 Classification-F1 0.03404810199942045 on epoch=157
05/16/2022 08:52:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.12 on epoch=157
05/16/2022 08:52:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.20 on epoch=158
05/16/2022 08:52:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.11 on epoch=159
05/16/2022 08:53:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.02 on epoch=159
05/16/2022 08:53:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.12 on epoch=160
05/16/2022 08:53:04 - INFO - __main__ - Global step 2250 Train loss 2.11 Classification-F1 0.08554525990012071 on epoch=160
05/16/2022 08:53:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.12 on epoch=161
05/16/2022 08:53:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.18 on epoch=162
05/16/2022 08:53:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.17 on epoch=162
05/16/2022 08:53:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.99 on epoch=163
05/16/2022 08:53:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.26 on epoch=164
05/16/2022 08:53:12 - INFO - __main__ - Global step 2300 Train loss 2.14 Classification-F1 0.07306821053428718 on epoch=164
05/16/2022 08:53:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.11 on epoch=164
05/16/2022 08:53:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.16 on epoch=165
05/16/2022 08:53:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.19 on epoch=166
05/16/2022 08:53:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.10 on epoch=167
05/16/2022 08:53:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.13 on epoch=167
05/16/2022 08:53:21 - INFO - __main__ - Global step 2350 Train loss 2.14 Classification-F1 0.08106761401291554 on epoch=167
05/16/2022 08:53:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.12 on epoch=168
05/16/2022 08:53:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.20 on epoch=169
05/16/2022 08:53:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.19 on epoch=169
05/16/2022 08:53:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.16 on epoch=170
05/16/2022 08:53:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.99 on epoch=171
05/16/2022 08:53:30 - INFO - __main__ - Global step 2400 Train loss 2.13 Classification-F1 0.1279972743356626 on epoch=171
05/16/2022 08:53:30 - INFO - __main__ - Saving model with best Classification-F1: 0.09792532397574416 -> 0.1279972743356626 on epoch=171, global_step=2400
05/16/2022 08:53:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.12 on epoch=172
05/16/2022 08:53:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.11 on epoch=172
05/16/2022 08:53:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.10 on epoch=173
05/16/2022 08:53:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.12 on epoch=174
05/16/2022 08:53:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.12 on epoch=174
05/16/2022 08:53:39 - INFO - __main__ - Global step 2450 Train loss 2.11 Classification-F1 0.08636073050262648 on epoch=174
05/16/2022 08:53:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.08 on epoch=175
05/16/2022 08:53:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.00 on epoch=176
05/16/2022 08:53:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.09 on epoch=177
05/16/2022 08:53:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.04 on epoch=177
05/16/2022 08:53:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.04 on epoch=178
05/16/2022 08:53:48 - INFO - __main__ - Global step 2500 Train loss 2.05 Classification-F1 0.08215098154857191 on epoch=178
05/16/2022 08:53:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.03 on epoch=179
05/16/2022 08:53:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.01 on epoch=179
05/16/2022 08:53:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.97 on epoch=180
05/16/2022 08:53:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.00 on epoch=181
05/16/2022 08:53:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.19 on epoch=182
05/16/2022 08:53:58 - INFO - __main__ - Global step 2550 Train loss 2.04 Classification-F1 0.0767401832527883 on epoch=182
05/16/2022 08:53:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.17 on epoch=182
05/16/2022 08:54:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.00 on epoch=183
05/16/2022 08:54:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.18 on epoch=184
05/16/2022 08:54:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.04 on epoch=184
05/16/2022 08:54:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.06 on epoch=185
05/16/2022 08:54:06 - INFO - __main__ - Global step 2600 Train loss 2.09 Classification-F1 0.11065121574539484 on epoch=185
05/16/2022 08:54:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.10 on epoch=186
05/16/2022 08:54:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.15 on epoch=187
05/16/2022 08:54:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.01 on epoch=187
05/16/2022 08:54:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.99 on epoch=188
05/16/2022 08:54:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.01 on epoch=189
05/16/2022 08:54:15 - INFO - __main__ - Global step 2650 Train loss 2.05 Classification-F1 0.12183472710166829 on epoch=189
05/16/2022 08:54:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.06 on epoch=189
05/16/2022 08:54:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.91 on epoch=190
05/16/2022 08:54:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.14 on epoch=191
05/16/2022 08:54:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.99 on epoch=192
05/16/2022 08:54:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.87 on epoch=192
05/16/2022 08:54:24 - INFO - __main__ - Global step 2700 Train loss 1.99 Classification-F1 0.06381159092780327 on epoch=192
05/16/2022 08:54:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.88 on epoch=193
05/16/2022 08:54:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.14 on epoch=194
05/16/2022 08:54:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.93 on epoch=194
05/16/2022 08:54:29 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.91 on epoch=195
05/16/2022 08:54:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.02 on epoch=196
05/16/2022 08:54:33 - INFO - __main__ - Global step 2750 Train loss 1.98 Classification-F1 0.09709732377799606 on epoch=196
05/16/2022 08:54:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.89 on epoch=197
05/16/2022 08:54:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.95 on epoch=197
05/16/2022 08:54:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.01 on epoch=198
05/16/2022 08:54:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.95 on epoch=199
05/16/2022 08:54:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.89 on epoch=199
05/16/2022 08:54:43 - INFO - __main__ - Global step 2800 Train loss 1.94 Classification-F1 0.032428955188632834 on epoch=199
05/16/2022 08:54:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.93 on epoch=200
05/16/2022 08:54:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.88 on epoch=201
05/16/2022 08:54:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.17 on epoch=202
05/16/2022 08:54:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.97 on epoch=202
05/16/2022 08:54:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.18 on epoch=203
05/16/2022 08:54:52 - INFO - __main__ - Global step 2850 Train loss 2.03 Classification-F1 0.06377555283497695 on epoch=203
05/16/2022 08:54:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.04 on epoch=204
05/16/2022 08:54:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.76 on epoch=204
05/16/2022 08:54:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.95 on epoch=205
05/16/2022 08:54:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.90 on epoch=206
05/16/2022 08:54:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.93 on epoch=207
05/16/2022 08:55:01 - INFO - __main__ - Global step 2900 Train loss 1.91 Classification-F1 0.1095378255541595 on epoch=207
05/16/2022 08:55:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.92 on epoch=207
05/16/2022 08:55:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.91 on epoch=208
05/16/2022 08:55:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.88 on epoch=209
05/16/2022 08:55:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.84 on epoch=209
05/16/2022 08:55:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.80 on epoch=210
05/16/2022 08:55:09 - INFO - __main__ - Global step 2950 Train loss 1.87 Classification-F1 0.14703579757647153 on epoch=210
05/16/2022 08:55:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1279972743356626 -> 0.14703579757647153 on epoch=210, global_step=2950
05/16/2022 08:55:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.94 on epoch=211
05/16/2022 08:55:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.74 on epoch=212
05/16/2022 08:55:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.85 on epoch=212
05/16/2022 08:55:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.82 on epoch=213
05/16/2022 08:55:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.97 on epoch=214
05/16/2022 08:55:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:55:18 - INFO - __main__ - Printing 3 examples
05/16/2022 08:55:18 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 08:55:18 - INFO - __main__ - ['Plant']
05/16/2022 08:55:18 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 08:55:18 - INFO - __main__ - ['Plant']
05/16/2022 08:55:18 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 08:55:18 - INFO - __main__ - ['Plant']
05/16/2022 08:55:18 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:55:18 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:55:18 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:55:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:55:18 - INFO - __main__ - Printing 3 examples
05/16/2022 08:55:18 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 08:55:18 - INFO - __main__ - ['Plant']
05/16/2022 08:55:18 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 08:55:18 - INFO - __main__ - ['Plant']
05/16/2022 08:55:18 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 08:55:18 - INFO - __main__ - ['Plant']
05/16/2022 08:55:18 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:55:18 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:55:18 - INFO - __main__ - Global step 3000 Train loss 1.86 Classification-F1 0.1746100375231241 on epoch=214
05/16/2022 08:55:18 - INFO - __main__ - Saving model with best Classification-F1: 0.14703579757647153 -> 0.1746100375231241 on epoch=214, global_step=3000
05/16/2022 08:55:18 - INFO - __main__ - save last model!
05/16/2022 08:55:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 08:55:19 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 08:55:19 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:55:19 - INFO - __main__ - Printing 3 examples
05/16/2022 08:55:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 08:55:19 - INFO - __main__ - ['Animal']
05/16/2022 08:55:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 08:55:19 - INFO - __main__ - ['Animal']
05/16/2022 08:55:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 08:55:19 - INFO - __main__ - ['Village']
05/16/2022 08:55:19 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:55:21 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:55:24 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:55:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:55:24 - INFO - __main__ - Starting training!
05/16/2022 08:55:24 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 08:56:13 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/16/2022 08:56:13 - INFO - __main__ - Classification-F1 on test data: 0.1394
05/16/2022 08:56:14 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.1746100375231241, test_performance=0.1394210518472774
05/16/2022 08:56:14 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/16/2022 08:56:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:56:15 - INFO - __main__ - Printing 3 examples
05/16/2022 08:56:15 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 08:56:15 - INFO - __main__ - ['Plant']
05/16/2022 08:56:15 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 08:56:15 - INFO - __main__ - ['Plant']
05/16/2022 08:56:15 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 08:56:15 - INFO - __main__ - ['Plant']
05/16/2022 08:56:15 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:56:15 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:56:15 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 08:56:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 08:56:15 - INFO - __main__ - Printing 3 examples
05/16/2022 08:56:15 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 08:56:15 - INFO - __main__ - ['Plant']
05/16/2022 08:56:15 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 08:56:15 - INFO - __main__ - ['Plant']
05/16/2022 08:56:15 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 08:56:15 - INFO - __main__ - ['Plant']
05/16/2022 08:56:15 - INFO - __main__ - Tokenizing Input ...
05/16/2022 08:56:15 - INFO - __main__ - Tokenizing Output ...
05/16/2022 08:56:15 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 08:56:21 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 08:56:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 08:56:21 - INFO - __main__ - Starting training!
05/16/2022 08:56:22 - INFO - __main__ - Step 10 Global step 10 Train loss 7.78 on epoch=0
05/16/2022 08:56:24 - INFO - __main__ - Step 20 Global step 20 Train loss 7.39 on epoch=1
05/16/2022 08:56:25 - INFO - __main__ - Step 30 Global step 30 Train loss 7.39 on epoch=2
05/16/2022 08:56:26 - INFO - __main__ - Step 40 Global step 40 Train loss 7.36 on epoch=2
05/16/2022 08:56:27 - INFO - __main__ - Step 50 Global step 50 Train loss 7.05 on epoch=3
05/16/2022 08:56:48 - INFO - __main__ - Global step 50 Train loss 7.39 Classification-F1 0.0 on epoch=3
05/16/2022 08:56:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 08:56:50 - INFO - __main__ - Step 60 Global step 60 Train loss 6.89 on epoch=4
05/16/2022 08:56:51 - INFO - __main__ - Step 70 Global step 70 Train loss 6.72 on epoch=4
05/16/2022 08:56:52 - INFO - __main__ - Step 80 Global step 80 Train loss 6.76 on epoch=5
05/16/2022 08:56:54 - INFO - __main__ - Step 90 Global step 90 Train loss 6.58 on epoch=6
05/16/2022 08:56:55 - INFO - __main__ - Step 100 Global step 100 Train loss 6.77 on epoch=7
05/16/2022 08:57:58 - INFO - __main__ - Global step 100 Train loss 6.74 Classification-F1 0.0 on epoch=7
05/16/2022 08:57:59 - INFO - __main__ - Step 110 Global step 110 Train loss 6.59 on epoch=7
05/16/2022 08:58:01 - INFO - __main__ - Step 120 Global step 120 Train loss 6.38 on epoch=8
05/16/2022 08:58:02 - INFO - __main__ - Step 130 Global step 130 Train loss 6.48 on epoch=9
05/16/2022 08:58:03 - INFO - __main__ - Step 140 Global step 140 Train loss 6.15 on epoch=9
05/16/2022 08:58:05 - INFO - __main__ - Step 150 Global step 150 Train loss 6.16 on epoch=10
05/16/2022 08:58:54 - INFO - __main__ - Global step 150 Train loss 6.35 Classification-F1 0.0 on epoch=10
05/16/2022 08:58:55 - INFO - __main__ - Step 160 Global step 160 Train loss 6.02 on epoch=11
05/16/2022 08:58:56 - INFO - __main__ - Step 170 Global step 170 Train loss 6.21 on epoch=12
05/16/2022 08:58:58 - INFO - __main__ - Step 180 Global step 180 Train loss 6.09 on epoch=12
05/16/2022 08:58:59 - INFO - __main__ - Step 190 Global step 190 Train loss 5.96 on epoch=13
05/16/2022 08:59:00 - INFO - __main__ - Step 200 Global step 200 Train loss 5.87 on epoch=14
05/16/2022 09:00:16 - INFO - __main__ - Global step 200 Train loss 6.03 Classification-F1 0.0 on epoch=14
05/16/2022 09:00:17 - INFO - __main__ - Step 210 Global step 210 Train loss 5.92 on epoch=14
05/16/2022 09:00:18 - INFO - __main__ - Step 220 Global step 220 Train loss 5.88 on epoch=15
05/16/2022 09:00:20 - INFO - __main__ - Step 230 Global step 230 Train loss 5.65 on epoch=16
05/16/2022 09:00:21 - INFO - __main__ - Step 240 Global step 240 Train loss 5.83 on epoch=17
05/16/2022 09:00:22 - INFO - __main__ - Step 250 Global step 250 Train loss 5.82 on epoch=17
05/16/2022 09:01:17 - INFO - __main__ - Global step 250 Train loss 5.82 Classification-F1 0.0 on epoch=17
05/16/2022 09:01:18 - INFO - __main__ - Step 260 Global step 260 Train loss 5.72 on epoch=18
05/16/2022 09:01:19 - INFO - __main__ - Step 270 Global step 270 Train loss 5.64 on epoch=19
05/16/2022 09:01:21 - INFO - __main__ - Step 280 Global step 280 Train loss 5.60 on epoch=19
05/16/2022 09:01:22 - INFO - __main__ - Step 290 Global step 290 Train loss 5.65 on epoch=20
05/16/2022 09:01:23 - INFO - __main__ - Step 300 Global step 300 Train loss 5.44 on epoch=21
05/16/2022 09:01:43 - INFO - __main__ - Global step 300 Train loss 5.61 Classification-F1 0.001670843776106934 on epoch=21
05/16/2022 09:01:43 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.001670843776106934 on epoch=21, global_step=300
05/16/2022 09:01:45 - INFO - __main__ - Step 310 Global step 310 Train loss 5.40 on epoch=22
05/16/2022 09:01:46 - INFO - __main__ - Step 320 Global step 320 Train loss 5.33 on epoch=22
05/16/2022 09:01:48 - INFO - __main__ - Step 330 Global step 330 Train loss 5.28 on epoch=23
05/16/2022 09:01:49 - INFO - __main__ - Step 340 Global step 340 Train loss 5.20 on epoch=24
05/16/2022 09:01:50 - INFO - __main__ - Step 350 Global step 350 Train loss 5.01 on epoch=24
05/16/2022 09:01:54 - INFO - __main__ - Global step 350 Train loss 5.24 Classification-F1 0.006211180124223603 on epoch=24
05/16/2022 09:01:54 - INFO - __main__ - Saving model with best Classification-F1: 0.001670843776106934 -> 0.006211180124223603 on epoch=24, global_step=350
05/16/2022 09:01:55 - INFO - __main__ - Step 360 Global step 360 Train loss 5.03 on epoch=25
05/16/2022 09:01:56 - INFO - __main__ - Step 370 Global step 370 Train loss 4.90 on epoch=26
05/16/2022 09:01:58 - INFO - __main__ - Step 380 Global step 380 Train loss 5.11 on epoch=27
05/16/2022 09:01:59 - INFO - __main__ - Step 390 Global step 390 Train loss 5.03 on epoch=27
05/16/2022 09:02:00 - INFO - __main__ - Step 400 Global step 400 Train loss 4.84 on epoch=28
05/16/2022 09:02:03 - INFO - __main__ - Global step 400 Train loss 4.98 Classification-F1 0.009523809523809523 on epoch=28
05/16/2022 09:02:03 - INFO - __main__ - Saving model with best Classification-F1: 0.006211180124223603 -> 0.009523809523809523 on epoch=28, global_step=400
05/16/2022 09:02:04 - INFO - __main__ - Step 410 Global step 410 Train loss 4.97 on epoch=29
05/16/2022 09:02:05 - INFO - __main__ - Step 420 Global step 420 Train loss 4.91 on epoch=29
05/16/2022 09:02:07 - INFO - __main__ - Step 430 Global step 430 Train loss 4.85 on epoch=30
05/16/2022 09:02:08 - INFO - __main__ - Step 440 Global step 440 Train loss 4.63 on epoch=31
05/16/2022 09:02:09 - INFO - __main__ - Step 450 Global step 450 Train loss 4.77 on epoch=32
05/16/2022 09:02:11 - INFO - __main__ - Global step 450 Train loss 4.83 Classification-F1 0.009523809523809523 on epoch=32
05/16/2022 09:02:13 - INFO - __main__ - Step 460 Global step 460 Train loss 4.83 on epoch=32
05/16/2022 09:02:14 - INFO - __main__ - Step 470 Global step 470 Train loss 4.56 on epoch=33
05/16/2022 09:02:15 - INFO - __main__ - Step 480 Global step 480 Train loss 4.49 on epoch=34
05/16/2022 09:02:17 - INFO - __main__ - Step 490 Global step 490 Train loss 4.41 on epoch=34
05/16/2022 09:02:18 - INFO - __main__ - Step 500 Global step 500 Train loss 4.37 on epoch=35
05/16/2022 09:02:20 - INFO - __main__ - Global step 500 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=35
05/16/2022 09:02:21 - INFO - __main__ - Step 510 Global step 510 Train loss 4.23 on epoch=36
05/16/2022 09:02:23 - INFO - __main__ - Step 520 Global step 520 Train loss 4.44 on epoch=37
05/16/2022 09:02:24 - INFO - __main__ - Step 530 Global step 530 Train loss 4.23 on epoch=37
05/16/2022 09:02:25 - INFO - __main__ - Step 540 Global step 540 Train loss 4.16 on epoch=38
05/16/2022 09:02:26 - INFO - __main__ - Step 550 Global step 550 Train loss 4.06 on epoch=39
05/16/2022 09:02:28 - INFO - __main__ - Global step 550 Train loss 4.22 Classification-F1 0.0200271395816761 on epoch=39
05/16/2022 09:02:28 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.0200271395816761 on epoch=39, global_step=550
05/16/2022 09:02:30 - INFO - __main__ - Step 560 Global step 560 Train loss 3.96 on epoch=39
05/16/2022 09:02:31 - INFO - __main__ - Step 570 Global step 570 Train loss 3.89 on epoch=40
05/16/2022 09:02:32 - INFO - __main__ - Step 580 Global step 580 Train loss 3.95 on epoch=41
05/16/2022 09:02:33 - INFO - __main__ - Step 590 Global step 590 Train loss 3.90 on epoch=42
05/16/2022 09:02:35 - INFO - __main__ - Step 600 Global step 600 Train loss 3.78 on epoch=42
05/16/2022 09:02:37 - INFO - __main__ - Global step 600 Train loss 3.90 Classification-F1 0.023094829698603287 on epoch=42
05/16/2022 09:02:37 - INFO - __main__ - Saving model with best Classification-F1: 0.0200271395816761 -> 0.023094829698603287 on epoch=42, global_step=600
05/16/2022 09:02:38 - INFO - __main__ - Step 610 Global step 610 Train loss 3.91 on epoch=43
05/16/2022 09:02:39 - INFO - __main__ - Step 620 Global step 620 Train loss 3.59 on epoch=44
05/16/2022 09:02:41 - INFO - __main__ - Step 630 Global step 630 Train loss 3.67 on epoch=44
05/16/2022 09:02:42 - INFO - __main__ - Step 640 Global step 640 Train loss 3.72 on epoch=45
05/16/2022 09:02:43 - INFO - __main__ - Step 650 Global step 650 Train loss 3.62 on epoch=46
05/16/2022 09:02:45 - INFO - __main__ - Global step 650 Train loss 3.70 Classification-F1 0.026227058329052446 on epoch=46
05/16/2022 09:02:45 - INFO - __main__ - Saving model with best Classification-F1: 0.023094829698603287 -> 0.026227058329052446 on epoch=46, global_step=650
05/16/2022 09:02:46 - INFO - __main__ - Step 660 Global step 660 Train loss 3.69 on epoch=47
05/16/2022 09:02:48 - INFO - __main__ - Step 670 Global step 670 Train loss 3.32 on epoch=47
05/16/2022 09:02:49 - INFO - __main__ - Step 680 Global step 680 Train loss 3.62 on epoch=48
05/16/2022 09:02:50 - INFO - __main__ - Step 690 Global step 690 Train loss 3.45 on epoch=49
05/16/2022 09:02:51 - INFO - __main__ - Step 700 Global step 700 Train loss 3.58 on epoch=49
05/16/2022 09:02:53 - INFO - __main__ - Global step 700 Train loss 3.53 Classification-F1 0.03942182933779572 on epoch=49
05/16/2022 09:02:53 - INFO - __main__ - Saving model with best Classification-F1: 0.026227058329052446 -> 0.03942182933779572 on epoch=49, global_step=700
05/16/2022 09:02:55 - INFO - __main__ - Step 710 Global step 710 Train loss 3.25 on epoch=50
05/16/2022 09:02:56 - INFO - __main__ - Step 720 Global step 720 Train loss 3.36 on epoch=51
05/16/2022 09:02:57 - INFO - __main__ - Step 730 Global step 730 Train loss 3.44 on epoch=52
05/16/2022 09:02:59 - INFO - __main__ - Step 740 Global step 740 Train loss 3.26 on epoch=52
05/16/2022 09:03:00 - INFO - __main__ - Step 750 Global step 750 Train loss 3.36 on epoch=53
05/16/2022 09:03:02 - INFO - __main__ - Global step 750 Train loss 3.33 Classification-F1 0.04128577441655533 on epoch=53
05/16/2022 09:03:02 - INFO - __main__ - Saving model with best Classification-F1: 0.03942182933779572 -> 0.04128577441655533 on epoch=53, global_step=750
05/16/2022 09:03:03 - INFO - __main__ - Step 760 Global step 760 Train loss 3.07 on epoch=54
05/16/2022 09:03:04 - INFO - __main__ - Step 770 Global step 770 Train loss 3.12 on epoch=54
05/16/2022 09:03:06 - INFO - __main__ - Step 780 Global step 780 Train loss 3.26 on epoch=55
05/16/2022 09:03:07 - INFO - __main__ - Step 790 Global step 790 Train loss 3.23 on epoch=56
05/16/2022 09:03:08 - INFO - __main__ - Step 800 Global step 800 Train loss 3.20 on epoch=57
05/16/2022 09:03:10 - INFO - __main__ - Global step 800 Train loss 3.18 Classification-F1 0.04330958948816501 on epoch=57
05/16/2022 09:03:10 - INFO - __main__ - Saving model with best Classification-F1: 0.04128577441655533 -> 0.04330958948816501 on epoch=57, global_step=800
05/16/2022 09:03:11 - INFO - __main__ - Step 810 Global step 810 Train loss 3.15 on epoch=57
05/16/2022 09:03:13 - INFO - __main__ - Step 820 Global step 820 Train loss 3.13 on epoch=58
05/16/2022 09:03:14 - INFO - __main__ - Step 830 Global step 830 Train loss 3.08 on epoch=59
05/16/2022 09:03:16 - INFO - __main__ - Step 840 Global step 840 Train loss 3.02 on epoch=59
05/16/2022 09:03:17 - INFO - __main__ - Step 850 Global step 850 Train loss 2.89 on epoch=60
05/16/2022 09:03:19 - INFO - __main__ - Global step 850 Train loss 3.06 Classification-F1 0.025749621205767736 on epoch=60
05/16/2022 09:03:20 - INFO - __main__ - Step 860 Global step 860 Train loss 3.19 on epoch=61
05/16/2022 09:03:22 - INFO - __main__ - Step 870 Global step 870 Train loss 3.20 on epoch=62
05/16/2022 09:03:23 - INFO - __main__ - Step 880 Global step 880 Train loss 2.77 on epoch=62
05/16/2022 09:03:25 - INFO - __main__ - Step 890 Global step 890 Train loss 2.92 on epoch=63
05/16/2022 09:03:26 - INFO - __main__ - Step 900 Global step 900 Train loss 2.99 on epoch=64
05/16/2022 09:03:28 - INFO - __main__ - Global step 900 Train loss 3.01 Classification-F1 0.030619195381172224 on epoch=64
05/16/2022 09:03:29 - INFO - __main__ - Step 910 Global step 910 Train loss 2.95 on epoch=64
05/16/2022 09:03:30 - INFO - __main__ - Step 920 Global step 920 Train loss 2.80 on epoch=65
05/16/2022 09:03:32 - INFO - __main__ - Step 930 Global step 930 Train loss 2.95 on epoch=66
05/16/2022 09:03:33 - INFO - __main__ - Step 940 Global step 940 Train loss 2.91 on epoch=67
05/16/2022 09:03:34 - INFO - __main__ - Step 950 Global step 950 Train loss 2.97 on epoch=67
05/16/2022 09:03:36 - INFO - __main__ - Global step 950 Train loss 2.91 Classification-F1 0.009523809523809523 on epoch=67
05/16/2022 09:03:38 - INFO - __main__ - Step 960 Global step 960 Train loss 3.03 on epoch=68
05/16/2022 09:03:39 - INFO - __main__ - Step 970 Global step 970 Train loss 2.95 on epoch=69
05/16/2022 09:03:40 - INFO - __main__ - Step 980 Global step 980 Train loss 2.86 on epoch=69
05/16/2022 09:03:42 - INFO - __main__ - Step 990 Global step 990 Train loss 2.64 on epoch=70
05/16/2022 09:03:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.98 on epoch=71
05/16/2022 09:03:45 - INFO - __main__ - Global step 1000 Train loss 2.89 Classification-F1 0.04597201523431032 on epoch=71
05/16/2022 09:03:45 - INFO - __main__ - Saving model with best Classification-F1: 0.04330958948816501 -> 0.04597201523431032 on epoch=71, global_step=1000
05/16/2022 09:03:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.05 on epoch=72
05/16/2022 09:03:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.94 on epoch=72
05/16/2022 09:03:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.97 on epoch=73
05/16/2022 09:03:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.79 on epoch=74
05/16/2022 09:03:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.74 on epoch=74
05/16/2022 09:03:54 - INFO - __main__ - Global step 1050 Train loss 2.90 Classification-F1 0.030529383470559942 on epoch=74
05/16/2022 09:03:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.54 on epoch=75
05/16/2022 09:03:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.83 on epoch=76
05/16/2022 09:03:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.93 on epoch=77
05/16/2022 09:03:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.87 on epoch=77
05/16/2022 09:04:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.69 on epoch=78
05/16/2022 09:04:03 - INFO - __main__ - Global step 1100 Train loss 2.77 Classification-F1 0.042616774594823985 on epoch=78
05/16/2022 09:04:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.87 on epoch=79
05/16/2022 09:04:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.73 on epoch=79
05/16/2022 09:04:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=80
05/16/2022 09:04:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.77 on epoch=81
05/16/2022 09:04:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.71 on epoch=82
05/16/2022 09:04:12 - INFO - __main__ - Global step 1150 Train loss 2.72 Classification-F1 0.009603841536614645 on epoch=82
05/16/2022 09:04:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.47 on epoch=82
05/16/2022 09:04:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=83
05/16/2022 09:04:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.77 on epoch=84
05/16/2022 09:04:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.78 on epoch=84
05/16/2022 09:04:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.63 on epoch=85
05/16/2022 09:04:20 - INFO - __main__ - Global step 1200 Train loss 2.68 Classification-F1 0.01684981684981685 on epoch=85
05/16/2022 09:04:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.80 on epoch=86
05/16/2022 09:04:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.67 on epoch=87
05/16/2022 09:04:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.51 on epoch=87
05/16/2022 09:04:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.68 on epoch=88
05/16/2022 09:04:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.71 on epoch=89
05/16/2022 09:04:29 - INFO - __main__ - Global step 1250 Train loss 2.67 Classification-F1 0.04071046005002686 on epoch=89
05/16/2022 09:04:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.52 on epoch=89
05/16/2022 09:04:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.37 on epoch=90
05/16/2022 09:04:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.63 on epoch=91
05/16/2022 09:04:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.60 on epoch=92
05/16/2022 09:04:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.68 on epoch=92
05/16/2022 09:04:38 - INFO - __main__ - Global step 1300 Train loss 2.56 Classification-F1 0.03548410668615272 on epoch=92
05/16/2022 09:04:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.67 on epoch=93
05/16/2022 09:04:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.46 on epoch=94
05/16/2022 09:04:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.65 on epoch=94
05/16/2022 09:04:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.41 on epoch=95
05/16/2022 09:04:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.72 on epoch=96
05/16/2022 09:04:46 - INFO - __main__ - Global step 1350 Train loss 2.58 Classification-F1 0.01859857243389967 on epoch=96
05/16/2022 09:04:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.52 on epoch=97
05/16/2022 09:04:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.36 on epoch=97
05/16/2022 09:04:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.51 on epoch=98
05/16/2022 09:04:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.64 on epoch=99
05/16/2022 09:04:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.49 on epoch=99
05/16/2022 09:04:56 - INFO - __main__ - Global step 1400 Train loss 2.51 Classification-F1 0.017540349473122583 on epoch=99
05/16/2022 09:04:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.36 on epoch=100
05/16/2022 09:04:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.61 on epoch=101
05/16/2022 09:05:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.43 on epoch=102
05/16/2022 09:05:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.46 on epoch=102
05/16/2022 09:05:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.51 on epoch=103
05/16/2022 09:05:04 - INFO - __main__ - Global step 1450 Train loss 2.47 Classification-F1 0.009981285090455396 on epoch=103
05/16/2022 09:05:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.57 on epoch=104
05/16/2022 09:05:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.39 on epoch=104
05/16/2022 09:05:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.39 on epoch=105
05/16/2022 09:05:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.52 on epoch=106
05/16/2022 09:05:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.50 on epoch=107
05/16/2022 09:05:14 - INFO - __main__ - Global step 1500 Train loss 2.47 Classification-F1 0.009563658099222952 on epoch=107
05/16/2022 09:05:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.37 on epoch=107
05/16/2022 09:05:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.46 on epoch=108
05/16/2022 09:05:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.46 on epoch=109
05/16/2022 09:05:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.44 on epoch=109
05/16/2022 09:05:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.31 on epoch=110
05/16/2022 09:05:22 - INFO - __main__ - Global step 1550 Train loss 2.41 Classification-F1 0.00976800976800977 on epoch=110
05/16/2022 09:05:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.71 on epoch=111
05/16/2022 09:05:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.45 on epoch=112
05/16/2022 09:05:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.38 on epoch=112
05/16/2022 09:05:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.44 on epoch=113
05/16/2022 09:05:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.46 on epoch=114
05/16/2022 09:05:31 - INFO - __main__ - Global step 1600 Train loss 2.49 Classification-F1 0.02539843523616343 on epoch=114
05/16/2022 09:05:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.39 on epoch=114
05/16/2022 09:05:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=115
05/16/2022 09:05:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.54 on epoch=116
05/16/2022 09:05:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.46 on epoch=117
05/16/2022 09:05:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.42 on epoch=117
05/16/2022 09:05:40 - INFO - __main__ - Global step 1650 Train loss 2.42 Classification-F1 0.03448045885020675 on epoch=117
05/16/2022 09:05:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.38 on epoch=118
05/16/2022 09:05:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.40 on epoch=119
05/16/2022 09:05:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.36 on epoch=119
05/16/2022 09:05:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.26 on epoch=120
05/16/2022 09:05:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.43 on epoch=121
05/16/2022 09:05:48 - INFO - __main__ - Global step 1700 Train loss 2.37 Classification-F1 0.03299880671908943 on epoch=121
05/16/2022 09:05:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.34 on epoch=122
05/16/2022 09:05:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.42 on epoch=122
05/16/2022 09:05:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.38 on epoch=123
05/16/2022 09:05:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.33 on epoch=124
05/16/2022 09:05:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.44 on epoch=124
05/16/2022 09:05:57 - INFO - __main__ - Global step 1750 Train loss 2.38 Classification-F1 0.009644364074743823 on epoch=124
05/16/2022 09:05:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.19 on epoch=125
05/16/2022 09:06:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.38 on epoch=126
05/16/2022 09:06:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.32 on epoch=127
05/16/2022 09:06:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.35 on epoch=127
05/16/2022 09:06:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.41 on epoch=128
05/16/2022 09:06:06 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.009563658099222952 on epoch=128
05/16/2022 09:06:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.53 on epoch=129
05/16/2022 09:06:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.26 on epoch=129
05/16/2022 09:06:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.29 on epoch=130
05/16/2022 09:06:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.44 on epoch=131
05/16/2022 09:06:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.28 on epoch=132
05/16/2022 09:06:15 - INFO - __main__ - Global step 1850 Train loss 2.36 Classification-F1 0.01821329390125149 on epoch=132
05/16/2022 09:06:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.24 on epoch=132
05/16/2022 09:06:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.30 on epoch=133
05/16/2022 09:06:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.20 on epoch=134
05/16/2022 09:06:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.31 on epoch=134
05/16/2022 09:06:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.17 on epoch=135
05/16/2022 09:06:24 - INFO - __main__ - Global step 1900 Train loss 2.24 Classification-F1 0.0173015873015873 on epoch=135
05/16/2022 09:06:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.34 on epoch=136
05/16/2022 09:06:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.45 on epoch=137
05/16/2022 09:06:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.17 on epoch=137
05/16/2022 09:06:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.26 on epoch=138
05/16/2022 09:06:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.28 on epoch=139
05/16/2022 09:06:33 - INFO - __main__ - Global step 1950 Train loss 2.30 Classification-F1 0.03815945890551342 on epoch=139
05/16/2022 09:06:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.24 on epoch=139
05/16/2022 09:06:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.12 on epoch=140
05/16/2022 09:06:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.34 on epoch=141
05/16/2022 09:06:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.19 on epoch=142
05/16/2022 09:06:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.11 on epoch=142
05/16/2022 09:06:41 - INFO - __main__ - Global step 2000 Train loss 2.20 Classification-F1 0.03237537026533056 on epoch=142
05/16/2022 09:06:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.27 on epoch=143
05/16/2022 09:06:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.30 on epoch=144
05/16/2022 09:06:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.21 on epoch=144
05/16/2022 09:06:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.16 on epoch=145
05/16/2022 09:06:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.23 on epoch=146
05/16/2022 09:06:50 - INFO - __main__ - Global step 2050 Train loss 2.23 Classification-F1 0.031266119501413614 on epoch=146
05/16/2022 09:06:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.09 on epoch=147
05/16/2022 09:06:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.17 on epoch=147
05/16/2022 09:06:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.14 on epoch=148
05/16/2022 09:06:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.17 on epoch=149
05/16/2022 09:06:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.28 on epoch=149
05/16/2022 09:06:59 - INFO - __main__ - Global step 2100 Train loss 2.17 Classification-F1 0.047908962382646594 on epoch=149
05/16/2022 09:06:59 - INFO - __main__ - Saving model with best Classification-F1: 0.04597201523431032 -> 0.047908962382646594 on epoch=149, global_step=2100
05/16/2022 09:07:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.12 on epoch=150
05/16/2022 09:07:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.21 on epoch=151
05/16/2022 09:07:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.16 on epoch=152
05/16/2022 09:07:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.13 on epoch=152
05/16/2022 09:07:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.14 on epoch=153
05/16/2022 09:07:07 - INFO - __main__ - Global step 2150 Train loss 2.15 Classification-F1 0.040203935408440264 on epoch=153
05/16/2022 09:07:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.17 on epoch=154
05/16/2022 09:07:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.14 on epoch=154
05/16/2022 09:07:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.07 on epoch=155
05/16/2022 09:07:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.20 on epoch=156
05/16/2022 09:07:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.19 on epoch=157
05/16/2022 09:07:16 - INFO - __main__ - Global step 2200 Train loss 2.15 Classification-F1 0.04658091524450971 on epoch=157
05/16/2022 09:07:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.11 on epoch=157
05/16/2022 09:07:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.13 on epoch=158
05/16/2022 09:07:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.35 on epoch=159
05/16/2022 09:07:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.09 on epoch=159
05/16/2022 09:07:22 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.99 on epoch=160
05/16/2022 09:07:24 - INFO - __main__ - Global step 2250 Train loss 2.13 Classification-F1 0.03142928223640453 on epoch=160
05/16/2022 09:07:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.15 on epoch=161
05/16/2022 09:07:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.13 on epoch=162
05/16/2022 09:07:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.94 on epoch=162
05/16/2022 09:07:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.16 on epoch=163
05/16/2022 09:07:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.10 on epoch=164
05/16/2022 09:07:33 - INFO - __main__ - Global step 2300 Train loss 2.10 Classification-F1 0.02653453274246962 on epoch=164
05/16/2022 09:07:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.95 on epoch=164
05/16/2022 09:07:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.14 on epoch=165
05/16/2022 09:07:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.14 on epoch=166
05/16/2022 09:07:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.97 on epoch=167
05/16/2022 09:07:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.98 on epoch=167
05/16/2022 09:07:41 - INFO - __main__ - Global step 2350 Train loss 2.03 Classification-F1 0.02191401320321181 on epoch=167
05/16/2022 09:07:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.04 on epoch=168
05/16/2022 09:07:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.17 on epoch=169
05/16/2022 09:07:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.05 on epoch=169
05/16/2022 09:07:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.94 on epoch=170
05/16/2022 09:07:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.14 on epoch=171
05/16/2022 09:07:50 - INFO - __main__ - Global step 2400 Train loss 2.07 Classification-F1 0.06162667804206133 on epoch=171
05/16/2022 09:07:50 - INFO - __main__ - Saving model with best Classification-F1: 0.047908962382646594 -> 0.06162667804206133 on epoch=171, global_step=2400
05/16/2022 09:07:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.08 on epoch=172
05/16/2022 09:07:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.06 on epoch=172
05/16/2022 09:07:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.03 on epoch=173
05/16/2022 09:07:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.25 on epoch=174
05/16/2022 09:07:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.04 on epoch=174
05/16/2022 09:07:59 - INFO - __main__ - Global step 2450 Train loss 2.09 Classification-F1 0.06436763743985287 on epoch=174
05/16/2022 09:07:59 - INFO - __main__ - Saving model with best Classification-F1: 0.06162667804206133 -> 0.06436763743985287 on epoch=174, global_step=2450
05/16/2022 09:08:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.00 on epoch=175
05/16/2022 09:08:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.16 on epoch=176
05/16/2022 09:08:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.08 on epoch=177
05/16/2022 09:08:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.10 on epoch=177
05/16/2022 09:08:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.06 on epoch=178
05/16/2022 09:08:08 - INFO - __main__ - Global step 2500 Train loss 2.08 Classification-F1 0.03567792771041884 on epoch=178
05/16/2022 09:08:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.07 on epoch=179
05/16/2022 09:08:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.03 on epoch=179
05/16/2022 09:08:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.98 on epoch=180
05/16/2022 09:08:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.07 on epoch=181
05/16/2022 09:08:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.02 on epoch=182
05/16/2022 09:08:17 - INFO - __main__ - Global step 2550 Train loss 2.03 Classification-F1 0.06633062282805793 on epoch=182
05/16/2022 09:08:17 - INFO - __main__ - Saving model with best Classification-F1: 0.06436763743985287 -> 0.06633062282805793 on epoch=182, global_step=2550
05/16/2022 09:08:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.96 on epoch=182
05/16/2022 09:08:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.10 on epoch=183
05/16/2022 09:08:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.07 on epoch=184
05/16/2022 09:08:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.88 on epoch=184
05/16/2022 09:08:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.89 on epoch=185
05/16/2022 09:08:25 - INFO - __main__ - Global step 2600 Train loss 1.98 Classification-F1 0.05829225322812231 on epoch=185
05/16/2022 09:08:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.04 on epoch=186
05/16/2022 09:08:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.06 on epoch=187
05/16/2022 09:08:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.01 on epoch=187
05/16/2022 09:08:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.91 on epoch=188
05/16/2022 09:08:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.95 on epoch=189
05/16/2022 09:08:34 - INFO - __main__ - Global step 2650 Train loss 1.99 Classification-F1 0.05541127650661119 on epoch=189
05/16/2022 09:08:35 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.04 on epoch=189
05/16/2022 09:08:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.94 on epoch=190
05/16/2022 09:08:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.77 on epoch=191
05/16/2022 09:08:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.97 on epoch=192
05/16/2022 09:08:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.04 on epoch=192
05/16/2022 09:08:43 - INFO - __main__ - Global step 2700 Train loss 1.95 Classification-F1 0.05029732751317736 on epoch=192
05/16/2022 09:08:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.92 on epoch=193
05/16/2022 09:08:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.04 on epoch=194
05/16/2022 09:08:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.01 on epoch=194
05/16/2022 09:08:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.81 on epoch=195
05/16/2022 09:08:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.97 on epoch=196
05/16/2022 09:08:51 - INFO - __main__ - Global step 2750 Train loss 1.95 Classification-F1 0.06288139392173114 on epoch=196
05/16/2022 09:08:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.90 on epoch=197
05/16/2022 09:08:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.83 on epoch=197
05/16/2022 09:08:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.89 on epoch=198
05/16/2022 09:08:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.89 on epoch=199
05/16/2022 09:08:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.88 on epoch=199
05/16/2022 09:09:00 - INFO - __main__ - Global step 2800 Train loss 1.88 Classification-F1 0.06757184355223571 on epoch=199
05/16/2022 09:09:00 - INFO - __main__ - Saving model with best Classification-F1: 0.06633062282805793 -> 0.06757184355223571 on epoch=199, global_step=2800
05/16/2022 09:09:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.95 on epoch=200
05/16/2022 09:09:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.94 on epoch=201
05/16/2022 09:09:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.98 on epoch=202
05/16/2022 09:09:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.81 on epoch=202
05/16/2022 09:09:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.82 on epoch=203
05/16/2022 09:09:09 - INFO - __main__ - Global step 2850 Train loss 1.90 Classification-F1 0.08760807839209815 on epoch=203
05/16/2022 09:09:09 - INFO - __main__ - Saving model with best Classification-F1: 0.06757184355223571 -> 0.08760807839209815 on epoch=203, global_step=2850
05/16/2022 09:09:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.87 on epoch=204
05/16/2022 09:09:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.96 on epoch=204
05/16/2022 09:09:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.81 on epoch=205
05/16/2022 09:09:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.86 on epoch=206
05/16/2022 09:09:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.80 on epoch=207
05/16/2022 09:09:18 - INFO - __main__ - Global step 2900 Train loss 1.86 Classification-F1 0.09128023537141387 on epoch=207
05/16/2022 09:09:18 - INFO - __main__ - Saving model with best Classification-F1: 0.08760807839209815 -> 0.09128023537141387 on epoch=207, global_step=2900
05/16/2022 09:09:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.81 on epoch=207
05/16/2022 09:09:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.80 on epoch=208
05/16/2022 09:09:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.82 on epoch=209
05/16/2022 09:09:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.84 on epoch=209
05/16/2022 09:09:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.77 on epoch=210
05/16/2022 09:09:26 - INFO - __main__ - Global step 2950 Train loss 1.81 Classification-F1 0.07217303302729187 on epoch=210
05/16/2022 09:09:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.91 on epoch=211
05/16/2022 09:09:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.99 on epoch=212
05/16/2022 09:09:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.92 on epoch=212
05/16/2022 09:09:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.74 on epoch=213
05/16/2022 09:09:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.80 on epoch=214
05/16/2022 09:09:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:09:34 - INFO - __main__ - Printing 3 examples
05/16/2022 09:09:34 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 09:09:34 - INFO - __main__ - ['Plant']
05/16/2022 09:09:34 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 09:09:34 - INFO - __main__ - ['Plant']
05/16/2022 09:09:34 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 09:09:34 - INFO - __main__ - ['Plant']
05/16/2022 09:09:34 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:09:34 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:09:35 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 09:09:35 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:09:35 - INFO - __main__ - Printing 3 examples
05/16/2022 09:09:35 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 09:09:35 - INFO - __main__ - ['Plant']
05/16/2022 09:09:35 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 09:09:35 - INFO - __main__ - ['Plant']
05/16/2022 09:09:35 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 09:09:35 - INFO - __main__ - ['Plant']
05/16/2022 09:09:35 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:09:35 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:09:35 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 09:09:35 - INFO - __main__ - Global step 3000 Train loss 1.87 Classification-F1 0.04565594353683502 on epoch=214
05/16/2022 09:09:35 - INFO - __main__ - save last model!
05/16/2022 09:09:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 09:09:35 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 09:09:35 - INFO - __main__ - Printing 3 examples
05/16/2022 09:09:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 09:09:35 - INFO - __main__ - ['Animal']
05/16/2022 09:09:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 09:09:35 - INFO - __main__ - ['Animal']
05/16/2022 09:09:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 09:09:35 - INFO - __main__ - ['Village']
05/16/2022 09:09:35 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:09:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:09:41 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 09:09:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 09:09:41 - INFO - __main__ - Starting training!
05/16/2022 09:09:42 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 09:10:13 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/16/2022 09:10:13 - INFO - __main__ - Classification-F1 on test data: 0.0481
05/16/2022 09:10:14 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.09128023537141387, test_performance=0.04810263099986528
05/16/2022 09:10:14 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/16/2022 09:10:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:10:15 - INFO - __main__ - Printing 3 examples
05/16/2022 09:10:15 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 09:10:15 - INFO - __main__ - ['Plant']
05/16/2022 09:10:15 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 09:10:15 - INFO - __main__ - ['Plant']
05/16/2022 09:10:15 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 09:10:15 - INFO - __main__ - ['Plant']
05/16/2022 09:10:15 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:10:15 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:10:15 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 09:10:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:10:15 - INFO - __main__ - Printing 3 examples
05/16/2022 09:10:15 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 09:10:15 - INFO - __main__ - ['Plant']
05/16/2022 09:10:15 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 09:10:15 - INFO - __main__ - ['Plant']
05/16/2022 09:10:15 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 09:10:15 - INFO - __main__ - ['Plant']
05/16/2022 09:10:15 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:10:15 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:10:15 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 09:10:21 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 09:10:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 09:10:21 - INFO - __main__ - Starting training!
05/16/2022 09:10:22 - INFO - __main__ - Step 10 Global step 10 Train loss 7.74 on epoch=0
05/16/2022 09:10:24 - INFO - __main__ - Step 20 Global step 20 Train loss 7.41 on epoch=1
05/16/2022 09:10:25 - INFO - __main__ - Step 30 Global step 30 Train loss 7.65 on epoch=2
05/16/2022 09:10:26 - INFO - __main__ - Step 40 Global step 40 Train loss 7.47 on epoch=2
05/16/2022 09:10:28 - INFO - __main__ - Step 50 Global step 50 Train loss 7.26 on epoch=3
05/16/2022 09:10:36 - INFO - __main__ - Global step 50 Train loss 7.51 Classification-F1 0.0 on epoch=3
05/16/2022 09:10:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 09:10:38 - INFO - __main__ - Step 60 Global step 60 Train loss 7.30 on epoch=4
05/16/2022 09:10:39 - INFO - __main__ - Step 70 Global step 70 Train loss 7.07 on epoch=4
05/16/2022 09:10:40 - INFO - __main__ - Step 80 Global step 80 Train loss 7.14 on epoch=5
05/16/2022 09:10:42 - INFO - __main__ - Step 90 Global step 90 Train loss 6.97 on epoch=6
05/16/2022 09:10:43 - INFO - __main__ - Step 100 Global step 100 Train loss 7.04 on epoch=7
05/16/2022 09:11:43 - INFO - __main__ - Global step 100 Train loss 7.10 Classification-F1 0.0 on epoch=7
05/16/2022 09:11:44 - INFO - __main__ - Step 110 Global step 110 Train loss 7.12 on epoch=7
05/16/2022 09:11:45 - INFO - __main__ - Step 120 Global step 120 Train loss 6.70 on epoch=8
05/16/2022 09:11:47 - INFO - __main__ - Step 130 Global step 130 Train loss 6.77 on epoch=9
05/16/2022 09:11:48 - INFO - __main__ - Step 140 Global step 140 Train loss 6.68 on epoch=9
05/16/2022 09:11:49 - INFO - __main__ - Step 150 Global step 150 Train loss 6.67 on epoch=10
05/16/2022 09:13:03 - INFO - __main__ - Global step 150 Train loss 6.79 Classification-F1 0.0 on epoch=10
05/16/2022 09:13:04 - INFO - __main__ - Step 160 Global step 160 Train loss 6.48 on epoch=11
05/16/2022 09:13:06 - INFO - __main__ - Step 170 Global step 170 Train loss 6.59 on epoch=12
05/16/2022 09:13:07 - INFO - __main__ - Step 180 Global step 180 Train loss 6.62 on epoch=12
05/16/2022 09:13:08 - INFO - __main__ - Step 190 Global step 190 Train loss 6.37 on epoch=13
05/16/2022 09:13:10 - INFO - __main__ - Step 200 Global step 200 Train loss 6.38 on epoch=14
05/16/2022 09:13:58 - INFO - __main__ - Global step 200 Train loss 6.49 Classification-F1 0.0 on epoch=14
05/16/2022 09:13:59 - INFO - __main__ - Step 210 Global step 210 Train loss 6.33 on epoch=14
05/16/2022 09:14:01 - INFO - __main__ - Step 220 Global step 220 Train loss 6.35 on epoch=15
05/16/2022 09:14:02 - INFO - __main__ - Step 230 Global step 230 Train loss 6.10 on epoch=16
05/16/2022 09:14:04 - INFO - __main__ - Step 240 Global step 240 Train loss 6.30 on epoch=17
05/16/2022 09:14:05 - INFO - __main__ - Step 250 Global step 250 Train loss 6.19 on epoch=17
05/16/2022 09:14:55 - INFO - __main__ - Global step 250 Train loss 6.26 Classification-F1 0.0 on epoch=17
05/16/2022 09:14:57 - INFO - __main__ - Step 260 Global step 260 Train loss 6.18 on epoch=18
05/16/2022 09:14:58 - INFO - __main__ - Step 270 Global step 270 Train loss 6.12 on epoch=19
05/16/2022 09:14:59 - INFO - __main__ - Step 280 Global step 280 Train loss 5.94 on epoch=19
05/16/2022 09:15:01 - INFO - __main__ - Step 290 Global step 290 Train loss 5.96 on epoch=20
05/16/2022 09:15:02 - INFO - __main__ - Step 300 Global step 300 Train loss 5.96 on epoch=21
05/16/2022 09:16:08 - INFO - __main__ - Global step 300 Train loss 6.03 Classification-F1 0.0 on epoch=21
05/16/2022 09:16:09 - INFO - __main__ - Step 310 Global step 310 Train loss 6.02 on epoch=22
05/16/2022 09:16:11 - INFO - __main__ - Step 320 Global step 320 Train loss 6.03 on epoch=22
05/16/2022 09:16:12 - INFO - __main__ - Step 330 Global step 330 Train loss 5.73 on epoch=23
05/16/2022 09:16:13 - INFO - __main__ - Step 340 Global step 340 Train loss 5.73 on epoch=24
05/16/2022 09:16:14 - INFO - __main__ - Step 350 Global step 350 Train loss 5.77 on epoch=24
05/16/2022 09:16:56 - INFO - __main__ - Global step 350 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/16/2022 09:16:58 - INFO - __main__ - Step 360 Global step 360 Train loss 5.53 on epoch=25
05/16/2022 09:16:59 - INFO - __main__ - Step 370 Global step 370 Train loss 5.70 on epoch=26
05/16/2022 09:17:00 - INFO - __main__ - Step 380 Global step 380 Train loss 5.71 on epoch=27
05/16/2022 09:17:02 - INFO - __main__ - Step 390 Global step 390 Train loss 5.69 on epoch=27
05/16/2022 09:17:03 - INFO - __main__ - Step 400 Global step 400 Train loss 5.53 on epoch=28
05/16/2022 09:18:13 - INFO - __main__ - Global step 400 Train loss 5.63 Classification-F1 0.0 on epoch=28
05/16/2022 09:18:14 - INFO - __main__ - Step 410 Global step 410 Train loss 5.64 on epoch=29
05/16/2022 09:18:15 - INFO - __main__ - Step 420 Global step 420 Train loss 5.48 on epoch=29
05/16/2022 09:18:17 - INFO - __main__ - Step 430 Global step 430 Train loss 5.49 on epoch=30
05/16/2022 09:18:18 - INFO - __main__ - Step 440 Global step 440 Train loss 5.38 on epoch=31
05/16/2022 09:18:20 - INFO - __main__ - Step 450 Global step 450 Train loss 5.32 on epoch=32
05/16/2022 09:19:31 - INFO - __main__ - Global step 450 Train loss 5.46 Classification-F1 0.0 on epoch=32
05/16/2022 09:19:32 - INFO - __main__ - Step 460 Global step 460 Train loss 5.43 on epoch=32
05/16/2022 09:19:34 - INFO - __main__ - Step 470 Global step 470 Train loss 5.33 on epoch=33
05/16/2022 09:19:35 - INFO - __main__ - Step 480 Global step 480 Train loss 5.38 on epoch=34
05/16/2022 09:19:36 - INFO - __main__ - Step 490 Global step 490 Train loss 5.24 on epoch=34
05/16/2022 09:19:38 - INFO - __main__ - Step 500 Global step 500 Train loss 5.12 on epoch=35
05/16/2022 09:20:27 - INFO - __main__ - Global step 500 Train loss 5.30 Classification-F1 0.0 on epoch=35
05/16/2022 09:20:28 - INFO - __main__ - Step 510 Global step 510 Train loss 5.14 on epoch=36
05/16/2022 09:20:30 - INFO - __main__ - Step 520 Global step 520 Train loss 5.22 on epoch=37
05/16/2022 09:20:31 - INFO - __main__ - Step 530 Global step 530 Train loss 5.14 on epoch=37
05/16/2022 09:20:32 - INFO - __main__ - Step 540 Global step 540 Train loss 5.02 on epoch=38
05/16/2022 09:20:33 - INFO - __main__ - Step 550 Global step 550 Train loss 5.01 on epoch=39
05/16/2022 09:20:45 - INFO - __main__ - Global step 550 Train loss 5.10 Classification-F1 0.0 on epoch=39
05/16/2022 09:20:46 - INFO - __main__ - Step 560 Global step 560 Train loss 5.00 on epoch=39
05/16/2022 09:20:48 - INFO - __main__ - Step 570 Global step 570 Train loss 4.98 on epoch=40
05/16/2022 09:20:49 - INFO - __main__ - Step 580 Global step 580 Train loss 4.91 on epoch=41
05/16/2022 09:20:51 - INFO - __main__ - Step 590 Global step 590 Train loss 5.16 on epoch=42
05/16/2022 09:20:52 - INFO - __main__ - Step 600 Global step 600 Train loss 5.00 on epoch=42
05/16/2022 09:21:00 - INFO - __main__ - Global step 600 Train loss 5.01 Classification-F1 0.0 on epoch=42
05/16/2022 09:21:01 - INFO - __main__ - Step 610 Global step 610 Train loss 4.83 on epoch=43
05/16/2022 09:21:03 - INFO - __main__ - Step 620 Global step 620 Train loss 4.76 on epoch=44
05/16/2022 09:21:04 - INFO - __main__ - Step 630 Global step 630 Train loss 4.78 on epoch=44
05/16/2022 09:21:05 - INFO - __main__ - Step 640 Global step 640 Train loss 4.79 on epoch=45
05/16/2022 09:21:07 - INFO - __main__ - Step 650 Global step 650 Train loss 4.73 on epoch=46
05/16/2022 09:21:09 - INFO - __main__ - Global step 650 Train loss 4.78 Classification-F1 0.010551948051948054 on epoch=46
05/16/2022 09:21:09 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.010551948051948054 on epoch=46, global_step=650
05/16/2022 09:21:11 - INFO - __main__ - Step 660 Global step 660 Train loss 4.65 on epoch=47
05/16/2022 09:21:12 - INFO - __main__ - Step 670 Global step 670 Train loss 4.73 on epoch=47
05/16/2022 09:21:13 - INFO - __main__ - Step 680 Global step 680 Train loss 4.60 on epoch=48
05/16/2022 09:21:15 - INFO - __main__ - Step 690 Global step 690 Train loss 4.53 on epoch=49
05/16/2022 09:21:16 - INFO - __main__ - Step 700 Global step 700 Train loss 4.64 on epoch=49
05/16/2022 09:21:18 - INFO - __main__ - Global step 700 Train loss 4.63 Classification-F1 0.009006473402758232 on epoch=49
05/16/2022 09:21:19 - INFO - __main__ - Step 710 Global step 710 Train loss 4.57 on epoch=50
05/16/2022 09:21:20 - INFO - __main__ - Step 720 Global step 720 Train loss 4.44 on epoch=51
05/16/2022 09:21:22 - INFO - __main__ - Step 730 Global step 730 Train loss 4.56 on epoch=52
05/16/2022 09:21:23 - INFO - __main__ - Step 740 Global step 740 Train loss 4.48 on epoch=52
05/16/2022 09:21:25 - INFO - __main__ - Step 750 Global step 750 Train loss 4.22 on epoch=53
05/16/2022 09:21:26 - INFO - __main__ - Global step 750 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=53
05/16/2022 09:21:28 - INFO - __main__ - Step 760 Global step 760 Train loss 4.20 on epoch=54
05/16/2022 09:21:29 - INFO - __main__ - Step 770 Global step 770 Train loss 4.25 on epoch=54
05/16/2022 09:21:30 - INFO - __main__ - Step 780 Global step 780 Train loss 4.29 on epoch=55
05/16/2022 09:21:32 - INFO - __main__ - Step 790 Global step 790 Train loss 4.20 on epoch=56
05/16/2022 09:21:33 - INFO - __main__ - Step 800 Global step 800 Train loss 4.21 on epoch=57
05/16/2022 09:21:35 - INFO - __main__ - Global step 800 Train loss 4.23 Classification-F1 0.008438818565400845 on epoch=57
05/16/2022 09:21:36 - INFO - __main__ - Step 810 Global step 810 Train loss 4.12 on epoch=57
05/16/2022 09:21:38 - INFO - __main__ - Step 820 Global step 820 Train loss 4.10 on epoch=58
05/16/2022 09:21:39 - INFO - __main__ - Step 830 Global step 830 Train loss 4.13 on epoch=59
05/16/2022 09:21:40 - INFO - __main__ - Step 840 Global step 840 Train loss 3.90 on epoch=59
05/16/2022 09:21:42 - INFO - __main__ - Step 850 Global step 850 Train loss 3.88 on epoch=60
05/16/2022 09:21:44 - INFO - __main__ - Global step 850 Train loss 4.03 Classification-F1 0.00892608089260809 on epoch=60
05/16/2022 09:21:45 - INFO - __main__ - Step 860 Global step 860 Train loss 3.96 on epoch=61
05/16/2022 09:21:46 - INFO - __main__ - Step 870 Global step 870 Train loss 3.83 on epoch=62
05/16/2022 09:21:47 - INFO - __main__ - Step 880 Global step 880 Train loss 3.85 on epoch=62
05/16/2022 09:21:49 - INFO - __main__ - Step 890 Global step 890 Train loss 3.84 on epoch=63
05/16/2022 09:21:50 - INFO - __main__ - Step 900 Global step 900 Train loss 4.04 on epoch=64
05/16/2022 09:21:52 - INFO - __main__ - Global step 900 Train loss 3.90 Classification-F1 0.009563658099222952 on epoch=64
05/16/2022 09:21:53 - INFO - __main__ - Step 910 Global step 910 Train loss 3.89 on epoch=64
05/16/2022 09:21:55 - INFO - __main__ - Step 920 Global step 920 Train loss 3.71 on epoch=65
05/16/2022 09:21:56 - INFO - __main__ - Step 930 Global step 930 Train loss 3.83 on epoch=66
05/16/2022 09:21:57 - INFO - __main__ - Step 940 Global step 940 Train loss 3.79 on epoch=67
05/16/2022 09:21:59 - INFO - __main__ - Step 950 Global step 950 Train loss 3.78 on epoch=67
05/16/2022 09:22:01 - INFO - __main__ - Global step 950 Train loss 3.80 Classification-F1 0.008403361344537815 on epoch=67
05/16/2022 09:22:02 - INFO - __main__ - Step 960 Global step 960 Train loss 4.01 on epoch=68
05/16/2022 09:22:03 - INFO - __main__ - Step 970 Global step 970 Train loss 3.76 on epoch=69
05/16/2022 09:22:05 - INFO - __main__ - Step 980 Global step 980 Train loss 3.90 on epoch=69
05/16/2022 09:22:06 - INFO - __main__ - Step 990 Global step 990 Train loss 3.68 on epoch=70
05/16/2022 09:22:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.54 on epoch=71
05/16/2022 09:22:09 - INFO - __main__ - Global step 1000 Train loss 3.78 Classification-F1 0.02133884387405514 on epoch=71
05/16/2022 09:22:09 - INFO - __main__ - Saving model with best Classification-F1: 0.010551948051948054 -> 0.02133884387405514 on epoch=71, global_step=1000
05/16/2022 09:22:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.65 on epoch=72
05/16/2022 09:22:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.48 on epoch=72
05/16/2022 09:22:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.67 on epoch=73
05/16/2022 09:22:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.54 on epoch=74
05/16/2022 09:22:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.67 on epoch=74
05/16/2022 09:22:18 - INFO - __main__ - Global step 1050 Train loss 3.60 Classification-F1 0.018692796635061626 on epoch=74
05/16/2022 09:22:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.41 on epoch=75
05/16/2022 09:22:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.68 on epoch=76
05/16/2022 09:22:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.65 on epoch=77
05/16/2022 09:22:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.46 on epoch=77
05/16/2022 09:22:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.61 on epoch=78
05/16/2022 09:22:26 - INFO - __main__ - Global step 1100 Train loss 3.56 Classification-F1 0.01785945147289685 on epoch=78
05/16/2022 09:22:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.41 on epoch=79
05/16/2022 09:22:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.49 on epoch=79
05/16/2022 09:22:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.52 on epoch=80
05/16/2022 09:22:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.41 on epoch=81
05/16/2022 09:22:33 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.72 on epoch=82
05/16/2022 09:22:35 - INFO - __main__ - Global step 1150 Train loss 3.51 Classification-F1 0.021158827539195638 on epoch=82
05/16/2022 09:22:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.38 on epoch=82
05/16/2022 09:22:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.46 on epoch=83
05/16/2022 09:22:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.49 on epoch=84
05/16/2022 09:22:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.56 on epoch=84
05/16/2022 09:22:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.22 on epoch=85
05/16/2022 09:22:44 - INFO - __main__ - Global step 1200 Train loss 3.42 Classification-F1 0.02825489922264116 on epoch=85
05/16/2022 09:22:44 - INFO - __main__ - Saving model with best Classification-F1: 0.02133884387405514 -> 0.02825489922264116 on epoch=85, global_step=1200
05/16/2022 09:22:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.31 on epoch=86
05/16/2022 09:22:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.32 on epoch=87
05/16/2022 09:22:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.19 on epoch=87
05/16/2022 09:22:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.28 on epoch=88
05/16/2022 09:22:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.41 on epoch=89
05/16/2022 09:22:52 - INFO - __main__ - Global step 1250 Train loss 3.30 Classification-F1 0.0325978344554196 on epoch=89
05/16/2022 09:22:52 - INFO - __main__ - Saving model with best Classification-F1: 0.02825489922264116 -> 0.0325978344554196 on epoch=89, global_step=1250
05/16/2022 09:22:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.33 on epoch=89
05/16/2022 09:22:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.25 on epoch=90
05/16/2022 09:22:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.26 on epoch=91
05/16/2022 09:22:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.31 on epoch=92
05/16/2022 09:22:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.23 on epoch=92
05/16/2022 09:23:01 - INFO - __main__ - Global step 1300 Train loss 3.28 Classification-F1 0.020044802867383513 on epoch=92
05/16/2022 09:23:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.28 on epoch=93
05/16/2022 09:23:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.30 on epoch=94
05/16/2022 09:23:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.23 on epoch=94
05/16/2022 09:23:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.20 on epoch=95
05/16/2022 09:23:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.12 on epoch=96
05/16/2022 09:23:10 - INFO - __main__ - Global step 1350 Train loss 3.23 Classification-F1 0.02570638511814982 on epoch=96
05/16/2022 09:23:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.22 on epoch=97
05/16/2022 09:23:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.26 on epoch=97
05/16/2022 09:23:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.21 on epoch=98
05/16/2022 09:23:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.35 on epoch=99
05/16/2022 09:23:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.35 on epoch=99
05/16/2022 09:23:18 - INFO - __main__ - Global step 1400 Train loss 3.28 Classification-F1 0.03740617807554927 on epoch=99
05/16/2022 09:23:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0325978344554196 -> 0.03740617807554927 on epoch=99, global_step=1400
05/16/2022 09:23:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.01 on epoch=100
05/16/2022 09:23:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.24 on epoch=101
05/16/2022 09:23:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.20 on epoch=102
05/16/2022 09:23:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.03 on epoch=102
05/16/2022 09:23:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.11 on epoch=103
05/16/2022 09:23:27 - INFO - __main__ - Global step 1450 Train loss 3.12 Classification-F1 0.024716813032964233 on epoch=103
05/16/2022 09:23:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.16 on epoch=104
05/16/2022 09:23:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.97 on epoch=104
05/16/2022 09:23:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.94 on epoch=105
05/16/2022 09:23:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.11 on epoch=106
05/16/2022 09:23:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.07 on epoch=107
05/16/2022 09:23:36 - INFO - __main__ - Global step 1500 Train loss 3.05 Classification-F1 0.029645028651063915 on epoch=107
05/16/2022 09:23:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.87 on epoch=107
05/16/2022 09:23:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.95 on epoch=108
05/16/2022 09:23:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.14 on epoch=109
05/16/2022 09:23:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.04 on epoch=109
05/16/2022 09:23:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.03 on epoch=110
05/16/2022 09:23:44 - INFO - __main__ - Global step 1550 Train loss 3.01 Classification-F1 0.029594645311540765 on epoch=110
05/16/2022 09:23:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.14 on epoch=111
05/16/2022 09:23:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.93 on epoch=112
05/16/2022 09:23:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.87 on epoch=112
05/16/2022 09:23:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.06 on epoch=113
05/16/2022 09:23:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.00 on epoch=114
05/16/2022 09:23:53 - INFO - __main__ - Global step 1600 Train loss 3.00 Classification-F1 0.040725761307657864 on epoch=114
05/16/2022 09:23:53 - INFO - __main__ - Saving model with best Classification-F1: 0.03740617807554927 -> 0.040725761307657864 on epoch=114, global_step=1600
05/16/2022 09:23:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.01 on epoch=114
05/16/2022 09:23:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.89 on epoch=115
05/16/2022 09:23:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.89 on epoch=116
05/16/2022 09:23:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.00 on epoch=117
05/16/2022 09:24:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.84 on epoch=117
05/16/2022 09:24:02 - INFO - __main__ - Global step 1650 Train loss 2.93 Classification-F1 0.03234662659865313 on epoch=117
05/16/2022 09:24:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.97 on epoch=118
05/16/2022 09:24:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.04 on epoch=119
05/16/2022 09:24:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.91 on epoch=119
05/16/2022 09:24:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.70 on epoch=120
05/16/2022 09:24:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.04 on epoch=121
05/16/2022 09:24:11 - INFO - __main__ - Global step 1700 Train loss 2.93 Classification-F1 0.009685230024213076 on epoch=121
05/16/2022 09:24:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.02 on epoch=122
05/16/2022 09:24:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.91 on epoch=122
05/16/2022 09:24:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.85 on epoch=123
05/16/2022 09:24:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.90 on epoch=124
05/16/2022 09:24:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.94 on epoch=124
05/16/2022 09:24:19 - INFO - __main__ - Global step 1750 Train loss 2.93 Classification-F1 0.02530752167775761 on epoch=124
05/16/2022 09:24:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.92 on epoch=125
05/16/2022 09:24:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.99 on epoch=126
05/16/2022 09:24:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.81 on epoch=127
05/16/2022 09:24:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.74 on epoch=127
05/16/2022 09:24:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.01 on epoch=128
05/16/2022 09:24:28 - INFO - __main__ - Global step 1800 Train loss 2.89 Classification-F1 0.022360248447204967 on epoch=128
05/16/2022 09:24:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.82 on epoch=129
05/16/2022 09:24:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.74 on epoch=129
05/16/2022 09:24:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.87 on epoch=130
05/16/2022 09:24:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.91 on epoch=131
05/16/2022 09:24:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.97 on epoch=132
05/16/2022 09:24:37 - INFO - __main__ - Global step 1850 Train loss 2.86 Classification-F1 0.045566502463054194 on epoch=132
05/16/2022 09:24:37 - INFO - __main__ - Saving model with best Classification-F1: 0.040725761307657864 -> 0.045566502463054194 on epoch=132, global_step=1850
05/16/2022 09:24:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.78 on epoch=132
05/16/2022 09:24:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.94 on epoch=133
05/16/2022 09:24:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.81 on epoch=134
05/16/2022 09:24:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.85 on epoch=134
05/16/2022 09:24:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.70 on epoch=135
05/16/2022 09:24:46 - INFO - __main__ - Global step 1900 Train loss 2.82 Classification-F1 0.027167717850947664 on epoch=135
05/16/2022 09:24:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.76 on epoch=136
05/16/2022 09:24:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.69 on epoch=137
05/16/2022 09:24:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.69 on epoch=137
05/16/2022 09:24:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.81 on epoch=138
05/16/2022 09:24:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.72 on epoch=139
05/16/2022 09:24:55 - INFO - __main__ - Global step 1950 Train loss 2.74 Classification-F1 0.04412817015556742 on epoch=139
05/16/2022 09:24:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.89 on epoch=139
05/16/2022 09:24:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.53 on epoch=140
05/16/2022 09:24:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.71 on epoch=141
05/16/2022 09:25:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.72 on epoch=142
05/16/2022 09:25:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.64 on epoch=142
05/16/2022 09:25:04 - INFO - __main__ - Global step 2000 Train loss 2.70 Classification-F1 0.04027093596059113 on epoch=142
05/16/2022 09:25:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.85 on epoch=143
05/16/2022 09:25:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.74 on epoch=144
05/16/2022 09:25:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.62 on epoch=144
05/16/2022 09:25:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.55 on epoch=145
05/16/2022 09:25:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.76 on epoch=146
05/16/2022 09:25:13 - INFO - __main__ - Global step 2050 Train loss 2.71 Classification-F1 0.0298874017889298 on epoch=146
05/16/2022 09:25:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.71 on epoch=147
05/16/2022 09:25:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.44 on epoch=147
05/16/2022 09:25:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.73 on epoch=148
05/16/2022 09:25:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.69 on epoch=149
05/16/2022 09:25:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.78 on epoch=149
05/16/2022 09:25:22 - INFO - __main__ - Global step 2100 Train loss 2.67 Classification-F1 0.023067757080732054 on epoch=149
05/16/2022 09:25:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.57 on epoch=150
05/16/2022 09:25:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.77 on epoch=151
05/16/2022 09:25:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.74 on epoch=152
05/16/2022 09:25:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.71 on epoch=152
05/16/2022 09:25:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.76 on epoch=153
05/16/2022 09:25:31 - INFO - __main__ - Global step 2150 Train loss 2.71 Classification-F1 0.036413755948639666 on epoch=153
05/16/2022 09:25:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.71 on epoch=154
05/16/2022 09:25:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.88 on epoch=154
05/16/2022 09:25:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.40 on epoch=155
05/16/2022 09:25:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.75 on epoch=156
05/16/2022 09:25:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.72 on epoch=157
05/16/2022 09:25:41 - INFO - __main__ - Global step 2200 Train loss 2.69 Classification-F1 0.027220587231548136 on epoch=157
05/16/2022 09:25:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.55 on epoch=157
05/16/2022 09:25:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.65 on epoch=158
05/16/2022 09:25:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.55 on epoch=159
05/16/2022 09:25:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.67 on epoch=159
05/16/2022 09:25:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.59 on epoch=160
05/16/2022 09:25:50 - INFO - __main__ - Global step 2250 Train loss 2.60 Classification-F1 0.021284614921498135 on epoch=160
05/16/2022 09:25:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.65 on epoch=161
05/16/2022 09:25:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.74 on epoch=162
05/16/2022 09:25:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.52 on epoch=162
05/16/2022 09:25:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.81 on epoch=163
05/16/2022 09:25:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.53 on epoch=164
05/16/2022 09:26:00 - INFO - __main__ - Global step 2300 Train loss 2.65 Classification-F1 0.04231365021883736 on epoch=164
05/16/2022 09:26:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.76 on epoch=164
05/16/2022 09:26:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.42 on epoch=165
05/16/2022 09:26:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.66 on epoch=166
05/16/2022 09:26:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.68 on epoch=167
05/16/2022 09:26:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.70 on epoch=167
05/16/2022 09:26:09 - INFO - __main__ - Global step 2350 Train loss 2.64 Classification-F1 0.04769492568521971 on epoch=167
05/16/2022 09:26:09 - INFO - __main__ - Saving model with best Classification-F1: 0.045566502463054194 -> 0.04769492568521971 on epoch=167, global_step=2350
05/16/2022 09:26:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.51 on epoch=168
05/16/2022 09:26:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.47 on epoch=169
05/16/2022 09:26:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.69 on epoch=169
05/16/2022 09:26:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.22 on epoch=170
05/16/2022 09:26:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.79 on epoch=171
05/16/2022 09:26:18 - INFO - __main__ - Global step 2400 Train loss 2.53 Classification-F1 0.03735537213628994 on epoch=171
05/16/2022 09:26:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.65 on epoch=172
05/16/2022 09:26:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.56 on epoch=172
05/16/2022 09:26:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.61 on epoch=173
05/16/2022 09:26:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.46 on epoch=174
05/16/2022 09:26:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.60 on epoch=174
05/16/2022 09:26:27 - INFO - __main__ - Global step 2450 Train loss 2.58 Classification-F1 0.033191152567221584 on epoch=174
05/16/2022 09:26:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.38 on epoch=175
05/16/2022 09:26:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.66 on epoch=176
05/16/2022 09:26:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.55 on epoch=177
05/16/2022 09:26:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.58 on epoch=177
05/16/2022 09:26:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.58 on epoch=178
05/16/2022 09:26:35 - INFO - __main__ - Global step 2500 Train loss 2.55 Classification-F1 0.05581797664292635 on epoch=178
05/16/2022 09:26:35 - INFO - __main__ - Saving model with best Classification-F1: 0.04769492568521971 -> 0.05581797664292635 on epoch=178, global_step=2500
05/16/2022 09:26:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.61 on epoch=179
05/16/2022 09:26:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.52 on epoch=179
05/16/2022 09:26:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.39 on epoch=180
05/16/2022 09:26:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.44 on epoch=181
05/16/2022 09:26:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.45 on epoch=182
05/16/2022 09:26:44 - INFO - __main__ - Global step 2550 Train loss 2.48 Classification-F1 0.050119869256614866 on epoch=182
05/16/2022 09:26:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.36 on epoch=182
05/16/2022 09:26:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.45 on epoch=183
05/16/2022 09:26:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.45 on epoch=184
05/16/2022 09:26:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.41 on epoch=184
05/16/2022 09:26:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.54 on epoch=185
05/16/2022 09:26:53 - INFO - __main__ - Global step 2600 Train loss 2.44 Classification-F1 0.031312205520930926 on epoch=185
05/16/2022 09:26:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.60 on epoch=186
05/16/2022 09:26:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.41 on epoch=187
05/16/2022 09:26:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.38 on epoch=187
05/16/2022 09:26:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.39 on epoch=188
05/16/2022 09:27:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.53 on epoch=189
05/16/2022 09:27:02 - INFO - __main__ - Global step 2650 Train loss 2.46 Classification-F1 0.04898239607300094 on epoch=189
05/16/2022 09:27:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.43 on epoch=189
05/16/2022 09:27:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.31 on epoch=190
05/16/2022 09:27:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.49 on epoch=191
05/16/2022 09:27:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.52 on epoch=192
05/16/2022 09:27:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.34 on epoch=192
05/16/2022 09:27:10 - INFO - __main__ - Global step 2700 Train loss 2.42 Classification-F1 0.042943722943722944 on epoch=192
05/16/2022 09:27:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.43 on epoch=193
05/16/2022 09:27:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.34 on epoch=194
05/16/2022 09:27:14 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.45 on epoch=194
05/16/2022 09:27:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.38 on epoch=195
05/16/2022 09:27:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.40 on epoch=196
05/16/2022 09:27:19 - INFO - __main__ - Global step 2750 Train loss 2.40 Classification-F1 0.047283615261143344 on epoch=196
05/16/2022 09:27:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.36 on epoch=197
05/16/2022 09:27:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.37 on epoch=197
05/16/2022 09:27:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.52 on epoch=198
05/16/2022 09:27:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.46 on epoch=199
05/16/2022 09:27:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.41 on epoch=199
05/16/2022 09:27:28 - INFO - __main__ - Global step 2800 Train loss 2.42 Classification-F1 0.05426710092555489 on epoch=199
05/16/2022 09:27:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.29 on epoch=200
05/16/2022 09:27:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.67 on epoch=201
05/16/2022 09:27:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.39 on epoch=202
05/16/2022 09:27:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.38 on epoch=202
05/16/2022 09:27:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.46 on epoch=203
05/16/2022 09:27:36 - INFO - __main__ - Global step 2850 Train loss 2.44 Classification-F1 0.04893769101843637 on epoch=203
05/16/2022 09:27:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.43 on epoch=204
05/16/2022 09:27:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.30 on epoch=204
05/16/2022 09:27:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.19 on epoch=205
05/16/2022 09:27:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.46 on epoch=206
05/16/2022 09:27:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.44 on epoch=207
05/16/2022 09:27:45 - INFO - __main__ - Global step 2900 Train loss 2.36 Classification-F1 0.0196219715956558 on epoch=207
05/16/2022 09:27:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.19 on epoch=207
05/16/2022 09:27:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.37 on epoch=208
05/16/2022 09:27:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.41 on epoch=209
05/16/2022 09:27:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.48 on epoch=209
05/16/2022 09:27:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.34 on epoch=210
05/16/2022 09:27:53 - INFO - __main__ - Global step 2950 Train loss 2.36 Classification-F1 0.04166897619522721 on epoch=210
05/16/2022 09:27:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.24 on epoch=211
05/16/2022 09:27:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.40 on epoch=212
05/16/2022 09:27:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.47 on epoch=212
05/16/2022 09:27:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.45 on epoch=213
05/16/2022 09:28:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.27 on epoch=214
05/16/2022 09:28:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:28:01 - INFO - __main__ - Printing 3 examples
05/16/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 09:28:01 - INFO - __main__ - ['Plant']
05/16/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 09:28:01 - INFO - __main__ - ['Plant']
05/16/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 09:28:01 - INFO - __main__ - ['Plant']
05/16/2022 09:28:01 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:28:01 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:28:01 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 09:28:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:28:01 - INFO - __main__ - Printing 3 examples
05/16/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 09:28:01 - INFO - __main__ - ['Plant']
05/16/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 09:28:01 - INFO - __main__ - ['Plant']
05/16/2022 09:28:01 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 09:28:01 - INFO - __main__ - ['Plant']
05/16/2022 09:28:01 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:28:01 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:28:02 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 09:28:02 - INFO - __main__ - Global step 3000 Train loss 2.36 Classification-F1 0.046092189346564796 on epoch=214
05/16/2022 09:28:02 - INFO - __main__ - save last model!
05/16/2022 09:28:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 09:28:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 09:28:02 - INFO - __main__ - Printing 3 examples
05/16/2022 09:28:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 09:28:02 - INFO - __main__ - ['Animal']
05/16/2022 09:28:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 09:28:02 - INFO - __main__ - ['Animal']
05/16/2022 09:28:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 09:28:02 - INFO - __main__ - ['Village']
05/16/2022 09:28:02 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:28:04 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:28:07 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 09:28:07 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 09:28:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 09:28:08 - INFO - __main__ - Starting training!
05/16/2022 09:28:37 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/16/2022 09:28:37 - INFO - __main__ - Classification-F1 on test data: 0.0403
05/16/2022 09:28:37 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.05581797664292635, test_performance=0.0402732922290327
05/16/2022 09:28:37 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/16/2022 09:28:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:28:38 - INFO - __main__ - Printing 3 examples
05/16/2022 09:28:38 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/16/2022 09:28:38 - INFO - __main__ - ['Plant']
05/16/2022 09:28:38 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/16/2022 09:28:38 - INFO - __main__ - ['Plant']
05/16/2022 09:28:38 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/16/2022 09:28:38 - INFO - __main__ - ['Plant']
05/16/2022 09:28:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:28:39 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:28:39 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 09:28:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:28:39 - INFO - __main__ - Printing 3 examples
05/16/2022 09:28:39 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/16/2022 09:28:39 - INFO - __main__ - ['Plant']
05/16/2022 09:28:39 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/16/2022 09:28:39 - INFO - __main__ - ['Plant']
05/16/2022 09:28:39 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/16/2022 09:28:39 - INFO - __main__ - ['Plant']
05/16/2022 09:28:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:28:39 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:28:39 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 09:28:44 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 09:28:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 09:28:44 - INFO - __main__ - Starting training!
05/16/2022 09:28:47 - INFO - __main__ - Step 10 Global step 10 Train loss 7.60 on epoch=0
05/16/2022 09:28:49 - INFO - __main__ - Step 20 Global step 20 Train loss 7.44 on epoch=1
05/16/2022 09:28:50 - INFO - __main__ - Step 30 Global step 30 Train loss 7.55 on epoch=2
05/16/2022 09:28:51 - INFO - __main__ - Step 40 Global step 40 Train loss 7.72 on epoch=2
05/16/2022 09:28:53 - INFO - __main__ - Step 50 Global step 50 Train loss 7.34 on epoch=3
05/16/2022 09:28:59 - INFO - __main__ - Global step 50 Train loss 7.53 Classification-F1 0.0 on epoch=3
05/16/2022 09:28:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 09:29:00 - INFO - __main__ - Step 60 Global step 60 Train loss 7.22 on epoch=4
05/16/2022 09:29:02 - INFO - __main__ - Step 70 Global step 70 Train loss 7.26 on epoch=4
05/16/2022 09:29:03 - INFO - __main__ - Step 80 Global step 80 Train loss 7.11 on epoch=5
05/16/2022 09:29:04 - INFO - __main__ - Step 90 Global step 90 Train loss 7.04 on epoch=6
05/16/2022 09:29:06 - INFO - __main__ - Step 100 Global step 100 Train loss 7.07 on epoch=7
05/16/2022 09:29:28 - INFO - __main__ - Global step 100 Train loss 7.14 Classification-F1 0.0 on epoch=7
05/16/2022 09:29:30 - INFO - __main__ - Step 110 Global step 110 Train loss 7.26 on epoch=7
05/16/2022 09:29:31 - INFO - __main__ - Step 120 Global step 120 Train loss 6.87 on epoch=8
05/16/2022 09:29:32 - INFO - __main__ - Step 130 Global step 130 Train loss 6.91 on epoch=9
05/16/2022 09:29:34 - INFO - __main__ - Step 140 Global step 140 Train loss 6.89 on epoch=9
05/16/2022 09:29:35 - INFO - __main__ - Step 150 Global step 150 Train loss 6.87 on epoch=10
05/16/2022 09:30:13 - INFO - __main__ - Global step 150 Train loss 6.96 Classification-F1 0.0 on epoch=10
05/16/2022 09:30:15 - INFO - __main__ - Step 160 Global step 160 Train loss 6.65 on epoch=11
05/16/2022 09:30:16 - INFO - __main__ - Step 170 Global step 170 Train loss 6.79 on epoch=12
05/16/2022 09:30:17 - INFO - __main__ - Step 180 Global step 180 Train loss 6.89 on epoch=12
05/16/2022 09:30:19 - INFO - __main__ - Step 190 Global step 190 Train loss 6.57 on epoch=13
05/16/2022 09:30:20 - INFO - __main__ - Step 200 Global step 200 Train loss 6.63 on epoch=14
05/16/2022 09:31:23 - INFO - __main__ - Global step 200 Train loss 6.71 Classification-F1 0.0 on epoch=14
05/16/2022 09:31:24 - INFO - __main__ - Step 210 Global step 210 Train loss 6.51 on epoch=14
05/16/2022 09:31:25 - INFO - __main__ - Step 220 Global step 220 Train loss 6.50 on epoch=15
05/16/2022 09:31:27 - INFO - __main__ - Step 230 Global step 230 Train loss 6.35 on epoch=16
05/16/2022 09:31:28 - INFO - __main__ - Step 240 Global step 240 Train loss 6.50 on epoch=17
05/16/2022 09:31:29 - INFO - __main__ - Step 250 Global step 250 Train loss 6.49 on epoch=17
05/16/2022 09:32:37 - INFO - __main__ - Global step 250 Train loss 6.47 Classification-F1 0.0 on epoch=17
05/16/2022 09:32:39 - INFO - __main__ - Step 260 Global step 260 Train loss 6.32 on epoch=18
05/16/2022 09:32:40 - INFO - __main__ - Step 270 Global step 270 Train loss 6.24 on epoch=19
05/16/2022 09:32:41 - INFO - __main__ - Step 280 Global step 280 Train loss 6.27 on epoch=19
05/16/2022 09:32:43 - INFO - __main__ - Step 290 Global step 290 Train loss 6.22 on epoch=20
05/16/2022 09:32:44 - INFO - __main__ - Step 300 Global step 300 Train loss 6.08 on epoch=21
05/16/2022 09:33:58 - INFO - __main__ - Global step 300 Train loss 6.23 Classification-F1 0.0 on epoch=21
05/16/2022 09:34:00 - INFO - __main__ - Step 310 Global step 310 Train loss 6.39 on epoch=22
05/16/2022 09:34:01 - INFO - __main__ - Step 320 Global step 320 Train loss 6.33 on epoch=22
05/16/2022 09:34:02 - INFO - __main__ - Step 330 Global step 330 Train loss 6.14 on epoch=23
05/16/2022 09:34:04 - INFO - __main__ - Step 340 Global step 340 Train loss 6.27 on epoch=24
05/16/2022 09:34:05 - INFO - __main__ - Step 350 Global step 350 Train loss 6.09 on epoch=24
05/16/2022 09:34:59 - INFO - __main__ - Global step 350 Train loss 6.24 Classification-F1 0.0 on epoch=24
05/16/2022 09:35:00 - INFO - __main__ - Step 360 Global step 360 Train loss 6.14 on epoch=25
05/16/2022 09:35:02 - INFO - __main__ - Step 370 Global step 370 Train loss 5.98 on epoch=26
05/16/2022 09:35:03 - INFO - __main__ - Step 380 Global step 380 Train loss 6.10 on epoch=27
05/16/2022 09:35:04 - INFO - __main__ - Step 390 Global step 390 Train loss 6.12 on epoch=27
05/16/2022 09:35:06 - INFO - __main__ - Step 400 Global step 400 Train loss 5.99 on epoch=28
05/16/2022 09:36:05 - INFO - __main__ - Global step 400 Train loss 6.07 Classification-F1 0.0 on epoch=28
05/16/2022 09:36:06 - INFO - __main__ - Step 410 Global step 410 Train loss 5.99 on epoch=29
05/16/2022 09:36:07 - INFO - __main__ - Step 420 Global step 420 Train loss 5.81 on epoch=29
05/16/2022 09:36:09 - INFO - __main__ - Step 430 Global step 430 Train loss 5.99 on epoch=30
05/16/2022 09:36:10 - INFO - __main__ - Step 440 Global step 440 Train loss 5.87 on epoch=31
05/16/2022 09:36:11 - INFO - __main__ - Step 450 Global step 450 Train loss 6.04 on epoch=32
05/16/2022 09:37:04 - INFO - __main__ - Global step 450 Train loss 5.94 Classification-F1 0.0 on epoch=32
05/16/2022 09:37:06 - INFO - __main__ - Step 460 Global step 460 Train loss 5.98 on epoch=32
05/16/2022 09:37:07 - INFO - __main__ - Step 470 Global step 470 Train loss 5.85 on epoch=33
05/16/2022 09:37:09 - INFO - __main__ - Step 480 Global step 480 Train loss 5.80 on epoch=34
05/16/2022 09:37:10 - INFO - __main__ - Step 490 Global step 490 Train loss 5.71 on epoch=34
05/16/2022 09:37:11 - INFO - __main__ - Step 500 Global step 500 Train loss 5.75 on epoch=35
05/16/2022 09:38:08 - INFO - __main__ - Global step 500 Train loss 5.82 Classification-F1 0.0 on epoch=35
05/16/2022 09:38:09 - INFO - __main__ - Step 510 Global step 510 Train loss 5.60 on epoch=36
05/16/2022 09:38:10 - INFO - __main__ - Step 520 Global step 520 Train loss 5.85 on epoch=37
05/16/2022 09:38:11 - INFO - __main__ - Step 530 Global step 530 Train loss 5.73 on epoch=37
05/16/2022 09:38:13 - INFO - __main__ - Step 540 Global step 540 Train loss 5.70 on epoch=38
05/16/2022 09:38:14 - INFO - __main__ - Step 550 Global step 550 Train loss 5.48 on epoch=39
05/16/2022 09:38:31 - INFO - __main__ - Global step 550 Train loss 5.67 Classification-F1 0.0 on epoch=39
05/16/2022 09:38:32 - INFO - __main__ - Step 560 Global step 560 Train loss 5.44 on epoch=39
05/16/2022 09:38:33 - INFO - __main__ - Step 570 Global step 570 Train loss 5.56 on epoch=40
05/16/2022 09:38:35 - INFO - __main__ - Step 580 Global step 580 Train loss 5.38 on epoch=41
05/16/2022 09:38:36 - INFO - __main__ - Step 590 Global step 590 Train loss 5.71 on epoch=42
05/16/2022 09:38:37 - INFO - __main__ - Step 600 Global step 600 Train loss 5.56 on epoch=42
05/16/2022 09:38:59 - INFO - __main__ - Global step 600 Train loss 5.53 Classification-F1 0.0056737588652482265 on epoch=42
05/16/2022 09:38:59 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0056737588652482265 on epoch=42, global_step=600
05/16/2022 09:39:01 - INFO - __main__ - Step 610 Global step 610 Train loss 5.51 on epoch=43
05/16/2022 09:39:02 - INFO - __main__ - Step 620 Global step 620 Train loss 5.48 on epoch=44
05/16/2022 09:39:03 - INFO - __main__ - Step 630 Global step 630 Train loss 5.43 on epoch=44
05/16/2022 09:39:05 - INFO - __main__ - Step 640 Global step 640 Train loss 5.45 on epoch=45
05/16/2022 09:39:06 - INFO - __main__ - Step 650 Global step 650 Train loss 5.16 on epoch=46
05/16/2022 09:39:13 - INFO - __main__ - Global step 650 Train loss 5.41 Classification-F1 0.004713804713804714 on epoch=46
05/16/2022 09:39:14 - INFO - __main__ - Step 660 Global step 660 Train loss 5.38 on epoch=47
05/16/2022 09:39:15 - INFO - __main__ - Step 670 Global step 670 Train loss 5.47 on epoch=47
05/16/2022 09:39:17 - INFO - __main__ - Step 680 Global step 680 Train loss 5.21 on epoch=48
05/16/2022 09:39:18 - INFO - __main__ - Step 690 Global step 690 Train loss 5.32 on epoch=49
05/16/2022 09:39:19 - INFO - __main__ - Step 700 Global step 700 Train loss 5.07 on epoch=49
05/16/2022 09:39:27 - INFO - __main__ - Global step 700 Train loss 5.29 Classification-F1 0.005952380952380953 on epoch=49
05/16/2022 09:39:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0056737588652482265 -> 0.005952380952380953 on epoch=49, global_step=700
05/16/2022 09:39:28 - INFO - __main__ - Step 710 Global step 710 Train loss 5.28 on epoch=50
05/16/2022 09:39:30 - INFO - __main__ - Step 720 Global step 720 Train loss 5.05 on epoch=51
05/16/2022 09:39:31 - INFO - __main__ - Step 730 Global step 730 Train loss 5.24 on epoch=52
05/16/2022 09:39:32 - INFO - __main__ - Step 740 Global step 740 Train loss 5.28 on epoch=52
05/16/2022 09:39:34 - INFO - __main__ - Step 750 Global step 750 Train loss 5.09 on epoch=53
05/16/2022 09:39:45 - INFO - __main__ - Global step 750 Train loss 5.19 Classification-F1 0.00573394495412844 on epoch=53
05/16/2022 09:39:46 - INFO - __main__ - Step 760 Global step 760 Train loss 5.19 on epoch=54
05/16/2022 09:39:47 - INFO - __main__ - Step 770 Global step 770 Train loss 4.98 on epoch=54
05/16/2022 09:39:49 - INFO - __main__ - Step 780 Global step 780 Train loss 5.14 on epoch=55
05/16/2022 09:39:50 - INFO - __main__ - Step 790 Global step 790 Train loss 4.98 on epoch=56
05/16/2022 09:39:51 - INFO - __main__ - Step 800 Global step 800 Train loss 5.04 on epoch=57
05/16/2022 09:39:54 - INFO - __main__ - Global step 800 Train loss 5.06 Classification-F1 0.007446016381236037 on epoch=57
05/16/2022 09:39:54 - INFO - __main__ - Saving model with best Classification-F1: 0.005952380952380953 -> 0.007446016381236037 on epoch=57, global_step=800
05/16/2022 09:39:56 - INFO - __main__ - Step 810 Global step 810 Train loss 5.00 on epoch=57
05/16/2022 09:39:57 - INFO - __main__ - Step 820 Global step 820 Train loss 5.05 on epoch=58
05/16/2022 09:39:58 - INFO - __main__ - Step 830 Global step 830 Train loss 4.98 on epoch=59
05/16/2022 09:40:00 - INFO - __main__ - Step 840 Global step 840 Train loss 4.83 on epoch=59
05/16/2022 09:40:01 - INFO - __main__ - Step 850 Global step 850 Train loss 4.92 on epoch=60
05/16/2022 09:40:10 - INFO - __main__ - Global step 850 Train loss 4.96 Classification-F1 0.006211180124223602 on epoch=60
05/16/2022 09:40:11 - INFO - __main__ - Step 860 Global step 860 Train loss 4.83 on epoch=61
05/16/2022 09:40:12 - INFO - __main__ - Step 870 Global step 870 Train loss 4.95 on epoch=62
05/16/2022 09:40:13 - INFO - __main__ - Step 880 Global step 880 Train loss 4.94 on epoch=62
05/16/2022 09:40:15 - INFO - __main__ - Step 890 Global step 890 Train loss 4.79 on epoch=63
05/16/2022 09:40:16 - INFO - __main__ - Step 900 Global step 900 Train loss 4.92 on epoch=64
05/16/2022 09:40:20 - INFO - __main__ - Global step 900 Train loss 4.89 Classification-F1 0.007509386733416771 on epoch=64
05/16/2022 09:40:20 - INFO - __main__ - Saving model with best Classification-F1: 0.007446016381236037 -> 0.007509386733416771 on epoch=64, global_step=900
05/16/2022 09:40:21 - INFO - __main__ - Step 910 Global step 910 Train loss 4.81 on epoch=64
05/16/2022 09:40:22 - INFO - __main__ - Step 920 Global step 920 Train loss 4.87 on epoch=65
05/16/2022 09:40:24 - INFO - __main__ - Step 930 Global step 930 Train loss 4.68 on epoch=66
05/16/2022 09:40:25 - INFO - __main__ - Step 940 Global step 940 Train loss 4.84 on epoch=67
05/16/2022 09:40:26 - INFO - __main__ - Step 950 Global step 950 Train loss 4.77 on epoch=67
05/16/2022 09:40:29 - INFO - __main__ - Global step 950 Train loss 4.80 Classification-F1 0.009523809523809523 on epoch=67
05/16/2022 09:40:29 - INFO - __main__ - Saving model with best Classification-F1: 0.007509386733416771 -> 0.009523809523809523 on epoch=67, global_step=950
05/16/2022 09:40:30 - INFO - __main__ - Step 960 Global step 960 Train loss 4.83 on epoch=68
05/16/2022 09:40:32 - INFO - __main__ - Step 970 Global step 970 Train loss 4.81 on epoch=69
05/16/2022 09:40:33 - INFO - __main__ - Step 980 Global step 980 Train loss 4.78 on epoch=69
05/16/2022 09:40:34 - INFO - __main__ - Step 990 Global step 990 Train loss 4.75 on epoch=70
05/16/2022 09:40:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.70 on epoch=71
05/16/2022 09:40:39 - INFO - __main__ - Global step 1000 Train loss 4.77 Classification-F1 0.00892608089260809 on epoch=71
05/16/2022 09:40:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.75 on epoch=72
05/16/2022 09:40:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.71 on epoch=72
05/16/2022 09:40:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.71 on epoch=73
05/16/2022 09:40:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.72 on epoch=74
05/16/2022 09:40:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.60 on epoch=74
05/16/2022 09:40:47 - INFO - __main__ - Global step 1050 Train loss 4.70 Classification-F1 0.009523809523809523 on epoch=74
05/16/2022 09:40:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.63 on epoch=75
05/16/2022 09:40:50 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.52 on epoch=76
05/16/2022 09:40:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.75 on epoch=77
05/16/2022 09:40:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.58 on epoch=77
05/16/2022 09:40:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.52 on epoch=78
05/16/2022 09:40:56 - INFO - __main__ - Global step 1100 Train loss 4.60 Classification-F1 0.009523809523809523 on epoch=78
05/16/2022 09:40:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.48 on epoch=79
05/16/2022 09:40:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.62 on epoch=79
05/16/2022 09:41:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.57 on epoch=80
05/16/2022 09:41:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.55 on epoch=81
05/16/2022 09:41:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.55 on epoch=82
05/16/2022 09:41:05 - INFO - __main__ - Global step 1150 Train loss 4.55 Classification-F1 0.00892608089260809 on epoch=82
05/16/2022 09:41:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.52 on epoch=82
05/16/2022 09:41:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.53 on epoch=83
05/16/2022 09:41:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.55 on epoch=84
05/16/2022 09:41:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.29 on epoch=84
05/16/2022 09:41:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.34 on epoch=85
05/16/2022 09:41:14 - INFO - __main__ - Global step 1200 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=85
05/16/2022 09:41:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.42 on epoch=86
05/16/2022 09:41:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.38 on epoch=87
05/16/2022 09:41:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.34 on epoch=87
05/16/2022 09:41:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.48 on epoch=88
05/16/2022 09:41:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.47 on epoch=89
05/16/2022 09:41:22 - INFO - __main__ - Global step 1250 Train loss 4.42 Classification-F1 0.009523809523809523 on epoch=89
05/16/2022 09:41:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.25 on epoch=89
05/16/2022 09:41:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.31 on epoch=90
05/16/2022 09:41:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.29 on epoch=91
05/16/2022 09:41:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.33 on epoch=92
05/16/2022 09:41:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 4.22 on epoch=92
05/16/2022 09:41:31 - INFO - __main__ - Global step 1300 Train loss 4.28 Classification-F1 0.009523809523809523 on epoch=92
05/16/2022 09:41:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.24 on epoch=93
05/16/2022 09:41:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.42 on epoch=94
05/16/2022 09:41:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 4.10 on epoch=94
05/16/2022 09:41:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.05 on epoch=95
05/16/2022 09:41:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 4.05 on epoch=96
05/16/2022 09:41:39 - INFO - __main__ - Global step 1350 Train loss 4.17 Classification-F1 0.02009897221164827 on epoch=96
05/16/2022 09:41:39 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02009897221164827 on epoch=96, global_step=1350
05/16/2022 09:41:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 4.27 on epoch=97
05/16/2022 09:41:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 4.23 on epoch=97
05/16/2022 09:41:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 4.22 on epoch=98
05/16/2022 09:41:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 4.02 on epoch=99
05/16/2022 09:41:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 4.14 on epoch=99
05/16/2022 09:41:48 - INFO - __main__ - Global step 1400 Train loss 4.17 Classification-F1 0.015634944206372778 on epoch=99
05/16/2022 09:41:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 4.11 on epoch=100
05/16/2022 09:41:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 4.13 on epoch=101
05/16/2022 09:41:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 4.04 on epoch=102
05/16/2022 09:41:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 4.04 on epoch=102
05/16/2022 09:41:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 4.13 on epoch=103
05/16/2022 09:41:57 - INFO - __main__ - Global step 1450 Train loss 4.09 Classification-F1 0.010296010296010296 on epoch=103
05/16/2022 09:41:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 4.09 on epoch=104
05/16/2022 09:42:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 4.04 on epoch=104
05/16/2022 09:42:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 4.13 on epoch=105
05/16/2022 09:42:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 4.10 on epoch=106
05/16/2022 09:42:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 4.08 on epoch=107
05/16/2022 09:42:06 - INFO - __main__ - Global step 1500 Train loss 4.09 Classification-F1 0.015609152752009895 on epoch=107
05/16/2022 09:42:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.88 on epoch=107
05/16/2022 09:42:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 4.11 on epoch=108
05/16/2022 09:42:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 4.10 on epoch=109
05/16/2022 09:42:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 4.01 on epoch=109
05/16/2022 09:42:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.89 on epoch=110
05/16/2022 09:42:14 - INFO - __main__ - Global step 1550 Train loss 4.00 Classification-F1 0.015921262121870023 on epoch=110
05/16/2022 09:42:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 4.08 on epoch=111
05/16/2022 09:42:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 4.00 on epoch=112
05/16/2022 09:42:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.97 on epoch=112
05/16/2022 09:42:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 4.08 on epoch=113
05/16/2022 09:42:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.81 on epoch=114
05/16/2022 09:42:23 - INFO - __main__ - Global step 1600 Train loss 3.99 Classification-F1 0.010158730158730159 on epoch=114
05/16/2022 09:42:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.90 on epoch=114
05/16/2022 09:42:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.89 on epoch=115
05/16/2022 09:42:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.81 on epoch=116
05/16/2022 09:42:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.92 on epoch=117
05/16/2022 09:42:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.81 on epoch=117
05/16/2022 09:42:31 - INFO - __main__ - Global step 1650 Train loss 3.87 Classification-F1 0.009563658099222952 on epoch=117
05/16/2022 09:42:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.92 on epoch=118
05/16/2022 09:42:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.84 on epoch=119
05/16/2022 09:42:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.64 on epoch=119
05/16/2022 09:42:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.79 on epoch=120
05/16/2022 09:42:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.72 on epoch=121
05/16/2022 09:42:40 - INFO - __main__ - Global step 1700 Train loss 3.78 Classification-F1 0.009523809523809523 on epoch=121
05/16/2022 09:42:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.83 on epoch=122
05/16/2022 09:42:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.69 on epoch=122
05/16/2022 09:42:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.76 on epoch=123
05/16/2022 09:42:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.73 on epoch=124
05/16/2022 09:42:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.83 on epoch=124
05/16/2022 09:42:48 - INFO - __main__ - Global step 1750 Train loss 3.77 Classification-F1 0.019005478297513697 on epoch=124
05/16/2022 09:42:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.66 on epoch=125
05/16/2022 09:42:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.82 on epoch=126
05/16/2022 09:42:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.77 on epoch=127
05/16/2022 09:42:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.74 on epoch=127
05/16/2022 09:42:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.82 on epoch=128
05/16/2022 09:42:57 - INFO - __main__ - Global step 1800 Train loss 3.76 Classification-F1 0.013897866839043307 on epoch=128
05/16/2022 09:42:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.72 on epoch=129
05/16/2022 09:42:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.76 on epoch=129
05/16/2022 09:43:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.70 on epoch=130
05/16/2022 09:43:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.75 on epoch=131
05/16/2022 09:43:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.67 on epoch=132
05/16/2022 09:43:05 - INFO - __main__ - Global step 1850 Train loss 3.72 Classification-F1 0.009603841536614645 on epoch=132
05/16/2022 09:43:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.50 on epoch=132
05/16/2022 09:43:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.70 on epoch=133
05/16/2022 09:43:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.67 on epoch=134
05/16/2022 09:43:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.54 on epoch=134
05/16/2022 09:43:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.47 on epoch=135
05/16/2022 09:43:14 - INFO - __main__ - Global step 1900 Train loss 3.57 Classification-F1 0.01599953286035444 on epoch=135
05/16/2022 09:43:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.65 on epoch=136
05/16/2022 09:43:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.63 on epoch=137
05/16/2022 09:43:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.55 on epoch=137
05/16/2022 09:43:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.60 on epoch=138
05/16/2022 09:43:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.48 on epoch=139
05/16/2022 09:43:22 - INFO - __main__ - Global step 1950 Train loss 3.58 Classification-F1 0.015228818800247373 on epoch=139
05/16/2022 09:43:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.63 on epoch=139
05/16/2022 09:43:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.48 on epoch=140
05/16/2022 09:43:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.45 on epoch=141
05/16/2022 09:43:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.59 on epoch=142
05/16/2022 09:43:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.58 on epoch=142
05/16/2022 09:43:31 - INFO - __main__ - Global step 2000 Train loss 3.54 Classification-F1 0.015609152752009895 on epoch=142
05/16/2022 09:43:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.54 on epoch=143
05/16/2022 09:43:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.34 on epoch=144
05/16/2022 09:43:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.54 on epoch=144
05/16/2022 09:43:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.39 on epoch=145
05/16/2022 09:43:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.42 on epoch=146
05/16/2022 09:43:39 - INFO - __main__ - Global step 2050 Train loss 3.45 Classification-F1 0.010249839846252402 on epoch=146
05/16/2022 09:43:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.42 on epoch=147
05/16/2022 09:43:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.37 on epoch=147
05/16/2022 09:43:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.41 on epoch=148
05/16/2022 09:43:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.45 on epoch=149
05/16/2022 09:43:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.36 on epoch=149
05/16/2022 09:43:47 - INFO - __main__ - Global step 2100 Train loss 3.40 Classification-F1 0.02399566791890886 on epoch=149
05/16/2022 09:43:47 - INFO - __main__ - Saving model with best Classification-F1: 0.02009897221164827 -> 0.02399566791890886 on epoch=149, global_step=2100
05/16/2022 09:43:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.16 on epoch=150
05/16/2022 09:43:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.44 on epoch=151
05/16/2022 09:43:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.41 on epoch=152
05/16/2022 09:43:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.31 on epoch=152
05/16/2022 09:43:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.37 on epoch=153
05/16/2022 09:43:55 - INFO - __main__ - Global step 2150 Train loss 3.34 Classification-F1 0.020174346201743465 on epoch=153
05/16/2022 09:43:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.29 on epoch=154
05/16/2022 09:43:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.30 on epoch=154
05/16/2022 09:43:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.17 on epoch=155
05/16/2022 09:44:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.47 on epoch=156
05/16/2022 09:44:02 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.38 on epoch=157
05/16/2022 09:44:04 - INFO - __main__ - Global step 2200 Train loss 3.32 Classification-F1 0.019215714831873874 on epoch=157
05/16/2022 09:44:05 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.25 on epoch=157
05/16/2022 09:44:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.34 on epoch=158
05/16/2022 09:44:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 3.30 on epoch=159
05/16/2022 09:44:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.20 on epoch=159
05/16/2022 09:44:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 3.26 on epoch=160
05/16/2022 09:44:13 - INFO - __main__ - Global step 2250 Train loss 3.27 Classification-F1 0.016521110898620937 on epoch=160
05/16/2022 09:44:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.34 on epoch=161
05/16/2022 09:44:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.34 on epoch=162
05/16/2022 09:44:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.18 on epoch=162
05/16/2022 09:44:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 3.40 on epoch=163
05/16/2022 09:44:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.09 on epoch=164
05/16/2022 09:44:21 - INFO - __main__ - Global step 2300 Train loss 3.27 Classification-F1 0.024935224163651848 on epoch=164
05/16/2022 09:44:21 - INFO - __main__ - Saving model with best Classification-F1: 0.02399566791890886 -> 0.024935224163651848 on epoch=164, global_step=2300
05/16/2022 09:44:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.16 on epoch=164
05/16/2022 09:44:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.14 on epoch=165
05/16/2022 09:44:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 3.40 on epoch=166
05/16/2022 09:44:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.31 on epoch=167
05/16/2022 09:44:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.07 on epoch=167
05/16/2022 09:44:30 - INFO - __main__ - Global step 2350 Train loss 3.22 Classification-F1 0.028674388674388675 on epoch=167
05/16/2022 09:44:30 - INFO - __main__ - Saving model with best Classification-F1: 0.024935224163651848 -> 0.028674388674388675 on epoch=167, global_step=2350
05/16/2022 09:44:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.19 on epoch=168
05/16/2022 09:44:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 3.13 on epoch=169
05/16/2022 09:44:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 3.15 on epoch=169
05/16/2022 09:44:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 3.07 on epoch=170
05/16/2022 09:44:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 3.24 on epoch=171
05/16/2022 09:44:39 - INFO - __main__ - Global step 2400 Train loss 3.16 Classification-F1 0.0343266447040032 on epoch=171
05/16/2022 09:44:39 - INFO - __main__ - Saving model with best Classification-F1: 0.028674388674388675 -> 0.0343266447040032 on epoch=171, global_step=2400
05/16/2022 09:44:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.21 on epoch=172
05/16/2022 09:44:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.01 on epoch=172
05/16/2022 09:44:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.22 on epoch=173
05/16/2022 09:44:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 3.05 on epoch=174
05/16/2022 09:44:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.22 on epoch=174
05/16/2022 09:44:48 - INFO - __main__ - Global step 2450 Train loss 3.14 Classification-F1 0.023751561163714945 on epoch=174
05/16/2022 09:44:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 3.09 on epoch=175
05/16/2022 09:44:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 3.13 on epoch=176
05/16/2022 09:44:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 3.13 on epoch=177
05/16/2022 09:44:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 3.02 on epoch=177
05/16/2022 09:44:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.11 on epoch=178
05/16/2022 09:44:56 - INFO - __main__ - Global step 2500 Train loss 3.10 Classification-F1 0.0445169970822337 on epoch=178
05/16/2022 09:44:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0343266447040032 -> 0.0445169970822337 on epoch=178, global_step=2500
05/16/2022 09:44:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 3.12 on epoch=179
05/16/2022 09:44:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 3.15 on epoch=179
05/16/2022 09:45:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 3.03 on epoch=180
05/16/2022 09:45:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.14 on epoch=181
05/16/2022 09:45:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.02 on epoch=182
05/16/2022 09:45:05 - INFO - __main__ - Global step 2550 Train loss 3.09 Classification-F1 0.022368421052631576 on epoch=182
05/16/2022 09:45:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.98 on epoch=182
05/16/2022 09:45:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 3.05 on epoch=183
05/16/2022 09:45:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 3.16 on epoch=184
05/16/2022 09:45:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.99 on epoch=184
05/16/2022 09:45:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 3.14 on epoch=185
05/16/2022 09:45:13 - INFO - __main__ - Global step 2600 Train loss 3.07 Classification-F1 0.032536199432751156 on epoch=185
05/16/2022 09:45:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 3.12 on epoch=186
05/16/2022 09:45:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 3.16 on epoch=187
05/16/2022 09:45:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.99 on epoch=187
05/16/2022 09:45:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 3.04 on epoch=188
05/16/2022 09:45:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.99 on epoch=189
05/16/2022 09:45:22 - INFO - __main__ - Global step 2650 Train loss 3.06 Classification-F1 0.026552742411773248 on epoch=189
05/16/2022 09:45:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 3.09 on epoch=189
05/16/2022 09:45:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 3.07 on epoch=190
05/16/2022 09:45:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 3.12 on epoch=191
05/16/2022 09:45:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 3.04 on epoch=192
05/16/2022 09:45:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.89 on epoch=192
05/16/2022 09:45:30 - INFO - __main__ - Global step 2700 Train loss 3.04 Classification-F1 0.025995564068958563 on epoch=192
05/16/2022 09:45:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 3.05 on epoch=193
05/16/2022 09:45:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.95 on epoch=194
05/16/2022 09:45:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.89 on epoch=194
05/16/2022 09:45:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.73 on epoch=195
05/16/2022 09:45:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/16/2022 09:45:39 - INFO - __main__ - Global step 2750 Train loss 2.91 Classification-F1 0.014339203423304804 on epoch=196
05/16/2022 09:45:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.87 on epoch=197
05/16/2022 09:45:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.97 on epoch=197
05/16/2022 09:45:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 3.02 on epoch=198
05/16/2022 09:45:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.95 on epoch=199
05/16/2022 09:45:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 3.06 on epoch=199
05/16/2022 09:45:47 - INFO - __main__ - Global step 2800 Train loss 2.97 Classification-F1 0.009563658099222952 on epoch=199
05/16/2022 09:45:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.83 on epoch=200
05/16/2022 09:45:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 3.07 on epoch=201
05/16/2022 09:45:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 3.03 on epoch=202
05/16/2022 09:45:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.95 on epoch=202
05/16/2022 09:45:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.95 on epoch=203
05/16/2022 09:45:56 - INFO - __main__ - Global step 2850 Train loss 2.97 Classification-F1 0.009523809523809523 on epoch=203
05/16/2022 09:45:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.79 on epoch=204
05/16/2022 09:45:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.90 on epoch=204
05/16/2022 09:46:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.75 on epoch=205
05/16/2022 09:46:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.99 on epoch=206
05/16/2022 09:46:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.97 on epoch=207
05/16/2022 09:46:05 - INFO - __main__ - Global step 2900 Train loss 2.88 Classification-F1 0.0291613990729035 on epoch=207
05/16/2022 09:46:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.79 on epoch=207
05/16/2022 09:46:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.96 on epoch=208
05/16/2022 09:46:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.98 on epoch=209
05/16/2022 09:46:10 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.88 on epoch=209
05/16/2022 09:46:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.76 on epoch=210
05/16/2022 09:46:14 - INFO - __main__ - Global step 2950 Train loss 2.88 Classification-F1 0.036080666570998066 on epoch=210
05/16/2022 09:46:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.89 on epoch=211
05/16/2022 09:46:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.80 on epoch=212
05/16/2022 09:46:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.83 on epoch=212
05/16/2022 09:46:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 3.01 on epoch=213
05/16/2022 09:46:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.78 on epoch=214
05/16/2022 09:46:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:46:22 - INFO - __main__ - Printing 3 examples
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 09:46:22 - INFO - __main__ - ['Company']
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 09:46:22 - INFO - __main__ - ['Company']
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 09:46:22 - INFO - __main__ - ['Company']
05/16/2022 09:46:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:46:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:46:22 - INFO - __main__ - Global step 3000 Train loss 2.86 Classification-F1 0.025317369666313125 on epoch=214
05/16/2022 09:46:22 - INFO - __main__ - save last model!
05/16/2022 09:46:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 09:46:22 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 09:46:22 - INFO - __main__ - Printing 3 examples
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 09:46:22 - INFO - __main__ - ['Animal']
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 09:46:22 - INFO - __main__ - ['Animal']
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 09:46:22 - INFO - __main__ - ['Village']
05/16/2022 09:46:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:46:22 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 09:46:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:46:22 - INFO - __main__ - Printing 3 examples
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 09:46:22 - INFO - __main__ - ['Company']
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 09:46:22 - INFO - __main__ - ['Company']
05/16/2022 09:46:22 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 09:46:22 - INFO - __main__ - ['Company']
05/16/2022 09:46:22 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:46:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:46:23 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 09:46:24 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:46:27 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 09:46:28 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 09:46:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 09:46:29 - INFO - __main__ - Starting training!
05/16/2022 09:46:57 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/16/2022 09:46:57 - INFO - __main__ - Classification-F1 on test data: 0.0202
05/16/2022 09:46:57 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.0445169970822337, test_performance=0.02022454943077747
05/16/2022 09:46:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/16/2022 09:46:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:46:58 - INFO - __main__ - Printing 3 examples
05/16/2022 09:46:58 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 09:46:58 - INFO - __main__ - ['Company']
05/16/2022 09:46:58 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 09:46:58 - INFO - __main__ - ['Company']
05/16/2022 09:46:58 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 09:46:58 - INFO - __main__ - ['Company']
05/16/2022 09:46:58 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:46:58 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:46:59 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 09:46:59 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 09:46:59 - INFO - __main__ - Printing 3 examples
05/16/2022 09:46:59 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 09:46:59 - INFO - __main__ - ['Company']
05/16/2022 09:46:59 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 09:46:59 - INFO - __main__ - ['Company']
05/16/2022 09:46:59 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 09:46:59 - INFO - __main__ - ['Company']
05/16/2022 09:46:59 - INFO - __main__ - Tokenizing Input ...
05/16/2022 09:46:59 - INFO - __main__ - Tokenizing Output ...
05/16/2022 09:46:59 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 09:47:05 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 09:47:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 09:47:05 - INFO - __main__ - Starting training!
05/16/2022 09:47:07 - INFO - __main__ - Step 10 Global step 10 Train loss 7.28 on epoch=0
05/16/2022 09:47:08 - INFO - __main__ - Step 20 Global step 20 Train loss 7.48 on epoch=1
05/16/2022 09:47:10 - INFO - __main__ - Step 30 Global step 30 Train loss 7.28 on epoch=2
05/16/2022 09:47:11 - INFO - __main__ - Step 40 Global step 40 Train loss 6.75 on epoch=2
05/16/2022 09:47:12 - INFO - __main__ - Step 50 Global step 50 Train loss 7.08 on epoch=3
05/16/2022 09:48:19 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/16/2022 09:48:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 09:48:21 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/16/2022 09:48:22 - INFO - __main__ - Step 70 Global step 70 Train loss 6.87 on epoch=4
05/16/2022 09:48:23 - INFO - __main__ - Step 80 Global step 80 Train loss 6.49 on epoch=5
05/16/2022 09:48:25 - INFO - __main__ - Step 90 Global step 90 Train loss 6.63 on epoch=6
05/16/2022 09:48:26 - INFO - __main__ - Step 100 Global step 100 Train loss 6.46 on epoch=7
05/16/2022 09:49:18 - INFO - __main__ - Global step 100 Train loss 6.64 Classification-F1 0.0 on epoch=7
05/16/2022 09:49:20 - INFO - __main__ - Step 110 Global step 110 Train loss 6.14 on epoch=7
05/16/2022 09:49:21 - INFO - __main__ - Step 120 Global step 120 Train loss 6.29 on epoch=8
05/16/2022 09:49:22 - INFO - __main__ - Step 130 Global step 130 Train loss 5.98 on epoch=9
05/16/2022 09:49:24 - INFO - __main__ - Step 140 Global step 140 Train loss 6.19 on epoch=9
05/16/2022 09:49:25 - INFO - __main__ - Step 150 Global step 150 Train loss 5.83 on epoch=10
05/16/2022 09:50:46 - INFO - __main__ - Global step 150 Train loss 6.08 Classification-F1 0.0 on epoch=10
05/16/2022 09:50:48 - INFO - __main__ - Step 160 Global step 160 Train loss 5.99 on epoch=11
05/16/2022 09:50:49 - INFO - __main__ - Step 170 Global step 170 Train loss 5.93 on epoch=12
05/16/2022 09:50:50 - INFO - __main__ - Step 180 Global step 180 Train loss 5.64 on epoch=12
05/16/2022 09:50:52 - INFO - __main__ - Step 190 Global step 190 Train loss 5.71 on epoch=13
05/16/2022 09:50:53 - INFO - __main__ - Step 200 Global step 200 Train loss 5.54 on epoch=14
05/16/2022 09:51:33 - INFO - __main__ - Global step 200 Train loss 5.76 Classification-F1 0.0 on epoch=14
05/16/2022 09:51:34 - INFO - __main__ - Step 210 Global step 210 Train loss 5.75 on epoch=14
05/16/2022 09:51:35 - INFO - __main__ - Step 220 Global step 220 Train loss 5.26 on epoch=15
05/16/2022 09:51:36 - INFO - __main__ - Step 230 Global step 230 Train loss 5.54 on epoch=16
05/16/2022 09:51:38 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=17
05/16/2022 09:51:39 - INFO - __main__ - Step 250 Global step 250 Train loss 5.24 on epoch=17
05/16/2022 09:52:36 - INFO - __main__ - Global step 250 Train loss 5.44 Classification-F1 0.0036215482118605704 on epoch=17
05/16/2022 09:52:36 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0036215482118605704 on epoch=17, global_step=250
05/16/2022 09:52:37 - INFO - __main__ - Step 260 Global step 260 Train loss 5.12 on epoch=18
05/16/2022 09:52:39 - INFO - __main__ - Step 270 Global step 270 Train loss 5.15 on epoch=19
05/16/2022 09:52:40 - INFO - __main__ - Step 280 Global step 280 Train loss 5.18 on epoch=19
05/16/2022 09:52:41 - INFO - __main__ - Step 290 Global step 290 Train loss 4.81 on epoch=20
05/16/2022 09:52:43 - INFO - __main__ - Step 300 Global step 300 Train loss 5.04 on epoch=21
05/16/2022 09:52:50 - INFO - __main__ - Global step 300 Train loss 5.06 Classification-F1 0.008113590263691683 on epoch=21
05/16/2022 09:52:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0036215482118605704 -> 0.008113590263691683 on epoch=21, global_step=300
05/16/2022 09:52:51 - INFO - __main__ - Step 310 Global step 310 Train loss 4.93 on epoch=22
05/16/2022 09:52:53 - INFO - __main__ - Step 320 Global step 320 Train loss 4.79 on epoch=22
05/16/2022 09:52:54 - INFO - __main__ - Step 330 Global step 330 Train loss 4.68 on epoch=23
05/16/2022 09:52:56 - INFO - __main__ - Step 340 Global step 340 Train loss 4.45 on epoch=24
05/16/2022 09:52:57 - INFO - __main__ - Step 350 Global step 350 Train loss 4.61 on epoch=24
05/16/2022 09:53:00 - INFO - __main__ - Global step 350 Train loss 4.69 Classification-F1 0.009523809523809523 on epoch=24
05/16/2022 09:53:00 - INFO - __main__ - Saving model with best Classification-F1: 0.008113590263691683 -> 0.009523809523809523 on epoch=24, global_step=350
05/16/2022 09:53:01 - INFO - __main__ - Step 360 Global step 360 Train loss 4.52 on epoch=25
05/16/2022 09:53:03 - INFO - __main__ - Step 370 Global step 370 Train loss 4.37 on epoch=26
05/16/2022 09:53:04 - INFO - __main__ - Step 380 Global step 380 Train loss 4.51 on epoch=27
05/16/2022 09:53:05 - INFO - __main__ - Step 390 Global step 390 Train loss 4.33 on epoch=27
05/16/2022 09:53:06 - INFO - __main__ - Step 400 Global step 400 Train loss 4.40 on epoch=28
05/16/2022 09:53:09 - INFO - __main__ - Global step 400 Train loss 4.43 Classification-F1 0.009603841536614645 on epoch=28
05/16/2022 09:53:09 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009603841536614645 on epoch=28, global_step=400
05/16/2022 09:53:10 - INFO - __main__ - Step 410 Global step 410 Train loss 4.22 on epoch=29
05/16/2022 09:53:11 - INFO - __main__ - Step 420 Global step 420 Train loss 4.52 on epoch=29
05/16/2022 09:53:12 - INFO - __main__ - Step 430 Global step 430 Train loss 4.05 on epoch=30
05/16/2022 09:53:14 - INFO - __main__ - Step 440 Global step 440 Train loss 4.11 on epoch=31
05/16/2022 09:53:15 - INFO - __main__ - Step 450 Global step 450 Train loss 4.07 on epoch=32
05/16/2022 09:53:17 - INFO - __main__ - Global step 450 Train loss 4.19 Classification-F1 0.02676089201318559 on epoch=32
05/16/2022 09:53:17 - INFO - __main__ - Saving model with best Classification-F1: 0.009603841536614645 -> 0.02676089201318559 on epoch=32, global_step=450
05/16/2022 09:53:18 - INFO - __main__ - Step 460 Global step 460 Train loss 4.03 on epoch=32
05/16/2022 09:53:20 - INFO - __main__ - Step 470 Global step 470 Train loss 4.07 on epoch=33
05/16/2022 09:53:21 - INFO - __main__ - Step 480 Global step 480 Train loss 3.92 on epoch=34
05/16/2022 09:53:23 - INFO - __main__ - Step 490 Global step 490 Train loss 4.11 on epoch=34
05/16/2022 09:53:24 - INFO - __main__ - Step 500 Global step 500 Train loss 3.79 on epoch=35
05/16/2022 09:53:26 - INFO - __main__ - Global step 500 Train loss 3.98 Classification-F1 0.03431197040219596 on epoch=35
05/16/2022 09:53:26 - INFO - __main__ - Saving model with best Classification-F1: 0.02676089201318559 -> 0.03431197040219596 on epoch=35, global_step=500
05/16/2022 09:53:28 - INFO - __main__ - Step 510 Global step 510 Train loss 3.82 on epoch=36
05/16/2022 09:53:29 - INFO - __main__ - Step 520 Global step 520 Train loss 3.88 on epoch=37
05/16/2022 09:53:30 - INFO - __main__ - Step 530 Global step 530 Train loss 3.88 on epoch=37
05/16/2022 09:53:32 - INFO - __main__ - Step 540 Global step 540 Train loss 3.74 on epoch=38
05/16/2022 09:53:33 - INFO - __main__ - Step 550 Global step 550 Train loss 3.80 on epoch=39
05/16/2022 09:53:35 - INFO - __main__ - Global step 550 Train loss 3.83 Classification-F1 0.009523809523809523 on epoch=39
05/16/2022 09:53:36 - INFO - __main__ - Step 560 Global step 560 Train loss 3.88 on epoch=39
05/16/2022 09:53:38 - INFO - __main__ - Step 570 Global step 570 Train loss 3.74 on epoch=40
05/16/2022 09:53:39 - INFO - __main__ - Step 580 Global step 580 Train loss 3.75 on epoch=41
05/16/2022 09:53:40 - INFO - __main__ - Step 590 Global step 590 Train loss 3.57 on epoch=42
05/16/2022 09:53:42 - INFO - __main__ - Step 600 Global step 600 Train loss 3.68 on epoch=42
05/16/2022 09:53:43 - INFO - __main__ - Global step 600 Train loss 3.72 Classification-F1 0.02999268220516973 on epoch=42
05/16/2022 09:53:45 - INFO - __main__ - Step 610 Global step 610 Train loss 3.60 on epoch=43
05/16/2022 09:53:46 - INFO - __main__ - Step 620 Global step 620 Train loss 3.60 on epoch=44
05/16/2022 09:53:47 - INFO - __main__ - Step 630 Global step 630 Train loss 3.65 on epoch=44
05/16/2022 09:53:49 - INFO - __main__ - Step 640 Global step 640 Train loss 3.40 on epoch=45
05/16/2022 09:53:50 - INFO - __main__ - Step 650 Global step 650 Train loss 3.63 on epoch=46
05/16/2022 09:53:52 - INFO - __main__ - Global step 650 Train loss 3.58 Classification-F1 0.009523809523809523 on epoch=46
05/16/2022 09:53:53 - INFO - __main__ - Step 660 Global step 660 Train loss 3.47 on epoch=47
05/16/2022 09:53:54 - INFO - __main__ - Step 670 Global step 670 Train loss 3.49 on epoch=47
05/16/2022 09:53:56 - INFO - __main__ - Step 680 Global step 680 Train loss 3.38 on epoch=48
05/16/2022 09:53:57 - INFO - __main__ - Step 690 Global step 690 Train loss 3.39 on epoch=49
05/16/2022 09:53:59 - INFO - __main__ - Step 700 Global step 700 Train loss 3.36 on epoch=49
05/16/2022 09:54:00 - INFO - __main__ - Global step 700 Train loss 3.42 Classification-F1 0.017795193914596903 on epoch=49
05/16/2022 09:54:02 - INFO - __main__ - Step 710 Global step 710 Train loss 3.26 on epoch=50
05/16/2022 09:54:03 - INFO - __main__ - Step 720 Global step 720 Train loss 3.27 on epoch=51
05/16/2022 09:54:04 - INFO - __main__ - Step 730 Global step 730 Train loss 3.39 on epoch=52
05/16/2022 09:54:06 - INFO - __main__ - Step 740 Global step 740 Train loss 3.29 on epoch=52
05/16/2022 09:54:07 - INFO - __main__ - Step 750 Global step 750 Train loss 3.24 on epoch=53
05/16/2022 09:54:09 - INFO - __main__ - Global step 750 Train loss 3.29 Classification-F1 0.015657161358958345 on epoch=53
05/16/2022 09:54:10 - INFO - __main__ - Step 760 Global step 760 Train loss 3.19 on epoch=54
05/16/2022 09:54:11 - INFO - __main__ - Step 770 Global step 770 Train loss 3.35 on epoch=54
05/16/2022 09:54:13 - INFO - __main__ - Step 780 Global step 780 Train loss 3.34 on epoch=55
05/16/2022 09:54:14 - INFO - __main__ - Step 790 Global step 790 Train loss 3.26 on epoch=56
05/16/2022 09:54:15 - INFO - __main__ - Step 800 Global step 800 Train loss 3.06 on epoch=57
05/16/2022 09:54:17 - INFO - __main__ - Global step 800 Train loss 3.24 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 09:54:18 - INFO - __main__ - Step 810 Global step 810 Train loss 3.17 on epoch=57
05/16/2022 09:54:19 - INFO - __main__ - Step 820 Global step 820 Train loss 3.00 on epoch=58
05/16/2022 09:54:21 - INFO - __main__ - Step 830 Global step 830 Train loss 3.12 on epoch=59
05/16/2022 09:54:22 - INFO - __main__ - Step 840 Global step 840 Train loss 3.11 on epoch=59
05/16/2022 09:54:23 - INFO - __main__ - Step 850 Global step 850 Train loss 3.07 on epoch=60
05/16/2022 09:54:25 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.009563658099222952 on epoch=60
05/16/2022 09:54:26 - INFO - __main__ - Step 860 Global step 860 Train loss 2.94 on epoch=61
05/16/2022 09:54:28 - INFO - __main__ - Step 870 Global step 870 Train loss 3.16 on epoch=62
05/16/2022 09:54:29 - INFO - __main__ - Step 880 Global step 880 Train loss 3.01 on epoch=62
05/16/2022 09:54:30 - INFO - __main__ - Step 890 Global step 890 Train loss 3.01 on epoch=63
05/16/2022 09:54:32 - INFO - __main__ - Step 900 Global step 900 Train loss 3.07 on epoch=64
05/16/2022 09:54:34 - INFO - __main__ - Global step 900 Train loss 3.04 Classification-F1 0.009523809523809523 on epoch=64
05/16/2022 09:54:35 - INFO - __main__ - Step 910 Global step 910 Train loss 3.07 on epoch=64
05/16/2022 09:54:36 - INFO - __main__ - Step 920 Global step 920 Train loss 2.99 on epoch=65
05/16/2022 09:54:37 - INFO - __main__ - Step 930 Global step 930 Train loss 3.04 on epoch=66
05/16/2022 09:54:39 - INFO - __main__ - Step 940 Global step 940 Train loss 3.00 on epoch=67
05/16/2022 09:54:40 - INFO - __main__ - Step 950 Global step 950 Train loss 3.12 on epoch=67
05/16/2022 09:54:42 - INFO - __main__ - Global step 950 Train loss 3.04 Classification-F1 0.009726443768996961 on epoch=67
05/16/2022 09:54:43 - INFO - __main__ - Step 960 Global step 960 Train loss 2.83 on epoch=68
05/16/2022 09:54:45 - INFO - __main__ - Step 970 Global step 970 Train loss 2.75 on epoch=69
05/16/2022 09:54:46 - INFO - __main__ - Step 980 Global step 980 Train loss 2.80 on epoch=69
05/16/2022 09:54:47 - INFO - __main__ - Step 990 Global step 990 Train loss 2.83 on epoch=70
05/16/2022 09:54:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.01 on epoch=71
05/16/2022 09:54:50 - INFO - __main__ - Global step 1000 Train loss 2.84 Classification-F1 0.01800720288115246 on epoch=71
05/16/2022 09:54:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.95 on epoch=72
05/16/2022 09:54:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.94 on epoch=72
05/16/2022 09:54:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.91 on epoch=73
05/16/2022 09:54:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.88 on epoch=74
05/16/2022 09:54:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.88 on epoch=74
05/16/2022 09:54:58 - INFO - __main__ - Global step 1050 Train loss 2.91 Classification-F1 0.009894867037724181 on epoch=74
05/16/2022 09:55:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.91 on epoch=75
05/16/2022 09:55:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.66 on epoch=76
05/16/2022 09:55:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.75 on epoch=77
05/16/2022 09:55:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.83 on epoch=77
05/16/2022 09:55:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.86 on epoch=78
05/16/2022 09:55:07 - INFO - __main__ - Global step 1100 Train loss 2.80 Classification-F1 0.02989399980550423 on epoch=78
05/16/2022 09:55:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.80 on epoch=79
05/16/2022 09:55:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.70 on epoch=79
05/16/2022 09:55:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.80 on epoch=80
05/16/2022 09:55:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.76 on epoch=81
05/16/2022 09:55:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.83 on epoch=82
05/16/2022 09:55:15 - INFO - __main__ - Global step 1150 Train loss 2.78 Classification-F1 0.024187321579100227 on epoch=82
05/16/2022 09:55:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/16/2022 09:55:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.70 on epoch=83
05/16/2022 09:55:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.51 on epoch=84
05/16/2022 09:55:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.68 on epoch=84
05/16/2022 09:55:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.60 on epoch=85
05/16/2022 09:55:23 - INFO - __main__ - Global step 1200 Train loss 2.66 Classification-F1 0.031015037593984968 on epoch=85
05/16/2022 09:55:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.55 on epoch=86
05/16/2022 09:55:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.72 on epoch=87
05/16/2022 09:55:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.62 on epoch=87
05/16/2022 09:55:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.63 on epoch=88
05/16/2022 09:55:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.59 on epoch=89
05/16/2022 09:55:32 - INFO - __main__ - Global step 1250 Train loss 2.63 Classification-F1 0.023548964099097198 on epoch=89
05/16/2022 09:55:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.65 on epoch=89
05/16/2022 09:55:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.60 on epoch=90
05/16/2022 09:55:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.61 on epoch=91
05/16/2022 09:55:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.61 on epoch=92
05/16/2022 09:55:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.69 on epoch=92
05/16/2022 09:55:40 - INFO - __main__ - Global step 1300 Train loss 2.63 Classification-F1 0.02614980183775942 on epoch=92
05/16/2022 09:55:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.57 on epoch=93
05/16/2022 09:55:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.55 on epoch=94
05/16/2022 09:55:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.61 on epoch=94
05/16/2022 09:55:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.48 on epoch=95
05/16/2022 09:55:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.51 on epoch=96
05/16/2022 09:55:48 - INFO - __main__ - Global step 1350 Train loss 2.54 Classification-F1 0.014948084496956676 on epoch=96
05/16/2022 09:55:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.51 on epoch=97
05/16/2022 09:55:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.55 on epoch=97
05/16/2022 09:55:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.54 on epoch=98
05/16/2022 09:55:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.58 on epoch=99
05/16/2022 09:55:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.73 on epoch=99
05/16/2022 09:55:56 - INFO - __main__ - Global step 1400 Train loss 2.58 Classification-F1 0.03706672009617311 on epoch=99
05/16/2022 09:55:56 - INFO - __main__ - Saving model with best Classification-F1: 0.03431197040219596 -> 0.03706672009617311 on epoch=99, global_step=1400
05/16/2022 09:55:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.43 on epoch=100
05/16/2022 09:55:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.63 on epoch=101
05/16/2022 09:55:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.68 on epoch=102
05/16/2022 09:56:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.56 on epoch=102
05/16/2022 09:56:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.52 on epoch=103
05/16/2022 09:56:04 - INFO - __main__ - Global step 1450 Train loss 2.57 Classification-F1 0.02634125134125134 on epoch=103
05/16/2022 09:56:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.49 on epoch=104
05/16/2022 09:56:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.48 on epoch=104
05/16/2022 09:56:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.46 on epoch=105
05/16/2022 09:56:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.60 on epoch=106
05/16/2022 09:56:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.55 on epoch=107
05/16/2022 09:56:12 - INFO - __main__ - Global step 1500 Train loss 2.51 Classification-F1 0.013309671694764864 on epoch=107
05/16/2022 09:56:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.53 on epoch=107
05/16/2022 09:56:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.59 on epoch=108
05/16/2022 09:56:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.56 on epoch=109
05/16/2022 09:56:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=109
05/16/2022 09:56:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.54 on epoch=110
05/16/2022 09:56:20 - INFO - __main__ - Global step 1550 Train loss 2.55 Classification-F1 0.01713875205254516 on epoch=110
05/16/2022 09:56:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.49 on epoch=111
05/16/2022 09:56:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.51 on epoch=112
05/16/2022 09:56:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.54 on epoch=112
05/16/2022 09:56:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.45 on epoch=113
05/16/2022 09:56:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.44 on epoch=114
05/16/2022 09:56:28 - INFO - __main__ - Global step 1600 Train loss 2.48 Classification-F1 0.009920634920634922 on epoch=114
05/16/2022 09:56:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.35 on epoch=114
05/16/2022 09:56:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.51 on epoch=115
05/16/2022 09:56:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.43 on epoch=116
05/16/2022 09:56:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.42 on epoch=117
05/16/2022 09:56:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.43 on epoch=117
05/16/2022 09:56:36 - INFO - __main__ - Global step 1650 Train loss 2.43 Classification-F1 0.009523809523809523 on epoch=117
05/16/2022 09:56:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.40 on epoch=118
05/16/2022 09:56:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.47 on epoch=119
05/16/2022 09:56:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.30 on epoch=119
05/16/2022 09:56:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.45 on epoch=120
05/16/2022 09:56:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.29 on epoch=121
05/16/2022 09:56:45 - INFO - __main__ - Global step 1700 Train loss 2.38 Classification-F1 0.04844822402611347 on epoch=121
05/16/2022 09:56:45 - INFO - __main__ - Saving model with best Classification-F1: 0.03706672009617311 -> 0.04844822402611347 on epoch=121, global_step=1700
05/16/2022 09:56:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.31 on epoch=122
05/16/2022 09:56:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.34 on epoch=122
05/16/2022 09:56:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.40 on epoch=123
05/16/2022 09:56:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.26 on epoch=124
05/16/2022 09:56:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.39 on epoch=124
05/16/2022 09:56:53 - INFO - __main__ - Global step 1750 Train loss 2.34 Classification-F1 0.048214285714285716 on epoch=124
05/16/2022 09:56:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.37 on epoch=125
05/16/2022 09:56:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.28 on epoch=126
05/16/2022 09:56:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.33 on epoch=127
05/16/2022 09:56:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.31 on epoch=127
05/16/2022 09:56:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.36 on epoch=128
05/16/2022 09:57:01 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.023325027685492803 on epoch=128
05/16/2022 09:57:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.22 on epoch=129
05/16/2022 09:57:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.23 on epoch=129
05/16/2022 09:57:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.22 on epoch=130
05/16/2022 09:57:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.33 on epoch=131
05/16/2022 09:57:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.30 on epoch=132
05/16/2022 09:57:09 - INFO - __main__ - Global step 1850 Train loss 2.26 Classification-F1 0.020835310868533463 on epoch=132
05/16/2022 09:57:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.34 on epoch=132
05/16/2022 09:57:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.31 on epoch=133
05/16/2022 09:57:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.11 on epoch=134
05/16/2022 09:57:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.18 on epoch=134
05/16/2022 09:57:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.20 on epoch=135
05/16/2022 09:57:18 - INFO - __main__ - Global step 1900 Train loss 2.23 Classification-F1 0.025723806268919052 on epoch=135
05/16/2022 09:57:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.35 on epoch=136
05/16/2022 09:57:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.18 on epoch=137
05/16/2022 09:57:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.19 on epoch=137
05/16/2022 09:57:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.26 on epoch=138
05/16/2022 09:57:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.24 on epoch=139
05/16/2022 09:57:26 - INFO - __main__ - Global step 1950 Train loss 2.24 Classification-F1 0.022740065293256784 on epoch=139
05/16/2022 09:57:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.07 on epoch=139
05/16/2022 09:57:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.21 on epoch=140
05/16/2022 09:57:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.26 on epoch=141
05/16/2022 09:57:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.18 on epoch=142
05/16/2022 09:57:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.22 on epoch=142
05/16/2022 09:57:34 - INFO - __main__ - Global step 2000 Train loss 2.19 Classification-F1 0.02677775229942164 on epoch=142
05/16/2022 09:57:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.29 on epoch=143
05/16/2022 09:57:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.10 on epoch=144
05/16/2022 09:57:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.21 on epoch=144
05/16/2022 09:57:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.15 on epoch=145
05/16/2022 09:57:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.07 on epoch=146
05/16/2022 09:57:43 - INFO - __main__ - Global step 2050 Train loss 2.16 Classification-F1 0.03790954219525648 on epoch=146
05/16/2022 09:57:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.16 on epoch=147
05/16/2022 09:57:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.04 on epoch=147
05/16/2022 09:57:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.01 on epoch=148
05/16/2022 09:57:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.17 on epoch=149
05/16/2022 09:57:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.03 on epoch=149
05/16/2022 09:57:51 - INFO - __main__ - Global step 2100 Train loss 2.08 Classification-F1 0.03715874667209773 on epoch=149
05/16/2022 09:57:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.03 on epoch=150
05/16/2022 09:57:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.96 on epoch=151
05/16/2022 09:57:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.05 on epoch=152
05/16/2022 09:57:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.17 on epoch=152
05/16/2022 09:57:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.98 on epoch=153
05/16/2022 09:58:00 - INFO - __main__ - Global step 2150 Train loss 2.04 Classification-F1 0.03395922327520234 on epoch=153
05/16/2022 09:58:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.14 on epoch=154
05/16/2022 09:58:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.12 on epoch=154
05/16/2022 09:58:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.01 on epoch=155
05/16/2022 09:58:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.86 on epoch=156
05/16/2022 09:58:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.06 on epoch=157
05/16/2022 09:58:08 - INFO - __main__ - Global step 2200 Train loss 2.04 Classification-F1 0.05662044072948329 on epoch=157
05/16/2022 09:58:08 - INFO - __main__ - Saving model with best Classification-F1: 0.04844822402611347 -> 0.05662044072948329 on epoch=157, global_step=2200
05/16/2022 09:58:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.00 on epoch=157
05/16/2022 09:58:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.04 on epoch=158
05/16/2022 09:58:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.96 on epoch=159
05/16/2022 09:58:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.06 on epoch=159
05/16/2022 09:58:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.99 on epoch=160
05/16/2022 09:58:16 - INFO - __main__ - Global step 2250 Train loss 2.01 Classification-F1 0.062470170212105706 on epoch=160
05/16/2022 09:58:16 - INFO - __main__ - Saving model with best Classification-F1: 0.05662044072948329 -> 0.062470170212105706 on epoch=160, global_step=2250
05/16/2022 09:58:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.08 on epoch=161
05/16/2022 09:58:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.99 on epoch=162
05/16/2022 09:58:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.96 on epoch=162
05/16/2022 09:58:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.98 on epoch=163
05/16/2022 09:58:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.94 on epoch=164
05/16/2022 09:58:25 - INFO - __main__ - Global step 2300 Train loss 1.99 Classification-F1 0.04513179968892421 on epoch=164
05/16/2022 09:58:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.81 on epoch=164
05/16/2022 09:58:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.97 on epoch=165
05/16/2022 09:58:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.93 on epoch=166
05/16/2022 09:58:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.99 on epoch=167
05/16/2022 09:58:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.86 on epoch=167
05/16/2022 09:58:33 - INFO - __main__ - Global step 2350 Train loss 1.91 Classification-F1 0.07333057559506033 on epoch=167
05/16/2022 09:58:33 - INFO - __main__ - Saving model with best Classification-F1: 0.062470170212105706 -> 0.07333057559506033 on epoch=167, global_step=2350
05/16/2022 09:58:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.01 on epoch=168
05/16/2022 09:58:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.95 on epoch=169
05/16/2022 09:58:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.03 on epoch=169
05/16/2022 09:58:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.86 on epoch=170
05/16/2022 09:58:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.98 on epoch=171
05/16/2022 09:58:41 - INFO - __main__ - Global step 2400 Train loss 1.97 Classification-F1 0.04171852043902861 on epoch=171
05/16/2022 09:58:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.84 on epoch=172
05/16/2022 09:58:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.84 on epoch=172
05/16/2022 09:58:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.97 on epoch=173
05/16/2022 09:58:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.85 on epoch=174
05/16/2022 09:58:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.97 on epoch=174
05/16/2022 09:58:49 - INFO - __main__ - Global step 2450 Train loss 1.89 Classification-F1 0.06168731756967051 on epoch=174
05/16/2022 09:58:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.99 on epoch=175
05/16/2022 09:58:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.95 on epoch=176
05/16/2022 09:58:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.90 on epoch=177
05/16/2022 09:58:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.69 on epoch=177
05/16/2022 09:58:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.04 on epoch=178
05/16/2022 09:58:57 - INFO - __main__ - Global step 2500 Train loss 1.91 Classification-F1 0.07772376179317322 on epoch=178
05/16/2022 09:58:57 - INFO - __main__ - Saving model with best Classification-F1: 0.07333057559506033 -> 0.07772376179317322 on epoch=178, global_step=2500
05/16/2022 09:58:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.91 on epoch=179
05/16/2022 09:59:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.85 on epoch=179
05/16/2022 09:59:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.92 on epoch=180
05/16/2022 09:59:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.78 on epoch=181
05/16/2022 09:59:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.92 on epoch=182
05/16/2022 09:59:05 - INFO - __main__ - Global step 2550 Train loss 1.88 Classification-F1 0.08242901746991259 on epoch=182
05/16/2022 09:59:05 - INFO - __main__ - Saving model with best Classification-F1: 0.07772376179317322 -> 0.08242901746991259 on epoch=182, global_step=2550
05/16/2022 09:59:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.90 on epoch=182
05/16/2022 09:59:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.90 on epoch=183
05/16/2022 09:59:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.84 on epoch=184
05/16/2022 09:59:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.78 on epoch=184
05/16/2022 09:59:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.90 on epoch=185
05/16/2022 09:59:14 - INFO - __main__ - Global step 2600 Train loss 1.86 Classification-F1 0.05927219237988134 on epoch=185
05/16/2022 09:59:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.96 on epoch=186
05/16/2022 09:59:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.82 on epoch=187
05/16/2022 09:59:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.78 on epoch=187
05/16/2022 09:59:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.90 on epoch=188
05/16/2022 09:59:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.89 on epoch=189
05/16/2022 09:59:22 - INFO - __main__ - Global step 2650 Train loss 1.87 Classification-F1 0.06874328678839955 on epoch=189
05/16/2022 09:59:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.83 on epoch=189
05/16/2022 09:59:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.70 on epoch=190
05/16/2022 09:59:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.90 on epoch=191
05/16/2022 09:59:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.81 on epoch=192
05/16/2022 09:59:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.77 on epoch=192
05/16/2022 09:59:30 - INFO - __main__ - Global step 2700 Train loss 1.80 Classification-F1 0.07563898861438888 on epoch=192
05/16/2022 09:59:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.67 on epoch=193
05/16/2022 09:59:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.91 on epoch=194
05/16/2022 09:59:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.92 on epoch=194
05/16/2022 09:59:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.71 on epoch=195
05/16/2022 09:59:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.72 on epoch=196
05/16/2022 09:59:38 - INFO - __main__ - Global step 2750 Train loss 1.79 Classification-F1 0.04166666666666667 on epoch=196
05/16/2022 09:59:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.86 on epoch=197
05/16/2022 09:59:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.68 on epoch=197
05/16/2022 09:59:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.71 on epoch=198
05/16/2022 09:59:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.84 on epoch=199
05/16/2022 09:59:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.79 on epoch=199
05/16/2022 09:59:47 - INFO - __main__ - Global step 2800 Train loss 1.78 Classification-F1 0.048707804884355325 on epoch=199
05/16/2022 09:59:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.61 on epoch=200
05/16/2022 09:59:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.66 on epoch=201
05/16/2022 09:59:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.79 on epoch=202
05/16/2022 09:59:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.67 on epoch=202
05/16/2022 09:59:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.84 on epoch=203
05/16/2022 09:59:55 - INFO - __main__ - Global step 2850 Train loss 1.71 Classification-F1 0.04450504132370516 on epoch=203
05/16/2022 09:59:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.73 on epoch=204
05/16/2022 09:59:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.67 on epoch=204
05/16/2022 09:59:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.65 on epoch=205
05/16/2022 10:00:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.82 on epoch=206
05/16/2022 10:00:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.69 on epoch=207
05/16/2022 10:00:03 - INFO - __main__ - Global step 2900 Train loss 1.71 Classification-F1 0.047229053747522745 on epoch=207
05/16/2022 10:00:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.59 on epoch=207
05/16/2022 10:00:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.75 on epoch=208
05/16/2022 10:00:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.65 on epoch=209
05/16/2022 10:00:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.74 on epoch=209
05/16/2022 10:00:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.70 on epoch=210
05/16/2022 10:00:12 - INFO - __main__ - Global step 2950 Train loss 1.68 Classification-F1 0.036088164598356176 on epoch=210
05/16/2022 10:00:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.69 on epoch=211
05/16/2022 10:00:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.66 on epoch=212
05/16/2022 10:00:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.66 on epoch=212
05/16/2022 10:00:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.78 on epoch=213
05/16/2022 10:00:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.68 on epoch=214
05/16/2022 10:00:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:00:19 - INFO - __main__ - Printing 3 examples
05/16/2022 10:00:19 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 10:00:19 - INFO - __main__ - ['Company']
05/16/2022 10:00:19 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 10:00:19 - INFO - __main__ - ['Company']
05/16/2022 10:00:19 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 10:00:19 - INFO - __main__ - ['Company']
05/16/2022 10:00:19 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:00:19 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:00:19 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:00:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:00:19 - INFO - __main__ - Printing 3 examples
05/16/2022 10:00:19 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 10:00:19 - INFO - __main__ - ['Company']
05/16/2022 10:00:19 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 10:00:19 - INFO - __main__ - ['Company']
05/16/2022 10:00:19 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 10:00:19 - INFO - __main__ - ['Company']
05/16/2022 10:00:19 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:00:20 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:00:20 - INFO - __main__ - Global step 3000 Train loss 1.69 Classification-F1 0.009685230024213076 on epoch=214
05/16/2022 10:00:20 - INFO - __main__ - save last model!
05/16/2022 10:00:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 10:00:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 10:00:20 - INFO - __main__ - Printing 3 examples
05/16/2022 10:00:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 10:00:20 - INFO - __main__ - ['Animal']
05/16/2022 10:00:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 10:00:20 - INFO - __main__ - ['Animal']
05/16/2022 10:00:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 10:00:20 - INFO - __main__ - ['Village']
05/16/2022 10:00:20 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:00:20 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:00:22 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:00:25 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 10:00:26 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:00:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:00:26 - INFO - __main__ - Starting training!
05/16/2022 10:00:54 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/16/2022 10:00:54 - INFO - __main__ - Classification-F1 on test data: 0.0120
05/16/2022 10:00:55 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.08242901746991259, test_performance=0.012025883515299303
05/16/2022 10:00:55 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/16/2022 10:00:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:00:55 - INFO - __main__ - Printing 3 examples
05/16/2022 10:00:55 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 10:00:55 - INFO - __main__ - ['Company']
05/16/2022 10:00:55 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 10:00:55 - INFO - __main__ - ['Company']
05/16/2022 10:00:55 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 10:00:55 - INFO - __main__ - ['Company']
05/16/2022 10:00:55 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:00:56 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:00:56 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:00:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:00:56 - INFO - __main__ - Printing 3 examples
05/16/2022 10:00:56 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 10:00:56 - INFO - __main__ - ['Company']
05/16/2022 10:00:56 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 10:00:56 - INFO - __main__ - ['Company']
05/16/2022 10:00:56 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 10:00:56 - INFO - __main__ - ['Company']
05/16/2022 10:00:56 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:00:56 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:00:56 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:01:02 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:01:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:01:02 - INFO - __main__ - Starting training!
05/16/2022 10:01:03 - INFO - __main__ - Step 10 Global step 10 Train loss 7.34 on epoch=0
05/16/2022 10:01:05 - INFO - __main__ - Step 20 Global step 20 Train loss 7.59 on epoch=1
05/16/2022 10:01:06 - INFO - __main__ - Step 30 Global step 30 Train loss 7.50 on epoch=2
05/16/2022 10:01:07 - INFO - __main__ - Step 40 Global step 40 Train loss 6.85 on epoch=2
05/16/2022 10:01:09 - INFO - __main__ - Step 50 Global step 50 Train loss 7.29 on epoch=3
05/16/2022 10:01:22 - INFO - __main__ - Global step 50 Train loss 7.32 Classification-F1 0.0 on epoch=3
05/16/2022 10:01:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 10:01:24 - INFO - __main__ - Step 60 Global step 60 Train loss 6.86 on epoch=4
05/16/2022 10:01:25 - INFO - __main__ - Step 70 Global step 70 Train loss 7.05 on epoch=4
05/16/2022 10:01:26 - INFO - __main__ - Step 80 Global step 80 Train loss 6.61 on epoch=5
05/16/2022 10:01:28 - INFO - __main__ - Step 90 Global step 90 Train loss 6.81 on epoch=6
05/16/2022 10:01:29 - INFO - __main__ - Step 100 Global step 100 Train loss 6.77 on epoch=7
05/16/2022 10:02:07 - INFO - __main__ - Global step 100 Train loss 6.82 Classification-F1 0.0 on epoch=7
05/16/2022 10:02:09 - INFO - __main__ - Step 110 Global step 110 Train loss 6.24 on epoch=7
05/16/2022 10:02:10 - INFO - __main__ - Step 120 Global step 120 Train loss 6.58 on epoch=8
05/16/2022 10:02:11 - INFO - __main__ - Step 130 Global step 130 Train loss 6.20 on epoch=9
05/16/2022 10:02:13 - INFO - __main__ - Step 140 Global step 140 Train loss 6.54 on epoch=9
05/16/2022 10:02:14 - INFO - __main__ - Step 150 Global step 150 Train loss 6.06 on epoch=10
05/16/2022 10:02:41 - INFO - __main__ - Global step 150 Train loss 6.32 Classification-F1 0.0 on epoch=10
05/16/2022 10:02:42 - INFO - __main__ - Step 160 Global step 160 Train loss 6.18 on epoch=11
05/16/2022 10:02:43 - INFO - __main__ - Step 170 Global step 170 Train loss 6.18 on epoch=12
05/16/2022 10:02:44 - INFO - __main__ - Step 180 Global step 180 Train loss 5.70 on epoch=12
05/16/2022 10:02:46 - INFO - __main__ - Step 190 Global step 190 Train loss 6.09 on epoch=13
05/16/2022 10:02:47 - INFO - __main__ - Step 200 Global step 200 Train loss 5.69 on epoch=14
05/16/2022 10:03:31 - INFO - __main__ - Global step 200 Train loss 5.97 Classification-F1 0.0 on epoch=14
05/16/2022 10:03:32 - INFO - __main__ - Step 210 Global step 210 Train loss 6.01 on epoch=14
05/16/2022 10:03:33 - INFO - __main__ - Step 220 Global step 220 Train loss 5.70 on epoch=15
05/16/2022 10:03:35 - INFO - __main__ - Step 230 Global step 230 Train loss 5.83 on epoch=16
05/16/2022 10:03:36 - INFO - __main__ - Step 240 Global step 240 Train loss 5.62 on epoch=17
05/16/2022 10:03:37 - INFO - __main__ - Step 250 Global step 250 Train loss 5.38 on epoch=17
05/16/2022 10:04:06 - INFO - __main__ - Global step 250 Train loss 5.71 Classification-F1 0.0 on epoch=17
05/16/2022 10:04:08 - INFO - __main__ - Step 260 Global step 260 Train loss 5.48 on epoch=18
05/16/2022 10:04:09 - INFO - __main__ - Step 270 Global step 270 Train loss 5.26 on epoch=19
05/16/2022 10:04:10 - INFO - __main__ - Step 280 Global step 280 Train loss 5.42 on epoch=19
05/16/2022 10:04:12 - INFO - __main__ - Step 290 Global step 290 Train loss 5.03 on epoch=20
05/16/2022 10:04:13 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/16/2022 10:04:28 - INFO - __main__ - Global step 300 Train loss 5.32 Classification-F1 0.0065832784726793945 on epoch=21
05/16/2022 10:04:28 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0065832784726793945 on epoch=21, global_step=300
05/16/2022 10:04:30 - INFO - __main__ - Step 310 Global step 310 Train loss 5.14 on epoch=22
05/16/2022 10:04:31 - INFO - __main__ - Step 320 Global step 320 Train loss 4.94 on epoch=22
05/16/2022 10:04:33 - INFO - __main__ - Step 330 Global step 330 Train loss 5.09 on epoch=23
05/16/2022 10:04:34 - INFO - __main__ - Step 340 Global step 340 Train loss 5.08 on epoch=24
05/16/2022 10:04:36 - INFO - __main__ - Step 350 Global step 350 Train loss 5.18 on epoch=24
05/16/2022 10:04:39 - INFO - __main__ - Global step 350 Train loss 5.09 Classification-F1 0.007231404958677684 on epoch=24
05/16/2022 10:04:39 - INFO - __main__ - Saving model with best Classification-F1: 0.0065832784726793945 -> 0.007231404958677684 on epoch=24, global_step=350
05/16/2022 10:04:41 - INFO - __main__ - Step 360 Global step 360 Train loss 4.86 on epoch=25
05/16/2022 10:04:42 - INFO - __main__ - Step 370 Global step 370 Train loss 5.03 on epoch=26
05/16/2022 10:04:43 - INFO - __main__ - Step 380 Global step 380 Train loss 4.98 on epoch=27
05/16/2022 10:04:45 - INFO - __main__ - Step 390 Global step 390 Train loss 4.62 on epoch=27
05/16/2022 10:04:46 - INFO - __main__ - Step 400 Global step 400 Train loss 4.77 on epoch=28
05/16/2022 10:04:48 - INFO - __main__ - Global step 400 Train loss 4.85 Classification-F1 0.0072028811524609835 on epoch=28
05/16/2022 10:04:50 - INFO - __main__ - Step 410 Global step 410 Train loss 4.67 on epoch=29
05/16/2022 10:04:51 - INFO - __main__ - Step 420 Global step 420 Train loss 4.82 on epoch=29
05/16/2022 10:04:52 - INFO - __main__ - Step 430 Global step 430 Train loss 4.47 on epoch=30
05/16/2022 10:04:54 - INFO - __main__ - Step 440 Global step 440 Train loss 4.63 on epoch=31
05/16/2022 10:04:55 - INFO - __main__ - Step 450 Global step 450 Train loss 4.56 on epoch=32
05/16/2022 10:04:57 - INFO - __main__ - Global step 450 Train loss 4.63 Classification-F1 0.008403361344537815 on epoch=32
05/16/2022 10:04:57 - INFO - __main__ - Saving model with best Classification-F1: 0.007231404958677684 -> 0.008403361344537815 on epoch=32, global_step=450
05/16/2022 10:04:59 - INFO - __main__ - Step 460 Global step 460 Train loss 4.42 on epoch=32
05/16/2022 10:05:00 - INFO - __main__ - Step 470 Global step 470 Train loss 4.47 on epoch=33
05/16/2022 10:05:01 - INFO - __main__ - Step 480 Global step 480 Train loss 4.34 on epoch=34
05/16/2022 10:05:03 - INFO - __main__ - Step 490 Global step 490 Train loss 4.36 on epoch=34
05/16/2022 10:05:04 - INFO - __main__ - Step 500 Global step 500 Train loss 4.24 on epoch=35
05/16/2022 10:05:06 - INFO - __main__ - Global step 500 Train loss 4.37 Classification-F1 0.009523809523809523 on epoch=35
05/16/2022 10:05:06 - INFO - __main__ - Saving model with best Classification-F1: 0.008403361344537815 -> 0.009523809523809523 on epoch=35, global_step=500
05/16/2022 10:05:07 - INFO - __main__ - Step 510 Global step 510 Train loss 4.31 on epoch=36
05/16/2022 10:05:08 - INFO - __main__ - Step 520 Global step 520 Train loss 4.16 on epoch=37
05/16/2022 10:05:10 - INFO - __main__ - Step 530 Global step 530 Train loss 4.08 on epoch=37
05/16/2022 10:05:11 - INFO - __main__ - Step 540 Global step 540 Train loss 4.08 on epoch=38
05/16/2022 10:05:12 - INFO - __main__ - Step 550 Global step 550 Train loss 4.08 on epoch=39
05/16/2022 10:05:14 - INFO - __main__ - Global step 550 Train loss 4.14 Classification-F1 0.009523809523809523 on epoch=39
05/16/2022 10:05:16 - INFO - __main__ - Step 560 Global step 560 Train loss 4.09 on epoch=39
05/16/2022 10:05:17 - INFO - __main__ - Step 570 Global step 570 Train loss 3.99 on epoch=40
05/16/2022 10:05:18 - INFO - __main__ - Step 580 Global step 580 Train loss 3.83 on epoch=41
05/16/2022 10:05:19 - INFO - __main__ - Step 590 Global step 590 Train loss 3.90 on epoch=42
05/16/2022 10:05:21 - INFO - __main__ - Step 600 Global step 600 Train loss 3.83 on epoch=42
05/16/2022 10:05:23 - INFO - __main__ - Global step 600 Train loss 3.93 Classification-F1 0.009523809523809523 on epoch=42
05/16/2022 10:05:24 - INFO - __main__ - Step 610 Global step 610 Train loss 3.84 on epoch=43
05/16/2022 10:05:25 - INFO - __main__ - Step 620 Global step 620 Train loss 3.72 on epoch=44
05/16/2022 10:05:26 - INFO - __main__ - Step 630 Global step 630 Train loss 3.88 on epoch=44
05/16/2022 10:05:28 - INFO - __main__ - Step 640 Global step 640 Train loss 3.58 on epoch=45
05/16/2022 10:05:29 - INFO - __main__ - Step 650 Global step 650 Train loss 3.71 on epoch=46
05/16/2022 10:05:31 - INFO - __main__ - Global step 650 Train loss 3.75 Classification-F1 0.009523809523809523 on epoch=46
05/16/2022 10:05:32 - INFO - __main__ - Step 660 Global step 660 Train loss 3.55 on epoch=47
05/16/2022 10:05:33 - INFO - __main__ - Step 670 Global step 670 Train loss 3.61 on epoch=47
05/16/2022 10:05:35 - INFO - __main__ - Step 680 Global step 680 Train loss 3.65 on epoch=48
05/16/2022 10:05:36 - INFO - __main__ - Step 690 Global step 690 Train loss 3.45 on epoch=49
05/16/2022 10:05:37 - INFO - __main__ - Step 700 Global step 700 Train loss 3.64 on epoch=49
05/16/2022 10:05:39 - INFO - __main__ - Global step 700 Train loss 3.58 Classification-F1 0.028485757121439276 on epoch=49
05/16/2022 10:05:39 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.028485757121439276 on epoch=49, global_step=700
05/16/2022 10:05:40 - INFO - __main__ - Step 710 Global step 710 Train loss 3.44 on epoch=50
05/16/2022 10:05:42 - INFO - __main__ - Step 720 Global step 720 Train loss 3.35 on epoch=51
05/16/2022 10:05:43 - INFO - __main__ - Step 730 Global step 730 Train loss 3.31 on epoch=52
05/16/2022 10:05:44 - INFO - __main__ - Step 740 Global step 740 Train loss 3.42 on epoch=52
05/16/2022 10:05:45 - INFO - __main__ - Step 750 Global step 750 Train loss 3.35 on epoch=53
05/16/2022 10:05:47 - INFO - __main__ - Global step 750 Train loss 3.37 Classification-F1 0.01800720288115246 on epoch=53
05/16/2022 10:05:49 - INFO - __main__ - Step 760 Global step 760 Train loss 3.24 on epoch=54
05/16/2022 10:05:50 - INFO - __main__ - Step 770 Global step 770 Train loss 3.32 on epoch=54
05/16/2022 10:05:51 - INFO - __main__ - Step 780 Global step 780 Train loss 3.18 on epoch=55
05/16/2022 10:05:52 - INFO - __main__ - Step 790 Global step 790 Train loss 3.26 on epoch=56
05/16/2022 10:05:54 - INFO - __main__ - Step 800 Global step 800 Train loss 3.18 on epoch=57
05/16/2022 10:05:56 - INFO - __main__ - Global step 800 Train loss 3.24 Classification-F1 0.025068946497517928 on epoch=57
05/16/2022 10:05:57 - INFO - __main__ - Step 810 Global step 810 Train loss 3.22 on epoch=57
05/16/2022 10:05:58 - INFO - __main__ - Step 820 Global step 820 Train loss 3.04 on epoch=58
05/16/2022 10:06:00 - INFO - __main__ - Step 830 Global step 830 Train loss 3.13 on epoch=59
05/16/2022 10:06:01 - INFO - __main__ - Step 840 Global step 840 Train loss 3.18 on epoch=59
05/16/2022 10:06:02 - INFO - __main__ - Step 850 Global step 850 Train loss 2.88 on epoch=60
05/16/2022 10:06:04 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.009563658099222952 on epoch=60
05/16/2022 10:06:05 - INFO - __main__ - Step 860 Global step 860 Train loss 2.98 on epoch=61
05/16/2022 10:06:07 - INFO - __main__ - Step 870 Global step 870 Train loss 2.89 on epoch=62
05/16/2022 10:06:08 - INFO - __main__ - Step 880 Global step 880 Train loss 3.02 on epoch=62
05/16/2022 10:06:09 - INFO - __main__ - Step 890 Global step 890 Train loss 3.03 on epoch=63
05/16/2022 10:06:10 - INFO - __main__ - Step 900 Global step 900 Train loss 2.96 on epoch=64
05/16/2022 10:06:12 - INFO - __main__ - Global step 900 Train loss 2.98 Classification-F1 0.024081089128564808 on epoch=64
05/16/2022 10:06:14 - INFO - __main__ - Step 910 Global step 910 Train loss 2.83 on epoch=64
05/16/2022 10:06:15 - INFO - __main__ - Step 920 Global step 920 Train loss 2.69 on epoch=65
05/16/2022 10:06:16 - INFO - __main__ - Step 930 Global step 930 Train loss 2.95 on epoch=66
05/16/2022 10:06:17 - INFO - __main__ - Step 940 Global step 940 Train loss 2.93 on epoch=67
05/16/2022 10:06:19 - INFO - __main__ - Step 950 Global step 950 Train loss 2.89 on epoch=67
05/16/2022 10:06:22 - INFO - __main__ - Global step 950 Train loss 2.86 Classification-F1 0.05508180344245918 on epoch=67
05/16/2022 10:06:22 - INFO - __main__ - Saving model with best Classification-F1: 0.028485757121439276 -> 0.05508180344245918 on epoch=67, global_step=950
05/16/2022 10:06:23 - INFO - __main__ - Step 960 Global step 960 Train loss 2.80 on epoch=68
05/16/2022 10:06:24 - INFO - __main__ - Step 970 Global step 970 Train loss 2.79 on epoch=69
05/16/2022 10:06:26 - INFO - __main__ - Step 980 Global step 980 Train loss 2.92 on epoch=69
05/16/2022 10:06:27 - INFO - __main__ - Step 990 Global step 990 Train loss 2.81 on epoch=70
05/16/2022 10:06:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.73 on epoch=71
05/16/2022 10:06:31 - INFO - __main__ - Global step 1000 Train loss 2.81 Classification-F1 0.07907107670654469 on epoch=71
05/16/2022 10:06:31 - INFO - __main__ - Saving model with best Classification-F1: 0.05508180344245918 -> 0.07907107670654469 on epoch=71, global_step=1000
05/16/2022 10:06:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.75 on epoch=72
05/16/2022 10:06:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.88 on epoch=72
05/16/2022 10:06:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.65 on epoch=73
05/16/2022 10:06:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.72 on epoch=74
05/16/2022 10:06:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.59 on epoch=74
05/16/2022 10:06:40 - INFO - __main__ - Global step 1050 Train loss 2.72 Classification-F1 0.046860500803379605 on epoch=74
05/16/2022 10:06:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.58 on epoch=75
05/16/2022 10:06:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.53 on epoch=76
05/16/2022 10:06:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.68 on epoch=77
05/16/2022 10:06:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.51 on epoch=77
05/16/2022 10:06:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.49 on epoch=78
05/16/2022 10:06:49 - INFO - __main__ - Global step 1100 Train loss 2.56 Classification-F1 0.048964630897404 on epoch=78
05/16/2022 10:06:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.55 on epoch=79
05/16/2022 10:06:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.61 on epoch=79
05/16/2022 10:06:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=80
05/16/2022 10:06:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.54 on epoch=81
05/16/2022 10:06:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.49 on epoch=82
05/16/2022 10:06:58 - INFO - __main__ - Global step 1150 Train loss 2.55 Classification-F1 0.04747840147294873 on epoch=82
05/16/2022 10:06:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.63 on epoch=82
05/16/2022 10:07:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.50 on epoch=83
05/16/2022 10:07:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.60 on epoch=84
05/16/2022 10:07:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.60 on epoch=84
05/16/2022 10:07:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.45 on epoch=85
05/16/2022 10:07:07 - INFO - __main__ - Global step 1200 Train loss 2.56 Classification-F1 0.07546270653121834 on epoch=85
05/16/2022 10:07:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.32 on epoch=86
05/16/2022 10:07:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.45 on epoch=87
05/16/2022 10:07:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.37 on epoch=87
05/16/2022 10:07:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.36 on epoch=88
05/16/2022 10:07:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.23 on epoch=89
05/16/2022 10:07:16 - INFO - __main__ - Global step 1250 Train loss 2.35 Classification-F1 0.059761348708217775 on epoch=89
05/16/2022 10:07:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.39 on epoch=89
05/16/2022 10:07:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.28 on epoch=90
05/16/2022 10:07:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.23 on epoch=91
05/16/2022 10:07:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.31 on epoch=92
05/16/2022 10:07:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.19 on epoch=92
05/16/2022 10:07:25 - INFO - __main__ - Global step 1300 Train loss 2.28 Classification-F1 0.055208935643718246 on epoch=92
05/16/2022 10:07:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.28 on epoch=93
05/16/2022 10:07:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.27 on epoch=94
05/16/2022 10:07:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.37 on epoch=94
05/16/2022 10:07:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.36 on epoch=95
05/16/2022 10:07:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.31 on epoch=96
05/16/2022 10:07:34 - INFO - __main__ - Global step 1350 Train loss 2.32 Classification-F1 0.0776048367620732 on epoch=96
05/16/2022 10:07:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.41 on epoch=97
05/16/2022 10:07:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.24 on epoch=97
05/16/2022 10:07:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.20 on epoch=98
05/16/2022 10:07:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.13 on epoch=99
05/16/2022 10:07:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.09 on epoch=99
05/16/2022 10:07:42 - INFO - __main__ - Global step 1400 Train loss 2.21 Classification-F1 0.07363172150112762 on epoch=99
05/16/2022 10:07:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.12 on epoch=100
05/16/2022 10:07:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.27 on epoch=101
05/16/2022 10:07:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.30 on epoch=102
05/16/2022 10:07:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.27 on epoch=102
05/16/2022 10:07:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.20 on epoch=103
05/16/2022 10:07:51 - INFO - __main__ - Global step 1450 Train loss 2.23 Classification-F1 0.07114280934156711 on epoch=103
05/16/2022 10:07:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.99 on epoch=104
05/16/2022 10:07:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.38 on epoch=104
05/16/2022 10:07:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.18 on epoch=105
05/16/2022 10:07:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.25 on epoch=106
05/16/2022 10:07:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.11 on epoch=107
05/16/2022 10:08:00 - INFO - __main__ - Global step 1500 Train loss 2.18 Classification-F1 0.08958019633051473 on epoch=107
05/16/2022 10:08:00 - INFO - __main__ - Saving model with best Classification-F1: 0.07907107670654469 -> 0.08958019633051473 on epoch=107, global_step=1500
05/16/2022 10:08:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.19 on epoch=107
05/16/2022 10:08:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.05 on epoch=108
05/16/2022 10:08:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.97 on epoch=109
05/16/2022 10:08:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.14 on epoch=109
05/16/2022 10:08:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.06 on epoch=110
05/16/2022 10:08:10 - INFO - __main__ - Global step 1550 Train loss 2.08 Classification-F1 0.1096157581140896 on epoch=110
05/16/2022 10:08:10 - INFO - __main__ - Saving model with best Classification-F1: 0.08958019633051473 -> 0.1096157581140896 on epoch=110, global_step=1550
05/16/2022 10:08:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.93 on epoch=111
05/16/2022 10:08:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.05 on epoch=112
05/16/2022 10:08:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.07 on epoch=112
05/16/2022 10:08:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.05 on epoch=113
05/16/2022 10:08:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.00 on epoch=114
05/16/2022 10:08:19 - INFO - __main__ - Global step 1600 Train loss 2.02 Classification-F1 0.11571149159003588 on epoch=114
05/16/2022 10:08:19 - INFO - __main__ - Saving model with best Classification-F1: 0.1096157581140896 -> 0.11571149159003588 on epoch=114, global_step=1600
05/16/2022 10:08:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.16 on epoch=114
05/16/2022 10:08:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.89 on epoch=115
05/16/2022 10:08:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.08 on epoch=116
05/16/2022 10:08:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.09 on epoch=117
05/16/2022 10:08:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.25 on epoch=117
05/16/2022 10:08:29 - INFO - __main__ - Global step 1650 Train loss 2.10 Classification-F1 0.13002759632281005 on epoch=117
05/16/2022 10:08:29 - INFO - __main__ - Saving model with best Classification-F1: 0.11571149159003588 -> 0.13002759632281005 on epoch=117, global_step=1650
05/16/2022 10:08:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.83 on epoch=118
05/16/2022 10:08:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.87 on epoch=119
05/16/2022 10:08:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.07 on epoch=119
05/16/2022 10:08:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.00 on epoch=120
05/16/2022 10:08:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.03 on epoch=121
05/16/2022 10:08:37 - INFO - __main__ - Global step 1700 Train loss 1.96 Classification-F1 0.11659487521556487 on epoch=121
05/16/2022 10:08:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.99 on epoch=122
05/16/2022 10:08:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.97 on epoch=122
05/16/2022 10:08:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.09 on epoch=123
05/16/2022 10:08:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.96 on epoch=124
05/16/2022 10:08:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.12 on epoch=124
05/16/2022 10:08:47 - INFO - __main__ - Global step 1750 Train loss 2.03 Classification-F1 0.05395443823380785 on epoch=124
05/16/2022 10:08:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.93 on epoch=125
05/16/2022 10:08:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.01 on epoch=126
05/16/2022 10:08:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.24 on epoch=127
05/16/2022 10:08:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.27 on epoch=127
05/16/2022 10:08:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.21 on epoch=128
05/16/2022 10:08:55 - INFO - __main__ - Global step 1800 Train loss 2.13 Classification-F1 0.09902841519382874 on epoch=128
05/16/2022 10:08:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.03 on epoch=129
05/16/2022 10:08:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.03 on epoch=129
05/16/2022 10:09:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.90 on epoch=130
05/16/2022 10:09:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.97 on epoch=131
05/16/2022 10:09:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.11 on epoch=132
05/16/2022 10:09:04 - INFO - __main__ - Global step 1850 Train loss 2.01 Classification-F1 0.01821329390125149 on epoch=132
05/16/2022 10:09:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.92 on epoch=132
05/16/2022 10:09:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.80 on epoch=133
05/16/2022 10:09:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.98 on epoch=134
05/16/2022 10:09:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.90 on epoch=134
05/16/2022 10:09:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.87 on epoch=135
05/16/2022 10:09:14 - INFO - __main__ - Global step 1900 Train loss 1.89 Classification-F1 0.038769757374408534 on epoch=135
05/16/2022 10:09:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.00 on epoch=136
05/16/2022 10:09:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.91 on epoch=137
05/16/2022 10:09:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.98 on epoch=137
05/16/2022 10:09:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.96 on epoch=138
05/16/2022 10:09:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.88 on epoch=139
05/16/2022 10:09:22 - INFO - __main__ - Global step 1950 Train loss 1.95 Classification-F1 0.009726443768996961 on epoch=139
05/16/2022 10:09:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.29 on epoch=139
05/16/2022 10:09:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.97 on epoch=140
05/16/2022 10:09:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.97 on epoch=141
05/16/2022 10:09:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.95 on epoch=142
05/16/2022 10:09:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.97 on epoch=142
05/16/2022 10:09:31 - INFO - __main__ - Global step 2000 Train loss 2.03 Classification-F1 0.06975881261595547 on epoch=142
05/16/2022 10:09:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.00 on epoch=143
05/16/2022 10:09:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.79 on epoch=144
05/16/2022 10:09:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.94 on epoch=144
05/16/2022 10:09:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.72 on epoch=145
05/16/2022 10:09:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.90 on epoch=146
05/16/2022 10:09:41 - INFO - __main__ - Global step 2050 Train loss 1.87 Classification-F1 0.08109941452585301 on epoch=146
05/16/2022 10:09:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.89 on epoch=147
05/16/2022 10:09:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.82 on epoch=147
05/16/2022 10:09:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.79 on epoch=148
05/16/2022 10:09:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.73 on epoch=149
05/16/2022 10:09:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.87 on epoch=149
05/16/2022 10:09:51 - INFO - __main__ - Global step 2100 Train loss 1.82 Classification-F1 0.15528383316919533 on epoch=149
05/16/2022 10:09:51 - INFO - __main__ - Saving model with best Classification-F1: 0.13002759632281005 -> 0.15528383316919533 on epoch=149, global_step=2100
05/16/2022 10:09:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.69 on epoch=150
05/16/2022 10:09:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.89 on epoch=151
05/16/2022 10:09:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.75 on epoch=152
05/16/2022 10:09:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.74 on epoch=152
05/16/2022 10:09:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.99 on epoch=153
05/16/2022 10:10:00 - INFO - __main__ - Global step 2150 Train loss 1.81 Classification-F1 0.0957826363875423 on epoch=153
05/16/2022 10:10:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.73 on epoch=154
05/16/2022 10:10:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.33 on epoch=154
05/16/2022 10:10:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.00 on epoch=155
05/16/2022 10:10:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.03 on epoch=156
05/16/2022 10:10:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.14 on epoch=157
05/16/2022 10:10:09 - INFO - __main__ - Global step 2200 Train loss 2.05 Classification-F1 0.11688786827495667 on epoch=157
05/16/2022 10:10:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.09 on epoch=157
05/16/2022 10:10:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.95 on epoch=158
05/16/2022 10:10:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.92 on epoch=159
05/16/2022 10:10:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.98 on epoch=159
05/16/2022 10:10:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.88 on epoch=160
05/16/2022 10:10:18 - INFO - __main__ - Global step 2250 Train loss 1.97 Classification-F1 0.03043525102348632 on epoch=160
05/16/2022 10:10:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.07 on epoch=161
05/16/2022 10:10:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.91 on epoch=162
05/16/2022 10:10:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.87 on epoch=162
05/16/2022 10:10:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.75 on epoch=163
05/16/2022 10:10:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.83 on epoch=164
05/16/2022 10:10:27 - INFO - __main__ - Global step 2300 Train loss 1.88 Classification-F1 0.11716569533771395 on epoch=164
05/16/2022 10:10:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.83 on epoch=164
05/16/2022 10:10:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.61 on epoch=165
05/16/2022 10:10:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.75 on epoch=166
05/16/2022 10:10:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.82 on epoch=167
05/16/2022 10:10:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.61 on epoch=167
05/16/2022 10:10:36 - INFO - __main__ - Global step 2350 Train loss 1.72 Classification-F1 0.13881679049917098 on epoch=167
05/16/2022 10:10:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.70 on epoch=168
05/16/2022 10:10:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.68 on epoch=169
05/16/2022 10:10:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.73 on epoch=169
05/16/2022 10:10:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.62 on epoch=170
05/16/2022 10:10:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.72 on epoch=171
05/16/2022 10:10:47 - INFO - __main__ - Global step 2400 Train loss 1.69 Classification-F1 0.0956001046933549 on epoch=171
05/16/2022 10:10:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.69 on epoch=172
05/16/2022 10:10:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.67 on epoch=172
05/16/2022 10:10:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.66 on epoch=173
05/16/2022 10:10:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.54 on epoch=174
05/16/2022 10:10:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.74 on epoch=174
05/16/2022 10:10:56 - INFO - __main__ - Global step 2450 Train loss 1.66 Classification-F1 0.04853688056375626 on epoch=174
05/16/2022 10:10:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.68 on epoch=175
05/16/2022 10:10:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.72 on epoch=176
05/16/2022 10:11:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.79 on epoch=177
05/16/2022 10:11:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.79 on epoch=177
05/16/2022 10:11:03 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.76 on epoch=178
05/16/2022 10:11:06 - INFO - __main__ - Global step 2500 Train loss 1.75 Classification-F1 0.09196071249210445 on epoch=178
05/16/2022 10:11:07 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.69 on epoch=179
05/16/2022 10:11:08 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.72 on epoch=179
05/16/2022 10:11:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.63 on epoch=180
05/16/2022 10:11:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.70 on epoch=181
05/16/2022 10:11:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.56 on epoch=182
05/16/2022 10:11:15 - INFO - __main__ - Global step 2550 Train loss 1.66 Classification-F1 0.16868017576963074 on epoch=182
05/16/2022 10:11:15 - INFO - __main__ - Saving model with best Classification-F1: 0.15528383316919533 -> 0.16868017576963074 on epoch=182, global_step=2550
05/16/2022 10:11:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.62 on epoch=182
05/16/2022 10:11:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.62 on epoch=183
05/16/2022 10:11:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.52 on epoch=184
05/16/2022 10:11:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.64 on epoch=184
05/16/2022 10:11:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.59 on epoch=185
05/16/2022 10:11:24 - INFO - __main__ - Global step 2600 Train loss 1.60 Classification-F1 0.10489123348990428 on epoch=185
05/16/2022 10:11:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.75 on epoch=186
05/16/2022 10:11:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.64 on epoch=187
05/16/2022 10:11:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.56 on epoch=187
05/16/2022 10:11:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.57 on epoch=188
05/16/2022 10:11:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.51 on epoch=189
05/16/2022 10:11:33 - INFO - __main__ - Global step 2650 Train loss 1.60 Classification-F1 0.07845594378102116 on epoch=189
05/16/2022 10:11:35 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.70 on epoch=189
05/16/2022 10:11:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.58 on epoch=190
05/16/2022 10:11:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.57 on epoch=191
05/16/2022 10:11:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.59 on epoch=192
05/16/2022 10:11:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.47 on epoch=192
05/16/2022 10:11:42 - INFO - __main__ - Global step 2700 Train loss 1.58 Classification-F1 0.08701359744838008 on epoch=192
05/16/2022 10:11:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.58 on epoch=193
05/16/2022 10:11:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.67 on epoch=194
05/16/2022 10:11:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.85 on epoch=194
05/16/2022 10:11:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.55 on epoch=195
05/16/2022 10:11:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.58 on epoch=196
05/16/2022 10:11:51 - INFO - __main__ - Global step 2750 Train loss 1.64 Classification-F1 0.11014064944101198 on epoch=196
05/16/2022 10:11:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.66 on epoch=197
05/16/2022 10:11:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.61 on epoch=197
05/16/2022 10:11:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.58 on epoch=198
05/16/2022 10:11:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.63 on epoch=199
05/16/2022 10:11:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.59 on epoch=199
05/16/2022 10:12:01 - INFO - __main__ - Global step 2800 Train loss 1.61 Classification-F1 0.1179954810206911 on epoch=199
05/16/2022 10:12:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.51 on epoch=200
05/16/2022 10:12:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.65 on epoch=201
05/16/2022 10:12:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.58 on epoch=202
05/16/2022 10:12:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.50 on epoch=202
05/16/2022 10:12:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.66 on epoch=203
05/16/2022 10:12:10 - INFO - __main__ - Global step 2850 Train loss 1.58 Classification-F1 0.08898313871002947 on epoch=203
05/16/2022 10:12:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.53 on epoch=204
05/16/2022 10:12:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.56 on epoch=204
05/16/2022 10:12:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.47 on epoch=205
05/16/2022 10:12:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.53 on epoch=206
05/16/2022 10:12:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.49 on epoch=207
05/16/2022 10:12:18 - INFO - __main__ - Global step 2900 Train loss 1.51 Classification-F1 0.08250942605781315 on epoch=207
05/16/2022 10:12:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.54 on epoch=207
05/16/2022 10:12:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.66 on epoch=208
05/16/2022 10:12:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.47 on epoch=209
05/16/2022 10:12:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.68 on epoch=209
05/16/2022 10:12:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.48 on epoch=210
05/16/2022 10:12:27 - INFO - __main__ - Global step 2950 Train loss 1.56 Classification-F1 0.05943655657751823 on epoch=210
05/16/2022 10:12:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.59 on epoch=211
05/16/2022 10:12:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.48 on epoch=212
05/16/2022 10:12:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.63 on epoch=212
05/16/2022 10:12:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.57 on epoch=213
05/16/2022 10:12:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.68 on epoch=214
05/16/2022 10:12:35 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:12:35 - INFO - __main__ - Printing 3 examples
05/16/2022 10:12:35 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 10:12:35 - INFO - __main__ - ['Company']
05/16/2022 10:12:35 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 10:12:35 - INFO - __main__ - ['Company']
05/16/2022 10:12:35 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 10:12:35 - INFO - __main__ - ['Company']
05/16/2022 10:12:35 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:12:35 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:12:36 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:12:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:12:36 - INFO - __main__ - Printing 3 examples
05/16/2022 10:12:36 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 10:12:36 - INFO - __main__ - ['Company']
05/16/2022 10:12:36 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 10:12:36 - INFO - __main__ - ['Company']
05/16/2022 10:12:36 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 10:12:36 - INFO - __main__ - ['Company']
05/16/2022 10:12:36 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:12:36 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:12:36 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:12:36 - INFO - __main__ - Global step 3000 Train loss 1.59 Classification-F1 0.10468724074995853 on epoch=214
05/16/2022 10:12:36 - INFO - __main__ - save last model!
05/16/2022 10:12:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 10:12:36 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 10:12:36 - INFO - __main__ - Printing 3 examples
05/16/2022 10:12:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 10:12:36 - INFO - __main__ - ['Animal']
05/16/2022 10:12:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 10:12:36 - INFO - __main__ - ['Animal']
05/16/2022 10:12:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 10:12:36 - INFO - __main__ - ['Village']
05/16/2022 10:12:36 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:12:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:12:41 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 10:12:42 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:12:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:12:42 - INFO - __main__ - Starting training!
05/16/2022 10:13:13 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/16/2022 10:13:13 - INFO - __main__ - Classification-F1 on test data: 0.0784
05/16/2022 10:13:13 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.16868017576963074, test_performance=0.07841842630528417
05/16/2022 10:13:13 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/16/2022 10:13:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:13:14 - INFO - __main__ - Printing 3 examples
05/16/2022 10:13:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 10:13:14 - INFO - __main__ - ['Company']
05/16/2022 10:13:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 10:13:14 - INFO - __main__ - ['Company']
05/16/2022 10:13:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 10:13:14 - INFO - __main__ - ['Company']
05/16/2022 10:13:14 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:13:15 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:13:15 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:13:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:13:15 - INFO - __main__ - Printing 3 examples
05/16/2022 10:13:15 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 10:13:15 - INFO - __main__ - ['Company']
05/16/2022 10:13:15 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 10:13:15 - INFO - __main__ - ['Company']
05/16/2022 10:13:15 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 10:13:15 - INFO - __main__ - ['Company']
05/16/2022 10:13:15 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:13:15 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:13:15 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:13:22 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:13:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:13:22 - INFO - __main__ - Starting training!
05/16/2022 10:13:24 - INFO - __main__ - Step 10 Global step 10 Train loss 7.29 on epoch=0
05/16/2022 10:13:25 - INFO - __main__ - Step 20 Global step 20 Train loss 7.64 on epoch=1
05/16/2022 10:13:26 - INFO - __main__ - Step 30 Global step 30 Train loss 7.35 on epoch=2
05/16/2022 10:13:28 - INFO - __main__ - Step 40 Global step 40 Train loss 6.90 on epoch=2
05/16/2022 10:13:29 - INFO - __main__ - Step 50 Global step 50 Train loss 7.15 on epoch=3
05/16/2022 10:13:39 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/16/2022 10:13:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 10:13:40 - INFO - __main__ - Step 60 Global step 60 Train loss 6.90 on epoch=4
05/16/2022 10:13:42 - INFO - __main__ - Step 70 Global step 70 Train loss 7.04 on epoch=4
05/16/2022 10:13:43 - INFO - __main__ - Step 80 Global step 80 Train loss 6.57 on epoch=5
05/16/2022 10:13:44 - INFO - __main__ - Step 90 Global step 90 Train loss 6.85 on epoch=6
05/16/2022 10:13:46 - INFO - __main__ - Step 100 Global step 100 Train loss 6.84 on epoch=7
05/16/2022 10:14:46 - INFO - __main__ - Global step 100 Train loss 6.84 Classification-F1 0.0 on epoch=7
05/16/2022 10:14:47 - INFO - __main__ - Step 110 Global step 110 Train loss 6.28 on epoch=7
05/16/2022 10:14:48 - INFO - __main__ - Step 120 Global step 120 Train loss 6.59 on epoch=8
05/16/2022 10:14:50 - INFO - __main__ - Step 130 Global step 130 Train loss 6.31 on epoch=9
05/16/2022 10:14:51 - INFO - __main__ - Step 140 Global step 140 Train loss 6.49 on epoch=9
05/16/2022 10:14:52 - INFO - __main__ - Step 150 Global step 150 Train loss 6.06 on epoch=10
05/16/2022 10:16:08 - INFO - __main__ - Global step 150 Train loss 6.35 Classification-F1 0.0 on epoch=10
05/16/2022 10:16:10 - INFO - __main__ - Step 160 Global step 160 Train loss 6.45 on epoch=11
05/16/2022 10:16:11 - INFO - __main__ - Step 170 Global step 170 Train loss 6.22 on epoch=12
05/16/2022 10:16:12 - INFO - __main__ - Step 180 Global step 180 Train loss 5.85 on epoch=12
05/16/2022 10:16:14 - INFO - __main__ - Step 190 Global step 190 Train loss 6.10 on epoch=13
05/16/2022 10:16:15 - INFO - __main__ - Step 200 Global step 200 Train loss 5.99 on epoch=14
05/16/2022 10:17:00 - INFO - __main__ - Global step 200 Train loss 6.12 Classification-F1 0.0 on epoch=14
05/16/2022 10:17:01 - INFO - __main__ - Step 210 Global step 210 Train loss 6.13 on epoch=14
05/16/2022 10:17:02 - INFO - __main__ - Step 220 Global step 220 Train loss 5.73 on epoch=15
05/16/2022 10:17:04 - INFO - __main__ - Step 230 Global step 230 Train loss 6.13 on epoch=16
05/16/2022 10:17:05 - INFO - __main__ - Step 240 Global step 240 Train loss 6.02 on epoch=17
05/16/2022 10:17:06 - INFO - __main__ - Step 250 Global step 250 Train loss 5.66 on epoch=17
05/16/2022 10:18:10 - INFO - __main__ - Global step 250 Train loss 5.93 Classification-F1 0.0 on epoch=17
05/16/2022 10:18:11 - INFO - __main__ - Step 260 Global step 260 Train loss 5.88 on epoch=18
05/16/2022 10:18:13 - INFO - __main__ - Step 270 Global step 270 Train loss 5.65 on epoch=19
05/16/2022 10:18:14 - INFO - __main__ - Step 280 Global step 280 Train loss 5.84 on epoch=19
05/16/2022 10:18:15 - INFO - __main__ - Step 290 Global step 290 Train loss 5.53 on epoch=20
05/16/2022 10:18:17 - INFO - __main__ - Step 300 Global step 300 Train loss 5.82 on epoch=21
05/16/2022 10:18:43 - INFO - __main__ - Global step 300 Train loss 5.74 Classification-F1 0.0 on epoch=21
05/16/2022 10:18:44 - INFO - __main__ - Step 310 Global step 310 Train loss 5.72 on epoch=22
05/16/2022 10:18:46 - INFO - __main__ - Step 320 Global step 320 Train loss 5.49 on epoch=22
05/16/2022 10:18:47 - INFO - __main__ - Step 330 Global step 330 Train loss 5.70 on epoch=23
05/16/2022 10:18:49 - INFO - __main__ - Step 340 Global step 340 Train loss 5.55 on epoch=24
05/16/2022 10:18:50 - INFO - __main__ - Step 350 Global step 350 Train loss 5.62 on epoch=24
05/16/2022 10:19:04 - INFO - __main__ - Global step 350 Train loss 5.62 Classification-F1 0.0 on epoch=24
05/16/2022 10:19:06 - INFO - __main__ - Step 360 Global step 360 Train loss 5.40 on epoch=25
05/16/2022 10:19:07 - INFO - __main__ - Step 370 Global step 370 Train loss 5.43 on epoch=26
05/16/2022 10:19:09 - INFO - __main__ - Step 380 Global step 380 Train loss 5.48 on epoch=27
05/16/2022 10:19:10 - INFO - __main__ - Step 390 Global step 390 Train loss 5.19 on epoch=27
05/16/2022 10:19:11 - INFO - __main__ - Step 400 Global step 400 Train loss 5.44 on epoch=28
05/16/2022 10:19:16 - INFO - __main__ - Global step 400 Train loss 5.39 Classification-F1 0.0 on epoch=28
05/16/2022 10:19:17 - INFO - __main__ - Step 410 Global step 410 Train loss 5.10 on epoch=29
05/16/2022 10:19:19 - INFO - __main__ - Step 420 Global step 420 Train loss 5.43 on epoch=29
05/16/2022 10:19:20 - INFO - __main__ - Step 430 Global step 430 Train loss 5.11 on epoch=30
05/16/2022 10:19:21 - INFO - __main__ - Step 440 Global step 440 Train loss 5.28 on epoch=31
05/16/2022 10:19:23 - INFO - __main__ - Step 450 Global step 450 Train loss 5.17 on epoch=32
05/16/2022 10:19:26 - INFO - __main__ - Global step 450 Train loss 5.22 Classification-F1 0.005050505050505051 on epoch=32
05/16/2022 10:19:26 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005050505050505051 on epoch=32, global_step=450
05/16/2022 10:19:27 - INFO - __main__ - Step 460 Global step 460 Train loss 4.97 on epoch=32
05/16/2022 10:19:28 - INFO - __main__ - Step 470 Global step 470 Train loss 5.10 on epoch=33
05/16/2022 10:19:30 - INFO - __main__ - Step 480 Global step 480 Train loss 4.99 on epoch=34
05/16/2022 10:19:31 - INFO - __main__ - Step 490 Global step 490 Train loss 5.29 on epoch=34
05/16/2022 10:19:32 - INFO - __main__ - Step 500 Global step 500 Train loss 4.97 on epoch=35
05/16/2022 10:19:36 - INFO - __main__ - Global step 500 Train loss 5.06 Classification-F1 0.006521739130434782 on epoch=35
05/16/2022 10:19:36 - INFO - __main__ - Saving model with best Classification-F1: 0.005050505050505051 -> 0.006521739130434782 on epoch=35, global_step=500
05/16/2022 10:19:37 - INFO - __main__ - Step 510 Global step 510 Train loss 5.05 on epoch=36
05/16/2022 10:19:38 - INFO - __main__ - Step 520 Global step 520 Train loss 4.94 on epoch=37
05/16/2022 10:19:40 - INFO - __main__ - Step 530 Global step 530 Train loss 4.81 on epoch=37
05/16/2022 10:19:42 - INFO - __main__ - Step 540 Global step 540 Train loss 4.90 on epoch=38
05/16/2022 10:19:43 - INFO - __main__ - Step 550 Global step 550 Train loss 4.74 on epoch=39
05/16/2022 10:19:51 - INFO - __main__ - Global step 550 Train loss 4.89 Classification-F1 0.007183908045977012 on epoch=39
05/16/2022 10:19:51 - INFO - __main__ - Saving model with best Classification-F1: 0.006521739130434782 -> 0.007183908045977012 on epoch=39, global_step=550
05/16/2022 10:19:52 - INFO - __main__ - Step 560 Global step 560 Train loss 4.94 on epoch=39
05/16/2022 10:19:53 - INFO - __main__ - Step 570 Global step 570 Train loss 4.66 on epoch=40
05/16/2022 10:19:55 - INFO - __main__ - Step 580 Global step 580 Train loss 4.77 on epoch=41
05/16/2022 10:19:56 - INFO - __main__ - Step 590 Global step 590 Train loss 4.76 on epoch=42
05/16/2022 10:19:57 - INFO - __main__ - Step 600 Global step 600 Train loss 4.66 on epoch=42
05/16/2022 10:20:15 - INFO - __main__ - Global step 600 Train loss 4.76 Classification-F1 0.006410256410256411 on epoch=42
05/16/2022 10:20:16 - INFO - __main__ - Step 610 Global step 610 Train loss 4.65 on epoch=43
05/16/2022 10:20:18 - INFO - __main__ - Step 620 Global step 620 Train loss 4.39 on epoch=44
05/16/2022 10:20:19 - INFO - __main__ - Step 630 Global step 630 Train loss 4.76 on epoch=44
05/16/2022 10:20:21 - INFO - __main__ - Step 640 Global step 640 Train loss 4.42 on epoch=45
05/16/2022 10:20:22 - INFO - __main__ - Step 650 Global step 650 Train loss 5.00 on epoch=46
05/16/2022 10:20:35 - INFO - __main__ - Global step 650 Train loss 4.64 Classification-F1 0.00892608089260809 on epoch=46
05/16/2022 10:20:35 - INFO - __main__ - Saving model with best Classification-F1: 0.007183908045977012 -> 0.00892608089260809 on epoch=46, global_step=650
05/16/2022 10:20:36 - INFO - __main__ - Step 660 Global step 660 Train loss 4.49 on epoch=47
05/16/2022 10:20:37 - INFO - __main__ - Step 670 Global step 670 Train loss 4.38 on epoch=47
05/16/2022 10:20:39 - INFO - __main__ - Step 680 Global step 680 Train loss 4.43 on epoch=48
05/16/2022 10:20:40 - INFO - __main__ - Step 690 Global step 690 Train loss 4.30 on epoch=49
05/16/2022 10:20:41 - INFO - __main__ - Step 700 Global step 700 Train loss 4.70 on epoch=49
05/16/2022 10:20:43 - INFO - __main__ - Global step 700 Train loss 4.46 Classification-F1 0.009523809523809523 on epoch=49
05/16/2022 10:20:43 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=49, global_step=700
05/16/2022 10:20:45 - INFO - __main__ - Step 710 Global step 710 Train loss 4.27 on epoch=50
05/16/2022 10:20:46 - INFO - __main__ - Step 720 Global step 720 Train loss 4.39 on epoch=51
05/16/2022 10:20:47 - INFO - __main__ - Step 730 Global step 730 Train loss 4.46 on epoch=52
05/16/2022 10:20:49 - INFO - __main__ - Step 740 Global step 740 Train loss 4.26 on epoch=52
05/16/2022 10:20:50 - INFO - __main__ - Step 750 Global step 750 Train loss 4.29 on epoch=53
05/16/2022 10:20:52 - INFO - __main__ - Global step 750 Train loss 4.33 Classification-F1 0.01680672268907563 on epoch=53
05/16/2022 10:20:52 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01680672268907563 on epoch=53, global_step=750
05/16/2022 10:20:54 - INFO - __main__ - Step 760 Global step 760 Train loss 4.14 on epoch=54
05/16/2022 10:20:55 - INFO - __main__ - Step 770 Global step 770 Train loss 4.43 on epoch=54
05/16/2022 10:20:56 - INFO - __main__ - Step 780 Global step 780 Train loss 4.10 on epoch=55
05/16/2022 10:20:58 - INFO - __main__ - Step 790 Global step 790 Train loss 4.21 on epoch=56
05/16/2022 10:20:59 - INFO - __main__ - Step 800 Global step 800 Train loss 4.15 on epoch=57
05/16/2022 10:21:01 - INFO - __main__ - Global step 800 Train loss 4.21 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 10:21:02 - INFO - __main__ - Step 810 Global step 810 Train loss 4.08 on epoch=57
05/16/2022 10:21:04 - INFO - __main__ - Step 820 Global step 820 Train loss 4.19 on epoch=58
05/16/2022 10:21:05 - INFO - __main__ - Step 830 Global step 830 Train loss 4.15 on epoch=59
05/16/2022 10:21:06 - INFO - __main__ - Step 840 Global step 840 Train loss 4.08 on epoch=59
05/16/2022 10:21:08 - INFO - __main__ - Step 850 Global step 850 Train loss 4.00 on epoch=60
05/16/2022 10:21:09 - INFO - __main__ - Global step 850 Train loss 4.10 Classification-F1 0.02902852369017783 on epoch=60
05/16/2022 10:21:10 - INFO - __main__ - Saving model with best Classification-F1: 0.01680672268907563 -> 0.02902852369017783 on epoch=60, global_step=850
05/16/2022 10:21:11 - INFO - __main__ - Step 860 Global step 860 Train loss 4.07 on epoch=61
05/16/2022 10:21:12 - INFO - __main__ - Step 870 Global step 870 Train loss 3.97 on epoch=62
05/16/2022 10:21:13 - INFO - __main__ - Step 880 Global step 880 Train loss 4.09 on epoch=62
05/16/2022 10:21:15 - INFO - __main__ - Step 890 Global step 890 Train loss 4.04 on epoch=63
05/16/2022 10:21:16 - INFO - __main__ - Step 900 Global step 900 Train loss 4.01 on epoch=64
05/16/2022 10:21:18 - INFO - __main__ - Global step 900 Train loss 4.04 Classification-F1 0.01259538567150518 on epoch=64
05/16/2022 10:21:19 - INFO - __main__ - Step 910 Global step 910 Train loss 4.20 on epoch=64
05/16/2022 10:21:21 - INFO - __main__ - Step 920 Global step 920 Train loss 3.89 on epoch=65
05/16/2022 10:21:22 - INFO - __main__ - Step 930 Global step 930 Train loss 3.97 on epoch=66
05/16/2022 10:21:23 - INFO - __main__ - Step 940 Global step 940 Train loss 3.97 on epoch=67
05/16/2022 10:21:25 - INFO - __main__ - Step 950 Global step 950 Train loss 3.96 on epoch=67
05/16/2022 10:21:26 - INFO - __main__ - Global step 950 Train loss 4.00 Classification-F1 0.033948273948273947 on epoch=67
05/16/2022 10:21:26 - INFO - __main__ - Saving model with best Classification-F1: 0.02902852369017783 -> 0.033948273948273947 on epoch=67, global_step=950
05/16/2022 10:21:28 - INFO - __main__ - Step 960 Global step 960 Train loss 3.84 on epoch=68
05/16/2022 10:21:29 - INFO - __main__ - Step 970 Global step 970 Train loss 3.81 on epoch=69
05/16/2022 10:21:31 - INFO - __main__ - Step 980 Global step 980 Train loss 3.94 on epoch=69
05/16/2022 10:21:32 - INFO - __main__ - Step 990 Global step 990 Train loss 3.81 on epoch=70
05/16/2022 10:21:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.85 on epoch=71
05/16/2022 10:21:35 - INFO - __main__ - Global step 1000 Train loss 3.85 Classification-F1 0.027836117288370394 on epoch=71
05/16/2022 10:21:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.72 on epoch=72
05/16/2022 10:21:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.82 on epoch=72
05/16/2022 10:21:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.60 on epoch=73
05/16/2022 10:21:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.77 on epoch=74
05/16/2022 10:21:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.87 on epoch=74
05/16/2022 10:21:44 - INFO - __main__ - Global step 1050 Train loss 3.76 Classification-F1 0.03267599946156953 on epoch=74
05/16/2022 10:21:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.61 on epoch=75
05/16/2022 10:21:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.67 on epoch=76
05/16/2022 10:21:48 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.64 on epoch=77
05/16/2022 10:21:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.67 on epoch=77
05/16/2022 10:21:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.72 on epoch=78
05/16/2022 10:21:53 - INFO - __main__ - Global step 1100 Train loss 3.66 Classification-F1 0.02391395154553049 on epoch=78
05/16/2022 10:21:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.53 on epoch=79
05/16/2022 10:21:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.62 on epoch=79
05/16/2022 10:21:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.56 on epoch=80
05/16/2022 10:21:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.56 on epoch=81
05/16/2022 10:22:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.45 on epoch=82
05/16/2022 10:22:02 - INFO - __main__ - Global step 1150 Train loss 3.54 Classification-F1 0.030845335542797597 on epoch=82
05/16/2022 10:22:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.62 on epoch=82
05/16/2022 10:22:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.57 on epoch=83
05/16/2022 10:22:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.45 on epoch=84
05/16/2022 10:22:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.60 on epoch=84
05/16/2022 10:22:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.36 on epoch=85
05/16/2022 10:22:11 - INFO - __main__ - Global step 1200 Train loss 3.52 Classification-F1 0.037323322331073126 on epoch=85
05/16/2022 10:22:11 - INFO - __main__ - Saving model with best Classification-F1: 0.033948273948273947 -> 0.037323322331073126 on epoch=85, global_step=1200
05/16/2022 10:22:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.44 on epoch=86
05/16/2022 10:22:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.43 on epoch=87
05/16/2022 10:22:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.59 on epoch=87
05/16/2022 10:22:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.48 on epoch=88
05/16/2022 10:22:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.57 on epoch=89
05/16/2022 10:22:19 - INFO - __main__ - Global step 1250 Train loss 3.50 Classification-F1 0.022622375111545325 on epoch=89
05/16/2022 10:22:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.61 on epoch=89
05/16/2022 10:22:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.49 on epoch=90
05/16/2022 10:22:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.61 on epoch=91
05/16/2022 10:22:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.51 on epoch=92
05/16/2022 10:22:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.48 on epoch=92
05/16/2022 10:22:28 - INFO - __main__ - Global step 1300 Train loss 3.54 Classification-F1 0.012162759840778416 on epoch=92
05/16/2022 10:22:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.53 on epoch=93
05/16/2022 10:22:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.53 on epoch=94
05/16/2022 10:22:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.50 on epoch=94
05/16/2022 10:22:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.39 on epoch=95
05/16/2022 10:22:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.48 on epoch=96
05/16/2022 10:22:37 - INFO - __main__ - Global step 1350 Train loss 3.49 Classification-F1 0.02346962346962347 on epoch=96
05/16/2022 10:22:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.32 on epoch=97
05/16/2022 10:22:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.33 on epoch=97
05/16/2022 10:22:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.40 on epoch=98
05/16/2022 10:22:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.29 on epoch=99
05/16/2022 10:22:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.38 on epoch=99
05/16/2022 10:22:46 - INFO - __main__ - Global step 1400 Train loss 3.34 Classification-F1 0.03506898157814432 on epoch=99
05/16/2022 10:22:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.33 on epoch=100
05/16/2022 10:22:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.25 on epoch=101
05/16/2022 10:22:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.36 on epoch=102
05/16/2022 10:22:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.43 on epoch=102
05/16/2022 10:22:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.34 on epoch=103
05/16/2022 10:22:55 - INFO - __main__ - Global step 1450 Train loss 3.34 Classification-F1 0.04311540536381989 on epoch=103
05/16/2022 10:22:55 - INFO - __main__ - Saving model with best Classification-F1: 0.037323322331073126 -> 0.04311540536381989 on epoch=103, global_step=1450
05/16/2022 10:22:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.30 on epoch=104
05/16/2022 10:22:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.32 on epoch=104
05/16/2022 10:22:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.23 on epoch=105
05/16/2022 10:23:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.34 on epoch=106
05/16/2022 10:23:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.28 on epoch=107
05/16/2022 10:23:03 - INFO - __main__ - Global step 1500 Train loss 3.30 Classification-F1 0.045524454841225026 on epoch=107
05/16/2022 10:23:03 - INFO - __main__ - Saving model with best Classification-F1: 0.04311540536381989 -> 0.045524454841225026 on epoch=107, global_step=1500
05/16/2022 10:23:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.49 on epoch=107
05/16/2022 10:23:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.27 on epoch=108
05/16/2022 10:23:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.18 on epoch=109
05/16/2022 10:23:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.44 on epoch=109
05/16/2022 10:23:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.22 on epoch=110
05/16/2022 10:23:12 - INFO - __main__ - Global step 1550 Train loss 3.32 Classification-F1 0.02108428737348598 on epoch=110
05/16/2022 10:23:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.31 on epoch=111
05/16/2022 10:23:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.29 on epoch=112
05/16/2022 10:23:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.17 on epoch=112
05/16/2022 10:23:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.23 on epoch=113
05/16/2022 10:23:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.34 on epoch=114
05/16/2022 10:23:21 - INFO - __main__ - Global step 1600 Train loss 3.27 Classification-F1 0.04195208393000998 on epoch=114
05/16/2022 10:23:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.41 on epoch=114
05/16/2022 10:23:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.29 on epoch=115
05/16/2022 10:23:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.17 on epoch=116
05/16/2022 10:23:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.18 on epoch=117
05/16/2022 10:23:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.22 on epoch=117
05/16/2022 10:23:30 - INFO - __main__ - Global step 1650 Train loss 3.25 Classification-F1 0.04641714468542176 on epoch=117
05/16/2022 10:23:30 - INFO - __main__ - Saving model with best Classification-F1: 0.045524454841225026 -> 0.04641714468542176 on epoch=117, global_step=1650
05/16/2022 10:23:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.32 on epoch=118
05/16/2022 10:23:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.05 on epoch=119
05/16/2022 10:23:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.14 on epoch=119
05/16/2022 10:23:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.12 on epoch=120
05/16/2022 10:23:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.16 on epoch=121
05/16/2022 10:23:39 - INFO - __main__ - Global step 1700 Train loss 3.16 Classification-F1 0.046672016342300705 on epoch=121
05/16/2022 10:23:39 - INFO - __main__ - Saving model with best Classification-F1: 0.04641714468542176 -> 0.046672016342300705 on epoch=121, global_step=1700
05/16/2022 10:23:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.19 on epoch=122
05/16/2022 10:23:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.31 on epoch=122
05/16/2022 10:23:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.03 on epoch=123
05/16/2022 10:23:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.98 on epoch=124
05/16/2022 10:23:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.14 on epoch=124
05/16/2022 10:23:47 - INFO - __main__ - Global step 1750 Train loss 3.13 Classification-F1 0.03506934996676299 on epoch=124
05/16/2022 10:23:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.16 on epoch=125
05/16/2022 10:23:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.99 on epoch=126
05/16/2022 10:23:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.06 on epoch=127
05/16/2022 10:23:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.17 on epoch=127
05/16/2022 10:23:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.89 on epoch=128
05/16/2022 10:23:56 - INFO - __main__ - Global step 1800 Train loss 3.05 Classification-F1 0.027360160365086476 on epoch=128
05/16/2022 10:23:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.07 on epoch=129
05/16/2022 10:23:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.20 on epoch=129
05/16/2022 10:24:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.09 on epoch=130
05/16/2022 10:24:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.11 on epoch=131
05/16/2022 10:24:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.98 on epoch=132
05/16/2022 10:24:05 - INFO - __main__ - Global step 1850 Train loss 3.09 Classification-F1 0.04830607760239014 on epoch=132
05/16/2022 10:24:05 - INFO - __main__ - Saving model with best Classification-F1: 0.046672016342300705 -> 0.04830607760239014 on epoch=132, global_step=1850
05/16/2022 10:24:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.02 on epoch=132
05/16/2022 10:24:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.03 on epoch=133
05/16/2022 10:24:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.13 on epoch=134
05/16/2022 10:24:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.11 on epoch=134
05/16/2022 10:24:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.11 on epoch=135
05/16/2022 10:24:14 - INFO - __main__ - Global step 1900 Train loss 3.08 Classification-F1 0.021404899988164278 on epoch=135
05/16/2022 10:24:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.93 on epoch=136
05/16/2022 10:24:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.97 on epoch=137
05/16/2022 10:24:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.01 on epoch=137
05/16/2022 10:24:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.10 on epoch=138
05/16/2022 10:24:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.01 on epoch=139
05/16/2022 10:24:23 - INFO - __main__ - Global step 1950 Train loss 3.00 Classification-F1 0.00927643784786642 on epoch=139
05/16/2022 10:24:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.10 on epoch=139
05/16/2022 10:24:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.06 on epoch=140
05/16/2022 10:24:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.02 on epoch=141
05/16/2022 10:24:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.02 on epoch=142
05/16/2022 10:24:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.90 on epoch=142
05/16/2022 10:24:31 - INFO - __main__ - Global step 2000 Train loss 3.02 Classification-F1 0.013223249235222525 on epoch=142
05/16/2022 10:24:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.05 on epoch=143
05/16/2022 10:24:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.84 on epoch=144
05/16/2022 10:24:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.10 on epoch=144
05/16/2022 10:24:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.98 on epoch=145
05/16/2022 10:24:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.00 on epoch=146
05/16/2022 10:24:40 - INFO - __main__ - Global step 2050 Train loss 2.99 Classification-F1 0.018456213654292886 on epoch=146
05/16/2022 10:24:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.96 on epoch=147
05/16/2022 10:24:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.12 on epoch=147
05/16/2022 10:24:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.91 on epoch=148
05/16/2022 10:24:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.87 on epoch=149
05/16/2022 10:24:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.00 on epoch=149
05/16/2022 10:24:49 - INFO - __main__ - Global step 2100 Train loss 2.97 Classification-F1 0.013583638583638582 on epoch=149
05/16/2022 10:24:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.82 on epoch=150
05/16/2022 10:24:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.02 on epoch=151
05/16/2022 10:24:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.90 on epoch=152
05/16/2022 10:24:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.82 on epoch=152
05/16/2022 10:24:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.92 on epoch=153
05/16/2022 10:24:58 - INFO - __main__ - Global step 2150 Train loss 2.90 Classification-F1 0.03500566893424036 on epoch=153
05/16/2022 10:24:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.05 on epoch=154
05/16/2022 10:25:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.88 on epoch=154
05/16/2022 10:25:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.95 on epoch=155
05/16/2022 10:25:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.84 on epoch=156
05/16/2022 10:25:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.03 on epoch=157
05/16/2022 10:25:06 - INFO - __main__ - Global step 2200 Train loss 2.95 Classification-F1 0.04679183385534213 on epoch=157
05/16/2022 10:25:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.94 on epoch=157
05/16/2022 10:25:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.95 on epoch=158
05/16/2022 10:25:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.78 on epoch=159
05/16/2022 10:25:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.96 on epoch=159
05/16/2022 10:25:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.90 on epoch=160
05/16/2022 10:25:15 - INFO - __main__ - Global step 2250 Train loss 2.91 Classification-F1 0.024481792717086837 on epoch=160
05/16/2022 10:25:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.71 on epoch=161
05/16/2022 10:25:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.85 on epoch=162
05/16/2022 10:25:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.97 on epoch=162
05/16/2022 10:25:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.76 on epoch=163
05/16/2022 10:25:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.83 on epoch=164
05/16/2022 10:25:24 - INFO - __main__ - Global step 2300 Train loss 2.82 Classification-F1 0.046359587077960285 on epoch=164
05/16/2022 10:25:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.03 on epoch=164
05/16/2022 10:25:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.96 on epoch=165
05/16/2022 10:25:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.92 on epoch=166
05/16/2022 10:25:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.94 on epoch=167
05/16/2022 10:25:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.90 on epoch=167
05/16/2022 10:25:33 - INFO - __main__ - Global step 2350 Train loss 2.95 Classification-F1 0.05851316603196303 on epoch=167
05/16/2022 10:25:33 - INFO - __main__ - Saving model with best Classification-F1: 0.04830607760239014 -> 0.05851316603196303 on epoch=167, global_step=2350
05/16/2022 10:25:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.88 on epoch=168
05/16/2022 10:25:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.93 on epoch=169
05/16/2022 10:25:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.85 on epoch=169
05/16/2022 10:25:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.85 on epoch=170
05/16/2022 10:25:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.75 on epoch=171
05/16/2022 10:25:41 - INFO - __main__ - Global step 2400 Train loss 2.85 Classification-F1 0.02644981437551097 on epoch=171
05/16/2022 10:25:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.71 on epoch=172
05/16/2022 10:25:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.03 on epoch=172
05/16/2022 10:25:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.91 on epoch=173
05/16/2022 10:25:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.79 on epoch=174
05/16/2022 10:25:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.00 on epoch=174
05/16/2022 10:25:50 - INFO - __main__ - Global step 2450 Train loss 2.89 Classification-F1 0.016828087167070217 on epoch=174
05/16/2022 10:25:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.81 on epoch=175
05/16/2022 10:25:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.95 on epoch=176
05/16/2022 10:25:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.87 on epoch=177
05/16/2022 10:25:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.99 on epoch=177
05/16/2022 10:25:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.76 on epoch=178
05/16/2022 10:25:59 - INFO - __main__ - Global step 2500 Train loss 2.88 Classification-F1 0.009685230024213076 on epoch=178
05/16/2022 10:26:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.84 on epoch=179
05/16/2022 10:26:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.97 on epoch=179
05/16/2022 10:26:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.81 on epoch=180
05/16/2022 10:26:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.91 on epoch=181
05/16/2022 10:26:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.85 on epoch=182
05/16/2022 10:26:08 - INFO - __main__ - Global step 2550 Train loss 2.87 Classification-F1 0.009316770186335404 on epoch=182
05/16/2022 10:26:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.70 on epoch=182
05/16/2022 10:26:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.70 on epoch=183
05/16/2022 10:26:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.91 on epoch=184
05/16/2022 10:26:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.75 on epoch=184
05/16/2022 10:26:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.73 on epoch=185
05/16/2022 10:26:17 - INFO - __main__ - Global step 2600 Train loss 2.76 Classification-F1 0.015652173913043476 on epoch=185
05/16/2022 10:26:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.88 on epoch=186
05/16/2022 10:26:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.77 on epoch=187
05/16/2022 10:26:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.88 on epoch=187
05/16/2022 10:26:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.89 on epoch=188
05/16/2022 10:26:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.74 on epoch=189
05/16/2022 10:26:26 - INFO - __main__ - Global step 2650 Train loss 2.83 Classification-F1 0.009644364074743823 on epoch=189
05/16/2022 10:26:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.77 on epoch=189
05/16/2022 10:26:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.71 on epoch=190
05/16/2022 10:26:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.81 on epoch=191
05/16/2022 10:26:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.83 on epoch=192
05/16/2022 10:26:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.82 on epoch=192
05/16/2022 10:26:35 - INFO - __main__ - Global step 2700 Train loss 2.79 Classification-F1 0.025164835164835166 on epoch=192
05/16/2022 10:26:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.91 on epoch=193
05/16/2022 10:26:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.78 on epoch=194
05/16/2022 10:26:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.89 on epoch=194
05/16/2022 10:26:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.68 on epoch=195
05/16/2022 10:26:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/16/2022 10:26:43 - INFO - __main__ - Global step 2750 Train loss 2.84 Classification-F1 0.043001885338208326 on epoch=196
05/16/2022 10:26:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.79 on epoch=197
05/16/2022 10:26:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.79 on epoch=197
05/16/2022 10:26:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.72 on epoch=198
05/16/2022 10:26:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.68 on epoch=199
05/16/2022 10:26:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.78 on epoch=199
05/16/2022 10:26:52 - INFO - __main__ - Global step 2800 Train loss 2.75 Classification-F1 0.0189098998887653 on epoch=199
05/16/2022 10:26:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.80 on epoch=200
05/16/2022 10:26:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.73 on epoch=201
05/16/2022 10:26:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.84 on epoch=202
05/16/2022 10:26:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.78 on epoch=202
05/16/2022 10:26:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.68 on epoch=203
05/16/2022 10:27:02 - INFO - __main__ - Global step 2850 Train loss 2.76 Classification-F1 0.031145617667356802 on epoch=203
05/16/2022 10:27:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.63 on epoch=204
05/16/2022 10:27:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.76 on epoch=204
05/16/2022 10:27:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.68 on epoch=205
05/16/2022 10:27:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.65 on epoch=206
05/16/2022 10:27:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.76 on epoch=207
05/16/2022 10:27:11 - INFO - __main__ - Global step 2900 Train loss 2.69 Classification-F1 0.04006211180124224 on epoch=207
05/16/2022 10:27:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.78 on epoch=207
05/16/2022 10:27:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.57 on epoch=208
05/16/2022 10:27:15 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.65 on epoch=209
05/16/2022 10:27:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.71 on epoch=209
05/16/2022 10:27:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.60 on epoch=210
05/16/2022 10:27:20 - INFO - __main__ - Global step 2950 Train loss 2.66 Classification-F1 0.009523809523809523 on epoch=210
05/16/2022 10:27:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.68 on epoch=211
05/16/2022 10:27:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.93 on epoch=212
05/16/2022 10:27:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.74 on epoch=212
05/16/2022 10:27:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.68 on epoch=213
05/16/2022 10:27:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.69 on epoch=214
05/16/2022 10:27:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:27:28 - INFO - __main__ - Printing 3 examples
05/16/2022 10:27:28 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 10:27:28 - INFO - __main__ - ['Company']
05/16/2022 10:27:28 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 10:27:28 - INFO - __main__ - ['Company']
05/16/2022 10:27:28 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 10:27:28 - INFO - __main__ - ['Company']
05/16/2022 10:27:28 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:27:28 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:27:28 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:27:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:27:28 - INFO - __main__ - Printing 3 examples
05/16/2022 10:27:28 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 10:27:28 - INFO - __main__ - ['Company']
05/16/2022 10:27:28 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 10:27:28 - INFO - __main__ - ['Company']
05/16/2022 10:27:28 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 10:27:28 - INFO - __main__ - ['Company']
05/16/2022 10:27:28 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:27:28 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:27:29 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:27:29 - INFO - __main__ - Global step 3000 Train loss 2.74 Classification-F1 0.02791094586230164 on epoch=214
05/16/2022 10:27:29 - INFO - __main__ - save last model!
05/16/2022 10:27:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 10:27:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 10:27:29 - INFO - __main__ - Printing 3 examples
05/16/2022 10:27:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 10:27:29 - INFO - __main__ - ['Animal']
05/16/2022 10:27:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 10:27:29 - INFO - __main__ - ['Animal']
05/16/2022 10:27:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 10:27:29 - INFO - __main__ - ['Village']
05/16/2022 10:27:29 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:27:31 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:27:34 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 10:27:34 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:27:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:27:35 - INFO - __main__ - Starting training!
05/16/2022 10:28:07 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/16/2022 10:28:07 - INFO - __main__ - Classification-F1 on test data: 0.0245
05/16/2022 10:28:08 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.05851316603196303, test_performance=0.02453195594723706
05/16/2022 10:28:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/16/2022 10:28:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:28:09 - INFO - __main__ - Printing 3 examples
05/16/2022 10:28:09 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/16/2022 10:28:09 - INFO - __main__ - ['Company']
05/16/2022 10:28:09 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/16/2022 10:28:09 - INFO - __main__ - ['Company']
05/16/2022 10:28:09 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/16/2022 10:28:09 - INFO - __main__ - ['Company']
05/16/2022 10:28:09 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:28:09 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:28:09 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:28:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:28:09 - INFO - __main__ - Printing 3 examples
05/16/2022 10:28:09 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/16/2022 10:28:09 - INFO - __main__ - ['Company']
05/16/2022 10:28:09 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/16/2022 10:28:09 - INFO - __main__ - ['Company']
05/16/2022 10:28:09 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/16/2022 10:28:09 - INFO - __main__ - ['Company']
05/16/2022 10:28:09 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:28:09 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:28:10 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:28:15 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:28:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:28:15 - INFO - __main__ - Starting training!
05/16/2022 10:28:20 - INFO - __main__ - Step 10 Global step 10 Train loss 7.33 on epoch=0
05/16/2022 10:28:22 - INFO - __main__ - Step 20 Global step 20 Train loss 7.59 on epoch=1
05/16/2022 10:28:23 - INFO - __main__ - Step 30 Global step 30 Train loss 7.56 on epoch=2
05/16/2022 10:28:24 - INFO - __main__ - Step 40 Global step 40 Train loss 7.00 on epoch=2
05/16/2022 10:28:26 - INFO - __main__ - Step 50 Global step 50 Train loss 7.35 on epoch=3
05/16/2022 10:28:35 - INFO - __main__ - Global step 50 Train loss 7.37 Classification-F1 0.0 on epoch=3
05/16/2022 10:28:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 10:28:36 - INFO - __main__ - Step 60 Global step 60 Train loss 7.08 on epoch=4
05/16/2022 10:28:37 - INFO - __main__ - Step 70 Global step 70 Train loss 7.19 on epoch=4
05/16/2022 10:28:39 - INFO - __main__ - Step 80 Global step 80 Train loss 6.90 on epoch=5
05/16/2022 10:28:40 - INFO - __main__ - Step 90 Global step 90 Train loss 6.99 on epoch=6
05/16/2022 10:28:42 - INFO - __main__ - Step 100 Global step 100 Train loss 6.99 on epoch=7
05/16/2022 10:29:19 - INFO - __main__ - Global step 100 Train loss 7.03 Classification-F1 0.0 on epoch=7
05/16/2022 10:29:21 - INFO - __main__ - Step 110 Global step 110 Train loss 6.62 on epoch=7
05/16/2022 10:29:22 - INFO - __main__ - Step 120 Global step 120 Train loss 6.95 on epoch=8
05/16/2022 10:29:23 - INFO - __main__ - Step 130 Global step 130 Train loss 6.75 on epoch=9
05/16/2022 10:29:25 - INFO - __main__ - Step 140 Global step 140 Train loss 6.94 on epoch=9
05/16/2022 10:29:26 - INFO - __main__ - Step 150 Global step 150 Train loss 6.47 on epoch=10
05/16/2022 10:30:14 - INFO - __main__ - Global step 150 Train loss 6.74 Classification-F1 0.0 on epoch=10
05/16/2022 10:30:15 - INFO - __main__ - Step 160 Global step 160 Train loss 6.85 on epoch=11
05/16/2022 10:30:16 - INFO - __main__ - Step 170 Global step 170 Train loss 6.77 on epoch=12
05/16/2022 10:30:18 - INFO - __main__ - Step 180 Global step 180 Train loss 6.38 on epoch=12
05/16/2022 10:30:19 - INFO - __main__ - Step 190 Global step 190 Train loss 6.73 on epoch=13
05/16/2022 10:30:20 - INFO - __main__ - Step 200 Global step 200 Train loss 6.39 on epoch=14
05/16/2022 10:31:31 - INFO - __main__ - Global step 200 Train loss 6.62 Classification-F1 0.0 on epoch=14
05/16/2022 10:31:33 - INFO - __main__ - Step 210 Global step 210 Train loss 6.63 on epoch=14
05/16/2022 10:31:34 - INFO - __main__ - Step 220 Global step 220 Train loss 6.22 on epoch=15
05/16/2022 10:31:35 - INFO - __main__ - Step 230 Global step 230 Train loss 6.54 on epoch=16
05/16/2022 10:31:37 - INFO - __main__ - Step 240 Global step 240 Train loss 6.39 on epoch=17
05/16/2022 10:31:38 - INFO - __main__ - Step 250 Global step 250 Train loss 6.21 on epoch=17
05/16/2022 10:32:54 - INFO - __main__ - Global step 250 Train loss 6.40 Classification-F1 0.0 on epoch=17
05/16/2022 10:32:55 - INFO - __main__ - Step 260 Global step 260 Train loss 6.45 on epoch=18
05/16/2022 10:32:56 - INFO - __main__ - Step 270 Global step 270 Train loss 6.16 on epoch=19
05/16/2022 10:32:58 - INFO - __main__ - Step 280 Global step 280 Train loss 6.35 on epoch=19
05/16/2022 10:32:59 - INFO - __main__ - Step 290 Global step 290 Train loss 6.01 on epoch=20
05/16/2022 10:33:00 - INFO - __main__ - Step 300 Global step 300 Train loss 6.29 on epoch=21
05/16/2022 10:34:19 - INFO - __main__ - Global step 300 Train loss 6.25 Classification-F1 0.0 on epoch=21
05/16/2022 10:34:20 - INFO - __main__ - Step 310 Global step 310 Train loss 6.12 on epoch=22
05/16/2022 10:34:21 - INFO - __main__ - Step 320 Global step 320 Train loss 5.87 on epoch=22
05/16/2022 10:34:23 - INFO - __main__ - Step 330 Global step 330 Train loss 6.08 on epoch=23
05/16/2022 10:34:24 - INFO - __main__ - Step 340 Global step 340 Train loss 5.95 on epoch=24
05/16/2022 10:34:25 - INFO - __main__ - Step 350 Global step 350 Train loss 6.02 on epoch=24
05/16/2022 10:35:44 - INFO - __main__ - Global step 350 Train loss 6.01 Classification-F1 0.0 on epoch=24
05/16/2022 10:35:45 - INFO - __main__ - Step 360 Global step 360 Train loss 5.83 on epoch=25
05/16/2022 10:35:46 - INFO - __main__ - Step 370 Global step 370 Train loss 5.92 on epoch=26
05/16/2022 10:35:48 - INFO - __main__ - Step 380 Global step 380 Train loss 5.99 on epoch=27
05/16/2022 10:35:49 - INFO - __main__ - Step 390 Global step 390 Train loss 5.64 on epoch=27
05/16/2022 10:35:51 - INFO - __main__ - Step 400 Global step 400 Train loss 5.93 on epoch=28
05/16/2022 10:37:08 - INFO - __main__ - Global step 400 Train loss 5.86 Classification-F1 0.0 on epoch=28
05/16/2022 10:37:09 - INFO - __main__ - Step 410 Global step 410 Train loss 5.83 on epoch=29
05/16/2022 10:37:11 - INFO - __main__ - Step 420 Global step 420 Train loss 5.87 on epoch=29
05/16/2022 10:37:12 - INFO - __main__ - Step 430 Global step 430 Train loss 5.66 on epoch=30
05/16/2022 10:37:14 - INFO - __main__ - Step 440 Global step 440 Train loss 5.63 on epoch=31
05/16/2022 10:37:15 - INFO - __main__ - Step 450 Global step 450 Train loss 5.68 on epoch=32
05/16/2022 10:37:54 - INFO - __main__ - Global step 450 Train loss 5.73 Classification-F1 0.0 on epoch=32
05/16/2022 10:37:55 - INFO - __main__ - Step 460 Global step 460 Train loss 5.39 on epoch=32
05/16/2022 10:37:57 - INFO - __main__ - Step 470 Global step 470 Train loss 5.63 on epoch=33
05/16/2022 10:37:58 - INFO - __main__ - Step 480 Global step 480 Train loss 5.35 on epoch=34
05/16/2022 10:37:59 - INFO - __main__ - Step 490 Global step 490 Train loss 5.71 on epoch=34
05/16/2022 10:38:01 - INFO - __main__ - Step 500 Global step 500 Train loss 5.46 on epoch=35
05/16/2022 10:38:37 - INFO - __main__ - Global step 500 Train loss 5.51 Classification-F1 0.0 on epoch=35
05/16/2022 10:38:38 - INFO - __main__ - Step 510 Global step 510 Train loss 5.52 on epoch=36
05/16/2022 10:38:40 - INFO - __main__ - Step 520 Global step 520 Train loss 5.52 on epoch=37
05/16/2022 10:38:41 - INFO - __main__ - Step 530 Global step 530 Train loss 5.27 on epoch=37
05/16/2022 10:38:43 - INFO - __main__ - Step 540 Global step 540 Train loss 5.44 on epoch=38
05/16/2022 10:38:44 - INFO - __main__ - Step 550 Global step 550 Train loss 5.28 on epoch=39
05/16/2022 10:39:13 - INFO - __main__ - Global step 550 Train loss 5.41 Classification-F1 0.0009775171065493648 on epoch=39
05/16/2022 10:39:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0009775171065493648 on epoch=39, global_step=550
05/16/2022 10:39:14 - INFO - __main__ - Step 560 Global step 560 Train loss 5.44 on epoch=39
05/16/2022 10:39:15 - INFO - __main__ - Step 570 Global step 570 Train loss 5.22 on epoch=40
05/16/2022 10:39:17 - INFO - __main__ - Step 580 Global step 580 Train loss 5.32 on epoch=41
05/16/2022 10:39:18 - INFO - __main__ - Step 590 Global step 590 Train loss 5.28 on epoch=42
05/16/2022 10:39:19 - INFO - __main__ - Step 600 Global step 600 Train loss 5.19 on epoch=42
05/16/2022 10:39:32 - INFO - __main__ - Global step 600 Train loss 5.29 Classification-F1 0.002197802197802198 on epoch=42
05/16/2022 10:39:32 - INFO - __main__ - Saving model with best Classification-F1: 0.0009775171065493648 -> 0.002197802197802198 on epoch=42, global_step=600
05/16/2022 10:39:33 - INFO - __main__ - Step 610 Global step 610 Train loss 5.42 on epoch=43
05/16/2022 10:39:35 - INFO - __main__ - Step 620 Global step 620 Train loss 5.12 on epoch=44
05/16/2022 10:39:36 - INFO - __main__ - Step 630 Global step 630 Train loss 5.42 on epoch=44
05/16/2022 10:39:38 - INFO - __main__ - Step 640 Global step 640 Train loss 4.96 on epoch=45
05/16/2022 10:39:39 - INFO - __main__ - Step 650 Global step 650 Train loss 5.20 on epoch=46
05/16/2022 10:39:42 - INFO - __main__ - Global step 650 Train loss 5.22 Classification-F1 0.006284038542103057 on epoch=46
05/16/2022 10:39:42 - INFO - __main__ - Saving model with best Classification-F1: 0.002197802197802198 -> 0.006284038542103057 on epoch=46, global_step=650
05/16/2022 10:39:43 - INFO - __main__ - Step 660 Global step 660 Train loss 5.14 on epoch=47
05/16/2022 10:39:45 - INFO - __main__ - Step 670 Global step 670 Train loss 4.91 on epoch=47
05/16/2022 10:39:46 - INFO - __main__ - Step 680 Global step 680 Train loss 5.13 on epoch=48
05/16/2022 10:39:48 - INFO - __main__ - Step 690 Global step 690 Train loss 5.03 on epoch=49
05/16/2022 10:39:49 - INFO - __main__ - Step 700 Global step 700 Train loss 5.19 on epoch=49
05/16/2022 10:39:52 - INFO - __main__ - Global step 700 Train loss 5.08 Classification-F1 0.00640614990390775 on epoch=49
05/16/2022 10:39:52 - INFO - __main__ - Saving model with best Classification-F1: 0.006284038542103057 -> 0.00640614990390775 on epoch=49, global_step=700
05/16/2022 10:39:53 - INFO - __main__ - Step 710 Global step 710 Train loss 4.89 on epoch=50
05/16/2022 10:39:55 - INFO - __main__ - Step 720 Global step 720 Train loss 5.08 on epoch=51
05/16/2022 10:39:56 - INFO - __main__ - Step 730 Global step 730 Train loss 4.90 on epoch=52
05/16/2022 10:39:58 - INFO - __main__ - Step 740 Global step 740 Train loss 4.75 on epoch=52
05/16/2022 10:39:59 - INFO - __main__ - Step 750 Global step 750 Train loss 4.87 on epoch=53
05/16/2022 10:40:02 - INFO - __main__ - Global step 750 Train loss 4.90 Classification-F1 0.007942417473318442 on epoch=53
05/16/2022 10:40:02 - INFO - __main__ - Saving model with best Classification-F1: 0.00640614990390775 -> 0.007942417473318442 on epoch=53, global_step=750
05/16/2022 10:40:03 - INFO - __main__ - Step 760 Global step 760 Train loss 4.79 on epoch=54
05/16/2022 10:40:04 - INFO - __main__ - Step 770 Global step 770 Train loss 4.99 on epoch=54
05/16/2022 10:40:05 - INFO - __main__ - Step 780 Global step 780 Train loss 4.65 on epoch=55
05/16/2022 10:40:07 - INFO - __main__ - Step 790 Global step 790 Train loss 4.84 on epoch=56
05/16/2022 10:40:08 - INFO - __main__ - Step 800 Global step 800 Train loss 4.80 on epoch=57
05/16/2022 10:40:11 - INFO - __main__ - Global step 800 Train loss 4.81 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 10:40:11 - INFO - __main__ - Saving model with best Classification-F1: 0.007942417473318442 -> 0.009523809523809523 on epoch=57, global_step=800
05/16/2022 10:40:12 - INFO - __main__ - Step 810 Global step 810 Train loss 4.72 on epoch=57
05/16/2022 10:40:14 - INFO - __main__ - Step 820 Global step 820 Train loss 4.89 on epoch=58
05/16/2022 10:40:15 - INFO - __main__ - Step 830 Global step 830 Train loss 4.71 on epoch=59
05/16/2022 10:40:16 - INFO - __main__ - Step 840 Global step 840 Train loss 4.85 on epoch=59
05/16/2022 10:40:18 - INFO - __main__ - Step 850 Global step 850 Train loss 4.76 on epoch=60
05/16/2022 10:40:20 - INFO - __main__ - Global step 850 Train loss 4.79 Classification-F1 0.009523809523809523 on epoch=60
05/16/2022 10:40:22 - INFO - __main__ - Step 860 Global step 860 Train loss 4.79 on epoch=61
05/16/2022 10:40:23 - INFO - __main__ - Step 870 Global step 870 Train loss 4.70 on epoch=62
05/16/2022 10:40:24 - INFO - __main__ - Step 880 Global step 880 Train loss 4.53 on epoch=62
05/16/2022 10:40:26 - INFO - __main__ - Step 890 Global step 890 Train loss 4.64 on epoch=63
05/16/2022 10:40:27 - INFO - __main__ - Step 900 Global step 900 Train loss 4.61 on epoch=64
05/16/2022 10:40:30 - INFO - __main__ - Global step 900 Train loss 4.66 Classification-F1 0.009523809523809523 on epoch=64
05/16/2022 10:40:31 - INFO - __main__ - Step 910 Global step 910 Train loss 4.88 on epoch=64
05/16/2022 10:40:32 - INFO - __main__ - Step 920 Global step 920 Train loss 4.49 on epoch=65
05/16/2022 10:40:34 - INFO - __main__ - Step 930 Global step 930 Train loss 4.62 on epoch=66
05/16/2022 10:40:35 - INFO - __main__ - Step 940 Global step 940 Train loss 4.53 on epoch=67
05/16/2022 10:40:37 - INFO - __main__ - Step 950 Global step 950 Train loss 4.44 on epoch=67
05/16/2022 10:40:39 - INFO - __main__ - Global step 950 Train loss 4.59 Classification-F1 0.009523809523809523 on epoch=67
05/16/2022 10:40:40 - INFO - __main__ - Step 960 Global step 960 Train loss 4.53 on epoch=68
05/16/2022 10:40:41 - INFO - __main__ - Step 970 Global step 970 Train loss 4.39 on epoch=69
05/16/2022 10:40:43 - INFO - __main__ - Step 980 Global step 980 Train loss 4.67 on epoch=69
05/16/2022 10:40:44 - INFO - __main__ - Step 990 Global step 990 Train loss 4.48 on epoch=70
05/16/2022 10:40:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.59 on epoch=71
05/16/2022 10:40:47 - INFO - __main__ - Global step 1000 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=71
05/16/2022 10:40:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.29 on epoch=72
05/16/2022 10:40:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.26 on epoch=72
05/16/2022 10:40:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.47 on epoch=73
05/16/2022 10:40:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.23 on epoch=74
05/16/2022 10:40:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.45 on epoch=74
05/16/2022 10:40:57 - INFO - __main__ - Global step 1050 Train loss 4.34 Classification-F1 0.009523809523809523 on epoch=74
05/16/2022 10:40:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.29 on epoch=75
05/16/2022 10:40:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.27 on epoch=76
05/16/2022 10:41:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.28 on epoch=77
05/16/2022 10:41:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.14 on epoch=77
05/16/2022 10:41:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.25 on epoch=78
05/16/2022 10:41:06 - INFO - __main__ - Global step 1100 Train loss 4.24 Classification-F1 0.009523809523809523 on epoch=78
05/16/2022 10:41:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.27 on epoch=79
05/16/2022 10:41:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.28 on epoch=79
05/16/2022 10:41:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.00 on epoch=80
05/16/2022 10:41:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.22 on epoch=81
05/16/2022 10:41:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.17 on epoch=82
05/16/2022 10:41:14 - INFO - __main__ - Global step 1150 Train loss 4.19 Classification-F1 0.009523809523809523 on epoch=82
05/16/2022 10:41:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.26 on epoch=82
05/16/2022 10:41:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.04 on epoch=83
05/16/2022 10:41:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.11 on epoch=84
05/16/2022 10:41:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.11 on epoch=84
05/16/2022 10:41:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.01 on epoch=85
05/16/2022 10:41:23 - INFO - __main__ - Global step 1200 Train loss 4.11 Classification-F1 0.01796701944376077 on epoch=85
05/16/2022 10:41:23 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01796701944376077 on epoch=85, global_step=1200
05/16/2022 10:41:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.15 on epoch=86
05/16/2022 10:41:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.02 on epoch=87
05/16/2022 10:41:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.99 on epoch=87
05/16/2022 10:41:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.98 on epoch=88
05/16/2022 10:41:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.02 on epoch=89
05/16/2022 10:41:31 - INFO - __main__ - Global step 1250 Train loss 4.03 Classification-F1 0.029210814760686883 on epoch=89
05/16/2022 10:41:31 - INFO - __main__ - Saving model with best Classification-F1: 0.01796701944376077 -> 0.029210814760686883 on epoch=89, global_step=1250
05/16/2022 10:41:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.15 on epoch=89
05/16/2022 10:41:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.88 on epoch=90
05/16/2022 10:41:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.09 on epoch=91
05/16/2022 10:41:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.06 on epoch=92
05/16/2022 10:41:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.93 on epoch=92
05/16/2022 10:41:40 - INFO - __main__ - Global step 1300 Train loss 4.02 Classification-F1 0.016618075801749267 on epoch=92
05/16/2022 10:41:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.89 on epoch=93
05/16/2022 10:41:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.00 on epoch=94
05/16/2022 10:41:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.94 on epoch=94
05/16/2022 10:41:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.83 on epoch=95
05/16/2022 10:41:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.91 on epoch=96
05/16/2022 10:41:49 - INFO - __main__ - Global step 1350 Train loss 3.91 Classification-F1 0.01724307022940238 on epoch=96
05/16/2022 10:41:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.73 on epoch=97
05/16/2022 10:41:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.89 on epoch=97
05/16/2022 10:41:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.79 on epoch=98
05/16/2022 10:41:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.83 on epoch=99
05/16/2022 10:41:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.83 on epoch=99
05/16/2022 10:41:58 - INFO - __main__ - Global step 1400 Train loss 3.81 Classification-F1 0.013267418768749737 on epoch=99
05/16/2022 10:41:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.67 on epoch=100
05/16/2022 10:42:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.77 on epoch=101
05/16/2022 10:42:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.65 on epoch=102
05/16/2022 10:42:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.74 on epoch=102
05/16/2022 10:42:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.70 on epoch=103
05/16/2022 10:42:07 - INFO - __main__ - Global step 1450 Train loss 3.71 Classification-F1 0.009563658099222952 on epoch=103
05/16/2022 10:42:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.54 on epoch=104
05/16/2022 10:42:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.82 on epoch=104
05/16/2022 10:42:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.61 on epoch=105
05/16/2022 10:42:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.56 on epoch=106
05/16/2022 10:42:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.48 on epoch=107
05/16/2022 10:42:16 - INFO - __main__ - Global step 1500 Train loss 3.60 Classification-F1 0.009644364074743823 on epoch=107
05/16/2022 10:42:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.61 on epoch=107
05/16/2022 10:42:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.64 on epoch=108
05/16/2022 10:42:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.50 on epoch=109
05/16/2022 10:42:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.67 on epoch=109
05/16/2022 10:42:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.50 on epoch=110
05/16/2022 10:42:24 - INFO - __main__ - Global step 1550 Train loss 3.58 Classification-F1 0.009563658099222952 on epoch=110
05/16/2022 10:42:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.41 on epoch=111
05/16/2022 10:42:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.56 on epoch=112
05/16/2022 10:42:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.54 on epoch=112
05/16/2022 10:42:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.56 on epoch=113
05/16/2022 10:42:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.64 on epoch=114
05/16/2022 10:42:33 - INFO - __main__ - Global step 1600 Train loss 3.54 Classification-F1 0.017163161067225024 on epoch=114
05/16/2022 10:42:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.66 on epoch=114
05/16/2022 10:42:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.52 on epoch=115
05/16/2022 10:42:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.59 on epoch=116
05/16/2022 10:42:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.62 on epoch=117
05/16/2022 10:42:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.57 on epoch=117
05/16/2022 10:42:42 - INFO - __main__ - Global step 1650 Train loss 3.59 Classification-F1 0.024042555098455716 on epoch=117
05/16/2022 10:42:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.45 on epoch=118
05/16/2022 10:42:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.40 on epoch=119
05/16/2022 10:42:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.51 on epoch=119
05/16/2022 10:42:47 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.50 on epoch=120
05/16/2022 10:42:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.52 on epoch=121
05/16/2022 10:42:51 - INFO - __main__ - Global step 1700 Train loss 3.48 Classification-F1 0.024675324675324677 on epoch=121
05/16/2022 10:42:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.47 on epoch=122
05/16/2022 10:42:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.40 on epoch=122
05/16/2022 10:42:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.27 on epoch=123
05/16/2022 10:42:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.38 on epoch=124
05/16/2022 10:42:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.37 on epoch=124
05/16/2022 10:42:59 - INFO - __main__ - Global step 1750 Train loss 3.38 Classification-F1 0.03539319501264533 on epoch=124
05/16/2022 10:42:59 - INFO - __main__ - Saving model with best Classification-F1: 0.029210814760686883 -> 0.03539319501264533 on epoch=124, global_step=1750
05/16/2022 10:43:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.42 on epoch=125
05/16/2022 10:43:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.49 on epoch=126
05/16/2022 10:43:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.42 on epoch=127
05/16/2022 10:43:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.35 on epoch=127
05/16/2022 10:43:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.33 on epoch=128
05/16/2022 10:43:09 - INFO - __main__ - Global step 1800 Train loss 3.40 Classification-F1 0.020719040684715744 on epoch=128
05/16/2022 10:43:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.36 on epoch=129
05/16/2022 10:43:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.36 on epoch=129
05/16/2022 10:43:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.25 on epoch=130
05/16/2022 10:43:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.30 on epoch=131
05/16/2022 10:43:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.21 on epoch=132
05/16/2022 10:43:17 - INFO - __main__ - Global step 1850 Train loss 3.30 Classification-F1 0.04694632765972536 on epoch=132
05/16/2022 10:43:17 - INFO - __main__ - Saving model with best Classification-F1: 0.03539319501264533 -> 0.04694632765972536 on epoch=132, global_step=1850
05/16/2022 10:43:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.40 on epoch=132
05/16/2022 10:43:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.18 on epoch=133
05/16/2022 10:43:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.25 on epoch=134
05/16/2022 10:43:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.36 on epoch=134
05/16/2022 10:43:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.34 on epoch=135
05/16/2022 10:43:26 - INFO - __main__ - Global step 1900 Train loss 3.31 Classification-F1 0.027522268251751532 on epoch=135
05/16/2022 10:43:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.30 on epoch=136
05/16/2022 10:43:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.26 on epoch=137
05/16/2022 10:43:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.19 on epoch=137
05/16/2022 10:43:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.17 on epoch=138
05/16/2022 10:43:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.26 on epoch=139
05/16/2022 10:43:35 - INFO - __main__ - Global step 1950 Train loss 3.24 Classification-F1 0.00976800976800977 on epoch=139
05/16/2022 10:43:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.25 on epoch=139
05/16/2022 10:43:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.16 on epoch=140
05/16/2022 10:43:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.09 on epoch=141
05/16/2022 10:43:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.21 on epoch=142
05/16/2022 10:43:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.30 on epoch=142
05/16/2022 10:43:44 - INFO - __main__ - Global step 2000 Train loss 3.20 Classification-F1 0.010342598577892695 on epoch=142
05/16/2022 10:43:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.07 on epoch=143
05/16/2022 10:43:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.15 on epoch=144
05/16/2022 10:43:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.15 on epoch=144
05/16/2022 10:43:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.35 on epoch=145
05/16/2022 10:43:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.23 on epoch=146
05/16/2022 10:43:53 - INFO - __main__ - Global step 2050 Train loss 3.19 Classification-F1 0.04818032941072327 on epoch=146
05/16/2022 10:43:53 - INFO - __main__ - Saving model with best Classification-F1: 0.04694632765972536 -> 0.04818032941072327 on epoch=146, global_step=2050
05/16/2022 10:43:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.17 on epoch=147
05/16/2022 10:43:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.13 on epoch=147
05/16/2022 10:43:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.14 on epoch=148
05/16/2022 10:43:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.07 on epoch=149
05/16/2022 10:44:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.14 on epoch=149
05/16/2022 10:44:01 - INFO - __main__ - Global step 2100 Train loss 3.13 Classification-F1 0.0552718062260047 on epoch=149
05/16/2022 10:44:01 - INFO - __main__ - Saving model with best Classification-F1: 0.04818032941072327 -> 0.0552718062260047 on epoch=149, global_step=2100
05/16/2022 10:44:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.06 on epoch=150
05/16/2022 10:44:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.12 on epoch=151
05/16/2022 10:44:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.16 on epoch=152
05/16/2022 10:44:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.09 on epoch=152
05/16/2022 10:44:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.12 on epoch=153
05/16/2022 10:44:10 - INFO - __main__ - Global step 2150 Train loss 3.11 Classification-F1 0.03472338073035329 on epoch=153
05/16/2022 10:44:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.16 on epoch=154
05/16/2022 10:44:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.11 on epoch=154
05/16/2022 10:44:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.12 on epoch=155
05/16/2022 10:44:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.07 on epoch=156
05/16/2022 10:44:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.06 on epoch=157
05/16/2022 10:44:19 - INFO - __main__ - Global step 2200 Train loss 3.10 Classification-F1 0.022954485661667984 on epoch=157
05/16/2022 10:44:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.18 on epoch=157
05/16/2022 10:44:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.16 on epoch=158
05/16/2022 10:44:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.99 on epoch=159
05/16/2022 10:44:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.12 on epoch=159
05/16/2022 10:44:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.99 on epoch=160
05/16/2022 10:44:28 - INFO - __main__ - Global step 2250 Train loss 3.09 Classification-F1 0.02650290885585003 on epoch=160
05/16/2022 10:44:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.05 on epoch=161
05/16/2022 10:44:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.07 on epoch=162
05/16/2022 10:44:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.02 on epoch=162
05/16/2022 10:44:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.99 on epoch=163
05/16/2022 10:44:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.96 on epoch=164
05/16/2022 10:44:37 - INFO - __main__ - Global step 2300 Train loss 3.02 Classification-F1 0.020205600850762142 on epoch=164
05/16/2022 10:44:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.11 on epoch=164
05/16/2022 10:44:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.05 on epoch=165
05/16/2022 10:44:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.94 on epoch=166
05/16/2022 10:44:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.00 on epoch=167
05/16/2022 10:44:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.10 on epoch=167
05/16/2022 10:44:46 - INFO - __main__ - Global step 2350 Train loss 3.04 Classification-F1 0.019029314860184166 on epoch=167
05/16/2022 10:44:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.06 on epoch=168
05/16/2022 10:44:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.89 on epoch=169
05/16/2022 10:44:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.84 on epoch=169
05/16/2022 10:44:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.92 on epoch=170
05/16/2022 10:44:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 3.15 on epoch=171
05/16/2022 10:44:54 - INFO - __main__ - Global step 2400 Train loss 2.97 Classification-F1 0.022183117367887806 on epoch=171
05/16/2022 10:44:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.97 on epoch=172
05/16/2022 10:44:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.94 on epoch=172
05/16/2022 10:44:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.26 on epoch=173
05/16/2022 10:45:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.89 on epoch=174
05/16/2022 10:45:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.05 on epoch=174
05/16/2022 10:45:03 - INFO - __main__ - Global step 2450 Train loss 3.02 Classification-F1 0.014139581758629378 on epoch=174
05/16/2022 10:45:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.84 on epoch=175
05/16/2022 10:45:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.87 on epoch=176
05/16/2022 10:45:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.97 on epoch=177
05/16/2022 10:45:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.92 on epoch=177
05/16/2022 10:45:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.87 on epoch=178
05/16/2022 10:45:12 - INFO - __main__ - Global step 2500 Train loss 2.89 Classification-F1 0.01773445696686635 on epoch=178
05/16/2022 10:45:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.89 on epoch=179
05/16/2022 10:45:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.91 on epoch=179
05/16/2022 10:45:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.87 on epoch=180
05/16/2022 10:45:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.04 on epoch=181
05/16/2022 10:45:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.00 on epoch=182
05/16/2022 10:45:21 - INFO - __main__ - Global step 2550 Train loss 2.94 Classification-F1 0.025985125985125986 on epoch=182
05/16/2022 10:45:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.91 on epoch=182
05/16/2022 10:45:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.78 on epoch=183
05/16/2022 10:45:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.84 on epoch=184
05/16/2022 10:45:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.87 on epoch=184
05/16/2022 10:45:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.88 on epoch=185
05/16/2022 10:45:30 - INFO - __main__ - Global step 2600 Train loss 2.86 Classification-F1 0.0467401141743247 on epoch=185
05/16/2022 10:45:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.88 on epoch=186
05/16/2022 10:45:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.95 on epoch=187
05/16/2022 10:45:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 3.02 on epoch=187
05/16/2022 10:45:35 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.81 on epoch=188
05/16/2022 10:45:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.67 on epoch=189
05/16/2022 10:45:39 - INFO - __main__ - Global step 2650 Train loss 2.86 Classification-F1 0.02337600058231268 on epoch=189
05/16/2022 10:45:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.94 on epoch=189
05/16/2022 10:45:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.60 on epoch=190
05/16/2022 10:45:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.82 on epoch=191
05/16/2022 10:45:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.90 on epoch=192
05/16/2022 10:45:45 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.79 on epoch=192
05/16/2022 10:45:47 - INFO - __main__ - Global step 2700 Train loss 2.81 Classification-F1 0.03251112879292918 on epoch=192
05/16/2022 10:45:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.73 on epoch=193
05/16/2022 10:45:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.83 on epoch=194
05/16/2022 10:45:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.84 on epoch=194
05/16/2022 10:45:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.72 on epoch=195
05/16/2022 10:45:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.63 on epoch=196
05/16/2022 10:45:56 - INFO - __main__ - Global step 2750 Train loss 2.75 Classification-F1 0.019543650793650797 on epoch=196
05/16/2022 10:45:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.72 on epoch=197
05/16/2022 10:45:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.77 on epoch=197
05/16/2022 10:46:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.77 on epoch=198
05/16/2022 10:46:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.64 on epoch=199
05/16/2022 10:46:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.64 on epoch=199
05/16/2022 10:46:05 - INFO - __main__ - Global step 2800 Train loss 2.71 Classification-F1 0.016314435507505942 on epoch=199
05/16/2022 10:46:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.67 on epoch=200
05/16/2022 10:46:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.72 on epoch=201
05/16/2022 10:46:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.75 on epoch=202
05/16/2022 10:46:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.71 on epoch=202
05/16/2022 10:46:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.70 on epoch=203
05/16/2022 10:46:14 - INFO - __main__ - Global step 2850 Train loss 2.71 Classification-F1 0.04089140672991604 on epoch=203
05/16/2022 10:46:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.70 on epoch=204
05/16/2022 10:46:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.75 on epoch=204
05/16/2022 10:46:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.79 on epoch=205
05/16/2022 10:46:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.69 on epoch=206
05/16/2022 10:46:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.74 on epoch=207
05/16/2022 10:46:24 - INFO - __main__ - Global step 2900 Train loss 2.74 Classification-F1 0.01972558514931396 on epoch=207
05/16/2022 10:46:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.79 on epoch=207
05/16/2022 10:46:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.73 on epoch=208
05/16/2022 10:46:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.68 on epoch=209
05/16/2022 10:46:29 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.86 on epoch=209
05/16/2022 10:46:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.58 on epoch=210
05/16/2022 10:46:33 - INFO - __main__ - Global step 2950 Train loss 2.73 Classification-F1 0.040890652557319225 on epoch=210
05/16/2022 10:46:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.81 on epoch=211
05/16/2022 10:46:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.60 on epoch=212
05/16/2022 10:46:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.63 on epoch=212
05/16/2022 10:46:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.69 on epoch=213
05/16/2022 10:46:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.75 on epoch=214
05/16/2022 10:46:41 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:46:41 - INFO - __main__ - Printing 3 examples
05/16/2022 10:46:41 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 10:46:41 - INFO - __main__ - ['Film']
05/16/2022 10:46:41 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 10:46:41 - INFO - __main__ - ['Film']
05/16/2022 10:46:41 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 10:46:41 - INFO - __main__ - ['Film']
05/16/2022 10:46:41 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:46:41 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:46:41 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:46:41 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:46:41 - INFO - __main__ - Printing 3 examples
05/16/2022 10:46:41 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 10:46:41 - INFO - __main__ - ['Film']
05/16/2022 10:46:41 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 10:46:41 - INFO - __main__ - ['Film']
05/16/2022 10:46:41 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 10:46:41 - INFO - __main__ - ['Film']
05/16/2022 10:46:41 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:46:41 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:46:42 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:46:42 - INFO - __main__ - Global step 3000 Train loss 2.70 Classification-F1 0.01610070257611241 on epoch=214
05/16/2022 10:46:42 - INFO - __main__ - save last model!
05/16/2022 10:46:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 10:46:42 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 10:46:42 - INFO - __main__ - Printing 3 examples
05/16/2022 10:46:42 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 10:46:42 - INFO - __main__ - ['Animal']
05/16/2022 10:46:42 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 10:46:42 - INFO - __main__ - ['Animal']
05/16/2022 10:46:42 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 10:46:42 - INFO - __main__ - ['Village']
05/16/2022 10:46:42 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:46:44 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:46:47 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:46:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:46:48 - INFO - __main__ - Starting training!
05/16/2022 10:46:49 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 10:47:27 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/16/2022 10:47:27 - INFO - __main__ - Classification-F1 on test data: 0.0182
05/16/2022 10:47:28 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.0552718062260047, test_performance=0.018247439487849383
05/16/2022 10:47:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/16/2022 10:47:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:47:29 - INFO - __main__ - Printing 3 examples
05/16/2022 10:47:29 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 10:47:29 - INFO - __main__ - ['Film']
05/16/2022 10:47:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 10:47:29 - INFO - __main__ - ['Film']
05/16/2022 10:47:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 10:47:29 - INFO - __main__ - ['Film']
05/16/2022 10:47:29 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:47:29 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:47:29 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:47:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:47:29 - INFO - __main__ - Printing 3 examples
05/16/2022 10:47:29 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 10:47:29 - INFO - __main__ - ['Film']
05/16/2022 10:47:29 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 10:47:29 - INFO - __main__ - ['Film']
05/16/2022 10:47:29 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 10:47:29 - INFO - __main__ - ['Film']
05/16/2022 10:47:29 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:47:29 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:47:29 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:47:36 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:47:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:47:36 - INFO - __main__ - Starting training!
05/16/2022 10:47:38 - INFO - __main__ - Step 10 Global step 10 Train loss 7.39 on epoch=0
05/16/2022 10:47:39 - INFO - __main__ - Step 20 Global step 20 Train loss 7.49 on epoch=1
05/16/2022 10:47:40 - INFO - __main__ - Step 30 Global step 30 Train loss 6.92 on epoch=2
05/16/2022 10:47:42 - INFO - __main__ - Step 40 Global step 40 Train loss 7.17 on epoch=2
05/16/2022 10:47:43 - INFO - __main__ - Step 50 Global step 50 Train loss 6.78 on epoch=3
05/16/2022 10:48:38 - INFO - __main__ - Global step 50 Train loss 7.15 Classification-F1 0.0 on epoch=3
05/16/2022 10:48:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 10:48:39 - INFO - __main__ - Step 60 Global step 60 Train loss 6.74 on epoch=4
05/16/2022 10:48:41 - INFO - __main__ - Step 70 Global step 70 Train loss 6.64 on epoch=4
05/16/2022 10:48:42 - INFO - __main__ - Step 80 Global step 80 Train loss 6.55 on epoch=5
05/16/2022 10:48:43 - INFO - __main__ - Step 90 Global step 90 Train loss 6.30 on epoch=6
05/16/2022 10:48:45 - INFO - __main__ - Step 100 Global step 100 Train loss 6.15 on epoch=7
05/16/2022 10:49:45 - INFO - __main__ - Global step 100 Train loss 6.48 Classification-F1 0.0 on epoch=7
05/16/2022 10:49:46 - INFO - __main__ - Step 110 Global step 110 Train loss 6.19 on epoch=7
05/16/2022 10:49:47 - INFO - __main__ - Step 120 Global step 120 Train loss 5.97 on epoch=8
05/16/2022 10:49:49 - INFO - __main__ - Step 130 Global step 130 Train loss 5.77 on epoch=9
05/16/2022 10:49:50 - INFO - __main__ - Step 140 Global step 140 Train loss 5.93 on epoch=9
05/16/2022 10:49:51 - INFO - __main__ - Step 150 Global step 150 Train loss 5.76 on epoch=10
05/16/2022 10:50:20 - INFO - __main__ - Global step 150 Train loss 5.92 Classification-F1 0.0 on epoch=10
05/16/2022 10:50:22 - INFO - __main__ - Step 160 Global step 160 Train loss 5.74 on epoch=11
05/16/2022 10:50:23 - INFO - __main__ - Step 170 Global step 170 Train loss 5.66 on epoch=12
05/16/2022 10:50:24 - INFO - __main__ - Step 180 Global step 180 Train loss 5.62 on epoch=12
05/16/2022 10:50:26 - INFO - __main__ - Step 190 Global step 190 Train loss 5.42 on epoch=13
05/16/2022 10:50:27 - INFO - __main__ - Step 200 Global step 200 Train loss 5.39 on epoch=14
05/16/2022 10:50:38 - INFO - __main__ - Global step 200 Train loss 5.57 Classification-F1 0.0 on epoch=14
05/16/2022 10:50:39 - INFO - __main__ - Step 210 Global step 210 Train loss 5.44 on epoch=14
05/16/2022 10:50:40 - INFO - __main__ - Step 220 Global step 220 Train loss 5.49 on epoch=15
05/16/2022 10:50:42 - INFO - __main__ - Step 230 Global step 230 Train loss 5.27 on epoch=16
05/16/2022 10:50:43 - INFO - __main__ - Step 240 Global step 240 Train loss 5.17 on epoch=17
05/16/2022 10:50:44 - INFO - __main__ - Step 250 Global step 250 Train loss 5.17 on epoch=17
05/16/2022 10:50:53 - INFO - __main__ - Global step 250 Train loss 5.31 Classification-F1 0.005305039787798408 on epoch=17
05/16/2022 10:50:53 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005305039787798408 on epoch=17, global_step=250
05/16/2022 10:50:54 - INFO - __main__ - Step 260 Global step 260 Train loss 5.07 on epoch=18
05/16/2022 10:50:56 - INFO - __main__ - Step 270 Global step 270 Train loss 5.07 on epoch=19
05/16/2022 10:50:57 - INFO - __main__ - Step 280 Global step 280 Train loss 5.25 on epoch=19
05/16/2022 10:50:59 - INFO - __main__ - Step 290 Global step 290 Train loss 5.09 on epoch=20
05/16/2022 10:51:00 - INFO - __main__ - Step 300 Global step 300 Train loss 4.97 on epoch=21
05/16/2022 10:51:03 - INFO - __main__ - Global step 300 Train loss 5.09 Classification-F1 0.008771929824561405 on epoch=21
05/16/2022 10:51:03 - INFO - __main__ - Saving model with best Classification-F1: 0.005305039787798408 -> 0.008771929824561405 on epoch=21, global_step=300
05/16/2022 10:51:05 - INFO - __main__ - Step 310 Global step 310 Train loss 4.95 on epoch=22
05/16/2022 10:51:06 - INFO - __main__ - Step 320 Global step 320 Train loss 4.88 on epoch=22
05/16/2022 10:51:08 - INFO - __main__ - Step 330 Global step 330 Train loss 4.92 on epoch=23
05/16/2022 10:51:09 - INFO - __main__ - Step 340 Global step 340 Train loss 4.75 on epoch=24
05/16/2022 10:51:11 - INFO - __main__ - Step 350 Global step 350 Train loss 4.81 on epoch=24
05/16/2022 10:51:14 - INFO - __main__ - Global step 350 Train loss 4.86 Classification-F1 0.008963585434173669 on epoch=24
05/16/2022 10:51:14 - INFO - __main__ - Saving model with best Classification-F1: 0.008771929824561405 -> 0.008963585434173669 on epoch=24, global_step=350
05/16/2022 10:51:15 - INFO - __main__ - Step 360 Global step 360 Train loss 4.75 on epoch=25
05/16/2022 10:51:16 - INFO - __main__ - Step 370 Global step 370 Train loss 4.73 on epoch=26
05/16/2022 10:51:18 - INFO - __main__ - Step 380 Global step 380 Train loss 4.69 on epoch=27
05/16/2022 10:51:19 - INFO - __main__ - Step 390 Global step 390 Train loss 4.58 on epoch=27
05/16/2022 10:51:20 - INFO - __main__ - Step 400 Global step 400 Train loss 4.59 on epoch=28
05/16/2022 10:51:23 - INFO - __main__ - Global step 400 Train loss 4.67 Classification-F1 0.006508135168961201 on epoch=28
05/16/2022 10:51:24 - INFO - __main__ - Step 410 Global step 410 Train loss 4.56 on epoch=29
05/16/2022 10:51:26 - INFO - __main__ - Step 420 Global step 420 Train loss 4.61 on epoch=29
05/16/2022 10:51:27 - INFO - __main__ - Step 430 Global step 430 Train loss 4.52 on epoch=30
05/16/2022 10:51:29 - INFO - __main__ - Step 440 Global step 440 Train loss 4.35 on epoch=31
05/16/2022 10:51:30 - INFO - __main__ - Step 450 Global step 450 Train loss 4.37 on epoch=32
05/16/2022 10:51:32 - INFO - __main__ - Global step 450 Train loss 4.48 Classification-F1 0.009523809523809523 on epoch=32
05/16/2022 10:51:32 - INFO - __main__ - Saving model with best Classification-F1: 0.008963585434173669 -> 0.009523809523809523 on epoch=32, global_step=450
05/16/2022 10:51:34 - INFO - __main__ - Step 460 Global step 460 Train loss 4.33 on epoch=32
05/16/2022 10:51:35 - INFO - __main__ - Step 470 Global step 470 Train loss 4.27 on epoch=33
05/16/2022 10:51:36 - INFO - __main__ - Step 480 Global step 480 Train loss 4.20 on epoch=34
05/16/2022 10:51:38 - INFO - __main__ - Step 490 Global step 490 Train loss 4.34 on epoch=34
05/16/2022 10:51:39 - INFO - __main__ - Step 500 Global step 500 Train loss 4.23 on epoch=35
05/16/2022 10:51:42 - INFO - __main__ - Global step 500 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=35
05/16/2022 10:51:43 - INFO - __main__ - Step 510 Global step 510 Train loss 4.02 on epoch=36
05/16/2022 10:51:44 - INFO - __main__ - Step 520 Global step 520 Train loss 4.16 on epoch=37
05/16/2022 10:51:46 - INFO - __main__ - Step 530 Global step 530 Train loss 3.99 on epoch=37
05/16/2022 10:51:47 - INFO - __main__ - Step 540 Global step 540 Train loss 4.02 on epoch=38
05/16/2022 10:51:48 - INFO - __main__ - Step 550 Global step 550 Train loss 3.70 on epoch=39
05/16/2022 10:51:50 - INFO - __main__ - Global step 550 Train loss 3.98 Classification-F1 0.009523809523809523 on epoch=39
05/16/2022 10:51:51 - INFO - __main__ - Step 560 Global step 560 Train loss 3.90 on epoch=39
05/16/2022 10:51:53 - INFO - __main__ - Step 570 Global step 570 Train loss 3.85 on epoch=40
05/16/2022 10:51:54 - INFO - __main__ - Step 580 Global step 580 Train loss 3.55 on epoch=41
05/16/2022 10:51:55 - INFO - __main__ - Step 590 Global step 590 Train loss 3.77 on epoch=42
05/16/2022 10:51:57 - INFO - __main__ - Step 600 Global step 600 Train loss 3.60 on epoch=42
05/16/2022 10:51:59 - INFO - __main__ - Global step 600 Train loss 3.74 Classification-F1 0.024729891956782712 on epoch=42
05/16/2022 10:51:59 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024729891956782712 on epoch=42, global_step=600
05/16/2022 10:52:00 - INFO - __main__ - Step 610 Global step 610 Train loss 3.61 on epoch=43
05/16/2022 10:52:01 - INFO - __main__ - Step 620 Global step 620 Train loss 3.52 on epoch=44
05/16/2022 10:52:03 - INFO - __main__ - Step 630 Global step 630 Train loss 3.61 on epoch=44
05/16/2022 10:52:04 - INFO - __main__ - Step 640 Global step 640 Train loss 3.70 on epoch=45
05/16/2022 10:52:06 - INFO - __main__ - Step 650 Global step 650 Train loss 3.41 on epoch=46
05/16/2022 10:52:08 - INFO - __main__ - Global step 650 Train loss 3.57 Classification-F1 0.04756188189561539 on epoch=46
05/16/2022 10:52:08 - INFO - __main__ - Saving model with best Classification-F1: 0.024729891956782712 -> 0.04756188189561539 on epoch=46, global_step=650
05/16/2022 10:52:09 - INFO - __main__ - Step 660 Global step 660 Train loss 3.54 on epoch=47
05/16/2022 10:52:11 - INFO - __main__ - Step 670 Global step 670 Train loss 3.50 on epoch=47
05/16/2022 10:52:12 - INFO - __main__ - Step 680 Global step 680 Train loss 3.51 on epoch=48
05/16/2022 10:52:13 - INFO - __main__ - Step 690 Global step 690 Train loss 3.37 on epoch=49
05/16/2022 10:52:15 - INFO - __main__ - Step 700 Global step 700 Train loss 3.30 on epoch=49
05/16/2022 10:52:17 - INFO - __main__ - Global step 700 Train loss 3.44 Classification-F1 0.022575037920306462 on epoch=49
05/16/2022 10:52:18 - INFO - __main__ - Step 710 Global step 710 Train loss 3.44 on epoch=50
05/16/2022 10:52:19 - INFO - __main__ - Step 720 Global step 720 Train loss 3.18 on epoch=51
05/16/2022 10:52:21 - INFO - __main__ - Step 730 Global step 730 Train loss 3.42 on epoch=52
05/16/2022 10:52:22 - INFO - __main__ - Step 740 Global step 740 Train loss 3.30 on epoch=52
05/16/2022 10:52:23 - INFO - __main__ - Step 750 Global step 750 Train loss 3.18 on epoch=53
05/16/2022 10:52:25 - INFO - __main__ - Global step 750 Train loss 3.30 Classification-F1 0.01392136603404209 on epoch=53
05/16/2022 10:52:27 - INFO - __main__ - Step 760 Global step 760 Train loss 3.13 on epoch=54
05/16/2022 10:52:28 - INFO - __main__ - Step 770 Global step 770 Train loss 3.16 on epoch=54
05/16/2022 10:52:30 - INFO - __main__ - Step 780 Global step 780 Train loss 3.22 on epoch=55
05/16/2022 10:52:31 - INFO - __main__ - Step 790 Global step 790 Train loss 3.00 on epoch=56
05/16/2022 10:52:32 - INFO - __main__ - Step 800 Global step 800 Train loss 3.11 on epoch=57
05/16/2022 10:52:34 - INFO - __main__ - Global step 800 Train loss 3.12 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 10:52:36 - INFO - __main__ - Step 810 Global step 810 Train loss 3.14 on epoch=57
05/16/2022 10:52:37 - INFO - __main__ - Step 820 Global step 820 Train loss 3.12 on epoch=58
05/16/2022 10:52:38 - INFO - __main__ - Step 830 Global step 830 Train loss 3.00 on epoch=59
05/16/2022 10:52:40 - INFO - __main__ - Step 840 Global step 840 Train loss 3.10 on epoch=59
05/16/2022 10:52:41 - INFO - __main__ - Step 850 Global step 850 Train loss 3.22 on epoch=60
05/16/2022 10:52:43 - INFO - __main__ - Global step 850 Train loss 3.12 Classification-F1 0.04542263713996236 on epoch=60
05/16/2022 10:52:44 - INFO - __main__ - Step 860 Global step 860 Train loss 2.91 on epoch=61
05/16/2022 10:52:46 - INFO - __main__ - Step 870 Global step 870 Train loss 3.11 on epoch=62
05/16/2022 10:52:47 - INFO - __main__ - Step 880 Global step 880 Train loss 2.95 on epoch=62
05/16/2022 10:52:48 - INFO - __main__ - Step 890 Global step 890 Train loss 2.91 on epoch=63
05/16/2022 10:52:50 - INFO - __main__ - Step 900 Global step 900 Train loss 2.98 on epoch=64
05/16/2022 10:52:52 - INFO - __main__ - Global step 900 Train loss 2.97 Classification-F1 0.016965179052456817 on epoch=64
05/16/2022 10:52:53 - INFO - __main__ - Step 910 Global step 910 Train loss 2.89 on epoch=64
05/16/2022 10:52:54 - INFO - __main__ - Step 920 Global step 920 Train loss 3.02 on epoch=65
05/16/2022 10:52:56 - INFO - __main__ - Step 930 Global step 930 Train loss 2.87 on epoch=66
05/16/2022 10:52:57 - INFO - __main__ - Step 940 Global step 940 Train loss 2.94 on epoch=67
05/16/2022 10:52:58 - INFO - __main__ - Step 950 Global step 950 Train loss 2.86 on epoch=67
05/16/2022 10:53:00 - INFO - __main__ - Global step 950 Train loss 2.91 Classification-F1 0.026761069391260155 on epoch=67
05/16/2022 10:53:02 - INFO - __main__ - Step 960 Global step 960 Train loss 2.97 on epoch=68
05/16/2022 10:53:03 - INFO - __main__ - Step 970 Global step 970 Train loss 2.82 on epoch=69
05/16/2022 10:53:04 - INFO - __main__ - Step 980 Global step 980 Train loss 2.88 on epoch=69
05/16/2022 10:53:06 - INFO - __main__ - Step 990 Global step 990 Train loss 2.94 on epoch=70
05/16/2022 10:53:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.70 on epoch=71
05/16/2022 10:53:09 - INFO - __main__ - Global step 1000 Train loss 2.86 Classification-F1 0.014221829082510197 on epoch=71
05/16/2022 10:53:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.86 on epoch=72
05/16/2022 10:53:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.68 on epoch=72
05/16/2022 10:53:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.92 on epoch=73
05/16/2022 10:53:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.84 on epoch=74
05/16/2022 10:53:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.80 on epoch=74
05/16/2022 10:53:17 - INFO - __main__ - Global step 1050 Train loss 2.82 Classification-F1 0.02734234866563723 on epoch=74
05/16/2022 10:53:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.84 on epoch=75
05/16/2022 10:53:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.73 on epoch=76
05/16/2022 10:53:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.78 on epoch=77
05/16/2022 10:53:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.60 on epoch=77
05/16/2022 10:53:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.66 on epoch=78
05/16/2022 10:53:26 - INFO - __main__ - Global step 1100 Train loss 2.72 Classification-F1 0.024704618689581095 on epoch=78
05/16/2022 10:53:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.72 on epoch=79
05/16/2022 10:53:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.81 on epoch=79
05/16/2022 10:53:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.75 on epoch=80
05/16/2022 10:53:31 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.71 on epoch=81
05/16/2022 10:53:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.79 on epoch=82
05/16/2022 10:53:34 - INFO - __main__ - Global step 1150 Train loss 2.76 Classification-F1 0.0717237184952866 on epoch=82
05/16/2022 10:53:34 - INFO - __main__ - Saving model with best Classification-F1: 0.04756188189561539 -> 0.0717237184952866 on epoch=82, global_step=1150
05/16/2022 10:53:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/16/2022 10:53:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=83
05/16/2022 10:53:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.78 on epoch=84
05/16/2022 10:53:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.63 on epoch=84
05/16/2022 10:53:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.70 on epoch=85
05/16/2022 10:53:43 - INFO - __main__ - Global step 1200 Train loss 2.73 Classification-F1 0.07011087263188104 on epoch=85
05/16/2022 10:53:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.76 on epoch=86
05/16/2022 10:53:45 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.83 on epoch=87
05/16/2022 10:53:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.64 on epoch=87
05/16/2022 10:53:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.63 on epoch=88
05/16/2022 10:53:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.46 on epoch=89
05/16/2022 10:53:51 - INFO - __main__ - Global step 1250 Train loss 2.67 Classification-F1 0.04789395677949894 on epoch=89
05/16/2022 10:53:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.53 on epoch=89
05/16/2022 10:53:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.55 on epoch=90
05/16/2022 10:53:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.51 on epoch=91
05/16/2022 10:53:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.63 on epoch=92
05/16/2022 10:53:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.61 on epoch=92
05/16/2022 10:54:00 - INFO - __main__ - Global step 1300 Train loss 2.57 Classification-F1 0.009523809523809523 on epoch=92
05/16/2022 10:54:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.56 on epoch=93
05/16/2022 10:54:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.48 on epoch=94
05/16/2022 10:54:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.44 on epoch=94
05/16/2022 10:54:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.65 on epoch=95
05/16/2022 10:54:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.47 on epoch=96
05/16/2022 10:54:09 - INFO - __main__ - Global step 1350 Train loss 2.52 Classification-F1 0.039384214372349166 on epoch=96
05/16/2022 10:54:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.57 on epoch=97
05/16/2022 10:54:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.60 on epoch=97
05/16/2022 10:54:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.54 on epoch=98
05/16/2022 10:54:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.54 on epoch=99
05/16/2022 10:54:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.53 on epoch=99
05/16/2022 10:54:17 - INFO - __main__ - Global step 1400 Train loss 2.55 Classification-F1 0.04631297964631298 on epoch=99
05/16/2022 10:54:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.46 on epoch=100
05/16/2022 10:54:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.47 on epoch=101
05/16/2022 10:54:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.71 on epoch=102
05/16/2022 10:54:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.41 on epoch=102
05/16/2022 10:54:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.49 on epoch=103
05/16/2022 10:54:26 - INFO - __main__ - Global step 1450 Train loss 2.51 Classification-F1 0.04603658819275097 on epoch=103
05/16/2022 10:54:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.60 on epoch=104
05/16/2022 10:54:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.42 on epoch=104
05/16/2022 10:54:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.56 on epoch=105
05/16/2022 10:54:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.44 on epoch=106
05/16/2022 10:54:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.36 on epoch=107
05/16/2022 10:54:34 - INFO - __main__ - Global step 1500 Train loss 2.48 Classification-F1 0.04733882464028138 on epoch=107
05/16/2022 10:54:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.61 on epoch=107
05/16/2022 10:54:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.27 on epoch=108
05/16/2022 10:54:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.30 on epoch=109
05/16/2022 10:54:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.30 on epoch=109
05/16/2022 10:54:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.47 on epoch=110
05/16/2022 10:54:43 - INFO - __main__ - Global step 1550 Train loss 2.39 Classification-F1 0.04896407962842083 on epoch=110
05/16/2022 10:54:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.29 on epoch=111
05/16/2022 10:54:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.40 on epoch=112
05/16/2022 10:54:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.36 on epoch=112
05/16/2022 10:54:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.31 on epoch=113
05/16/2022 10:54:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.28 on epoch=114
05/16/2022 10:54:53 - INFO - __main__ - Global step 1600 Train loss 2.33 Classification-F1 0.03653731421499494 on epoch=114
05/16/2022 10:54:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.28 on epoch=114
05/16/2022 10:54:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.47 on epoch=115
05/16/2022 10:54:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.27 on epoch=116
05/16/2022 10:54:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.42 on epoch=117
05/16/2022 10:55:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.25 on epoch=117
05/16/2022 10:55:02 - INFO - __main__ - Global step 1650 Train loss 2.34 Classification-F1 0.025097956158000638 on epoch=117
05/16/2022 10:55:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.33 on epoch=118
05/16/2022 10:55:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.28 on epoch=119
05/16/2022 10:55:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.33 on epoch=119
05/16/2022 10:55:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.31 on epoch=120
05/16/2022 10:55:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.28 on epoch=121
05/16/2022 10:55:11 - INFO - __main__ - Global step 1700 Train loss 2.30 Classification-F1 0.018132626184802277 on epoch=121
05/16/2022 10:55:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.33 on epoch=122
05/16/2022 10:55:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.27 on epoch=122
05/16/2022 10:55:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.37 on epoch=123
05/16/2022 10:55:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.13 on epoch=124
05/16/2022 10:55:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.15 on epoch=124
05/16/2022 10:55:20 - INFO - __main__ - Global step 1750 Train loss 2.25 Classification-F1 0.05229575178641393 on epoch=124
05/16/2022 10:55:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.26 on epoch=125
05/16/2022 10:55:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.27 on epoch=126
05/16/2022 10:55:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.25 on epoch=127
05/16/2022 10:55:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.09 on epoch=127
05/16/2022 10:55:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.09 on epoch=128
05/16/2022 10:55:30 - INFO - __main__ - Global step 1800 Train loss 2.19 Classification-F1 0.017662951705504897 on epoch=128
05/16/2022 10:55:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.20 on epoch=129
05/16/2022 10:55:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.28 on epoch=129
05/16/2022 10:55:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.25 on epoch=130
05/16/2022 10:55:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.19 on epoch=131
05/16/2022 10:55:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.30 on epoch=132
05/16/2022 10:55:39 - INFO - __main__ - Global step 1850 Train loss 2.24 Classification-F1 0.07346803058325077 on epoch=132
05/16/2022 10:55:39 - INFO - __main__ - Saving model with best Classification-F1: 0.0717237184952866 -> 0.07346803058325077 on epoch=132, global_step=1850
05/16/2022 10:55:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.29 on epoch=132
05/16/2022 10:55:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.32 on epoch=133
05/16/2022 10:55:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.22 on epoch=134
05/16/2022 10:55:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.26 on epoch=134
05/16/2022 10:55:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.26 on epoch=135
05/16/2022 10:55:48 - INFO - __main__ - Global step 1900 Train loss 2.27 Classification-F1 0.04010450333979746 on epoch=135
05/16/2022 10:55:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.15 on epoch=136
05/16/2022 10:55:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.20 on epoch=137
05/16/2022 10:55:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.06 on epoch=137
05/16/2022 10:55:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.24 on epoch=138
05/16/2022 10:55:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.13 on epoch=139
05/16/2022 10:55:57 - INFO - __main__ - Global step 1950 Train loss 2.16 Classification-F1 0.03805075419622878 on epoch=139
05/16/2022 10:55:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.10 on epoch=139
05/16/2022 10:55:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.20 on epoch=140
05/16/2022 10:56:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.15 on epoch=141
05/16/2022 10:56:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.23 on epoch=142
05/16/2022 10:56:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.11 on epoch=142
05/16/2022 10:56:05 - INFO - __main__ - Global step 2000 Train loss 2.16 Classification-F1 0.03984319773793458 on epoch=142
05/16/2022 10:56:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.06 on epoch=143
05/16/2022 10:56:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.14 on epoch=144
05/16/2022 10:56:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.17 on epoch=144
05/16/2022 10:56:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.14 on epoch=145
05/16/2022 10:56:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.03 on epoch=146
05/16/2022 10:56:14 - INFO - __main__ - Global step 2050 Train loss 2.11 Classification-F1 0.03137844724172507 on epoch=146
05/16/2022 10:56:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.29 on epoch=147
05/16/2022 10:56:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.09 on epoch=147
05/16/2022 10:56:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.00 on epoch=148
05/16/2022 10:56:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.02 on epoch=149
05/16/2022 10:56:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.09 on epoch=149
05/16/2022 10:56:23 - INFO - __main__ - Global step 2100 Train loss 2.10 Classification-F1 0.05099846390168971 on epoch=149
05/16/2022 10:56:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.14 on epoch=150
05/16/2022 10:56:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.04 on epoch=151
05/16/2022 10:56:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.04 on epoch=152
05/16/2022 10:56:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.16 on epoch=152
05/16/2022 10:56:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.13 on epoch=153
05/16/2022 10:56:31 - INFO - __main__ - Global step 2150 Train loss 2.10 Classification-F1 0.009523809523809523 on epoch=153
05/16/2022 10:56:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.10 on epoch=154
05/16/2022 10:56:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.06 on epoch=154
05/16/2022 10:56:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.06 on epoch=155
05/16/2022 10:56:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.00 on epoch=156
05/16/2022 10:56:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.05 on epoch=157
05/16/2022 10:56:40 - INFO - __main__ - Global step 2200 Train loss 2.06 Classification-F1 0.022799860514724015 on epoch=157
05/16/2022 10:56:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.08 on epoch=157
05/16/2022 10:56:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.20 on epoch=158
05/16/2022 10:56:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.95 on epoch=159
05/16/2022 10:56:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.02 on epoch=159
05/16/2022 10:56:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.01 on epoch=160
05/16/2022 10:56:48 - INFO - __main__ - Global step 2250 Train loss 2.05 Classification-F1 0.015995994413260602 on epoch=160
05/16/2022 10:56:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.99 on epoch=161
05/16/2022 10:56:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.04 on epoch=162
05/16/2022 10:56:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.04 on epoch=162
05/16/2022 10:56:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.87 on epoch=163
05/16/2022 10:56:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.01 on epoch=164
05/16/2022 10:56:57 - INFO - __main__ - Global step 2300 Train loss 1.99 Classification-F1 0.014995334302641003 on epoch=164
05/16/2022 10:56:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.09 on epoch=164
05/16/2022 10:56:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.83 on epoch=165
05/16/2022 10:57:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.98 on epoch=166
05/16/2022 10:57:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.93 on epoch=167
05/16/2022 10:57:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.96 on epoch=167
05/16/2022 10:57:05 - INFO - __main__ - Global step 2350 Train loss 1.96 Classification-F1 0.028196969402999556 on epoch=167
05/16/2022 10:57:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.04 on epoch=168
05/16/2022 10:57:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.94 on epoch=169
05/16/2022 10:57:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.00 on epoch=169
05/16/2022 10:57:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.03 on epoch=170
05/16/2022 10:57:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.99 on epoch=171
05/16/2022 10:57:15 - INFO - __main__ - Global step 2400 Train loss 2.00 Classification-F1 0.027810728277003188 on epoch=171
05/16/2022 10:57:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.97 on epoch=172
05/16/2022 10:57:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.88 on epoch=172
05/16/2022 10:57:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.94 on epoch=173
05/16/2022 10:57:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.82 on epoch=174
05/16/2022 10:57:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.85 on epoch=174
05/16/2022 10:57:23 - INFO - __main__ - Global step 2450 Train loss 1.89 Classification-F1 0.009603841536614645 on epoch=174
05/16/2022 10:57:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.97 on epoch=175
05/16/2022 10:57:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.86 on epoch=176
05/16/2022 10:57:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.95 on epoch=177
05/16/2022 10:57:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.95 on epoch=177
05/16/2022 10:57:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.97 on epoch=178
05/16/2022 10:57:32 - INFO - __main__ - Global step 2500 Train loss 1.94 Classification-F1 0.05139314562064986 on epoch=178
05/16/2022 10:57:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.81 on epoch=179
05/16/2022 10:57:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.97 on epoch=179
05/16/2022 10:57:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.85 on epoch=180
05/16/2022 10:57:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.79 on epoch=181
05/16/2022 10:57:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.75 on epoch=182
05/16/2022 10:57:41 - INFO - __main__ - Global step 2550 Train loss 1.83 Classification-F1 0.02613400037812132 on epoch=182
05/16/2022 10:57:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.78 on epoch=182
05/16/2022 10:57:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.88 on epoch=183
05/16/2022 10:57:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.94 on epoch=184
05/16/2022 10:57:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.87 on epoch=184
05/16/2022 10:57:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.88 on epoch=185
05/16/2022 10:57:49 - INFO - __main__ - Global step 2600 Train loss 1.87 Classification-F1 0.021771609428138945 on epoch=185
05/16/2022 10:57:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.88 on epoch=186
05/16/2022 10:57:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.85 on epoch=187
05/16/2022 10:57:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.83 on epoch=187
05/16/2022 10:57:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.74 on epoch=188
05/16/2022 10:57:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.86 on epoch=189
05/16/2022 10:57:59 - INFO - __main__ - Global step 2650 Train loss 1.83 Classification-F1 0.02977867203219316 on epoch=189
05/16/2022 10:58:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.96 on epoch=189
05/16/2022 10:58:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.73 on epoch=190
05/16/2022 10:58:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.89 on epoch=191
05/16/2022 10:58:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.84 on epoch=192
05/16/2022 10:58:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.77 on epoch=192
05/16/2022 10:58:08 - INFO - __main__ - Global step 2700 Train loss 1.84 Classification-F1 0.03324269682217117 on epoch=192
05/16/2022 10:58:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.71 on epoch=193
05/16/2022 10:58:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.75 on epoch=194
05/16/2022 10:58:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.00 on epoch=194
05/16/2022 10:58:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.74 on epoch=195
05/16/2022 10:58:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.77 on epoch=196
05/16/2022 10:58:17 - INFO - __main__ - Global step 2750 Train loss 1.79 Classification-F1 0.05477356600952106 on epoch=196
05/16/2022 10:58:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.69 on epoch=197
05/16/2022 10:58:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.90 on epoch=197
05/16/2022 10:58:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.64 on epoch=198
05/16/2022 10:58:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.87 on epoch=199
05/16/2022 10:58:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.73 on epoch=199
05/16/2022 10:58:27 - INFO - __main__ - Global step 2800 Train loss 1.77 Classification-F1 0.0630140518787636 on epoch=199
05/16/2022 10:58:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.70 on epoch=200
05/16/2022 10:58:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.80 on epoch=201
05/16/2022 10:58:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.73 on epoch=202
05/16/2022 10:58:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.73 on epoch=202
05/16/2022 10:58:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.71 on epoch=203
05/16/2022 10:58:35 - INFO - __main__ - Global step 2850 Train loss 1.74 Classification-F1 0.04603778535817371 on epoch=203
05/16/2022 10:58:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.63 on epoch=204
05/16/2022 10:58:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.70 on epoch=204
05/16/2022 10:58:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.75 on epoch=205
05/16/2022 10:58:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.80 on epoch=206
05/16/2022 10:58:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.82 on epoch=207
05/16/2022 10:58:44 - INFO - __main__ - Global step 2900 Train loss 1.74 Classification-F1 0.03289108058393018 on epoch=207
05/16/2022 10:58:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.73 on epoch=207
05/16/2022 10:58:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.65 on epoch=208
05/16/2022 10:58:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.84 on epoch=209
05/16/2022 10:58:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.69 on epoch=209
05/16/2022 10:58:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.68 on epoch=210
05/16/2022 10:58:52 - INFO - __main__ - Global step 2950 Train loss 1.72 Classification-F1 0.049508387226489745 on epoch=210
05/16/2022 10:58:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.75 on epoch=211
05/16/2022 10:58:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.73 on epoch=212
05/16/2022 10:58:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.62 on epoch=212
05/16/2022 10:58:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.86 on epoch=213
05/16/2022 10:58:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.71 on epoch=214
05/16/2022 10:59:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:59:00 - INFO - __main__ - Printing 3 examples
05/16/2022 10:59:00 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 10:59:00 - INFO - __main__ - ['Film']
05/16/2022 10:59:00 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 10:59:00 - INFO - __main__ - ['Film']
05/16/2022 10:59:00 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 10:59:00 - INFO - __main__ - ['Film']
05/16/2022 10:59:00 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:59:00 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:59:01 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:59:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:59:01 - INFO - __main__ - Printing 3 examples
05/16/2022 10:59:01 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 10:59:01 - INFO - __main__ - ['Film']
05/16/2022 10:59:01 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 10:59:01 - INFO - __main__ - ['Film']
05/16/2022 10:59:01 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 10:59:01 - INFO - __main__ - ['Film']
05/16/2022 10:59:01 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:59:01 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:59:01 - INFO - __main__ - Global step 3000 Train loss 1.73 Classification-F1 0.013777818819835624 on epoch=214
05/16/2022 10:59:01 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:59:01 - INFO - __main__ - save last model!
05/16/2022 10:59:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 10:59:01 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 10:59:01 - INFO - __main__ - Printing 3 examples
05/16/2022 10:59:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 10:59:01 - INFO - __main__ - ['Animal']
05/16/2022 10:59:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 10:59:01 - INFO - __main__ - ['Animal']
05/16/2022 10:59:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 10:59:01 - INFO - __main__ - ['Village']
05/16/2022 10:59:01 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:59:03 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:59:06 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 10:59:06 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:59:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:59:07 - INFO - __main__ - Starting training!
05/16/2022 10:59:37 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/16/2022 10:59:37 - INFO - __main__ - Classification-F1 on test data: 0.0174
05/16/2022 10:59:37 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.07346803058325077, test_performance=0.017445121297461487
05/16/2022 10:59:37 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/16/2022 10:59:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:59:38 - INFO - __main__ - Printing 3 examples
05/16/2022 10:59:38 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 10:59:38 - INFO - __main__ - ['Film']
05/16/2022 10:59:38 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 10:59:38 - INFO - __main__ - ['Film']
05/16/2022 10:59:38 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 10:59:38 - INFO - __main__ - ['Film']
05/16/2022 10:59:38 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:59:38 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:59:39 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 10:59:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 10:59:39 - INFO - __main__ - Printing 3 examples
05/16/2022 10:59:39 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 10:59:39 - INFO - __main__ - ['Film']
05/16/2022 10:59:39 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 10:59:39 - INFO - __main__ - ['Film']
05/16/2022 10:59:39 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 10:59:39 - INFO - __main__ - ['Film']
05/16/2022 10:59:39 - INFO - __main__ - Tokenizing Input ...
05/16/2022 10:59:39 - INFO - __main__ - Tokenizing Output ...
05/16/2022 10:59:39 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 10:59:45 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 10:59:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 10:59:45 - INFO - __main__ - Starting training!
05/16/2022 10:59:48 - INFO - __main__ - Step 10 Global step 10 Train loss 7.36 on epoch=0
05/16/2022 10:59:50 - INFO - __main__ - Step 20 Global step 20 Train loss 7.47 on epoch=1
05/16/2022 10:59:52 - INFO - __main__ - Step 30 Global step 30 Train loss 7.10 on epoch=2
05/16/2022 10:59:53 - INFO - __main__ - Step 40 Global step 40 Train loss 7.12 on epoch=2
05/16/2022 10:59:54 - INFO - __main__ - Step 50 Global step 50 Train loss 6.78 on epoch=3
05/16/2022 11:00:18 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/16/2022 11:00:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 11:00:19 - INFO - __main__ - Step 60 Global step 60 Train loss 6.60 on epoch=4
05/16/2022 11:00:21 - INFO - __main__ - Step 70 Global step 70 Train loss 6.66 on epoch=4
05/16/2022 11:00:22 - INFO - __main__ - Step 80 Global step 80 Train loss 6.56 on epoch=5
05/16/2022 11:00:24 - INFO - __main__ - Step 90 Global step 90 Train loss 6.54 on epoch=6
05/16/2022 11:00:25 - INFO - __main__ - Step 100 Global step 100 Train loss 6.28 on epoch=7
05/16/2022 11:01:30 - INFO - __main__ - Global step 100 Train loss 6.53 Classification-F1 0.0 on epoch=7
05/16/2022 11:01:32 - INFO - __main__ - Step 110 Global step 110 Train loss 6.34 on epoch=7
05/16/2022 11:01:33 - INFO - __main__ - Step 120 Global step 120 Train loss 6.14 on epoch=8
05/16/2022 11:01:34 - INFO - __main__ - Step 130 Global step 130 Train loss 5.97 on epoch=9
05/16/2022 11:01:36 - INFO - __main__ - Step 140 Global step 140 Train loss 6.18 on epoch=9
05/16/2022 11:01:37 - INFO - __main__ - Step 150 Global step 150 Train loss 6.09 on epoch=10
05/16/2022 11:02:45 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/16/2022 11:02:46 - INFO - __main__ - Step 160 Global step 160 Train loss 6.10 on epoch=11
05/16/2022 11:02:48 - INFO - __main__ - Step 170 Global step 170 Train loss 5.93 on epoch=12
05/16/2022 11:02:49 - INFO - __main__ - Step 180 Global step 180 Train loss 5.97 on epoch=12
05/16/2022 11:02:51 - INFO - __main__ - Step 190 Global step 190 Train loss 5.72 on epoch=13
05/16/2022 11:02:52 - INFO - __main__ - Step 200 Global step 200 Train loss 5.78 on epoch=14
05/16/2022 11:04:09 - INFO - __main__ - Global step 200 Train loss 5.90 Classification-F1 0.0 on epoch=14
05/16/2022 11:04:11 - INFO - __main__ - Step 210 Global step 210 Train loss 5.86 on epoch=14
05/16/2022 11:04:12 - INFO - __main__ - Step 220 Global step 220 Train loss 5.79 on epoch=15
05/16/2022 11:04:14 - INFO - __main__ - Step 230 Global step 230 Train loss 5.92 on epoch=16
05/16/2022 11:04:15 - INFO - __main__ - Step 240 Global step 240 Train loss 5.60 on epoch=17
05/16/2022 11:04:17 - INFO - __main__ - Step 250 Global step 250 Train loss 5.54 on epoch=17
05/16/2022 11:05:01 - INFO - __main__ - Global step 250 Train loss 5.74 Classification-F1 0.0 on epoch=17
05/16/2022 11:05:02 - INFO - __main__ - Step 260 Global step 260 Train loss 5.58 on epoch=18
05/16/2022 11:05:03 - INFO - __main__ - Step 270 Global step 270 Train loss 5.52 on epoch=19
05/16/2022 11:05:05 - INFO - __main__ - Step 280 Global step 280 Train loss 5.63 on epoch=19
05/16/2022 11:05:06 - INFO - __main__ - Step 290 Global step 290 Train loss 5.53 on epoch=20
05/16/2022 11:05:07 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/16/2022 11:05:23 - INFO - __main__ - Global step 300 Train loss 5.54 Classification-F1 0.0 on epoch=21
05/16/2022 11:05:25 - INFO - __main__ - Step 310 Global step 310 Train loss 5.36 on epoch=22
05/16/2022 11:05:26 - INFO - __main__ - Step 320 Global step 320 Train loss 5.50 on epoch=22
05/16/2022 11:05:27 - INFO - __main__ - Step 330 Global step 330 Train loss 5.31 on epoch=23
05/16/2022 11:05:28 - INFO - __main__ - Step 340 Global step 340 Train loss 5.23 on epoch=24
05/16/2022 11:05:30 - INFO - __main__ - Step 350 Global step 350 Train loss 5.29 on epoch=24
05/16/2022 11:05:33 - INFO - __main__ - Global step 350 Train loss 5.34 Classification-F1 0.00538116591928251 on epoch=24
05/16/2022 11:05:33 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.00538116591928251 on epoch=24, global_step=350
05/16/2022 11:05:34 - INFO - __main__ - Step 360 Global step 360 Train loss 5.16 on epoch=25
05/16/2022 11:05:36 - INFO - __main__ - Step 370 Global step 370 Train loss 5.23 on epoch=26
05/16/2022 11:05:37 - INFO - __main__ - Step 380 Global step 380 Train loss 5.34 on epoch=27
05/16/2022 11:05:38 - INFO - __main__ - Step 390 Global step 390 Train loss 4.94 on epoch=27
05/16/2022 11:05:40 - INFO - __main__ - Step 400 Global step 400 Train loss 4.95 on epoch=28
05/16/2022 11:05:44 - INFO - __main__ - Global step 400 Train loss 5.12 Classification-F1 0.008438818565400845 on epoch=28
05/16/2022 11:05:44 - INFO - __main__ - Saving model with best Classification-F1: 0.00538116591928251 -> 0.008438818565400845 on epoch=28, global_step=400
05/16/2022 11:05:45 - INFO - __main__ - Step 410 Global step 410 Train loss 4.91 on epoch=29
05/16/2022 11:05:46 - INFO - __main__ - Step 420 Global step 420 Train loss 5.04 on epoch=29
05/16/2022 11:05:47 - INFO - __main__ - Step 430 Global step 430 Train loss 4.92 on epoch=30
05/16/2022 11:05:49 - INFO - __main__ - Step 440 Global step 440 Train loss 4.79 on epoch=31
05/16/2022 11:05:50 - INFO - __main__ - Step 450 Global step 450 Train loss 4.89 on epoch=32
05/16/2022 11:05:52 - INFO - __main__ - Global step 450 Train loss 4.91 Classification-F1 0.009523809523809523 on epoch=32
05/16/2022 11:05:52 - INFO - __main__ - Saving model with best Classification-F1: 0.008438818565400845 -> 0.009523809523809523 on epoch=32, global_step=450
05/16/2022 11:05:54 - INFO - __main__ - Step 460 Global step 460 Train loss 4.80 on epoch=32
05/16/2022 11:05:55 - INFO - __main__ - Step 470 Global step 470 Train loss 4.70 on epoch=33
05/16/2022 11:05:57 - INFO - __main__ - Step 480 Global step 480 Train loss 4.73 on epoch=34
05/16/2022 11:05:58 - INFO - __main__ - Step 490 Global step 490 Train loss 4.66 on epoch=34
05/16/2022 11:05:59 - INFO - __main__ - Step 500 Global step 500 Train loss 4.65 on epoch=35
05/16/2022 11:06:01 - INFO - __main__ - Global step 500 Train loss 4.71 Classification-F1 0.009523809523809523 on epoch=35
05/16/2022 11:06:03 - INFO - __main__ - Step 510 Global step 510 Train loss 4.50 on epoch=36
05/16/2022 11:06:04 - INFO - __main__ - Step 520 Global step 520 Train loss 4.69 on epoch=37
05/16/2022 11:06:06 - INFO - __main__ - Step 530 Global step 530 Train loss 4.44 on epoch=37
05/16/2022 11:06:07 - INFO - __main__ - Step 540 Global step 540 Train loss 4.41 on epoch=38
05/16/2022 11:06:09 - INFO - __main__ - Step 550 Global step 550 Train loss 4.46 on epoch=39
05/16/2022 11:06:11 - INFO - __main__ - Global step 550 Train loss 4.50 Classification-F1 0.009523809523809523 on epoch=39
05/16/2022 11:06:12 - INFO - __main__ - Step 560 Global step 560 Train loss 4.40 on epoch=39
05/16/2022 11:06:14 - INFO - __main__ - Step 570 Global step 570 Train loss 4.49 on epoch=40
05/16/2022 11:06:15 - INFO - __main__ - Step 580 Global step 580 Train loss 4.28 on epoch=41
05/16/2022 11:06:17 - INFO - __main__ - Step 590 Global step 590 Train loss 4.11 on epoch=42
05/16/2022 11:06:18 - INFO - __main__ - Step 600 Global step 600 Train loss 4.18 on epoch=42
05/16/2022 11:06:20 - INFO - __main__ - Global step 600 Train loss 4.29 Classification-F1 0.014082268421387245 on epoch=42
05/16/2022 11:06:20 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.014082268421387245 on epoch=42, global_step=600
05/16/2022 11:06:21 - INFO - __main__ - Step 610 Global step 610 Train loss 4.20 on epoch=43
05/16/2022 11:06:23 - INFO - __main__ - Step 620 Global step 620 Train loss 4.15 on epoch=44
05/16/2022 11:06:24 - INFO - __main__ - Step 630 Global step 630 Train loss 4.11 on epoch=44
05/16/2022 11:06:26 - INFO - __main__ - Step 640 Global step 640 Train loss 4.33 on epoch=45
05/16/2022 11:06:27 - INFO - __main__ - Step 650 Global step 650 Train loss 3.93 on epoch=46
05/16/2022 11:06:29 - INFO - __main__ - Global step 650 Train loss 4.14 Classification-F1 0.009696186166774399 on epoch=46
05/16/2022 11:06:31 - INFO - __main__ - Step 660 Global step 660 Train loss 4.14 on epoch=47
05/16/2022 11:06:33 - INFO - __main__ - Step 670 Global step 670 Train loss 4.04 on epoch=47
05/16/2022 11:06:34 - INFO - __main__ - Step 680 Global step 680 Train loss 3.97 on epoch=48
05/16/2022 11:06:36 - INFO - __main__ - Step 690 Global step 690 Train loss 3.96 on epoch=49
05/16/2022 11:06:38 - INFO - __main__ - Step 700 Global step 700 Train loss 3.91 on epoch=49
05/16/2022 11:06:40 - INFO - __main__ - Global step 700 Train loss 4.00 Classification-F1 0.016021112680937276 on epoch=49
05/16/2022 11:06:40 - INFO - __main__ - Saving model with best Classification-F1: 0.014082268421387245 -> 0.016021112680937276 on epoch=49, global_step=700
05/16/2022 11:06:42 - INFO - __main__ - Step 710 Global step 710 Train loss 3.92 on epoch=50
05/16/2022 11:06:43 - INFO - __main__ - Step 720 Global step 720 Train loss 3.76 on epoch=51
05/16/2022 11:06:45 - INFO - __main__ - Step 730 Global step 730 Train loss 3.83 on epoch=52
05/16/2022 11:06:46 - INFO - __main__ - Step 740 Global step 740 Train loss 3.84 on epoch=52
05/16/2022 11:06:47 - INFO - __main__ - Step 750 Global step 750 Train loss 3.83 on epoch=53
05/16/2022 11:06:49 - INFO - __main__ - Global step 750 Train loss 3.83 Classification-F1 0.022077595196145407 on epoch=53
05/16/2022 11:06:49 - INFO - __main__ - Saving model with best Classification-F1: 0.016021112680937276 -> 0.022077595196145407 on epoch=53, global_step=750
05/16/2022 11:06:51 - INFO - __main__ - Step 760 Global step 760 Train loss 3.67 on epoch=54
05/16/2022 11:06:52 - INFO - __main__ - Step 770 Global step 770 Train loss 3.57 on epoch=54
05/16/2022 11:06:54 - INFO - __main__ - Step 780 Global step 780 Train loss 3.81 on epoch=55
05/16/2022 11:06:55 - INFO - __main__ - Step 790 Global step 790 Train loss 3.66 on epoch=56
05/16/2022 11:06:56 - INFO - __main__ - Step 800 Global step 800 Train loss 3.46 on epoch=57
05/16/2022 11:06:58 - INFO - __main__ - Global step 800 Train loss 3.63 Classification-F1 0.009563658099222952 on epoch=57
05/16/2022 11:07:00 - INFO - __main__ - Step 810 Global step 810 Train loss 3.71 on epoch=57
05/16/2022 11:07:01 - INFO - __main__ - Step 820 Global step 820 Train loss 3.70 on epoch=58
05/16/2022 11:07:02 - INFO - __main__ - Step 830 Global step 830 Train loss 3.46 on epoch=59
05/16/2022 11:07:04 - INFO - __main__ - Step 840 Global step 840 Train loss 3.45 on epoch=59
05/16/2022 11:07:05 - INFO - __main__ - Step 850 Global step 850 Train loss 3.67 on epoch=60
05/16/2022 11:07:07 - INFO - __main__ - Global step 850 Train loss 3.60 Classification-F1 0.015243052328283296 on epoch=60
05/16/2022 11:07:08 - INFO - __main__ - Step 860 Global step 860 Train loss 3.34 on epoch=61
05/16/2022 11:07:10 - INFO - __main__ - Step 870 Global step 870 Train loss 3.45 on epoch=62
05/16/2022 11:07:11 - INFO - __main__ - Step 880 Global step 880 Train loss 3.44 on epoch=62
05/16/2022 11:07:12 - INFO - __main__ - Step 890 Global step 890 Train loss 3.37 on epoch=63
05/16/2022 11:07:14 - INFO - __main__ - Step 900 Global step 900 Train loss 3.28 on epoch=64
05/16/2022 11:07:16 - INFO - __main__ - Global step 900 Train loss 3.38 Classification-F1 0.008965929468021518 on epoch=64
05/16/2022 11:07:17 - INFO - __main__ - Step 910 Global step 910 Train loss 3.21 on epoch=64
05/16/2022 11:07:18 - INFO - __main__ - Step 920 Global step 920 Train loss 3.44 on epoch=65
05/16/2022 11:07:20 - INFO - __main__ - Step 930 Global step 930 Train loss 3.24 on epoch=66
05/16/2022 11:07:21 - INFO - __main__ - Step 940 Global step 940 Train loss 3.29 on epoch=67
05/16/2022 11:07:22 - INFO - __main__ - Step 950 Global step 950 Train loss 3.31 on epoch=67
05/16/2022 11:07:24 - INFO - __main__ - Global step 950 Train loss 3.30 Classification-F1 0.017540349473122583 on epoch=67
05/16/2022 11:07:26 - INFO - __main__ - Step 960 Global step 960 Train loss 3.22 on epoch=68
05/16/2022 11:07:27 - INFO - __main__ - Step 970 Global step 970 Train loss 3.28 on epoch=69
05/16/2022 11:07:28 - INFO - __main__ - Step 980 Global step 980 Train loss 2.96 on epoch=69
05/16/2022 11:07:30 - INFO - __main__ - Step 990 Global step 990 Train loss 3.24 on epoch=70
05/16/2022 11:07:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.15 on epoch=71
05/16/2022 11:07:33 - INFO - __main__ - Global step 1000 Train loss 3.17 Classification-F1 0.01216579655117861 on epoch=71
05/16/2022 11:07:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.22 on epoch=72
05/16/2022 11:07:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.15 on epoch=72
05/16/2022 11:07:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.14 on epoch=73
05/16/2022 11:07:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.25 on epoch=74
05/16/2022 11:07:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.03 on epoch=74
05/16/2022 11:07:42 - INFO - __main__ - Global step 1050 Train loss 3.16 Classification-F1 0.029260582241872675 on epoch=74
05/16/2022 11:07:42 - INFO - __main__ - Saving model with best Classification-F1: 0.022077595196145407 -> 0.029260582241872675 on epoch=74, global_step=1050
05/16/2022 11:07:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.15 on epoch=75
05/16/2022 11:07:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.14 on epoch=76
05/16/2022 11:07:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.01 on epoch=77
05/16/2022 11:07:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.96 on epoch=77
05/16/2022 11:07:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.94 on epoch=78
05/16/2022 11:07:51 - INFO - __main__ - Global step 1100 Train loss 3.04 Classification-F1 0.016664141796697472 on epoch=78
05/16/2022 11:07:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.00 on epoch=79
05/16/2022 11:07:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.92 on epoch=79
05/16/2022 11:07:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.11 on epoch=80
05/16/2022 11:07:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.85 on epoch=81
05/16/2022 11:07:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.03 on epoch=82
05/16/2022 11:08:00 - INFO - __main__ - Global step 1150 Train loss 2.98 Classification-F1 0.0228843736908253 on epoch=82
05/16/2022 11:08:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.03 on epoch=82
05/16/2022 11:08:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.95 on epoch=83
05/16/2022 11:08:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.01 on epoch=84
05/16/2022 11:08:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.84 on epoch=84
05/16/2022 11:08:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.00 on epoch=85
05/16/2022 11:08:10 - INFO - __main__ - Global step 1200 Train loss 2.97 Classification-F1 0.025842115775498452 on epoch=85
05/16/2022 11:08:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.95 on epoch=86
05/16/2022 11:08:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.05 on epoch=87
05/16/2022 11:08:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.88 on epoch=87
05/16/2022 11:08:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.94 on epoch=88
05/16/2022 11:08:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.75 on epoch=89
05/16/2022 11:08:19 - INFO - __main__ - Global step 1250 Train loss 2.92 Classification-F1 0.041557699594084174 on epoch=89
05/16/2022 11:08:19 - INFO - __main__ - Saving model with best Classification-F1: 0.029260582241872675 -> 0.041557699594084174 on epoch=89, global_step=1250
05/16/2022 11:08:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.86 on epoch=89
05/16/2022 11:08:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.00 on epoch=90
05/16/2022 11:08:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.83 on epoch=91
05/16/2022 11:08:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.91 on epoch=92
05/16/2022 11:08:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.89 on epoch=92
05/16/2022 11:08:28 - INFO - __main__ - Global step 1300 Train loss 2.90 Classification-F1 0.04131000578368999 on epoch=92
05/16/2022 11:08:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.96 on epoch=93
05/16/2022 11:08:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.66 on epoch=94
05/16/2022 11:08:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.82 on epoch=94
05/16/2022 11:08:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.96 on epoch=95
05/16/2022 11:08:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.81 on epoch=96
05/16/2022 11:08:37 - INFO - __main__ - Global step 1350 Train loss 2.84 Classification-F1 0.034306198438578926 on epoch=96
05/16/2022 11:08:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.87 on epoch=97
05/16/2022 11:08:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.82 on epoch=97
05/16/2022 11:08:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.86 on epoch=98
05/16/2022 11:08:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.82 on epoch=99
05/16/2022 11:08:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.63 on epoch=99
05/16/2022 11:08:46 - INFO - __main__ - Global step 1400 Train loss 2.80 Classification-F1 0.009937888198757764 on epoch=99
05/16/2022 11:08:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.93 on epoch=100
05/16/2022 11:08:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.73 on epoch=101
05/16/2022 11:08:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.82 on epoch=102
05/16/2022 11:08:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.81 on epoch=102
05/16/2022 11:08:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.71 on epoch=103
05/16/2022 11:08:54 - INFO - __main__ - Global step 1450 Train loss 2.80 Classification-F1 0.015154185022026432 on epoch=103
05/16/2022 11:08:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.77 on epoch=104
05/16/2022 11:08:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.83 on epoch=104
05/16/2022 11:08:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.87 on epoch=105
05/16/2022 11:09:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.73 on epoch=106
05/16/2022 11:09:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.73 on epoch=107
05/16/2022 11:09:03 - INFO - __main__ - Global step 1500 Train loss 2.78 Classification-F1 0.02032227032227032 on epoch=107
05/16/2022 11:09:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.67 on epoch=107
05/16/2022 11:09:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.82 on epoch=108
05/16/2022 11:09:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.64 on epoch=109
05/16/2022 11:09:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.69 on epoch=109
05/16/2022 11:09:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.76 on epoch=110
05/16/2022 11:09:12 - INFO - __main__ - Global step 1550 Train loss 2.72 Classification-F1 0.022980987266701555 on epoch=110
05/16/2022 11:09:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.52 on epoch=111
05/16/2022 11:09:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.66 on epoch=112
05/16/2022 11:09:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.53 on epoch=112
05/16/2022 11:09:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.69 on epoch=113
05/16/2022 11:09:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.55 on epoch=114
05/16/2022 11:09:21 - INFO - __main__ - Global step 1600 Train loss 2.59 Classification-F1 0.03183846228959011 on epoch=114
05/16/2022 11:09:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.53 on epoch=114
05/16/2022 11:09:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.72 on epoch=115
05/16/2022 11:09:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.43 on epoch=116
05/16/2022 11:09:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.65 on epoch=117
05/16/2022 11:09:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.61 on epoch=117
05/16/2022 11:09:30 - INFO - __main__ - Global step 1650 Train loss 2.59 Classification-F1 0.01767752715121136 on epoch=117
05/16/2022 11:09:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.76 on epoch=118
05/16/2022 11:09:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.53 on epoch=119
05/16/2022 11:09:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.49 on epoch=119
05/16/2022 11:09:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.74 on epoch=120
05/16/2022 11:09:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.44 on epoch=121
05/16/2022 11:09:39 - INFO - __main__ - Global step 1700 Train loss 2.59 Classification-F1 0.009937888198757764 on epoch=121
05/16/2022 11:09:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.70 on epoch=122
05/16/2022 11:09:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.41 on epoch=122
05/16/2022 11:09:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.67 on epoch=123
05/16/2022 11:09:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.57 on epoch=124
05/16/2022 11:09:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.52 on epoch=124
05/16/2022 11:09:48 - INFO - __main__ - Global step 1750 Train loss 2.57 Classification-F1 0.04742028246128682 on epoch=124
05/16/2022 11:09:48 - INFO - __main__ - Saving model with best Classification-F1: 0.041557699594084174 -> 0.04742028246128682 on epoch=124, global_step=1750
05/16/2022 11:09:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.67 on epoch=125
05/16/2022 11:09:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.59 on epoch=126
05/16/2022 11:09:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.67 on epoch=127
05/16/2022 11:09:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.52 on epoch=127
05/16/2022 11:09:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.70 on epoch=128
05/16/2022 11:09:58 - INFO - __main__ - Global step 1800 Train loss 2.63 Classification-F1 0.0653606488170099 on epoch=128
05/16/2022 11:09:58 - INFO - __main__ - Saving model with best Classification-F1: 0.04742028246128682 -> 0.0653606488170099 on epoch=128, global_step=1800
05/16/2022 11:09:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.45 on epoch=129
05/16/2022 11:10:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.48 on epoch=129
05/16/2022 11:10:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.62 on epoch=130
05/16/2022 11:10:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.46 on epoch=131
05/16/2022 11:10:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.68 on epoch=132
05/16/2022 11:10:06 - INFO - __main__ - Global step 1850 Train loss 2.54 Classification-F1 0.027562111801242233 on epoch=132
05/16/2022 11:10:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.52 on epoch=132
05/16/2022 11:10:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.45 on epoch=133
05/16/2022 11:10:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.59 on epoch=134
05/16/2022 11:10:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.36 on epoch=134
05/16/2022 11:10:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.58 on epoch=135
05/16/2022 11:10:15 - INFO - __main__ - Global step 1900 Train loss 2.50 Classification-F1 0.01728680676049097 on epoch=135
05/16/2022 11:10:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.46 on epoch=136
05/16/2022 11:10:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.57 on epoch=137
05/16/2022 11:10:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.57 on epoch=137
05/16/2022 11:10:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.49 on epoch=138
05/16/2022 11:10:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.42 on epoch=139
05/16/2022 11:10:24 - INFO - __main__ - Global step 1950 Train loss 2.51 Classification-F1 0.030137743170662756 on epoch=139
05/16/2022 11:10:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.29 on epoch=139
05/16/2022 11:10:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.73 on epoch=140
05/16/2022 11:10:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.46 on epoch=141
05/16/2022 11:10:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.47 on epoch=142
05/16/2022 11:10:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.49 on epoch=142
05/16/2022 11:10:33 - INFO - __main__ - Global step 2000 Train loss 2.49 Classification-F1 0.016910866910866913 on epoch=142
05/16/2022 11:10:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.32 on epoch=143
05/16/2022 11:10:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.28 on epoch=144
05/16/2022 11:10:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.47 on epoch=144
05/16/2022 11:10:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.64 on epoch=145
05/16/2022 11:10:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.35 on epoch=146
05/16/2022 11:10:42 - INFO - __main__ - Global step 2050 Train loss 2.41 Classification-F1 0.017052560934687776 on epoch=146
05/16/2022 11:10:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.51 on epoch=147
05/16/2022 11:10:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.30 on epoch=147
05/16/2022 11:10:46 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.39 on epoch=148
05/16/2022 11:10:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.32 on epoch=149
05/16/2022 11:10:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.33 on epoch=149
05/16/2022 11:10:51 - INFO - __main__ - Global step 2100 Train loss 2.37 Classification-F1 0.017704517704517704 on epoch=149
05/16/2022 11:10:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.67 on epoch=150
05/16/2022 11:10:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.39 on epoch=151
05/16/2022 11:10:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.46 on epoch=152
05/16/2022 11:10:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.37 on epoch=152
05/16/2022 11:10:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.42 on epoch=153
05/16/2022 11:11:00 - INFO - __main__ - Global step 2150 Train loss 2.46 Classification-F1 0.026077097505668938 on epoch=153
05/16/2022 11:11:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.33 on epoch=154
05/16/2022 11:11:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.23 on epoch=154
05/16/2022 11:11:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.26 on epoch=155
05/16/2022 11:11:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.26 on epoch=156
05/16/2022 11:11:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.41 on epoch=157
05/16/2022 11:11:08 - INFO - __main__ - Global step 2200 Train loss 2.30 Classification-F1 0.041230826194922146 on epoch=157
05/16/2022 11:11:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.10 on epoch=157
05/16/2022 11:11:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.23 on epoch=158
05/16/2022 11:11:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.45 on epoch=159
05/16/2022 11:11:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.29 on epoch=159
05/16/2022 11:11:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.35 on epoch=160
05/16/2022 11:11:17 - INFO - __main__ - Global step 2250 Train loss 2.28 Classification-F1 0.03471051365788208 on epoch=160
05/16/2022 11:11:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.28 on epoch=161
05/16/2022 11:11:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.28 on epoch=162
05/16/2022 11:11:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.25 on epoch=162
05/16/2022 11:11:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.26 on epoch=163
05/16/2022 11:11:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.39 on epoch=164
05/16/2022 11:11:26 - INFO - __main__ - Global step 2300 Train loss 2.29 Classification-F1 0.037531925050722045 on epoch=164
05/16/2022 11:11:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.38 on epoch=164
05/16/2022 11:11:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.29 on epoch=165
05/16/2022 11:11:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.11 on epoch=166
05/16/2022 11:11:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.37 on epoch=167
05/16/2022 11:11:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.20 on epoch=167
05/16/2022 11:11:35 - INFO - __main__ - Global step 2350 Train loss 2.27 Classification-F1 0.047017333369690696 on epoch=167
05/16/2022 11:11:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.24 on epoch=168
05/16/2022 11:11:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.23 on epoch=169
05/16/2022 11:11:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.14 on epoch=169
05/16/2022 11:11:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.25 on epoch=170
05/16/2022 11:11:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.30 on epoch=171
05/16/2022 11:11:44 - INFO - __main__ - Global step 2400 Train loss 2.23 Classification-F1 0.04487647559936717 on epoch=171
05/16/2022 11:11:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.30 on epoch=172
05/16/2022 11:11:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.13 on epoch=172
05/16/2022 11:11:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.22 on epoch=173
05/16/2022 11:11:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.23 on epoch=174
05/16/2022 11:11:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.22 on epoch=174
05/16/2022 11:11:53 - INFO - __main__ - Global step 2450 Train loss 2.22 Classification-F1 0.048135084421991006 on epoch=174
05/16/2022 11:11:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.22 on epoch=175
05/16/2022 11:11:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.96 on epoch=176
05/16/2022 11:11:57 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.15 on epoch=177
05/16/2022 11:11:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.07 on epoch=177
05/16/2022 11:12:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.23 on epoch=178
05/16/2022 11:12:02 - INFO - __main__ - Global step 2500 Train loss 2.12 Classification-F1 0.034098404378087 on epoch=178
05/16/2022 11:12:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.14 on epoch=179
05/16/2022 11:12:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.21 on epoch=179
05/16/2022 11:12:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.26 on epoch=180
05/16/2022 11:12:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.12 on epoch=181
05/16/2022 11:12:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.35 on epoch=182
05/16/2022 11:12:11 - INFO - __main__ - Global step 2550 Train loss 2.21 Classification-F1 0.02442466348241424 on epoch=182
05/16/2022 11:12:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.12 on epoch=182
05/16/2022 11:12:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.30 on epoch=183
05/16/2022 11:12:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.18 on epoch=184
05/16/2022 11:12:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.15 on epoch=184
05/16/2022 11:12:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.27 on epoch=185
05/16/2022 11:12:20 - INFO - __main__ - Global step 2600 Train loss 2.21 Classification-F1 0.04423105922929991 on epoch=185
05/16/2022 11:12:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.22 on epoch=186
05/16/2022 11:12:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.21 on epoch=187
05/16/2022 11:12:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.07 on epoch=187
05/16/2022 11:12:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.03 on epoch=188
05/16/2022 11:12:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.95 on epoch=189
05/16/2022 11:12:30 - INFO - __main__ - Global step 2650 Train loss 2.10 Classification-F1 0.07818484200616001 on epoch=189
05/16/2022 11:12:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0653606488170099 -> 0.07818484200616001 on epoch=189, global_step=2650
05/16/2022 11:12:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.13 on epoch=189
05/16/2022 11:12:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.16 on epoch=190
05/16/2022 11:12:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.01 on epoch=191
05/16/2022 11:12:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.13 on epoch=192
05/16/2022 11:12:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.99 on epoch=192
05/16/2022 11:12:39 - INFO - __main__ - Global step 2700 Train loss 2.09 Classification-F1 0.061139459343052156 on epoch=192
05/16/2022 11:12:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.06 on epoch=193
05/16/2022 11:12:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.06 on epoch=194
05/16/2022 11:12:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.08 on epoch=194
05/16/2022 11:12:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.97 on epoch=195
05/16/2022 11:12:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.06 on epoch=196
05/16/2022 11:12:48 - INFO - __main__ - Global step 2750 Train loss 2.05 Classification-F1 0.06845545235638115 on epoch=196
05/16/2022 11:12:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.08 on epoch=197
05/16/2022 11:12:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.01 on epoch=197
05/16/2022 11:12:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.06 on epoch=198
05/16/2022 11:12:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.05 on epoch=199
05/16/2022 11:12:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.03 on epoch=199
05/16/2022 11:12:57 - INFO - __main__ - Global step 2800 Train loss 2.05 Classification-F1 0.0901874136374937 on epoch=199
05/16/2022 11:12:57 - INFO - __main__ - Saving model with best Classification-F1: 0.07818484200616001 -> 0.0901874136374937 on epoch=199, global_step=2800
05/16/2022 11:12:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.08 on epoch=200
05/16/2022 11:13:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.06 on epoch=201
05/16/2022 11:13:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.15 on epoch=202
05/16/2022 11:13:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.06 on epoch=202
05/16/2022 11:13:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.11 on epoch=203
05/16/2022 11:13:06 - INFO - __main__ - Global step 2850 Train loss 2.09 Classification-F1 0.08084187475288178 on epoch=203
05/16/2022 11:13:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.06 on epoch=204
05/16/2022 11:13:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.14 on epoch=204
05/16/2022 11:13:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.01 on epoch=205
05/16/2022 11:13:12 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.06 on epoch=206
05/16/2022 11:13:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.00 on epoch=207
05/16/2022 11:13:16 - INFO - __main__ - Global step 2900 Train loss 2.06 Classification-F1 0.0707468127342237 on epoch=207
05/16/2022 11:13:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.02 on epoch=207
05/16/2022 11:13:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.10 on epoch=208
05/16/2022 11:13:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.03 on epoch=209
05/16/2022 11:13:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.11 on epoch=209
05/16/2022 11:13:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.91 on epoch=210
05/16/2022 11:13:25 - INFO - __main__ - Global step 2950 Train loss 2.03 Classification-F1 0.08941591453169584 on epoch=210
05/16/2022 11:13:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.09 on epoch=211
05/16/2022 11:13:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.94 on epoch=212
05/16/2022 11:13:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.86 on epoch=212
05/16/2022 11:13:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.93 on epoch=213
05/16/2022 11:13:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.99 on epoch=214
05/16/2022 11:13:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:13:33 - INFO - __main__ - Printing 3 examples
05/16/2022 11:13:33 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 11:13:33 - INFO - __main__ - ['Film']
05/16/2022 11:13:33 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 11:13:33 - INFO - __main__ - ['Film']
05/16/2022 11:13:33 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 11:13:33 - INFO - __main__ - ['Film']
05/16/2022 11:13:33 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:13:33 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:13:33 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 11:13:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:13:33 - INFO - __main__ - Printing 3 examples
05/16/2022 11:13:33 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 11:13:33 - INFO - __main__ - ['Film']
05/16/2022 11:13:33 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 11:13:33 - INFO - __main__ - ['Film']
05/16/2022 11:13:33 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 11:13:33 - INFO - __main__ - ['Film']
05/16/2022 11:13:33 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:13:33 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:13:34 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 11:13:34 - INFO - __main__ - Global step 3000 Train loss 1.96 Classification-F1 0.06239911021037329 on epoch=214
05/16/2022 11:13:34 - INFO - __main__ - save last model!
05/16/2022 11:13:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 11:13:34 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 11:13:34 - INFO - __main__ - Printing 3 examples
05/16/2022 11:13:34 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 11:13:34 - INFO - __main__ - ['Animal']
05/16/2022 11:13:34 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 11:13:34 - INFO - __main__ - ['Animal']
05/16/2022 11:13:34 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 11:13:34 - INFO - __main__ - ['Village']
05/16/2022 11:13:34 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:13:36 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:13:39 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 11:13:39 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 11:13:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 11:13:39 - INFO - __main__ - Starting training!
05/16/2022 11:14:10 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/16/2022 11:14:10 - INFO - __main__ - Classification-F1 on test data: 0.0605
05/16/2022 11:14:10 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.0901874136374937, test_performance=0.06054021125330055
05/16/2022 11:14:10 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/16/2022 11:14:11 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:14:11 - INFO - __main__ - Printing 3 examples
05/16/2022 11:14:11 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 11:14:11 - INFO - __main__ - ['Film']
05/16/2022 11:14:11 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 11:14:11 - INFO - __main__ - ['Film']
05/16/2022 11:14:11 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 11:14:11 - INFO - __main__ - ['Film']
05/16/2022 11:14:11 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:14:11 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:14:12 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 11:14:12 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:14:12 - INFO - __main__ - Printing 3 examples
05/16/2022 11:14:12 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 11:14:12 - INFO - __main__ - ['Film']
05/16/2022 11:14:12 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 11:14:12 - INFO - __main__ - ['Film']
05/16/2022 11:14:12 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 11:14:12 - INFO - __main__ - ['Film']
05/16/2022 11:14:12 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:14:12 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:14:12 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 11:14:18 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 11:14:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 11:14:19 - INFO - __main__ - Starting training!
05/16/2022 11:14:22 - INFO - __main__ - Step 10 Global step 10 Train loss 7.43 on epoch=0
05/16/2022 11:14:24 - INFO - __main__ - Step 20 Global step 20 Train loss 7.35 on epoch=1
05/16/2022 11:14:25 - INFO - __main__ - Step 30 Global step 30 Train loss 7.04 on epoch=2
05/16/2022 11:14:26 - INFO - __main__ - Step 40 Global step 40 Train loss 7.27 on epoch=2
05/16/2022 11:14:28 - INFO - __main__ - Step 50 Global step 50 Train loss 6.91 on epoch=3
05/16/2022 11:14:39 - INFO - __main__ - Global step 50 Train loss 7.20 Classification-F1 0.0 on epoch=3
05/16/2022 11:14:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 11:14:41 - INFO - __main__ - Step 60 Global step 60 Train loss 6.77 on epoch=4
05/16/2022 11:14:42 - INFO - __main__ - Step 70 Global step 70 Train loss 6.97 on epoch=4
05/16/2022 11:14:43 - INFO - __main__ - Step 80 Global step 80 Train loss 6.76 on epoch=5
05/16/2022 11:14:45 - INFO - __main__ - Step 90 Global step 90 Train loss 6.68 on epoch=6
05/16/2022 11:14:46 - INFO - __main__ - Step 100 Global step 100 Train loss 6.56 on epoch=7
05/16/2022 11:15:09 - INFO - __main__ - Global step 100 Train loss 6.75 Classification-F1 0.0 on epoch=7
05/16/2022 11:15:11 - INFO - __main__ - Step 110 Global step 110 Train loss 6.59 on epoch=7
05/16/2022 11:15:12 - INFO - __main__ - Step 120 Global step 120 Train loss 6.38 on epoch=8
05/16/2022 11:15:14 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/16/2022 11:15:16 - INFO - __main__ - Step 140 Global step 140 Train loss 6.43 on epoch=9
05/16/2022 11:15:17 - INFO - __main__ - Step 150 Global step 150 Train loss 6.29 on epoch=10
05/16/2022 11:16:20 - INFO - __main__ - Global step 150 Train loss 6.41 Classification-F1 0.0 on epoch=10
05/16/2022 11:16:22 - INFO - __main__ - Step 160 Global step 160 Train loss 6.36 on epoch=11
05/16/2022 11:16:23 - INFO - __main__ - Step 170 Global step 170 Train loss 6.17 on epoch=12
05/16/2022 11:16:25 - INFO - __main__ - Step 180 Global step 180 Train loss 6.12 on epoch=12
05/16/2022 11:16:26 - INFO - __main__ - Step 190 Global step 190 Train loss 6.13 on epoch=13
05/16/2022 11:16:27 - INFO - __main__ - Step 200 Global step 200 Train loss 5.88 on epoch=14
05/16/2022 11:17:30 - INFO - __main__ - Global step 200 Train loss 6.13 Classification-F1 0.0 on epoch=14
05/16/2022 11:17:32 - INFO - __main__ - Step 210 Global step 210 Train loss 6.18 on epoch=14
05/16/2022 11:17:33 - INFO - __main__ - Step 220 Global step 220 Train loss 5.99 on epoch=15
05/16/2022 11:17:35 - INFO - __main__ - Step 230 Global step 230 Train loss 5.79 on epoch=16
05/16/2022 11:17:36 - INFO - __main__ - Step 240 Global step 240 Train loss 5.82 on epoch=17
05/16/2022 11:17:37 - INFO - __main__ - Step 250 Global step 250 Train loss 5.95 on epoch=17
05/16/2022 11:18:41 - INFO - __main__ - Global step 250 Train loss 5.95 Classification-F1 0.0 on epoch=17
05/16/2022 11:18:42 - INFO - __main__ - Step 260 Global step 260 Train loss 5.65 on epoch=18
05/16/2022 11:18:44 - INFO - __main__ - Step 270 Global step 270 Train loss 5.61 on epoch=19
05/16/2022 11:18:45 - INFO - __main__ - Step 280 Global step 280 Train loss 5.76 on epoch=19
05/16/2022 11:18:46 - INFO - __main__ - Step 290 Global step 290 Train loss 5.62 on epoch=20
05/16/2022 11:18:47 - INFO - __main__ - Step 300 Global step 300 Train loss 5.62 on epoch=21
05/16/2022 11:19:39 - INFO - __main__ - Global step 300 Train loss 5.65 Classification-F1 0.0 on epoch=21
05/16/2022 11:19:40 - INFO - __main__ - Step 310 Global step 310 Train loss 5.68 on epoch=22
05/16/2022 11:19:42 - INFO - __main__ - Step 320 Global step 320 Train loss 5.59 on epoch=22
05/16/2022 11:19:43 - INFO - __main__ - Step 330 Global step 330 Train loss 5.46 on epoch=23
05/16/2022 11:19:44 - INFO - __main__ - Step 340 Global step 340 Train loss 5.33 on epoch=24
05/16/2022 11:19:46 - INFO - __main__ - Step 350 Global step 350 Train loss 5.45 on epoch=24
05/16/2022 11:20:37 - INFO - __main__ - Global step 350 Train loss 5.50 Classification-F1 0.0 on epoch=24
05/16/2022 11:20:38 - INFO - __main__ - Step 360 Global step 360 Train loss 5.41 on epoch=25
05/16/2022 11:20:39 - INFO - __main__ - Step 370 Global step 370 Train loss 5.35 on epoch=26
05/16/2022 11:20:41 - INFO - __main__ - Step 380 Global step 380 Train loss 5.19 on epoch=27
05/16/2022 11:20:42 - INFO - __main__ - Step 390 Global step 390 Train loss 5.38 on epoch=27
05/16/2022 11:20:43 - INFO - __main__ - Step 400 Global step 400 Train loss 5.19 on epoch=28
05/16/2022 11:20:47 - INFO - __main__ - Global step 400 Train loss 5.30 Classification-F1 0.0 on epoch=28
05/16/2022 11:20:49 - INFO - __main__ - Step 410 Global step 410 Train loss 4.96 on epoch=29
05/16/2022 11:20:50 - INFO - __main__ - Step 420 Global step 420 Train loss 5.19 on epoch=29
05/16/2022 11:20:51 - INFO - __main__ - Step 430 Global step 430 Train loss 5.30 on epoch=30
05/16/2022 11:20:53 - INFO - __main__ - Step 440 Global step 440 Train loss 5.04 on epoch=31
05/16/2022 11:20:54 - INFO - __main__ - Step 450 Global step 450 Train loss 4.98 on epoch=32
05/16/2022 11:21:02 - INFO - __main__ - Global step 450 Train loss 5.09 Classification-F1 0.0038940809968847356 on epoch=32
05/16/2022 11:21:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0038940809968847356 on epoch=32, global_step=450
05/16/2022 11:21:03 - INFO - __main__ - Step 460 Global step 460 Train loss 5.17 on epoch=32
05/16/2022 11:21:05 - INFO - __main__ - Step 470 Global step 470 Train loss 5.17 on epoch=33
05/16/2022 11:21:06 - INFO - __main__ - Step 480 Global step 480 Train loss 4.96 on epoch=34
05/16/2022 11:21:08 - INFO - __main__ - Step 490 Global step 490 Train loss 5.08 on epoch=34
05/16/2022 11:21:09 - INFO - __main__ - Step 500 Global step 500 Train loss 5.04 on epoch=35
05/16/2022 11:21:12 - INFO - __main__ - Global step 500 Train loss 5.08 Classification-F1 0.00847457627118644 on epoch=35
05/16/2022 11:21:12 - INFO - __main__ - Saving model with best Classification-F1: 0.0038940809968847356 -> 0.00847457627118644 on epoch=35, global_step=500
05/16/2022 11:21:13 - INFO - __main__ - Step 510 Global step 510 Train loss 4.84 on epoch=36
05/16/2022 11:21:15 - INFO - __main__ - Step 520 Global step 520 Train loss 4.78 on epoch=37
05/16/2022 11:21:16 - INFO - __main__ - Step 530 Global step 530 Train loss 4.79 on epoch=37
05/16/2022 11:21:17 - INFO - __main__ - Step 540 Global step 540 Train loss 4.70 on epoch=38
05/16/2022 11:21:18 - INFO - __main__ - Step 550 Global step 550 Train loss 4.67 on epoch=39
05/16/2022 11:21:32 - INFO - __main__ - Global step 550 Train loss 4.76 Classification-F1 0.00597524541186513 on epoch=39
05/16/2022 11:21:33 - INFO - __main__ - Step 560 Global step 560 Train loss 4.81 on epoch=39
05/16/2022 11:21:35 - INFO - __main__ - Step 570 Global step 570 Train loss 4.65 on epoch=40
05/16/2022 11:21:37 - INFO - __main__ - Step 580 Global step 580 Train loss 4.70 on epoch=41
05/16/2022 11:21:38 - INFO - __main__ - Step 590 Global step 590 Train loss 4.58 on epoch=42
05/16/2022 11:21:40 - INFO - __main__ - Step 600 Global step 600 Train loss 4.68 on epoch=42
05/16/2022 11:21:42 - INFO - __main__ - Global step 600 Train loss 4.68 Classification-F1 0.00892608089260809 on epoch=42
05/16/2022 11:21:42 - INFO - __main__ - Saving model with best Classification-F1: 0.00847457627118644 -> 0.00892608089260809 on epoch=42, global_step=600
05/16/2022 11:21:44 - INFO - __main__ - Step 610 Global step 610 Train loss 4.59 on epoch=43
05/16/2022 11:21:45 - INFO - __main__ - Step 620 Global step 620 Train loss 4.43 on epoch=44
05/16/2022 11:21:47 - INFO - __main__ - Step 630 Global step 630 Train loss 4.57 on epoch=44
05/16/2022 11:21:48 - INFO - __main__ - Step 640 Global step 640 Train loss 4.62 on epoch=45
05/16/2022 11:21:50 - INFO - __main__ - Step 650 Global step 650 Train loss 4.50 on epoch=46
05/16/2022 11:21:52 - INFO - __main__ - Global step 650 Train loss 4.54 Classification-F1 0.009523809523809523 on epoch=46
05/16/2022 11:21:52 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=46, global_step=650
05/16/2022 11:21:54 - INFO - __main__ - Step 660 Global step 660 Train loss 4.59 on epoch=47
05/16/2022 11:21:56 - INFO - __main__ - Step 670 Global step 670 Train loss 4.40 on epoch=47
05/16/2022 11:21:57 - INFO - __main__ - Step 680 Global step 680 Train loss 4.49 on epoch=48
05/16/2022 11:21:59 - INFO - __main__ - Step 690 Global step 690 Train loss 4.30 on epoch=49
05/16/2022 11:22:00 - INFO - __main__ - Step 700 Global step 700 Train loss 4.44 on epoch=49
05/16/2022 11:22:02 - INFO - __main__ - Global step 700 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=49
05/16/2022 11:22:04 - INFO - __main__ - Step 710 Global step 710 Train loss 4.39 on epoch=50
05/16/2022 11:22:06 - INFO - __main__ - Step 720 Global step 720 Train loss 4.30 on epoch=51
05/16/2022 11:22:07 - INFO - __main__ - Step 730 Global step 730 Train loss 4.30 on epoch=52
05/16/2022 11:22:09 - INFO - __main__ - Step 740 Global step 740 Train loss 4.28 on epoch=52
05/16/2022 11:22:11 - INFO - __main__ - Step 750 Global step 750 Train loss 4.31 on epoch=53
05/16/2022 11:22:13 - INFO - __main__ - Global step 750 Train loss 4.31 Classification-F1 0.009523809523809523 on epoch=53
05/16/2022 11:22:14 - INFO - __main__ - Step 760 Global step 760 Train loss 4.17 on epoch=54
05/16/2022 11:22:16 - INFO - __main__ - Step 770 Global step 770 Train loss 4.21 on epoch=54
05/16/2022 11:22:18 - INFO - __main__ - Step 780 Global step 780 Train loss 4.35 on epoch=55
05/16/2022 11:22:19 - INFO - __main__ - Step 790 Global step 790 Train loss 4.16 on epoch=56
05/16/2022 11:22:21 - INFO - __main__ - Step 800 Global step 800 Train loss 4.04 on epoch=57
05/16/2022 11:22:23 - INFO - __main__ - Global step 800 Train loss 4.19 Classification-F1 0.009563658099222952 on epoch=57
05/16/2022 11:22:23 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009563658099222952 on epoch=57, global_step=800
05/16/2022 11:22:24 - INFO - __main__ - Step 810 Global step 810 Train loss 4.17 on epoch=57
05/16/2022 11:22:26 - INFO - __main__ - Step 820 Global step 820 Train loss 4.23 on epoch=58
05/16/2022 11:22:27 - INFO - __main__ - Step 830 Global step 830 Train loss 4.04 on epoch=59
05/16/2022 11:22:29 - INFO - __main__ - Step 840 Global step 840 Train loss 4.04 on epoch=59
05/16/2022 11:22:30 - INFO - __main__ - Step 850 Global step 850 Train loss 4.16 on epoch=60
05/16/2022 11:22:32 - INFO - __main__ - Global step 850 Train loss 4.13 Classification-F1 0.01540799189614267 on epoch=60
05/16/2022 11:22:32 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.01540799189614267 on epoch=60, global_step=850
05/16/2022 11:22:34 - INFO - __main__ - Step 860 Global step 860 Train loss 3.96 on epoch=61
05/16/2022 11:22:36 - INFO - __main__ - Step 870 Global step 870 Train loss 3.95 on epoch=62
05/16/2022 11:22:37 - INFO - __main__ - Step 880 Global step 880 Train loss 3.88 on epoch=62
05/16/2022 11:22:38 - INFO - __main__ - Step 890 Global step 890 Train loss 4.08 on epoch=63
05/16/2022 11:22:40 - INFO - __main__ - Step 900 Global step 900 Train loss 3.90 on epoch=64
05/16/2022 11:22:42 - INFO - __main__ - Global step 900 Train loss 3.96 Classification-F1 0.025388637400428116 on epoch=64
05/16/2022 11:22:42 - INFO - __main__ - Saving model with best Classification-F1: 0.01540799189614267 -> 0.025388637400428116 on epoch=64, global_step=900
05/16/2022 11:22:43 - INFO - __main__ - Step 910 Global step 910 Train loss 3.79 on epoch=64
05/16/2022 11:22:44 - INFO - __main__ - Step 920 Global step 920 Train loss 4.00 on epoch=65
05/16/2022 11:22:46 - INFO - __main__ - Step 930 Global step 930 Train loss 3.85 on epoch=66
05/16/2022 11:22:47 - INFO - __main__ - Step 940 Global step 940 Train loss 3.82 on epoch=67
05/16/2022 11:22:49 - INFO - __main__ - Step 950 Global step 950 Train loss 3.91 on epoch=67
05/16/2022 11:22:51 - INFO - __main__ - Global step 950 Train loss 3.87 Classification-F1 0.032004429678848284 on epoch=67
05/16/2022 11:22:51 - INFO - __main__ - Saving model with best Classification-F1: 0.025388637400428116 -> 0.032004429678848284 on epoch=67, global_step=950
05/16/2022 11:22:52 - INFO - __main__ - Step 960 Global step 960 Train loss 3.80 on epoch=68
05/16/2022 11:22:53 - INFO - __main__ - Step 970 Global step 970 Train loss 3.60 on epoch=69
05/16/2022 11:22:55 - INFO - __main__ - Step 980 Global step 980 Train loss 3.83 on epoch=69
05/16/2022 11:22:56 - INFO - __main__ - Step 990 Global step 990 Train loss 3.90 on epoch=70
05/16/2022 11:22:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.46 on epoch=71
05/16/2022 11:22:59 - INFO - __main__ - Global step 1000 Train loss 3.72 Classification-F1 0.016692785828740474 on epoch=71
05/16/2022 11:23:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.71 on epoch=72
05/16/2022 11:23:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.72 on epoch=72
05/16/2022 11:23:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.69 on epoch=73
05/16/2022 11:23:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.60 on epoch=74
05/16/2022 11:23:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.62 on epoch=74
05/16/2022 11:23:08 - INFO - __main__ - Global step 1050 Train loss 3.67 Classification-F1 0.03493897559023609 on epoch=74
05/16/2022 11:23:08 - INFO - __main__ - Saving model with best Classification-F1: 0.032004429678848284 -> 0.03493897559023609 on epoch=74, global_step=1050
05/16/2022 11:23:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.70 on epoch=75
05/16/2022 11:23:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.43 on epoch=76
05/16/2022 11:23:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.79 on epoch=77
05/16/2022 11:23:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.58 on epoch=77
05/16/2022 11:23:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.66 on epoch=78
05/16/2022 11:23:17 - INFO - __main__ - Global step 1100 Train loss 3.63 Classification-F1 0.017377860235003092 on epoch=78
05/16/2022 11:23:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.37 on epoch=79
05/16/2022 11:23:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.46 on epoch=79
05/16/2022 11:23:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.49 on epoch=80
05/16/2022 11:23:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.34 on epoch=81
05/16/2022 11:23:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.29 on epoch=82
05/16/2022 11:23:25 - INFO - __main__ - Global step 1150 Train loss 3.39 Classification-F1 0.021957671957671957 on epoch=82
05/16/2022 11:23:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.54 on epoch=82
05/16/2022 11:23:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.48 on epoch=83
05/16/2022 11:23:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.32 on epoch=84
05/16/2022 11:23:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.27 on epoch=84
05/16/2022 11:23:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.48 on epoch=85
05/16/2022 11:23:34 - INFO - __main__ - Global step 1200 Train loss 3.42 Classification-F1 0.012877180575200375 on epoch=85
05/16/2022 11:23:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.51 on epoch=86
05/16/2022 11:23:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.41 on epoch=87
05/16/2022 11:23:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.40 on epoch=87
05/16/2022 11:23:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.31 on epoch=88
05/16/2022 11:23:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.21 on epoch=89
05/16/2022 11:23:43 - INFO - __main__ - Global step 1250 Train loss 3.37 Classification-F1 0.031569494335451774 on epoch=89
05/16/2022 11:23:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.17 on epoch=89
05/16/2022 11:23:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.32 on epoch=90
05/16/2022 11:23:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.20 on epoch=91
05/16/2022 11:23:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.25 on epoch=92
05/16/2022 11:23:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.27 on epoch=92
05/16/2022 11:23:52 - INFO - __main__ - Global step 1300 Train loss 3.24 Classification-F1 0.04141254202830558 on epoch=92
05/16/2022 11:23:52 - INFO - __main__ - Saving model with best Classification-F1: 0.03493897559023609 -> 0.04141254202830558 on epoch=92, global_step=1300
05/16/2022 11:23:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.15 on epoch=93
05/16/2022 11:23:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.26 on epoch=94
05/16/2022 11:23:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.15 on epoch=94
05/16/2022 11:23:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.34 on epoch=95
05/16/2022 11:23:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.05 on epoch=96
05/16/2022 11:24:01 - INFO - __main__ - Global step 1350 Train loss 3.19 Classification-F1 0.017552515511699188 on epoch=96
05/16/2022 11:24:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.03 on epoch=97
05/16/2022 11:24:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.10 on epoch=97
05/16/2022 11:24:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.97 on epoch=98
05/16/2022 11:24:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.11 on epoch=99
05/16/2022 11:24:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.11 on epoch=99
05/16/2022 11:24:09 - INFO - __main__ - Global step 1400 Train loss 3.06 Classification-F1 0.047930038156995085 on epoch=99
05/16/2022 11:24:09 - INFO - __main__ - Saving model with best Classification-F1: 0.04141254202830558 -> 0.047930038156995085 on epoch=99, global_step=1400
05/16/2022 11:24:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.19 on epoch=100
05/16/2022 11:24:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.91 on epoch=101
05/16/2022 11:24:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.99 on epoch=102
05/16/2022 11:24:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.02 on epoch=102
05/16/2022 11:24:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.01 on epoch=103
05/16/2022 11:24:18 - INFO - __main__ - Global step 1450 Train loss 3.02 Classification-F1 0.02766318411794775 on epoch=103
05/16/2022 11:24:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.03 on epoch=104
05/16/2022 11:24:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.88 on epoch=104
05/16/2022 11:24:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.11 on epoch=105
05/16/2022 11:24:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.88 on epoch=106
05/16/2022 11:24:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.99 on epoch=107
05/16/2022 11:24:27 - INFO - __main__ - Global step 1500 Train loss 2.98 Classification-F1 0.05494765281999324 on epoch=107
05/16/2022 11:24:27 - INFO - __main__ - Saving model with best Classification-F1: 0.047930038156995085 -> 0.05494765281999324 on epoch=107, global_step=1500
05/16/2022 11:24:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.06 on epoch=107
05/16/2022 11:24:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.04 on epoch=108
05/16/2022 11:24:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.83 on epoch=109
05/16/2022 11:24:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.93 on epoch=109
05/16/2022 11:24:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.07 on epoch=110
05/16/2022 11:24:36 - INFO - __main__ - Global step 1550 Train loss 2.99 Classification-F1 0.03438228438228438 on epoch=110
05/16/2022 11:24:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.99 on epoch=111
05/16/2022 11:24:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.98 on epoch=112
05/16/2022 11:24:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.86 on epoch=112
05/16/2022 11:24:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.87 on epoch=113
05/16/2022 11:24:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.89 on epoch=114
05/16/2022 11:24:45 - INFO - __main__ - Global step 1600 Train loss 2.92 Classification-F1 0.04339544513457557 on epoch=114
05/16/2022 11:24:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.88 on epoch=114
05/16/2022 11:24:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.05 on epoch=115
05/16/2022 11:24:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.87 on epoch=116
05/16/2022 11:24:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.99 on epoch=117
05/16/2022 11:24:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.90 on epoch=117
05/16/2022 11:24:54 - INFO - __main__ - Global step 1650 Train loss 2.94 Classification-F1 0.033651672694394216 on epoch=117
05/16/2022 11:24:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.93 on epoch=118
05/16/2022 11:24:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.91 on epoch=119
05/16/2022 11:24:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.81 on epoch=119
05/16/2022 11:25:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.91 on epoch=120
05/16/2022 11:25:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.74 on epoch=121
05/16/2022 11:25:03 - INFO - __main__ - Global step 1700 Train loss 2.86 Classification-F1 0.048099280382744955 on epoch=121
05/16/2022 11:25:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.85 on epoch=122
05/16/2022 11:25:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.76 on epoch=122
05/16/2022 11:25:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.77 on epoch=123
05/16/2022 11:25:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.79 on epoch=124
05/16/2022 11:25:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.84 on epoch=124
05/16/2022 11:25:12 - INFO - __main__ - Global step 1750 Train loss 2.80 Classification-F1 0.04834505634566592 on epoch=124
05/16/2022 11:25:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.04 on epoch=125
05/16/2022 11:25:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.79 on epoch=126
05/16/2022 11:25:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.82 on epoch=127
05/16/2022 11:25:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.78 on epoch=127
05/16/2022 11:25:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.89 on epoch=128
05/16/2022 11:25:21 - INFO - __main__ - Global step 1800 Train loss 2.86 Classification-F1 0.04475408520150356 on epoch=128
05/16/2022 11:25:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.71 on epoch=129
05/16/2022 11:25:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.77 on epoch=129
05/16/2022 11:25:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.76 on epoch=130
05/16/2022 11:25:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.82 on epoch=131
05/16/2022 11:25:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.82 on epoch=132
05/16/2022 11:25:32 - INFO - __main__ - Global step 1850 Train loss 2.78 Classification-F1 0.02227791701475912 on epoch=132
05/16/2022 11:25:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.73 on epoch=132
05/16/2022 11:25:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.84 on epoch=133
05/16/2022 11:25:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.68 on epoch=134
05/16/2022 11:25:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.64 on epoch=134
05/16/2022 11:25:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.83 on epoch=135
05/16/2022 11:25:42 - INFO - __main__ - Global step 1900 Train loss 2.75 Classification-F1 0.009644364074743823 on epoch=135
05/16/2022 11:25:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.65 on epoch=136
05/16/2022 11:25:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.81 on epoch=137
05/16/2022 11:25:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.74 on epoch=137
05/16/2022 11:25:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.75 on epoch=138
05/16/2022 11:25:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.66 on epoch=139
05/16/2022 11:25:52 - INFO - __main__ - Global step 1950 Train loss 2.72 Classification-F1 0.03380307635626784 on epoch=139
05/16/2022 11:25:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.73 on epoch=139
05/16/2022 11:25:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.69 on epoch=140
05/16/2022 11:25:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.51 on epoch=141
05/16/2022 11:25:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.60 on epoch=142
05/16/2022 11:25:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.53 on epoch=142
05/16/2022 11:26:01 - INFO - __main__ - Global step 2000 Train loss 2.61 Classification-F1 0.009523809523809523 on epoch=142
05/16/2022 11:26:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.70 on epoch=143
05/16/2022 11:26:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.73 on epoch=144
05/16/2022 11:26:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.64 on epoch=144
05/16/2022 11:26:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.71 on epoch=145
05/16/2022 11:26:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.61 on epoch=146
05/16/2022 11:26:10 - INFO - __main__ - Global step 2050 Train loss 2.68 Classification-F1 0.009235209235209235 on epoch=146
05/16/2022 11:26:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.52 on epoch=147
05/16/2022 11:26:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.70 on epoch=147
05/16/2022 11:26:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.49 on epoch=148
05/16/2022 11:26:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.66 on epoch=149
05/16/2022 11:26:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.56 on epoch=149
05/16/2022 11:26:19 - INFO - __main__ - Global step 2100 Train loss 2.59 Classification-F1 0.009563658099222952 on epoch=149
05/16/2022 11:26:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.53 on epoch=150
05/16/2022 11:26:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.46 on epoch=151
05/16/2022 11:26:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.65 on epoch=152
05/16/2022 11:26:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.59 on epoch=152
05/16/2022 11:26:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.78 on epoch=153
05/16/2022 11:26:29 - INFO - __main__ - Global step 2150 Train loss 2.60 Classification-F1 0.009001406469760902 on epoch=153
05/16/2022 11:26:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.53 on epoch=154
05/16/2022 11:26:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.52 on epoch=154
05/16/2022 11:26:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.60 on epoch=155
05/16/2022 11:26:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.43 on epoch=156
05/16/2022 11:26:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.61 on epoch=157
05/16/2022 11:26:37 - INFO - __main__ - Global step 2200 Train loss 2.54 Classification-F1 0.009563658099222952 on epoch=157
05/16/2022 11:26:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.53 on epoch=157
05/16/2022 11:26:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.58 on epoch=158
05/16/2022 11:26:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.55 on epoch=159
05/16/2022 11:26:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.47 on epoch=159
05/16/2022 11:26:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.49 on epoch=160
05/16/2022 11:26:46 - INFO - __main__ - Global step 2250 Train loss 2.52 Classification-F1 0.0435077890805445 on epoch=160
05/16/2022 11:26:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.40 on epoch=161
05/16/2022 11:26:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.54 on epoch=162
05/16/2022 11:26:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.35 on epoch=162
05/16/2022 11:26:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.62 on epoch=163
05/16/2022 11:26:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.44 on epoch=164
05/16/2022 11:26:55 - INFO - __main__ - Global step 2300 Train loss 2.47 Classification-F1 0.01762173796072101 on epoch=164
05/16/2022 11:26:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.52 on epoch=164
05/16/2022 11:26:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.54 on epoch=165
05/16/2022 11:26:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.55 on epoch=166
05/16/2022 11:27:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.72 on epoch=167
05/16/2022 11:27:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.46 on epoch=167
05/16/2022 11:27:04 - INFO - __main__ - Global step 2350 Train loss 2.56 Classification-F1 0.009523809523809523 on epoch=167
05/16/2022 11:27:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.50 on epoch=168
05/16/2022 11:27:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.50 on epoch=169
05/16/2022 11:27:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.41 on epoch=169
05/16/2022 11:27:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.55 on epoch=170
05/16/2022 11:27:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.40 on epoch=171
05/16/2022 11:27:13 - INFO - __main__ - Global step 2400 Train loss 2.47 Classification-F1 0.04017250333039807 on epoch=171
05/16/2022 11:27:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.39 on epoch=172
05/16/2022 11:27:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.44 on epoch=172
05/16/2022 11:27:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.47 on epoch=173
05/16/2022 11:27:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.42 on epoch=174
05/16/2022 11:27:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.48 on epoch=174
05/16/2022 11:27:22 - INFO - __main__ - Global step 2450 Train loss 2.44 Classification-F1 0.061464262142871484 on epoch=174
05/16/2022 11:27:22 - INFO - __main__ - Saving model with best Classification-F1: 0.05494765281999324 -> 0.061464262142871484 on epoch=174, global_step=2450
05/16/2022 11:27:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.49 on epoch=175
05/16/2022 11:27:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.40 on epoch=176
05/16/2022 11:27:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.44 on epoch=177
05/16/2022 11:27:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.29 on epoch=177
05/16/2022 11:27:29 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.47 on epoch=178
05/16/2022 11:27:31 - INFO - __main__ - Global step 2500 Train loss 2.42 Classification-F1 0.04415255463887683 on epoch=178
05/16/2022 11:27:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.52 on epoch=179
05/16/2022 11:27:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.44 on epoch=179
05/16/2022 11:27:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.42 on epoch=180
05/16/2022 11:27:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.32 on epoch=181
05/16/2022 11:27:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.35 on epoch=182
05/16/2022 11:27:40 - INFO - __main__ - Global step 2550 Train loss 2.41 Classification-F1 0.009563658099222952 on epoch=182
05/16/2022 11:27:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.28 on epoch=182
05/16/2022 11:27:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.30 on epoch=183
05/16/2022 11:27:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.32 on epoch=184
05/16/2022 11:27:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.39 on epoch=184
05/16/2022 11:27:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.38 on epoch=185
05/16/2022 11:27:50 - INFO - __main__ - Global step 2600 Train loss 2.34 Classification-F1 0.02801300538217087 on epoch=185
05/16/2022 11:27:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.36 on epoch=186
05/16/2022 11:27:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.34 on epoch=187
05/16/2022 11:27:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.44 on epoch=187
05/16/2022 11:27:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.59 on epoch=188
05/16/2022 11:27:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.37 on epoch=189
05/16/2022 11:28:00 - INFO - __main__ - Global step 2650 Train loss 2.42 Classification-F1 0.03751951344398237 on epoch=189
05/16/2022 11:28:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.31 on epoch=189
05/16/2022 11:28:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.29 on epoch=190
05/16/2022 11:28:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.28 on epoch=191
05/16/2022 11:28:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.45 on epoch=192
05/16/2022 11:28:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.28 on epoch=192
05/16/2022 11:28:08 - INFO - __main__ - Global step 2700 Train loss 2.32 Classification-F1 0.018255578093306284 on epoch=192
05/16/2022 11:28:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.34 on epoch=193
05/16/2022 11:28:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.30 on epoch=194
05/16/2022 11:28:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.46 on epoch=194
05/16/2022 11:28:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.39 on epoch=195
05/16/2022 11:28:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.15 on epoch=196
05/16/2022 11:28:17 - INFO - __main__ - Global step 2750 Train loss 2.33 Classification-F1 0.04852607709750567 on epoch=196
05/16/2022 11:28:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.31 on epoch=197
05/16/2022 11:28:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.27 on epoch=197
05/16/2022 11:28:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.37 on epoch=198
05/16/2022 11:28:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.26 on epoch=199
05/16/2022 11:28:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.25 on epoch=199
05/16/2022 11:28:27 - INFO - __main__ - Global step 2800 Train loss 2.29 Classification-F1 0.026835822210475306 on epoch=199
05/16/2022 11:28:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.37 on epoch=200
05/16/2022 11:28:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.21 on epoch=201
05/16/2022 11:28:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.33 on epoch=202
05/16/2022 11:28:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.21 on epoch=202
05/16/2022 11:28:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.24 on epoch=203
05/16/2022 11:28:37 - INFO - __main__ - Global step 2850 Train loss 2.27 Classification-F1 0.028522039757994815 on epoch=203
05/16/2022 11:28:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.11 on epoch=204
05/16/2022 11:28:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.29 on epoch=204
05/16/2022 11:28:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.26 on epoch=205
05/16/2022 11:28:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.09 on epoch=206
05/16/2022 11:28:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.22 on epoch=207
05/16/2022 11:28:46 - INFO - __main__ - Global step 2900 Train loss 2.19 Classification-F1 0.030750761843198814 on epoch=207
05/16/2022 11:28:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.22 on epoch=207
05/16/2022 11:28:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.33 on epoch=208
05/16/2022 11:28:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.04 on epoch=209
05/16/2022 11:28:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.24 on epoch=209
05/16/2022 11:28:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.19 on epoch=210
05/16/2022 11:28:55 - INFO - __main__ - Global step 2950 Train loss 2.20 Classification-F1 0.03557417736382803 on epoch=210
05/16/2022 11:28:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.16 on epoch=211
05/16/2022 11:28:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.23 on epoch=212
05/16/2022 11:28:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.29 on epoch=212
05/16/2022 11:29:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.25 on epoch=213
05/16/2022 11:29:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.17 on epoch=214
05/16/2022 11:29:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:29:03 - INFO - __main__ - Printing 3 examples
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 11:29:03 - INFO - __main__ - ['Film']
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 11:29:03 - INFO - __main__ - ['Film']
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 11:29:03 - INFO - __main__ - ['Film']
05/16/2022 11:29:03 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:29:03 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:29:03 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 11:29:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:29:03 - INFO - __main__ - Printing 3 examples
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 11:29:03 - INFO - __main__ - ['Film']
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 11:29:03 - INFO - __main__ - ['Film']
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 11:29:03 - INFO - __main__ - ['Film']
05/16/2022 11:29:03 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:29:03 - INFO - __main__ - Global step 3000 Train loss 2.22 Classification-F1 0.032851719521665414 on epoch=214
05/16/2022 11:29:03 - INFO - __main__ - save last model!
05/16/2022 11:29:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 11:29:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 11:29:03 - INFO - __main__ - Printing 3 examples
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 11:29:03 - INFO - __main__ - ['Animal']
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 11:29:03 - INFO - __main__ - ['Animal']
05/16/2022 11:29:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 11:29:03 - INFO - __main__ - ['Village']
05/16/2022 11:29:03 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:29:03 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:29:04 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 11:29:05 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:29:09 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 11:29:09 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 11:29:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 11:29:09 - INFO - __main__ - Starting training!
05/16/2022 11:29:39 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/16/2022 11:29:39 - INFO - __main__ - Classification-F1 on test data: 0.0347
05/16/2022 11:29:39 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.061464262142871484, test_performance=0.0346654571503911
05/16/2022 11:29:39 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/16/2022 11:29:40 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:29:40 - INFO - __main__ - Printing 3 examples
05/16/2022 11:29:40 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/16/2022 11:29:40 - INFO - __main__ - ['Film']
05/16/2022 11:29:40 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/16/2022 11:29:40 - INFO - __main__ - ['Film']
05/16/2022 11:29:40 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/16/2022 11:29:40 - INFO - __main__ - ['Film']
05/16/2022 11:29:40 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:29:40 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:29:40 - INFO - __main__ - Loaded 224 examples from train data
05/16/2022 11:29:40 - INFO - __main__ - Start tokenizing ... 224 instances
05/16/2022 11:29:40 - INFO - __main__ - Printing 3 examples
05/16/2022 11:29:40 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/16/2022 11:29:40 - INFO - __main__ - ['Film']
05/16/2022 11:29:40 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/16/2022 11:29:40 - INFO - __main__ - ['Film']
05/16/2022 11:29:40 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/16/2022 11:29:40 - INFO - __main__ - ['Film']
05/16/2022 11:29:40 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:29:40 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:29:41 - INFO - __main__ - Loaded 224 examples from dev data
05/16/2022 11:29:46 - INFO - __main__ - load prompt embedding from ckpt
05/16/2022 11:29:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/16/2022 11:29:47 - INFO - __main__ - Starting training!
05/16/2022 11:29:50 - INFO - __main__ - Step 10 Global step 10 Train loss 7.40 on epoch=0
05/16/2022 11:29:52 - INFO - __main__ - Step 20 Global step 20 Train loss 7.44 on epoch=1
05/16/2022 11:29:53 - INFO - __main__ - Step 30 Global step 30 Train loss 7.14 on epoch=2
05/16/2022 11:29:55 - INFO - __main__ - Step 40 Global step 40 Train loss 7.24 on epoch=2
05/16/2022 11:29:56 - INFO - __main__ - Step 50 Global step 50 Train loss 7.14 on epoch=3
05/16/2022 11:30:08 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/16/2022 11:30:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/16/2022 11:30:10 - INFO - __main__ - Step 60 Global step 60 Train loss 6.87 on epoch=4
05/16/2022 11:30:11 - INFO - __main__ - Step 70 Global step 70 Train loss 7.23 on epoch=4
05/16/2022 11:30:12 - INFO - __main__ - Step 80 Global step 80 Train loss 6.86 on epoch=5
05/16/2022 11:30:14 - INFO - __main__ - Step 90 Global step 90 Train loss 6.93 on epoch=6
05/16/2022 11:30:15 - INFO - __main__ - Step 100 Global step 100 Train loss 6.70 on epoch=7
05/16/2022 11:30:59 - INFO - __main__ - Global step 100 Train loss 6.92 Classification-F1 0.0 on epoch=7
05/16/2022 11:31:00 - INFO - __main__ - Step 110 Global step 110 Train loss 6.77 on epoch=7
05/16/2022 11:31:01 - INFO - __main__ - Step 120 Global step 120 Train loss 6.57 on epoch=8
05/16/2022 11:31:03 - INFO - __main__ - Step 130 Global step 130 Train loss 6.61 on epoch=9
05/16/2022 11:31:04 - INFO - __main__ - Step 140 Global step 140 Train loss 6.74 on epoch=9
05/16/2022 11:31:05 - INFO - __main__ - Step 150 Global step 150 Train loss 6.56 on epoch=10
05/16/2022 11:32:06 - INFO - __main__ - Global step 150 Train loss 6.65 Classification-F1 0.0 on epoch=10
05/16/2022 11:32:07 - INFO - __main__ - Step 160 Global step 160 Train loss 6.67 on epoch=11
05/16/2022 11:32:09 - INFO - __main__ - Step 170 Global step 170 Train loss 6.57 on epoch=12
05/16/2022 11:32:10 - INFO - __main__ - Step 180 Global step 180 Train loss 6.67 on epoch=12
05/16/2022 11:32:11 - INFO - __main__ - Step 190 Global step 190 Train loss 6.40 on epoch=13
05/16/2022 11:32:13 - INFO - __main__ - Step 200 Global step 200 Train loss 6.33 on epoch=14
05/16/2022 11:33:20 - INFO - __main__ - Global step 200 Train loss 6.53 Classification-F1 0.0 on epoch=14
05/16/2022 11:33:21 - INFO - __main__ - Step 210 Global step 210 Train loss 6.54 on epoch=14
05/16/2022 11:33:22 - INFO - __main__ - Step 220 Global step 220 Train loss 6.45 on epoch=15
05/16/2022 11:33:24 - INFO - __main__ - Step 230 Global step 230 Train loss 6.30 on epoch=16
05/16/2022 11:33:25 - INFO - __main__ - Step 240 Global step 240 Train loss 6.22 on epoch=17
05/16/2022 11:33:26 - INFO - __main__ - Step 250 Global step 250 Train loss 6.47 on epoch=17
05/16/2022 11:34:24 - INFO - __main__ - Global step 250 Train loss 6.39 Classification-F1 0.0 on epoch=17
05/16/2022 11:34:26 - INFO - __main__ - Step 260 Global step 260 Train loss 6.30 on epoch=18
05/16/2022 11:34:27 - INFO - __main__ - Step 270 Global step 270 Train loss 6.17 on epoch=19
05/16/2022 11:34:28 - INFO - __main__ - Step 280 Global step 280 Train loss 6.35 on epoch=19
05/16/2022 11:34:30 - INFO - __main__ - Step 290 Global step 290 Train loss 6.19 on epoch=20
05/16/2022 11:34:31 - INFO - __main__ - Step 300 Global step 300 Train loss 6.28 on epoch=21
05/16/2022 11:35:43 - INFO - __main__ - Global step 300 Train loss 6.26 Classification-F1 0.0 on epoch=21
05/16/2022 11:35:45 - INFO - __main__ - Step 310 Global step 310 Train loss 6.17 on epoch=22
05/16/2022 11:35:46 - INFO - __main__ - Step 320 Global step 320 Train loss 6.27 on epoch=22
05/16/2022 11:35:48 - INFO - __main__ - Step 330 Global step 330 Train loss 6.14 on epoch=23
05/16/2022 11:35:49 - INFO - __main__ - Step 340 Global step 340 Train loss 5.99 on epoch=24
05/16/2022 11:35:50 - INFO - __main__ - Step 350 Global step 350 Train loss 6.21 on epoch=24
05/16/2022 11:37:00 - INFO - __main__ - Global step 350 Train loss 6.16 Classification-F1 0.0 on epoch=24
05/16/2022 11:37:01 - INFO - __main__ - Step 360 Global step 360 Train loss 6.03 on epoch=25
05/16/2022 11:37:03 - INFO - __main__ - Step 370 Global step 370 Train loss 6.07 on epoch=26
05/16/2022 11:37:04 - INFO - __main__ - Step 380 Global step 380 Train loss 5.89 on epoch=27
05/16/2022 11:37:06 - INFO - __main__ - Step 390 Global step 390 Train loss 5.97 on epoch=27
05/16/2022 11:37:07 - INFO - __main__ - Step 400 Global step 400 Train loss 5.79 on epoch=28
05/16/2022 11:38:19 - INFO - __main__ - Global step 400 Train loss 5.95 Classification-F1 0.0 on epoch=28
05/16/2022 11:38:21 - INFO - __main__ - Step 410 Global step 410 Train loss 5.85 on epoch=29
05/16/2022 11:38:22 - INFO - __main__ - Step 420 Global step 420 Train loss 6.00 on epoch=29
05/16/2022 11:38:23 - INFO - __main__ - Step 430 Global step 430 Train loss 5.83 on epoch=30
05/16/2022 11:38:25 - INFO - __main__ - Step 440 Global step 440 Train loss 5.80 on epoch=31
05/16/2022 11:38:26 - INFO - __main__ - Step 450 Global step 450 Train loss 5.67 on epoch=32
05/16/2022 11:39:22 - INFO - __main__ - Global step 450 Train loss 5.83 Classification-F1 0.0 on epoch=32
05/16/2022 11:39:24 - INFO - __main__ - Step 460 Global step 460 Train loss 5.74 on epoch=32
05/16/2022 11:39:25 - INFO - __main__ - Step 470 Global step 470 Train loss 5.61 on epoch=33
05/16/2022 11:39:26 - INFO - __main__ - Step 480 Global step 480 Train loss 5.54 on epoch=34
05/16/2022 11:39:28 - INFO - __main__ - Step 490 Global step 490 Train loss 5.72 on epoch=34
05/16/2022 11:39:29 - INFO - __main__ - Step 500 Global step 500 Train loss 5.58 on epoch=35
05/16/2022 11:40:03 - INFO - __main__ - Global step 500 Train loss 5.64 Classification-F1 0.0019230769230769232 on epoch=35
05/16/2022 11:40:03 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0019230769230769232 on epoch=35, global_step=500
05/16/2022 11:40:04 - INFO - __main__ - Step 510 Global step 510 Train loss 5.59 on epoch=36
05/16/2022 11:40:06 - INFO - __main__ - Step 520 Global step 520 Train loss 5.54 on epoch=37
05/16/2022 11:40:07 - INFO - __main__ - Step 530 Global step 530 Train loss 5.57 on epoch=37
05/16/2022 11:40:08 - INFO - __main__ - Step 540 Global step 540 Train loss 5.40 on epoch=38
05/16/2022 11:40:10 - INFO - __main__ - Step 550 Global step 550 Train loss 5.38 on epoch=39
05/16/2022 11:40:36 - INFO - __main__ - Global step 550 Train loss 5.50 Classification-F1 0.003961516694963214 on epoch=39
05/16/2022 11:40:36 - INFO - __main__ - Saving model with best Classification-F1: 0.0019230769230769232 -> 0.003961516694963214 on epoch=39, global_step=550
05/16/2022 11:40:38 - INFO - __main__ - Step 560 Global step 560 Train loss 5.50 on epoch=39
05/16/2022 11:40:39 - INFO - __main__ - Step 570 Global step 570 Train loss 5.49 on epoch=40
05/16/2022 11:40:40 - INFO - __main__ - Step 580 Global step 580 Train loss 5.35 on epoch=41
05/16/2022 11:40:42 - INFO - __main__ - Step 590 Global step 590 Train loss 5.28 on epoch=42
05/16/2022 11:40:43 - INFO - __main__ - Step 600 Global step 600 Train loss 5.47 on epoch=42
05/16/2022 11:41:10 - INFO - __main__ - Global step 600 Train loss 5.42 Classification-F1 0.0026262036766851473 on epoch=42
05/16/2022 11:41:11 - INFO - __main__ - Step 610 Global step 610 Train loss 5.28 on epoch=43
05/16/2022 11:41:12 - INFO - __main__ - Step 620 Global step 620 Train loss 5.16 on epoch=44
05/16/2022 11:41:14 - INFO - __main__ - Step 630 Global step 630 Train loss 5.38 on epoch=44
05/16/2022 11:41:15 - INFO - __main__ - Step 640 Global step 640 Train loss 5.25 on epoch=45
05/16/2022 11:41:16 - INFO - __main__ - Step 650 Global step 650 Train loss 5.30 on epoch=46
05/16/2022 11:41:44 - INFO - __main__ - Global step 650 Train loss 5.27 Classification-F1 0.004222972972972973 on epoch=46
05/16/2022 11:41:44 - INFO - __main__ - Saving model with best Classification-F1: 0.003961516694963214 -> 0.004222972972972973 on epoch=46, global_step=650
05/16/2022 11:41:46 - INFO - __main__ - Step 660 Global step 660 Train loss 5.30 on epoch=47
05/16/2022 11:41:47 - INFO - __main__ - Step 670 Global step 670 Train loss 5.32 on epoch=47
05/16/2022 11:41:48 - INFO - __main__ - Step 680 Global step 680 Train loss 5.22 on epoch=48
05/16/2022 11:41:50 - INFO - __main__ - Step 690 Global step 690 Train loss 5.12 on epoch=49
05/16/2022 11:41:51 - INFO - __main__ - Step 700 Global step 700 Train loss 5.16 on epoch=49
05/16/2022 11:41:55 - INFO - __main__ - Global step 700 Train loss 5.22 Classification-F1 0.0071225071225071235 on epoch=49
05/16/2022 11:41:55 - INFO - __main__ - Saving model with best Classification-F1: 0.004222972972972973 -> 0.0071225071225071235 on epoch=49, global_step=700
05/16/2022 11:41:56 - INFO - __main__ - Step 710 Global step 710 Train loss 5.11 on epoch=50
05/16/2022 11:41:58 - INFO - __main__ - Step 720 Global step 720 Train loss 5.11 on epoch=51
05/16/2022 11:41:59 - INFO - __main__ - Step 730 Global step 730 Train loss 5.13 on epoch=52
05/16/2022 11:42:00 - INFO - __main__ - Step 740 Global step 740 Train loss 5.12 on epoch=52
05/16/2022 11:42:02 - INFO - __main__ - Step 750 Global step 750 Train loss 5.01 on epoch=53
05/16/2022 11:42:04 - INFO - __main__ - Global step 750 Train loss 5.10 Classification-F1 0.009523809523809523 on epoch=53
05/16/2022 11:42:04 - INFO - __main__ - Saving model with best Classification-F1: 0.0071225071225071235 -> 0.009523809523809523 on epoch=53, global_step=750
05/16/2022 11:42:06 - INFO - __main__ - Step 760 Global step 760 Train loss 4.95 on epoch=54
05/16/2022 11:42:07 - INFO - __main__ - Step 770 Global step 770 Train loss 5.02 on epoch=54
05/16/2022 11:42:08 - INFO - __main__ - Step 780 Global step 780 Train loss 5.04 on epoch=55
05/16/2022 11:42:10 - INFO - __main__ - Step 790 Global step 790 Train loss 4.93 on epoch=56
05/16/2022 11:42:11 - INFO - __main__ - Step 800 Global step 800 Train loss 4.91 on epoch=57
05/16/2022 11:42:14 - INFO - __main__ - Global step 800 Train loss 4.97 Classification-F1 0.009523809523809523 on epoch=57
05/16/2022 11:42:15 - INFO - __main__ - Step 810 Global step 810 Train loss 4.95 on epoch=57
05/16/2022 11:42:16 - INFO - __main__ - Step 820 Global step 820 Train loss 4.89 on epoch=58
05/16/2022 11:42:18 - INFO - __main__ - Step 830 Global step 830 Train loss 4.81 on epoch=59
05/16/2022 11:42:19 - INFO - __main__ - Step 840 Global step 840 Train loss 4.93 on epoch=59
05/16/2022 11:42:21 - INFO - __main__ - Step 850 Global step 850 Train loss 4.95 on epoch=60
05/16/2022 11:42:24 - INFO - __main__ - Global step 850 Train loss 4.91 Classification-F1 0.009523809523809523 on epoch=60
05/16/2022 11:42:25 - INFO - __main__ - Step 860 Global step 860 Train loss 4.73 on epoch=61
05/16/2022 11:42:27 - INFO - __main__ - Step 870 Global step 870 Train loss 4.80 on epoch=62
05/16/2022 11:42:28 - INFO - __main__ - Step 880 Global step 880 Train loss 4.68 on epoch=62
05/16/2022 11:42:29 - INFO - __main__ - Step 890 Global step 890 Train loss 4.71 on epoch=63
05/16/2022 11:42:31 - INFO - __main__ - Step 900 Global step 900 Train loss 4.70 on epoch=64
05/16/2022 11:42:33 - INFO - __main__ - Global step 900 Train loss 4.73 Classification-F1 0.009523809523809523 on epoch=64
05/16/2022 11:42:34 - INFO - __main__ - Step 910 Global step 910 Train loss 4.82 on epoch=64
05/16/2022 11:42:36 - INFO - __main__ - Step 920 Global step 920 Train loss 4.75 on epoch=65
05/16/2022 11:42:37 - INFO - __main__ - Step 930 Global step 930 Train loss 4.59 on epoch=66
05/16/2022 11:42:38 - INFO - __main__ - Step 940 Global step 940 Train loss 4.64 on epoch=67
05/16/2022 11:42:40 - INFO - __main__ - Step 950 Global step 950 Train loss 4.70 on epoch=67
05/16/2022 11:42:42 - INFO - __main__ - Global step 950 Train loss 4.70 Classification-F1 0.009523809523809523 on epoch=67
05/16/2022 11:42:43 - INFO - __main__ - Step 960 Global step 960 Train loss 4.49 on epoch=68
05/16/2022 11:42:44 - INFO - __main__ - Step 970 Global step 970 Train loss 4.50 on epoch=69
05/16/2022 11:42:46 - INFO - __main__ - Step 980 Global step 980 Train loss 4.53 on epoch=69
05/16/2022 11:42:47 - INFO - __main__ - Step 990 Global step 990 Train loss 4.63 on epoch=70
05/16/2022 11:42:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.39 on epoch=71
05/16/2022 11:42:50 - INFO - __main__ - Global step 1000 Train loss 4.51 Classification-F1 0.009523809523809523 on epoch=71
05/16/2022 11:42:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.47 on epoch=72
05/16/2022 11:42:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.39 on epoch=72
05/16/2022 11:42:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.49 on epoch=73
05/16/2022 11:42:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.25 on epoch=74
05/16/2022 11:42:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.42 on epoch=74
05/16/2022 11:42:59 - INFO - __main__ - Global step 1050 Train loss 4.41 Classification-F1 0.009523809523809523 on epoch=74
05/16/2022 11:43:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.47 on epoch=75
05/16/2022 11:43:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.40 on epoch=76
05/16/2022 11:43:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.47 on epoch=77
05/16/2022 11:43:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.31 on epoch=77
05/16/2022 11:43:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.38 on epoch=78
05/16/2022 11:43:08 - INFO - __main__ - Global step 1100 Train loss 4.41 Classification-F1 0.009523809523809523 on epoch=78
05/16/2022 11:43:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.23 on epoch=79
05/16/2022 11:43:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.23 on epoch=79
05/16/2022 11:43:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.46 on epoch=80
05/16/2022 11:43:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.27 on epoch=81
05/16/2022 11:43:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.21 on epoch=82
05/16/2022 11:43:16 - INFO - __main__ - Global step 1150 Train loss 4.28 Classification-F1 0.009563658099222952 on epoch=82
05/16/2022 11:43:16 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009563658099222952 on epoch=82, global_step=1150
05/16/2022 11:43:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.20 on epoch=82
05/16/2022 11:43:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.28 on epoch=83
05/16/2022 11:43:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.06 on epoch=84
05/16/2022 11:43:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.17 on epoch=84
05/16/2022 11:43:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.38 on epoch=85
05/16/2022 11:43:25 - INFO - __main__ - Global step 1200 Train loss 4.22 Classification-F1 0.017104407565519775 on epoch=85
05/16/2022 11:43:25 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.017104407565519775 on epoch=85, global_step=1200
05/16/2022 11:43:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.06 on epoch=86
05/16/2022 11:43:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.06 on epoch=87
05/16/2022 11:43:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.09 on epoch=87
05/16/2022 11:43:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.10 on epoch=88
05/16/2022 11:43:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.02 on epoch=89
05/16/2022 11:43:34 - INFO - __main__ - Global step 1250 Train loss 4.07 Classification-F1 0.01761922888683452 on epoch=89
05/16/2022 11:43:34 - INFO - __main__ - Saving model with best Classification-F1: 0.017104407565519775 -> 0.01761922888683452 on epoch=89, global_step=1250
05/16/2022 11:43:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.02 on epoch=89
05/16/2022 11:43:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.31 on epoch=90
05/16/2022 11:43:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.87 on epoch=91
05/16/2022 11:43:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.10 on epoch=92
05/16/2022 11:43:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.99 on epoch=92
05/16/2022 11:43:43 - INFO - __main__ - Global step 1300 Train loss 4.06 Classification-F1 0.021873187930223786 on epoch=92
05/16/2022 11:43:43 - INFO - __main__ - Saving model with best Classification-F1: 0.01761922888683452 -> 0.021873187930223786 on epoch=92, global_step=1300
05/16/2022 11:43:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.04 on epoch=93
05/16/2022 11:43:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.82 on epoch=94
05/16/2022 11:43:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.95 on epoch=94
05/16/2022 11:43:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.03 on epoch=95
05/16/2022 11:43:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.83 on epoch=96
05/16/2022 11:43:52 - INFO - __main__ - Global step 1350 Train loss 3.93 Classification-F1 0.018614718614718615 on epoch=96
05/16/2022 11:43:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.93 on epoch=97
05/16/2022 11:43:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.96 on epoch=97
05/16/2022 11:43:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.91 on epoch=98
05/16/2022 11:43:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.80 on epoch=99
05/16/2022 11:43:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.74 on epoch=99
05/16/2022 11:44:00 - INFO - __main__ - Global step 1400 Train loss 3.87 Classification-F1 0.014901337247227659 on epoch=99
05/16/2022 11:44:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.93 on epoch=100
05/16/2022 11:44:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.64 on epoch=101
05/16/2022 11:44:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.73 on epoch=102
05/16/2022 11:44:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.72 on epoch=102
05/16/2022 11:44:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.80 on epoch=103
05/16/2022 11:44:09 - INFO - __main__ - Global step 1450 Train loss 3.76 Classification-F1 0.019930875576036868 on epoch=103
05/16/2022 11:44:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.65 on epoch=104
05/16/2022 11:44:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.72 on epoch=104
05/16/2022 11:44:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.83 on epoch=105
05/16/2022 11:44:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.65 on epoch=106
05/16/2022 11:44:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.65 on epoch=107
05/16/2022 11:44:18 - INFO - __main__ - Global step 1500 Train loss 3.70 Classification-F1 0.024521114427606305 on epoch=107
05/16/2022 11:44:18 - INFO - __main__ - Saving model with best Classification-F1: 0.021873187930223786 -> 0.024521114427606305 on epoch=107, global_step=1500
05/16/2022 11:44:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.77 on epoch=107
05/16/2022 11:44:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.71 on epoch=108
05/16/2022 11:44:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.65 on epoch=109
05/16/2022 11:44:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.56 on epoch=109
05/16/2022 11:44:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.68 on epoch=110
05/16/2022 11:44:27 - INFO - __main__ - Global step 1550 Train loss 3.67 Classification-F1 0.03806269982740571 on epoch=110
05/16/2022 11:44:27 - INFO - __main__ - Saving model with best Classification-F1: 0.024521114427606305 -> 0.03806269982740571 on epoch=110, global_step=1550
05/16/2022 11:44:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.58 on epoch=111
05/16/2022 11:44:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.69 on epoch=112
05/16/2022 11:44:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.68 on epoch=112
05/16/2022 11:44:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.53 on epoch=113
05/16/2022 11:44:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.67 on epoch=114
05/16/2022 11:44:35 - INFO - __main__ - Global step 1600 Train loss 3.63 Classification-F1 0.02168909092660188 on epoch=114
05/16/2022 11:44:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.52 on epoch=114
05/16/2022 11:44:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.71 on epoch=115
05/16/2022 11:44:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.55 on epoch=116
05/16/2022 11:44:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.61 on epoch=117
05/16/2022 11:44:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.45 on epoch=117
05/16/2022 11:44:44 - INFO - __main__ - Global step 1650 Train loss 3.57 Classification-F1 0.009563658099222952 on epoch=117
05/16/2022 11:44:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.67 on epoch=118
05/16/2022 11:44:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.47 on epoch=119
05/16/2022 11:44:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.43 on epoch=119
05/16/2022 11:44:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.70 on epoch=120
05/16/2022 11:44:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.55 on epoch=121
05/16/2022 11:44:53 - INFO - __main__ - Global step 1700 Train loss 3.56 Classification-F1 0.017704517704517704 on epoch=121
05/16/2022 11:44:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.62 on epoch=122
05/16/2022 11:44:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.47 on epoch=122
05/16/2022 11:44:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.70 on epoch=123
05/16/2022 11:44:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.44 on epoch=124
05/16/2022 11:45:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.44 on epoch=124
05/16/2022 11:45:02 - INFO - __main__ - Global step 1750 Train loss 3.53 Classification-F1 0.027118440539566906 on epoch=124
05/16/2022 11:45:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.65 on epoch=125
05/16/2022 11:45:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.43 on epoch=126
05/16/2022 11:45:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.45 on epoch=127
05/16/2022 11:45:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.29 on epoch=127
05/16/2022 11:45:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.54 on epoch=128
05/16/2022 11:45:11 - INFO - __main__ - Global step 1800 Train loss 3.47 Classification-F1 0.024031853828118684 on epoch=128
05/16/2022 11:45:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.37 on epoch=129
05/16/2022 11:45:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.50 on epoch=129
05/16/2022 11:45:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.61 on epoch=130
05/16/2022 11:45:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.37 on epoch=131
05/16/2022 11:45:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.53 on epoch=132
05/16/2022 11:45:20 - INFO - __main__ - Global step 1850 Train loss 3.48 Classification-F1 0.012161468360929278 on epoch=132
05/16/2022 11:45:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.48 on epoch=132
05/16/2022 11:45:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.55 on epoch=133
05/16/2022 11:45:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.42 on epoch=134
05/16/2022 11:45:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.36 on epoch=134
05/16/2022 11:45:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.47 on epoch=135
05/16/2022 11:45:29 - INFO - __main__ - Global step 1900 Train loss 3.46 Classification-F1 0.010249839846252402 on epoch=135
05/16/2022 11:45:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.31 on epoch=136
05/16/2022 11:45:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.41 on epoch=137
05/16/2022 11:45:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.34 on epoch=137
05/16/2022 11:45:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.39 on epoch=138
05/16/2022 11:45:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.45 on epoch=139
05/16/2022 11:45:38 - INFO - __main__ - Global step 1950 Train loss 3.38 Classification-F1 0.0206747275712793 on epoch=139
05/16/2022 11:45:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.39 on epoch=139
05/16/2022 11:45:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.58 on epoch=140
05/16/2022 11:45:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.33 on epoch=141
05/16/2022 11:45:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.32 on epoch=142
05/16/2022 11:45:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.40 on epoch=142
05/16/2022 11:45:46 - INFO - __main__ - Global step 2000 Train loss 3.40 Classification-F1 0.02703772418058133 on epoch=142
05/16/2022 11:45:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.35 on epoch=143
05/16/2022 11:45:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.27 on epoch=144
05/16/2022 11:45:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.24 on epoch=144
05/16/2022 11:45:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.38 on epoch=145
05/16/2022 11:45:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.23 on epoch=146
05/16/2022 11:45:55 - INFO - __main__ - Global step 2050 Train loss 3.30 Classification-F1 0.021442651969264186 on epoch=146
05/16/2022 11:45:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.40 on epoch=147
05/16/2022 11:45:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.14 on epoch=147
05/16/2022 11:45:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.46 on epoch=148
05/16/2022 11:46:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.26 on epoch=149
05/16/2022 11:46:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.35 on epoch=149
05/16/2022 11:46:04 - INFO - __main__ - Global step 2100 Train loss 3.32 Classification-F1 0.009563658099222952 on epoch=149
05/16/2022 11:46:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.43 on epoch=150
05/16/2022 11:46:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.20 on epoch=151
05/16/2022 11:46:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.21 on epoch=152
05/16/2022 11:46:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.22 on epoch=152
05/16/2022 11:46:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.36 on epoch=153
05/16/2022 11:46:14 - INFO - __main__ - Global step 2150 Train loss 3.28 Classification-F1 0.01544973544973545 on epoch=153
05/16/2022 11:46:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.24 on epoch=154
05/16/2022 11:46:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.17 on epoch=154
05/16/2022 11:46:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.35 on epoch=155
05/16/2022 11:46:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.03 on epoch=156
05/16/2022 11:46:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.18 on epoch=157
05/16/2022 11:46:24 - INFO - __main__ - Global step 2200 Train loss 3.19 Classification-F1 0.009563658099222952 on epoch=157
05/16/2022 11:46:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.17 on epoch=157
05/16/2022 11:46:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.18 on epoch=158
05/16/2022 11:46:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 3.17 on epoch=159
05/16/2022 11:46:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.13 on epoch=159
05/16/2022 11:46:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 3.21 on epoch=160
05/16/2022 11:46:34 - INFO - __main__ - Global step 2250 Train loss 3.17 Classification-F1 0.009523809523809523 on epoch=160
05/16/2022 11:46:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.12 on epoch=161
05/16/2022 11:46:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.33 on epoch=162
05/16/2022 11:46:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.04 on epoch=162
05/16/2022 11:46:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 3.16 on epoch=163
05/16/2022 11:46:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.12 on epoch=164
05/16/2022 11:46:43 - INFO - __main__ - Global step 2300 Train loss 3.15 Classification-F1 0.009563658099222952 on epoch=164
05/16/2022 11:46:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.08 on epoch=164
05/16/2022 11:46:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.26 on epoch=165
05/16/2022 11:46:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 3.22 on epoch=166
05/16/2022 11:46:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.09 on epoch=167
05/16/2022 11:46:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.13 on epoch=167
05/16/2022 11:46:53 - INFO - __main__ - Global step 2350 Train loss 3.16 Classification-F1 0.01796701944376077 on epoch=167
05/16/2022 11:46:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.15 on epoch=168
05/16/2022 11:46:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.98 on epoch=169
05/16/2022 11:46:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 3.08 on epoch=169
05/16/2022 11:46:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 3.23 on epoch=170
05/16/2022 11:47:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.92 on epoch=171
05/16/2022 11:47:03 - INFO - __main__ - Global step 2400 Train loss 3.07 Classification-F1 0.015272290381460687 on epoch=171
05/16/2022 11:47:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.19 on epoch=172
05/16/2022 11:47:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.00 on epoch=172
05/16/2022 11:47:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.14 on epoch=173
05/16/2022 11:47:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.99 on epoch=174
05/16/2022 11:47:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.07 on epoch=174
05/16/2022 11:47:13 - INFO - __main__ - Global step 2450 Train loss 3.08 Classification-F1 0.009523809523809523 on epoch=174
05/16/2022 11:47:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 3.14 on epoch=175
05/16/2022 11:47:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.92 on epoch=176
05/16/2022 11:47:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.99 on epoch=177
05/16/2022 11:47:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 3.21 on epoch=177
05/16/2022 11:47:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.11 on epoch=178
05/16/2022 11:47:23 - INFO - __main__ - Global step 2500 Train loss 3.07 Classification-F1 0.022317227286171384 on epoch=178
05/16/2022 11:47:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 3.07 on epoch=179
05/16/2022 11:47:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 3.04 on epoch=179
05/16/2022 11:47:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 3.12 on epoch=180
05/16/2022 11:47:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.11 on epoch=181
05/16/2022 11:47:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.08 on epoch=182
05/16/2022 11:47:31 - INFO - __main__ - Global step 2550 Train loss 3.08 Classification-F1 0.017580872011251757 on epoch=182
05/16/2022 11:47:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 3.01 on epoch=182
05/16/2022 11:47:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 3.11 on epoch=183
05/16/2022 11:47:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.79 on epoch=184
05/16/2022 11:47:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.93 on epoch=184
05/16/2022 11:47:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 3.12 on epoch=185
05/16/2022 11:47:40 - INFO - __main__ - Global step 2600 Train loss 2.99 Classification-F1 0.009644364074743823 on epoch=185
05/16/2022 11:47:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.86 on epoch=186
05/16/2022 11:47:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 3.07 on epoch=187
05/16/2022 11:47:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.84 on epoch=187
05/16/2022 11:47:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 3.02 on epoch=188
05/16/2022 11:47:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.95 on epoch=189
05/16/2022 11:47:48 - INFO - __main__ - Global step 2650 Train loss 2.95 Classification-F1 0.009041591320072331 on epoch=189
05/16/2022 11:47:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.95 on epoch=189
05/16/2022 11:47:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 3.11 on epoch=190
05/16/2022 11:47:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.99 on epoch=191
05/16/2022 11:47:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.98 on epoch=192
05/16/2022 11:47:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 3.03 on epoch=192
05/16/2022 11:47:57 - INFO - __main__ - Global step 2700 Train loss 3.01 Classification-F1 0.009523809523809523 on epoch=192
05/16/2022 11:47:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 3.06 on epoch=193
05/16/2022 11:48:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.96 on epoch=194
05/16/2022 11:48:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.93 on epoch=194
05/16/2022 11:48:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 3.11 on epoch=195
05/16/2022 11:48:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/16/2022 11:48:06 - INFO - __main__ - Global step 2750 Train loss 3.00 Classification-F1 0.009523809523809523 on epoch=196
05/16/2022 11:48:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 3.21 on epoch=197
05/16/2022 11:48:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.98 on epoch=197
05/16/2022 11:48:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 3.19 on epoch=198
05/16/2022 11:48:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.94 on epoch=199
05/16/2022 11:48:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.94 on epoch=199
05/16/2022 11:48:14 - INFO - __main__ - Global step 2800 Train loss 3.05 Classification-F1 0.0394118460156196 on epoch=199
05/16/2022 11:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.03806269982740571 -> 0.0394118460156196 on epoch=199, global_step=2800
05/16/2022 11:48:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 3.06 on epoch=200
05/16/2022 11:48:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.84 on epoch=201
05/16/2022 11:48:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.90 on epoch=202
05/16/2022 11:48:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 3.04 on epoch=202
05/16/2022 11:48:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 3.08 on epoch=203
05/16/2022 11:48:23 - INFO - __main__ - Global step 2850 Train loss 2.98 Classification-F1 0.04125036111791079 on epoch=203
05/16/2022 11:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.0394118460156196 -> 0.04125036111791079 on epoch=203, global_step=2850
05/16/2022 11:48:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.90 on epoch=204
05/16/2022 11:48:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.88 on epoch=204
05/16/2022 11:48:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 3.10 on epoch=205
05/16/2022 11:48:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.96 on epoch=206
05/16/2022 11:48:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.95 on epoch=207
05/16/2022 11:48:32 - INFO - __main__ - Global step 2900 Train loss 2.96 Classification-F1 0.0442352965116097 on epoch=207
05/16/2022 11:48:32 - INFO - __main__ - Saving model with best Classification-F1: 0.04125036111791079 -> 0.0442352965116097 on epoch=207, global_step=2900
05/16/2022 11:48:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.82 on epoch=207
05/16/2022 11:48:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 3.07 on epoch=208
05/16/2022 11:48:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.94 on epoch=209
05/16/2022 11:48:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.86 on epoch=209
05/16/2022 11:48:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 3.08 on epoch=210
05/16/2022 11:48:40 - INFO - __main__ - Global step 2950 Train loss 2.95 Classification-F1 0.05457669787448294 on epoch=210
05/16/2022 11:48:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0442352965116097 -> 0.05457669787448294 on epoch=210, global_step=2950
05/16/2022 11:48:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.69 on epoch=211
05/16/2022 11:48:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.90 on epoch=212
05/16/2022 11:48:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.86 on epoch=212
05/16/2022 11:48:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.98 on epoch=213
05/16/2022 11:48:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.88 on epoch=214
05/16/2022 11:48:51 - INFO - __main__ - Global step 3000 Train loss 2.86 Classification-F1 0.020305480682839168 on epoch=214
05/16/2022 11:48:51 - INFO - __main__ - save last model!
05/16/2022 11:48:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/16/2022 11:48:51 - INFO - __main__ - Start tokenizing ... 3500 instances
05/16/2022 11:48:51 - INFO - __main__ - Printing 3 examples
05/16/2022 11:48:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/16/2022 11:48:51 - INFO - __main__ - ['Animal']
05/16/2022 11:48:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/16/2022 11:48:51 - INFO - __main__ - ['Animal']
05/16/2022 11:48:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/16/2022 11:48:51 - INFO - __main__ - ['Village']
05/16/2022 11:48:51 - INFO - __main__ - Tokenizing Input ...
05/16/2022 11:48:53 - INFO - __main__ - Tokenizing Output ...
05/16/2022 11:48:57 - INFO - __main__ - Loaded 3500 examples from test data
05/16/2022 11:49:26 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/16/2022 11:49:26 - INFO - __main__ - Classification-F1 on test data: 0.0272
05/16/2022 11:49:27 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.05457669787448294, test_performance=0.027175661431532258
05/20/2022 09:30:16 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/20/2022 09:30:16 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
05/20/2022 09:30:16 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/20/2022 09:30:16 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
05/20/2022 09:30:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/20/2022 09:30:18 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/20/2022 09:30:18 - INFO - __main__ - args.device: cuda:0
05/20/2022 09:30:18 - INFO - __main__ - Using 2 gpus
05/20/2022 09:30:18 - INFO - __main__ - args.device: cuda:1
05/20/2022 09:30:18 - INFO - __main__ - Using 2 gpus
05/20/2022 09:30:18 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/20/2022 09:30:18 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/20/2022 09:30:25 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/20/2022 09:30:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:30:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:30:26 - INFO - __main__ - Printing 3 examples
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ - Printing 3 examples
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:30:26 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 09:30:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:30:26 - INFO - __main__ - Printing 3 examples
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:30:26 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 09:30:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:30:26 - INFO - __main__ - Printing 3 examples
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 09:30:26 - INFO - __main__ - ['Animal']
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:30:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:30:26 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 09:30:26 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 09:30:32 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 09:30:32 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 09:30:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 09:30:32 - INFO - __main__ - Starting training!
05/20/2022 09:30:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 09:30:38 - INFO - __main__ - Starting training!
05/20/2022 09:30:40 - INFO - __main__ - Step 10 Global step 10 Train loss 7.27 on epoch=0
05/20/2022 09:30:41 - INFO - __main__ - Step 20 Global step 20 Train loss 7.27 on epoch=1
05/20/2022 09:30:43 - INFO - __main__ - Step 30 Global step 30 Train loss 6.96 on epoch=2
05/20/2022 09:30:44 - INFO - __main__ - Step 40 Global step 40 Train loss 6.94 on epoch=2
05/20/2022 09:30:45 - INFO - __main__ - Step 50 Global step 50 Train loss 6.87 on epoch=3
05/20/2022 09:31:32 - INFO - __main__ - Global step 50 Train loss 7.06 Classification-F1 0.0 on epoch=3
05/20/2022 09:31:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 09:31:33 - INFO - __main__ - Step 60 Global step 60 Train loss 6.61 on epoch=4
05/20/2022 09:31:34 - INFO - __main__ - Step 70 Global step 70 Train loss 6.73 on epoch=4
05/20/2022 09:31:35 - INFO - __main__ - Step 80 Global step 80 Train loss 6.51 on epoch=5
05/20/2022 09:31:37 - INFO - __main__ - Step 90 Global step 90 Train loss 6.22 on epoch=6
05/20/2022 09:31:38 - INFO - __main__ - Step 100 Global step 100 Train loss 6.19 on epoch=7
05/20/2022 09:32:37 - INFO - __main__ - Global step 100 Train loss 6.45 Classification-F1 0.0 on epoch=7
05/20/2022 09:32:38 - INFO - __main__ - Step 110 Global step 110 Train loss 6.21 on epoch=7
05/20/2022 09:32:40 - INFO - __main__ - Step 120 Global step 120 Train loss 6.12 on epoch=8
05/20/2022 09:32:41 - INFO - __main__ - Step 130 Global step 130 Train loss 5.88 on epoch=9
05/20/2022 09:32:42 - INFO - __main__ - Step 140 Global step 140 Train loss 6.11 on epoch=9
05/20/2022 09:32:43 - INFO - __main__ - Step 150 Global step 150 Train loss 6.02 on epoch=10
05/20/2022 09:33:15 - INFO - __main__ - Global step 150 Train loss 6.07 Classification-F1 0.0 on epoch=10
05/20/2022 09:33:16 - INFO - __main__ - Step 160 Global step 160 Train loss 5.87 on epoch=11
05/20/2022 09:33:17 - INFO - __main__ - Step 170 Global step 170 Train loss 5.65 on epoch=12
05/20/2022 09:33:18 - INFO - __main__ - Step 180 Global step 180 Train loss 5.76 on epoch=12
05/20/2022 09:33:19 - INFO - __main__ - Step 190 Global step 190 Train loss 5.65 on epoch=13
05/20/2022 09:33:21 - INFO - __main__ - Step 200 Global step 200 Train loss 5.54 on epoch=14
05/20/2022 09:34:28 - INFO - __main__ - Global step 200 Train loss 5.69 Classification-F1 0.0 on epoch=14
05/20/2022 09:34:29 - INFO - __main__ - Step 210 Global step 210 Train loss 5.63 on epoch=14
05/20/2022 09:34:30 - INFO - __main__ - Step 220 Global step 220 Train loss 5.43 on epoch=15
05/20/2022 09:34:31 - INFO - __main__ - Step 230 Global step 230 Train loss 5.51 on epoch=16
05/20/2022 09:34:32 - INFO - __main__ - Step 240 Global step 240 Train loss 5.26 on epoch=17
05/20/2022 09:34:34 - INFO - __main__ - Step 250 Global step 250 Train loss 5.33 on epoch=17
05/20/2022 09:35:09 - INFO - __main__ - Global step 250 Train loss 5.43 Classification-F1 0.0 on epoch=17
05/20/2022 09:35:10 - INFO - __main__ - Step 260 Global step 260 Train loss 5.27 on epoch=18
05/20/2022 09:35:11 - INFO - __main__ - Step 270 Global step 270 Train loss 5.16 on epoch=19
05/20/2022 09:35:13 - INFO - __main__ - Step 280 Global step 280 Train loss 5.10 on epoch=19
05/20/2022 09:35:14 - INFO - __main__ - Step 290 Global step 290 Train loss 5.18 on epoch=20
05/20/2022 09:35:15 - INFO - __main__ - Step 300 Global step 300 Train loss 5.00 on epoch=21
05/20/2022 09:35:26 - INFO - __main__ - Global step 300 Train loss 5.14 Classification-F1 0.005291005291005292 on epoch=21
05/20/2022 09:35:26 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005291005291005292 on epoch=21, global_step=300
05/20/2022 09:35:28 - INFO - __main__ - Step 310 Global step 310 Train loss 4.90 on epoch=22
05/20/2022 09:35:29 - INFO - __main__ - Step 320 Global step 320 Train loss 5.02 on epoch=22
05/20/2022 09:35:30 - INFO - __main__ - Step 330 Global step 330 Train loss 4.99 on epoch=23
05/20/2022 09:35:31 - INFO - __main__ - Step 340 Global step 340 Train loss 4.79 on epoch=24
05/20/2022 09:35:32 - INFO - __main__ - Step 350 Global step 350 Train loss 4.77 on epoch=24
05/20/2022 09:35:35 - INFO - __main__ - Global step 350 Train loss 4.90 Classification-F1 0.007352941176470587 on epoch=24
05/20/2022 09:35:35 - INFO - __main__ - Saving model with best Classification-F1: 0.005291005291005292 -> 0.007352941176470587 on epoch=24, global_step=350
05/20/2022 09:35:37 - INFO - __main__ - Step 360 Global step 360 Train loss 4.75 on epoch=25
05/20/2022 09:35:38 - INFO - __main__ - Step 370 Global step 370 Train loss 4.66 on epoch=26
05/20/2022 09:35:39 - INFO - __main__ - Step 380 Global step 380 Train loss 4.57 on epoch=27
05/20/2022 09:35:40 - INFO - __main__ - Step 390 Global step 390 Train loss 4.59 on epoch=27
05/20/2022 09:35:41 - INFO - __main__ - Step 400 Global step 400 Train loss 4.61 on epoch=28
05/20/2022 09:35:44 - INFO - __main__ - Global step 400 Train loss 4.63 Classification-F1 0.009523809523809523 on epoch=28
05/20/2022 09:35:44 - INFO - __main__ - Saving model with best Classification-F1: 0.007352941176470587 -> 0.009523809523809523 on epoch=28, global_step=400
05/20/2022 09:35:45 - INFO - __main__ - Step 410 Global step 410 Train loss 4.55 on epoch=29
05/20/2022 09:35:46 - INFO - __main__ - Step 420 Global step 420 Train loss 4.47 on epoch=29
05/20/2022 09:35:47 - INFO - __main__ - Step 430 Global step 430 Train loss 4.59 on epoch=30
05/20/2022 09:35:49 - INFO - __main__ - Step 440 Global step 440 Train loss 4.25 on epoch=31
05/20/2022 09:35:50 - INFO - __main__ - Step 450 Global step 450 Train loss 4.37 on epoch=32
05/20/2022 09:35:52 - INFO - __main__ - Global step 450 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=32
05/20/2022 09:35:53 - INFO - __main__ - Step 460 Global step 460 Train loss 4.23 on epoch=32
05/20/2022 09:35:54 - INFO - __main__ - Step 470 Global step 470 Train loss 4.23 on epoch=33
05/20/2022 09:35:55 - INFO - __main__ - Step 480 Global step 480 Train loss 4.08 on epoch=34
05/20/2022 09:35:56 - INFO - __main__ - Step 490 Global step 490 Train loss 4.17 on epoch=34
05/20/2022 09:35:58 - INFO - __main__ - Step 500 Global step 500 Train loss 4.00 on epoch=35
05/20/2022 09:35:59 - INFO - __main__ - Global step 500 Train loss 4.14 Classification-F1 0.009523809523809523 on epoch=35
05/20/2022 09:36:01 - INFO - __main__ - Step 510 Global step 510 Train loss 3.94 on epoch=36
05/20/2022 09:36:02 - INFO - __main__ - Step 520 Global step 520 Train loss 3.94 on epoch=37
05/20/2022 09:36:03 - INFO - __main__ - Step 530 Global step 530 Train loss 4.06 on epoch=37
05/20/2022 09:36:04 - INFO - __main__ - Step 540 Global step 540 Train loss 3.75 on epoch=38
05/20/2022 09:36:05 - INFO - __main__ - Step 550 Global step 550 Train loss 3.82 on epoch=39
05/20/2022 09:36:07 - INFO - __main__ - Global step 550 Train loss 3.90 Classification-F1 0.010025062656641603 on epoch=39
05/20/2022 09:36:07 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.010025062656641603 on epoch=39, global_step=550
05/20/2022 09:36:09 - INFO - __main__ - Step 560 Global step 560 Train loss 3.70 on epoch=39
05/20/2022 09:36:10 - INFO - __main__ - Step 570 Global step 570 Train loss 3.94 on epoch=40
05/20/2022 09:36:11 - INFO - __main__ - Step 580 Global step 580 Train loss 3.47 on epoch=41
05/20/2022 09:36:12 - INFO - __main__ - Step 590 Global step 590 Train loss 3.58 on epoch=42
05/20/2022 09:36:13 - INFO - __main__ - Step 600 Global step 600 Train loss 3.65 on epoch=42
05/20/2022 09:36:15 - INFO - __main__ - Global step 600 Train loss 3.67 Classification-F1 0.018887743776755988 on epoch=42
05/20/2022 09:36:15 - INFO - __main__ - Saving model with best Classification-F1: 0.010025062656641603 -> 0.018887743776755988 on epoch=42, global_step=600
05/20/2022 09:36:16 - INFO - __main__ - Step 610 Global step 610 Train loss 3.51 on epoch=43
05/20/2022 09:36:18 - INFO - __main__ - Step 620 Global step 620 Train loss 3.68 on epoch=44
05/20/2022 09:36:19 - INFO - __main__ - Step 630 Global step 630 Train loss 3.39 on epoch=44
05/20/2022 09:36:20 - INFO - __main__ - Step 640 Global step 640 Train loss 3.54 on epoch=45
05/20/2022 09:36:21 - INFO - __main__ - Step 650 Global step 650 Train loss 3.44 on epoch=46
05/20/2022 09:36:23 - INFO - __main__ - Global step 650 Train loss 3.51 Classification-F1 0.027956989247311832 on epoch=46
05/20/2022 09:36:23 - INFO - __main__ - Saving model with best Classification-F1: 0.018887743776755988 -> 0.027956989247311832 on epoch=46, global_step=650
05/20/2022 09:36:24 - INFO - __main__ - Step 660 Global step 660 Train loss 3.52 on epoch=47
05/20/2022 09:36:25 - INFO - __main__ - Step 670 Global step 670 Train loss 3.47 on epoch=47
05/20/2022 09:36:26 - INFO - __main__ - Step 680 Global step 680 Train loss 3.36 on epoch=48
05/20/2022 09:36:28 - INFO - __main__ - Step 690 Global step 690 Train loss 3.31 on epoch=49
05/20/2022 09:36:29 - INFO - __main__ - Step 700 Global step 700 Train loss 3.34 on epoch=49
05/20/2022 09:36:31 - INFO - __main__ - Global step 700 Train loss 3.40 Classification-F1 0.020337301587301588 on epoch=49
05/20/2022 09:36:32 - INFO - __main__ - Step 710 Global step 710 Train loss 3.23 on epoch=50
05/20/2022 09:36:33 - INFO - __main__ - Step 720 Global step 720 Train loss 3.26 on epoch=51
05/20/2022 09:36:34 - INFO - __main__ - Step 730 Global step 730 Train loss 3.12 on epoch=52
05/20/2022 09:36:36 - INFO - __main__ - Step 740 Global step 740 Train loss 3.50 on epoch=52
05/20/2022 09:36:37 - INFO - __main__ - Step 750 Global step 750 Train loss 3.07 on epoch=53
05/20/2022 09:36:39 - INFO - __main__ - Global step 750 Train loss 3.24 Classification-F1 0.022669796663604715 on epoch=53
05/20/2022 09:36:40 - INFO - __main__ - Step 760 Global step 760 Train loss 3.37 on epoch=54
05/20/2022 09:36:41 - INFO - __main__ - Step 770 Global step 770 Train loss 3.16 on epoch=54
05/20/2022 09:36:42 - INFO - __main__ - Step 780 Global step 780 Train loss 3.28 on epoch=55
05/20/2022 09:36:44 - INFO - __main__ - Step 790 Global step 790 Train loss 3.12 on epoch=56
05/20/2022 09:36:45 - INFO - __main__ - Step 800 Global step 800 Train loss 3.16 on epoch=57
05/20/2022 09:36:47 - INFO - __main__ - Global step 800 Train loss 3.22 Classification-F1 0.029869573672629705 on epoch=57
05/20/2022 09:36:47 - INFO - __main__ - Saving model with best Classification-F1: 0.027956989247311832 -> 0.029869573672629705 on epoch=57, global_step=800
05/20/2022 09:36:48 - INFO - __main__ - Step 810 Global step 810 Train loss 3.18 on epoch=57
05/20/2022 09:36:49 - INFO - __main__ - Step 820 Global step 820 Train loss 3.01 on epoch=58
05/20/2022 09:36:50 - INFO - __main__ - Step 830 Global step 830 Train loss 3.15 on epoch=59
05/20/2022 09:36:52 - INFO - __main__ - Step 840 Global step 840 Train loss 3.00 on epoch=59
05/20/2022 09:36:53 - INFO - __main__ - Step 850 Global step 850 Train loss 3.08 on epoch=60
05/20/2022 09:36:55 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.047294246554072286 on epoch=60
05/20/2022 09:36:55 - INFO - __main__ - Saving model with best Classification-F1: 0.029869573672629705 -> 0.047294246554072286 on epoch=60, global_step=850
05/20/2022 09:36:56 - INFO - __main__ - Step 860 Global step 860 Train loss 3.01 on epoch=61
05/20/2022 09:36:57 - INFO - __main__ - Step 870 Global step 870 Train loss 3.03 on epoch=62
05/20/2022 09:36:58 - INFO - __main__ - Step 880 Global step 880 Train loss 3.11 on epoch=62
05/20/2022 09:37:00 - INFO - __main__ - Step 890 Global step 890 Train loss 3.14 on epoch=63
05/20/2022 09:37:01 - INFO - __main__ - Step 900 Global step 900 Train loss 3.04 on epoch=64
05/20/2022 09:37:03 - INFO - __main__ - Global step 900 Train loss 3.06 Classification-F1 0.04571456323477886 on epoch=64
05/20/2022 09:37:04 - INFO - __main__ - Step 910 Global step 910 Train loss 2.88 on epoch=64
05/20/2022 09:37:05 - INFO - __main__ - Step 920 Global step 920 Train loss 3.04 on epoch=65
05/20/2022 09:37:06 - INFO - __main__ - Step 930 Global step 930 Train loss 2.85 on epoch=66
05/20/2022 09:37:07 - INFO - __main__ - Step 940 Global step 940 Train loss 2.81 on epoch=67
05/20/2022 09:37:09 - INFO - __main__ - Step 950 Global step 950 Train loss 2.92 on epoch=67
05/20/2022 09:37:10 - INFO - __main__ - Global step 950 Train loss 2.90 Classification-F1 0.05722270245125096 on epoch=67
05/20/2022 09:37:10 - INFO - __main__ - Saving model with best Classification-F1: 0.047294246554072286 -> 0.05722270245125096 on epoch=67, global_step=950
05/20/2022 09:37:12 - INFO - __main__ - Step 960 Global step 960 Train loss 2.72 on epoch=68
05/20/2022 09:37:13 - INFO - __main__ - Step 970 Global step 970 Train loss 2.97 on epoch=69
05/20/2022 09:37:14 - INFO - __main__ - Step 980 Global step 980 Train loss 2.64 on epoch=69
05/20/2022 09:37:15 - INFO - __main__ - Step 990 Global step 990 Train loss 2.87 on epoch=70
05/20/2022 09:37:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.70 on epoch=71
05/20/2022 09:37:18 - INFO - __main__ - Global step 1000 Train loss 2.78 Classification-F1 0.06777881146408957 on epoch=71
05/20/2022 09:37:18 - INFO - __main__ - Saving model with best Classification-F1: 0.05722270245125096 -> 0.06777881146408957 on epoch=71, global_step=1000
05/20/2022 09:37:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.78 on epoch=72
05/20/2022 09:37:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.69 on epoch=72
05/20/2022 09:37:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.78 on epoch=73
05/20/2022 09:37:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.80 on epoch=74
05/20/2022 09:37:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.45 on epoch=74
05/20/2022 09:37:26 - INFO - __main__ - Global step 1050 Train loss 2.70 Classification-F1 0.06117963720703446 on epoch=74
05/20/2022 09:37:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.94 on epoch=75
05/20/2022 09:37:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.56 on epoch=76
05/20/2022 09:37:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.67 on epoch=77
05/20/2022 09:37:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.87 on epoch=77
05/20/2022 09:37:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.65 on epoch=78
05/20/2022 09:37:34 - INFO - __main__ - Global step 1100 Train loss 2.74 Classification-F1 0.055416841223292844 on epoch=78
05/20/2022 09:37:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.84 on epoch=79
05/20/2022 09:37:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.63 on epoch=79
05/20/2022 09:37:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.78 on epoch=80
05/20/2022 09:37:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.62 on epoch=81
05/20/2022 09:37:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.79 on epoch=82
05/20/2022 09:37:42 - INFO - __main__ - Global step 1150 Train loss 2.73 Classification-F1 0.036294517807122846 on epoch=82
05/20/2022 09:37:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.72 on epoch=82
05/20/2022 09:37:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.59 on epoch=83
05/20/2022 09:37:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.70 on epoch=84
05/20/2022 09:37:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.60 on epoch=84
05/20/2022 09:37:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.67 on epoch=85
05/20/2022 09:37:50 - INFO - __main__ - Global step 1200 Train loss 2.66 Classification-F1 0.037661792905081495 on epoch=85
05/20/2022 09:37:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.42 on epoch=86
05/20/2022 09:37:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.53 on epoch=87
05/20/2022 09:37:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.60 on epoch=87
05/20/2022 09:37:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.52 on epoch=88
05/20/2022 09:37:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.63 on epoch=89
05/20/2022 09:37:58 - INFO - __main__ - Global step 1250 Train loss 2.54 Classification-F1 0.04100095279575462 on epoch=89
05/20/2022 09:37:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.55 on epoch=89
05/20/2022 09:38:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.38 on epoch=90
05/20/2022 09:38:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.45 on epoch=91
05/20/2022 09:38:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.38 on epoch=92
05/20/2022 09:38:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.71 on epoch=92
05/20/2022 09:38:06 - INFO - __main__ - Global step 1300 Train loss 2.49 Classification-F1 0.036953856502728685 on epoch=92
05/20/2022 09:38:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.65 on epoch=93
05/20/2022 09:38:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.64 on epoch=94
05/20/2022 09:38:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.38 on epoch=94
05/20/2022 09:38:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.45 on epoch=95
05/20/2022 09:38:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.44 on epoch=96
05/20/2022 09:38:14 - INFO - __main__ - Global step 1350 Train loss 2.51 Classification-F1 0.03842364532019704 on epoch=96
05/20/2022 09:38:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.54 on epoch=97
05/20/2022 09:38:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.56 on epoch=97
05/20/2022 09:38:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.65 on epoch=98
05/20/2022 09:38:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.56 on epoch=99
05/20/2022 09:38:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.39 on epoch=99
05/20/2022 09:38:22 - INFO - __main__ - Global step 1400 Train loss 2.54 Classification-F1 0.06573914150640493 on epoch=99
05/20/2022 09:38:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.54 on epoch=100
05/20/2022 09:38:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.48 on epoch=101
05/20/2022 09:38:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.42 on epoch=102
05/20/2022 09:38:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.46 on epoch=102
05/20/2022 09:38:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.49 on epoch=103
05/20/2022 09:38:30 - INFO - __main__ - Global step 1450 Train loss 2.48 Classification-F1 0.05746239783334139 on epoch=103
05/20/2022 09:38:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.52 on epoch=104
05/20/2022 09:38:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.30 on epoch=104
05/20/2022 09:38:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.43 on epoch=105
05/20/2022 09:38:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.34 on epoch=106
05/20/2022 09:38:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.35 on epoch=107
05/20/2022 09:38:37 - INFO - __main__ - Global step 1500 Train loss 2.39 Classification-F1 0.08818117246125592 on epoch=107
05/20/2022 09:38:37 - INFO - __main__ - Saving model with best Classification-F1: 0.06777881146408957 -> 0.08818117246125592 on epoch=107, global_step=1500
05/20/2022 09:38:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.24 on epoch=107
05/20/2022 09:38:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.29 on epoch=108
05/20/2022 09:38:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.40 on epoch=109
05/20/2022 09:38:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.20 on epoch=109
05/20/2022 09:38:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.37 on epoch=110
05/20/2022 09:38:46 - INFO - __main__ - Global step 1550 Train loss 2.30 Classification-F1 0.04395149364093463 on epoch=110
05/20/2022 09:38:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.31 on epoch=111
05/20/2022 09:38:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.30 on epoch=112
05/20/2022 09:38:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.40 on epoch=112
05/20/2022 09:38:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.30 on epoch=113
05/20/2022 09:38:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.19 on epoch=114
05/20/2022 09:38:53 - INFO - __main__ - Global step 1600 Train loss 2.30 Classification-F1 0.009563658099222952 on epoch=114
05/20/2022 09:38:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.38 on epoch=114
05/20/2022 09:38:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.20 on epoch=115
05/20/2022 09:38:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.31 on epoch=116
05/20/2022 09:38:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.20 on epoch=117
05/20/2022 09:38:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.10 on epoch=117
05/20/2022 09:39:01 - INFO - __main__ - Global step 1650 Train loss 2.24 Classification-F1 0.08235901140766592 on epoch=117
05/20/2022 09:39:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.10 on epoch=118
05/20/2022 09:39:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.16 on epoch=119
05/20/2022 09:39:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.09 on epoch=119
05/20/2022 09:39:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.21 on epoch=120
05/20/2022 09:39:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.13 on epoch=121
05/20/2022 09:39:09 - INFO - __main__ - Global step 1700 Train loss 2.14 Classification-F1 0.0758425587398516 on epoch=121
05/20/2022 09:39:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.04 on epoch=122
05/20/2022 09:39:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.14 on epoch=122
05/20/2022 09:39:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.10 on epoch=123
05/20/2022 09:39:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.25 on epoch=124
05/20/2022 09:39:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.05 on epoch=124
05/20/2022 09:39:18 - INFO - __main__ - Global step 1750 Train loss 2.12 Classification-F1 0.09199202343127434 on epoch=124
05/20/2022 09:39:18 - INFO - __main__ - Saving model with best Classification-F1: 0.08818117246125592 -> 0.09199202343127434 on epoch=124, global_step=1750
05/20/2022 09:39:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.01 on epoch=125
05/20/2022 09:39:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.96 on epoch=126
05/20/2022 09:39:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.10 on epoch=127
05/20/2022 09:39:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.10 on epoch=127
05/20/2022 09:39:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.00 on epoch=128
05/20/2022 09:39:26 - INFO - __main__ - Global step 1800 Train loss 2.03 Classification-F1 0.04276155217331688 on epoch=128
05/20/2022 09:39:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.10 on epoch=129
05/20/2022 09:39:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.01 on epoch=129
05/20/2022 09:39:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.16 on epoch=130
05/20/2022 09:39:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.91 on epoch=131
05/20/2022 09:39:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.09 on epoch=132
05/20/2022 09:39:34 - INFO - __main__ - Global step 1850 Train loss 2.05 Classification-F1 0.0772836966954614 on epoch=132
05/20/2022 09:39:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.00 on epoch=132
05/20/2022 09:39:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.97 on epoch=133
05/20/2022 09:39:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.93 on epoch=134
05/20/2022 09:39:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.03 on epoch=134
05/20/2022 09:39:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.08 on epoch=135
05/20/2022 09:39:43 - INFO - __main__ - Global step 1900 Train loss 2.00 Classification-F1 0.1358986016399465 on epoch=135
05/20/2022 09:39:43 - INFO - __main__ - Saving model with best Classification-F1: 0.09199202343127434 -> 0.1358986016399465 on epoch=135, global_step=1900
05/20/2022 09:39:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.02 on epoch=136
05/20/2022 09:39:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.95 on epoch=137
05/20/2022 09:39:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.95 on epoch=137
05/20/2022 09:39:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.01 on epoch=138
05/20/2022 09:39:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.00 on epoch=139
05/20/2022 09:39:51 - INFO - __main__ - Global step 1950 Train loss 1.99 Classification-F1 0.13749163350492255 on epoch=139
05/20/2022 09:39:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1358986016399465 -> 0.13749163350492255 on epoch=139, global_step=1950
05/20/2022 09:39:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.90 on epoch=139
05/20/2022 09:39:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.98 on epoch=140
05/20/2022 09:39:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.00 on epoch=141
05/20/2022 09:39:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.99 on epoch=142
05/20/2022 09:39:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.97 on epoch=142
05/20/2022 09:39:59 - INFO - __main__ - Global step 2000 Train loss 1.97 Classification-F1 0.07585988360132458 on epoch=142
05/20/2022 09:40:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.94 on epoch=143
05/20/2022 09:40:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.82 on epoch=144
05/20/2022 09:40:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.91 on epoch=144
05/20/2022 09:40:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.83 on epoch=145
05/20/2022 09:40:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.84 on epoch=146
05/20/2022 09:40:07 - INFO - __main__ - Global step 2050 Train loss 1.87 Classification-F1 0.06060839360939062 on epoch=146
05/20/2022 09:40:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.76 on epoch=147
05/20/2022 09:40:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.92 on epoch=147
05/20/2022 09:40:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.84 on epoch=148
05/20/2022 09:40:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.83 on epoch=149
05/20/2022 09:40:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.92 on epoch=149
05/20/2022 09:40:16 - INFO - __main__ - Global step 2100 Train loss 1.85 Classification-F1 0.1467214031078043 on epoch=149
05/20/2022 09:40:16 - INFO - __main__ - Saving model with best Classification-F1: 0.13749163350492255 -> 0.1467214031078043 on epoch=149, global_step=2100
05/20/2022 09:40:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.81 on epoch=150
05/20/2022 09:40:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.79 on epoch=151
05/20/2022 09:40:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.70 on epoch=152
05/20/2022 09:40:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.83 on epoch=152
05/20/2022 09:40:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.75 on epoch=153
05/20/2022 09:40:24 - INFO - __main__ - Global step 2150 Train loss 1.78 Classification-F1 0.18730469328380228 on epoch=153
05/20/2022 09:40:24 - INFO - __main__ - Saving model with best Classification-F1: 0.1467214031078043 -> 0.18730469328380228 on epoch=153, global_step=2150
05/20/2022 09:40:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.84 on epoch=154
05/20/2022 09:40:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.70 on epoch=154
05/20/2022 09:40:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.90 on epoch=155
05/20/2022 09:40:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.82 on epoch=156
05/20/2022 09:40:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.78 on epoch=157
05/20/2022 09:40:33 - INFO - __main__ - Global step 2200 Train loss 1.81 Classification-F1 0.2156707433079219 on epoch=157
05/20/2022 09:40:33 - INFO - __main__ - Saving model with best Classification-F1: 0.18730469328380228 -> 0.2156707433079219 on epoch=157, global_step=2200
05/20/2022 09:40:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.76 on epoch=157
05/20/2022 09:40:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.71 on epoch=158
05/20/2022 09:40:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.81 on epoch=159
05/20/2022 09:40:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.72 on epoch=159
05/20/2022 09:40:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.89 on epoch=160
05/20/2022 09:40:41 - INFO - __main__ - Global step 2250 Train loss 1.78 Classification-F1 0.23713464290581981 on epoch=160
05/20/2022 09:40:41 - INFO - __main__ - Saving model with best Classification-F1: 0.2156707433079219 -> 0.23713464290581981 on epoch=160, global_step=2250
05/20/2022 09:40:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.75 on epoch=161
05/20/2022 09:40:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.69 on epoch=162
05/20/2022 09:40:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.57 on epoch=162
05/20/2022 09:40:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.83 on epoch=163
05/20/2022 09:40:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.71 on epoch=164
05/20/2022 09:40:49 - INFO - __main__ - Global step 2300 Train loss 1.71 Classification-F1 0.24540822757444516 on epoch=164
05/20/2022 09:40:50 - INFO - __main__ - Saving model with best Classification-F1: 0.23713464290581981 -> 0.24540822757444516 on epoch=164, global_step=2300
05/20/2022 09:40:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.65 on epoch=164
05/20/2022 09:40:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.67 on epoch=165
05/20/2022 09:40:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.66 on epoch=166
05/20/2022 09:40:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.71 on epoch=167
05/20/2022 09:40:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.69 on epoch=167
05/20/2022 09:40:58 - INFO - __main__ - Global step 2350 Train loss 1.67 Classification-F1 0.20157112512872594 on epoch=167
05/20/2022 09:40:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.63 on epoch=168
05/20/2022 09:41:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.71 on epoch=169
05/20/2022 09:41:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.69 on epoch=169
05/20/2022 09:41:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.72 on epoch=170
05/20/2022 09:41:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.78 on epoch=171
05/20/2022 09:41:06 - INFO - __main__ - Global step 2400 Train loss 1.70 Classification-F1 0.2670019335999158 on epoch=171
05/20/2022 09:41:06 - INFO - __main__ - Saving model with best Classification-F1: 0.24540822757444516 -> 0.2670019335999158 on epoch=171, global_step=2400
05/20/2022 09:41:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.66 on epoch=172
05/20/2022 09:41:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.57 on epoch=172
05/20/2022 09:41:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.69 on epoch=173
05/20/2022 09:41:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.49 on epoch=174
05/20/2022 09:41:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.63 on epoch=174
05/20/2022 09:41:15 - INFO - __main__ - Global step 2450 Train loss 1.61 Classification-F1 0.20804672747358435 on epoch=174
05/20/2022 09:41:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.55 on epoch=175
05/20/2022 09:41:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.55 on epoch=176
05/20/2022 09:41:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.59 on epoch=177
05/20/2022 09:41:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.58 on epoch=177
05/20/2022 09:41:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.59 on epoch=178
05/20/2022 09:41:23 - INFO - __main__ - Global step 2500 Train loss 1.57 Classification-F1 0.30142174721450904 on epoch=178
05/20/2022 09:41:23 - INFO - __main__ - Saving model with best Classification-F1: 0.2670019335999158 -> 0.30142174721450904 on epoch=178, global_step=2500
05/20/2022 09:41:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.64 on epoch=179
05/20/2022 09:41:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.51 on epoch=179
05/20/2022 09:41:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.56 on epoch=180
05/20/2022 09:41:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.71 on epoch=181
05/20/2022 09:41:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.61 on epoch=182
05/20/2022 09:41:32 - INFO - __main__ - Global step 2550 Train loss 1.60 Classification-F1 0.183016358755275 on epoch=182
05/20/2022 09:41:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.69 on epoch=182
05/20/2022 09:41:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.63 on epoch=183
05/20/2022 09:41:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.55 on epoch=184
05/20/2022 09:41:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.63 on epoch=184
05/20/2022 09:41:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.58 on epoch=185
05/20/2022 09:41:40 - INFO - __main__ - Global step 2600 Train loss 1.61 Classification-F1 0.18653851870108443 on epoch=185
05/20/2022 09:41:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.59 on epoch=186
05/20/2022 09:41:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.58 on epoch=187
05/20/2022 09:41:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.54 on epoch=187
05/20/2022 09:41:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.64 on epoch=188
05/20/2022 09:41:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.39 on epoch=189
05/20/2022 09:41:49 - INFO - __main__ - Global step 2650 Train loss 1.55 Classification-F1 0.28334397491229685 on epoch=189
05/20/2022 09:41:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.54 on epoch=189
05/20/2022 09:41:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.65 on epoch=190
05/20/2022 09:41:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.49 on epoch=191
05/20/2022 09:41:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.59 on epoch=192
05/20/2022 09:41:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.44 on epoch=192
05/20/2022 09:41:58 - INFO - __main__ - Global step 2700 Train loss 1.54 Classification-F1 0.25181042980421653 on epoch=192
05/20/2022 09:41:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.55 on epoch=193
05/20/2022 09:42:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.49 on epoch=194
05/20/2022 09:42:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.54 on epoch=194
05/20/2022 09:42:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.43 on epoch=195
05/20/2022 09:42:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.59 on epoch=196
05/20/2022 09:42:06 - INFO - __main__ - Global step 2750 Train loss 1.52 Classification-F1 0.24703446691735118 on epoch=196
05/20/2022 09:42:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.35 on epoch=197
05/20/2022 09:42:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.37 on epoch=197
05/20/2022 09:42:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.52 on epoch=198
05/20/2022 09:42:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.47 on epoch=199
05/20/2022 09:42:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.53 on epoch=199
05/20/2022 09:42:15 - INFO - __main__ - Global step 2800 Train loss 1.45 Classification-F1 0.2813225879160257 on epoch=199
05/20/2022 09:42:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.48 on epoch=200
05/20/2022 09:42:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.47 on epoch=201
05/20/2022 09:42:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.42 on epoch=202
05/20/2022 09:42:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.47 on epoch=202
05/20/2022 09:42:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.51 on epoch=203
05/20/2022 09:42:24 - INFO - __main__ - Global step 2850 Train loss 1.47 Classification-F1 0.3463450938633764 on epoch=203
05/20/2022 09:42:24 - INFO - __main__ - Saving model with best Classification-F1: 0.30142174721450904 -> 0.3463450938633764 on epoch=203, global_step=2850
05/20/2022 09:42:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.53 on epoch=204
05/20/2022 09:42:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.41 on epoch=204
05/20/2022 09:42:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.39 on epoch=205
05/20/2022 09:42:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.48 on epoch=206
05/20/2022 09:42:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.36 on epoch=207
05/20/2022 09:42:33 - INFO - __main__ - Global step 2900 Train loss 1.43 Classification-F1 0.37502529902529896 on epoch=207
05/20/2022 09:42:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3463450938633764 -> 0.37502529902529896 on epoch=207, global_step=2900
05/20/2022 09:42:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.33 on epoch=207
05/20/2022 09:42:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.33 on epoch=208
05/20/2022 09:42:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.38 on epoch=209
05/20/2022 09:42:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.32 on epoch=209
05/20/2022 09:42:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.36 on epoch=210
05/20/2022 09:42:43 - INFO - __main__ - Global step 2950 Train loss 1.34 Classification-F1 0.3392752506331597 on epoch=210
05/20/2022 09:42:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.40 on epoch=211
05/20/2022 09:42:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.38 on epoch=212
05/20/2022 09:42:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.29 on epoch=212
05/20/2022 09:42:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.44 on epoch=213
05/20/2022 09:42:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.39 on epoch=214
05/20/2022 09:42:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:42:50 - INFO - __main__ - Printing 3 examples
05/20/2022 09:42:50 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 09:42:50 - INFO - __main__ - ['Animal']
05/20/2022 09:42:50 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 09:42:50 - INFO - __main__ - ['Animal']
05/20/2022 09:42:50 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 09:42:50 - INFO - __main__ - ['Animal']
05/20/2022 09:42:50 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:42:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:42:51 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 09:42:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:42:51 - INFO - __main__ - Printing 3 examples
05/20/2022 09:42:51 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 09:42:51 - INFO - __main__ - ['Animal']
05/20/2022 09:42:51 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 09:42:51 - INFO - __main__ - ['Animal']
05/20/2022 09:42:51 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 09:42:51 - INFO - __main__ - ['Animal']
05/20/2022 09:42:51 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:42:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:42:51 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 09:42:52 - INFO - __main__ - Global step 3000 Train loss 1.38 Classification-F1 0.3952647899862215 on epoch=214
05/20/2022 09:42:52 - INFO - __main__ - Saving model with best Classification-F1: 0.37502529902529896 -> 0.3952647899862215 on epoch=214, global_step=3000
05/20/2022 09:42:52 - INFO - __main__ - save last model!
05/20/2022 09:42:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 09:42:52 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 09:42:52 - INFO - __main__ - Printing 3 examples
05/20/2022 09:42:52 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 09:42:52 - INFO - __main__ - ['Animal']
05/20/2022 09:42:52 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 09:42:52 - INFO - __main__ - ['Animal']
05/20/2022 09:42:52 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 09:42:52 - INFO - __main__ - ['Village']
05/20/2022 09:42:52 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:42:54 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:42:56 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 09:42:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 09:42:57 - INFO - __main__ - Starting training!
05/20/2022 09:42:57 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 09:43:50 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/20/2022 09:43:50 - INFO - __main__ - Classification-F1 on test data: 0.3192
05/20/2022 09:43:50 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.3952647899862215, test_performance=0.3192215004932146
05/20/2022 09:43:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/20/2022 09:43:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:43:51 - INFO - __main__ - Printing 3 examples
05/20/2022 09:43:51 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 09:43:51 - INFO - __main__ - ['Animal']
05/20/2022 09:43:51 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 09:43:51 - INFO - __main__ - ['Animal']
05/20/2022 09:43:51 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 09:43:51 - INFO - __main__ - ['Animal']
05/20/2022 09:43:51 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:43:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:43:52 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 09:43:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:43:52 - INFO - __main__ - Printing 3 examples
05/20/2022 09:43:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 09:43:52 - INFO - __main__ - ['Animal']
05/20/2022 09:43:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 09:43:52 - INFO - __main__ - ['Animal']
05/20/2022 09:43:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 09:43:52 - INFO - __main__ - ['Animal']
05/20/2022 09:43:52 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:43:52 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:43:52 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 09:43:57 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 09:43:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 09:43:58 - INFO - __main__ - Starting training!
05/20/2022 09:43:59 - INFO - __main__ - Step 10 Global step 10 Train loss 7.37 on epoch=0
05/20/2022 09:44:00 - INFO - __main__ - Step 20 Global step 20 Train loss 7.34 on epoch=1
05/20/2022 09:44:02 - INFO - __main__ - Step 30 Global step 30 Train loss 7.08 on epoch=2
05/20/2022 09:44:03 - INFO - __main__ - Step 40 Global step 40 Train loss 6.93 on epoch=2
05/20/2022 09:44:04 - INFO - __main__ - Step 50 Global step 50 Train loss 6.92 on epoch=3
05/20/2022 09:44:28 - INFO - __main__ - Global step 50 Train loss 7.13 Classification-F1 0.0 on epoch=3
05/20/2022 09:44:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 09:44:29 - INFO - __main__ - Step 60 Global step 60 Train loss 6.60 on epoch=4
05/20/2022 09:44:30 - INFO - __main__ - Step 70 Global step 70 Train loss 6.65 on epoch=4
05/20/2022 09:44:32 - INFO - __main__ - Step 80 Global step 80 Train loss 6.44 on epoch=5
05/20/2022 09:44:33 - INFO - __main__ - Step 90 Global step 90 Train loss 6.25 on epoch=6
05/20/2022 09:44:34 - INFO - __main__ - Step 100 Global step 100 Train loss 6.28 on epoch=7
05/20/2022 09:45:13 - INFO - __main__ - Global step 100 Train loss 6.45 Classification-F1 0.0 on epoch=7
05/20/2022 09:45:15 - INFO - __main__ - Step 110 Global step 110 Train loss 6.31 on epoch=7
05/20/2022 09:45:16 - INFO - __main__ - Step 120 Global step 120 Train loss 6.17 on epoch=8
05/20/2022 09:45:17 - INFO - __main__ - Step 130 Global step 130 Train loss 6.08 on epoch=9
05/20/2022 09:45:18 - INFO - __main__ - Step 140 Global step 140 Train loss 6.16 on epoch=9
05/20/2022 09:45:19 - INFO - __main__ - Step 150 Global step 150 Train loss 5.99 on epoch=10
05/20/2022 09:46:27 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/20/2022 09:46:28 - INFO - __main__ - Step 160 Global step 160 Train loss 5.96 on epoch=11
05/20/2022 09:46:30 - INFO - __main__ - Step 170 Global step 170 Train loss 5.91 on epoch=12
05/20/2022 09:46:31 - INFO - __main__ - Step 180 Global step 180 Train loss 5.74 on epoch=12
05/20/2022 09:46:32 - INFO - __main__ - Step 190 Global step 190 Train loss 5.77 on epoch=13
05/20/2022 09:46:33 - INFO - __main__ - Step 200 Global step 200 Train loss 5.56 on epoch=14
05/20/2022 09:47:07 - INFO - __main__ - Global step 200 Train loss 5.79 Classification-F1 0.0 on epoch=14
05/20/2022 09:47:09 - INFO - __main__ - Step 210 Global step 210 Train loss 5.68 on epoch=14
05/20/2022 09:47:10 - INFO - __main__ - Step 220 Global step 220 Train loss 5.52 on epoch=15
05/20/2022 09:47:11 - INFO - __main__ - Step 230 Global step 230 Train loss 5.51 on epoch=16
05/20/2022 09:47:13 - INFO - __main__ - Step 240 Global step 240 Train loss 5.38 on epoch=17
05/20/2022 09:47:14 - INFO - __main__ - Step 250 Global step 250 Train loss 5.38 on epoch=17
05/20/2022 09:47:41 - INFO - __main__ - Global step 250 Train loss 5.49 Classification-F1 0.0 on epoch=17
05/20/2022 09:47:42 - INFO - __main__ - Step 260 Global step 260 Train loss 5.32 on epoch=18
05/20/2022 09:47:43 - INFO - __main__ - Step 270 Global step 270 Train loss 5.40 on epoch=19
05/20/2022 09:47:45 - INFO - __main__ - Step 280 Global step 280 Train loss 5.25 on epoch=19
05/20/2022 09:47:46 - INFO - __main__ - Step 290 Global step 290 Train loss 5.20 on epoch=20
05/20/2022 09:47:47 - INFO - __main__ - Step 300 Global step 300 Train loss 5.13 on epoch=21
05/20/2022 09:48:07 - INFO - __main__ - Global step 300 Train loss 5.26 Classification-F1 0.0 on epoch=21
05/20/2022 09:48:08 - INFO - __main__ - Step 310 Global step 310 Train loss 4.99 on epoch=22
05/20/2022 09:48:10 - INFO - __main__ - Step 320 Global step 320 Train loss 5.00 on epoch=22
05/20/2022 09:48:11 - INFO - __main__ - Step 330 Global step 330 Train loss 4.91 on epoch=23
05/20/2022 09:48:12 - INFO - __main__ - Step 340 Global step 340 Train loss 4.90 on epoch=24
05/20/2022 09:48:13 - INFO - __main__ - Step 350 Global step 350 Train loss 5.00 on epoch=24
05/20/2022 09:48:16 - INFO - __main__ - Global step 350 Train loss 4.96 Classification-F1 0.01215277777777778 on epoch=24
05/20/2022 09:48:16 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.01215277777777778 on epoch=24, global_step=350
05/20/2022 09:48:17 - INFO - __main__ - Step 360 Global step 360 Train loss 4.91 on epoch=25
05/20/2022 09:48:18 - INFO - __main__ - Step 370 Global step 370 Train loss 4.87 on epoch=26
05/20/2022 09:48:20 - INFO - __main__ - Step 380 Global step 380 Train loss 4.76 on epoch=27
05/20/2022 09:48:21 - INFO - __main__ - Step 390 Global step 390 Train loss 4.75 on epoch=27
05/20/2022 09:48:22 - INFO - __main__ - Step 400 Global step 400 Train loss 4.82 on epoch=28
05/20/2022 09:48:25 - INFO - __main__ - Global step 400 Train loss 4.82 Classification-F1 0.007729468599033816 on epoch=28
05/20/2022 09:48:26 - INFO - __main__ - Step 410 Global step 410 Train loss 4.68 on epoch=29
05/20/2022 09:48:27 - INFO - __main__ - Step 420 Global step 420 Train loss 4.65 on epoch=29
05/20/2022 09:48:29 - INFO - __main__ - Step 430 Global step 430 Train loss 4.70 on epoch=30
05/20/2022 09:48:30 - INFO - __main__ - Step 440 Global step 440 Train loss 4.45 on epoch=31
05/20/2022 09:48:31 - INFO - __main__ - Step 450 Global step 450 Train loss 4.47 on epoch=32
05/20/2022 09:48:33 - INFO - __main__ - Global step 450 Train loss 4.59 Classification-F1 0.00892608089260809 on epoch=32
05/20/2022 09:48:35 - INFO - __main__ - Step 460 Global step 460 Train loss 4.58 on epoch=32
05/20/2022 09:48:36 - INFO - __main__ - Step 470 Global step 470 Train loss 4.52 on epoch=33
05/20/2022 09:48:37 - INFO - __main__ - Step 480 Global step 480 Train loss 4.45 on epoch=34
05/20/2022 09:48:38 - INFO - __main__ - Step 490 Global step 490 Train loss 4.33 on epoch=34
05/20/2022 09:48:40 - INFO - __main__ - Step 500 Global step 500 Train loss 4.47 on epoch=35
05/20/2022 09:48:42 - INFO - __main__ - Global step 500 Train loss 4.47 Classification-F1 0.009523809523809523 on epoch=35
05/20/2022 09:48:43 - INFO - __main__ - Step 510 Global step 510 Train loss 4.27 on epoch=36
05/20/2022 09:48:44 - INFO - __main__ - Step 520 Global step 520 Train loss 4.44 on epoch=37
05/20/2022 09:48:46 - INFO - __main__ - Step 530 Global step 530 Train loss 4.27 on epoch=37
05/20/2022 09:48:47 - INFO - __main__ - Step 540 Global step 540 Train loss 4.14 on epoch=38
05/20/2022 09:48:48 - INFO - __main__ - Step 550 Global step 550 Train loss 4.22 on epoch=39
05/20/2022 09:48:50 - INFO - __main__ - Global step 550 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=39
05/20/2022 09:48:51 - INFO - __main__ - Step 560 Global step 560 Train loss 4.17 on epoch=39
05/20/2022 09:48:52 - INFO - __main__ - Step 570 Global step 570 Train loss 4.06 on epoch=40
05/20/2022 09:48:54 - INFO - __main__ - Step 580 Global step 580 Train loss 3.98 on epoch=41
05/20/2022 09:48:55 - INFO - __main__ - Step 590 Global step 590 Train loss 3.99 on epoch=42
05/20/2022 09:48:56 - INFO - __main__ - Step 600 Global step 600 Train loss 4.09 on epoch=42
05/20/2022 09:48:58 - INFO - __main__ - Global step 600 Train loss 4.06 Classification-F1 0.009523809523809523 on epoch=42
05/20/2022 09:49:00 - INFO - __main__ - Step 610 Global step 610 Train loss 3.90 on epoch=43
05/20/2022 09:49:01 - INFO - __main__ - Step 620 Global step 620 Train loss 3.77 on epoch=44
05/20/2022 09:49:02 - INFO - __main__ - Step 630 Global step 630 Train loss 3.80 on epoch=44
05/20/2022 09:49:03 - INFO - __main__ - Step 640 Global step 640 Train loss 3.90 on epoch=45
05/20/2022 09:49:05 - INFO - __main__ - Step 650 Global step 650 Train loss 3.71 on epoch=46
05/20/2022 09:49:06 - INFO - __main__ - Global step 650 Train loss 3.81 Classification-F1 0.009523809523809523 on epoch=46
05/20/2022 09:49:08 - INFO - __main__ - Step 660 Global step 660 Train loss 3.63 on epoch=47
05/20/2022 09:49:09 - INFO - __main__ - Step 670 Global step 670 Train loss 3.64 on epoch=47
05/20/2022 09:49:10 - INFO - __main__ - Step 680 Global step 680 Train loss 3.67 on epoch=48
05/20/2022 09:49:11 - INFO - __main__ - Step 690 Global step 690 Train loss 3.72 on epoch=49
05/20/2022 09:49:13 - INFO - __main__ - Step 700 Global step 700 Train loss 3.55 on epoch=49
05/20/2022 09:49:15 - INFO - __main__ - Global step 700 Train loss 3.64 Classification-F1 0.024408468244084682 on epoch=49
05/20/2022 09:49:15 - INFO - __main__ - Saving model with best Classification-F1: 0.01215277777777778 -> 0.024408468244084682 on epoch=49, global_step=700
05/20/2022 09:49:16 - INFO - __main__ - Step 710 Global step 710 Train loss 3.68 on epoch=50
05/20/2022 09:49:17 - INFO - __main__ - Step 720 Global step 720 Train loss 3.56 on epoch=51
05/20/2022 09:49:18 - INFO - __main__ - Step 730 Global step 730 Train loss 3.49 on epoch=52
05/20/2022 09:49:20 - INFO - __main__ - Step 740 Global step 740 Train loss 3.46 on epoch=52
05/20/2022 09:49:21 - INFO - __main__ - Step 750 Global step 750 Train loss 3.36 on epoch=53
05/20/2022 09:49:23 - INFO - __main__ - Global step 750 Train loss 3.51 Classification-F1 0.025960798985678952 on epoch=53
05/20/2022 09:49:23 - INFO - __main__ - Saving model with best Classification-F1: 0.024408468244084682 -> 0.025960798985678952 on epoch=53, global_step=750
05/20/2022 09:49:24 - INFO - __main__ - Step 760 Global step 760 Train loss 3.37 on epoch=54
05/20/2022 09:49:25 - INFO - __main__ - Step 770 Global step 770 Train loss 3.45 on epoch=54
05/20/2022 09:49:27 - INFO - __main__ - Step 780 Global step 780 Train loss 3.50 on epoch=55
05/20/2022 09:49:28 - INFO - __main__ - Step 790 Global step 790 Train loss 3.35 on epoch=56
05/20/2022 09:49:29 - INFO - __main__ - Step 800 Global step 800 Train loss 3.30 on epoch=57
05/20/2022 09:49:31 - INFO - __main__ - Global step 800 Train loss 3.39 Classification-F1 0.028797581150674156 on epoch=57
05/20/2022 09:49:31 - INFO - __main__ - Saving model with best Classification-F1: 0.025960798985678952 -> 0.028797581150674156 on epoch=57, global_step=800
05/20/2022 09:49:32 - INFO - __main__ - Step 810 Global step 810 Train loss 3.43 on epoch=57
05/20/2022 09:49:34 - INFO - __main__ - Step 820 Global step 820 Train loss 3.23 on epoch=58
05/20/2022 09:49:35 - INFO - __main__ - Step 830 Global step 830 Train loss 3.39 on epoch=59
05/20/2022 09:49:36 - INFO - __main__ - Step 840 Global step 840 Train loss 3.34 on epoch=59
05/20/2022 09:49:37 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/20/2022 09:49:39 - INFO - __main__ - Global step 850 Train loss 3.32 Classification-F1 0.024344964816523453 on epoch=60
05/20/2022 09:49:41 - INFO - __main__ - Step 860 Global step 860 Train loss 3.15 on epoch=61
05/20/2022 09:49:42 - INFO - __main__ - Step 870 Global step 870 Train loss 3.24 on epoch=62
05/20/2022 09:49:43 - INFO - __main__ - Step 880 Global step 880 Train loss 3.32 on epoch=62
05/20/2022 09:49:44 - INFO - __main__ - Step 890 Global step 890 Train loss 3.16 on epoch=63
05/20/2022 09:49:46 - INFO - __main__ - Step 900 Global step 900 Train loss 3.35 on epoch=64
05/20/2022 09:49:47 - INFO - __main__ - Global step 900 Train loss 3.24 Classification-F1 0.009726443768996961 on epoch=64
05/20/2022 09:49:49 - INFO - __main__ - Step 910 Global step 910 Train loss 3.23 on epoch=64
05/20/2022 09:49:50 - INFO - __main__ - Step 920 Global step 920 Train loss 3.27 on epoch=65
05/20/2022 09:49:51 - INFO - __main__ - Step 930 Global step 930 Train loss 3.23 on epoch=66
05/20/2022 09:49:53 - INFO - __main__ - Step 940 Global step 940 Train loss 3.08 on epoch=67
05/20/2022 09:49:54 - INFO - __main__ - Step 950 Global step 950 Train loss 3.14 on epoch=67
05/20/2022 09:49:56 - INFO - __main__ - Global step 950 Train loss 3.19 Classification-F1 0.03988684582743989 on epoch=67
05/20/2022 09:49:56 - INFO - __main__ - Saving model with best Classification-F1: 0.028797581150674156 -> 0.03988684582743989 on epoch=67, global_step=950
05/20/2022 09:49:57 - INFO - __main__ - Step 960 Global step 960 Train loss 3.18 on epoch=68
05/20/2022 09:49:58 - INFO - __main__ - Step 970 Global step 970 Train loss 3.37 on epoch=69
05/20/2022 09:50:00 - INFO - __main__ - Step 980 Global step 980 Train loss 3.08 on epoch=69
05/20/2022 09:50:01 - INFO - __main__ - Step 990 Global step 990 Train loss 3.08 on epoch=70
05/20/2022 09:50:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.00 on epoch=71
05/20/2022 09:50:04 - INFO - __main__ - Global step 1000 Train loss 3.14 Classification-F1 0.009563658099222952 on epoch=71
05/20/2022 09:50:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.06 on epoch=72
05/20/2022 09:50:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.16 on epoch=72
05/20/2022 09:50:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.99 on epoch=73
05/20/2022 09:50:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.22 on epoch=74
05/20/2022 09:50:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.98 on epoch=74
05/20/2022 09:50:12 - INFO - __main__ - Global step 1050 Train loss 3.08 Classification-F1 0.03559501611080259 on epoch=74
05/20/2022 09:50:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.13 on epoch=75
05/20/2022 09:50:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.96 on epoch=76
05/20/2022 09:50:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.00 on epoch=77
05/20/2022 09:50:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.10 on epoch=77
05/20/2022 09:50:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.97 on epoch=78
05/20/2022 09:50:20 - INFO - __main__ - Global step 1100 Train loss 3.03 Classification-F1 0.024012158054711248 on epoch=78
05/20/2022 09:50:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.11 on epoch=79
05/20/2022 09:50:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.89 on epoch=79
05/20/2022 09:50:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.02 on epoch=80
05/20/2022 09:50:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.90 on epoch=81
05/20/2022 09:50:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.99 on epoch=82
05/20/2022 09:50:29 - INFO - __main__ - Global step 1150 Train loss 2.98 Classification-F1 0.03926738212577846 on epoch=82
05/20/2022 09:50:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.03 on epoch=82
05/20/2022 09:50:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.01 on epoch=83
05/20/2022 09:50:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.92 on epoch=84
05/20/2022 09:50:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.85 on epoch=84
05/20/2022 09:50:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.08 on epoch=85
05/20/2022 09:50:37 - INFO - __main__ - Global step 1200 Train loss 2.98 Classification-F1 0.05591070884161431 on epoch=85
05/20/2022 09:50:37 - INFO - __main__ - Saving model with best Classification-F1: 0.03988684582743989 -> 0.05591070884161431 on epoch=85, global_step=1200
05/20/2022 09:50:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.97 on epoch=86
05/20/2022 09:50:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.03 on epoch=87
05/20/2022 09:50:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.75 on epoch=87
05/20/2022 09:50:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.93 on epoch=88
05/20/2022 09:50:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.01 on epoch=89
05/20/2022 09:50:45 - INFO - __main__ - Global step 1250 Train loss 2.94 Classification-F1 0.012645502645502646 on epoch=89
05/20/2022 09:50:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.85 on epoch=89
05/20/2022 09:50:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.98 on epoch=90
05/20/2022 09:50:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.78 on epoch=91
05/20/2022 09:50:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.84 on epoch=92
05/20/2022 09:50:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.96 on epoch=92
05/20/2022 09:50:53 - INFO - __main__ - Global step 1300 Train loss 2.88 Classification-F1 0.02854864433811802 on epoch=92
05/20/2022 09:50:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.72 on epoch=93
05/20/2022 09:50:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.87 on epoch=94
05/20/2022 09:50:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.80 on epoch=94
05/20/2022 09:50:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.93 on epoch=95
05/20/2022 09:51:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.77 on epoch=96
05/20/2022 09:51:01 - INFO - __main__ - Global step 1350 Train loss 2.82 Classification-F1 0.0503467087318019 on epoch=96
05/20/2022 09:51:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.79 on epoch=97
05/20/2022 09:51:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.81 on epoch=97
05/20/2022 09:51:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.51 on epoch=98
05/20/2022 09:51:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.80 on epoch=99
05/20/2022 09:51:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.60 on epoch=99
05/20/2022 09:51:10 - INFO - __main__ - Global step 1400 Train loss 2.70 Classification-F1 0.05899651301474002 on epoch=99
05/20/2022 09:51:10 - INFO - __main__ - Saving model with best Classification-F1: 0.05591070884161431 -> 0.05899651301474002 on epoch=99, global_step=1400
05/20/2022 09:51:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.79 on epoch=100
05/20/2022 09:51:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.70 on epoch=101
05/20/2022 09:51:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.68 on epoch=102
05/20/2022 09:51:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.83 on epoch=102
05/20/2022 09:51:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.62 on epoch=103
05/20/2022 09:51:18 - INFO - __main__ - Global step 1450 Train loss 2.72 Classification-F1 0.06075578556781564 on epoch=103
05/20/2022 09:51:18 - INFO - __main__ - Saving model with best Classification-F1: 0.05899651301474002 -> 0.06075578556781564 on epoch=103, global_step=1450
05/20/2022 09:51:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.81 on epoch=104
05/20/2022 09:51:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.69 on epoch=104
05/20/2022 09:51:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.90 on epoch=105
05/20/2022 09:51:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.69 on epoch=106
05/20/2022 09:51:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.59 on epoch=107
05/20/2022 09:51:26 - INFO - __main__ - Global step 1500 Train loss 2.74 Classification-F1 0.06039103118789736 on epoch=107
05/20/2022 09:51:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.90 on epoch=107
05/20/2022 09:51:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.76 on epoch=108
05/20/2022 09:51:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.89 on epoch=109
05/20/2022 09:51:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.84 on epoch=109
05/20/2022 09:51:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.79 on epoch=110
05/20/2022 09:51:34 - INFO - __main__ - Global step 1550 Train loss 2.84 Classification-F1 0.045434429746823636 on epoch=110
05/20/2022 09:51:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.68 on epoch=111
05/20/2022 09:51:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.71 on epoch=112
05/20/2022 09:51:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.86 on epoch=112
05/20/2022 09:51:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.85 on epoch=113
05/20/2022 09:51:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.91 on epoch=114
05/20/2022 09:51:43 - INFO - __main__ - Global step 1600 Train loss 2.80 Classification-F1 0.034115464367565206 on epoch=114
05/20/2022 09:51:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.70 on epoch=114
05/20/2022 09:51:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.90 on epoch=115
05/20/2022 09:51:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.69 on epoch=116
05/20/2022 09:51:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.66 on epoch=117
05/20/2022 09:51:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.70 on epoch=117
05/20/2022 09:51:51 - INFO - __main__ - Global step 1650 Train loss 2.73 Classification-F1 0.05213988549536723 on epoch=117
05/20/2022 09:51:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.69 on epoch=118
05/20/2022 09:51:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.78 on epoch=119
05/20/2022 09:51:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.75 on epoch=119
05/20/2022 09:51:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.76 on epoch=120
05/20/2022 09:51:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.61 on epoch=121
05/20/2022 09:51:59 - INFO - __main__ - Global step 1700 Train loss 2.72 Classification-F1 0.04008525852585259 on epoch=121
05/20/2022 09:52:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.55 on epoch=122
05/20/2022 09:52:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.66 on epoch=122
05/20/2022 09:52:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.66 on epoch=123
05/20/2022 09:52:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.77 on epoch=124
05/20/2022 09:52:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.62 on epoch=124
05/20/2022 09:52:07 - INFO - __main__ - Global step 1750 Train loss 2.65 Classification-F1 0.03936439147706753 on epoch=124
05/20/2022 09:52:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.57 on epoch=125
05/20/2022 09:52:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.57 on epoch=126
05/20/2022 09:52:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.69 on epoch=127
05/20/2022 09:52:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.64 on epoch=127
05/20/2022 09:52:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.63 on epoch=128
05/20/2022 09:52:16 - INFO - __main__ - Global step 1800 Train loss 2.62 Classification-F1 0.04099675712578939 on epoch=128
05/20/2022 09:52:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.63 on epoch=129
05/20/2022 09:52:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.57 on epoch=129
05/20/2022 09:52:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.79 on epoch=130
05/20/2022 09:52:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.49 on epoch=131
05/20/2022 09:52:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.43 on epoch=132
05/20/2022 09:52:25 - INFO - __main__ - Global step 1850 Train loss 2.58 Classification-F1 0.06432599621454112 on epoch=132
05/20/2022 09:52:25 - INFO - __main__ - Saving model with best Classification-F1: 0.06075578556781564 -> 0.06432599621454112 on epoch=132, global_step=1850
05/20/2022 09:52:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.60 on epoch=132
05/20/2022 09:52:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.45 on epoch=133
05/20/2022 09:52:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.55 on epoch=134
05/20/2022 09:52:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.42 on epoch=134
05/20/2022 09:52:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.60 on epoch=135
05/20/2022 09:52:33 - INFO - __main__ - Global step 1900 Train loss 2.52 Classification-F1 0.06273607345035916 on epoch=135
05/20/2022 09:52:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.51 on epoch=136
05/20/2022 09:52:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.50 on epoch=137
05/20/2022 09:52:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.52 on epoch=137
05/20/2022 09:52:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.44 on epoch=138
05/20/2022 09:52:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.53 on epoch=139
05/20/2022 09:52:42 - INFO - __main__ - Global step 1950 Train loss 2.50 Classification-F1 0.07868985103654184 on epoch=139
05/20/2022 09:52:42 - INFO - __main__ - Saving model with best Classification-F1: 0.06432599621454112 -> 0.07868985103654184 on epoch=139, global_step=1950
05/20/2022 09:52:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.38 on epoch=139
05/20/2022 09:52:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.52 on epoch=140
05/20/2022 09:52:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.42 on epoch=141
05/20/2022 09:52:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.49 on epoch=142
05/20/2022 09:52:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.58 on epoch=142
05/20/2022 09:52:50 - INFO - __main__ - Global step 2000 Train loss 2.48 Classification-F1 0.03327922077922078 on epoch=142
05/20/2022 09:52:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.38 on epoch=143
05/20/2022 09:52:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.49 on epoch=144
05/20/2022 09:52:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.38 on epoch=144
05/20/2022 09:52:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.39 on epoch=145
05/20/2022 09:52:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.35 on epoch=146
05/20/2022 09:52:58 - INFO - __main__ - Global step 2050 Train loss 2.40 Classification-F1 0.03295707407856941 on epoch=146
05/20/2022 09:52:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.41 on epoch=147
05/20/2022 09:53:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.26 on epoch=147
05/20/2022 09:53:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.22 on epoch=148
05/20/2022 09:53:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.52 on epoch=149
05/20/2022 09:53:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.41 on epoch=149
05/20/2022 09:53:06 - INFO - __main__ - Global step 2100 Train loss 2.37 Classification-F1 0.03571428571428571 on epoch=149
05/20/2022 09:53:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.41 on epoch=150
05/20/2022 09:53:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.30 on epoch=151
05/20/2022 09:53:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.30 on epoch=152
05/20/2022 09:53:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.51 on epoch=152
05/20/2022 09:53:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.42 on epoch=153
05/20/2022 09:53:15 - INFO - __main__ - Global step 2150 Train loss 2.39 Classification-F1 0.056014266171584906 on epoch=153
05/20/2022 09:53:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.42 on epoch=154
05/20/2022 09:53:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.32 on epoch=154
05/20/2022 09:53:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.45 on epoch=155
05/20/2022 09:53:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.13 on epoch=156
05/20/2022 09:53:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.20 on epoch=157
05/20/2022 09:53:23 - INFO - __main__ - Global step 2200 Train loss 2.30 Classification-F1 0.021790041747276247 on epoch=157
05/20/2022 09:53:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.33 on epoch=157
05/20/2022 09:53:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.31 on epoch=158
05/20/2022 09:53:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.29 on epoch=159
05/20/2022 09:53:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.39 on epoch=159
05/20/2022 09:53:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.28 on epoch=160
05/20/2022 09:53:31 - INFO - __main__ - Global step 2250 Train loss 2.32 Classification-F1 0.08729050081403379 on epoch=160
05/20/2022 09:53:31 - INFO - __main__ - Saving model with best Classification-F1: 0.07868985103654184 -> 0.08729050081403379 on epoch=160, global_step=2250
05/20/2022 09:53:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.26 on epoch=161
05/20/2022 09:53:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.31 on epoch=162
05/20/2022 09:53:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.33 on epoch=162
05/20/2022 09:53:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.30 on epoch=163
05/20/2022 09:53:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.23 on epoch=164
05/20/2022 09:53:40 - INFO - __main__ - Global step 2300 Train loss 2.28 Classification-F1 0.027275864232385972 on epoch=164
05/20/2022 09:53:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.14 on epoch=164
05/20/2022 09:53:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.33 on epoch=165
05/20/2022 09:53:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.25 on epoch=166
05/20/2022 09:53:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.26 on epoch=167
05/20/2022 09:53:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.31 on epoch=167
05/20/2022 09:53:48 - INFO - __main__ - Global step 2350 Train loss 2.26 Classification-F1 0.025114283467927625 on epoch=167
05/20/2022 09:53:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.08 on epoch=168
05/20/2022 09:53:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.14 on epoch=169
05/20/2022 09:53:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.07 on epoch=169
05/20/2022 09:53:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.19 on epoch=170
05/20/2022 09:53:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.17 on epoch=171
05/20/2022 09:53:57 - INFO - __main__ - Global step 2400 Train loss 2.13 Classification-F1 0.11498029508593534 on epoch=171
05/20/2022 09:53:57 - INFO - __main__ - Saving model with best Classification-F1: 0.08729050081403379 -> 0.11498029508593534 on epoch=171, global_step=2400
05/20/2022 09:53:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.19 on epoch=172
05/20/2022 09:54:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.16 on epoch=172
05/20/2022 09:54:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.07 on epoch=173
05/20/2022 09:54:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.11 on epoch=174
05/20/2022 09:54:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.02 on epoch=174
05/20/2022 09:54:06 - INFO - __main__ - Global step 2450 Train loss 2.11 Classification-F1 0.05520253017161674 on epoch=174
05/20/2022 09:54:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.25 on epoch=175
05/20/2022 09:54:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.03 on epoch=176
05/20/2022 09:54:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.01 on epoch=177
05/20/2022 09:54:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.14 on epoch=177
05/20/2022 09:54:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.10 on epoch=178
05/20/2022 09:54:14 - INFO - __main__ - Global step 2500 Train loss 2.10 Classification-F1 0.07884223923683185 on epoch=178
05/20/2022 09:54:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.04 on epoch=179
05/20/2022 09:54:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.06 on epoch=179
05/20/2022 09:54:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.07 on epoch=180
05/20/2022 09:54:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.98 on epoch=181
05/20/2022 09:54:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.18 on epoch=182
05/20/2022 09:54:22 - INFO - __main__ - Global step 2550 Train loss 2.07 Classification-F1 0.07902730984867065 on epoch=182
05/20/2022 09:54:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.02 on epoch=182
05/20/2022 09:54:25 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.01 on epoch=183
05/20/2022 09:54:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.03 on epoch=184
05/20/2022 09:54:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.06 on epoch=184
05/20/2022 09:54:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.09 on epoch=185
05/20/2022 09:54:30 - INFO - __main__ - Global step 2600 Train loss 2.04 Classification-F1 0.038448712818460726 on epoch=185
05/20/2022 09:54:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.95 on epoch=186
05/20/2022 09:54:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.94 on epoch=187
05/20/2022 09:54:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.92 on epoch=187
05/20/2022 09:54:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.97 on epoch=188
05/20/2022 09:54:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.04 on epoch=189
05/20/2022 09:54:39 - INFO - __main__ - Global step 2650 Train loss 1.97 Classification-F1 0.03574597540879706 on epoch=189
05/20/2022 09:54:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.90 on epoch=189
05/20/2022 09:54:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.04 on epoch=190
05/20/2022 09:54:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.03 on epoch=191
05/20/2022 09:54:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.03 on epoch=192
05/20/2022 09:54:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.87 on epoch=192
05/20/2022 09:54:48 - INFO - __main__ - Global step 2700 Train loss 1.97 Classification-F1 0.04159743338627463 on epoch=192
05/20/2022 09:54:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.89 on epoch=193
05/20/2022 09:54:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.01 on epoch=194
05/20/2022 09:54:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.88 on epoch=194
05/20/2022 09:54:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.01 on epoch=195
05/20/2022 09:54:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.69 on epoch=196
05/20/2022 09:54:56 - INFO - __main__ - Global step 2750 Train loss 1.90 Classification-F1 0.07502613948805328 on epoch=196
05/20/2022 09:54:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.94 on epoch=197
05/20/2022 09:54:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.92 on epoch=197
05/20/2022 09:55:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.96 on epoch=198
05/20/2022 09:55:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.68 on epoch=199
05/20/2022 09:55:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.71 on epoch=199
05/20/2022 09:55:04 - INFO - __main__ - Global step 2800 Train loss 1.84 Classification-F1 0.04879460556152286 on epoch=199
05/20/2022 09:55:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.92 on epoch=200
05/20/2022 09:55:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.89 on epoch=201
05/20/2022 09:55:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.75 on epoch=202
05/20/2022 09:55:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.68 on epoch=202
05/20/2022 09:55:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.98 on epoch=203
05/20/2022 09:55:13 - INFO - __main__ - Global step 2850 Train loss 1.84 Classification-F1 0.07830965417019801 on epoch=203
05/20/2022 09:55:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.71 on epoch=204
05/20/2022 09:55:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.70 on epoch=204
05/20/2022 09:55:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.68 on epoch=205
05/20/2022 09:55:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.88 on epoch=206
05/20/2022 09:55:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.85 on epoch=207
05/20/2022 09:55:21 - INFO - __main__ - Global step 2900 Train loss 1.77 Classification-F1 0.08540829098120564 on epoch=207
05/20/2022 09:55:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.75 on epoch=207
05/20/2022 09:55:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.66 on epoch=208
05/20/2022 09:55:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.77 on epoch=209
05/20/2022 09:55:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.83 on epoch=209
05/20/2022 09:55:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.83 on epoch=210
05/20/2022 09:55:30 - INFO - __main__ - Global step 2950 Train loss 1.77 Classification-F1 0.05729429231733379 on epoch=210
05/20/2022 09:55:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.82 on epoch=211
05/20/2022 09:55:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.73 on epoch=212
05/20/2022 09:55:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.65 on epoch=212
05/20/2022 09:55:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.65 on epoch=213
05/20/2022 09:55:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.71 on epoch=214
05/20/2022 09:55:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:55:37 - INFO - __main__ - Printing 3 examples
05/20/2022 09:55:37 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 09:55:37 - INFO - __main__ - ['Animal']
05/20/2022 09:55:37 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 09:55:37 - INFO - __main__ - ['Animal']
05/20/2022 09:55:37 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 09:55:37 - INFO - __main__ - ['Animal']
05/20/2022 09:55:37 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:55:37 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:55:38 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 09:55:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:55:38 - INFO - __main__ - Printing 3 examples
05/20/2022 09:55:38 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 09:55:38 - INFO - __main__ - ['Animal']
05/20/2022 09:55:38 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 09:55:38 - INFO - __main__ - ['Animal']
05/20/2022 09:55:38 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 09:55:38 - INFO - __main__ - ['Animal']
05/20/2022 09:55:38 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:55:38 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:55:38 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 09:55:39 - INFO - __main__ - Global step 3000 Train loss 1.71 Classification-F1 0.10399315101612874 on epoch=214
05/20/2022 09:55:39 - INFO - __main__ - save last model!
05/20/2022 09:55:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 09:55:39 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 09:55:39 - INFO - __main__ - Printing 3 examples
05/20/2022 09:55:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 09:55:39 - INFO - __main__ - ['Animal']
05/20/2022 09:55:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 09:55:39 - INFO - __main__ - ['Animal']
05/20/2022 09:55:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 09:55:39 - INFO - __main__ - ['Village']
05/20/2022 09:55:39 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:55:40 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:55:44 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 09:55:44 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 09:55:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 09:55:44 - INFO - __main__ - Starting training!
05/20/2022 09:56:27 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/20/2022 09:56:27 - INFO - __main__ - Classification-F1 on test data: 0.0803
05/20/2022 09:56:28 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.11498029508593534, test_performance=0.08025207598044115
05/20/2022 09:56:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/20/2022 09:56:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:56:28 - INFO - __main__ - Printing 3 examples
05/20/2022 09:56:28 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 09:56:28 - INFO - __main__ - ['Animal']
05/20/2022 09:56:28 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 09:56:28 - INFO - __main__ - ['Animal']
05/20/2022 09:56:28 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 09:56:28 - INFO - __main__ - ['Animal']
05/20/2022 09:56:28 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:56:29 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:56:29 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 09:56:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 09:56:29 - INFO - __main__ - Printing 3 examples
05/20/2022 09:56:29 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 09:56:29 - INFO - __main__ - ['Animal']
05/20/2022 09:56:29 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 09:56:29 - INFO - __main__ - ['Animal']
05/20/2022 09:56:29 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 09:56:29 - INFO - __main__ - ['Animal']
05/20/2022 09:56:29 - INFO - __main__ - Tokenizing Input ...
05/20/2022 09:56:29 - INFO - __main__ - Tokenizing Output ...
05/20/2022 09:56:29 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 09:56:34 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 09:56:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 09:56:35 - INFO - __main__ - Starting training!
05/20/2022 09:56:36 - INFO - __main__ - Step 10 Global step 10 Train loss 7.34 on epoch=0
05/20/2022 09:56:37 - INFO - __main__ - Step 20 Global step 20 Train loss 7.31 on epoch=1
05/20/2022 09:56:39 - INFO - __main__ - Step 30 Global step 30 Train loss 7.12 on epoch=2
05/20/2022 09:56:40 - INFO - __main__ - Step 40 Global step 40 Train loss 7.04 on epoch=2
05/20/2022 09:56:41 - INFO - __main__ - Step 50 Global step 50 Train loss 7.03 on epoch=3
05/20/2022 09:57:03 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/20/2022 09:57:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 09:57:04 - INFO - __main__ - Step 60 Global step 60 Train loss 6.63 on epoch=4
05/20/2022 09:57:05 - INFO - __main__ - Step 70 Global step 70 Train loss 6.95 on epoch=4
05/20/2022 09:57:06 - INFO - __main__ - Step 80 Global step 80 Train loss 6.78 on epoch=5
05/20/2022 09:57:08 - INFO - __main__ - Step 90 Global step 90 Train loss 6.72 on epoch=6
05/20/2022 09:57:09 - INFO - __main__ - Step 100 Global step 100 Train loss 6.57 on epoch=7
05/20/2022 09:58:03 - INFO - __main__ - Global step 100 Train loss 6.73 Classification-F1 0.0 on epoch=7
05/20/2022 09:58:04 - INFO - __main__ - Step 110 Global step 110 Train loss 6.53 on epoch=7
05/20/2022 09:58:05 - INFO - __main__ - Step 120 Global step 120 Train loss 6.48 on epoch=8
05/20/2022 09:58:06 - INFO - __main__ - Step 130 Global step 130 Train loss 6.39 on epoch=9
05/20/2022 09:58:07 - INFO - __main__ - Step 140 Global step 140 Train loss 6.45 on epoch=9
05/20/2022 09:58:09 - INFO - __main__ - Step 150 Global step 150 Train loss 6.37 on epoch=10
05/20/2022 09:58:41 - INFO - __main__ - Global step 150 Train loss 6.45 Classification-F1 0.0 on epoch=10
05/20/2022 09:58:43 - INFO - __main__ - Step 160 Global step 160 Train loss 6.39 on epoch=11
05/20/2022 09:58:44 - INFO - __main__ - Step 170 Global step 170 Train loss 6.15 on epoch=12
05/20/2022 09:58:45 - INFO - __main__ - Step 180 Global step 180 Train loss 6.09 on epoch=12
05/20/2022 09:58:46 - INFO - __main__ - Step 190 Global step 190 Train loss 6.24 on epoch=13
05/20/2022 09:58:48 - INFO - __main__ - Step 200 Global step 200 Train loss 6.02 on epoch=14
05/20/2022 09:59:17 - INFO - __main__ - Global step 200 Train loss 6.18 Classification-F1 0.0 on epoch=14
05/20/2022 09:59:18 - INFO - __main__ - Step 210 Global step 210 Train loss 6.26 on epoch=14
05/20/2022 09:59:19 - INFO - __main__ - Step 220 Global step 220 Train loss 6.20 on epoch=15
05/20/2022 09:59:21 - INFO - __main__ - Step 230 Global step 230 Train loss 6.08 on epoch=16
05/20/2022 09:59:22 - INFO - __main__ - Step 240 Global step 240 Train loss 5.89 on epoch=17
05/20/2022 09:59:23 - INFO - __main__ - Step 250 Global step 250 Train loss 5.94 on epoch=17
05/20/2022 10:00:16 - INFO - __main__ - Global step 250 Train loss 6.07 Classification-F1 0.0 on epoch=17
05/20/2022 10:00:17 - INFO - __main__ - Step 260 Global step 260 Train loss 5.95 on epoch=18
05/20/2022 10:00:18 - INFO - __main__ - Step 270 Global step 270 Train loss 5.73 on epoch=19
05/20/2022 10:00:20 - INFO - __main__ - Step 280 Global step 280 Train loss 5.78 on epoch=19
05/20/2022 10:00:21 - INFO - __main__ - Step 290 Global step 290 Train loss 5.74 on epoch=20
05/20/2022 10:00:22 - INFO - __main__ - Step 300 Global step 300 Train loss 5.59 on epoch=21
05/20/2022 10:00:56 - INFO - __main__ - Global step 300 Train loss 5.76 Classification-F1 0.0 on epoch=21
05/20/2022 10:00:57 - INFO - __main__ - Step 310 Global step 310 Train loss 5.58 on epoch=22
05/20/2022 10:00:58 - INFO - __main__ - Step 320 Global step 320 Train loss 5.66 on epoch=22
05/20/2022 10:00:59 - INFO - __main__ - Step 330 Global step 330 Train loss 5.60 on epoch=23
05/20/2022 10:01:00 - INFO - __main__ - Step 340 Global step 340 Train loss 5.46 on epoch=24
05/20/2022 10:01:02 - INFO - __main__ - Step 350 Global step 350 Train loss 5.70 on epoch=24
05/20/2022 10:01:39 - INFO - __main__ - Global step 350 Train loss 5.60 Classification-F1 0.0 on epoch=24
05/20/2022 10:01:40 - INFO - __main__ - Step 360 Global step 360 Train loss 5.53 on epoch=25
05/20/2022 10:01:41 - INFO - __main__ - Step 370 Global step 370 Train loss 5.51 on epoch=26
05/20/2022 10:01:43 - INFO - __main__ - Step 380 Global step 380 Train loss 5.45 on epoch=27
05/20/2022 10:01:44 - INFO - __main__ - Step 390 Global step 390 Train loss 5.47 on epoch=27
05/20/2022 10:01:45 - INFO - __main__ - Step 400 Global step 400 Train loss 5.40 on epoch=28
05/20/2022 10:01:56 - INFO - __main__ - Global step 400 Train loss 5.47 Classification-F1 0.0 on epoch=28
05/20/2022 10:01:57 - INFO - __main__ - Step 410 Global step 410 Train loss 5.40 on epoch=29
05/20/2022 10:01:59 - INFO - __main__ - Step 420 Global step 420 Train loss 5.23 on epoch=29
05/20/2022 10:02:00 - INFO - __main__ - Step 430 Global step 430 Train loss 5.28 on epoch=30
05/20/2022 10:02:01 - INFO - __main__ - Step 440 Global step 440 Train loss 5.34 on epoch=31
05/20/2022 10:02:02 - INFO - __main__ - Step 450 Global step 450 Train loss 5.18 on epoch=32
05/20/2022 10:02:15 - INFO - __main__ - Global step 450 Train loss 5.28 Classification-F1 0.0 on epoch=32
05/20/2022 10:02:16 - INFO - __main__ - Step 460 Global step 460 Train loss 5.28 on epoch=32
05/20/2022 10:02:17 - INFO - __main__ - Step 470 Global step 470 Train loss 5.14 on epoch=33
05/20/2022 10:02:18 - INFO - __main__ - Step 480 Global step 480 Train loss 5.04 on epoch=34
05/20/2022 10:02:20 - INFO - __main__ - Step 490 Global step 490 Train loss 5.14 on epoch=34
05/20/2022 10:02:21 - INFO - __main__ - Step 500 Global step 500 Train loss 5.21 on epoch=35
05/20/2022 10:02:29 - INFO - __main__ - Global step 500 Train loss 5.16 Classification-F1 0.0 on epoch=35
05/20/2022 10:02:30 - INFO - __main__ - Step 510 Global step 510 Train loss 5.03 on epoch=36
05/20/2022 10:02:31 - INFO - __main__ - Step 520 Global step 520 Train loss 4.89 on epoch=37
05/20/2022 10:02:32 - INFO - __main__ - Step 530 Global step 530 Train loss 5.06 on epoch=37
05/20/2022 10:02:33 - INFO - __main__ - Step 540 Global step 540 Train loss 4.91 on epoch=38
05/20/2022 10:02:35 - INFO - __main__ - Step 550 Global step 550 Train loss 5.00 on epoch=39
05/20/2022 10:02:38 - INFO - __main__ - Global step 550 Train loss 4.98 Classification-F1 0.004166666666666667 on epoch=39
05/20/2022 10:02:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.004166666666666667 on epoch=39, global_step=550
05/20/2022 10:02:39 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/20/2022 10:02:40 - INFO - __main__ - Step 570 Global step 570 Train loss 4.90 on epoch=40
05/20/2022 10:02:41 - INFO - __main__ - Step 580 Global step 580 Train loss 4.81 on epoch=41
05/20/2022 10:02:42 - INFO - __main__ - Step 590 Global step 590 Train loss 4.81 on epoch=42
05/20/2022 10:02:44 - INFO - __main__ - Step 600 Global step 600 Train loss 4.78 on epoch=42
05/20/2022 10:02:46 - INFO - __main__ - Global step 600 Train loss 4.88 Classification-F1 0.010912698412698416 on epoch=42
05/20/2022 10:02:46 - INFO - __main__ - Saving model with best Classification-F1: 0.004166666666666667 -> 0.010912698412698416 on epoch=42, global_step=600
05/20/2022 10:02:47 - INFO - __main__ - Step 610 Global step 610 Train loss 4.85 on epoch=43
05/20/2022 10:02:49 - INFO - __main__ - Step 620 Global step 620 Train loss 4.66 on epoch=44
05/20/2022 10:02:50 - INFO - __main__ - Step 630 Global step 630 Train loss 4.94 on epoch=44
05/20/2022 10:02:51 - INFO - __main__ - Step 640 Global step 640 Train loss 4.66 on epoch=45
05/20/2022 10:02:52 - INFO - __main__ - Step 650 Global step 650 Train loss 4.70 on epoch=46
05/20/2022 10:02:55 - INFO - __main__ - Global step 650 Train loss 4.76 Classification-F1 0.007352941176470588 on epoch=46
05/20/2022 10:02:56 - INFO - __main__ - Step 660 Global step 660 Train loss 4.61 on epoch=47
05/20/2022 10:02:57 - INFO - __main__ - Step 670 Global step 670 Train loss 4.68 on epoch=47
05/20/2022 10:02:58 - INFO - __main__ - Step 680 Global step 680 Train loss 4.60 on epoch=48
05/20/2022 10:03:00 - INFO - __main__ - Step 690 Global step 690 Train loss 4.43 on epoch=49
05/20/2022 10:03:01 - INFO - __main__ - Step 700 Global step 700 Train loss 4.56 on epoch=49
05/20/2022 10:03:03 - INFO - __main__ - Global step 700 Train loss 4.58 Classification-F1 0.00903954802259887 on epoch=49
05/20/2022 10:03:04 - INFO - __main__ - Step 710 Global step 710 Train loss 4.55 on epoch=50
05/20/2022 10:03:06 - INFO - __main__ - Step 720 Global step 720 Train loss 4.33 on epoch=51
05/20/2022 10:03:07 - INFO - __main__ - Step 730 Global step 730 Train loss 4.45 on epoch=52
05/20/2022 10:03:08 - INFO - __main__ - Step 740 Global step 740 Train loss 4.42 on epoch=52
05/20/2022 10:03:09 - INFO - __main__ - Step 750 Global step 750 Train loss 4.34 on epoch=53
05/20/2022 10:03:12 - INFO - __main__ - Global step 750 Train loss 4.42 Classification-F1 0.00892608089260809 on epoch=53
05/20/2022 10:03:13 - INFO - __main__ - Step 760 Global step 760 Train loss 4.43 on epoch=54
05/20/2022 10:03:14 - INFO - __main__ - Step 770 Global step 770 Train loss 4.29 on epoch=54
05/20/2022 10:03:15 - INFO - __main__ - Step 780 Global step 780 Train loss 4.28 on epoch=55
05/20/2022 10:03:16 - INFO - __main__ - Step 790 Global step 790 Train loss 4.22 on epoch=56
05/20/2022 10:03:18 - INFO - __main__ - Step 800 Global step 800 Train loss 4.15 on epoch=57
05/20/2022 10:03:20 - INFO - __main__ - Global step 800 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 10:03:21 - INFO - __main__ - Step 810 Global step 810 Train loss 4.24 on epoch=57
05/20/2022 10:03:22 - INFO - __main__ - Step 820 Global step 820 Train loss 4.05 on epoch=58
05/20/2022 10:03:23 - INFO - __main__ - Step 830 Global step 830 Train loss 4.15 on epoch=59
05/20/2022 10:03:24 - INFO - __main__ - Step 840 Global step 840 Train loss 4.00 on epoch=59
05/20/2022 10:03:26 - INFO - __main__ - Step 850 Global step 850 Train loss 4.05 on epoch=60
05/20/2022 10:03:27 - INFO - __main__ - Global step 850 Train loss 4.10 Classification-F1 0.009523809523809523 on epoch=60
05/20/2022 10:03:29 - INFO - __main__ - Step 860 Global step 860 Train loss 4.00 on epoch=61
05/20/2022 10:03:30 - INFO - __main__ - Step 870 Global step 870 Train loss 3.88 on epoch=62
05/20/2022 10:03:31 - INFO - __main__ - Step 880 Global step 880 Train loss 3.88 on epoch=62
05/20/2022 10:03:32 - INFO - __main__ - Step 890 Global step 890 Train loss 3.89 on epoch=63
05/20/2022 10:03:34 - INFO - __main__ - Step 900 Global step 900 Train loss 3.95 on epoch=64
05/20/2022 10:03:35 - INFO - __main__ - Global step 900 Train loss 3.92 Classification-F1 0.009523809523809523 on epoch=64
05/20/2022 10:03:37 - INFO - __main__ - Step 910 Global step 910 Train loss 3.87 on epoch=64
05/20/2022 10:03:38 - INFO - __main__ - Step 920 Global step 920 Train loss 3.96 on epoch=65
05/20/2022 10:03:39 - INFO - __main__ - Step 930 Global step 930 Train loss 3.76 on epoch=66
05/20/2022 10:03:40 - INFO - __main__ - Step 940 Global step 940 Train loss 3.61 on epoch=67
05/20/2022 10:03:42 - INFO - __main__ - Step 950 Global step 950 Train loss 3.79 on epoch=67
05/20/2022 10:03:44 - INFO - __main__ - Global step 950 Train loss 3.80 Classification-F1 0.019513819513819513 on epoch=67
05/20/2022 10:03:44 - INFO - __main__ - Saving model with best Classification-F1: 0.010912698412698416 -> 0.019513819513819513 on epoch=67, global_step=950
05/20/2022 10:03:45 - INFO - __main__ - Step 960 Global step 960 Train loss 3.62 on epoch=68
05/20/2022 10:03:46 - INFO - __main__ - Step 970 Global step 970 Train loss 3.70 on epoch=69
05/20/2022 10:03:47 - INFO - __main__ - Step 980 Global step 980 Train loss 3.75 on epoch=69
05/20/2022 10:03:48 - INFO - __main__ - Step 990 Global step 990 Train loss 3.81 on epoch=70
05/20/2022 10:03:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.55 on epoch=71
05/20/2022 10:03:51 - INFO - __main__ - Global step 1000 Train loss 3.69 Classification-F1 0.02487557352826814 on epoch=71
05/20/2022 10:03:51 - INFO - __main__ - Saving model with best Classification-F1: 0.019513819513819513 -> 0.02487557352826814 on epoch=71, global_step=1000
05/20/2022 10:03:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.43 on epoch=72
05/20/2022 10:03:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.51 on epoch=72
05/20/2022 10:03:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.50 on epoch=73
05/20/2022 10:03:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.52 on epoch=74
05/20/2022 10:03:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.49 on epoch=74
05/20/2022 10:03:59 - INFO - __main__ - Global step 1050 Train loss 3.49 Classification-F1 0.029365079365079365 on epoch=74
05/20/2022 10:04:00 - INFO - __main__ - Saving model with best Classification-F1: 0.02487557352826814 -> 0.029365079365079365 on epoch=74, global_step=1050
05/20/2022 10:04:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.42 on epoch=75
05/20/2022 10:04:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.29 on epoch=76
05/20/2022 10:04:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.29 on epoch=77
05/20/2022 10:04:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.34 on epoch=77
05/20/2022 10:04:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.25 on epoch=78
05/20/2022 10:04:07 - INFO - __main__ - Global step 1100 Train loss 3.32 Classification-F1 0.029725376664152172 on epoch=78
05/20/2022 10:04:07 - INFO - __main__ - Saving model with best Classification-F1: 0.029365079365079365 -> 0.029725376664152172 on epoch=78, global_step=1100
05/20/2022 10:04:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.46 on epoch=79
05/20/2022 10:04:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.18 on epoch=79
05/20/2022 10:04:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.31 on epoch=80
05/20/2022 10:04:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.15 on epoch=81
05/20/2022 10:04:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.27 on epoch=82
05/20/2022 10:04:15 - INFO - __main__ - Global step 1150 Train loss 3.28 Classification-F1 0.05411477411477412 on epoch=82
05/20/2022 10:04:15 - INFO - __main__ - Saving model with best Classification-F1: 0.029725376664152172 -> 0.05411477411477412 on epoch=82, global_step=1150
05/20/2022 10:04:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.26 on epoch=82
05/20/2022 10:04:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.14 on epoch=83
05/20/2022 10:04:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.37 on epoch=84
05/20/2022 10:04:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.13 on epoch=84
05/20/2022 10:04:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.33 on epoch=85
05/20/2022 10:04:23 - INFO - __main__ - Global step 1200 Train loss 3.24 Classification-F1 0.03407632123584524 on epoch=85
05/20/2022 10:04:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.07 on epoch=86
05/20/2022 10:04:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.19 on epoch=87
05/20/2022 10:04:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.24 on epoch=87
05/20/2022 10:04:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.05 on epoch=88
05/20/2022 10:04:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.16 on epoch=89
05/20/2022 10:04:31 - INFO - __main__ - Global step 1250 Train loss 3.14 Classification-F1 0.009523809523809523 on epoch=89
05/20/2022 10:04:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.20 on epoch=89
05/20/2022 10:04:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.15 on epoch=90
05/20/2022 10:04:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.00 on epoch=91
05/20/2022 10:04:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.97 on epoch=92
05/20/2022 10:04:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.12 on epoch=92
05/20/2022 10:04:39 - INFO - __main__ - Global step 1300 Train loss 3.09 Classification-F1 0.025522521901082982 on epoch=92
05/20/2022 10:04:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.03 on epoch=93
05/20/2022 10:04:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.13 on epoch=94
05/20/2022 10:04:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.12 on epoch=94
05/20/2022 10:04:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.22 on epoch=95
05/20/2022 10:04:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.02 on epoch=96
05/20/2022 10:04:48 - INFO - __main__ - Global step 1350 Train loss 3.11 Classification-F1 0.03929584434002696 on epoch=96
05/20/2022 10:04:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.05 on epoch=97
05/20/2022 10:04:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.03 on epoch=97
05/20/2022 10:04:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.07 on epoch=98
05/20/2022 10:04:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.22 on epoch=99
05/20/2022 10:04:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.84 on epoch=99
05/20/2022 10:04:56 - INFO - __main__ - Global step 1400 Train loss 3.04 Classification-F1 0.04978446674098848 on epoch=99
05/20/2022 10:04:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.99 on epoch=100
05/20/2022 10:04:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.87 on epoch=101
05/20/2022 10:05:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.98 on epoch=102
05/20/2022 10:05:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.99 on epoch=102
05/20/2022 10:05:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.99 on epoch=103
05/20/2022 10:05:04 - INFO - __main__ - Global step 1450 Train loss 2.97 Classification-F1 0.04846696398715437 on epoch=103
05/20/2022 10:05:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.18 on epoch=104
05/20/2022 10:05:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.93 on epoch=104
05/20/2022 10:05:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.98 on epoch=105
05/20/2022 10:05:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.71 on epoch=106
05/20/2022 10:05:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.93 on epoch=107
05/20/2022 10:05:12 - INFO - __main__ - Global step 1500 Train loss 2.95 Classification-F1 0.08564914993196823 on epoch=107
05/20/2022 10:05:12 - INFO - __main__ - Saving model with best Classification-F1: 0.05411477411477412 -> 0.08564914993196823 on epoch=107, global_step=1500
05/20/2022 10:05:13 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.94 on epoch=107
05/20/2022 10:05:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.81 on epoch=108
05/20/2022 10:05:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.93 on epoch=109
05/20/2022 10:05:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.90 on epoch=109
05/20/2022 10:05:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.96 on epoch=110
05/20/2022 10:05:20 - INFO - __main__ - Global step 1550 Train loss 2.91 Classification-F1 0.07037050172601314 on epoch=110
05/20/2022 10:05:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.95 on epoch=111
05/20/2022 10:05:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.89 on epoch=112
05/20/2022 10:05:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.89 on epoch=112
05/20/2022 10:05:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.80 on epoch=113
05/20/2022 10:05:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.80 on epoch=114
05/20/2022 10:05:28 - INFO - __main__ - Global step 1600 Train loss 2.86 Classification-F1 0.05826422254269592 on epoch=114
05/20/2022 10:05:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.66 on epoch=114
05/20/2022 10:05:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.92 on epoch=115
05/20/2022 10:05:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.76 on epoch=116
05/20/2022 10:05:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.80 on epoch=117
05/20/2022 10:05:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.87 on epoch=117
05/20/2022 10:05:36 - INFO - __main__ - Global step 1650 Train loss 2.80 Classification-F1 0.025524530857245906 on epoch=117
05/20/2022 10:05:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.73 on epoch=118
05/20/2022 10:05:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.90 on epoch=119
05/20/2022 10:05:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.73 on epoch=119
05/20/2022 10:05:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.77 on epoch=120
05/20/2022 10:05:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.73 on epoch=121
05/20/2022 10:05:45 - INFO - __main__ - Global step 1700 Train loss 2.77 Classification-F1 0.00976800976800977 on epoch=121
05/20/2022 10:05:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.78 on epoch=122
05/20/2022 10:05:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.86 on epoch=122
05/20/2022 10:05:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.63 on epoch=123
05/20/2022 10:05:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.76 on epoch=124
05/20/2022 10:05:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.58 on epoch=124
05/20/2022 10:05:53 - INFO - __main__ - Global step 1750 Train loss 2.72 Classification-F1 0.01762173796072101 on epoch=124
05/20/2022 10:05:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.82 on epoch=125
05/20/2022 10:05:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.62 on epoch=126
05/20/2022 10:05:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.67 on epoch=127
05/20/2022 10:05:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.62 on epoch=127
05/20/2022 10:05:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.58 on epoch=128
05/20/2022 10:06:01 - INFO - __main__ - Global step 1800 Train loss 2.66 Classification-F1 0.023302308635023684 on epoch=128
05/20/2022 10:06:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.80 on epoch=129
05/20/2022 10:06:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.56 on epoch=129
05/20/2022 10:06:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.57 on epoch=130
05/20/2022 10:06:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.62 on epoch=131
05/20/2022 10:06:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.60 on epoch=132
05/20/2022 10:06:10 - INFO - __main__ - Global step 1850 Train loss 2.63 Classification-F1 0.043428293795023686 on epoch=132
05/20/2022 10:06:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.84 on epoch=132
05/20/2022 10:06:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.65 on epoch=133
05/20/2022 10:06:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.81 on epoch=134
05/20/2022 10:06:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.65 on epoch=134
05/20/2022 10:06:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.72 on epoch=135
05/20/2022 10:06:18 - INFO - __main__ - Global step 1900 Train loss 2.73 Classification-F1 0.06727584426591747 on epoch=135
05/20/2022 10:06:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.64 on epoch=136
05/20/2022 10:06:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.49 on epoch=137
05/20/2022 10:06:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.80 on epoch=137
05/20/2022 10:06:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.48 on epoch=138
05/20/2022 10:06:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.80 on epoch=139
05/20/2022 10:06:26 - INFO - __main__ - Global step 1950 Train loss 2.64 Classification-F1 0.06319981878900258 on epoch=139
05/20/2022 10:06:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.63 on epoch=139
05/20/2022 10:06:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.62 on epoch=140
05/20/2022 10:06:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.41 on epoch=141
05/20/2022 10:06:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.54 on epoch=142
05/20/2022 10:06:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.68 on epoch=142
05/20/2022 10:06:34 - INFO - __main__ - Global step 2000 Train loss 2.58 Classification-F1 0.04786390080507728 on epoch=142
05/20/2022 10:06:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.59 on epoch=143
05/20/2022 10:06:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.63 on epoch=144
05/20/2022 10:06:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.48 on epoch=144
05/20/2022 10:06:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.68 on epoch=145
05/20/2022 10:06:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.59 on epoch=146
05/20/2022 10:06:42 - INFO - __main__ - Global step 2050 Train loss 2.59 Classification-F1 0.06245020530734816 on epoch=146
05/20/2022 10:06:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.58 on epoch=147
05/20/2022 10:06:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.60 on epoch=147
05/20/2022 10:06:46 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.42 on epoch=148
05/20/2022 10:06:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.56 on epoch=149
05/20/2022 10:06:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.50 on epoch=149
05/20/2022 10:06:50 - INFO - __main__ - Global step 2100 Train loss 2.53 Classification-F1 0.05118303502926768 on epoch=149
05/20/2022 10:06:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.66 on epoch=150
05/20/2022 10:06:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.32 on epoch=151
05/20/2022 10:06:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.57 on epoch=152
05/20/2022 10:06:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.63 on epoch=152
05/20/2022 10:06:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.51 on epoch=153
05/20/2022 10:06:58 - INFO - __main__ - Global step 2150 Train loss 2.54 Classification-F1 0.09707065103769727 on epoch=153
05/20/2022 10:06:58 - INFO - __main__ - Saving model with best Classification-F1: 0.08564914993196823 -> 0.09707065103769727 on epoch=153, global_step=2150
05/20/2022 10:07:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.59 on epoch=154
05/20/2022 10:07:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.41 on epoch=154
05/20/2022 10:07:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.55 on epoch=155
05/20/2022 10:07:03 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.30 on epoch=156
05/20/2022 10:07:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.45 on epoch=157
05/20/2022 10:07:07 - INFO - __main__ - Global step 2200 Train loss 2.46 Classification-F1 0.05982916714960914 on epoch=157
05/20/2022 10:07:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.55 on epoch=157
05/20/2022 10:07:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.39 on epoch=158
05/20/2022 10:07:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.38 on epoch=159
05/20/2022 10:07:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.48 on epoch=159
05/20/2022 10:07:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.56 on epoch=160
05/20/2022 10:07:15 - INFO - __main__ - Global step 2250 Train loss 2.47 Classification-F1 0.10385655513247835 on epoch=160
05/20/2022 10:07:15 - INFO - __main__ - Saving model with best Classification-F1: 0.09707065103769727 -> 0.10385655513247835 on epoch=160, global_step=2250
05/20/2022 10:07:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.34 on epoch=161
05/20/2022 10:07:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.35 on epoch=162
05/20/2022 10:07:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.35 on epoch=162
05/20/2022 10:07:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.39 on epoch=163
05/20/2022 10:07:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.54 on epoch=164
05/20/2022 10:07:23 - INFO - __main__ - Global step 2300 Train loss 2.39 Classification-F1 0.08221492080322121 on epoch=164
05/20/2022 10:07:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.15 on epoch=164
05/20/2022 10:07:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.45 on epoch=165
05/20/2022 10:07:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.24 on epoch=166
05/20/2022 10:07:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.35 on epoch=167
05/20/2022 10:07:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.35 on epoch=167
05/20/2022 10:07:32 - INFO - __main__ - Global step 2350 Train loss 2.31 Classification-F1 0.07818671263237269 on epoch=167
05/20/2022 10:07:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.40 on epoch=168
05/20/2022 10:07:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.51 on epoch=169
05/20/2022 10:07:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.33 on epoch=169
05/20/2022 10:07:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.42 on epoch=170
05/20/2022 10:07:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.28 on epoch=171
05/20/2022 10:07:40 - INFO - __main__ - Global step 2400 Train loss 2.39 Classification-F1 0.10707891534243065 on epoch=171
05/20/2022 10:07:40 - INFO - __main__ - Saving model with best Classification-F1: 0.10385655513247835 -> 0.10707891534243065 on epoch=171, global_step=2400
05/20/2022 10:07:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.31 on epoch=172
05/20/2022 10:07:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.40 on epoch=172
05/20/2022 10:07:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.26 on epoch=173
05/20/2022 10:07:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.35 on epoch=174
05/20/2022 10:07:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.22 on epoch=174
05/20/2022 10:07:48 - INFO - __main__ - Global step 2450 Train loss 2.31 Classification-F1 0.05883116883116883 on epoch=174
05/20/2022 10:07:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.34 on epoch=175
05/20/2022 10:07:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.21 on epoch=176
05/20/2022 10:07:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.28 on epoch=177
05/20/2022 10:07:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.28 on epoch=177
05/20/2022 10:07:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.07 on epoch=178
05/20/2022 10:07:56 - INFO - __main__ - Global step 2500 Train loss 2.24 Classification-F1 0.09106216645207921 on epoch=178
05/20/2022 10:07:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.20 on epoch=179
05/20/2022 10:07:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.13 on epoch=179
05/20/2022 10:08:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.38 on epoch=180
05/20/2022 10:08:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.22 on epoch=181
05/20/2022 10:08:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.26 on epoch=182
05/20/2022 10:08:05 - INFO - __main__ - Global step 2550 Train loss 2.24 Classification-F1 0.06731175228712175 on epoch=182
05/20/2022 10:08:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.31 on epoch=182
05/20/2022 10:08:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.24 on epoch=183
05/20/2022 10:08:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.43 on epoch=184
05/20/2022 10:08:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.17 on epoch=184
05/20/2022 10:08:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.31 on epoch=185
05/20/2022 10:08:13 - INFO - __main__ - Global step 2600 Train loss 2.29 Classification-F1 0.07487822293792444 on epoch=185
05/20/2022 10:08:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.18 on epoch=186
05/20/2022 10:08:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.15 on epoch=187
05/20/2022 10:08:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.22 on epoch=187
05/20/2022 10:08:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.16 on epoch=188
05/20/2022 10:08:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.29 on epoch=189
05/20/2022 10:08:22 - INFO - __main__ - Global step 2650 Train loss 2.20 Classification-F1 0.06955624355005159 on epoch=189
05/20/2022 10:08:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.10 on epoch=189
05/20/2022 10:08:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.36 on epoch=190
05/20/2022 10:08:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.10 on epoch=191
05/20/2022 10:08:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.12 on epoch=192
05/20/2022 10:08:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.28 on epoch=192
05/20/2022 10:08:30 - INFO - __main__ - Global step 2700 Train loss 2.19 Classification-F1 0.0835267073862512 on epoch=192
05/20/2022 10:08:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.17 on epoch=193
05/20/2022 10:08:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.31 on epoch=194
05/20/2022 10:08:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.23 on epoch=194
05/20/2022 10:08:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.15 on epoch=195
05/20/2022 10:08:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.08 on epoch=196
05/20/2022 10:08:38 - INFO - __main__ - Global step 2750 Train loss 2.19 Classification-F1 0.06294671265491915 on epoch=196
05/20/2022 10:08:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.24 on epoch=197
05/20/2022 10:08:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.94 on epoch=197
05/20/2022 10:08:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.09 on epoch=198
05/20/2022 10:08:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.06 on epoch=199
05/20/2022 10:08:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.05 on epoch=199
05/20/2022 10:08:47 - INFO - __main__ - Global step 2800 Train loss 2.07 Classification-F1 0.07226724640931244 on epoch=199
05/20/2022 10:08:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.29 on epoch=200
05/20/2022 10:08:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.05 on epoch=201
05/20/2022 10:08:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.05 on epoch=202
05/20/2022 10:08:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.10 on epoch=202
05/20/2022 10:08:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.11 on epoch=203
05/20/2022 10:08:55 - INFO - __main__ - Global step 2850 Train loss 2.12 Classification-F1 0.1245345068987809 on epoch=203
05/20/2022 10:08:55 - INFO - __main__ - Saving model with best Classification-F1: 0.10707891534243065 -> 0.1245345068987809 on epoch=203, global_step=2850
05/20/2022 10:08:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.98 on epoch=204
05/20/2022 10:08:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.02 on epoch=204
05/20/2022 10:08:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.11 on epoch=205
05/20/2022 10:09:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.86 on epoch=206
05/20/2022 10:09:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.10 on epoch=207
05/20/2022 10:09:04 - INFO - __main__ - Global step 2900 Train loss 2.01 Classification-F1 0.0700057800898137 on epoch=207
05/20/2022 10:09:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.01 on epoch=207
05/20/2022 10:09:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.07 on epoch=208
05/20/2022 10:09:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.11 on epoch=209
05/20/2022 10:09:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.09 on epoch=209
05/20/2022 10:09:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.10 on epoch=210
05/20/2022 10:09:13 - INFO - __main__ - Global step 2950 Train loss 2.08 Classification-F1 0.11344172969559967 on epoch=210
05/20/2022 10:09:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.00 on epoch=211
05/20/2022 10:09:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.98 on epoch=212
05/20/2022 10:09:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.08 on epoch=212
05/20/2022 10:09:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.86 on epoch=213
05/20/2022 10:09:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.97 on epoch=214
05/20/2022 10:09:21 - INFO - __main__ - Global step 3000 Train loss 1.98 Classification-F1 0.11477437776457383 on epoch=214
05/20/2022 10:09:21 - INFO - __main__ - save last model!
05/20/2022 10:09:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 10:09:21 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 10:09:21 - INFO - __main__ - Printing 3 examples
05/20/2022 10:09:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 10:09:21 - INFO - __main__ - ['Animal']
05/20/2022 10:09:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 10:09:21 - INFO - __main__ - ['Animal']
05/20/2022 10:09:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 10:09:21 - INFO - __main__ - ['Village']
05/20/2022 10:09:21 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:09:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:09:21 - INFO - __main__ - Printing 3 examples
05/20/2022 10:09:21 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 10:09:21 - INFO - __main__ - ['Animal']
05/20/2022 10:09:21 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 10:09:21 - INFO - __main__ - ['Animal']
05/20/2022 10:09:21 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 10:09:21 - INFO - __main__ - ['Animal']
05/20/2022 10:09:21 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:09:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:09:22 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:09:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:09:22 - INFO - __main__ - Printing 3 examples
05/20/2022 10:09:22 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 10:09:22 - INFO - __main__ - ['Animal']
05/20/2022 10:09:22 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 10:09:22 - INFO - __main__ - ['Animal']
05/20/2022 10:09:22 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 10:09:22 - INFO - __main__ - ['Animal']
05/20/2022 10:09:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:09:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:09:22 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:09:23 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:09:26 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 10:09:28 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:09:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:09:28 - INFO - __main__ - Starting training!
05/20/2022 10:10:07 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/20/2022 10:10:07 - INFO - __main__ - Classification-F1 on test data: 0.1187
05/20/2022 10:10:07 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.1245345068987809, test_performance=0.1187355508716266
05/20/2022 10:10:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/20/2022 10:10:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:10:08 - INFO - __main__ - Printing 3 examples
05/20/2022 10:10:08 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/20/2022 10:10:08 - INFO - __main__ - ['Animal']
05/20/2022 10:10:08 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/20/2022 10:10:08 - INFO - __main__ - ['Animal']
05/20/2022 10:10:08 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/20/2022 10:10:08 - INFO - __main__ - ['Animal']
05/20/2022 10:10:08 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:10:08 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:10:08 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:10:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:10:08 - INFO - __main__ - Printing 3 examples
05/20/2022 10:10:08 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/20/2022 10:10:08 - INFO - __main__ - ['Animal']
05/20/2022 10:10:08 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/20/2022 10:10:08 - INFO - __main__ - ['Animal']
05/20/2022 10:10:08 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/20/2022 10:10:08 - INFO - __main__ - ['Animal']
05/20/2022 10:10:08 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:10:09 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:10:09 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:10:14 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:10:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:10:14 - INFO - __main__ - Starting training!
05/20/2022 10:10:16 - INFO - __main__ - Step 10 Global step 10 Train loss 7.32 on epoch=0
05/20/2022 10:10:18 - INFO - __main__ - Step 20 Global step 20 Train loss 7.28 on epoch=1
05/20/2022 10:10:19 - INFO - __main__ - Step 30 Global step 30 Train loss 7.17 on epoch=2
05/20/2022 10:10:20 - INFO - __main__ - Step 40 Global step 40 Train loss 7.08 on epoch=2
05/20/2022 10:10:21 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/20/2022 10:10:37 - INFO - __main__ - Global step 50 Train loss 7.18 Classification-F1 0.0 on epoch=3
05/20/2022 10:10:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 10:10:38 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/20/2022 10:10:39 - INFO - __main__ - Step 70 Global step 70 Train loss 7.07 on epoch=4
05/20/2022 10:10:40 - INFO - __main__ - Step 80 Global step 80 Train loss 6.81 on epoch=5
05/20/2022 10:10:41 - INFO - __main__ - Step 90 Global step 90 Train loss 6.80 on epoch=6
05/20/2022 10:10:43 - INFO - __main__ - Step 100 Global step 100 Train loss 6.53 on epoch=7
05/20/2022 10:11:28 - INFO - __main__ - Global step 100 Train loss 6.79 Classification-F1 0.0 on epoch=7
05/20/2022 10:11:29 - INFO - __main__ - Step 110 Global step 110 Train loss 6.64 on epoch=7
05/20/2022 10:11:30 - INFO - __main__ - Step 120 Global step 120 Train loss 6.59 on epoch=8
05/20/2022 10:11:32 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/20/2022 10:11:33 - INFO - __main__ - Step 140 Global step 140 Train loss 6.56 on epoch=9
05/20/2022 10:11:34 - INFO - __main__ - Step 150 Global step 150 Train loss 6.49 on epoch=10
05/20/2022 10:12:28 - INFO - __main__ - Global step 150 Train loss 6.53 Classification-F1 0.0 on epoch=10
05/20/2022 10:12:29 - INFO - __main__ - Step 160 Global step 160 Train loss 6.37 on epoch=11
05/20/2022 10:12:31 - INFO - __main__ - Step 170 Global step 170 Train loss 6.26 on epoch=12
05/20/2022 10:12:32 - INFO - __main__ - Step 180 Global step 180 Train loss 6.31 on epoch=12
05/20/2022 10:12:33 - INFO - __main__ - Step 190 Global step 190 Train loss 6.25 on epoch=13
05/20/2022 10:12:34 - INFO - __main__ - Step 200 Global step 200 Train loss 6.05 on epoch=14
05/20/2022 10:13:33 - INFO - __main__ - Global step 200 Train loss 6.25 Classification-F1 0.0 on epoch=14
05/20/2022 10:13:34 - INFO - __main__ - Step 210 Global step 210 Train loss 6.32 on epoch=14
05/20/2022 10:13:35 - INFO - __main__ - Step 220 Global step 220 Train loss 6.15 on epoch=15
05/20/2022 10:13:36 - INFO - __main__ - Step 230 Global step 230 Train loss 6.10 on epoch=16
05/20/2022 10:13:37 - INFO - __main__ - Step 240 Global step 240 Train loss 6.01 on epoch=17
05/20/2022 10:13:39 - INFO - __main__ - Step 250 Global step 250 Train loss 5.84 on epoch=17
05/20/2022 10:14:25 - INFO - __main__ - Global step 250 Train loss 6.09 Classification-F1 0.0 on epoch=17
05/20/2022 10:14:27 - INFO - __main__ - Step 260 Global step 260 Train loss 5.96 on epoch=18
05/20/2022 10:14:28 - INFO - __main__ - Step 270 Global step 270 Train loss 5.82 on epoch=19
05/20/2022 10:14:29 - INFO - __main__ - Step 280 Global step 280 Train loss 5.96 on epoch=19
05/20/2022 10:14:30 - INFO - __main__ - Step 290 Global step 290 Train loss 5.99 on epoch=20
05/20/2022 10:14:32 - INFO - __main__ - Step 300 Global step 300 Train loss 5.72 on epoch=21
05/20/2022 10:15:22 - INFO - __main__ - Global step 300 Train loss 5.89 Classification-F1 0.0 on epoch=21
05/20/2022 10:15:23 - INFO - __main__ - Step 310 Global step 310 Train loss 5.87 on epoch=22
05/20/2022 10:15:24 - INFO - __main__ - Step 320 Global step 320 Train loss 5.91 on epoch=22
05/20/2022 10:15:25 - INFO - __main__ - Step 330 Global step 330 Train loss 5.85 on epoch=23
05/20/2022 10:15:27 - INFO - __main__ - Step 340 Global step 340 Train loss 5.67 on epoch=24
05/20/2022 10:15:28 - INFO - __main__ - Step 350 Global step 350 Train loss 5.80 on epoch=24
05/20/2022 10:15:57 - INFO - __main__ - Global step 350 Train loss 5.82 Classification-F1 0.0 on epoch=24
05/20/2022 10:15:58 - INFO - __main__ - Step 360 Global step 360 Train loss 5.87 on epoch=25
05/20/2022 10:15:59 - INFO - __main__ - Step 370 Global step 370 Train loss 5.68 on epoch=26
05/20/2022 10:16:01 - INFO - __main__ - Step 380 Global step 380 Train loss 5.62 on epoch=27
05/20/2022 10:16:02 - INFO - __main__ - Step 390 Global step 390 Train loss 5.56 on epoch=27
05/20/2022 10:16:03 - INFO - __main__ - Step 400 Global step 400 Train loss 5.65 on epoch=28
05/20/2022 10:16:38 - INFO - __main__ - Global step 400 Train loss 5.68 Classification-F1 0.0 on epoch=28
05/20/2022 10:16:40 - INFO - __main__ - Step 410 Global step 410 Train loss 5.55 on epoch=29
05/20/2022 10:16:41 - INFO - __main__ - Step 420 Global step 420 Train loss 5.60 on epoch=29
05/20/2022 10:16:42 - INFO - __main__ - Step 430 Global step 430 Train loss 5.55 on epoch=30
05/20/2022 10:16:43 - INFO - __main__ - Step 440 Global step 440 Train loss 5.46 on epoch=31
05/20/2022 10:16:45 - INFO - __main__ - Step 450 Global step 450 Train loss 5.49 on epoch=32
05/20/2022 10:17:19 - INFO - __main__ - Global step 450 Train loss 5.53 Classification-F1 0.0 on epoch=32
05/20/2022 10:17:21 - INFO - __main__ - Step 460 Global step 460 Train loss 5.40 on epoch=32
05/20/2022 10:17:22 - INFO - __main__ - Step 470 Global step 470 Train loss 5.31 on epoch=33
05/20/2022 10:17:23 - INFO - __main__ - Step 480 Global step 480 Train loss 5.30 on epoch=34
05/20/2022 10:17:24 - INFO - __main__ - Step 490 Global step 490 Train loss 5.41 on epoch=34
05/20/2022 10:17:26 - INFO - __main__ - Step 500 Global step 500 Train loss 5.43 on epoch=35
05/20/2022 10:17:58 - INFO - __main__ - Global step 500 Train loss 5.37 Classification-F1 0.0 on epoch=35
05/20/2022 10:17:59 - INFO - __main__ - Step 510 Global step 510 Train loss 5.32 on epoch=36
05/20/2022 10:18:00 - INFO - __main__ - Step 520 Global step 520 Train loss 5.16 on epoch=37
05/20/2022 10:18:01 - INFO - __main__ - Step 530 Global step 530 Train loss 5.29 on epoch=37
05/20/2022 10:18:02 - INFO - __main__ - Step 540 Global step 540 Train loss 5.30 on epoch=38
05/20/2022 10:18:04 - INFO - __main__ - Step 550 Global step 550 Train loss 5.10 on epoch=39
05/20/2022 10:18:41 - INFO - __main__ - Global step 550 Train loss 5.24 Classification-F1 0.0 on epoch=39
05/20/2022 10:18:43 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/20/2022 10:18:44 - INFO - __main__ - Step 570 Global step 570 Train loss 5.13 on epoch=40
05/20/2022 10:18:45 - INFO - __main__ - Step 580 Global step 580 Train loss 5.19 on epoch=41
05/20/2022 10:18:46 - INFO - __main__ - Step 590 Global step 590 Train loss 4.99 on epoch=42
05/20/2022 10:18:47 - INFO - __main__ - Step 600 Global step 600 Train loss 5.05 on epoch=42
05/20/2022 10:18:51 - INFO - __main__ - Global step 600 Train loss 5.09 Classification-F1 0.0011305822498586774 on epoch=42
05/20/2022 10:18:51 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0011305822498586774 on epoch=42, global_step=600
05/20/2022 10:18:53 - INFO - __main__ - Step 610 Global step 610 Train loss 5.06 on epoch=43
05/20/2022 10:18:54 - INFO - __main__ - Step 620 Global step 620 Train loss 5.01 on epoch=44
05/20/2022 10:18:55 - INFO - __main__ - Step 630 Global step 630 Train loss 5.00 on epoch=44
05/20/2022 10:18:56 - INFO - __main__ - Step 640 Global step 640 Train loss 5.13 on epoch=45
05/20/2022 10:18:57 - INFO - __main__ - Step 650 Global step 650 Train loss 4.92 on epoch=46
05/20/2022 10:19:00 - INFO - __main__ - Global step 650 Train loss 5.02 Classification-F1 0.005887681159420291 on epoch=46
05/20/2022 10:19:00 - INFO - __main__ - Saving model with best Classification-F1: 0.0011305822498586774 -> 0.005887681159420291 on epoch=46, global_step=650
05/20/2022 10:19:01 - INFO - __main__ - Step 660 Global step 660 Train loss 4.86 on epoch=47
05/20/2022 10:19:03 - INFO - __main__ - Step 670 Global step 670 Train loss 4.80 on epoch=47
05/20/2022 10:19:04 - INFO - __main__ - Step 680 Global step 680 Train loss 4.85 on epoch=48
05/20/2022 10:19:05 - INFO - __main__ - Step 690 Global step 690 Train loss 4.76 on epoch=49
05/20/2022 10:19:06 - INFO - __main__ - Step 700 Global step 700 Train loss 4.90 on epoch=49
05/20/2022 10:19:09 - INFO - __main__ - Global step 700 Train loss 4.83 Classification-F1 0.007629947544110634 on epoch=49
05/20/2022 10:19:09 - INFO - __main__ - Saving model with best Classification-F1: 0.005887681159420291 -> 0.007629947544110634 on epoch=49, global_step=700
05/20/2022 10:19:10 - INFO - __main__ - Step 710 Global step 710 Train loss 4.86 on epoch=50
05/20/2022 10:19:11 - INFO - __main__ - Step 720 Global step 720 Train loss 4.79 on epoch=51
05/20/2022 10:19:12 - INFO - __main__ - Step 730 Global step 730 Train loss 4.71 on epoch=52
05/20/2022 10:19:14 - INFO - __main__ - Step 740 Global step 740 Train loss 4.82 on epoch=52
05/20/2022 10:19:15 - INFO - __main__ - Step 750 Global step 750 Train loss 4.77 on epoch=53
05/20/2022 10:19:17 - INFO - __main__ - Global step 750 Train loss 4.79 Classification-F1 0.009523809523809523 on epoch=53
05/20/2022 10:19:17 - INFO - __main__ - Saving model with best Classification-F1: 0.007629947544110634 -> 0.009523809523809523 on epoch=53, global_step=750
05/20/2022 10:19:19 - INFO - __main__ - Step 760 Global step 760 Train loss 4.77 on epoch=54
05/20/2022 10:19:20 - INFO - __main__ - Step 770 Global step 770 Train loss 4.86 on epoch=54
05/20/2022 10:19:21 - INFO - __main__ - Step 780 Global step 780 Train loss 4.68 on epoch=55
05/20/2022 10:19:22 - INFO - __main__ - Step 790 Global step 790 Train loss 4.62 on epoch=56
05/20/2022 10:19:23 - INFO - __main__ - Step 800 Global step 800 Train loss 4.63 on epoch=57
05/20/2022 10:19:26 - INFO - __main__ - Global step 800 Train loss 4.71 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 10:19:27 - INFO - __main__ - Step 810 Global step 810 Train loss 4.82 on epoch=57
05/20/2022 10:19:28 - INFO - __main__ - Step 820 Global step 820 Train loss 4.81 on epoch=58
05/20/2022 10:19:29 - INFO - __main__ - Step 830 Global step 830 Train loss 4.61 on epoch=59
05/20/2022 10:19:31 - INFO - __main__ - Step 840 Global step 840 Train loss 4.61 on epoch=59
05/20/2022 10:19:32 - INFO - __main__ - Step 850 Global step 850 Train loss 4.67 on epoch=60
05/20/2022 10:19:34 - INFO - __main__ - Global step 850 Train loss 4.71 Classification-F1 0.008438818565400845 on epoch=60
05/20/2022 10:19:36 - INFO - __main__ - Step 860 Global step 860 Train loss 4.56 on epoch=61
05/20/2022 10:19:37 - INFO - __main__ - Step 870 Global step 870 Train loss 4.61 on epoch=62
05/20/2022 10:19:38 - INFO - __main__ - Step 880 Global step 880 Train loss 4.58 on epoch=62
05/20/2022 10:19:39 - INFO - __main__ - Step 890 Global step 890 Train loss 4.46 on epoch=63
05/20/2022 10:19:40 - INFO - __main__ - Step 900 Global step 900 Train loss 4.52 on epoch=64
05/20/2022 10:19:43 - INFO - __main__ - Global step 900 Train loss 4.55 Classification-F1 0.009523809523809523 on epoch=64
05/20/2022 10:19:44 - INFO - __main__ - Step 910 Global step 910 Train loss 4.53 on epoch=64
05/20/2022 10:19:45 - INFO - __main__ - Step 920 Global step 920 Train loss 4.63 on epoch=65
05/20/2022 10:19:46 - INFO - __main__ - Step 930 Global step 930 Train loss 4.56 on epoch=66
05/20/2022 10:19:48 - INFO - __main__ - Step 940 Global step 940 Train loss 4.48 on epoch=67
05/20/2022 10:19:49 - INFO - __main__ - Step 950 Global step 950 Train loss 4.46 on epoch=67
05/20/2022 10:19:51 - INFO - __main__ - Global step 950 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=67
05/20/2022 10:19:52 - INFO - __main__ - Step 960 Global step 960 Train loss 4.43 on epoch=68
05/20/2022 10:19:54 - INFO - __main__ - Step 970 Global step 970 Train loss 4.49 on epoch=69
05/20/2022 10:19:55 - INFO - __main__ - Step 980 Global step 980 Train loss 4.48 on epoch=69
05/20/2022 10:19:56 - INFO - __main__ - Step 990 Global step 990 Train loss 4.42 on epoch=70
05/20/2022 10:19:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.26 on epoch=71
05/20/2022 10:20:00 - INFO - __main__ - Global step 1000 Train loss 4.42 Classification-F1 0.009523809523809523 on epoch=71
05/20/2022 10:20:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.31 on epoch=72
05/20/2022 10:20:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.35 on epoch=72
05/20/2022 10:20:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.28 on epoch=73
05/20/2022 10:20:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.38 on epoch=74
05/20/2022 10:20:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.17 on epoch=74
05/20/2022 10:20:08 - INFO - __main__ - Global step 1050 Train loss 4.30 Classification-F1 0.009523809523809523 on epoch=74
05/20/2022 10:20:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.31 on epoch=75
05/20/2022 10:20:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.21 on epoch=76
05/20/2022 10:20:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.18 on epoch=77
05/20/2022 10:20:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.20 on epoch=77
05/20/2022 10:20:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.15 on epoch=78
05/20/2022 10:20:16 - INFO - __main__ - Global step 1100 Train loss 4.21 Classification-F1 0.009523809523809523 on epoch=78
05/20/2022 10:20:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.11 on epoch=79
05/20/2022 10:20:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.23 on epoch=79
05/20/2022 10:20:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.18 on epoch=80
05/20/2022 10:20:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.09 on epoch=81
05/20/2022 10:20:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.99 on epoch=82
05/20/2022 10:20:24 - INFO - __main__ - Global step 1150 Train loss 4.12 Classification-F1 0.009523809523809523 on epoch=82
05/20/2022 10:20:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.01 on epoch=82
05/20/2022 10:20:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.09 on epoch=83
05/20/2022 10:20:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.11 on epoch=84
05/20/2022 10:20:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.93 on epoch=84
05/20/2022 10:20:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.02 on epoch=85
05/20/2022 10:20:32 - INFO - __main__ - Global step 1200 Train loss 4.03 Classification-F1 0.009523809523809523 on epoch=85
05/20/2022 10:20:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.84 on epoch=86
05/20/2022 10:20:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.89 on epoch=87
05/20/2022 10:20:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.01 on epoch=87
05/20/2022 10:20:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.76 on epoch=88
05/20/2022 10:20:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.93 on epoch=89
05/20/2022 10:20:40 - INFO - __main__ - Global step 1250 Train loss 3.89 Classification-F1 0.009523809523809523 on epoch=89
05/20/2022 10:20:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.75 on epoch=89
05/20/2022 10:20:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.81 on epoch=90
05/20/2022 10:20:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.77 on epoch=91
05/20/2022 10:20:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.71 on epoch=92
05/20/2022 10:20:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.91 on epoch=92
05/20/2022 10:20:48 - INFO - __main__ - Global step 1300 Train loss 3.79 Classification-F1 0.016529164857432336 on epoch=92
05/20/2022 10:20:48 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.016529164857432336 on epoch=92, global_step=1300
05/20/2022 10:20:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.72 on epoch=93
05/20/2022 10:20:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.93 on epoch=94
05/20/2022 10:20:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.75 on epoch=94
05/20/2022 10:20:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.70 on epoch=95
05/20/2022 10:20:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.56 on epoch=96
05/20/2022 10:20:56 - INFO - __main__ - Global step 1350 Train loss 3.73 Classification-F1 0.03280840955910984 on epoch=96
05/20/2022 10:20:56 - INFO - __main__ - Saving model with best Classification-F1: 0.016529164857432336 -> 0.03280840955910984 on epoch=96, global_step=1350
05/20/2022 10:20:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.58 on epoch=97
05/20/2022 10:20:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.68 on epoch=97
05/20/2022 10:20:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.69 on epoch=98
05/20/2022 10:21:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.60 on epoch=99
05/20/2022 10:21:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.56 on epoch=99
05/20/2022 10:21:04 - INFO - __main__ - Global step 1400 Train loss 3.62 Classification-F1 0.026693806269296183 on epoch=99
05/20/2022 10:21:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.60 on epoch=100
05/20/2022 10:21:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.58 on epoch=101
05/20/2022 10:21:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.62 on epoch=102
05/20/2022 10:21:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.70 on epoch=102
05/20/2022 10:21:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.55 on epoch=103
05/20/2022 10:21:12 - INFO - __main__ - Global step 1450 Train loss 3.61 Classification-F1 0.02290105231281702 on epoch=103
05/20/2022 10:21:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.51 on epoch=104
05/20/2022 10:21:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.61 on epoch=104
05/20/2022 10:21:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.53 on epoch=105
05/20/2022 10:21:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.37 on epoch=106
05/20/2022 10:21:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.43 on epoch=107
05/20/2022 10:21:20 - INFO - __main__ - Global step 1500 Train loss 3.49 Classification-F1 0.026546250684181722 on epoch=107
05/20/2022 10:21:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.52 on epoch=107
05/20/2022 10:21:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.43 on epoch=108
05/20/2022 10:21:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.36 on epoch=109
05/20/2022 10:21:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.41 on epoch=109
05/20/2022 10:21:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.56 on epoch=110
05/20/2022 10:21:28 - INFO - __main__ - Global step 1550 Train loss 3.46 Classification-F1 0.035238095238095235 on epoch=110
05/20/2022 10:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.03280840955910984 -> 0.035238095238095235 on epoch=110, global_step=1550
05/20/2022 10:21:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.35 on epoch=111
05/20/2022 10:21:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.43 on epoch=112
05/20/2022 10:21:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.39 on epoch=112
05/20/2022 10:21:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.37 on epoch=113
05/20/2022 10:21:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.51 on epoch=114
05/20/2022 10:21:36 - INFO - __main__ - Global step 1600 Train loss 3.41 Classification-F1 0.03236663086287146 on epoch=114
05/20/2022 10:21:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.37 on epoch=114
05/20/2022 10:21:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.43 on epoch=115
05/20/2022 10:21:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.08 on epoch=116
05/20/2022 10:21:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.24 on epoch=117
05/20/2022 10:21:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.38 on epoch=117
05/20/2022 10:21:44 - INFO - __main__ - Global step 1650 Train loss 3.30 Classification-F1 0.02875124542022761 on epoch=117
05/20/2022 10:21:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.14 on epoch=118
05/20/2022 10:21:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.39 on epoch=119
05/20/2022 10:21:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.17 on epoch=119
05/20/2022 10:21:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.29 on epoch=120
05/20/2022 10:21:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.04 on epoch=121
05/20/2022 10:21:52 - INFO - __main__ - Global step 1700 Train loss 3.21 Classification-F1 0.034864588037049685 on epoch=121
05/20/2022 10:21:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.21 on epoch=122
05/20/2022 10:21:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.37 on epoch=122
05/20/2022 10:21:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.24 on epoch=123
05/20/2022 10:21:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.22 on epoch=124
05/20/2022 10:21:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.14 on epoch=124
05/20/2022 10:22:00 - INFO - __main__ - Global step 1750 Train loss 3.23 Classification-F1 0.030305850644833692 on epoch=124
05/20/2022 10:22:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.18 on epoch=125
05/20/2022 10:22:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.15 on epoch=126
05/20/2022 10:22:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.14 on epoch=127
05/20/2022 10:22:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.07 on epoch=127
05/20/2022 10:22:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.16 on epoch=128
05/20/2022 10:22:08 - INFO - __main__ - Global step 1800 Train loss 3.14 Classification-F1 0.027354627354627355 on epoch=128
05/20/2022 10:22:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.20 on epoch=129
05/20/2022 10:22:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.06 on epoch=129
05/20/2022 10:22:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.13 on epoch=130
05/20/2022 10:22:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.07 on epoch=131
05/20/2022 10:22:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.12 on epoch=132
05/20/2022 10:22:16 - INFO - __main__ - Global step 1850 Train loss 3.12 Classification-F1 0.02105711849957374 on epoch=132
05/20/2022 10:22:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.32 on epoch=132
05/20/2022 10:22:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.11 on epoch=133
05/20/2022 10:22:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.10 on epoch=134
05/20/2022 10:22:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.06 on epoch=134
05/20/2022 10:22:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.29 on epoch=135
05/20/2022 10:22:24 - INFO - __main__ - Global step 1900 Train loss 3.17 Classification-F1 0.02007459412022817 on epoch=135
05/20/2022 10:22:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.15 on epoch=136
05/20/2022 10:22:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.20 on epoch=137
05/20/2022 10:22:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.08 on epoch=137
05/20/2022 10:22:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.04 on epoch=138
05/20/2022 10:22:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.26 on epoch=139
05/20/2022 10:22:32 - INFO - __main__ - Global step 1950 Train loss 3.15 Classification-F1 0.03648724566965637 on epoch=139
05/20/2022 10:22:32 - INFO - __main__ - Saving model with best Classification-F1: 0.035238095238095235 -> 0.03648724566965637 on epoch=139, global_step=1950
05/20/2022 10:22:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.19 on epoch=139
05/20/2022 10:22:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.10 on epoch=140
05/20/2022 10:22:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.96 on epoch=141
05/20/2022 10:22:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.98 on epoch=142
05/20/2022 10:22:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.16 on epoch=142
05/20/2022 10:22:40 - INFO - __main__ - Global step 2000 Train loss 3.08 Classification-F1 0.015692848897927776 on epoch=142
05/20/2022 10:22:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.04 on epoch=143
05/20/2022 10:22:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.11 on epoch=144
05/20/2022 10:22:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.85 on epoch=144
05/20/2022 10:22:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.15 on epoch=145
05/20/2022 10:22:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.95 on epoch=146
05/20/2022 10:22:48 - INFO - __main__ - Global step 2050 Train loss 3.02 Classification-F1 0.02801120448179272 on epoch=146
05/20/2022 10:22:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.93 on epoch=147
05/20/2022 10:22:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.03 on epoch=147
05/20/2022 10:22:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.89 on epoch=148
05/20/2022 10:22:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.04 on epoch=149
05/20/2022 10:22:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.84 on epoch=149
05/20/2022 10:22:56 - INFO - __main__ - Global step 2100 Train loss 2.94 Classification-F1 0.05282334260649523 on epoch=149
05/20/2022 10:22:56 - INFO - __main__ - Saving model with best Classification-F1: 0.03648724566965637 -> 0.05282334260649523 on epoch=149, global_step=2100
05/20/2022 10:22:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.10 on epoch=150
05/20/2022 10:22:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.04 on epoch=151
05/20/2022 10:23:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.11 on epoch=152
05/20/2022 10:23:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.11 on epoch=152
05/20/2022 10:23:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.93 on epoch=153
05/20/2022 10:23:04 - INFO - __main__ - Global step 2150 Train loss 3.06 Classification-F1 0.0335785055162676 on epoch=153
05/20/2022 10:23:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.07 on epoch=154
05/20/2022 10:23:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.82 on epoch=154
05/20/2022 10:23:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.06 on epoch=155
05/20/2022 10:23:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.82 on epoch=156
05/20/2022 10:23:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.08 on epoch=157
05/20/2022 10:23:12 - INFO - __main__ - Global step 2200 Train loss 2.97 Classification-F1 0.05222320668626014 on epoch=157
05/20/2022 10:23:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.09 on epoch=157
05/20/2022 10:23:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.00 on epoch=158
05/20/2022 10:23:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.95 on epoch=159
05/20/2022 10:23:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.78 on epoch=159
05/20/2022 10:23:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.88 on epoch=160
05/20/2022 10:23:20 - INFO - __main__ - Global step 2250 Train loss 2.94 Classification-F1 0.03360454275786084 on epoch=160
05/20/2022 10:23:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.92 on epoch=161
05/20/2022 10:23:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.81 on epoch=162
05/20/2022 10:23:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.94 on epoch=162
05/20/2022 10:23:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.97 on epoch=163
05/20/2022 10:23:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.00 on epoch=164
05/20/2022 10:23:28 - INFO - __main__ - Global step 2300 Train loss 2.93 Classification-F1 0.025419902474264042 on epoch=164
05/20/2022 10:23:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.94 on epoch=164
05/20/2022 10:23:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.84 on epoch=165
05/20/2022 10:23:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.81 on epoch=166
05/20/2022 10:23:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.77 on epoch=167
05/20/2022 10:23:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.94 on epoch=167
05/20/2022 10:23:36 - INFO - __main__ - Global step 2350 Train loss 2.86 Classification-F1 0.02132343846629561 on epoch=167
05/20/2022 10:23:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.72 on epoch=168
05/20/2022 10:23:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.87 on epoch=169
05/20/2022 10:23:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.75 on epoch=169
05/20/2022 10:23:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.94 on epoch=170
05/20/2022 10:23:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.83 on epoch=171
05/20/2022 10:23:44 - INFO - __main__ - Global step 2400 Train loss 2.82 Classification-F1 0.02429906542056075 on epoch=171
05/20/2022 10:23:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.76 on epoch=172
05/20/2022 10:23:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.85 on epoch=172
05/20/2022 10:23:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.74 on epoch=173
05/20/2022 10:23:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.98 on epoch=174
05/20/2022 10:23:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.78 on epoch=174
05/20/2022 10:23:52 - INFO - __main__ - Global step 2450 Train loss 2.82 Classification-F1 0.017163161067225024 on epoch=174
05/20/2022 10:23:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.94 on epoch=175
05/20/2022 10:23:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.76 on epoch=176
05/20/2022 10:23:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.86 on epoch=177
05/20/2022 10:23:57 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.82 on epoch=177
05/20/2022 10:23:58 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.76 on epoch=178
05/20/2022 10:24:00 - INFO - __main__ - Global step 2500 Train loss 2.83 Classification-F1 0.044128059656009966 on epoch=178
05/20/2022 10:24:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.86 on epoch=179
05/20/2022 10:24:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.62 on epoch=179
05/20/2022 10:24:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.88 on epoch=180
05/20/2022 10:24:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.62 on epoch=181
05/20/2022 10:24:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.77 on epoch=182
05/20/2022 10:24:08 - INFO - __main__ - Global step 2550 Train loss 2.75 Classification-F1 0.021150560680893358 on epoch=182
05/20/2022 10:24:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.90 on epoch=182
05/20/2022 10:24:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.63 on epoch=183
05/20/2022 10:24:12 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.94 on epoch=184
05/20/2022 10:24:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.64 on epoch=184
05/20/2022 10:24:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.75 on epoch=185
05/20/2022 10:24:16 - INFO - __main__ - Global step 2600 Train loss 2.77 Classification-F1 0.032607801184990126 on epoch=185
05/20/2022 10:24:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.86 on epoch=186
05/20/2022 10:24:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.81 on epoch=187
05/20/2022 10:24:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.82 on epoch=187
05/20/2022 10:24:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.64 on epoch=188
05/20/2022 10:24:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.88 on epoch=189
05/20/2022 10:24:24 - INFO - __main__ - Global step 2650 Train loss 2.80 Classification-F1 0.03222432312829384 on epoch=189
05/20/2022 10:24:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.72 on epoch=189
05/20/2022 10:24:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.88 on epoch=190
05/20/2022 10:24:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.76 on epoch=191
05/20/2022 10:24:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.69 on epoch=192
05/20/2022 10:24:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.88 on epoch=192
05/20/2022 10:24:32 - INFO - __main__ - Global step 2700 Train loss 2.78 Classification-F1 0.026421404682274247 on epoch=192
05/20/2022 10:24:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.68 on epoch=193
05/20/2022 10:24:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.97 on epoch=194
05/20/2022 10:24:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.55 on epoch=194
05/20/2022 10:24:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.81 on epoch=195
05/20/2022 10:24:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.61 on epoch=196
05/20/2022 10:24:40 - INFO - __main__ - Global step 2750 Train loss 2.73 Classification-F1 0.03294548588666236 on epoch=196
05/20/2022 10:24:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.68 on epoch=197
05/20/2022 10:24:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.70 on epoch=197
05/20/2022 10:24:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.67 on epoch=198
05/20/2022 10:24:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.86 on epoch=199
05/20/2022 10:24:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.63 on epoch=199
05/20/2022 10:24:48 - INFO - __main__ - Global step 2800 Train loss 2.71 Classification-F1 0.03410553410553411 on epoch=199
05/20/2022 10:24:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.76 on epoch=200
05/20/2022 10:24:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.71 on epoch=201
05/20/2022 10:24:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.75 on epoch=202
05/20/2022 10:24:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.71 on epoch=202
05/20/2022 10:24:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.74 on epoch=203
05/20/2022 10:24:56 - INFO - __main__ - Global step 2850 Train loss 2.73 Classification-F1 0.02498635347150077 on epoch=203
05/20/2022 10:24:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.86 on epoch=204
05/20/2022 10:24:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.67 on epoch=204
05/20/2022 10:24:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.83 on epoch=205
05/20/2022 10:25:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.63 on epoch=206
05/20/2022 10:25:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.63 on epoch=207
05/20/2022 10:25:04 - INFO - __main__ - Global step 2900 Train loss 2.72 Classification-F1 0.05059829687270593 on epoch=207
05/20/2022 10:25:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.84 on epoch=207
05/20/2022 10:25:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.64 on epoch=208
05/20/2022 10:25:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.70 on epoch=209
05/20/2022 10:25:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.69 on epoch=209
05/20/2022 10:25:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.75 on epoch=210
05/20/2022 10:25:12 - INFO - __main__ - Global step 2950 Train loss 2.73 Classification-F1 0.048593706488443335 on epoch=210
05/20/2022 10:25:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.62 on epoch=211
05/20/2022 10:25:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.76 on epoch=212
05/20/2022 10:25:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.69 on epoch=212
05/20/2022 10:25:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.56 on epoch=213
05/20/2022 10:25:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.80 on epoch=214
05/20/2022 10:25:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:25:19 - INFO - __main__ - Printing 3 examples
05/20/2022 10:25:19 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 10:25:19 - INFO - __main__ - ['Animal']
05/20/2022 10:25:19 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 10:25:19 - INFO - __main__ - ['Animal']
05/20/2022 10:25:19 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 10:25:19 - INFO - __main__ - ['Animal']
05/20/2022 10:25:19 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:25:19 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:25:19 - INFO - __main__ - Global step 3000 Train loss 2.68 Classification-F1 0.038407839624878155 on epoch=214
05/20/2022 10:25:19 - INFO - __main__ - save last model!
05/20/2022 10:25:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 10:25:19 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 10:25:19 - INFO - __main__ - Printing 3 examples
05/20/2022 10:25:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 10:25:19 - INFO - __main__ - ['Animal']
05/20/2022 10:25:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 10:25:19 - INFO - __main__ - ['Animal']
05/20/2022 10:25:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 10:25:19 - INFO - __main__ - ['Village']
05/20/2022 10:25:19 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:25:20 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:25:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:25:20 - INFO - __main__ - Printing 3 examples
05/20/2022 10:25:20 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 10:25:20 - INFO - __main__ - ['Animal']
05/20/2022 10:25:20 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 10:25:20 - INFO - __main__ - ['Animal']
05/20/2022 10:25:20 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 10:25:20 - INFO - __main__ - ['Animal']
05/20/2022 10:25:20 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:25:20 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:25:20 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:25:21 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:25:25 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 10:25:25 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:25:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:25:25 - INFO - __main__ - Starting training!
05/20/2022 10:25:54 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/20/2022 10:25:54 - INFO - __main__ - Classification-F1 on test data: 0.0261
05/20/2022 10:25:54 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.05282334260649523, test_performance=0.026080949988889202
05/20/2022 10:25:54 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/20/2022 10:25:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:25:55 - INFO - __main__ - Printing 3 examples
05/20/2022 10:25:55 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 10:25:55 - INFO - __main__ - ['Animal']
05/20/2022 10:25:55 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 10:25:55 - INFO - __main__ - ['Animal']
05/20/2022 10:25:55 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 10:25:55 - INFO - __main__ - ['Animal']
05/20/2022 10:25:55 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:25:55 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:25:55 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:25:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:25:55 - INFO - __main__ - Printing 3 examples
05/20/2022 10:25:55 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 10:25:55 - INFO - __main__ - ['Animal']
05/20/2022 10:25:55 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 10:25:55 - INFO - __main__ - ['Animal']
05/20/2022 10:25:55 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 10:25:55 - INFO - __main__ - ['Animal']
05/20/2022 10:25:55 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:25:56 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:25:56 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:26:01 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:26:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:26:01 - INFO - __main__ - Starting training!
05/20/2022 10:26:03 - INFO - __main__ - Step 10 Global step 10 Train loss 7.31 on epoch=0
05/20/2022 10:26:04 - INFO - __main__ - Step 20 Global step 20 Train loss 7.37 on epoch=1
05/20/2022 10:26:05 - INFO - __main__ - Step 30 Global step 30 Train loss 7.08 on epoch=2
05/20/2022 10:26:07 - INFO - __main__ - Step 40 Global step 40 Train loss 6.84 on epoch=2
05/20/2022 10:26:08 - INFO - __main__ - Step 50 Global step 50 Train loss 6.81 on epoch=3
05/20/2022 10:26:27 - INFO - __main__ - Global step 50 Train loss 7.08 Classification-F1 0.0 on epoch=3
05/20/2022 10:26:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 10:26:28 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/20/2022 10:26:30 - INFO - __main__ - Step 70 Global step 70 Train loss 6.59 on epoch=4
05/20/2022 10:26:31 - INFO - __main__ - Step 80 Global step 80 Train loss 6.41 on epoch=5
05/20/2022 10:26:32 - INFO - __main__ - Step 90 Global step 90 Train loss 6.44 on epoch=6
05/20/2022 10:26:33 - INFO - __main__ - Step 100 Global step 100 Train loss 6.24 on epoch=7
05/20/2022 10:27:41 - INFO - __main__ - Global step 100 Train loss 6.49 Classification-F1 0.0 on epoch=7
05/20/2022 10:27:42 - INFO - __main__ - Step 110 Global step 110 Train loss 6.08 on epoch=7
05/20/2022 10:27:43 - INFO - __main__ - Step 120 Global step 120 Train loss 6.11 on epoch=8
05/20/2022 10:27:45 - INFO - __main__ - Step 130 Global step 130 Train loss 6.16 on epoch=9
05/20/2022 10:27:46 - INFO - __main__ - Step 140 Global step 140 Train loss 5.96 on epoch=9
05/20/2022 10:27:48 - INFO - __main__ - Step 150 Global step 150 Train loss 5.80 on epoch=10
05/20/2022 10:29:04 - INFO - __main__ - Global step 150 Train loss 6.02 Classification-F1 0.0 on epoch=10
05/20/2022 10:29:05 - INFO - __main__ - Step 160 Global step 160 Train loss 5.90 on epoch=11
05/20/2022 10:29:07 - INFO - __main__ - Step 170 Global step 170 Train loss 5.66 on epoch=12
05/20/2022 10:29:08 - INFO - __main__ - Step 180 Global step 180 Train loss 5.61 on epoch=12
05/20/2022 10:29:09 - INFO - __main__ - Step 190 Global step 190 Train loss 5.63 on epoch=13
05/20/2022 10:29:10 - INFO - __main__ - Step 200 Global step 200 Train loss 5.64 on epoch=14
05/20/2022 10:30:06 - INFO - __main__ - Global step 200 Train loss 5.69 Classification-F1 0.0 on epoch=14
05/20/2022 10:30:07 - INFO - __main__ - Step 210 Global step 210 Train loss 5.43 on epoch=14
05/20/2022 10:30:08 - INFO - __main__ - Step 220 Global step 220 Train loss 5.26 on epoch=15
05/20/2022 10:30:10 - INFO - __main__ - Step 230 Global step 230 Train loss 5.54 on epoch=16
05/20/2022 10:30:11 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=17
05/20/2022 10:30:12 - INFO - __main__ - Step 250 Global step 250 Train loss 5.43 on epoch=17
05/20/2022 10:30:42 - INFO - __main__ - Global step 250 Train loss 5.41 Classification-F1 0.0 on epoch=17
05/20/2022 10:30:44 - INFO - __main__ - Step 260 Global step 260 Train loss 5.26 on epoch=18
05/20/2022 10:30:45 - INFO - __main__ - Step 270 Global step 270 Train loss 5.33 on epoch=19
05/20/2022 10:30:46 - INFO - __main__ - Step 280 Global step 280 Train loss 5.28 on epoch=19
05/20/2022 10:30:47 - INFO - __main__ - Step 290 Global step 290 Train loss 5.01 on epoch=20
05/20/2022 10:30:49 - INFO - __main__ - Step 300 Global step 300 Train loss 5.24 on epoch=21
05/20/2022 10:31:19 - INFO - __main__ - Global step 300 Train loss 5.23 Classification-F1 0.0 on epoch=21
05/20/2022 10:31:21 - INFO - __main__ - Step 310 Global step 310 Train loss 5.03 on epoch=22
05/20/2022 10:31:22 - INFO - __main__ - Step 320 Global step 320 Train loss 4.87 on epoch=22
05/20/2022 10:31:23 - INFO - __main__ - Step 330 Global step 330 Train loss 4.94 on epoch=23
05/20/2022 10:31:24 - INFO - __main__ - Step 340 Global step 340 Train loss 4.83 on epoch=24
05/20/2022 10:31:26 - INFO - __main__ - Step 350 Global step 350 Train loss 4.96 on epoch=24
05/20/2022 10:31:32 - INFO - __main__ - Global step 350 Train loss 4.93 Classification-F1 0.007532956685499058 on epoch=24
05/20/2022 10:31:32 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.007532956685499058 on epoch=24, global_step=350
05/20/2022 10:31:33 - INFO - __main__ - Step 360 Global step 360 Train loss 4.66 on epoch=25
05/20/2022 10:31:34 - INFO - __main__ - Step 370 Global step 370 Train loss 4.72 on epoch=26
05/20/2022 10:31:36 - INFO - __main__ - Step 380 Global step 380 Train loss 4.74 on epoch=27
05/20/2022 10:31:37 - INFO - __main__ - Step 390 Global step 390 Train loss 4.60 on epoch=27
05/20/2022 10:31:38 - INFO - __main__ - Step 400 Global step 400 Train loss 4.66 on epoch=28
05/20/2022 10:31:40 - INFO - __main__ - Global step 400 Train loss 4.68 Classification-F1 0.00847457627118644 on epoch=28
05/20/2022 10:31:40 - INFO - __main__ - Saving model with best Classification-F1: 0.007532956685499058 -> 0.00847457627118644 on epoch=28, global_step=400
05/20/2022 10:31:42 - INFO - __main__ - Step 410 Global step 410 Train loss 4.52 on epoch=29
05/20/2022 10:31:43 - INFO - __main__ - Step 420 Global step 420 Train loss 4.52 on epoch=29
05/20/2022 10:31:44 - INFO - __main__ - Step 430 Global step 430 Train loss 4.22 on epoch=30
05/20/2022 10:31:45 - INFO - __main__ - Step 440 Global step 440 Train loss 4.39 on epoch=31
05/20/2022 10:31:47 - INFO - __main__ - Step 450 Global step 450 Train loss 4.55 on epoch=32
05/20/2022 10:31:49 - INFO - __main__ - Global step 450 Train loss 4.44 Classification-F1 0.009523809523809523 on epoch=32
05/20/2022 10:31:49 - INFO - __main__ - Saving model with best Classification-F1: 0.00847457627118644 -> 0.009523809523809523 on epoch=32, global_step=450
05/20/2022 10:31:50 - INFO - __main__ - Step 460 Global step 460 Train loss 4.33 on epoch=32
05/20/2022 10:31:51 - INFO - __main__ - Step 470 Global step 470 Train loss 4.32 on epoch=33
05/20/2022 10:31:53 - INFO - __main__ - Step 480 Global step 480 Train loss 4.36 on epoch=34
05/20/2022 10:31:54 - INFO - __main__ - Step 490 Global step 490 Train loss 4.21 on epoch=34
05/20/2022 10:31:55 - INFO - __main__ - Step 500 Global step 500 Train loss 4.22 on epoch=35
05/20/2022 10:31:57 - INFO - __main__ - Global step 500 Train loss 4.29 Classification-F1 0.00935672514619883 on epoch=35
05/20/2022 10:31:58 - INFO - __main__ - Step 510 Global step 510 Train loss 4.18 on epoch=36
05/20/2022 10:32:00 - INFO - __main__ - Step 520 Global step 520 Train loss 4.23 on epoch=37
05/20/2022 10:32:01 - INFO - __main__ - Step 530 Global step 530 Train loss 3.96 on epoch=37
05/20/2022 10:32:02 - INFO - __main__ - Step 540 Global step 540 Train loss 4.21 on epoch=38
05/20/2022 10:32:03 - INFO - __main__ - Step 550 Global step 550 Train loss 4.02 on epoch=39
05/20/2022 10:32:05 - INFO - __main__ - Global step 550 Train loss 4.12 Classification-F1 0.02746283698664651 on epoch=39
05/20/2022 10:32:05 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02746283698664651 on epoch=39, global_step=550
05/20/2022 10:32:06 - INFO - __main__ - Step 560 Global step 560 Train loss 4.02 on epoch=39
05/20/2022 10:32:08 - INFO - __main__ - Step 570 Global step 570 Train loss 4.01 on epoch=40
05/20/2022 10:32:09 - INFO - __main__ - Step 580 Global step 580 Train loss 4.00 on epoch=41
05/20/2022 10:32:10 - INFO - __main__ - Step 590 Global step 590 Train loss 4.07 on epoch=42
05/20/2022 10:32:11 - INFO - __main__ - Step 600 Global step 600 Train loss 3.84 on epoch=42
05/20/2022 10:32:13 - INFO - __main__ - Global step 600 Train loss 3.99 Classification-F1 0.0331370404158758 on epoch=42
05/20/2022 10:32:13 - INFO - __main__ - Saving model with best Classification-F1: 0.02746283698664651 -> 0.0331370404158758 on epoch=42, global_step=600
05/20/2022 10:32:15 - INFO - __main__ - Step 610 Global step 610 Train loss 3.89 on epoch=43
05/20/2022 10:32:16 - INFO - __main__ - Step 620 Global step 620 Train loss 3.92 on epoch=44
05/20/2022 10:32:17 - INFO - __main__ - Step 630 Global step 630 Train loss 3.96 on epoch=44
05/20/2022 10:32:18 - INFO - __main__ - Step 640 Global step 640 Train loss 3.82 on epoch=45
05/20/2022 10:32:20 - INFO - __main__ - Step 650 Global step 650 Train loss 3.82 on epoch=46
05/20/2022 10:32:21 - INFO - __main__ - Global step 650 Train loss 3.88 Classification-F1 0.02450451334379906 on epoch=46
05/20/2022 10:32:23 - INFO - __main__ - Step 660 Global step 660 Train loss 3.88 on epoch=47
05/20/2022 10:32:24 - INFO - __main__ - Step 670 Global step 670 Train loss 3.77 on epoch=47
05/20/2022 10:32:25 - INFO - __main__ - Step 680 Global step 680 Train loss 3.80 on epoch=48
05/20/2022 10:32:26 - INFO - __main__ - Step 690 Global step 690 Train loss 3.63 on epoch=49
05/20/2022 10:32:28 - INFO - __main__ - Step 700 Global step 700 Train loss 3.58 on epoch=49
05/20/2022 10:32:29 - INFO - __main__ - Global step 700 Train loss 3.73 Classification-F1 0.0359047619047619 on epoch=49
05/20/2022 10:32:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0331370404158758 -> 0.0359047619047619 on epoch=49, global_step=700
05/20/2022 10:32:31 - INFO - __main__ - Step 710 Global step 710 Train loss 3.48 on epoch=50
05/20/2022 10:32:32 - INFO - __main__ - Step 720 Global step 720 Train loss 3.51 on epoch=51
05/20/2022 10:32:33 - INFO - __main__ - Step 730 Global step 730 Train loss 3.66 on epoch=52
05/20/2022 10:32:34 - INFO - __main__ - Step 740 Global step 740 Train loss 3.42 on epoch=52
05/20/2022 10:32:36 - INFO - __main__ - Step 750 Global step 750 Train loss 3.40 on epoch=53
05/20/2022 10:32:37 - INFO - __main__ - Global step 750 Train loss 3.50 Classification-F1 0.020648259303721488 on epoch=53
05/20/2022 10:32:39 - INFO - __main__ - Step 760 Global step 760 Train loss 3.51 on epoch=54
05/20/2022 10:32:40 - INFO - __main__ - Step 770 Global step 770 Train loss 3.58 on epoch=54
05/20/2022 10:32:41 - INFO - __main__ - Step 780 Global step 780 Train loss 3.18 on epoch=55
05/20/2022 10:32:42 - INFO - __main__ - Step 790 Global step 790 Train loss 3.34 on epoch=56
05/20/2022 10:32:44 - INFO - __main__ - Step 800 Global step 800 Train loss 3.55 on epoch=57
05/20/2022 10:32:45 - INFO - __main__ - Global step 800 Train loss 3.43 Classification-F1 0.02895090490510338 on epoch=57
05/20/2022 10:32:47 - INFO - __main__ - Step 810 Global step 810 Train loss 3.20 on epoch=57
05/20/2022 10:32:48 - INFO - __main__ - Step 820 Global step 820 Train loss 3.43 on epoch=58
05/20/2022 10:32:49 - INFO - __main__ - Step 830 Global step 830 Train loss 3.24 on epoch=59
05/20/2022 10:32:50 - INFO - __main__ - Step 840 Global step 840 Train loss 3.32 on epoch=59
05/20/2022 10:32:52 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/20/2022 10:32:53 - INFO - __main__ - Global step 850 Train loss 3.28 Classification-F1 0.03400444147124499 on epoch=60
05/20/2022 10:32:55 - INFO - __main__ - Step 860 Global step 860 Train loss 3.31 on epoch=61
05/20/2022 10:32:56 - INFO - __main__ - Step 870 Global step 870 Train loss 3.33 on epoch=62
05/20/2022 10:32:57 - INFO - __main__ - Step 880 Global step 880 Train loss 3.16 on epoch=62
05/20/2022 10:32:58 - INFO - __main__ - Step 890 Global step 890 Train loss 3.15 on epoch=63
05/20/2022 10:33:00 - INFO - __main__ - Step 900 Global step 900 Train loss 3.12 on epoch=64
05/20/2022 10:33:01 - INFO - __main__ - Global step 900 Train loss 3.21 Classification-F1 0.009563658099222952 on epoch=64
05/20/2022 10:33:03 - INFO - __main__ - Step 910 Global step 910 Train loss 3.05 on epoch=64
05/20/2022 10:33:04 - INFO - __main__ - Step 920 Global step 920 Train loss 3.01 on epoch=65
05/20/2022 10:33:05 - INFO - __main__ - Step 930 Global step 930 Train loss 3.10 on epoch=66
05/20/2022 10:33:06 - INFO - __main__ - Step 940 Global step 940 Train loss 3.20 on epoch=67
05/20/2022 10:33:08 - INFO - __main__ - Step 950 Global step 950 Train loss 3.10 on epoch=67
05/20/2022 10:33:09 - INFO - __main__ - Global step 950 Train loss 3.09 Classification-F1 0.05680868838763576 on epoch=67
05/20/2022 10:33:09 - INFO - __main__ - Saving model with best Classification-F1: 0.0359047619047619 -> 0.05680868838763576 on epoch=67, global_step=950
05/20/2022 10:33:11 - INFO - __main__ - Step 960 Global step 960 Train loss 2.94 on epoch=68
05/20/2022 10:33:12 - INFO - __main__ - Step 970 Global step 970 Train loss 3.03 on epoch=69
05/20/2022 10:33:13 - INFO - __main__ - Step 980 Global step 980 Train loss 3.03 on epoch=69
05/20/2022 10:33:15 - INFO - __main__ - Step 990 Global step 990 Train loss 2.93 on epoch=70
05/20/2022 10:33:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.06 on epoch=71
05/20/2022 10:33:18 - INFO - __main__ - Global step 1000 Train loss 3.00 Classification-F1 0.060031803579098666 on epoch=71
05/20/2022 10:33:18 - INFO - __main__ - Saving model with best Classification-F1: 0.05680868838763576 -> 0.060031803579098666 on epoch=71, global_step=1000
05/20/2022 10:33:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.02 on epoch=72
05/20/2022 10:33:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.85 on epoch=72
05/20/2022 10:33:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.75 on epoch=73
05/20/2022 10:33:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.77 on epoch=74
05/20/2022 10:33:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.94 on epoch=74
05/20/2022 10:33:26 - INFO - __main__ - Global step 1050 Train loss 2.87 Classification-F1 0.026546934865900384 on epoch=74
05/20/2022 10:33:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.83 on epoch=75
05/20/2022 10:33:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.97 on epoch=76
05/20/2022 10:33:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.98 on epoch=77
05/20/2022 10:33:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.75 on epoch=77
05/20/2022 10:33:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.79 on epoch=78
05/20/2022 10:33:34 - INFO - __main__ - Global step 1100 Train loss 2.86 Classification-F1 0.031990231990231995 on epoch=78
05/20/2022 10:33:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.87 on epoch=79
05/20/2022 10:33:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.91 on epoch=79
05/20/2022 10:33:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.81 on epoch=80
05/20/2022 10:33:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.66 on epoch=81
05/20/2022 10:33:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.96 on epoch=82
05/20/2022 10:33:42 - INFO - __main__ - Global step 1150 Train loss 2.84 Classification-F1 0.024805603752972173 on epoch=82
05/20/2022 10:33:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/20/2022 10:33:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.86 on epoch=83
05/20/2022 10:33:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.78 on epoch=84
05/20/2022 10:33:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.91 on epoch=84
05/20/2022 10:33:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.78 on epoch=85
05/20/2022 10:33:50 - INFO - __main__ - Global step 1200 Train loss 2.82 Classification-F1 0.037926169499120276 on epoch=85
05/20/2022 10:33:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.79 on epoch=86
05/20/2022 10:33:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.86 on epoch=87
05/20/2022 10:33:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.71 on epoch=87
05/20/2022 10:33:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.67 on epoch=88
05/20/2022 10:33:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.69 on epoch=89
05/20/2022 10:33:58 - INFO - __main__ - Global step 1250 Train loss 2.74 Classification-F1 0.013344472291840714 on epoch=89
05/20/2022 10:33:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.82 on epoch=89
05/20/2022 10:34:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.66 on epoch=90
05/20/2022 10:34:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.64 on epoch=91
05/20/2022 10:34:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.82 on epoch=92
05/20/2022 10:34:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.67 on epoch=92
05/20/2022 10:34:06 - INFO - __main__ - Global step 1300 Train loss 2.72 Classification-F1 0.01728680676049097 on epoch=92
05/20/2022 10:34:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.79 on epoch=93
05/20/2022 10:34:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.62 on epoch=94
05/20/2022 10:34:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.84 on epoch=94
05/20/2022 10:34:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.68 on epoch=95
05/20/2022 10:34:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.72 on epoch=96
05/20/2022 10:34:15 - INFO - __main__ - Global step 1350 Train loss 2.73 Classification-F1 0.01719986240110079 on epoch=96
05/20/2022 10:34:17 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.83 on epoch=97
05/20/2022 10:34:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.62 on epoch=97
05/20/2022 10:34:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.72 on epoch=98
05/20/2022 10:34:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.65 on epoch=99
05/20/2022 10:34:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.76 on epoch=99
05/20/2022 10:34:23 - INFO - __main__ - Global step 1400 Train loss 2.71 Classification-F1 0.045825946981274325 on epoch=99
05/20/2022 10:34:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.71 on epoch=100
05/20/2022 10:34:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.55 on epoch=101
05/20/2022 10:34:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.69 on epoch=102
05/20/2022 10:34:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.50 on epoch=102
05/20/2022 10:34:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.52 on epoch=103
05/20/2022 10:34:32 - INFO - __main__ - Global step 1450 Train loss 2.59 Classification-F1 0.04442200471587681 on epoch=103
05/20/2022 10:34:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.55 on epoch=104
05/20/2022 10:34:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.51 on epoch=104
05/20/2022 10:34:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.38 on epoch=105
05/20/2022 10:34:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.42 on epoch=106
05/20/2022 10:34:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.71 on epoch=107
05/20/2022 10:34:40 - INFO - __main__ - Global step 1500 Train loss 2.52 Classification-F1 0.03651726226529376 on epoch=107
05/20/2022 10:34:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.58 on epoch=107
05/20/2022 10:34:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.52 on epoch=108
05/20/2022 10:34:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.58 on epoch=109
05/20/2022 10:34:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.57 on epoch=109
05/20/2022 10:34:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.52 on epoch=110
05/20/2022 10:34:48 - INFO - __main__ - Global step 1550 Train loss 2.56 Classification-F1 0.014835973915257802 on epoch=110
05/20/2022 10:34:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.49 on epoch=111
05/20/2022 10:34:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.51 on epoch=112
05/20/2022 10:34:52 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.37 on epoch=112
05/20/2022 10:34:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.55 on epoch=113
05/20/2022 10:34:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.58 on epoch=114
05/20/2022 10:34:56 - INFO - __main__ - Global step 1600 Train loss 2.50 Classification-F1 0.009523809523809523 on epoch=114
05/20/2022 10:34:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.55 on epoch=114
05/20/2022 10:34:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.36 on epoch=115
05/20/2022 10:35:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.25 on epoch=116
05/20/2022 10:35:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.55 on epoch=117
05/20/2022 10:35:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.39 on epoch=117
05/20/2022 10:35:04 - INFO - __main__ - Global step 1650 Train loss 2.42 Classification-F1 0.009523809523809523 on epoch=117
05/20/2022 10:35:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.46 on epoch=118
05/20/2022 10:35:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.39 on epoch=119
05/20/2022 10:35:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.44 on epoch=119
05/20/2022 10:35:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.21 on epoch=120
05/20/2022 10:35:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.47 on epoch=121
05/20/2022 10:35:13 - INFO - __main__ - Global step 1700 Train loss 2.39 Classification-F1 0.009563658099222952 on epoch=121
05/20/2022 10:35:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.41 on epoch=122
05/20/2022 10:35:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.26 on epoch=122
05/20/2022 10:35:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.44 on epoch=123
05/20/2022 10:35:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.37 on epoch=124
05/20/2022 10:35:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.45 on epoch=124
05/20/2022 10:35:21 - INFO - __main__ - Global step 1750 Train loss 2.39 Classification-F1 0.029976649365859333 on epoch=124
05/20/2022 10:35:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.30 on epoch=125
05/20/2022 10:35:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.38 on epoch=126
05/20/2022 10:35:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.55 on epoch=127
05/20/2022 10:35:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.25 on epoch=127
05/20/2022 10:35:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.42 on epoch=128
05/20/2022 10:35:29 - INFO - __main__ - Global step 1800 Train loss 2.38 Classification-F1 0.021886046995217297 on epoch=128
05/20/2022 10:35:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.57 on epoch=129
05/20/2022 10:35:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.54 on epoch=129
05/20/2022 10:35:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.19 on epoch=130
05/20/2022 10:35:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.33 on epoch=131
05/20/2022 10:35:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.40 on epoch=132
05/20/2022 10:35:38 - INFO - __main__ - Global step 1850 Train loss 2.40 Classification-F1 0.042642069496289445 on epoch=132
05/20/2022 10:35:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.35 on epoch=132
05/20/2022 10:35:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.20 on epoch=133
05/20/2022 10:35:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.24 on epoch=134
05/20/2022 10:35:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.25 on epoch=134
05/20/2022 10:35:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.12 on epoch=135
05/20/2022 10:35:46 - INFO - __main__ - Global step 1900 Train loss 2.23 Classification-F1 0.03963713631905852 on epoch=135
05/20/2022 10:35:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.34 on epoch=136
05/20/2022 10:35:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.44 on epoch=137
05/20/2022 10:35:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.15 on epoch=137
05/20/2022 10:35:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.16 on epoch=138
05/20/2022 10:35:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.26 on epoch=139
05/20/2022 10:35:54 - INFO - __main__ - Global step 1950 Train loss 2.27 Classification-F1 0.01834124954329558 on epoch=139
05/20/2022 10:35:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.14 on epoch=139
05/20/2022 10:35:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.11 on epoch=140
05/20/2022 10:35:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.06 on epoch=141
05/20/2022 10:35:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.26 on epoch=142
05/20/2022 10:36:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.20 on epoch=142
05/20/2022 10:36:02 - INFO - __main__ - Global step 2000 Train loss 2.15 Classification-F1 0.027881608783864423 on epoch=142
05/20/2022 10:36:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.14 on epoch=143
05/20/2022 10:36:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.19 on epoch=144
05/20/2022 10:36:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.20 on epoch=144
05/20/2022 10:36:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.10 on epoch=145
05/20/2022 10:36:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.95 on epoch=146
05/20/2022 10:36:11 - INFO - __main__ - Global step 2050 Train loss 2.12 Classification-F1 0.02495113257445096 on epoch=146
05/20/2022 10:36:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.22 on epoch=147
05/20/2022 10:36:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.12 on epoch=147
05/20/2022 10:36:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.10 on epoch=148
05/20/2022 10:36:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.16 on epoch=149
05/20/2022 10:36:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.30 on epoch=149
05/20/2022 10:36:19 - INFO - __main__ - Global step 2100 Train loss 2.18 Classification-F1 0.024543794455298886 on epoch=149
05/20/2022 10:36:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.21 on epoch=150
05/20/2022 10:36:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.18 on epoch=151
05/20/2022 10:36:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.16 on epoch=152
05/20/2022 10:36:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.04 on epoch=152
05/20/2022 10:36:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.03 on epoch=153
05/20/2022 10:36:27 - INFO - __main__ - Global step 2150 Train loss 2.12 Classification-F1 0.009563658099222952 on epoch=153
05/20/2022 10:36:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.24 on epoch=154
05/20/2022 10:36:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.99 on epoch=154
05/20/2022 10:36:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.08 on epoch=155
05/20/2022 10:36:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.09 on epoch=156
05/20/2022 10:36:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.08 on epoch=157
05/20/2022 10:36:35 - INFO - __main__ - Global step 2200 Train loss 2.10 Classification-F1 0.029605169078853293 on epoch=157
05/20/2022 10:36:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.93 on epoch=157
05/20/2022 10:36:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.04 on epoch=158
05/20/2022 10:36:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.11 on epoch=159
05/20/2022 10:36:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.99 on epoch=159
05/20/2022 10:36:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.98 on epoch=160
05/20/2022 10:36:43 - INFO - __main__ - Global step 2250 Train loss 2.01 Classification-F1 0.02123885083526339 on epoch=160
05/20/2022 10:36:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.00 on epoch=161
05/20/2022 10:36:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.23 on epoch=162
05/20/2022 10:36:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.05 on epoch=162
05/20/2022 10:36:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.85 on epoch=163
05/20/2022 10:36:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.04 on epoch=164
05/20/2022 10:36:52 - INFO - __main__ - Global step 2300 Train loss 2.03 Classification-F1 0.009726443768996961 on epoch=164
05/20/2022 10:36:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.97 on epoch=164
05/20/2022 10:36:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.96 on epoch=165
05/20/2022 10:36:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.98 on epoch=166
05/20/2022 10:36:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.05 on epoch=167
05/20/2022 10:36:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.95 on epoch=167
05/20/2022 10:37:00 - INFO - __main__ - Global step 2350 Train loss 1.98 Classification-F1 0.009644364074743823 on epoch=167
05/20/2022 10:37:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.05 on epoch=168
05/20/2022 10:37:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.00 on epoch=169
05/20/2022 10:37:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.85 on epoch=169
05/20/2022 10:37:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.92 on epoch=170
05/20/2022 10:37:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.90 on epoch=171
05/20/2022 10:37:08 - INFO - __main__ - Global step 2400 Train loss 1.94 Classification-F1 0.009563658099222952 on epoch=171
05/20/2022 10:37:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.95 on epoch=172
05/20/2022 10:37:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.91 on epoch=172
05/20/2022 10:37:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.84 on epoch=173
05/20/2022 10:37:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.91 on epoch=174
05/20/2022 10:37:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.88 on epoch=174
05/20/2022 10:37:16 - INFO - __main__ - Global step 2450 Train loss 1.90 Classification-F1 0.031085082525517876 on epoch=174
05/20/2022 10:37:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.89 on epoch=175
05/20/2022 10:37:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.84 on epoch=176
05/20/2022 10:37:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.83 on epoch=177
05/20/2022 10:37:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.92 on epoch=177
05/20/2022 10:37:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.85 on epoch=178
05/20/2022 10:37:25 - INFO - __main__ - Global step 2500 Train loss 1.86 Classification-F1 0.024212759014521128 on epoch=178
05/20/2022 10:37:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.89 on epoch=179
05/20/2022 10:37:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.78 on epoch=179
05/20/2022 10:37:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.81 on epoch=180
05/20/2022 10:37:30 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.92 on epoch=181
05/20/2022 10:37:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.91 on epoch=182
05/20/2022 10:37:33 - INFO - __main__ - Global step 2550 Train loss 1.86 Classification-F1 0.027898027898027897 on epoch=182
05/20/2022 10:37:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.91 on epoch=182
05/20/2022 10:37:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.88 on epoch=183
05/20/2022 10:37:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.87 on epoch=184
05/20/2022 10:37:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.85 on epoch=184
05/20/2022 10:37:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.76 on epoch=185
05/20/2022 10:37:41 - INFO - __main__ - Global step 2600 Train loss 1.85 Classification-F1 0.02358662613981763 on epoch=185
05/20/2022 10:37:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.90 on epoch=186
05/20/2022 10:37:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.83 on epoch=187
05/20/2022 10:37:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.76 on epoch=187
05/20/2022 10:37:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.80 on epoch=188
05/20/2022 10:37:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.91 on epoch=189
05/20/2022 10:37:50 - INFO - __main__ - Global step 2650 Train loss 1.84 Classification-F1 0.024117497132662164 on epoch=189
05/20/2022 10:37:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.72 on epoch=189
05/20/2022 10:37:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.80 on epoch=190
05/20/2022 10:37:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.82 on epoch=191
05/20/2022 10:37:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.77 on epoch=192
05/20/2022 10:37:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.83 on epoch=192
05/20/2022 10:37:58 - INFO - __main__ - Global step 2700 Train loss 1.79 Classification-F1 0.016570730856445143 on epoch=192
05/20/2022 10:37:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.80 on epoch=193
05/20/2022 10:38:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.85 on epoch=194
05/20/2022 10:38:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.79 on epoch=194
05/20/2022 10:38:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.81 on epoch=195
05/20/2022 10:38:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.86 on epoch=196
05/20/2022 10:38:07 - INFO - __main__ - Global step 2750 Train loss 1.82 Classification-F1 0.009685230024213076 on epoch=196
05/20/2022 10:38:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.84 on epoch=197
05/20/2022 10:38:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.79 on epoch=197
05/20/2022 10:38:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.88 on epoch=198
05/20/2022 10:38:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.83 on epoch=199
05/20/2022 10:38:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.84 on epoch=199
05/20/2022 10:38:16 - INFO - __main__ - Global step 2800 Train loss 1.84 Classification-F1 0.00976800976800977 on epoch=199
05/20/2022 10:38:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.65 on epoch=200
05/20/2022 10:38:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.79 on epoch=201
05/20/2022 10:38:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.69 on epoch=202
05/20/2022 10:38:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.92 on epoch=202
05/20/2022 10:38:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.78 on epoch=203
05/20/2022 10:38:24 - INFO - __main__ - Global step 2850 Train loss 1.76 Classification-F1 0.025558245897228944 on epoch=203
05/20/2022 10:38:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.82 on epoch=204
05/20/2022 10:38:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.74 on epoch=204
05/20/2022 10:38:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.71 on epoch=205
05/20/2022 10:38:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.85 on epoch=206
05/20/2022 10:38:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.71 on epoch=207
05/20/2022 10:38:32 - INFO - __main__ - Global step 2900 Train loss 1.77 Classification-F1 0.01800720288115246 on epoch=207
05/20/2022 10:38:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.62 on epoch=207
05/20/2022 10:38:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.79 on epoch=208
05/20/2022 10:38:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.67 on epoch=209
05/20/2022 10:38:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.71 on epoch=209
05/20/2022 10:38:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.68 on epoch=210
05/20/2022 10:38:41 - INFO - __main__ - Global step 2950 Train loss 1.69 Classification-F1 0.04142420226812241 on epoch=210
05/20/2022 10:38:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.69 on epoch=211
05/20/2022 10:38:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.84 on epoch=212
05/20/2022 10:38:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.76 on epoch=212
05/20/2022 10:38:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.77 on epoch=213
05/20/2022 10:38:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.77 on epoch=214
05/20/2022 10:38:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:38:48 - INFO - __main__ - Printing 3 examples
05/20/2022 10:38:48 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 10:38:48 - INFO - __main__ - ['Animal']
05/20/2022 10:38:48 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 10:38:48 - INFO - __main__ - ['Animal']
05/20/2022 10:38:48 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 10:38:48 - INFO - __main__ - ['Animal']
05/20/2022 10:38:48 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:38:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:38:49 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:38:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:38:49 - INFO - __main__ - Printing 3 examples
05/20/2022 10:38:49 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 10:38:49 - INFO - __main__ - ['Animal']
05/20/2022 10:38:49 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 10:38:49 - INFO - __main__ - ['Animal']
05/20/2022 10:38:49 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 10:38:49 - INFO - __main__ - ['Animal']
05/20/2022 10:38:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:38:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:38:49 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:38:49 - INFO - __main__ - Global step 3000 Train loss 1.77 Classification-F1 0.01804772541928164 on epoch=214
05/20/2022 10:38:49 - INFO - __main__ - save last model!
05/20/2022 10:38:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 10:38:49 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 10:38:49 - INFO - __main__ - Printing 3 examples
05/20/2022 10:38:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 10:38:49 - INFO - __main__ - ['Animal']
05/20/2022 10:38:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 10:38:49 - INFO - __main__ - ['Animal']
05/20/2022 10:38:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 10:38:49 - INFO - __main__ - ['Village']
05/20/2022 10:38:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:38:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:38:54 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:38:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:38:55 - INFO - __main__ - Starting training!
05/20/2022 10:38:55 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 10:39:32 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/20/2022 10:39:32 - INFO - __main__ - Classification-F1 on test data: 0.0106
05/20/2022 10:39:32 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.060031803579098666, test_performance=0.010601200001071525
05/20/2022 10:39:32 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/20/2022 10:39:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:39:33 - INFO - __main__ - Printing 3 examples
05/20/2022 10:39:33 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 10:39:33 - INFO - __main__ - ['Animal']
05/20/2022 10:39:33 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 10:39:33 - INFO - __main__ - ['Animal']
05/20/2022 10:39:33 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 10:39:33 - INFO - __main__ - ['Animal']
05/20/2022 10:39:33 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:39:33 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:39:34 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:39:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:39:34 - INFO - __main__ - Printing 3 examples
05/20/2022 10:39:34 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 10:39:34 - INFO - __main__ - ['Animal']
05/20/2022 10:39:34 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 10:39:34 - INFO - __main__ - ['Animal']
05/20/2022 10:39:34 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 10:39:34 - INFO - __main__ - ['Animal']
05/20/2022 10:39:34 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:39:34 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:39:34 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:39:39 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:39:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:39:39 - INFO - __main__ - Starting training!
05/20/2022 10:39:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.41 on epoch=0
05/20/2022 10:39:42 - INFO - __main__ - Step 20 Global step 20 Train loss 7.46 on epoch=1
05/20/2022 10:39:43 - INFO - __main__ - Step 30 Global step 30 Train loss 7.09 on epoch=2
05/20/2022 10:39:45 - INFO - __main__ - Step 40 Global step 40 Train loss 6.98 on epoch=2
05/20/2022 10:39:46 - INFO - __main__ - Step 50 Global step 50 Train loss 6.86 on epoch=3
05/20/2022 10:40:11 - INFO - __main__ - Global step 50 Train loss 7.16 Classification-F1 0.0 on epoch=3
05/20/2022 10:40:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 10:40:13 - INFO - __main__ - Step 60 Global step 60 Train loss 6.86 on epoch=4
05/20/2022 10:40:14 - INFO - __main__ - Step 70 Global step 70 Train loss 6.79 on epoch=4
05/20/2022 10:40:15 - INFO - __main__ - Step 80 Global step 80 Train loss 6.50 on epoch=5
05/20/2022 10:40:16 - INFO - __main__ - Step 90 Global step 90 Train loss 6.58 on epoch=6
05/20/2022 10:40:18 - INFO - __main__ - Step 100 Global step 100 Train loss 6.51 on epoch=7
05/20/2022 10:41:23 - INFO - __main__ - Global step 100 Train loss 6.65 Classification-F1 0.0 on epoch=7
05/20/2022 10:41:24 - INFO - __main__ - Step 110 Global step 110 Train loss 6.40 on epoch=7
05/20/2022 10:41:25 - INFO - __main__ - Step 120 Global step 120 Train loss 6.30 on epoch=8
05/20/2022 10:41:27 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/20/2022 10:41:28 - INFO - __main__ - Step 140 Global step 140 Train loss 6.27 on epoch=9
05/20/2022 10:41:29 - INFO - __main__ - Step 150 Global step 150 Train loss 5.96 on epoch=10
05/20/2022 10:42:40 - INFO - __main__ - Global step 150 Train loss 6.26 Classification-F1 0.0 on epoch=10
05/20/2022 10:42:41 - INFO - __main__ - Step 160 Global step 160 Train loss 6.31 on epoch=11
05/20/2022 10:42:42 - INFO - __main__ - Step 170 Global step 170 Train loss 6.02 on epoch=12
05/20/2022 10:42:43 - INFO - __main__ - Step 180 Global step 180 Train loss 5.85 on epoch=12
05/20/2022 10:42:45 - INFO - __main__ - Step 190 Global step 190 Train loss 5.84 on epoch=13
05/20/2022 10:42:46 - INFO - __main__ - Step 200 Global step 200 Train loss 5.98 on epoch=14
05/20/2022 10:43:55 - INFO - __main__ - Global step 200 Train loss 6.00 Classification-F1 0.0 on epoch=14
05/20/2022 10:43:56 - INFO - __main__ - Step 210 Global step 210 Train loss 5.86 on epoch=14
05/20/2022 10:43:58 - INFO - __main__ - Step 220 Global step 220 Train loss 5.49 on epoch=15
05/20/2022 10:43:59 - INFO - __main__ - Step 230 Global step 230 Train loss 5.74 on epoch=16
05/20/2022 10:44:00 - INFO - __main__ - Step 240 Global step 240 Train loss 5.50 on epoch=17
05/20/2022 10:44:01 - INFO - __main__ - Step 250 Global step 250 Train loss 5.51 on epoch=17
05/20/2022 10:44:29 - INFO - __main__ - Global step 250 Train loss 5.62 Classification-F1 0.0019157088122605363 on epoch=17
05/20/2022 10:44:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0019157088122605363 on epoch=17, global_step=250
05/20/2022 10:44:30 - INFO - __main__ - Step 260 Global step 260 Train loss 5.37 on epoch=18
05/20/2022 10:44:31 - INFO - __main__ - Step 270 Global step 270 Train loss 5.54 on epoch=19
05/20/2022 10:44:32 - INFO - __main__ - Step 280 Global step 280 Train loss 5.62 on epoch=19
05/20/2022 10:44:34 - INFO - __main__ - Step 290 Global step 290 Train loss 5.30 on epoch=20
05/20/2022 10:44:35 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/20/2022 10:44:52 - INFO - __main__ - Global step 300 Train loss 5.45 Classification-F1 0.0037993920972644382 on epoch=21
05/20/2022 10:44:52 - INFO - __main__ - Saving model with best Classification-F1: 0.0019157088122605363 -> 0.0037993920972644382 on epoch=21, global_step=300
05/20/2022 10:44:53 - INFO - __main__ - Step 310 Global step 310 Train loss 5.30 on epoch=22
05/20/2022 10:44:54 - INFO - __main__ - Step 320 Global step 320 Train loss 5.25 on epoch=22
05/20/2022 10:44:55 - INFO - __main__ - Step 330 Global step 330 Train loss 5.18 on epoch=23
05/20/2022 10:44:57 - INFO - __main__ - Step 340 Global step 340 Train loss 5.22 on epoch=24
05/20/2022 10:44:58 - INFO - __main__ - Step 350 Global step 350 Train loss 5.04 on epoch=24
05/20/2022 10:45:05 - INFO - __main__ - Global step 350 Train loss 5.20 Classification-F1 0.008695652173913044 on epoch=24
05/20/2022 10:45:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0037993920972644382 -> 0.008695652173913044 on epoch=24, global_step=350
05/20/2022 10:45:07 - INFO - __main__ - Step 360 Global step 360 Train loss 4.77 on epoch=25
05/20/2022 10:45:08 - INFO - __main__ - Step 370 Global step 370 Train loss 5.00 on epoch=26
05/20/2022 10:45:09 - INFO - __main__ - Step 380 Global step 380 Train loss 4.96 on epoch=27
05/20/2022 10:45:10 - INFO - __main__ - Step 390 Global step 390 Train loss 4.81 on epoch=27
05/20/2022 10:45:12 - INFO - __main__ - Step 400 Global step 400 Train loss 4.80 on epoch=28
05/20/2022 10:45:19 - INFO - __main__ - Global step 400 Train loss 4.87 Classification-F1 0.008658008658008658 on epoch=28
05/20/2022 10:45:20 - INFO - __main__ - Step 410 Global step 410 Train loss 4.80 on epoch=29
05/20/2022 10:45:21 - INFO - __main__ - Step 420 Global step 420 Train loss 4.80 on epoch=29
05/20/2022 10:45:23 - INFO - __main__ - Step 430 Global step 430 Train loss 4.71 on epoch=30
05/20/2022 10:45:24 - INFO - __main__ - Step 440 Global step 440 Train loss 4.72 on epoch=31
05/20/2022 10:45:25 - INFO - __main__ - Step 450 Global step 450 Train loss 4.77 on epoch=32
05/20/2022 10:45:27 - INFO - __main__ - Global step 450 Train loss 4.76 Classification-F1 0.009523809523809523 on epoch=32
05/20/2022 10:45:27 - INFO - __main__ - Saving model with best Classification-F1: 0.008695652173913044 -> 0.009523809523809523 on epoch=32, global_step=450
05/20/2022 10:45:28 - INFO - __main__ - Step 460 Global step 460 Train loss 4.44 on epoch=32
05/20/2022 10:45:30 - INFO - __main__ - Step 470 Global step 470 Train loss 4.66 on epoch=33
05/20/2022 10:45:31 - INFO - __main__ - Step 480 Global step 480 Train loss 4.44 on epoch=34
05/20/2022 10:45:32 - INFO - __main__ - Step 490 Global step 490 Train loss 4.52 on epoch=34
05/20/2022 10:45:33 - INFO - __main__ - Step 500 Global step 500 Train loss 4.23 on epoch=35
05/20/2022 10:45:35 - INFO - __main__ - Global step 500 Train loss 4.46 Classification-F1 0.009523809523809523 on epoch=35
05/20/2022 10:45:36 - INFO - __main__ - Step 510 Global step 510 Train loss 4.35 on epoch=36
05/20/2022 10:45:38 - INFO - __main__ - Step 520 Global step 520 Train loss 4.39 on epoch=37
05/20/2022 10:45:39 - INFO - __main__ - Step 530 Global step 530 Train loss 4.21 on epoch=37
05/20/2022 10:45:40 - INFO - __main__ - Step 540 Global step 540 Train loss 4.21 on epoch=38
05/20/2022 10:45:41 - INFO - __main__ - Step 550 Global step 550 Train loss 4.08 on epoch=39
05/20/2022 10:45:43 - INFO - __main__ - Global step 550 Train loss 4.25 Classification-F1 0.013888762148104212 on epoch=39
05/20/2022 10:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.013888762148104212 on epoch=39, global_step=550
05/20/2022 10:45:44 - INFO - __main__ - Step 560 Global step 560 Train loss 4.16 on epoch=39
05/20/2022 10:45:46 - INFO - __main__ - Step 570 Global step 570 Train loss 3.98 on epoch=40
05/20/2022 10:45:47 - INFO - __main__ - Step 580 Global step 580 Train loss 3.97 on epoch=41
05/20/2022 10:45:48 - INFO - __main__ - Step 590 Global step 590 Train loss 4.03 on epoch=42
05/20/2022 10:45:49 - INFO - __main__ - Step 600 Global step 600 Train loss 3.78 on epoch=42
05/20/2022 10:45:51 - INFO - __main__ - Global step 600 Train loss 3.99 Classification-F1 0.014366007682124954 on epoch=42
05/20/2022 10:45:51 - INFO - __main__ - Saving model with best Classification-F1: 0.013888762148104212 -> 0.014366007682124954 on epoch=42, global_step=600
05/20/2022 10:45:52 - INFO - __main__ - Step 610 Global step 610 Train loss 3.96 on epoch=43
05/20/2022 10:45:54 - INFO - __main__ - Step 620 Global step 620 Train loss 3.75 on epoch=44
05/20/2022 10:45:55 - INFO - __main__ - Step 630 Global step 630 Train loss 3.87 on epoch=44
05/20/2022 10:45:56 - INFO - __main__ - Step 640 Global step 640 Train loss 3.72 on epoch=45
05/20/2022 10:45:57 - INFO - __main__ - Step 650 Global step 650 Train loss 3.85 on epoch=46
05/20/2022 10:45:59 - INFO - __main__ - Global step 650 Train loss 3.83 Classification-F1 0.01900200021054848 on epoch=46
05/20/2022 10:45:59 - INFO - __main__ - Saving model with best Classification-F1: 0.014366007682124954 -> 0.01900200021054848 on epoch=46, global_step=650
05/20/2022 10:46:00 - INFO - __main__ - Step 660 Global step 660 Train loss 3.83 on epoch=47
05/20/2022 10:46:02 - INFO - __main__ - Step 670 Global step 670 Train loss 3.52 on epoch=47
05/20/2022 10:46:03 - INFO - __main__ - Step 680 Global step 680 Train loss 3.68 on epoch=48
05/20/2022 10:46:04 - INFO - __main__ - Step 690 Global step 690 Train loss 3.69 on epoch=49
05/20/2022 10:46:05 - INFO - __main__ - Step 700 Global step 700 Train loss 3.71 on epoch=49
05/20/2022 10:46:07 - INFO - __main__ - Global step 700 Train loss 3.69 Classification-F1 0.009726443768996961 on epoch=49
05/20/2022 10:46:08 - INFO - __main__ - Step 710 Global step 710 Train loss 3.65 on epoch=50
05/20/2022 10:46:10 - INFO - __main__ - Step 720 Global step 720 Train loss 3.66 on epoch=51
05/20/2022 10:46:11 - INFO - __main__ - Step 730 Global step 730 Train loss 3.66 on epoch=52
05/20/2022 10:46:12 - INFO - __main__ - Step 740 Global step 740 Train loss 3.52 on epoch=52
05/20/2022 10:46:13 - INFO - __main__ - Step 750 Global step 750 Train loss 3.61 on epoch=53
05/20/2022 10:46:15 - INFO - __main__ - Global step 750 Train loss 3.62 Classification-F1 0.022755022755022756 on epoch=53
05/20/2022 10:46:15 - INFO - __main__ - Saving model with best Classification-F1: 0.01900200021054848 -> 0.022755022755022756 on epoch=53, global_step=750
05/20/2022 10:46:17 - INFO - __main__ - Step 760 Global step 760 Train loss 3.46 on epoch=54
05/20/2022 10:46:18 - INFO - __main__ - Step 770 Global step 770 Train loss 3.54 on epoch=54
05/20/2022 10:46:19 - INFO - __main__ - Step 780 Global step 780 Train loss 3.35 on epoch=55
05/20/2022 10:46:20 - INFO - __main__ - Step 790 Global step 790 Train loss 3.33 on epoch=56
05/20/2022 10:46:21 - INFO - __main__ - Step 800 Global step 800 Train loss 3.63 on epoch=57
05/20/2022 10:46:23 - INFO - __main__ - Global step 800 Train loss 3.46 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 10:46:25 - INFO - __main__ - Step 810 Global step 810 Train loss 3.30 on epoch=57
05/20/2022 10:46:26 - INFO - __main__ - Step 820 Global step 820 Train loss 3.34 on epoch=58
05/20/2022 10:46:27 - INFO - __main__ - Step 830 Global step 830 Train loss 3.37 on epoch=59
05/20/2022 10:46:28 - INFO - __main__ - Step 840 Global step 840 Train loss 3.28 on epoch=59
05/20/2022 10:46:30 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/20/2022 10:46:31 - INFO - __main__ - Global step 850 Train loss 3.30 Classification-F1 0.010342598577892695 on epoch=60
05/20/2022 10:46:33 - INFO - __main__ - Step 860 Global step 860 Train loss 3.17 on epoch=61
05/20/2022 10:46:34 - INFO - __main__ - Step 870 Global step 870 Train loss 3.31 on epoch=62
05/20/2022 10:46:35 - INFO - __main__ - Step 880 Global step 880 Train loss 3.21 on epoch=62
05/20/2022 10:46:36 - INFO - __main__ - Step 890 Global step 890 Train loss 3.22 on epoch=63
05/20/2022 10:46:38 - INFO - __main__ - Step 900 Global step 900 Train loss 3.25 on epoch=64
05/20/2022 10:46:39 - INFO - __main__ - Global step 900 Train loss 3.23 Classification-F1 0.027015437392795882 on epoch=64
05/20/2022 10:46:40 - INFO - __main__ - Saving model with best Classification-F1: 0.022755022755022756 -> 0.027015437392795882 on epoch=64, global_step=900
05/20/2022 10:46:41 - INFO - __main__ - Step 910 Global step 910 Train loss 3.23 on epoch=64
05/20/2022 10:46:42 - INFO - __main__ - Step 920 Global step 920 Train loss 2.98 on epoch=65
05/20/2022 10:46:43 - INFO - __main__ - Step 930 Global step 930 Train loss 3.14 on epoch=66
05/20/2022 10:46:44 - INFO - __main__ - Step 940 Global step 940 Train loss 3.43 on epoch=67
05/20/2022 10:46:46 - INFO - __main__ - Step 950 Global step 950 Train loss 3.11 on epoch=67
05/20/2022 10:46:48 - INFO - __main__ - Global step 950 Train loss 3.18 Classification-F1 0.009523809523809523 on epoch=67
05/20/2022 10:46:49 - INFO - __main__ - Step 960 Global step 960 Train loss 3.02 on epoch=68
05/20/2022 10:46:50 - INFO - __main__ - Step 970 Global step 970 Train loss 3.09 on epoch=69
05/20/2022 10:46:51 - INFO - __main__ - Step 980 Global step 980 Train loss 3.19 on epoch=69
05/20/2022 10:46:52 - INFO - __main__ - Step 990 Global step 990 Train loss 3.00 on epoch=70
05/20/2022 10:46:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.00 on epoch=71
05/20/2022 10:46:56 - INFO - __main__ - Global step 1000 Train loss 3.06 Classification-F1 0.05026372121545007 on epoch=71
05/20/2022 10:46:56 - INFO - __main__ - Saving model with best Classification-F1: 0.027015437392795882 -> 0.05026372121545007 on epoch=71, global_step=1000
05/20/2022 10:46:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.25 on epoch=72
05/20/2022 10:46:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.95 on epoch=72
05/20/2022 10:46:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.04 on epoch=73
05/20/2022 10:47:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.95 on epoch=74
05/20/2022 10:47:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.98 on epoch=74
05/20/2022 10:47:04 - INFO - __main__ - Global step 1050 Train loss 3.03 Classification-F1 0.04220175308400969 on epoch=74
05/20/2022 10:47:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.86 on epoch=75
05/20/2022 10:47:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.91 on epoch=76
05/20/2022 10:47:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.11 on epoch=77
05/20/2022 10:47:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.76 on epoch=77
05/20/2022 10:47:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.85 on epoch=78
05/20/2022 10:47:12 - INFO - __main__ - Global step 1100 Train loss 2.90 Classification-F1 0.04597517464338154 on epoch=78
05/20/2022 10:47:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.94 on epoch=79
05/20/2022 10:47:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.99 on epoch=79
05/20/2022 10:47:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.93 on epoch=80
05/20/2022 10:47:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.83 on epoch=81
05/20/2022 10:47:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.01 on epoch=82
05/20/2022 10:47:20 - INFO - __main__ - Global step 1150 Train loss 2.94 Classification-F1 0.038212094653812444 on epoch=82
05/20/2022 10:47:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.86 on epoch=82
05/20/2022 10:47:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.82 on epoch=83
05/20/2022 10:47:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.72 on epoch=84
05/20/2022 10:47:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.87 on epoch=84
05/20/2022 10:47:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.75 on epoch=85
05/20/2022 10:47:28 - INFO - __main__ - Global step 1200 Train loss 2.80 Classification-F1 0.021293236782902136 on epoch=85
05/20/2022 10:47:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.62 on epoch=86
05/20/2022 10:47:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.94 on epoch=87
05/20/2022 10:47:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.66 on epoch=87
05/20/2022 10:47:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.68 on epoch=88
05/20/2022 10:47:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.81 on epoch=89
05/20/2022 10:47:36 - INFO - __main__ - Global step 1250 Train loss 2.74 Classification-F1 0.01835419482478306 on epoch=89
05/20/2022 10:47:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.82 on epoch=89
05/20/2022 10:47:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.73 on epoch=90
05/20/2022 10:47:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.75 on epoch=91
05/20/2022 10:47:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.87 on epoch=92
05/20/2022 10:47:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.72 on epoch=92
05/20/2022 10:47:44 - INFO - __main__ - Global step 1300 Train loss 2.78 Classification-F1 0.05359660311493018 on epoch=92
05/20/2022 10:47:44 - INFO - __main__ - Saving model with best Classification-F1: 0.05026372121545007 -> 0.05359660311493018 on epoch=92, global_step=1300
05/20/2022 10:47:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.88 on epoch=93
05/20/2022 10:47:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.88 on epoch=94
05/20/2022 10:47:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.87 on epoch=94
05/20/2022 10:47:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.76 on epoch=95
05/20/2022 10:47:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.68 on epoch=96
05/20/2022 10:47:52 - INFO - __main__ - Global step 1350 Train loss 2.81 Classification-F1 0.05269536019536019 on epoch=96
05/20/2022 10:47:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.83 on epoch=97
05/20/2022 10:47:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.61 on epoch=97
05/20/2022 10:47:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.68 on epoch=98
05/20/2022 10:47:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.54 on epoch=99
05/20/2022 10:47:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.79 on epoch=99
05/20/2022 10:48:00 - INFO - __main__ - Global step 1400 Train loss 2.69 Classification-F1 0.02796451914098973 on epoch=99
05/20/2022 10:48:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.69 on epoch=100
05/20/2022 10:48:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.77 on epoch=101
05/20/2022 10:48:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.78 on epoch=102
05/20/2022 10:48:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.69 on epoch=102
05/20/2022 10:48:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.80 on epoch=103
05/20/2022 10:48:08 - INFO - __main__ - Global step 1450 Train loss 2.75 Classification-F1 0.04128609263787635 on epoch=103
05/20/2022 10:48:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.62 on epoch=104
05/20/2022 10:48:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.69 on epoch=104
05/20/2022 10:48:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.69 on epoch=105
05/20/2022 10:48:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.58 on epoch=106
05/20/2022 10:48:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.76 on epoch=107
05/20/2022 10:48:16 - INFO - __main__ - Global step 1500 Train loss 2.67 Classification-F1 0.016683433936955063 on epoch=107
05/20/2022 10:48:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.68 on epoch=107
05/20/2022 10:48:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.66 on epoch=108
05/20/2022 10:48:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.47 on epoch=109
05/20/2022 10:48:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=109
05/20/2022 10:48:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.62 on epoch=110
05/20/2022 10:48:24 - INFO - __main__ - Global step 1550 Train loss 2.60 Classification-F1 0.016495956873315364 on epoch=110
05/20/2022 10:48:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.53 on epoch=111
05/20/2022 10:48:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.50 on epoch=112
05/20/2022 10:48:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.56 on epoch=112
05/20/2022 10:48:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.67 on epoch=113
05/20/2022 10:48:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.72 on epoch=114
05/20/2022 10:48:32 - INFO - __main__ - Global step 1600 Train loss 2.60 Classification-F1 0.05855550246854594 on epoch=114
05/20/2022 10:48:32 - INFO - __main__ - Saving model with best Classification-F1: 0.05359660311493018 -> 0.05855550246854594 on epoch=114, global_step=1600
05/20/2022 10:48:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.75 on epoch=114
05/20/2022 10:48:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.41 on epoch=115
05/20/2022 10:48:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.42 on epoch=116
05/20/2022 10:48:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.52 on epoch=117
05/20/2022 10:48:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.60 on epoch=117
05/20/2022 10:48:40 - INFO - __main__ - Global step 1650 Train loss 2.54 Classification-F1 0.045989010989010995 on epoch=117
05/20/2022 10:48:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.55 on epoch=118
05/20/2022 10:48:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.63 on epoch=119
05/20/2022 10:48:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.62 on epoch=119
05/20/2022 10:48:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.48 on epoch=120
05/20/2022 10:48:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.46 on epoch=121
05/20/2022 10:48:49 - INFO - __main__ - Global step 1700 Train loss 2.55 Classification-F1 0.015653235653235655 on epoch=121
05/20/2022 10:48:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.69 on epoch=122
05/20/2022 10:48:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.42 on epoch=122
05/20/2022 10:48:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.47 on epoch=123
05/20/2022 10:48:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.45 on epoch=124
05/20/2022 10:48:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.52 on epoch=124
05/20/2022 10:48:57 - INFO - __main__ - Global step 1750 Train loss 2.51 Classification-F1 0.023436680764794295 on epoch=124
05/20/2022 10:48:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.39 on epoch=125
05/20/2022 10:48:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.63 on epoch=126
05/20/2022 10:49:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.55 on epoch=127
05/20/2022 10:49:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.65 on epoch=127
05/20/2022 10:49:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.39 on epoch=128
05/20/2022 10:49:05 - INFO - __main__ - Global step 1800 Train loss 2.52 Classification-F1 0.019892421011823997 on epoch=128
05/20/2022 10:49:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.44 on epoch=129
05/20/2022 10:49:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.54 on epoch=129
05/20/2022 10:49:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.50 on epoch=130
05/20/2022 10:49:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.29 on epoch=131
05/20/2022 10:49:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.50 on epoch=132
05/20/2022 10:49:13 - INFO - __main__ - Global step 1850 Train loss 2.45 Classification-F1 0.03524025556027518 on epoch=132
05/20/2022 10:49:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.24 on epoch=132
05/20/2022 10:49:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.30 on epoch=133
05/20/2022 10:49:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.31 on epoch=134
05/20/2022 10:49:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.41 on epoch=134
05/20/2022 10:49:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.31 on epoch=135
05/20/2022 10:49:21 - INFO - __main__ - Global step 1900 Train loss 2.32 Classification-F1 0.035707445321468724 on epoch=135
05/20/2022 10:49:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.35 on epoch=136
05/20/2022 10:49:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.47 on epoch=137
05/20/2022 10:49:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.35 on epoch=137
05/20/2022 10:49:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.49 on epoch=138
05/20/2022 10:49:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.47 on epoch=139
05/20/2022 10:49:30 - INFO - __main__ - Global step 1950 Train loss 2.43 Classification-F1 0.019965996774052926 on epoch=139
05/20/2022 10:49:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.44 on epoch=139
05/20/2022 10:49:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.33 on epoch=140
05/20/2022 10:49:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.29 on epoch=141
05/20/2022 10:49:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.38 on epoch=142
05/20/2022 10:49:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.22 on epoch=142
05/20/2022 10:49:38 - INFO - __main__ - Global step 2000 Train loss 2.33 Classification-F1 0.009523809523809523 on epoch=142
05/20/2022 10:49:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.23 on epoch=143
05/20/2022 10:49:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.41 on epoch=144
05/20/2022 10:49:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.36 on epoch=144
05/20/2022 10:49:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.39 on epoch=145
05/20/2022 10:49:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.40 on epoch=146
05/20/2022 10:49:46 - INFO - __main__ - Global step 2050 Train loss 2.36 Classification-F1 0.0401387914285009 on epoch=146
05/20/2022 10:49:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.16 on epoch=147
05/20/2022 10:49:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.26 on epoch=147
05/20/2022 10:49:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.21 on epoch=148
05/20/2022 10:49:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.30 on epoch=149
05/20/2022 10:49:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.28 on epoch=149
05/20/2022 10:49:54 - INFO - __main__ - Global step 2100 Train loss 2.24 Classification-F1 0.02457716701902748 on epoch=149
05/20/2022 10:49:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.20 on epoch=150
05/20/2022 10:49:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.19 on epoch=151
05/20/2022 10:49:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.47 on epoch=152
05/20/2022 10:49:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.40 on epoch=152
05/20/2022 10:50:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.16 on epoch=153
05/20/2022 10:50:02 - INFO - __main__ - Global step 2150 Train loss 2.28 Classification-F1 0.017371013741249674 on epoch=153
05/20/2022 10:50:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.29 on epoch=154
05/20/2022 10:50:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.26 on epoch=154
05/20/2022 10:50:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.30 on epoch=155
05/20/2022 10:50:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.26 on epoch=156
05/20/2022 10:50:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.33 on epoch=157
05/20/2022 10:50:10 - INFO - __main__ - Global step 2200 Train loss 2.29 Classification-F1 0.009852216748768473 on epoch=157
05/20/2022 10:50:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.20 on epoch=157
05/20/2022 10:50:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.24 on epoch=158
05/20/2022 10:50:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.25 on epoch=159
05/20/2022 10:50:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.30 on epoch=159
05/20/2022 10:50:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.30 on epoch=160
05/20/2022 10:50:19 - INFO - __main__ - Global step 2250 Train loss 2.26 Classification-F1 0.023715052598236166 on epoch=160
05/20/2022 10:50:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.21 on epoch=161
05/20/2022 10:50:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.30 on epoch=162
05/20/2022 10:50:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.14 on epoch=162
05/20/2022 10:50:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.17 on epoch=163
05/20/2022 10:50:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.22 on epoch=164
05/20/2022 10:50:28 - INFO - __main__ - Global step 2300 Train loss 2.21 Classification-F1 0.066307911535387 on epoch=164
05/20/2022 10:50:28 - INFO - __main__ - Saving model with best Classification-F1: 0.05855550246854594 -> 0.066307911535387 on epoch=164, global_step=2300
05/20/2022 10:50:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.35 on epoch=164
05/20/2022 10:50:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.17 on epoch=165
05/20/2022 10:50:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.18 on epoch=166
05/20/2022 10:50:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.21 on epoch=167
05/20/2022 10:50:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.00 on epoch=167
05/20/2022 10:50:36 - INFO - __main__ - Global step 2350 Train loss 2.18 Classification-F1 0.03553433630857859 on epoch=167
05/20/2022 10:50:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.10 on epoch=168
05/20/2022 10:50:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.17 on epoch=169
05/20/2022 10:50:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.14 on epoch=169
05/20/2022 10:50:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.20 on epoch=170
05/20/2022 10:50:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.96 on epoch=171
05/20/2022 10:50:44 - INFO - __main__ - Global step 2400 Train loss 2.11 Classification-F1 0.0472108710255262 on epoch=171
05/20/2022 10:50:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.24 on epoch=172
05/20/2022 10:50:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.17 on epoch=172
05/20/2022 10:50:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.18 on epoch=173
05/20/2022 10:50:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.07 on epoch=174
05/20/2022 10:50:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.16 on epoch=174
05/20/2022 10:50:53 - INFO - __main__ - Global step 2450 Train loss 2.16 Classification-F1 0.04377074341301089 on epoch=174
05/20/2022 10:50:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.01 on epoch=175
05/20/2022 10:50:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.09 on epoch=176
05/20/2022 10:50:57 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.08 on epoch=177
05/20/2022 10:50:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.05 on epoch=177
05/20/2022 10:50:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.20 on epoch=178
05/20/2022 10:51:01 - INFO - __main__ - Global step 2500 Train loss 2.09 Classification-F1 0.02943967060508414 on epoch=178
05/20/2022 10:51:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.14 on epoch=179
05/20/2022 10:51:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.15 on epoch=179
05/20/2022 10:51:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.11 on epoch=180
05/20/2022 10:51:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.05 on epoch=181
05/20/2022 10:51:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.10 on epoch=182
05/20/2022 10:51:09 - INFO - __main__ - Global step 2550 Train loss 2.11 Classification-F1 0.061005356199864205 on epoch=182
05/20/2022 10:51:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.02 on epoch=182
05/20/2022 10:51:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.06 on epoch=183
05/20/2022 10:51:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.10 on epoch=184
05/20/2022 10:51:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.10 on epoch=184
05/20/2022 10:51:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.97 on epoch=185
05/20/2022 10:51:18 - INFO - __main__ - Global step 2600 Train loss 2.05 Classification-F1 0.02266225639191847 on epoch=185
05/20/2022 10:51:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.13 on epoch=186
05/20/2022 10:51:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.23 on epoch=187
05/20/2022 10:51:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.16 on epoch=187
05/20/2022 10:51:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.08 on epoch=188
05/20/2022 10:51:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.19 on epoch=189
05/20/2022 10:51:26 - INFO - __main__ - Global step 2650 Train loss 2.16 Classification-F1 0.043887626552153045 on epoch=189
05/20/2022 10:51:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.11 on epoch=189
05/20/2022 10:51:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.91 on epoch=190
05/20/2022 10:51:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.93 on epoch=191
05/20/2022 10:51:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.00 on epoch=192
05/20/2022 10:51:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.04 on epoch=192
05/20/2022 10:51:34 - INFO - __main__ - Global step 2700 Train loss 2.00 Classification-F1 0.04007709954210692 on epoch=192
05/20/2022 10:51:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.07 on epoch=193
05/20/2022 10:51:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.04 on epoch=194
05/20/2022 10:51:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.08 on epoch=194
05/20/2022 10:51:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.97 on epoch=195
05/20/2022 10:51:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.99 on epoch=196
05/20/2022 10:51:42 - INFO - __main__ - Global step 2750 Train loss 2.03 Classification-F1 0.0347377660741716 on epoch=196
05/20/2022 10:51:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.12 on epoch=197
05/20/2022 10:51:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.85 on epoch=197
05/20/2022 10:51:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.03 on epoch=198
05/20/2022 10:51:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.03 on epoch=199
05/20/2022 10:51:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.09 on epoch=199
05/20/2022 10:51:50 - INFO - __main__ - Global step 2800 Train loss 2.02 Classification-F1 0.0401556097125957 on epoch=199
05/20/2022 10:51:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.95 on epoch=200
05/20/2022 10:51:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.89 on epoch=201
05/20/2022 10:51:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.07 on epoch=202
05/20/2022 10:51:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.93 on epoch=202
05/20/2022 10:51:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.92 on epoch=203
05/20/2022 10:51:58 - INFO - __main__ - Global step 2850 Train loss 1.95 Classification-F1 0.0336038961038961 on epoch=203
05/20/2022 10:52:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.90 on epoch=204
05/20/2022 10:52:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.09 on epoch=204
05/20/2022 10:52:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.03 on epoch=205
05/20/2022 10:52:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.96 on epoch=206
05/20/2022 10:52:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.85 on epoch=207
05/20/2022 10:52:07 - INFO - __main__ - Global step 2900 Train loss 1.97 Classification-F1 0.02634920634920635 on epoch=207
05/20/2022 10:52:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.00 on epoch=207
05/20/2022 10:52:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.93 on epoch=208
05/20/2022 10:52:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.90 on epoch=209
05/20/2022 10:52:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.00 on epoch=209
05/20/2022 10:52:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.03 on epoch=210
05/20/2022 10:52:15 - INFO - __main__ - Global step 2950 Train loss 1.97 Classification-F1 0.029290452037233152 on epoch=210
05/20/2022 10:52:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.86 on epoch=211
05/20/2022 10:52:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.92 on epoch=212
05/20/2022 10:52:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.85 on epoch=212
05/20/2022 10:52:20 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.83 on epoch=213
05/20/2022 10:52:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.99 on epoch=214
05/20/2022 10:52:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:52:22 - INFO - __main__ - Printing 3 examples
05/20/2022 10:52:22 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 10:52:22 - INFO - __main__ - ['Animal']
05/20/2022 10:52:22 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 10:52:22 - INFO - __main__ - ['Animal']
05/20/2022 10:52:22 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 10:52:22 - INFO - __main__ - ['Animal']
05/20/2022 10:52:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:52:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:52:23 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:52:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:52:23 - INFO - __main__ - Printing 3 examples
05/20/2022 10:52:23 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 10:52:23 - INFO - __main__ - ['Animal']
05/20/2022 10:52:23 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 10:52:23 - INFO - __main__ - ['Animal']
05/20/2022 10:52:23 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 10:52:23 - INFO - __main__ - ['Animal']
05/20/2022 10:52:23 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:52:23 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:52:23 - INFO - __main__ - Global step 3000 Train loss 1.89 Classification-F1 0.009726443768996961 on epoch=214
05/20/2022 10:52:23 - INFO - __main__ - save last model!
05/20/2022 10:52:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 10:52:23 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:52:23 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 10:52:23 - INFO - __main__ - Printing 3 examples
05/20/2022 10:52:23 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 10:52:23 - INFO - __main__ - ['Animal']
05/20/2022 10:52:23 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 10:52:23 - INFO - __main__ - ['Animal']
05/20/2022 10:52:23 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 10:52:23 - INFO - __main__ - ['Village']
05/20/2022 10:52:23 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:52:25 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:52:28 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:52:28 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 10:52:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:52:28 - INFO - __main__ - Starting training!
05/20/2022 10:52:57 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/20/2022 10:52:57 - INFO - __main__ - Classification-F1 on test data: 0.0160
05/20/2022 10:52:58 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.066307911535387, test_performance=0.016044697001440494
05/20/2022 10:52:58 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/20/2022 10:52:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:52:58 - INFO - __main__ - Printing 3 examples
05/20/2022 10:52:58 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 10:52:58 - INFO - __main__ - ['Animal']
05/20/2022 10:52:58 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 10:52:58 - INFO - __main__ - ['Animal']
05/20/2022 10:52:58 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 10:52:58 - INFO - __main__ - ['Animal']
05/20/2022 10:52:58 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:52:59 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:52:59 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 10:52:59 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 10:52:59 - INFO - __main__ - Printing 3 examples
05/20/2022 10:52:59 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 10:52:59 - INFO - __main__ - ['Animal']
05/20/2022 10:52:59 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 10:52:59 - INFO - __main__ - ['Animal']
05/20/2022 10:52:59 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 10:52:59 - INFO - __main__ - ['Animal']
05/20/2022 10:52:59 - INFO - __main__ - Tokenizing Input ...
05/20/2022 10:52:59 - INFO - __main__ - Tokenizing Output ...
05/20/2022 10:52:59 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 10:53:04 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 10:53:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 10:53:05 - INFO - __main__ - Starting training!
05/20/2022 10:53:06 - INFO - __main__ - Step 10 Global step 10 Train loss 7.07 on epoch=0
05/20/2022 10:53:07 - INFO - __main__ - Step 20 Global step 20 Train loss 7.55 on epoch=1
05/20/2022 10:53:09 - INFO - __main__ - Step 30 Global step 30 Train loss 7.25 on epoch=2
05/20/2022 10:53:10 - INFO - __main__ - Step 40 Global step 40 Train loss 7.14 on epoch=2
05/20/2022 10:53:11 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/20/2022 10:53:21 - INFO - __main__ - Global step 50 Train loss 7.22 Classification-F1 0.0 on epoch=3
05/20/2022 10:53:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 10:53:22 - INFO - __main__ - Step 60 Global step 60 Train loss 7.20 on epoch=4
05/20/2022 10:53:23 - INFO - __main__ - Step 70 Global step 70 Train loss 7.16 on epoch=4
05/20/2022 10:53:25 - INFO - __main__ - Step 80 Global step 80 Train loss 6.73 on epoch=5
05/20/2022 10:53:26 - INFO - __main__ - Step 90 Global step 90 Train loss 7.00 on epoch=6
05/20/2022 10:53:27 - INFO - __main__ - Step 100 Global step 100 Train loss 6.76 on epoch=7
05/20/2022 10:54:02 - INFO - __main__ - Global step 100 Train loss 6.97 Classification-F1 0.0 on epoch=7
05/20/2022 10:54:04 - INFO - __main__ - Step 110 Global step 110 Train loss 6.71 on epoch=7
05/20/2022 10:54:05 - INFO - __main__ - Step 120 Global step 120 Train loss 6.64 on epoch=8
05/20/2022 10:54:06 - INFO - __main__ - Step 130 Global step 130 Train loss 6.80 on epoch=9
05/20/2022 10:54:07 - INFO - __main__ - Step 140 Global step 140 Train loss 6.68 on epoch=9
05/20/2022 10:54:09 - INFO - __main__ - Step 150 Global step 150 Train loss 6.34 on epoch=10
05/20/2022 10:55:15 - INFO - __main__ - Global step 150 Train loss 6.63 Classification-F1 0.0 on epoch=10
05/20/2022 10:55:16 - INFO - __main__ - Step 160 Global step 160 Train loss 6.55 on epoch=11
05/20/2022 10:55:18 - INFO - __main__ - Step 170 Global step 170 Train loss 6.28 on epoch=12
05/20/2022 10:55:19 - INFO - __main__ - Step 180 Global step 180 Train loss 6.35 on epoch=12
05/20/2022 10:55:20 - INFO - __main__ - Step 190 Global step 190 Train loss 6.28 on epoch=13
05/20/2022 10:55:21 - INFO - __main__ - Step 200 Global step 200 Train loss 6.41 on epoch=14
05/20/2022 10:56:19 - INFO - __main__ - Global step 200 Train loss 6.38 Classification-F1 0.0 on epoch=14
05/20/2022 10:56:20 - INFO - __main__ - Step 210 Global step 210 Train loss 6.34 on epoch=14
05/20/2022 10:56:21 - INFO - __main__ - Step 220 Global step 220 Train loss 6.07 on epoch=15
05/20/2022 10:56:23 - INFO - __main__ - Step 230 Global step 230 Train loss 6.32 on epoch=16
05/20/2022 10:56:24 - INFO - __main__ - Step 240 Global step 240 Train loss 6.12 on epoch=17
05/20/2022 10:56:25 - INFO - __main__ - Step 250 Global step 250 Train loss 6.07 on epoch=17
05/20/2022 10:57:22 - INFO - __main__ - Global step 250 Train loss 6.18 Classification-F1 0.0 on epoch=17
05/20/2022 10:57:23 - INFO - __main__ - Step 260 Global step 260 Train loss 5.99 on epoch=18
05/20/2022 10:57:25 - INFO - __main__ - Step 270 Global step 270 Train loss 6.14 on epoch=19
05/20/2022 10:57:26 - INFO - __main__ - Step 280 Global step 280 Train loss 6.20 on epoch=19
05/20/2022 10:57:27 - INFO - __main__ - Step 290 Global step 290 Train loss 5.90 on epoch=20
05/20/2022 10:57:29 - INFO - __main__ - Step 300 Global step 300 Train loss 6.08 on epoch=21
05/20/2022 10:58:19 - INFO - __main__ - Global step 300 Train loss 6.06 Classification-F1 0.0 on epoch=21
05/20/2022 10:58:21 - INFO - __main__ - Step 310 Global step 310 Train loss 5.98 on epoch=22
05/20/2022 10:58:22 - INFO - __main__ - Step 320 Global step 320 Train loss 5.87 on epoch=22
05/20/2022 10:58:23 - INFO - __main__ - Step 330 Global step 330 Train loss 5.85 on epoch=23
05/20/2022 10:58:24 - INFO - __main__ - Step 340 Global step 340 Train loss 5.86 on epoch=24
05/20/2022 10:58:26 - INFO - __main__ - Step 350 Global step 350 Train loss 5.83 on epoch=24
05/20/2022 10:59:02 - INFO - __main__ - Global step 350 Train loss 5.88 Classification-F1 0.0 on epoch=24
05/20/2022 10:59:04 - INFO - __main__ - Step 360 Global step 360 Train loss 5.63 on epoch=25
05/20/2022 10:59:05 - INFO - __main__ - Step 370 Global step 370 Train loss 5.71 on epoch=26
05/20/2022 10:59:06 - INFO - __main__ - Step 380 Global step 380 Train loss 5.62 on epoch=27
05/20/2022 10:59:07 - INFO - __main__ - Step 390 Global step 390 Train loss 5.48 on epoch=27
05/20/2022 10:59:08 - INFO - __main__ - Step 400 Global step 400 Train loss 5.54 on epoch=28
05/20/2022 10:59:30 - INFO - __main__ - Global step 400 Train loss 5.60 Classification-F1 0.0 on epoch=28
05/20/2022 10:59:31 - INFO - __main__ - Step 410 Global step 410 Train loss 5.64 on epoch=29
05/20/2022 10:59:32 - INFO - __main__ - Step 420 Global step 420 Train loss 5.63 on epoch=29
05/20/2022 10:59:33 - INFO - __main__ - Step 430 Global step 430 Train loss 5.47 on epoch=30
05/20/2022 10:59:34 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=31
05/20/2022 10:59:36 - INFO - __main__ - Step 450 Global step 450 Train loss 5.41 on epoch=32
05/20/2022 10:59:41 - INFO - __main__ - Global step 450 Train loss 5.55 Classification-F1 0.0052417006406523005 on epoch=32
05/20/2022 10:59:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0052417006406523005 on epoch=32, global_step=450
05/20/2022 10:59:42 - INFO - __main__ - Step 460 Global step 460 Train loss 5.36 on epoch=32
05/20/2022 10:59:43 - INFO - __main__ - Step 470 Global step 470 Train loss 5.42 on epoch=33
05/20/2022 10:59:45 - INFO - __main__ - Step 480 Global step 480 Train loss 5.34 on epoch=34
05/20/2022 10:59:46 - INFO - __main__ - Step 490 Global step 490 Train loss 5.44 on epoch=34
05/20/2022 10:59:47 - INFO - __main__ - Step 500 Global step 500 Train loss 5.02 on epoch=35
05/20/2022 11:00:07 - INFO - __main__ - Global step 500 Train loss 5.32 Classification-F1 0.006913580246913581 on epoch=35
05/20/2022 11:00:08 - INFO - __main__ - Saving model with best Classification-F1: 0.0052417006406523005 -> 0.006913580246913581 on epoch=35, global_step=500
05/20/2022 11:00:09 - INFO - __main__ - Step 510 Global step 510 Train loss 5.28 on epoch=36
05/20/2022 11:00:10 - INFO - __main__ - Step 520 Global step 520 Train loss 5.16 on epoch=37
05/20/2022 11:00:11 - INFO - __main__ - Step 530 Global step 530 Train loss 5.16 on epoch=37
05/20/2022 11:00:12 - INFO - __main__ - Step 540 Global step 540 Train loss 5.13 on epoch=38
05/20/2022 11:00:14 - INFO - __main__ - Step 550 Global step 550 Train loss 5.24 on epoch=39
05/20/2022 11:00:24 - INFO - __main__ - Global step 550 Train loss 5.19 Classification-F1 0.0071135430916552675 on epoch=39
05/20/2022 11:00:24 - INFO - __main__ - Saving model with best Classification-F1: 0.006913580246913581 -> 0.0071135430916552675 on epoch=39, global_step=550
05/20/2022 11:00:26 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/20/2022 11:00:27 - INFO - __main__ - Step 570 Global step 570 Train loss 5.01 on epoch=40
05/20/2022 11:00:28 - INFO - __main__ - Step 580 Global step 580 Train loss 4.96 on epoch=41
05/20/2022 11:00:29 - INFO - __main__ - Step 590 Global step 590 Train loss 4.89 on epoch=42
05/20/2022 11:00:30 - INFO - __main__ - Step 600 Global step 600 Train loss 4.91 on epoch=42
05/20/2022 11:00:38 - INFO - __main__ - Global step 600 Train loss 4.97 Classification-F1 0.008849557522123895 on epoch=42
05/20/2022 11:00:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0071135430916552675 -> 0.008849557522123895 on epoch=42, global_step=600
05/20/2022 11:00:40 - INFO - __main__ - Step 610 Global step 610 Train loss 4.86 on epoch=43
05/20/2022 11:00:41 - INFO - __main__ - Step 620 Global step 620 Train loss 4.79 on epoch=44
05/20/2022 11:00:42 - INFO - __main__ - Step 630 Global step 630 Train loss 4.81 on epoch=44
05/20/2022 11:00:43 - INFO - __main__ - Step 640 Global step 640 Train loss 4.78 on epoch=45
05/20/2022 11:00:44 - INFO - __main__ - Step 650 Global step 650 Train loss 4.75 on epoch=46
05/20/2022 11:00:47 - INFO - __main__ - Global step 650 Train loss 4.80 Classification-F1 0.009523809523809523 on epoch=46
05/20/2022 11:00:47 - INFO - __main__ - Saving model with best Classification-F1: 0.008849557522123895 -> 0.009523809523809523 on epoch=46, global_step=650
05/20/2022 11:00:48 - INFO - __main__ - Step 660 Global step 660 Train loss 4.64 on epoch=47
05/20/2022 11:00:49 - INFO - __main__ - Step 670 Global step 670 Train loss 4.49 on epoch=47
05/20/2022 11:00:50 - INFO - __main__ - Step 680 Global step 680 Train loss 4.61 on epoch=48
05/20/2022 11:00:52 - INFO - __main__ - Step 690 Global step 690 Train loss 4.52 on epoch=49
05/20/2022 11:00:53 - INFO - __main__ - Step 700 Global step 700 Train loss 4.73 on epoch=49
05/20/2022 11:00:55 - INFO - __main__ - Global step 700 Train loss 4.60 Classification-F1 0.039432362563755166 on epoch=49
05/20/2022 11:00:55 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.039432362563755166 on epoch=49, global_step=700
05/20/2022 11:00:56 - INFO - __main__ - Step 710 Global step 710 Train loss 4.32 on epoch=50
05/20/2022 11:00:57 - INFO - __main__ - Step 720 Global step 720 Train loss 4.55 on epoch=51
05/20/2022 11:00:59 - INFO - __main__ - Step 730 Global step 730 Train loss 4.39 on epoch=52
05/20/2022 11:01:00 - INFO - __main__ - Step 740 Global step 740 Train loss 4.24 on epoch=52
05/20/2022 11:01:01 - INFO - __main__ - Step 750 Global step 750 Train loss 4.30 on epoch=53
05/20/2022 11:01:08 - INFO - __main__ - Global step 750 Train loss 4.36 Classification-F1 0.02242063492063492 on epoch=53
05/20/2022 11:01:09 - INFO - __main__ - Step 760 Global step 760 Train loss 4.25 on epoch=54
05/20/2022 11:01:10 - INFO - __main__ - Step 770 Global step 770 Train loss 4.32 on epoch=54
05/20/2022 11:01:11 - INFO - __main__ - Step 780 Global step 780 Train loss 4.30 on epoch=55
05/20/2022 11:01:13 - INFO - __main__ - Step 790 Global step 790 Train loss 4.29 on epoch=56
05/20/2022 11:01:14 - INFO - __main__ - Step 800 Global step 800 Train loss 4.27 on epoch=57
05/20/2022 11:01:16 - INFO - __main__ - Global step 800 Train loss 4.29 Classification-F1 0.03304131889356419 on epoch=57
05/20/2022 11:01:17 - INFO - __main__ - Step 810 Global step 810 Train loss 4.10 on epoch=57
05/20/2022 11:01:18 - INFO - __main__ - Step 820 Global step 820 Train loss 4.19 on epoch=58
05/20/2022 11:01:19 - INFO - __main__ - Step 830 Global step 830 Train loss 4.21 on epoch=59
05/20/2022 11:01:20 - INFO - __main__ - Step 840 Global step 840 Train loss 4.33 on epoch=59
05/20/2022 11:01:22 - INFO - __main__ - Step 850 Global step 850 Train loss 4.08 on epoch=60
05/20/2022 11:01:23 - INFO - __main__ - Global step 850 Train loss 4.18 Classification-F1 0.022795082945458883 on epoch=60
05/20/2022 11:01:25 - INFO - __main__ - Step 860 Global step 860 Train loss 4.03 on epoch=61
05/20/2022 11:01:26 - INFO - __main__ - Step 870 Global step 870 Train loss 4.10 on epoch=62
05/20/2022 11:01:27 - INFO - __main__ - Step 880 Global step 880 Train loss 4.03 on epoch=62
05/20/2022 11:01:28 - INFO - __main__ - Step 890 Global step 890 Train loss 4.21 on epoch=63
05/20/2022 11:01:29 - INFO - __main__ - Step 900 Global step 900 Train loss 4.12 on epoch=64
05/20/2022 11:01:31 - INFO - __main__ - Global step 900 Train loss 4.10 Classification-F1 0.02463023701961755 on epoch=64
05/20/2022 11:01:32 - INFO - __main__ - Step 910 Global step 910 Train loss 4.09 on epoch=64
05/20/2022 11:01:34 - INFO - __main__ - Step 920 Global step 920 Train loss 4.03 on epoch=65
05/20/2022 11:01:35 - INFO - __main__ - Step 930 Global step 930 Train loss 4.04 on epoch=66
05/20/2022 11:01:36 - INFO - __main__ - Step 940 Global step 940 Train loss 4.16 on epoch=67
05/20/2022 11:01:37 - INFO - __main__ - Step 950 Global step 950 Train loss 4.01 on epoch=67
05/20/2022 11:01:39 - INFO - __main__ - Global step 950 Train loss 4.07 Classification-F1 0.009644364074743823 on epoch=67
05/20/2022 11:01:40 - INFO - __main__ - Step 960 Global step 960 Train loss 4.06 on epoch=68
05/20/2022 11:01:42 - INFO - __main__ - Step 970 Global step 970 Train loss 4.11 on epoch=69
05/20/2022 11:01:43 - INFO - __main__ - Step 980 Global step 980 Train loss 3.87 on epoch=69
05/20/2022 11:01:44 - INFO - __main__ - Step 990 Global step 990 Train loss 3.88 on epoch=70
05/20/2022 11:01:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.97 on epoch=71
05/20/2022 11:01:47 - INFO - __main__ - Global step 1000 Train loss 3.98 Classification-F1 0.02633573323228496 on epoch=71
05/20/2022 11:01:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.91 on epoch=72
05/20/2022 11:01:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.82 on epoch=72
05/20/2022 11:01:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.05 on epoch=73
05/20/2022 11:01:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.84 on epoch=74
05/20/2022 11:01:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.83 on epoch=74
05/20/2022 11:01:55 - INFO - __main__ - Global step 1050 Train loss 3.89 Classification-F1 0.040131068134059915 on epoch=74
05/20/2022 11:01:55 - INFO - __main__ - Saving model with best Classification-F1: 0.039432362563755166 -> 0.040131068134059915 on epoch=74, global_step=1050
05/20/2022 11:01:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.83 on epoch=75
05/20/2022 11:01:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.81 on epoch=76
05/20/2022 11:01:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.85 on epoch=77
05/20/2022 11:02:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.73 on epoch=77
05/20/2022 11:02:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.75 on epoch=78
05/20/2022 11:02:03 - INFO - __main__ - Global step 1100 Train loss 3.80 Classification-F1 0.0431586552475853 on epoch=78
05/20/2022 11:02:03 - INFO - __main__ - Saving model with best Classification-F1: 0.040131068134059915 -> 0.0431586552475853 on epoch=78, global_step=1100
05/20/2022 11:02:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.76 on epoch=79
05/20/2022 11:02:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.73 on epoch=79
05/20/2022 11:02:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.64 on epoch=80
05/20/2022 11:02:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.62 on epoch=81
05/20/2022 11:02:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.89 on epoch=82
05/20/2022 11:02:10 - INFO - __main__ - Global step 1150 Train loss 3.73 Classification-F1 0.030568975790757673 on epoch=82
05/20/2022 11:02:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.76 on epoch=82
05/20/2022 11:02:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.69 on epoch=83
05/20/2022 11:02:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.56 on epoch=84
05/20/2022 11:02:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.75 on epoch=84
05/20/2022 11:02:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.59 on epoch=85
05/20/2022 11:02:18 - INFO - __main__ - Global step 1200 Train loss 3.67 Classification-F1 0.04690474137774552 on epoch=85
05/20/2022 11:02:18 - INFO - __main__ - Saving model with best Classification-F1: 0.0431586552475853 -> 0.04690474137774552 on epoch=85, global_step=1200
05/20/2022 11:02:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.54 on epoch=86
05/20/2022 11:02:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.62 on epoch=87
05/20/2022 11:02:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.52 on epoch=87
05/20/2022 11:02:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.51 on epoch=88
05/20/2022 11:02:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.77 on epoch=89
05/20/2022 11:02:26 - INFO - __main__ - Global step 1250 Train loss 3.59 Classification-F1 0.04433647900324923 on epoch=89
05/20/2022 11:02:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.52 on epoch=89
05/20/2022 11:02:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.62 on epoch=90
05/20/2022 11:02:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.37 on epoch=91
05/20/2022 11:02:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.58 on epoch=92
05/20/2022 11:02:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.38 on epoch=92
05/20/2022 11:02:34 - INFO - __main__ - Global step 1300 Train loss 3.49 Classification-F1 0.053134431705860276 on epoch=92
05/20/2022 11:02:34 - INFO - __main__ - Saving model with best Classification-F1: 0.04690474137774552 -> 0.053134431705860276 on epoch=92, global_step=1300
05/20/2022 11:02:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.52 on epoch=93
05/20/2022 11:02:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.35 on epoch=94
05/20/2022 11:02:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.30 on epoch=94
05/20/2022 11:02:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.25 on epoch=95
05/20/2022 11:02:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.20 on epoch=96
05/20/2022 11:02:42 - INFO - __main__ - Global step 1350 Train loss 3.33 Classification-F1 0.07162035412336056 on epoch=96
05/20/2022 11:02:42 - INFO - __main__ - Saving model with best Classification-F1: 0.053134431705860276 -> 0.07162035412336056 on epoch=96, global_step=1350
05/20/2022 11:02:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.31 on epoch=97
05/20/2022 11:02:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.13 on epoch=97
05/20/2022 11:02:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.42 on epoch=98
05/20/2022 11:02:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.27 on epoch=99
05/20/2022 11:02:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.28 on epoch=99
05/20/2022 11:02:50 - INFO - __main__ - Global step 1400 Train loss 3.28 Classification-F1 0.01647479158396189 on epoch=99
05/20/2022 11:02:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.29 on epoch=100
05/20/2022 11:02:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.18 on epoch=101
05/20/2022 11:02:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.41 on epoch=102
05/20/2022 11:02:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.12 on epoch=102
05/20/2022 11:02:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.31 on epoch=103
05/20/2022 11:02:58 - INFO - __main__ - Global step 1450 Train loss 3.26 Classification-F1 0.026077097505668938 on epoch=103
05/20/2022 11:02:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.26 on epoch=104
05/20/2022 11:03:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.29 on epoch=104
05/20/2022 11:03:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.21 on epoch=105
05/20/2022 11:03:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.32 on epoch=106
05/20/2022 11:03:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.33 on epoch=107
05/20/2022 11:03:06 - INFO - __main__ - Global step 1500 Train loss 3.28 Classification-F1 0.06912981755087018 on epoch=107
05/20/2022 11:03:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.22 on epoch=107
05/20/2022 11:03:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.20 on epoch=108
05/20/2022 11:03:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.18 on epoch=109
05/20/2022 11:03:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.09 on epoch=109
05/20/2022 11:03:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.93 on epoch=110
05/20/2022 11:03:14 - INFO - __main__ - Global step 1550 Train loss 3.12 Classification-F1 0.028641137380618447 on epoch=110
05/20/2022 11:03:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.16 on epoch=111
05/20/2022 11:03:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.16 on epoch=112
05/20/2022 11:03:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.14 on epoch=112
05/20/2022 11:03:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.14 on epoch=113
05/20/2022 11:03:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.05 on epoch=114
05/20/2022 11:03:21 - INFO - __main__ - Global step 1600 Train loss 3.13 Classification-F1 0.025325249463180495 on epoch=114
05/20/2022 11:03:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.07 on epoch=114
05/20/2022 11:03:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.12 on epoch=115
05/20/2022 11:03:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.05 on epoch=116
05/20/2022 11:03:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.27 on epoch=117
05/20/2022 11:03:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.99 on epoch=117
05/20/2022 11:03:29 - INFO - __main__ - Global step 1650 Train loss 3.10 Classification-F1 0.03382939524243872 on epoch=117
05/20/2022 11:03:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.07 on epoch=118
05/20/2022 11:03:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.98 on epoch=119
05/20/2022 11:03:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.05 on epoch=119
05/20/2022 11:03:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.09 on epoch=120
05/20/2022 11:03:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.01 on epoch=121
05/20/2022 11:03:37 - INFO - __main__ - Global step 1700 Train loss 3.04 Classification-F1 0.0460601205772301 on epoch=121
05/20/2022 11:03:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.06 on epoch=122
05/20/2022 11:03:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.95 on epoch=122
05/20/2022 11:03:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.00 on epoch=123
05/20/2022 11:03:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.92 on epoch=124
05/20/2022 11:03:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.08 on epoch=124
05/20/2022 11:03:45 - INFO - __main__ - Global step 1750 Train loss 3.00 Classification-F1 0.027011403230915422 on epoch=124
05/20/2022 11:03:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.00 on epoch=125
05/20/2022 11:03:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.83 on epoch=126
05/20/2022 11:03:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.13 on epoch=127
05/20/2022 11:03:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.95 on epoch=127
05/20/2022 11:03:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.11 on epoch=128
05/20/2022 11:03:53 - INFO - __main__ - Global step 1800 Train loss 3.00 Classification-F1 0.038018389173851364 on epoch=128
05/20/2022 11:03:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.94 on epoch=129
05/20/2022 11:03:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.98 on epoch=129
05/20/2022 11:03:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.90 on epoch=130
05/20/2022 11:03:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.06 on epoch=131
05/20/2022 11:03:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.94 on epoch=132
05/20/2022 11:04:01 - INFO - __main__ - Global step 1850 Train loss 2.96 Classification-F1 0.028639301206952513 on epoch=132
05/20/2022 11:04:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.82 on epoch=132
05/20/2022 11:04:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.85 on epoch=133
05/20/2022 11:04:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.05 on epoch=134
05/20/2022 11:04:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.95 on epoch=134
05/20/2022 11:04:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.91 on epoch=135
05/20/2022 11:04:09 - INFO - __main__ - Global step 1900 Train loss 2.92 Classification-F1 0.043307643326087435 on epoch=135
05/20/2022 11:04:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.84 on epoch=136
05/20/2022 11:04:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.96 on epoch=137
05/20/2022 11:04:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.74 on epoch=137
05/20/2022 11:04:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.86 on epoch=138
05/20/2022 11:04:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.87 on epoch=139
05/20/2022 11:04:16 - INFO - __main__ - Global step 1950 Train loss 2.86 Classification-F1 0.028763164033385868 on epoch=139
05/20/2022 11:04:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.80 on epoch=139
05/20/2022 11:04:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.82 on epoch=140
05/20/2022 11:04:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.76 on epoch=141
05/20/2022 11:04:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.92 on epoch=142
05/20/2022 11:04:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.87 on epoch=142
05/20/2022 11:04:24 - INFO - __main__ - Global step 2000 Train loss 2.83 Classification-F1 0.009685230024213076 on epoch=142
05/20/2022 11:04:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.74 on epoch=143
05/20/2022 11:04:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.88 on epoch=144
05/20/2022 11:04:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.90 on epoch=144
05/20/2022 11:04:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.85 on epoch=145
05/20/2022 11:04:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.93 on epoch=146
05/20/2022 11:04:32 - INFO - __main__ - Global step 2050 Train loss 2.86 Classification-F1 0.09203906713558196 on epoch=146
05/20/2022 11:04:32 - INFO - __main__ - Saving model with best Classification-F1: 0.07162035412336056 -> 0.09203906713558196 on epoch=146, global_step=2050
05/20/2022 11:04:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.05 on epoch=147
05/20/2022 11:04:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.74 on epoch=147
05/20/2022 11:04:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.95 on epoch=148
05/20/2022 11:04:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.71 on epoch=149
05/20/2022 11:04:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.93 on epoch=149
05/20/2022 11:04:40 - INFO - __main__ - Global step 2100 Train loss 2.88 Classification-F1 0.11475159985029049 on epoch=149
05/20/2022 11:04:40 - INFO - __main__ - Saving model with best Classification-F1: 0.09203906713558196 -> 0.11475159985029049 on epoch=149, global_step=2100
05/20/2022 11:04:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.90 on epoch=150
05/20/2022 11:04:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.94 on epoch=151
05/20/2022 11:04:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.89 on epoch=152
05/20/2022 11:04:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.77 on epoch=152
05/20/2022 11:04:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.86 on epoch=153
05/20/2022 11:04:48 - INFO - __main__ - Global step 2150 Train loss 2.87 Classification-F1 0.08647727892810438 on epoch=153
05/20/2022 11:04:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.83 on epoch=154
05/20/2022 11:04:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.85 on epoch=154
05/20/2022 11:04:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.84 on epoch=155
05/20/2022 11:04:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.69 on epoch=156
05/20/2022 11:04:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.72 on epoch=157
05/20/2022 11:04:56 - INFO - __main__ - Global step 2200 Train loss 2.79 Classification-F1 0.09641713589853433 on epoch=157
05/20/2022 11:04:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.76 on epoch=157
05/20/2022 11:04:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.74 on epoch=158
05/20/2022 11:04:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.84 on epoch=159
05/20/2022 11:05:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.85 on epoch=159
05/20/2022 11:05:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.72 on epoch=160
05/20/2022 11:05:03 - INFO - __main__ - Global step 2250 Train loss 2.78 Classification-F1 0.03529973862454681 on epoch=160
05/20/2022 11:05:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.80 on epoch=161
05/20/2022 11:05:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.84 on epoch=162
05/20/2022 11:05:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.71 on epoch=162
05/20/2022 11:05:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.72 on epoch=163
05/20/2022 11:05:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.84 on epoch=164
05/20/2022 11:05:11 - INFO - __main__ - Global step 2300 Train loss 2.78 Classification-F1 0.028737776778689442 on epoch=164
05/20/2022 11:05:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.78 on epoch=164
05/20/2022 11:05:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.65 on epoch=165
05/20/2022 11:05:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.59 on epoch=166
05/20/2022 11:05:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.72 on epoch=167
05/20/2022 11:05:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.76 on epoch=167
05/20/2022 11:05:19 - INFO - __main__ - Global step 2350 Train loss 2.70 Classification-F1 0.026439719397465873 on epoch=167
05/20/2022 11:05:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.71 on epoch=168
05/20/2022 11:05:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.76 on epoch=169
05/20/2022 11:05:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.74 on epoch=169
05/20/2022 11:05:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.73 on epoch=170
05/20/2022 11:05:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.69 on epoch=171
05/20/2022 11:05:27 - INFO - __main__ - Global step 2400 Train loss 2.73 Classification-F1 0.066728321763488 on epoch=171
05/20/2022 11:05:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.83 on epoch=172
05/20/2022 11:05:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.54 on epoch=172
05/20/2022 11:05:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.75 on epoch=173
05/20/2022 11:05:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.76 on epoch=174
05/20/2022 11:05:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.67 on epoch=174
05/20/2022 11:05:35 - INFO - __main__ - Global step 2450 Train loss 2.71 Classification-F1 0.03537794419525866 on epoch=174
05/20/2022 11:05:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.71 on epoch=175
05/20/2022 11:05:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.55 on epoch=176
05/20/2022 11:05:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.75 on epoch=177
05/20/2022 11:05:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.66 on epoch=177
05/20/2022 11:05:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.62 on epoch=178
05/20/2022 11:05:43 - INFO - __main__ - Global step 2500 Train loss 2.66 Classification-F1 0.041590329313543596 on epoch=178
05/20/2022 11:05:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.57 on epoch=179
05/20/2022 11:05:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.51 on epoch=179
05/20/2022 11:05:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.56 on epoch=180
05/20/2022 11:05:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.59 on epoch=181
05/20/2022 11:05:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.60 on epoch=182
05/20/2022 11:05:51 - INFO - __main__ - Global step 2550 Train loss 2.57 Classification-F1 0.04276572208084004 on epoch=182
05/20/2022 11:05:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.55 on epoch=182
05/20/2022 11:05:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.62 on epoch=183
05/20/2022 11:05:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.58 on epoch=184
05/20/2022 11:05:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.68 on epoch=184
05/20/2022 11:05:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.60 on epoch=185
05/20/2022 11:05:59 - INFO - __main__ - Global step 2600 Train loss 2.61 Classification-F1 0.08188048222530982 on epoch=185
05/20/2022 11:06:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.47 on epoch=186
05/20/2022 11:06:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.69 on epoch=187
05/20/2022 11:06:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.61 on epoch=187
05/20/2022 11:06:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.69 on epoch=188
05/20/2022 11:06:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.48 on epoch=189
05/20/2022 11:06:07 - INFO - __main__ - Global step 2650 Train loss 2.59 Classification-F1 0.05094296084743619 on epoch=189
05/20/2022 11:06:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.67 on epoch=189
05/20/2022 11:06:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.46 on epoch=190
05/20/2022 11:06:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.39 on epoch=191
05/20/2022 11:06:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.63 on epoch=192
05/20/2022 11:06:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.46 on epoch=192
05/20/2022 11:06:15 - INFO - __main__ - Global step 2700 Train loss 2.52 Classification-F1 0.022683702280114838 on epoch=192
05/20/2022 11:06:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.67 on epoch=193
05/20/2022 11:06:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.42 on epoch=194
05/20/2022 11:06:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.56 on epoch=194
05/20/2022 11:06:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.48 on epoch=195
05/20/2022 11:06:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.50 on epoch=196
05/20/2022 11:06:23 - INFO - __main__ - Global step 2750 Train loss 2.53 Classification-F1 0.06769773474561605 on epoch=196
05/20/2022 11:06:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.64 on epoch=197
05/20/2022 11:06:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.54 on epoch=197
05/20/2022 11:06:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.48 on epoch=198
05/20/2022 11:06:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.53 on epoch=199
05/20/2022 11:06:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.59 on epoch=199
05/20/2022 11:06:31 - INFO - __main__ - Global step 2800 Train loss 2.56 Classification-F1 0.03835345940609098 on epoch=199
05/20/2022 11:06:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.49 on epoch=200
05/20/2022 11:06:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.42 on epoch=201
05/20/2022 11:06:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.63 on epoch=202
05/20/2022 11:06:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.45 on epoch=202
05/20/2022 11:06:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.43 on epoch=203
05/20/2022 11:06:39 - INFO - __main__ - Global step 2850 Train loss 2.48 Classification-F1 0.08288145257526543 on epoch=203
05/20/2022 11:06:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.39 on epoch=204
05/20/2022 11:06:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.52 on epoch=204
05/20/2022 11:06:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.34 on epoch=205
05/20/2022 11:06:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.37 on epoch=206
05/20/2022 11:06:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.52 on epoch=207
05/20/2022 11:06:47 - INFO - __main__ - Global step 2900 Train loss 2.43 Classification-F1 0.07635537619504891 on epoch=207
05/20/2022 11:06:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.41 on epoch=207
05/20/2022 11:06:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.37 on epoch=208
05/20/2022 11:06:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.36 on epoch=209
05/20/2022 11:06:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.52 on epoch=209
05/20/2022 11:06:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.54 on epoch=210
05/20/2022 11:06:55 - INFO - __main__ - Global step 2950 Train loss 2.44 Classification-F1 0.0671126319004925 on epoch=210
05/20/2022 11:06:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.31 on epoch=211
05/20/2022 11:06:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.39 on epoch=212
05/20/2022 11:06:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.48 on epoch=212
05/20/2022 11:07:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.34 on epoch=213
05/20/2022 11:07:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.31 on epoch=214
05/20/2022 11:07:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:07:03 - INFO - __main__ - Printing 3 examples
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:07:03 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:07:03 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:07:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:07:03 - INFO - __main__ - Printing 3 examples
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:07:03 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:07:03 - INFO - __main__ - Global step 3000 Train loss 2.37 Classification-F1 0.061276374956762365 on epoch=214
05/20/2022 11:07:03 - INFO - __main__ - save last model!
05/20/2022 11:07:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 11:07:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 11:07:03 - INFO - __main__ - Printing 3 examples
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 11:07:03 - INFO - __main__ - ['Animal']
05/20/2022 11:07:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 11:07:03 - INFO - __main__ - ['Village']
05/20/2022 11:07:03 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:07:03 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:07:05 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:07:09 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:07:09 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 11:07:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:07:09 - INFO - __main__ - Starting training!
05/20/2022 11:07:37 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/20/2022 11:07:37 - INFO - __main__ - Classification-F1 on test data: 0.0609
05/20/2022 11:07:38 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.11475159985029049, test_performance=0.060856417022197344
05/20/2022 11:07:38 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/20/2022 11:07:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:07:38 - INFO - __main__ - Printing 3 examples
05/20/2022 11:07:38 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/20/2022 11:07:38 - INFO - __main__ - ['Animal']
05/20/2022 11:07:38 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/20/2022 11:07:38 - INFO - __main__ - ['Animal']
05/20/2022 11:07:38 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/20/2022 11:07:38 - INFO - __main__ - ['Animal']
05/20/2022 11:07:38 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:07:39 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:07:39 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:07:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:07:39 - INFO - __main__ - Printing 3 examples
05/20/2022 11:07:39 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/20/2022 11:07:39 - INFO - __main__ - ['Animal']
05/20/2022 11:07:39 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/20/2022 11:07:39 - INFO - __main__ - ['Animal']
05/20/2022 11:07:39 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/20/2022 11:07:39 - INFO - __main__ - ['Animal']
05/20/2022 11:07:39 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:07:39 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:07:39 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:07:44 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:07:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:07:45 - INFO - __main__ - Starting training!
05/20/2022 11:07:46 - INFO - __main__ - Step 10 Global step 10 Train loss 7.24 on epoch=0
05/20/2022 11:07:48 - INFO - __main__ - Step 20 Global step 20 Train loss 7.52 on epoch=1
05/20/2022 11:07:49 - INFO - __main__ - Step 30 Global step 30 Train loss 7.24 on epoch=2
05/20/2022 11:07:50 - INFO - __main__ - Step 40 Global step 40 Train loss 7.26 on epoch=2
05/20/2022 11:07:51 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/20/2022 11:07:59 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/20/2022 11:07:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 11:08:00 - INFO - __main__ - Step 60 Global step 60 Train loss 7.30 on epoch=4
05/20/2022 11:08:01 - INFO - __main__ - Step 70 Global step 70 Train loss 7.12 on epoch=4
05/20/2022 11:08:03 - INFO - __main__ - Step 80 Global step 80 Train loss 6.84 on epoch=5
05/20/2022 11:08:04 - INFO - __main__ - Step 90 Global step 90 Train loss 7.03 on epoch=6
05/20/2022 11:08:05 - INFO - __main__ - Step 100 Global step 100 Train loss 6.93 on epoch=7
05/20/2022 11:08:15 - INFO - __main__ - Global step 100 Train loss 7.05 Classification-F1 0.0 on epoch=7
05/20/2022 11:08:16 - INFO - __main__ - Step 110 Global step 110 Train loss 6.84 on epoch=7
05/20/2022 11:08:17 - INFO - __main__ - Step 120 Global step 120 Train loss 6.65 on epoch=8
05/20/2022 11:08:19 - INFO - __main__ - Step 130 Global step 130 Train loss 6.90 on epoch=9
05/20/2022 11:08:20 - INFO - __main__ - Step 140 Global step 140 Train loss 6.88 on epoch=9
05/20/2022 11:08:21 - INFO - __main__ - Step 150 Global step 150 Train loss 6.53 on epoch=10
05/20/2022 11:08:37 - INFO - __main__ - Global step 150 Train loss 6.76 Classification-F1 0.0 on epoch=10
05/20/2022 11:08:39 - INFO - __main__ - Step 160 Global step 160 Train loss 6.74 on epoch=11
05/20/2022 11:08:40 - INFO - __main__ - Step 170 Global step 170 Train loss 6.51 on epoch=12
05/20/2022 11:08:41 - INFO - __main__ - Step 180 Global step 180 Train loss 6.50 on epoch=12
05/20/2022 11:08:42 - INFO - __main__ - Step 190 Global step 190 Train loss 6.41 on epoch=13
05/20/2022 11:08:43 - INFO - __main__ - Step 200 Global step 200 Train loss 6.55 on epoch=14
05/20/2022 11:09:21 - INFO - __main__ - Global step 200 Train loss 6.54 Classification-F1 0.0 on epoch=14
05/20/2022 11:09:23 - INFO - __main__ - Step 210 Global step 210 Train loss 6.39 on epoch=14
05/20/2022 11:09:24 - INFO - __main__ - Step 220 Global step 220 Train loss 6.15 on epoch=15
05/20/2022 11:09:25 - INFO - __main__ - Step 230 Global step 230 Train loss 6.46 on epoch=16
05/20/2022 11:09:26 - INFO - __main__ - Step 240 Global step 240 Train loss 6.23 on epoch=17
05/20/2022 11:09:27 - INFO - __main__ - Step 250 Global step 250 Train loss 6.14 on epoch=17
05/20/2022 11:10:19 - INFO - __main__ - Global step 250 Train loss 6.27 Classification-F1 0.0 on epoch=17
05/20/2022 11:10:21 - INFO - __main__ - Step 260 Global step 260 Train loss 5.99 on epoch=18
05/20/2022 11:10:22 - INFO - __main__ - Step 270 Global step 270 Train loss 6.31 on epoch=19
05/20/2022 11:10:23 - INFO - __main__ - Step 280 Global step 280 Train loss 6.14 on epoch=19
05/20/2022 11:10:24 - INFO - __main__ - Step 290 Global step 290 Train loss 5.88 on epoch=20
05/20/2022 11:10:25 - INFO - __main__ - Step 300 Global step 300 Train loss 5.97 on epoch=21
05/20/2022 11:11:17 - INFO - __main__ - Global step 300 Train loss 6.06 Classification-F1 0.0 on epoch=21
05/20/2022 11:11:18 - INFO - __main__ - Step 310 Global step 310 Train loss 6.01 on epoch=22
05/20/2022 11:11:19 - INFO - __main__ - Step 320 Global step 320 Train loss 5.80 on epoch=22
05/20/2022 11:11:21 - INFO - __main__ - Step 330 Global step 330 Train loss 5.82 on epoch=23
05/20/2022 11:11:22 - INFO - __main__ - Step 340 Global step 340 Train loss 5.82 on epoch=24
05/20/2022 11:11:23 - INFO - __main__ - Step 350 Global step 350 Train loss 5.83 on epoch=24
05/20/2022 11:12:10 - INFO - __main__ - Global step 350 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/20/2022 11:12:11 - INFO - __main__ - Step 360 Global step 360 Train loss 5.63 on epoch=25
05/20/2022 11:12:12 - INFO - __main__ - Step 370 Global step 370 Train loss 5.92 on epoch=26
05/20/2022 11:12:13 - INFO - __main__ - Step 380 Global step 380 Train loss 5.72 on epoch=27
05/20/2022 11:12:15 - INFO - __main__ - Step 390 Global step 390 Train loss 5.59 on epoch=27
05/20/2022 11:12:16 - INFO - __main__ - Step 400 Global step 400 Train loss 5.65 on epoch=28
05/20/2022 11:12:39 - INFO - __main__ - Global step 400 Train loss 5.70 Classification-F1 0.0 on epoch=28
05/20/2022 11:12:40 - INFO - __main__ - Step 410 Global step 410 Train loss 5.62 on epoch=29
05/20/2022 11:12:41 - INFO - __main__ - Step 420 Global step 420 Train loss 5.68 on epoch=29
05/20/2022 11:12:43 - INFO - __main__ - Step 430 Global step 430 Train loss 5.45 on epoch=30
05/20/2022 11:12:44 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=31
05/20/2022 11:12:45 - INFO - __main__ - Step 450 Global step 450 Train loss 5.49 on epoch=32
05/20/2022 11:13:14 - INFO - __main__ - Global step 450 Train loss 5.56 Classification-F1 0.0017841213202497768 on epoch=32
05/20/2022 11:13:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0017841213202497768 on epoch=32, global_step=450
05/20/2022 11:13:15 - INFO - __main__ - Step 460 Global step 460 Train loss 5.46 on epoch=32
05/20/2022 11:13:16 - INFO - __main__ - Step 470 Global step 470 Train loss 5.45 on epoch=33
05/20/2022 11:13:18 - INFO - __main__ - Step 480 Global step 480 Train loss 5.56 on epoch=34
05/20/2022 11:13:19 - INFO - __main__ - Step 490 Global step 490 Train loss 5.40 on epoch=34
05/20/2022 11:13:20 - INFO - __main__ - Step 500 Global step 500 Train loss 5.30 on epoch=35
05/20/2022 11:13:26 - INFO - __main__ - Global step 500 Train loss 5.43 Classification-F1 0.009009009009009007 on epoch=35
05/20/2022 11:13:26 - INFO - __main__ - Saving model with best Classification-F1: 0.0017841213202497768 -> 0.009009009009009007 on epoch=35, global_step=500
05/20/2022 11:13:28 - INFO - __main__ - Step 510 Global step 510 Train loss 5.37 on epoch=36
05/20/2022 11:13:29 - INFO - __main__ - Step 520 Global step 520 Train loss 5.29 on epoch=37
05/20/2022 11:13:30 - INFO - __main__ - Step 530 Global step 530 Train loss 5.19 on epoch=37
05/20/2022 11:13:31 - INFO - __main__ - Step 540 Global step 540 Train loss 5.20 on epoch=38
05/20/2022 11:13:32 - INFO - __main__ - Step 550 Global step 550 Train loss 5.36 on epoch=39
05/20/2022 11:13:35 - INFO - __main__ - Global step 550 Train loss 5.28 Classification-F1 0.006511123168746609 on epoch=39
05/20/2022 11:13:36 - INFO - __main__ - Step 560 Global step 560 Train loss 5.41 on epoch=39
05/20/2022 11:13:37 - INFO - __main__ - Step 570 Global step 570 Train loss 5.09 on epoch=40
05/20/2022 11:13:39 - INFO - __main__ - Step 580 Global step 580 Train loss 5.23 on epoch=41
05/20/2022 11:13:40 - INFO - __main__ - Step 590 Global step 590 Train loss 5.24 on epoch=42
05/20/2022 11:13:41 - INFO - __main__ - Step 600 Global step 600 Train loss 5.00 on epoch=42
05/20/2022 11:13:44 - INFO - __main__ - Global step 600 Train loss 5.19 Classification-F1 0.006796941376380628 on epoch=42
05/20/2022 11:13:45 - INFO - __main__ - Step 610 Global step 610 Train loss 5.13 on epoch=43
05/20/2022 11:13:47 - INFO - __main__ - Step 620 Global step 620 Train loss 5.20 on epoch=44
05/20/2022 11:13:48 - INFO - __main__ - Step 630 Global step 630 Train loss 5.08 on epoch=44
05/20/2022 11:13:49 - INFO - __main__ - Step 640 Global step 640 Train loss 4.86 on epoch=45
05/20/2022 11:13:50 - INFO - __main__ - Step 650 Global step 650 Train loss 5.04 on epoch=46
05/20/2022 11:13:53 - INFO - __main__ - Global step 650 Train loss 5.06 Classification-F1 0.008403361344537816 on epoch=46
05/20/2022 11:13:54 - INFO - __main__ - Step 660 Global step 660 Train loss 4.99 on epoch=47
05/20/2022 11:13:55 - INFO - __main__ - Step 670 Global step 670 Train loss 4.98 on epoch=47
05/20/2022 11:13:56 - INFO - __main__ - Step 680 Global step 680 Train loss 4.91 on epoch=48
05/20/2022 11:13:58 - INFO - __main__ - Step 690 Global step 690 Train loss 5.03 on epoch=49
05/20/2022 11:13:59 - INFO - __main__ - Step 700 Global step 700 Train loss 5.04 on epoch=49
05/20/2022 11:14:06 - INFO - __main__ - Global step 700 Train loss 4.99 Classification-F1 0.008733624454148471 on epoch=49
05/20/2022 11:14:08 - INFO - __main__ - Step 710 Global step 710 Train loss 4.70 on epoch=50
05/20/2022 11:14:09 - INFO - __main__ - Step 720 Global step 720 Train loss 4.85 on epoch=51
05/20/2022 11:14:10 - INFO - __main__ - Step 730 Global step 730 Train loss 4.86 on epoch=52
05/20/2022 11:14:11 - INFO - __main__ - Step 740 Global step 740 Train loss 4.85 on epoch=52
05/20/2022 11:14:12 - INFO - __main__ - Step 750 Global step 750 Train loss 4.80 on epoch=53
05/20/2022 11:14:20 - INFO - __main__ - Global step 750 Train loss 4.81 Classification-F1 0.006763285024154588 on epoch=53
05/20/2022 11:14:21 - INFO - __main__ - Step 760 Global step 760 Train loss 4.87 on epoch=54
05/20/2022 11:14:23 - INFO - __main__ - Step 770 Global step 770 Train loss 4.94 on epoch=54
05/20/2022 11:14:24 - INFO - __main__ - Step 780 Global step 780 Train loss 4.58 on epoch=55
05/20/2022 11:14:25 - INFO - __main__ - Step 790 Global step 790 Train loss 4.87 on epoch=56
05/20/2022 11:14:26 - INFO - __main__ - Step 800 Global step 800 Train loss 4.77 on epoch=57
05/20/2022 11:14:29 - INFO - __main__ - Global step 800 Train loss 4.81 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 11:14:29 - INFO - __main__ - Saving model with best Classification-F1: 0.009009009009009007 -> 0.009523809523809523 on epoch=57, global_step=800
05/20/2022 11:14:30 - INFO - __main__ - Step 810 Global step 810 Train loss 4.60 on epoch=57
05/20/2022 11:14:31 - INFO - __main__ - Step 820 Global step 820 Train loss 4.76 on epoch=58
05/20/2022 11:14:32 - INFO - __main__ - Step 830 Global step 830 Train loss 4.73 on epoch=59
05/20/2022 11:14:34 - INFO - __main__ - Step 840 Global step 840 Train loss 4.73 on epoch=59
05/20/2022 11:14:35 - INFO - __main__ - Step 850 Global step 850 Train loss 4.48 on epoch=60
05/20/2022 11:14:37 - INFO - __main__ - Global step 850 Train loss 4.66 Classification-F1 0.009523809523809523 on epoch=60
05/20/2022 11:14:38 - INFO - __main__ - Step 860 Global step 860 Train loss 4.54 on epoch=61
05/20/2022 11:14:40 - INFO - __main__ - Step 870 Global step 870 Train loss 4.67 on epoch=62
05/20/2022 11:14:41 - INFO - __main__ - Step 880 Global step 880 Train loss 4.46 on epoch=62
05/20/2022 11:14:42 - INFO - __main__ - Step 890 Global step 890 Train loss 4.64 on epoch=63
05/20/2022 11:14:43 - INFO - __main__ - Step 900 Global step 900 Train loss 4.63 on epoch=64
05/20/2022 11:14:46 - INFO - __main__ - Global step 900 Train loss 4.59 Classification-F1 0.009523809523809523 on epoch=64
05/20/2022 11:14:47 - INFO - __main__ - Step 910 Global step 910 Train loss 4.55 on epoch=64
05/20/2022 11:14:48 - INFO - __main__ - Step 920 Global step 920 Train loss 4.36 on epoch=65
05/20/2022 11:14:49 - INFO - __main__ - Step 930 Global step 930 Train loss 4.51 on epoch=66
05/20/2022 11:14:51 - INFO - __main__ - Step 940 Global step 940 Train loss 4.65 on epoch=67
05/20/2022 11:14:52 - INFO - __main__ - Step 950 Global step 950 Train loss 4.33 on epoch=67
05/20/2022 11:14:54 - INFO - __main__ - Global step 950 Train loss 4.48 Classification-F1 0.009523809523809523 on epoch=67
05/20/2022 11:14:55 - INFO - __main__ - Step 960 Global step 960 Train loss 4.56 on epoch=68
05/20/2022 11:14:56 - INFO - __main__ - Step 970 Global step 970 Train loss 4.38 on epoch=69
05/20/2022 11:14:58 - INFO - __main__ - Step 980 Global step 980 Train loss 4.55 on epoch=69
05/20/2022 11:14:59 - INFO - __main__ - Step 990 Global step 990 Train loss 4.22 on epoch=70
05/20/2022 11:15:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.29 on epoch=71
05/20/2022 11:15:02 - INFO - __main__ - Global step 1000 Train loss 4.40 Classification-F1 0.009523809523809523 on epoch=71
05/20/2022 11:15:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.34 on epoch=72
05/20/2022 11:15:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.32 on epoch=72
05/20/2022 11:15:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.29 on epoch=73
05/20/2022 11:15:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.33 on epoch=74
05/20/2022 11:15:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.39 on epoch=74
05/20/2022 11:15:10 - INFO - __main__ - Global step 1050 Train loss 4.34 Classification-F1 0.009523809523809523 on epoch=74
05/20/2022 11:15:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.21 on epoch=75
05/20/2022 11:15:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.36 on epoch=76
05/20/2022 11:15:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.34 on epoch=77
05/20/2022 11:15:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.07 on epoch=77
05/20/2022 11:15:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.12 on epoch=78
05/20/2022 11:15:18 - INFO - __main__ - Global step 1100 Train loss 4.22 Classification-F1 0.009523809523809523 on epoch=78
05/20/2022 11:15:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.32 on epoch=79
05/20/2022 11:15:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.42 on epoch=79
05/20/2022 11:15:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.07 on epoch=80
05/20/2022 11:15:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.27 on epoch=81
05/20/2022 11:15:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.37 on epoch=82
05/20/2022 11:15:26 - INFO - __main__ - Global step 1150 Train loss 4.29 Classification-F1 0.009523809523809523 on epoch=82
05/20/2022 11:15:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.05 on epoch=82
05/20/2022 11:15:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.16 on epoch=83
05/20/2022 11:15:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.16 on epoch=84
05/20/2022 11:15:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.15 on epoch=84
05/20/2022 11:15:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.00 on epoch=85
05/20/2022 11:15:34 - INFO - __main__ - Global step 1200 Train loss 4.10 Classification-F1 0.009523809523809523 on epoch=85
05/20/2022 11:15:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.98 on epoch=86
05/20/2022 11:15:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.07 on epoch=87
05/20/2022 11:15:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.87 on epoch=87
05/20/2022 11:15:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.01 on epoch=88
05/20/2022 11:15:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.90 on epoch=89
05/20/2022 11:15:42 - INFO - __main__ - Global step 1250 Train loss 3.96 Classification-F1 0.024250609334642948 on epoch=89
05/20/2022 11:15:42 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024250609334642948 on epoch=89, global_step=1250
05/20/2022 11:15:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.07 on epoch=89
05/20/2022 11:15:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.74 on epoch=90
05/20/2022 11:15:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.82 on epoch=91
05/20/2022 11:15:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.02 on epoch=92
05/20/2022 11:15:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.79 on epoch=92
05/20/2022 11:15:50 - INFO - __main__ - Global step 1300 Train loss 3.89 Classification-F1 0.02283922973578146 on epoch=92
05/20/2022 11:15:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.89 on epoch=93
05/20/2022 11:15:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.80 on epoch=94
05/20/2022 11:15:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.94 on epoch=94
05/20/2022 11:15:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.78 on epoch=95
05/20/2022 11:15:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.69 on epoch=96
05/20/2022 11:15:58 - INFO - __main__ - Global step 1350 Train loss 3.82 Classification-F1 0.02564102564102564 on epoch=96
05/20/2022 11:15:58 - INFO - __main__ - Saving model with best Classification-F1: 0.024250609334642948 -> 0.02564102564102564 on epoch=96, global_step=1350
05/20/2022 11:15:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.90 on epoch=97
05/20/2022 11:16:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.68 on epoch=97
05/20/2022 11:16:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.66 on epoch=98
05/20/2022 11:16:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.63 on epoch=99
05/20/2022 11:16:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.68 on epoch=99
05/20/2022 11:16:06 - INFO - __main__ - Global step 1400 Train loss 3.71 Classification-F1 0.009523809523809523 on epoch=99
05/20/2022 11:16:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.69 on epoch=100
05/20/2022 11:16:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.69 on epoch=101
05/20/2022 11:16:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.77 on epoch=102
05/20/2022 11:16:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.59 on epoch=102
05/20/2022 11:16:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.74 on epoch=103
05/20/2022 11:16:14 - INFO - __main__ - Global step 1450 Train loss 3.70 Classification-F1 0.009603841536614645 on epoch=103
05/20/2022 11:16:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.53 on epoch=104
05/20/2022 11:16:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.70 on epoch=104
05/20/2022 11:16:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.60 on epoch=105
05/20/2022 11:16:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.49 on epoch=106
05/20/2022 11:16:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.72 on epoch=107
05/20/2022 11:16:22 - INFO - __main__ - Global step 1500 Train loss 3.61 Classification-F1 0.056913863278115144 on epoch=107
05/20/2022 11:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.02564102564102564 -> 0.056913863278115144 on epoch=107, global_step=1500
05/20/2022 11:16:23 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.56 on epoch=107
05/20/2022 11:16:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.65 on epoch=108
05/20/2022 11:16:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.54 on epoch=109
05/20/2022 11:16:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.61 on epoch=109
05/20/2022 11:16:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.50 on epoch=110
05/20/2022 11:16:30 - INFO - __main__ - Global step 1550 Train loss 3.57 Classification-F1 0.009523809523809523 on epoch=110
05/20/2022 11:16:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.50 on epoch=111
05/20/2022 11:16:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.73 on epoch=112
05/20/2022 11:16:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.55 on epoch=112
05/20/2022 11:16:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.51 on epoch=113
05/20/2022 11:16:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.54 on epoch=114
05/20/2022 11:16:38 - INFO - __main__ - Global step 1600 Train loss 3.57 Classification-F1 0.009685230024213076 on epoch=114
05/20/2022 11:16:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.52 on epoch=114
05/20/2022 11:16:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.50 on epoch=115
05/20/2022 11:16:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.45 on epoch=116
05/20/2022 11:16:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.55 on epoch=117
05/20/2022 11:16:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.49 on epoch=117
05/20/2022 11:16:46 - INFO - __main__ - Global step 1650 Train loss 3.50 Classification-F1 0.02079365079365079 on epoch=117
05/20/2022 11:16:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.59 on epoch=118
05/20/2022 11:16:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.40 on epoch=119
05/20/2022 11:16:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.35 on epoch=119
05/20/2022 11:16:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.31 on epoch=120
05/20/2022 11:16:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.46 on epoch=121
05/20/2022 11:16:54 - INFO - __main__ - Global step 1700 Train loss 3.42 Classification-F1 0.04756952589464906 on epoch=121
05/20/2022 11:16:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.50 on epoch=122
05/20/2022 11:16:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.18 on epoch=122
05/20/2022 11:16:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.41 on epoch=123
05/20/2022 11:16:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.34 on epoch=124
05/20/2022 11:17:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.47 on epoch=124
05/20/2022 11:17:02 - INFO - __main__ - Global step 1750 Train loss 3.38 Classification-F1 0.031830914183855356 on epoch=124
05/20/2022 11:17:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.32 on epoch=125
05/20/2022 11:17:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.21 on epoch=126
05/20/2022 11:17:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.63 on epoch=127
05/20/2022 11:17:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.17 on epoch=127
05/20/2022 11:17:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.46 on epoch=128
05/20/2022 11:17:10 - INFO - __main__ - Global step 1800 Train loss 3.36 Classification-F1 0.020149832084732627 on epoch=128
05/20/2022 11:17:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.27 on epoch=129
05/20/2022 11:17:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.28 on epoch=129
05/20/2022 11:17:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.13 on epoch=130
05/20/2022 11:17:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.23 on epoch=131
05/20/2022 11:17:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.42 on epoch=132
05/20/2022 11:17:18 - INFO - __main__ - Global step 1850 Train loss 3.26 Classification-F1 0.03038179768949 on epoch=132
05/20/2022 11:17:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.21 on epoch=132
05/20/2022 11:17:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.42 on epoch=133
05/20/2022 11:17:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.19 on epoch=134
05/20/2022 11:17:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.42 on epoch=134
05/20/2022 11:17:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.13 on epoch=135
05/20/2022 11:17:26 - INFO - __main__ - Global step 1900 Train loss 3.27 Classification-F1 0.014436821040594627 on epoch=135
05/20/2022 11:17:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.26 on epoch=136
05/20/2022 11:17:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.26 on epoch=137
05/20/2022 11:17:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.09 on epoch=137
05/20/2022 11:17:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.25 on epoch=138
05/20/2022 11:17:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.25 on epoch=139
05/20/2022 11:17:34 - INFO - __main__ - Global step 1950 Train loss 3.22 Classification-F1 0.04897682914921132 on epoch=139
05/20/2022 11:17:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.23 on epoch=139
05/20/2022 11:17:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.01 on epoch=140
05/20/2022 11:17:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.06 on epoch=141
05/20/2022 11:17:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.30 on epoch=142
05/20/2022 11:17:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.10 on epoch=142
05/20/2022 11:17:42 - INFO - __main__ - Global step 2000 Train loss 3.14 Classification-F1 0.009523809523809523 on epoch=142
05/20/2022 11:17:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.23 on epoch=143
05/20/2022 11:17:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.25 on epoch=144
05/20/2022 11:17:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.18 on epoch=144
05/20/2022 11:17:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.05 on epoch=145
05/20/2022 11:17:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.05 on epoch=146
05/20/2022 11:17:50 - INFO - __main__ - Global step 2050 Train loss 3.15 Classification-F1 0.017456685191238965 on epoch=146
05/20/2022 11:17:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.19 on epoch=147
05/20/2022 11:17:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.03 on epoch=147
05/20/2022 11:17:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.15 on epoch=148
05/20/2022 11:17:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.24 on epoch=149
05/20/2022 11:17:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.17 on epoch=149
05/20/2022 11:17:58 - INFO - __main__ - Global step 2100 Train loss 3.16 Classification-F1 0.009603841536614645 on epoch=149
05/20/2022 11:17:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.06 on epoch=150
05/20/2022 11:18:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.16 on epoch=151
05/20/2022 11:18:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.01 on epoch=152
05/20/2022 11:18:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.25 on epoch=152
05/20/2022 11:18:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.99 on epoch=153
05/20/2022 11:18:06 - INFO - __main__ - Global step 2150 Train loss 3.09 Classification-F1 0.009523809523809523 on epoch=153
05/20/2022 11:18:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.00 on epoch=154
05/20/2022 11:18:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.03 on epoch=154
05/20/2022 11:18:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.02 on epoch=155
05/20/2022 11:18:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.88 on epoch=156
05/20/2022 11:18:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.05 on epoch=157
05/20/2022 11:18:14 - INFO - __main__ - Global step 2200 Train loss 3.00 Classification-F1 0.009563658099222952 on epoch=157
05/20/2022 11:18:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.85 on epoch=157
05/20/2022 11:18:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.02 on epoch=158
05/20/2022 11:18:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.92 on epoch=159
05/20/2022 11:18:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.98 on epoch=159
05/20/2022 11:18:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.84 on epoch=160
05/20/2022 11:18:22 - INFO - __main__ - Global step 2250 Train loss 2.92 Classification-F1 0.035132841015193955 on epoch=160
05/20/2022 11:18:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.86 on epoch=161
05/20/2022 11:18:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.03 on epoch=162
05/20/2022 11:18:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.90 on epoch=162
05/20/2022 11:18:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.95 on epoch=163
05/20/2022 11:18:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.10 on epoch=164
05/20/2022 11:18:30 - INFO - __main__ - Global step 2300 Train loss 2.97 Classification-F1 0.03645958383353341 on epoch=164
05/20/2022 11:18:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.00 on epoch=164
05/20/2022 11:18:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.06 on epoch=165
05/20/2022 11:18:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.79 on epoch=166
05/20/2022 11:18:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.03 on epoch=167
05/20/2022 11:18:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.85 on epoch=167
05/20/2022 11:18:38 - INFO - __main__ - Global step 2350 Train loss 2.95 Classification-F1 0.021386655489082806 on epoch=167
05/20/2022 11:18:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.83 on epoch=168
05/20/2022 11:18:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.95 on epoch=169
05/20/2022 11:18:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.93 on epoch=169
05/20/2022 11:18:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.95 on epoch=170
05/20/2022 11:18:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.76 on epoch=171
05/20/2022 11:18:46 - INFO - __main__ - Global step 2400 Train loss 2.89 Classification-F1 0.03701404249993591 on epoch=171
05/20/2022 11:18:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.07 on epoch=172
05/20/2022 11:18:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.96 on epoch=172
05/20/2022 11:18:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.89 on epoch=173
05/20/2022 11:18:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.80 on epoch=174
05/20/2022 11:18:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.94 on epoch=174
05/20/2022 11:18:54 - INFO - __main__ - Global step 2450 Train loss 2.93 Classification-F1 0.03170590243333451 on epoch=174
05/20/2022 11:18:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.78 on epoch=175
05/20/2022 11:18:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.81 on epoch=176
05/20/2022 11:18:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 3.01 on epoch=177
05/20/2022 11:18:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.83 on epoch=177
05/20/2022 11:19:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.03 on epoch=178
05/20/2022 11:19:02 - INFO - __main__ - Global step 2500 Train loss 2.89 Classification-F1 0.04703336290526692 on epoch=178
05/20/2022 11:19:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.69 on epoch=179
05/20/2022 11:19:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.88 on epoch=179
05/20/2022 11:19:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.64 on epoch=180
05/20/2022 11:19:07 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.80 on epoch=181
05/20/2022 11:19:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.90 on epoch=182
05/20/2022 11:19:10 - INFO - __main__ - Global step 2550 Train loss 2.78 Classification-F1 0.023472527472527475 on epoch=182
05/20/2022 11:19:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.76 on epoch=182
05/20/2022 11:19:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.91 on epoch=183
05/20/2022 11:19:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.58 on epoch=184
05/20/2022 11:19:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.91 on epoch=184
05/20/2022 11:19:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.57 on epoch=185
05/20/2022 11:19:18 - INFO - __main__ - Global step 2600 Train loss 2.75 Classification-F1 0.02255701582552742 on epoch=185
05/20/2022 11:19:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.65 on epoch=186
05/20/2022 11:19:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.88 on epoch=187
05/20/2022 11:19:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.69 on epoch=187
05/20/2022 11:19:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.82 on epoch=188
05/20/2022 11:19:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.67 on epoch=189
05/20/2022 11:19:26 - INFO - __main__ - Global step 2650 Train loss 2.74 Classification-F1 0.028641801548205486 on epoch=189
05/20/2022 11:19:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.74 on epoch=189
05/20/2022 11:19:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.77 on epoch=190
05/20/2022 11:19:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.67 on epoch=191
05/20/2022 11:19:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.90 on epoch=192
05/20/2022 11:19:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.66 on epoch=192
05/20/2022 11:19:34 - INFO - __main__ - Global step 2700 Train loss 2.75 Classification-F1 0.030124594640723673 on epoch=192
05/20/2022 11:19:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.76 on epoch=193
05/20/2022 11:19:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.73 on epoch=194
05/20/2022 11:19:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.61 on epoch=194
05/20/2022 11:19:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.66 on epoch=195
05/20/2022 11:19:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.68 on epoch=196
05/20/2022 11:19:42 - INFO - __main__ - Global step 2750 Train loss 2.69 Classification-F1 0.023376623376623377 on epoch=196
05/20/2022 11:19:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.81 on epoch=197
05/20/2022 11:19:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.81 on epoch=197
05/20/2022 11:19:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.76 on epoch=198
05/20/2022 11:19:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.71 on epoch=199
05/20/2022 11:19:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.72 on epoch=199
05/20/2022 11:19:50 - INFO - __main__ - Global step 2800 Train loss 2.76 Classification-F1 0.05061488009838082 on epoch=199
05/20/2022 11:19:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.62 on epoch=200
05/20/2022 11:19:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.54 on epoch=201
05/20/2022 11:19:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.90 on epoch=202
05/20/2022 11:19:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.68 on epoch=202
05/20/2022 11:19:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.69 on epoch=203
05/20/2022 11:19:58 - INFO - __main__ - Global step 2850 Train loss 2.68 Classification-F1 0.04377715307947866 on epoch=203
05/20/2022 11:19:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.68 on epoch=204
05/20/2022 11:20:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.73 on epoch=204
05/20/2022 11:20:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.71 on epoch=205
05/20/2022 11:20:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.64 on epoch=206
05/20/2022 11:20:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.87 on epoch=207
05/20/2022 11:20:06 - INFO - __main__ - Global step 2900 Train loss 2.73 Classification-F1 0.02614048073551755 on epoch=207
05/20/2022 11:20:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.46 on epoch=207
05/20/2022 11:20:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.52 on epoch=208
05/20/2022 11:20:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.54 on epoch=209
05/20/2022 11:20:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.63 on epoch=209
05/20/2022 11:20:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.49 on epoch=210
05/20/2022 11:20:14 - INFO - __main__ - Global step 2950 Train loss 2.53 Classification-F1 0.03708272511383691 on epoch=210
05/20/2022 11:20:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.56 on epoch=211
05/20/2022 11:20:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.74 on epoch=212
05/20/2022 11:20:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.59 on epoch=212
05/20/2022 11:20:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.59 on epoch=213
05/20/2022 11:20:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.81 on epoch=214
05/20/2022 11:20:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:20:22 - INFO - __main__ - Printing 3 examples
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 11:20:22 - INFO - __main__ - ['Plant']
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 11:20:22 - INFO - __main__ - ['Plant']
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 11:20:22 - INFO - __main__ - ['Plant']
05/20/2022 11:20:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:20:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:20:22 - INFO - __main__ - Global step 3000 Train loss 2.66 Classification-F1 0.01840291559917728 on epoch=214
05/20/2022 11:20:22 - INFO - __main__ - save last model!
05/20/2022 11:20:22 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:20:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:20:22 - INFO - __main__ - Printing 3 examples
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 11:20:22 - INFO - __main__ - ['Plant']
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 11:20:22 - INFO - __main__ - ['Plant']
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 11:20:22 - INFO - __main__ - ['Plant']
05/20/2022 11:20:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:20:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 11:20:22 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 11:20:22 - INFO - __main__ - Printing 3 examples
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 11:20:22 - INFO - __main__ - ['Animal']
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 11:20:22 - INFO - __main__ - ['Animal']
05/20/2022 11:20:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 11:20:22 - INFO - __main__ - ['Village']
05/20/2022 11:20:22 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:20:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:20:22 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:20:24 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:20:27 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 11:20:28 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:20:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:20:29 - INFO - __main__ - Starting training!
05/20/2022 11:20:56 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/20/2022 11:20:56 - INFO - __main__ - Classification-F1 on test data: 0.0300
05/20/2022 11:20:56 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.056913863278115144, test_performance=0.029997895534535614
05/20/2022 11:20:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/20/2022 11:20:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:20:57 - INFO - __main__ - Printing 3 examples
05/20/2022 11:20:57 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 11:20:57 - INFO - __main__ - ['Plant']
05/20/2022 11:20:57 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 11:20:57 - INFO - __main__ - ['Plant']
05/20/2022 11:20:57 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 11:20:57 - INFO - __main__ - ['Plant']
05/20/2022 11:20:57 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:20:57 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:20:58 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:20:58 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:20:58 - INFO - __main__ - Printing 3 examples
05/20/2022 11:20:58 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 11:20:58 - INFO - __main__ - ['Plant']
05/20/2022 11:20:58 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 11:20:58 - INFO - __main__ - ['Plant']
05/20/2022 11:20:58 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 11:20:58 - INFO - __main__ - ['Plant']
05/20/2022 11:20:58 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:20:58 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:20:58 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:21:04 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:21:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:21:04 - INFO - __main__ - Starting training!
05/20/2022 11:21:06 - INFO - __main__ - Step 10 Global step 10 Train loss 7.57 on epoch=0
05/20/2022 11:21:07 - INFO - __main__ - Step 20 Global step 20 Train loss 7.39 on epoch=1
05/20/2022 11:21:08 - INFO - __main__ - Step 30 Global step 30 Train loss 7.35 on epoch=2
05/20/2022 11:21:10 - INFO - __main__ - Step 40 Global step 40 Train loss 7.42 on epoch=2
05/20/2022 11:21:11 - INFO - __main__ - Step 50 Global step 50 Train loss 7.01 on epoch=3
05/20/2022 11:22:11 - INFO - __main__ - Global step 50 Train loss 7.35 Classification-F1 0.0 on epoch=3
05/20/2022 11:22:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 11:22:13 - INFO - __main__ - Step 60 Global step 60 Train loss 6.80 on epoch=4
05/20/2022 11:22:14 - INFO - __main__ - Step 70 Global step 70 Train loss 6.79 on epoch=4
05/20/2022 11:22:15 - INFO - __main__ - Step 80 Global step 80 Train loss 6.74 on epoch=5
05/20/2022 11:22:16 - INFO - __main__ - Step 90 Global step 90 Train loss 6.38 on epoch=6
05/20/2022 11:22:17 - INFO - __main__ - Step 100 Global step 100 Train loss 6.52 on epoch=7
05/20/2022 11:23:19 - INFO - __main__ - Global step 100 Train loss 6.65 Classification-F1 0.0 on epoch=7
05/20/2022 11:23:21 - INFO - __main__ - Step 110 Global step 110 Train loss 6.41 on epoch=7
05/20/2022 11:23:22 - INFO - __main__ - Step 120 Global step 120 Train loss 6.21 on epoch=8
05/20/2022 11:23:23 - INFO - __main__ - Step 130 Global step 130 Train loss 6.10 on epoch=9
05/20/2022 11:23:24 - INFO - __main__ - Step 140 Global step 140 Train loss 5.99 on epoch=9
05/20/2022 11:23:25 - INFO - __main__ - Step 150 Global step 150 Train loss 5.98 on epoch=10
05/20/2022 11:24:09 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/20/2022 11:24:10 - INFO - __main__ - Step 160 Global step 160 Train loss 5.78 on epoch=11
05/20/2022 11:24:11 - INFO - __main__ - Step 170 Global step 170 Train loss 6.06 on epoch=12
05/20/2022 11:24:13 - INFO - __main__ - Step 180 Global step 180 Train loss 5.82 on epoch=12
05/20/2022 11:24:14 - INFO - __main__ - Step 190 Global step 190 Train loss 5.63 on epoch=13
05/20/2022 11:24:15 - INFO - __main__ - Step 200 Global step 200 Train loss 5.61 on epoch=14
05/20/2022 11:24:35 - INFO - __main__ - Global step 200 Train loss 5.78 Classification-F1 0.0027359781121751026 on epoch=14
05/20/2022 11:24:35 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0027359781121751026 on epoch=14, global_step=200
05/20/2022 11:24:36 - INFO - __main__ - Step 210 Global step 210 Train loss 5.62 on epoch=14
05/20/2022 11:24:37 - INFO - __main__ - Step 220 Global step 220 Train loss 5.50 on epoch=15
05/20/2022 11:24:38 - INFO - __main__ - Step 230 Global step 230 Train loss 5.31 on epoch=16
05/20/2022 11:24:39 - INFO - __main__ - Step 240 Global step 240 Train loss 5.31 on epoch=17
05/20/2022 11:24:41 - INFO - __main__ - Step 250 Global step 250 Train loss 5.42 on epoch=17
05/20/2022 11:24:44 - INFO - __main__ - Global step 250 Train loss 5.43 Classification-F1 0.006493506493506495 on epoch=17
05/20/2022 11:24:44 - INFO - __main__ - Saving model with best Classification-F1: 0.0027359781121751026 -> 0.006493506493506495 on epoch=17, global_step=250
05/20/2022 11:24:46 - INFO - __main__ - Step 260 Global step 260 Train loss 5.20 on epoch=18
05/20/2022 11:24:47 - INFO - __main__ - Step 270 Global step 270 Train loss 5.26 on epoch=19
05/20/2022 11:24:48 - INFO - __main__ - Step 280 Global step 280 Train loss 5.14 on epoch=19
05/20/2022 11:24:49 - INFO - __main__ - Step 290 Global step 290 Train loss 5.04 on epoch=20
05/20/2022 11:24:51 - INFO - __main__ - Step 300 Global step 300 Train loss 5.00 on epoch=21
05/20/2022 11:24:54 - INFO - __main__ - Global step 300 Train loss 5.13 Classification-F1 0.00892608089260809 on epoch=21
05/20/2022 11:24:54 - INFO - __main__ - Saving model with best Classification-F1: 0.006493506493506495 -> 0.00892608089260809 on epoch=21, global_step=300
05/20/2022 11:24:55 - INFO - __main__ - Step 310 Global step 310 Train loss 5.13 on epoch=22
05/20/2022 11:24:56 - INFO - __main__ - Step 320 Global step 320 Train loss 5.00 on epoch=22
05/20/2022 11:24:57 - INFO - __main__ - Step 330 Global step 330 Train loss 4.83 on epoch=23
05/20/2022 11:24:59 - INFO - __main__ - Step 340 Global step 340 Train loss 4.81 on epoch=24
05/20/2022 11:25:00 - INFO - __main__ - Step 350 Global step 350 Train loss 4.57 on epoch=24
05/20/2022 11:25:02 - INFO - __main__ - Global step 350 Train loss 4.87 Classification-F1 0.009523809523809523 on epoch=24
05/20/2022 11:25:02 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=24, global_step=350
05/20/2022 11:25:03 - INFO - __main__ - Step 360 Global step 360 Train loss 4.67 on epoch=25
05/20/2022 11:25:05 - INFO - __main__ - Step 370 Global step 370 Train loss 4.46 on epoch=26
05/20/2022 11:25:06 - INFO - __main__ - Step 380 Global step 380 Train loss 4.61 on epoch=27
05/20/2022 11:25:07 - INFO - __main__ - Step 390 Global step 390 Train loss 4.61 on epoch=27
05/20/2022 11:25:08 - INFO - __main__ - Step 400 Global step 400 Train loss 4.69 on epoch=28
05/20/2022 11:25:10 - INFO - __main__ - Global step 400 Train loss 4.61 Classification-F1 0.009523809523809523 on epoch=28
05/20/2022 11:25:11 - INFO - __main__ - Step 410 Global step 410 Train loss 4.39 on epoch=29
05/20/2022 11:25:12 - INFO - __main__ - Step 420 Global step 420 Train loss 4.34 on epoch=29
05/20/2022 11:25:14 - INFO - __main__ - Step 430 Global step 430 Train loss 4.40 on epoch=30
05/20/2022 11:25:15 - INFO - __main__ - Step 440 Global step 440 Train loss 4.35 on epoch=31
05/20/2022 11:25:16 - INFO - __main__ - Step 450 Global step 450 Train loss 4.39 on epoch=32
05/20/2022 11:25:18 - INFO - __main__ - Global step 450 Train loss 4.37 Classification-F1 0.03533285516707069 on epoch=32
05/20/2022 11:25:18 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.03533285516707069 on epoch=32, global_step=450
05/20/2022 11:25:19 - INFO - __main__ - Step 460 Global step 460 Train loss 4.08 on epoch=32
05/20/2022 11:25:20 - INFO - __main__ - Step 470 Global step 470 Train loss 4.19 on epoch=33
05/20/2022 11:25:22 - INFO - __main__ - Step 480 Global step 480 Train loss 4.23 on epoch=34
05/20/2022 11:25:23 - INFO - __main__ - Step 490 Global step 490 Train loss 3.99 on epoch=34
05/20/2022 11:25:24 - INFO - __main__ - Step 500 Global step 500 Train loss 3.89 on epoch=35
05/20/2022 11:25:26 - INFO - __main__ - Global step 500 Train loss 4.08 Classification-F1 0.026969988291503193 on epoch=35
05/20/2022 11:25:27 - INFO - __main__ - Step 510 Global step 510 Train loss 3.93 on epoch=36
05/20/2022 11:25:28 - INFO - __main__ - Step 520 Global step 520 Train loss 4.00 on epoch=37
05/20/2022 11:25:29 - INFO - __main__ - Step 530 Global step 530 Train loss 3.81 on epoch=37
05/20/2022 11:25:31 - INFO - __main__ - Step 540 Global step 540 Train loss 3.95 on epoch=38
05/20/2022 11:25:32 - INFO - __main__ - Step 550 Global step 550 Train loss 3.69 on epoch=39
05/20/2022 11:25:34 - INFO - __main__ - Global step 550 Train loss 3.88 Classification-F1 0.01935875608681676 on epoch=39
05/20/2022 11:25:35 - INFO - __main__ - Step 560 Global step 560 Train loss 3.71 on epoch=39
05/20/2022 11:25:36 - INFO - __main__ - Step 570 Global step 570 Train loss 3.68 on epoch=40
05/20/2022 11:25:37 - INFO - __main__ - Step 580 Global step 580 Train loss 3.63 on epoch=41
05/20/2022 11:25:39 - INFO - __main__ - Step 590 Global step 590 Train loss 3.78 on epoch=42
05/20/2022 11:25:40 - INFO - __main__ - Step 600 Global step 600 Train loss 3.49 on epoch=42
05/20/2022 11:25:42 - INFO - __main__ - Global step 600 Train loss 3.66 Classification-F1 0.027561317052249977 on epoch=42
05/20/2022 11:25:43 - INFO - __main__ - Step 610 Global step 610 Train loss 3.62 on epoch=43
05/20/2022 11:25:44 - INFO - __main__ - Step 620 Global step 620 Train loss 3.63 on epoch=44
05/20/2022 11:25:45 - INFO - __main__ - Step 630 Global step 630 Train loss 3.50 on epoch=44
05/20/2022 11:25:47 - INFO - __main__ - Step 640 Global step 640 Train loss 3.47 on epoch=45
05/20/2022 11:25:48 - INFO - __main__ - Step 650 Global step 650 Train loss 3.53 on epoch=46
05/20/2022 11:25:50 - INFO - __main__ - Global step 650 Train loss 3.55 Classification-F1 0.020625885742164812 on epoch=46
05/20/2022 11:25:51 - INFO - __main__ - Step 660 Global step 660 Train loss 3.56 on epoch=47
05/20/2022 11:25:52 - INFO - __main__ - Step 670 Global step 670 Train loss 3.34 on epoch=47
05/20/2022 11:25:53 - INFO - __main__ - Step 680 Global step 680 Train loss 3.50 on epoch=48
05/20/2022 11:25:54 - INFO - __main__ - Step 690 Global step 690 Train loss 3.35 on epoch=49
05/20/2022 11:25:56 - INFO - __main__ - Step 700 Global step 700 Train loss 3.40 on epoch=49
05/20/2022 11:25:57 - INFO - __main__ - Global step 700 Train loss 3.43 Classification-F1 0.07079211716892876 on epoch=49
05/20/2022 11:25:57 - INFO - __main__ - Saving model with best Classification-F1: 0.03533285516707069 -> 0.07079211716892876 on epoch=49, global_step=700
05/20/2022 11:25:59 - INFO - __main__ - Step 710 Global step 710 Train loss 3.31 on epoch=50
05/20/2022 11:26:00 - INFO - __main__ - Step 720 Global step 720 Train loss 3.38 on epoch=51
05/20/2022 11:26:01 - INFO - __main__ - Step 730 Global step 730 Train loss 3.40 on epoch=52
05/20/2022 11:26:02 - INFO - __main__ - Step 740 Global step 740 Train loss 3.13 on epoch=52
05/20/2022 11:26:04 - INFO - __main__ - Step 750 Global step 750 Train loss 3.33 on epoch=53
05/20/2022 11:26:05 - INFO - __main__ - Global step 750 Train loss 3.31 Classification-F1 0.051475778947435526 on epoch=53
05/20/2022 11:26:07 - INFO - __main__ - Step 760 Global step 760 Train loss 3.29 on epoch=54
05/20/2022 11:26:08 - INFO - __main__ - Step 770 Global step 770 Train loss 3.17 on epoch=54
05/20/2022 11:26:09 - INFO - __main__ - Step 780 Global step 780 Train loss 3.23 on epoch=55
05/20/2022 11:26:10 - INFO - __main__ - Step 790 Global step 790 Train loss 3.34 on epoch=56
05/20/2022 11:26:12 - INFO - __main__ - Step 800 Global step 800 Train loss 3.25 on epoch=57
05/20/2022 11:26:13 - INFO - __main__ - Global step 800 Train loss 3.26 Classification-F1 0.032079459002535934 on epoch=57
05/20/2022 11:26:15 - INFO - __main__ - Step 810 Global step 810 Train loss 3.08 on epoch=57
05/20/2022 11:26:16 - INFO - __main__ - Step 820 Global step 820 Train loss 3.21 on epoch=58
05/20/2022 11:26:17 - INFO - __main__ - Step 830 Global step 830 Train loss 3.18 on epoch=59
05/20/2022 11:26:18 - INFO - __main__ - Step 840 Global step 840 Train loss 3.23 on epoch=59
05/20/2022 11:26:19 - INFO - __main__ - Step 850 Global step 850 Train loss 3.07 on epoch=60
05/20/2022 11:26:21 - INFO - __main__ - Global step 850 Train loss 3.15 Classification-F1 0.04134848202644813 on epoch=60
05/20/2022 11:26:23 - INFO - __main__ - Step 860 Global step 860 Train loss 3.17 on epoch=61
05/20/2022 11:26:24 - INFO - __main__ - Step 870 Global step 870 Train loss 3.26 on epoch=62
05/20/2022 11:26:25 - INFO - __main__ - Step 880 Global step 880 Train loss 2.92 on epoch=62
05/20/2022 11:26:26 - INFO - __main__ - Step 890 Global step 890 Train loss 3.12 on epoch=63
05/20/2022 11:26:27 - INFO - __main__ - Step 900 Global step 900 Train loss 3.10 on epoch=64
05/20/2022 11:26:29 - INFO - __main__ - Global step 900 Train loss 3.11 Classification-F1 0.029592629592629597 on epoch=64
05/20/2022 11:26:30 - INFO - __main__ - Step 910 Global step 910 Train loss 3.02 on epoch=64
05/20/2022 11:26:32 - INFO - __main__ - Step 920 Global step 920 Train loss 3.03 on epoch=65
05/20/2022 11:26:33 - INFO - __main__ - Step 930 Global step 930 Train loss 3.19 on epoch=66
05/20/2022 11:26:34 - INFO - __main__ - Step 940 Global step 940 Train loss 3.01 on epoch=67
05/20/2022 11:26:35 - INFO - __main__ - Step 950 Global step 950 Train loss 3.02 on epoch=67
05/20/2022 11:26:37 - INFO - __main__ - Global step 950 Train loss 3.05 Classification-F1 0.05177824467358462 on epoch=67
05/20/2022 11:26:38 - INFO - __main__ - Step 960 Global step 960 Train loss 3.10 on epoch=68
05/20/2022 11:26:40 - INFO - __main__ - Step 970 Global step 970 Train loss 2.93 on epoch=69
05/20/2022 11:26:41 - INFO - __main__ - Step 980 Global step 980 Train loss 2.98 on epoch=69
05/20/2022 11:26:42 - INFO - __main__ - Step 990 Global step 990 Train loss 2.92 on epoch=70
05/20/2022 11:26:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.02 on epoch=71
05/20/2022 11:26:45 - INFO - __main__ - Global step 1000 Train loss 2.99 Classification-F1 0.046340774654445714 on epoch=71
05/20/2022 11:26:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.11 on epoch=72
05/20/2022 11:26:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.89 on epoch=72
05/20/2022 11:26:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.02 on epoch=73
05/20/2022 11:26:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.01 on epoch=74
05/20/2022 11:26:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.95 on epoch=74
05/20/2022 11:26:53 - INFO - __main__ - Global step 1050 Train loss 3.00 Classification-F1 0.04162431256027315 on epoch=74
05/20/2022 11:26:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.79 on epoch=75
05/20/2022 11:26:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.04 on epoch=76
05/20/2022 11:26:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.95 on epoch=77
05/20/2022 11:26:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.68 on epoch=77
05/20/2022 11:26:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.77 on epoch=78
05/20/2022 11:27:01 - INFO - __main__ - Global step 1100 Train loss 2.85 Classification-F1 0.02476678251326139 on epoch=78
05/20/2022 11:27:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.94 on epoch=79
05/20/2022 11:27:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.84 on epoch=79
05/20/2022 11:27:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.65 on epoch=80
05/20/2022 11:27:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.00 on epoch=81
05/20/2022 11:27:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.91 on epoch=82
05/20/2022 11:27:09 - INFO - __main__ - Global step 1150 Train loss 2.87 Classification-F1 0.03142285566782211 on epoch=82
05/20/2022 11:27:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.74 on epoch=82
05/20/2022 11:27:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.90 on epoch=83
05/20/2022 11:27:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.73 on epoch=84
05/20/2022 11:27:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.89 on epoch=84
05/20/2022 11:27:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.72 on epoch=85
05/20/2022 11:27:17 - INFO - __main__ - Global step 1200 Train loss 2.80 Classification-F1 0.04982771652722391 on epoch=85
05/20/2022 11:27:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.77 on epoch=86
05/20/2022 11:27:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.89 on epoch=87
05/20/2022 11:27:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.78 on epoch=87
05/20/2022 11:27:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.87 on epoch=88
05/20/2022 11:27:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.67 on epoch=89
05/20/2022 11:27:25 - INFO - __main__ - Global step 1250 Train loss 2.80 Classification-F1 0.04095367420839119 on epoch=89
05/20/2022 11:27:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.83 on epoch=89
05/20/2022 11:27:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.62 on epoch=90
05/20/2022 11:27:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.79 on epoch=91
05/20/2022 11:27:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.76 on epoch=92
05/20/2022 11:27:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.59 on epoch=92
05/20/2022 11:27:33 - INFO - __main__ - Global step 1300 Train loss 2.72 Classification-F1 0.04871858668883503 on epoch=92
05/20/2022 11:27:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.69 on epoch=93
05/20/2022 11:27:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.71 on epoch=94
05/20/2022 11:27:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.62 on epoch=94
05/20/2022 11:27:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.55 on epoch=95
05/20/2022 11:27:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.89 on epoch=96
05/20/2022 11:27:40 - INFO - __main__ - Global step 1350 Train loss 2.69 Classification-F1 0.044776292583310125 on epoch=96
05/20/2022 11:27:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.63 on epoch=97
05/20/2022 11:27:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.69 on epoch=97
05/20/2022 11:27:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.57 on epoch=98
05/20/2022 11:27:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.51 on epoch=99
05/20/2022 11:27:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.55 on epoch=99
05/20/2022 11:27:48 - INFO - __main__ - Global step 1400 Train loss 2.59 Classification-F1 0.043598641305520665 on epoch=99
05/20/2022 11:27:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.34 on epoch=100
05/20/2022 11:27:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.71 on epoch=101
05/20/2022 11:27:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.55 on epoch=102
05/20/2022 11:27:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.41 on epoch=102
05/20/2022 11:27:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.56 on epoch=103
05/20/2022 11:27:56 - INFO - __main__ - Global step 1450 Train loss 2.51 Classification-F1 0.055157706978596434 on epoch=103
05/20/2022 11:27:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.55 on epoch=104
05/20/2022 11:27:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.57 on epoch=104
05/20/2022 11:28:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.45 on epoch=105
05/20/2022 11:28:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.54 on epoch=106
05/20/2022 11:28:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.46 on epoch=107
05/20/2022 11:28:04 - INFO - __main__ - Global step 1500 Train loss 2.51 Classification-F1 0.04579863376285171 on epoch=107
05/20/2022 11:28:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.39 on epoch=107
05/20/2022 11:28:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.54 on epoch=108
05/20/2022 11:28:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.57 on epoch=109
05/20/2022 11:28:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.37 on epoch=109
05/20/2022 11:28:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.42 on epoch=110
05/20/2022 11:28:12 - INFO - __main__ - Global step 1550 Train loss 2.46 Classification-F1 0.08420627340464937 on epoch=110
05/20/2022 11:28:12 - INFO - __main__ - Saving model with best Classification-F1: 0.07079211716892876 -> 0.08420627340464937 on epoch=110, global_step=1550
05/20/2022 11:28:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.57 on epoch=111
05/20/2022 11:28:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.63 on epoch=112
05/20/2022 11:28:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.33 on epoch=112
05/20/2022 11:28:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.58 on epoch=113
05/20/2022 11:28:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.52 on epoch=114
05/20/2022 11:28:20 - INFO - __main__ - Global step 1600 Train loss 2.53 Classification-F1 0.08191283506409557 on epoch=114
05/20/2022 11:28:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.47 on epoch=114
05/20/2022 11:28:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=115
05/20/2022 11:28:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.57 on epoch=116
05/20/2022 11:28:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.39 on epoch=117
05/20/2022 11:28:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.50 on epoch=117
05/20/2022 11:28:28 - INFO - __main__ - Global step 1650 Train loss 2.44 Classification-F1 0.04409073623802994 on epoch=117
05/20/2022 11:28:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.45 on epoch=118
05/20/2022 11:28:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.42 on epoch=119
05/20/2022 11:28:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.37 on epoch=119
05/20/2022 11:28:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.39 on epoch=120
05/20/2022 11:28:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.51 on epoch=121
05/20/2022 11:28:36 - INFO - __main__ - Global step 1700 Train loss 2.43 Classification-F1 0.09792532397574416 on epoch=121
05/20/2022 11:28:36 - INFO - __main__ - Saving model with best Classification-F1: 0.08420627340464937 -> 0.09792532397574416 on epoch=121, global_step=1700
05/20/2022 11:28:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.45 on epoch=122
05/20/2022 11:28:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.33 on epoch=122
05/20/2022 11:28:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.44 on epoch=123
05/20/2022 11:28:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.38 on epoch=124
05/20/2022 11:28:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.19 on epoch=124
05/20/2022 11:28:44 - INFO - __main__ - Global step 1750 Train loss 2.36 Classification-F1 0.051051999747267325 on epoch=124
05/20/2022 11:28:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.16 on epoch=125
05/20/2022 11:28:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.55 on epoch=126
05/20/2022 11:28:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.48 on epoch=127
05/20/2022 11:28:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.19 on epoch=127
05/20/2022 11:28:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.30 on epoch=128
05/20/2022 11:28:52 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.07094516594516594 on epoch=128
05/20/2022 11:28:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.32 on epoch=129
05/20/2022 11:28:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.40 on epoch=129
05/20/2022 11:28:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.29 on epoch=130
05/20/2022 11:28:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.41 on epoch=131
05/20/2022 11:28:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.31 on epoch=132
05/20/2022 11:29:00 - INFO - __main__ - Global step 1850 Train loss 2.35 Classification-F1 0.06932476694381455 on epoch=132
05/20/2022 11:29:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.19 on epoch=132
05/20/2022 11:29:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.37 on epoch=133
05/20/2022 11:29:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.32 on epoch=134
05/20/2022 11:29:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.37 on epoch=134
05/20/2022 11:29:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.26 on epoch=135
05/20/2022 11:29:08 - INFO - __main__ - Global step 1900 Train loss 2.30 Classification-F1 0.042841462619943635 on epoch=135
05/20/2022 11:29:09 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.33 on epoch=136
05/20/2022 11:29:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.30 on epoch=137
05/20/2022 11:29:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.14 on epoch=137
05/20/2022 11:29:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.28 on epoch=138
05/20/2022 11:29:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.36 on epoch=139
05/20/2022 11:29:16 - INFO - __main__ - Global step 1950 Train loss 2.28 Classification-F1 0.08516601421100457 on epoch=139
05/20/2022 11:29:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.27 on epoch=139
05/20/2022 11:29:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.04 on epoch=140
05/20/2022 11:29:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.22 on epoch=141
05/20/2022 11:29:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.20 on epoch=142
05/20/2022 11:29:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.12 on epoch=142
05/20/2022 11:29:24 - INFO - __main__ - Global step 2000 Train loss 2.17 Classification-F1 0.039463635382002725 on epoch=142
05/20/2022 11:29:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.20 on epoch=143
05/20/2022 11:29:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.34 on epoch=144
05/20/2022 11:29:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.10 on epoch=144
05/20/2022 11:29:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.17 on epoch=145
05/20/2022 11:29:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.15 on epoch=146
05/20/2022 11:29:32 - INFO - __main__ - Global step 2050 Train loss 2.19 Classification-F1 0.05369386108950537 on epoch=146
05/20/2022 11:29:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.30 on epoch=147
05/20/2022 11:29:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.24 on epoch=147
05/20/2022 11:29:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.22 on epoch=148
05/20/2022 11:29:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.34 on epoch=149
05/20/2022 11:29:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.16 on epoch=149
05/20/2022 11:29:40 - INFO - __main__ - Global step 2100 Train loss 2.25 Classification-F1 0.02848831840428479 on epoch=149
05/20/2022 11:29:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.16 on epoch=150
05/20/2022 11:29:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.33 on epoch=151
05/20/2022 11:29:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.07 on epoch=152
05/20/2022 11:29:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.17 on epoch=152
05/20/2022 11:29:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.14 on epoch=153
05/20/2022 11:29:48 - INFO - __main__ - Global step 2150 Train loss 2.17 Classification-F1 0.06874547612950507 on epoch=153
05/20/2022 11:29:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.23 on epoch=154
05/20/2022 11:29:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.22 on epoch=154
05/20/2022 11:29:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.18 on epoch=155
05/20/2022 11:29:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.07 on epoch=156
05/20/2022 11:29:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.19 on epoch=157
05/20/2022 11:29:57 - INFO - __main__ - Global step 2200 Train loss 2.18 Classification-F1 0.03404810199942045 on epoch=157
05/20/2022 11:29:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.12 on epoch=157
05/20/2022 11:29:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.20 on epoch=158
05/20/2022 11:30:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.11 on epoch=159
05/20/2022 11:30:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.02 on epoch=159
05/20/2022 11:30:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.12 on epoch=160
05/20/2022 11:30:05 - INFO - __main__ - Global step 2250 Train loss 2.11 Classification-F1 0.08554525990012071 on epoch=160
05/20/2022 11:30:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.12 on epoch=161
05/20/2022 11:30:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.18 on epoch=162
05/20/2022 11:30:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.17 on epoch=162
05/20/2022 11:30:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.99 on epoch=163
05/20/2022 11:30:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.26 on epoch=164
05/20/2022 11:30:14 - INFO - __main__ - Global step 2300 Train loss 2.14 Classification-F1 0.07306821053428718 on epoch=164
05/20/2022 11:30:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.11 on epoch=164
05/20/2022 11:30:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.16 on epoch=165
05/20/2022 11:30:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.19 on epoch=166
05/20/2022 11:30:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.10 on epoch=167
05/20/2022 11:30:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.13 on epoch=167
05/20/2022 11:30:22 - INFO - __main__ - Global step 2350 Train loss 2.14 Classification-F1 0.08106761401291554 on epoch=167
05/20/2022 11:30:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.12 on epoch=168
05/20/2022 11:30:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.20 on epoch=169
05/20/2022 11:30:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.19 on epoch=169
05/20/2022 11:30:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.16 on epoch=170
05/20/2022 11:30:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.99 on epoch=171
05/20/2022 11:30:31 - INFO - __main__ - Global step 2400 Train loss 2.13 Classification-F1 0.1279972743356626 on epoch=171
05/20/2022 11:30:31 - INFO - __main__ - Saving model with best Classification-F1: 0.09792532397574416 -> 0.1279972743356626 on epoch=171, global_step=2400
05/20/2022 11:30:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.12 on epoch=172
05/20/2022 11:30:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.11 on epoch=172
05/20/2022 11:30:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.10 on epoch=173
05/20/2022 11:30:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.12 on epoch=174
05/20/2022 11:30:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.12 on epoch=174
05/20/2022 11:30:39 - INFO - __main__ - Global step 2450 Train loss 2.11 Classification-F1 0.08636073050262648 on epoch=174
05/20/2022 11:30:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.08 on epoch=175
05/20/2022 11:30:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.00 on epoch=176
05/20/2022 11:30:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.09 on epoch=177
05/20/2022 11:30:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.04 on epoch=177
05/20/2022 11:30:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.04 on epoch=178
05/20/2022 11:30:48 - INFO - __main__ - Global step 2500 Train loss 2.05 Classification-F1 0.08215098154857191 on epoch=178
05/20/2022 11:30:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.03 on epoch=179
05/20/2022 11:30:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.01 on epoch=179
05/20/2022 11:30:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.97 on epoch=180
05/20/2022 11:30:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.00 on epoch=181
05/20/2022 11:30:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.19 on epoch=182
05/20/2022 11:30:57 - INFO - __main__ - Global step 2550 Train loss 2.04 Classification-F1 0.0767401832527883 on epoch=182
05/20/2022 11:30:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.17 on epoch=182
05/20/2022 11:30:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.00 on epoch=183
05/20/2022 11:31:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.18 on epoch=184
05/20/2022 11:31:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.04 on epoch=184
05/20/2022 11:31:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.06 on epoch=185
05/20/2022 11:31:05 - INFO - __main__ - Global step 2600 Train loss 2.09 Classification-F1 0.11065121574539484 on epoch=185
05/20/2022 11:31:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.10 on epoch=186
05/20/2022 11:31:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.15 on epoch=187
05/20/2022 11:31:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.01 on epoch=187
05/20/2022 11:31:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.99 on epoch=188
05/20/2022 11:31:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.01 on epoch=189
05/20/2022 11:31:14 - INFO - __main__ - Global step 2650 Train loss 2.05 Classification-F1 0.12183472710166829 on epoch=189
05/20/2022 11:31:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.06 on epoch=189
05/20/2022 11:31:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.91 on epoch=190
05/20/2022 11:31:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.14 on epoch=191
05/20/2022 11:31:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.99 on epoch=192
05/20/2022 11:31:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.87 on epoch=192
05/20/2022 11:31:22 - INFO - __main__ - Global step 2700 Train loss 1.99 Classification-F1 0.06381159092780327 on epoch=192
05/20/2022 11:31:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.88 on epoch=193
05/20/2022 11:31:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.14 on epoch=194
05/20/2022 11:31:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.93 on epoch=194
05/20/2022 11:31:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.91 on epoch=195
05/20/2022 11:31:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.02 on epoch=196
05/20/2022 11:31:31 - INFO - __main__ - Global step 2750 Train loss 1.98 Classification-F1 0.09709732377799606 on epoch=196
05/20/2022 11:31:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.89 on epoch=197
05/20/2022 11:31:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.95 on epoch=197
05/20/2022 11:31:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.01 on epoch=198
05/20/2022 11:31:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.95 on epoch=199
05/20/2022 11:31:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.89 on epoch=199
05/20/2022 11:31:39 - INFO - __main__ - Global step 2800 Train loss 1.94 Classification-F1 0.032428955188632834 on epoch=199
05/20/2022 11:31:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.93 on epoch=200
05/20/2022 11:31:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.88 on epoch=201
05/20/2022 11:31:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.17 on epoch=202
05/20/2022 11:31:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.97 on epoch=202
05/20/2022 11:31:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.18 on epoch=203
05/20/2022 11:31:48 - INFO - __main__ - Global step 2850 Train loss 2.03 Classification-F1 0.06377555283497695 on epoch=203
05/20/2022 11:31:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.04 on epoch=204
05/20/2022 11:31:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.76 on epoch=204
05/20/2022 11:31:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.95 on epoch=205
05/20/2022 11:31:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.90 on epoch=206
05/20/2022 11:31:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.93 on epoch=207
05/20/2022 11:31:57 - INFO - __main__ - Global step 2900 Train loss 1.91 Classification-F1 0.1095378255541595 on epoch=207
05/20/2022 11:31:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.92 on epoch=207
05/20/2022 11:32:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.91 on epoch=208
05/20/2022 11:32:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.88 on epoch=209
05/20/2022 11:32:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.84 on epoch=209
05/20/2022 11:32:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.80 on epoch=210
05/20/2022 11:32:06 - INFO - __main__ - Global step 2950 Train loss 1.87 Classification-F1 0.14703579757647153 on epoch=210
05/20/2022 11:32:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1279972743356626 -> 0.14703579757647153 on epoch=210, global_step=2950
05/20/2022 11:32:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.94 on epoch=211
05/20/2022 11:32:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.74 on epoch=212
05/20/2022 11:32:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.85 on epoch=212
05/20/2022 11:32:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.82 on epoch=213
05/20/2022 11:32:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.97 on epoch=214
05/20/2022 11:32:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:32:13 - INFO - __main__ - Printing 3 examples
05/20/2022 11:32:13 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 11:32:13 - INFO - __main__ - ['Plant']
05/20/2022 11:32:13 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 11:32:13 - INFO - __main__ - ['Plant']
05/20/2022 11:32:13 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 11:32:13 - INFO - __main__ - ['Plant']
05/20/2022 11:32:13 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:32:13 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:32:14 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:32:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:32:14 - INFO - __main__ - Printing 3 examples
05/20/2022 11:32:14 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 11:32:14 - INFO - __main__ - ['Plant']
05/20/2022 11:32:14 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 11:32:14 - INFO - __main__ - ['Plant']
05/20/2022 11:32:14 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 11:32:14 - INFO - __main__ - ['Plant']
05/20/2022 11:32:14 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:32:14 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:32:14 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:32:15 - INFO - __main__ - Global step 3000 Train loss 1.86 Classification-F1 0.1746100375231241 on epoch=214
05/20/2022 11:32:15 - INFO - __main__ - Saving model with best Classification-F1: 0.14703579757647153 -> 0.1746100375231241 on epoch=214, global_step=3000
05/20/2022 11:32:15 - INFO - __main__ - save last model!
05/20/2022 11:32:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 11:32:15 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 11:32:15 - INFO - __main__ - Printing 3 examples
05/20/2022 11:32:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 11:32:15 - INFO - __main__ - ['Animal']
05/20/2022 11:32:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 11:32:15 - INFO - __main__ - ['Animal']
05/20/2022 11:32:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 11:32:15 - INFO - __main__ - ['Village']
05/20/2022 11:32:15 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:32:16 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:32:19 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:32:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:32:19 - INFO - __main__ - Starting training!
05/20/2022 11:32:20 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 11:33:06 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/20/2022 11:33:06 - INFO - __main__ - Classification-F1 on test data: 0.1394
05/20/2022 11:33:06 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.1746100375231241, test_performance=0.1394210518472774
05/20/2022 11:33:06 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/20/2022 11:33:07 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:33:07 - INFO - __main__ - Printing 3 examples
05/20/2022 11:33:07 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 11:33:07 - INFO - __main__ - ['Plant']
05/20/2022 11:33:07 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 11:33:07 - INFO - __main__ - ['Plant']
05/20/2022 11:33:07 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 11:33:07 - INFO - __main__ - ['Plant']
05/20/2022 11:33:07 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:33:07 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:33:08 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:33:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:33:08 - INFO - __main__ - Printing 3 examples
05/20/2022 11:33:08 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 11:33:08 - INFO - __main__ - ['Plant']
05/20/2022 11:33:08 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 11:33:08 - INFO - __main__ - ['Plant']
05/20/2022 11:33:08 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 11:33:08 - INFO - __main__ - ['Plant']
05/20/2022 11:33:08 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:33:08 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:33:08 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:33:13 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:33:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:33:13 - INFO - __main__ - Starting training!
05/20/2022 11:33:15 - INFO - __main__ - Step 10 Global step 10 Train loss 7.78 on epoch=0
05/20/2022 11:33:16 - INFO - __main__ - Step 20 Global step 20 Train loss 7.39 on epoch=1
05/20/2022 11:33:17 - INFO - __main__ - Step 30 Global step 30 Train loss 7.39 on epoch=2
05/20/2022 11:33:18 - INFO - __main__ - Step 40 Global step 40 Train loss 7.36 on epoch=2
05/20/2022 11:33:20 - INFO - __main__ - Step 50 Global step 50 Train loss 7.05 on epoch=3
05/20/2022 11:33:40 - INFO - __main__ - Global step 50 Train loss 7.39 Classification-F1 0.0 on epoch=3
05/20/2022 11:33:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 11:33:42 - INFO - __main__ - Step 60 Global step 60 Train loss 6.89 on epoch=4
05/20/2022 11:33:43 - INFO - __main__ - Step 70 Global step 70 Train loss 6.72 on epoch=4
05/20/2022 11:33:44 - INFO - __main__ - Step 80 Global step 80 Train loss 6.76 on epoch=5
05/20/2022 11:33:45 - INFO - __main__ - Step 90 Global step 90 Train loss 6.58 on epoch=6
05/20/2022 11:33:46 - INFO - __main__ - Step 100 Global step 100 Train loss 6.77 on epoch=7
05/20/2022 11:34:47 - INFO - __main__ - Global step 100 Train loss 6.74 Classification-F1 0.0 on epoch=7
05/20/2022 11:34:49 - INFO - __main__ - Step 110 Global step 110 Train loss 6.59 on epoch=7
05/20/2022 11:34:50 - INFO - __main__ - Step 120 Global step 120 Train loss 6.38 on epoch=8
05/20/2022 11:34:51 - INFO - __main__ - Step 130 Global step 130 Train loss 6.48 on epoch=9
05/20/2022 11:34:52 - INFO - __main__ - Step 140 Global step 140 Train loss 6.15 on epoch=9
05/20/2022 11:34:53 - INFO - __main__ - Step 150 Global step 150 Train loss 6.16 on epoch=10
05/20/2022 11:35:41 - INFO - __main__ - Global step 150 Train loss 6.35 Classification-F1 0.0 on epoch=10
05/20/2022 11:35:42 - INFO - __main__ - Step 160 Global step 160 Train loss 6.02 on epoch=11
05/20/2022 11:35:44 - INFO - __main__ - Step 170 Global step 170 Train loss 6.21 on epoch=12
05/20/2022 11:35:45 - INFO - __main__ - Step 180 Global step 180 Train loss 6.09 on epoch=12
05/20/2022 11:35:46 - INFO - __main__ - Step 190 Global step 190 Train loss 5.96 on epoch=13
05/20/2022 11:35:48 - INFO - __main__ - Step 200 Global step 200 Train loss 5.87 on epoch=14
05/20/2022 11:37:00 - INFO - __main__ - Global step 200 Train loss 6.03 Classification-F1 0.0 on epoch=14
05/20/2022 11:37:01 - INFO - __main__ - Step 210 Global step 210 Train loss 5.92 on epoch=14
05/20/2022 11:37:03 - INFO - __main__ - Step 220 Global step 220 Train loss 5.88 on epoch=15
05/20/2022 11:37:04 - INFO - __main__ - Step 230 Global step 230 Train loss 5.65 on epoch=16
05/20/2022 11:37:05 - INFO - __main__ - Step 240 Global step 240 Train loss 5.83 on epoch=17
05/20/2022 11:37:06 - INFO - __main__ - Step 250 Global step 250 Train loss 5.82 on epoch=17
05/20/2022 11:37:59 - INFO - __main__ - Global step 250 Train loss 5.82 Classification-F1 0.0 on epoch=17
05/20/2022 11:38:00 - INFO - __main__ - Step 260 Global step 260 Train loss 5.72 on epoch=18
05/20/2022 11:38:01 - INFO - __main__ - Step 270 Global step 270 Train loss 5.64 on epoch=19
05/20/2022 11:38:03 - INFO - __main__ - Step 280 Global step 280 Train loss 5.60 on epoch=19
05/20/2022 11:38:04 - INFO - __main__ - Step 290 Global step 290 Train loss 5.65 on epoch=20
05/20/2022 11:38:05 - INFO - __main__ - Step 300 Global step 300 Train loss 5.44 on epoch=21
05/20/2022 11:38:24 - INFO - __main__ - Global step 300 Train loss 5.61 Classification-F1 0.001670843776106934 on epoch=21
05/20/2022 11:38:24 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.001670843776106934 on epoch=21, global_step=300
05/20/2022 11:38:26 - INFO - __main__ - Step 310 Global step 310 Train loss 5.40 on epoch=22
05/20/2022 11:38:27 - INFO - __main__ - Step 320 Global step 320 Train loss 5.33 on epoch=22
05/20/2022 11:38:28 - INFO - __main__ - Step 330 Global step 330 Train loss 5.28 on epoch=23
05/20/2022 11:38:29 - INFO - __main__ - Step 340 Global step 340 Train loss 5.20 on epoch=24
05/20/2022 11:38:31 - INFO - __main__ - Step 350 Global step 350 Train loss 5.01 on epoch=24
05/20/2022 11:38:34 - INFO - __main__ - Global step 350 Train loss 5.24 Classification-F1 0.006211180124223603 on epoch=24
05/20/2022 11:38:34 - INFO - __main__ - Saving model with best Classification-F1: 0.001670843776106934 -> 0.006211180124223603 on epoch=24, global_step=350
05/20/2022 11:38:35 - INFO - __main__ - Step 360 Global step 360 Train loss 5.03 on epoch=25
05/20/2022 11:38:37 - INFO - __main__ - Step 370 Global step 370 Train loss 4.90 on epoch=26
05/20/2022 11:38:38 - INFO - __main__ - Step 380 Global step 380 Train loss 5.11 on epoch=27
05/20/2022 11:38:39 - INFO - __main__ - Step 390 Global step 390 Train loss 5.03 on epoch=27
05/20/2022 11:38:40 - INFO - __main__ - Step 400 Global step 400 Train loss 4.84 on epoch=28
05/20/2022 11:38:43 - INFO - __main__ - Global step 400 Train loss 4.98 Classification-F1 0.009523809523809523 on epoch=28
05/20/2022 11:38:43 - INFO - __main__ - Saving model with best Classification-F1: 0.006211180124223603 -> 0.009523809523809523 on epoch=28, global_step=400
05/20/2022 11:38:44 - INFO - __main__ - Step 410 Global step 410 Train loss 4.97 on epoch=29
05/20/2022 11:38:45 - INFO - __main__ - Step 420 Global step 420 Train loss 4.91 on epoch=29
05/20/2022 11:38:47 - INFO - __main__ - Step 430 Global step 430 Train loss 4.85 on epoch=30
05/20/2022 11:38:48 - INFO - __main__ - Step 440 Global step 440 Train loss 4.63 on epoch=31
05/20/2022 11:38:49 - INFO - __main__ - Step 450 Global step 450 Train loss 4.77 on epoch=32
05/20/2022 11:38:51 - INFO - __main__ - Global step 450 Train loss 4.83 Classification-F1 0.009523809523809523 on epoch=32
05/20/2022 11:38:53 - INFO - __main__ - Step 460 Global step 460 Train loss 4.83 on epoch=32
05/20/2022 11:38:54 - INFO - __main__ - Step 470 Global step 470 Train loss 4.56 on epoch=33
05/20/2022 11:38:55 - INFO - __main__ - Step 480 Global step 480 Train loss 4.49 on epoch=34
05/20/2022 11:38:56 - INFO - __main__ - Step 490 Global step 490 Train loss 4.41 on epoch=34
05/20/2022 11:38:58 - INFO - __main__ - Step 500 Global step 500 Train loss 4.37 on epoch=35
05/20/2022 11:39:00 - INFO - __main__ - Global step 500 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=35
05/20/2022 11:39:01 - INFO - __main__ - Step 510 Global step 510 Train loss 4.23 on epoch=36
05/20/2022 11:39:02 - INFO - __main__ - Step 520 Global step 520 Train loss 4.44 on epoch=37
05/20/2022 11:39:03 - INFO - __main__ - Step 530 Global step 530 Train loss 4.23 on epoch=37
05/20/2022 11:39:05 - INFO - __main__ - Step 540 Global step 540 Train loss 4.16 on epoch=38
05/20/2022 11:39:06 - INFO - __main__ - Step 550 Global step 550 Train loss 4.06 on epoch=39
05/20/2022 11:39:08 - INFO - __main__ - Global step 550 Train loss 4.22 Classification-F1 0.0200271395816761 on epoch=39
05/20/2022 11:39:08 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.0200271395816761 on epoch=39, global_step=550
05/20/2022 11:39:09 - INFO - __main__ - Step 560 Global step 560 Train loss 3.96 on epoch=39
05/20/2022 11:39:10 - INFO - __main__ - Step 570 Global step 570 Train loss 3.89 on epoch=40
05/20/2022 11:39:12 - INFO - __main__ - Step 580 Global step 580 Train loss 3.95 on epoch=41
05/20/2022 11:39:13 - INFO - __main__ - Step 590 Global step 590 Train loss 3.90 on epoch=42
05/20/2022 11:39:14 - INFO - __main__ - Step 600 Global step 600 Train loss 3.78 on epoch=42
05/20/2022 11:39:16 - INFO - __main__ - Global step 600 Train loss 3.90 Classification-F1 0.023094829698603287 on epoch=42
05/20/2022 11:39:16 - INFO - __main__ - Saving model with best Classification-F1: 0.0200271395816761 -> 0.023094829698603287 on epoch=42, global_step=600
05/20/2022 11:39:17 - INFO - __main__ - Step 610 Global step 610 Train loss 3.91 on epoch=43
05/20/2022 11:39:18 - INFO - __main__ - Step 620 Global step 620 Train loss 3.59 on epoch=44
05/20/2022 11:39:20 - INFO - __main__ - Step 630 Global step 630 Train loss 3.67 on epoch=44
05/20/2022 11:39:21 - INFO - __main__ - Step 640 Global step 640 Train loss 3.72 on epoch=45
05/20/2022 11:39:22 - INFO - __main__ - Step 650 Global step 650 Train loss 3.62 on epoch=46
05/20/2022 11:39:24 - INFO - __main__ - Global step 650 Train loss 3.70 Classification-F1 0.026227058329052446 on epoch=46
05/20/2022 11:39:24 - INFO - __main__ - Saving model with best Classification-F1: 0.023094829698603287 -> 0.026227058329052446 on epoch=46, global_step=650
05/20/2022 11:39:25 - INFO - __main__ - Step 660 Global step 660 Train loss 3.69 on epoch=47
05/20/2022 11:39:27 - INFO - __main__ - Step 670 Global step 670 Train loss 3.32 on epoch=47
05/20/2022 11:39:28 - INFO - __main__ - Step 680 Global step 680 Train loss 3.62 on epoch=48
05/20/2022 11:39:29 - INFO - __main__ - Step 690 Global step 690 Train loss 3.45 on epoch=49
05/20/2022 11:39:31 - INFO - __main__ - Step 700 Global step 700 Train loss 3.58 on epoch=49
05/20/2022 11:39:32 - INFO - __main__ - Global step 700 Train loss 3.53 Classification-F1 0.03942182933779572 on epoch=49
05/20/2022 11:39:32 - INFO - __main__ - Saving model with best Classification-F1: 0.026227058329052446 -> 0.03942182933779572 on epoch=49, global_step=700
05/20/2022 11:39:34 - INFO - __main__ - Step 710 Global step 710 Train loss 3.25 on epoch=50
05/20/2022 11:39:35 - INFO - __main__ - Step 720 Global step 720 Train loss 3.36 on epoch=51
05/20/2022 11:39:36 - INFO - __main__ - Step 730 Global step 730 Train loss 3.44 on epoch=52
05/20/2022 11:39:37 - INFO - __main__ - Step 740 Global step 740 Train loss 3.26 on epoch=52
05/20/2022 11:39:39 - INFO - __main__ - Step 750 Global step 750 Train loss 3.36 on epoch=53
05/20/2022 11:39:41 - INFO - __main__ - Global step 750 Train loss 3.33 Classification-F1 0.04128577441655533 on epoch=53
05/20/2022 11:39:41 - INFO - __main__ - Saving model with best Classification-F1: 0.03942182933779572 -> 0.04128577441655533 on epoch=53, global_step=750
05/20/2022 11:39:42 - INFO - __main__ - Step 760 Global step 760 Train loss 3.07 on epoch=54
05/20/2022 11:39:43 - INFO - __main__ - Step 770 Global step 770 Train loss 3.12 on epoch=54
05/20/2022 11:39:44 - INFO - __main__ - Step 780 Global step 780 Train loss 3.26 on epoch=55
05/20/2022 11:39:46 - INFO - __main__ - Step 790 Global step 790 Train loss 3.23 on epoch=56
05/20/2022 11:39:47 - INFO - __main__ - Step 800 Global step 800 Train loss 3.20 on epoch=57
05/20/2022 11:39:49 - INFO - __main__ - Global step 800 Train loss 3.18 Classification-F1 0.04330958948816501 on epoch=57
05/20/2022 11:39:49 - INFO - __main__ - Saving model with best Classification-F1: 0.04128577441655533 -> 0.04330958948816501 on epoch=57, global_step=800
05/20/2022 11:39:50 - INFO - __main__ - Step 810 Global step 810 Train loss 3.15 on epoch=57
05/20/2022 11:39:51 - INFO - __main__ - Step 820 Global step 820 Train loss 3.13 on epoch=58
05/20/2022 11:39:53 - INFO - __main__ - Step 830 Global step 830 Train loss 3.08 on epoch=59
05/20/2022 11:39:54 - INFO - __main__ - Step 840 Global step 840 Train loss 3.02 on epoch=59
05/20/2022 11:39:55 - INFO - __main__ - Step 850 Global step 850 Train loss 2.89 on epoch=60
05/20/2022 11:39:57 - INFO - __main__ - Global step 850 Train loss 3.06 Classification-F1 0.025749621205767736 on epoch=60
05/20/2022 11:39:58 - INFO - __main__ - Step 860 Global step 860 Train loss 3.19 on epoch=61
05/20/2022 11:39:59 - INFO - __main__ - Step 870 Global step 870 Train loss 3.20 on epoch=62
05/20/2022 11:40:01 - INFO - __main__ - Step 880 Global step 880 Train loss 2.77 on epoch=62
05/20/2022 11:40:02 - INFO - __main__ - Step 890 Global step 890 Train loss 2.92 on epoch=63
05/20/2022 11:40:03 - INFO - __main__ - Step 900 Global step 900 Train loss 2.99 on epoch=64
05/20/2022 11:40:05 - INFO - __main__ - Global step 900 Train loss 3.01 Classification-F1 0.030619195381172224 on epoch=64
05/20/2022 11:40:06 - INFO - __main__ - Step 910 Global step 910 Train loss 2.95 on epoch=64
05/20/2022 11:40:08 - INFO - __main__ - Step 920 Global step 920 Train loss 2.80 on epoch=65
05/20/2022 11:40:09 - INFO - __main__ - Step 930 Global step 930 Train loss 2.95 on epoch=66
05/20/2022 11:40:10 - INFO - __main__ - Step 940 Global step 940 Train loss 2.91 on epoch=67
05/20/2022 11:40:11 - INFO - __main__ - Step 950 Global step 950 Train loss 2.97 on epoch=67
05/20/2022 11:40:13 - INFO - __main__ - Global step 950 Train loss 2.91 Classification-F1 0.009523809523809523 on epoch=67
05/20/2022 11:40:15 - INFO - __main__ - Step 960 Global step 960 Train loss 3.03 on epoch=68
05/20/2022 11:40:16 - INFO - __main__ - Step 970 Global step 970 Train loss 2.95 on epoch=69
05/20/2022 11:40:17 - INFO - __main__ - Step 980 Global step 980 Train loss 2.86 on epoch=69
05/20/2022 11:40:18 - INFO - __main__ - Step 990 Global step 990 Train loss 2.64 on epoch=70
05/20/2022 11:40:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.98 on epoch=71
05/20/2022 11:40:21 - INFO - __main__ - Global step 1000 Train loss 2.89 Classification-F1 0.04597201523431032 on epoch=71
05/20/2022 11:40:21 - INFO - __main__ - Saving model with best Classification-F1: 0.04330958948816501 -> 0.04597201523431032 on epoch=71, global_step=1000
05/20/2022 11:40:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.05 on epoch=72
05/20/2022 11:40:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.94 on epoch=72
05/20/2022 11:40:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.97 on epoch=73
05/20/2022 11:40:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.79 on epoch=74
05/20/2022 11:40:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.74 on epoch=74
05/20/2022 11:40:30 - INFO - __main__ - Global step 1050 Train loss 2.90 Classification-F1 0.030529383470559942 on epoch=74
05/20/2022 11:40:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.54 on epoch=75
05/20/2022 11:40:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.83 on epoch=76
05/20/2022 11:40:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.93 on epoch=77
05/20/2022 11:40:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.87 on epoch=77
05/20/2022 11:40:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.69 on epoch=78
05/20/2022 11:40:38 - INFO - __main__ - Global step 1100 Train loss 2.77 Classification-F1 0.042616774594823985 on epoch=78
05/20/2022 11:40:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.87 on epoch=79
05/20/2022 11:40:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.73 on epoch=79
05/20/2022 11:40:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=80
05/20/2022 11:40:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.77 on epoch=81
05/20/2022 11:40:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.71 on epoch=82
05/20/2022 11:40:46 - INFO - __main__ - Global step 1150 Train loss 2.72 Classification-F1 0.009603841536614645 on epoch=82
05/20/2022 11:40:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.47 on epoch=82
05/20/2022 11:40:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=83
05/20/2022 11:40:50 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.77 on epoch=84
05/20/2022 11:40:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.78 on epoch=84
05/20/2022 11:40:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.63 on epoch=85
05/20/2022 11:40:54 - INFO - __main__ - Global step 1200 Train loss 2.68 Classification-F1 0.01684981684981685 on epoch=85
05/20/2022 11:40:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.80 on epoch=86
05/20/2022 11:40:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.67 on epoch=87
05/20/2022 11:40:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.51 on epoch=87
05/20/2022 11:40:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.68 on epoch=88
05/20/2022 11:41:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.71 on epoch=89
05/20/2022 11:41:02 - INFO - __main__ - Global step 1250 Train loss 2.67 Classification-F1 0.04071046005002686 on epoch=89
05/20/2022 11:41:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.52 on epoch=89
05/20/2022 11:41:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.37 on epoch=90
05/20/2022 11:41:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.63 on epoch=91
05/20/2022 11:41:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.60 on epoch=92
05/20/2022 11:41:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.68 on epoch=92
05/20/2022 11:41:11 - INFO - __main__ - Global step 1300 Train loss 2.56 Classification-F1 0.03548410668615272 on epoch=92
05/20/2022 11:41:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.67 on epoch=93
05/20/2022 11:41:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.46 on epoch=94
05/20/2022 11:41:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.65 on epoch=94
05/20/2022 11:41:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.41 on epoch=95
05/20/2022 11:41:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.72 on epoch=96
05/20/2022 11:41:20 - INFO - __main__ - Global step 1350 Train loss 2.58 Classification-F1 0.01859857243389967 on epoch=96
05/20/2022 11:41:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.52 on epoch=97
05/20/2022 11:41:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.36 on epoch=97
05/20/2022 11:41:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.51 on epoch=98
05/20/2022 11:41:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.64 on epoch=99
05/20/2022 11:41:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.49 on epoch=99
05/20/2022 11:41:29 - INFO - __main__ - Global step 1400 Train loss 2.51 Classification-F1 0.017540349473122583 on epoch=99
05/20/2022 11:41:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.36 on epoch=100
05/20/2022 11:41:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.61 on epoch=101
05/20/2022 11:41:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.43 on epoch=102
05/20/2022 11:41:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.46 on epoch=102
05/20/2022 11:41:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.51 on epoch=103
05/20/2022 11:41:38 - INFO - __main__ - Global step 1450 Train loss 2.47 Classification-F1 0.009981285090455396 on epoch=103
05/20/2022 11:41:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.57 on epoch=104
05/20/2022 11:41:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.39 on epoch=104
05/20/2022 11:41:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.39 on epoch=105
05/20/2022 11:41:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.52 on epoch=106
05/20/2022 11:41:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.50 on epoch=107
05/20/2022 11:41:47 - INFO - __main__ - Global step 1500 Train loss 2.47 Classification-F1 0.009563658099222952 on epoch=107
05/20/2022 11:41:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.37 on epoch=107
05/20/2022 11:41:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.46 on epoch=108
05/20/2022 11:41:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.46 on epoch=109
05/20/2022 11:41:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.44 on epoch=109
05/20/2022 11:41:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.31 on epoch=110
05/20/2022 11:41:55 - INFO - __main__ - Global step 1550 Train loss 2.41 Classification-F1 0.00976800976800977 on epoch=110
05/20/2022 11:41:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.71 on epoch=111
05/20/2022 11:41:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.45 on epoch=112
05/20/2022 11:41:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.38 on epoch=112
05/20/2022 11:42:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.44 on epoch=113
05/20/2022 11:42:01 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.46 on epoch=114
05/20/2022 11:42:03 - INFO - __main__ - Global step 1600 Train loss 2.49 Classification-F1 0.02539843523616343 on epoch=114
05/20/2022 11:42:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.39 on epoch=114
05/20/2022 11:42:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=115
05/20/2022 11:42:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.54 on epoch=116
05/20/2022 11:42:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.46 on epoch=117
05/20/2022 11:42:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.42 on epoch=117
05/20/2022 11:42:11 - INFO - __main__ - Global step 1650 Train loss 2.42 Classification-F1 0.03448045885020675 on epoch=117
05/20/2022 11:42:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.38 on epoch=118
05/20/2022 11:42:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.40 on epoch=119
05/20/2022 11:42:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.36 on epoch=119
05/20/2022 11:42:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.26 on epoch=120
05/20/2022 11:42:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.43 on epoch=121
05/20/2022 11:42:19 - INFO - __main__ - Global step 1700 Train loss 2.37 Classification-F1 0.03299880671908943 on epoch=121
05/20/2022 11:42:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.34 on epoch=122
05/20/2022 11:42:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.42 on epoch=122
05/20/2022 11:42:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.38 on epoch=123
05/20/2022 11:42:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.33 on epoch=124
05/20/2022 11:42:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.44 on epoch=124
05/20/2022 11:42:27 - INFO - __main__ - Global step 1750 Train loss 2.38 Classification-F1 0.009644364074743823 on epoch=124
05/20/2022 11:42:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.19 on epoch=125
05/20/2022 11:42:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.38 on epoch=126
05/20/2022 11:42:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.32 on epoch=127
05/20/2022 11:42:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.35 on epoch=127
05/20/2022 11:42:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.41 on epoch=128
05/20/2022 11:42:35 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.009563658099222952 on epoch=128
05/20/2022 11:42:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.53 on epoch=129
05/20/2022 11:42:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.26 on epoch=129
05/20/2022 11:42:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.29 on epoch=130
05/20/2022 11:42:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.44 on epoch=131
05/20/2022 11:42:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.28 on epoch=132
05/20/2022 11:42:43 - INFO - __main__ - Global step 1850 Train loss 2.36 Classification-F1 0.01821329390125149 on epoch=132
05/20/2022 11:42:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.24 on epoch=132
05/20/2022 11:42:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.30 on epoch=133
05/20/2022 11:42:47 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.20 on epoch=134
05/20/2022 11:42:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.31 on epoch=134
05/20/2022 11:42:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.17 on epoch=135
05/20/2022 11:42:51 - INFO - __main__ - Global step 1900 Train loss 2.24 Classification-F1 0.0173015873015873 on epoch=135
05/20/2022 11:42:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.34 on epoch=136
05/20/2022 11:42:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.45 on epoch=137
05/20/2022 11:42:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.17 on epoch=137
05/20/2022 11:42:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.26 on epoch=138
05/20/2022 11:42:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.28 on epoch=139
05/20/2022 11:42:59 - INFO - __main__ - Global step 1950 Train loss 2.30 Classification-F1 0.03815945890551342 on epoch=139
05/20/2022 11:43:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.24 on epoch=139
05/20/2022 11:43:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.12 on epoch=140
05/20/2022 11:43:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.34 on epoch=141
05/20/2022 11:43:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.19 on epoch=142
05/20/2022 11:43:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.11 on epoch=142
05/20/2022 11:43:07 - INFO - __main__ - Global step 2000 Train loss 2.20 Classification-F1 0.03237537026533056 on epoch=142
05/20/2022 11:43:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.27 on epoch=143
05/20/2022 11:43:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.30 on epoch=144
05/20/2022 11:43:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.21 on epoch=144
05/20/2022 11:43:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.16 on epoch=145
05/20/2022 11:43:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.23 on epoch=146
05/20/2022 11:43:15 - INFO - __main__ - Global step 2050 Train loss 2.23 Classification-F1 0.031266119501413614 on epoch=146
05/20/2022 11:43:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.09 on epoch=147
05/20/2022 11:43:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.17 on epoch=147
05/20/2022 11:43:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.14 on epoch=148
05/20/2022 11:43:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.17 on epoch=149
05/20/2022 11:43:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.28 on epoch=149
05/20/2022 11:43:24 - INFO - __main__ - Global step 2100 Train loss 2.17 Classification-F1 0.047908962382646594 on epoch=149
05/20/2022 11:43:24 - INFO - __main__ - Saving model with best Classification-F1: 0.04597201523431032 -> 0.047908962382646594 on epoch=149, global_step=2100
05/20/2022 11:43:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.12 on epoch=150
05/20/2022 11:43:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.21 on epoch=151
05/20/2022 11:43:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.16 on epoch=152
05/20/2022 11:43:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.13 on epoch=152
05/20/2022 11:43:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.14 on epoch=153
05/20/2022 11:43:32 - INFO - __main__ - Global step 2150 Train loss 2.15 Classification-F1 0.040203935408440264 on epoch=153
05/20/2022 11:43:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.17 on epoch=154
05/20/2022 11:43:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.14 on epoch=154
05/20/2022 11:43:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.07 on epoch=155
05/20/2022 11:43:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.20 on epoch=156
05/20/2022 11:43:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.19 on epoch=157
05/20/2022 11:43:40 - INFO - __main__ - Global step 2200 Train loss 2.15 Classification-F1 0.04658091524450971 on epoch=157
05/20/2022 11:43:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.11 on epoch=157
05/20/2022 11:43:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.13 on epoch=158
05/20/2022 11:43:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.35 on epoch=159
05/20/2022 11:43:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.09 on epoch=159
05/20/2022 11:43:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.99 on epoch=160
05/20/2022 11:43:48 - INFO - __main__ - Global step 2250 Train loss 2.13 Classification-F1 0.03142928223640453 on epoch=160
05/20/2022 11:43:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.15 on epoch=161
05/20/2022 11:43:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.13 on epoch=162
05/20/2022 11:43:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.94 on epoch=162
05/20/2022 11:43:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.16 on epoch=163
05/20/2022 11:43:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.10 on epoch=164
05/20/2022 11:43:56 - INFO - __main__ - Global step 2300 Train loss 2.10 Classification-F1 0.02653453274246962 on epoch=164
05/20/2022 11:43:58 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.95 on epoch=164
05/20/2022 11:43:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.14 on epoch=165
05/20/2022 11:44:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.14 on epoch=166
05/20/2022 11:44:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.97 on epoch=167
05/20/2022 11:44:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.98 on epoch=167
05/20/2022 11:44:04 - INFO - __main__ - Global step 2350 Train loss 2.03 Classification-F1 0.02191401320321181 on epoch=167
05/20/2022 11:44:06 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.04 on epoch=168
05/20/2022 11:44:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.17 on epoch=169
05/20/2022 11:44:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.05 on epoch=169
05/20/2022 11:44:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.94 on epoch=170
05/20/2022 11:44:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.14 on epoch=171
05/20/2022 11:44:12 - INFO - __main__ - Global step 2400 Train loss 2.07 Classification-F1 0.06162667804206133 on epoch=171
05/20/2022 11:44:12 - INFO - __main__ - Saving model with best Classification-F1: 0.047908962382646594 -> 0.06162667804206133 on epoch=171, global_step=2400
05/20/2022 11:44:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.08 on epoch=172
05/20/2022 11:44:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.06 on epoch=172
05/20/2022 11:44:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.03 on epoch=173
05/20/2022 11:44:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.25 on epoch=174
05/20/2022 11:44:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.04 on epoch=174
05/20/2022 11:44:20 - INFO - __main__ - Global step 2450 Train loss 2.09 Classification-F1 0.06436763743985287 on epoch=174
05/20/2022 11:44:20 - INFO - __main__ - Saving model with best Classification-F1: 0.06162667804206133 -> 0.06436763743985287 on epoch=174, global_step=2450
05/20/2022 11:44:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.00 on epoch=175
05/20/2022 11:44:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.16 on epoch=176
05/20/2022 11:44:24 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.08 on epoch=177
05/20/2022 11:44:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.10 on epoch=177
05/20/2022 11:44:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.06 on epoch=178
05/20/2022 11:44:28 - INFO - __main__ - Global step 2500 Train loss 2.08 Classification-F1 0.03567792771041884 on epoch=178
05/20/2022 11:44:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.07 on epoch=179
05/20/2022 11:44:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.03 on epoch=179
05/20/2022 11:44:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.98 on epoch=180
05/20/2022 11:44:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.07 on epoch=181
05/20/2022 11:44:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.02 on epoch=182
05/20/2022 11:44:37 - INFO - __main__ - Global step 2550 Train loss 2.03 Classification-F1 0.06633062282805793 on epoch=182
05/20/2022 11:44:37 - INFO - __main__ - Saving model with best Classification-F1: 0.06436763743985287 -> 0.06633062282805793 on epoch=182, global_step=2550
05/20/2022 11:44:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.96 on epoch=182
05/20/2022 11:44:39 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.10 on epoch=183
05/20/2022 11:44:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.07 on epoch=184
05/20/2022 11:44:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.88 on epoch=184
05/20/2022 11:44:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.89 on epoch=185
05/20/2022 11:44:45 - INFO - __main__ - Global step 2600 Train loss 1.98 Classification-F1 0.05829225322812231 on epoch=185
05/20/2022 11:44:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.04 on epoch=186
05/20/2022 11:44:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.06 on epoch=187
05/20/2022 11:44:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.01 on epoch=187
05/20/2022 11:44:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.91 on epoch=188
05/20/2022 11:44:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.95 on epoch=189
05/20/2022 11:44:53 - INFO - __main__ - Global step 2650 Train loss 1.99 Classification-F1 0.05541127650661119 on epoch=189
05/20/2022 11:44:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.04 on epoch=189
05/20/2022 11:44:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.94 on epoch=190
05/20/2022 11:44:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.77 on epoch=191
05/20/2022 11:44:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.97 on epoch=192
05/20/2022 11:44:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.04 on epoch=192
05/20/2022 11:45:01 - INFO - __main__ - Global step 2700 Train loss 1.95 Classification-F1 0.05029732751317736 on epoch=192
05/20/2022 11:45:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.92 on epoch=193
05/20/2022 11:45:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.04 on epoch=194
05/20/2022 11:45:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.01 on epoch=194
05/20/2022 11:45:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.81 on epoch=195
05/20/2022 11:45:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.97 on epoch=196
05/20/2022 11:45:09 - INFO - __main__ - Global step 2750 Train loss 1.95 Classification-F1 0.06288139392173114 on epoch=196
05/20/2022 11:45:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.90 on epoch=197
05/20/2022 11:45:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.83 on epoch=197
05/20/2022 11:45:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.89 on epoch=198
05/20/2022 11:45:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.89 on epoch=199
05/20/2022 11:45:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.88 on epoch=199
05/20/2022 11:45:17 - INFO - __main__ - Global step 2800 Train loss 1.88 Classification-F1 0.06757184355223571 on epoch=199
05/20/2022 11:45:17 - INFO - __main__ - Saving model with best Classification-F1: 0.06633062282805793 -> 0.06757184355223571 on epoch=199, global_step=2800
05/20/2022 11:45:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.95 on epoch=200
05/20/2022 11:45:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.94 on epoch=201
05/20/2022 11:45:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.98 on epoch=202
05/20/2022 11:45:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.81 on epoch=202
05/20/2022 11:45:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.82 on epoch=203
05/20/2022 11:45:25 - INFO - __main__ - Global step 2850 Train loss 1.90 Classification-F1 0.08760807839209815 on epoch=203
05/20/2022 11:45:25 - INFO - __main__ - Saving model with best Classification-F1: 0.06757184355223571 -> 0.08760807839209815 on epoch=203, global_step=2850
05/20/2022 11:45:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.87 on epoch=204
05/20/2022 11:45:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.96 on epoch=204
05/20/2022 11:45:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.81 on epoch=205
05/20/2022 11:45:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.86 on epoch=206
05/20/2022 11:45:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.80 on epoch=207
05/20/2022 11:45:33 - INFO - __main__ - Global step 2900 Train loss 1.86 Classification-F1 0.09128023537141387 on epoch=207
05/20/2022 11:45:33 - INFO - __main__ - Saving model with best Classification-F1: 0.08760807839209815 -> 0.09128023537141387 on epoch=207, global_step=2900
05/20/2022 11:45:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.81 on epoch=207
05/20/2022 11:45:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.80 on epoch=208
05/20/2022 11:45:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.82 on epoch=209
05/20/2022 11:45:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.84 on epoch=209
05/20/2022 11:45:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.77 on epoch=210
05/20/2022 11:45:41 - INFO - __main__ - Global step 2950 Train loss 1.81 Classification-F1 0.07217303302729187 on epoch=210
05/20/2022 11:45:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.91 on epoch=211
05/20/2022 11:45:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.99 on epoch=212
05/20/2022 11:45:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.92 on epoch=212
05/20/2022 11:45:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.74 on epoch=213
05/20/2022 11:45:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.80 on epoch=214
05/20/2022 11:45:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:45:49 - INFO - __main__ - Printing 3 examples
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 11:45:49 - INFO - __main__ - ['Plant']
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 11:45:49 - INFO - __main__ - ['Plant']
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 11:45:49 - INFO - __main__ - ['Plant']
05/20/2022 11:45:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:45:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:45:49 - INFO - __main__ - Global step 3000 Train loss 1.87 Classification-F1 0.04565594353683502 on epoch=214
05/20/2022 11:45:49 - INFO - __main__ - save last model!
05/20/2022 11:45:49 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:45:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:45:49 - INFO - __main__ - Printing 3 examples
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 11:45:49 - INFO - __main__ - ['Plant']
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 11:45:49 - INFO - __main__ - ['Plant']
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 11:45:49 - INFO - __main__ - ['Plant']
05/20/2022 11:45:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:45:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 11:45:49 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 11:45:49 - INFO - __main__ - Printing 3 examples
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 11:45:49 - INFO - __main__ - ['Animal']
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 11:45:49 - INFO - __main__ - ['Animal']
05/20/2022 11:45:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 11:45:49 - INFO - __main__ - ['Village']
05/20/2022 11:45:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:45:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:45:50 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:45:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:45:54 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 11:45:56 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:45:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:45:56 - INFO - __main__ - Starting training!
05/20/2022 11:46:25 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/20/2022 11:46:25 - INFO - __main__ - Classification-F1 on test data: 0.0481
05/20/2022 11:46:25 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.09128023537141387, test_performance=0.04810263099986528
05/20/2022 11:46:25 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/20/2022 11:46:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:46:26 - INFO - __main__ - Printing 3 examples
05/20/2022 11:46:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 11:46:26 - INFO - __main__ - ['Plant']
05/20/2022 11:46:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 11:46:26 - INFO - __main__ - ['Plant']
05/20/2022 11:46:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 11:46:26 - INFO - __main__ - ['Plant']
05/20/2022 11:46:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:46:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:46:26 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 11:46:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 11:46:26 - INFO - __main__ - Printing 3 examples
05/20/2022 11:46:26 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 11:46:26 - INFO - __main__ - ['Plant']
05/20/2022 11:46:26 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 11:46:26 - INFO - __main__ - ['Plant']
05/20/2022 11:46:26 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 11:46:26 - INFO - __main__ - ['Plant']
05/20/2022 11:46:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 11:46:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 11:46:26 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 11:46:32 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 11:46:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 11:46:32 - INFO - __main__ - Starting training!
05/20/2022 11:46:33 - INFO - __main__ - Step 10 Global step 10 Train loss 7.74 on epoch=0
05/20/2022 11:46:35 - INFO - __main__ - Step 20 Global step 20 Train loss 7.41 on epoch=1
05/20/2022 11:46:36 - INFO - __main__ - Step 30 Global step 30 Train loss 7.65 on epoch=2
05/20/2022 11:46:37 - INFO - __main__ - Step 40 Global step 40 Train loss 7.47 on epoch=2
05/20/2022 11:46:38 - INFO - __main__ - Step 50 Global step 50 Train loss 7.26 on epoch=3
05/20/2022 11:46:47 - INFO - __main__ - Global step 50 Train loss 7.51 Classification-F1 0.0 on epoch=3
05/20/2022 11:46:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 11:46:48 - INFO - __main__ - Step 60 Global step 60 Train loss 7.30 on epoch=4
05/20/2022 11:46:50 - INFO - __main__ - Step 70 Global step 70 Train loss 7.07 on epoch=4
05/20/2022 11:46:51 - INFO - __main__ - Step 80 Global step 80 Train loss 7.14 on epoch=5
05/20/2022 11:46:52 - INFO - __main__ - Step 90 Global step 90 Train loss 6.97 on epoch=6
05/20/2022 11:46:53 - INFO - __main__ - Step 100 Global step 100 Train loss 7.04 on epoch=7
05/20/2022 11:47:52 - INFO - __main__ - Global step 100 Train loss 7.10 Classification-F1 0.0 on epoch=7
05/20/2022 11:47:53 - INFO - __main__ - Step 110 Global step 110 Train loss 7.12 on epoch=7
05/20/2022 11:47:54 - INFO - __main__ - Step 120 Global step 120 Train loss 6.70 on epoch=8
05/20/2022 11:47:55 - INFO - __main__ - Step 130 Global step 130 Train loss 6.77 on epoch=9
05/20/2022 11:47:57 - INFO - __main__ - Step 140 Global step 140 Train loss 6.68 on epoch=9
05/20/2022 11:47:58 - INFO - __main__ - Step 150 Global step 150 Train loss 6.67 on epoch=10
05/20/2022 11:49:09 - INFO - __main__ - Global step 150 Train loss 6.79 Classification-F1 0.0 on epoch=10
05/20/2022 11:49:11 - INFO - __main__ - Step 160 Global step 160 Train loss 6.48 on epoch=11
05/20/2022 11:49:12 - INFO - __main__ - Step 170 Global step 170 Train loss 6.59 on epoch=12
05/20/2022 11:49:13 - INFO - __main__ - Step 180 Global step 180 Train loss 6.62 on epoch=12
05/20/2022 11:49:14 - INFO - __main__ - Step 190 Global step 190 Train loss 6.37 on epoch=13
05/20/2022 11:49:16 - INFO - __main__ - Step 200 Global step 200 Train loss 6.38 on epoch=14
05/20/2022 11:50:03 - INFO - __main__ - Global step 200 Train loss 6.49 Classification-F1 0.0 on epoch=14
05/20/2022 11:50:04 - INFO - __main__ - Step 210 Global step 210 Train loss 6.33 on epoch=14
05/20/2022 11:50:05 - INFO - __main__ - Step 220 Global step 220 Train loss 6.35 on epoch=15
05/20/2022 11:50:06 - INFO - __main__ - Step 230 Global step 230 Train loss 6.10 on epoch=16
05/20/2022 11:50:08 - INFO - __main__ - Step 240 Global step 240 Train loss 6.30 on epoch=17
05/20/2022 11:50:09 - INFO - __main__ - Step 250 Global step 250 Train loss 6.19 on epoch=17
05/20/2022 11:50:58 - INFO - __main__ - Global step 250 Train loss 6.26 Classification-F1 0.0 on epoch=17
05/20/2022 11:50:59 - INFO - __main__ - Step 260 Global step 260 Train loss 6.18 on epoch=18
05/20/2022 11:51:01 - INFO - __main__ - Step 270 Global step 270 Train loss 6.12 on epoch=19
05/20/2022 11:51:02 - INFO - __main__ - Step 280 Global step 280 Train loss 5.94 on epoch=19
05/20/2022 11:51:03 - INFO - __main__ - Step 290 Global step 290 Train loss 5.96 on epoch=20
05/20/2022 11:51:04 - INFO - __main__ - Step 300 Global step 300 Train loss 5.96 on epoch=21
05/20/2022 11:52:08 - INFO - __main__ - Global step 300 Train loss 6.03 Classification-F1 0.0 on epoch=21
05/20/2022 11:52:09 - INFO - __main__ - Step 310 Global step 310 Train loss 6.02 on epoch=22
05/20/2022 11:52:11 - INFO - __main__ - Step 320 Global step 320 Train loss 6.03 on epoch=22
05/20/2022 11:52:12 - INFO - __main__ - Step 330 Global step 330 Train loss 5.73 on epoch=23
05/20/2022 11:52:13 - INFO - __main__ - Step 340 Global step 340 Train loss 5.73 on epoch=24
05/20/2022 11:52:14 - INFO - __main__ - Step 350 Global step 350 Train loss 5.77 on epoch=24
05/20/2022 11:52:55 - INFO - __main__ - Global step 350 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/20/2022 11:52:56 - INFO - __main__ - Step 360 Global step 360 Train loss 5.53 on epoch=25
05/20/2022 11:52:58 - INFO - __main__ - Step 370 Global step 370 Train loss 5.70 on epoch=26
05/20/2022 11:52:59 - INFO - __main__ - Step 380 Global step 380 Train loss 5.71 on epoch=27
05/20/2022 11:53:00 - INFO - __main__ - Step 390 Global step 390 Train loss 5.69 on epoch=27
05/20/2022 11:53:01 - INFO - __main__ - Step 400 Global step 400 Train loss 5.53 on epoch=28
05/20/2022 11:54:09 - INFO - __main__ - Global step 400 Train loss 5.63 Classification-F1 0.0 on epoch=28
05/20/2022 11:54:11 - INFO - __main__ - Step 410 Global step 410 Train loss 5.64 on epoch=29
05/20/2022 11:54:12 - INFO - __main__ - Step 420 Global step 420 Train loss 5.48 on epoch=29
05/20/2022 11:54:13 - INFO - __main__ - Step 430 Global step 430 Train loss 5.49 on epoch=30
05/20/2022 11:54:14 - INFO - __main__ - Step 440 Global step 440 Train loss 5.38 on epoch=31
05/20/2022 11:54:16 - INFO - __main__ - Step 450 Global step 450 Train loss 5.32 on epoch=32
05/20/2022 11:55:25 - INFO - __main__ - Global step 450 Train loss 5.46 Classification-F1 0.0 on epoch=32
05/20/2022 11:55:26 - INFO - __main__ - Step 460 Global step 460 Train loss 5.43 on epoch=32
05/20/2022 11:55:28 - INFO - __main__ - Step 470 Global step 470 Train loss 5.33 on epoch=33
05/20/2022 11:55:29 - INFO - __main__ - Step 480 Global step 480 Train loss 5.38 on epoch=34
05/20/2022 11:55:30 - INFO - __main__ - Step 490 Global step 490 Train loss 5.24 on epoch=34
05/20/2022 11:55:31 - INFO - __main__ - Step 500 Global step 500 Train loss 5.12 on epoch=35
05/20/2022 11:56:20 - INFO - __main__ - Global step 500 Train loss 5.30 Classification-F1 0.0 on epoch=35
05/20/2022 11:56:21 - INFO - __main__ - Step 510 Global step 510 Train loss 5.14 on epoch=36
05/20/2022 11:56:22 - INFO - __main__ - Step 520 Global step 520 Train loss 5.22 on epoch=37
05/20/2022 11:56:23 - INFO - __main__ - Step 530 Global step 530 Train loss 5.14 on epoch=37
05/20/2022 11:56:25 - INFO - __main__ - Step 540 Global step 540 Train loss 5.02 on epoch=38
05/20/2022 11:56:26 - INFO - __main__ - Step 550 Global step 550 Train loss 5.01 on epoch=39
05/20/2022 11:56:37 - INFO - __main__ - Global step 550 Train loss 5.10 Classification-F1 0.0 on epoch=39
05/20/2022 11:56:38 - INFO - __main__ - Step 560 Global step 560 Train loss 5.00 on epoch=39
05/20/2022 11:56:39 - INFO - __main__ - Step 570 Global step 570 Train loss 4.98 on epoch=40
05/20/2022 11:56:41 - INFO - __main__ - Step 580 Global step 580 Train loss 4.91 on epoch=41
05/20/2022 11:56:42 - INFO - __main__ - Step 590 Global step 590 Train loss 5.16 on epoch=42
05/20/2022 11:56:43 - INFO - __main__ - Step 600 Global step 600 Train loss 5.00 on epoch=42
05/20/2022 11:56:51 - INFO - __main__ - Global step 600 Train loss 5.01 Classification-F1 0.0 on epoch=42
05/20/2022 11:56:52 - INFO - __main__ - Step 610 Global step 610 Train loss 4.83 on epoch=43
05/20/2022 11:56:53 - INFO - __main__ - Step 620 Global step 620 Train loss 4.76 on epoch=44
05/20/2022 11:56:54 - INFO - __main__ - Step 630 Global step 630 Train loss 4.78 on epoch=44
05/20/2022 11:56:56 - INFO - __main__ - Step 640 Global step 640 Train loss 4.79 on epoch=45
05/20/2022 11:56:57 - INFO - __main__ - Step 650 Global step 650 Train loss 4.73 on epoch=46
05/20/2022 11:56:59 - INFO - __main__ - Global step 650 Train loss 4.78 Classification-F1 0.010551948051948054 on epoch=46
05/20/2022 11:56:59 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.010551948051948054 on epoch=46, global_step=650
05/20/2022 11:57:01 - INFO - __main__ - Step 660 Global step 660 Train loss 4.65 on epoch=47
05/20/2022 11:57:02 - INFO - __main__ - Step 670 Global step 670 Train loss 4.73 on epoch=47
05/20/2022 11:57:03 - INFO - __main__ - Step 680 Global step 680 Train loss 4.60 on epoch=48
05/20/2022 11:57:04 - INFO - __main__ - Step 690 Global step 690 Train loss 4.53 on epoch=49
05/20/2022 11:57:06 - INFO - __main__ - Step 700 Global step 700 Train loss 4.64 on epoch=49
05/20/2022 11:57:08 - INFO - __main__ - Global step 700 Train loss 4.63 Classification-F1 0.009006473402758232 on epoch=49
05/20/2022 11:57:09 - INFO - __main__ - Step 710 Global step 710 Train loss 4.57 on epoch=50
05/20/2022 11:57:10 - INFO - __main__ - Step 720 Global step 720 Train loss 4.44 on epoch=51
05/20/2022 11:57:11 - INFO - __main__ - Step 730 Global step 730 Train loss 4.56 on epoch=52
05/20/2022 11:57:13 - INFO - __main__ - Step 740 Global step 740 Train loss 4.48 on epoch=52
05/20/2022 11:57:14 - INFO - __main__ - Step 750 Global step 750 Train loss 4.22 on epoch=53
05/20/2022 11:57:16 - INFO - __main__ - Global step 750 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=53
05/20/2022 11:57:17 - INFO - __main__ - Step 760 Global step 760 Train loss 4.20 on epoch=54
05/20/2022 11:57:18 - INFO - __main__ - Step 770 Global step 770 Train loss 4.25 on epoch=54
05/20/2022 11:57:19 - INFO - __main__ - Step 780 Global step 780 Train loss 4.29 on epoch=55
05/20/2022 11:57:21 - INFO - __main__ - Step 790 Global step 790 Train loss 4.20 on epoch=56
05/20/2022 11:57:22 - INFO - __main__ - Step 800 Global step 800 Train loss 4.21 on epoch=57
05/20/2022 11:57:24 - INFO - __main__ - Global step 800 Train loss 4.23 Classification-F1 0.008438818565400845 on epoch=57
05/20/2022 11:57:25 - INFO - __main__ - Step 810 Global step 810 Train loss 4.12 on epoch=57
05/20/2022 11:57:26 - INFO - __main__ - Step 820 Global step 820 Train loss 4.10 on epoch=58
05/20/2022 11:57:28 - INFO - __main__ - Step 830 Global step 830 Train loss 4.13 on epoch=59
05/20/2022 11:57:29 - INFO - __main__ - Step 840 Global step 840 Train loss 3.90 on epoch=59
05/20/2022 11:57:30 - INFO - __main__ - Step 850 Global step 850 Train loss 3.88 on epoch=60
05/20/2022 11:57:32 - INFO - __main__ - Global step 850 Train loss 4.03 Classification-F1 0.00892608089260809 on epoch=60
05/20/2022 11:57:33 - INFO - __main__ - Step 860 Global step 860 Train loss 3.96 on epoch=61
05/20/2022 11:57:34 - INFO - __main__ - Step 870 Global step 870 Train loss 3.83 on epoch=62
05/20/2022 11:57:36 - INFO - __main__ - Step 880 Global step 880 Train loss 3.85 on epoch=62
05/20/2022 11:57:37 - INFO - __main__ - Step 890 Global step 890 Train loss 3.84 on epoch=63
05/20/2022 11:57:38 - INFO - __main__ - Step 900 Global step 900 Train loss 4.04 on epoch=64
05/20/2022 11:57:40 - INFO - __main__ - Global step 900 Train loss 3.90 Classification-F1 0.009563658099222952 on epoch=64
05/20/2022 11:57:41 - INFO - __main__ - Step 910 Global step 910 Train loss 3.89 on epoch=64
05/20/2022 11:57:43 - INFO - __main__ - Step 920 Global step 920 Train loss 3.71 on epoch=65
05/20/2022 11:57:44 - INFO - __main__ - Step 930 Global step 930 Train loss 3.83 on epoch=66
05/20/2022 11:57:45 - INFO - __main__ - Step 940 Global step 940 Train loss 3.79 on epoch=67
05/20/2022 11:57:46 - INFO - __main__ - Step 950 Global step 950 Train loss 3.78 on epoch=67
05/20/2022 11:57:48 - INFO - __main__ - Global step 950 Train loss 3.80 Classification-F1 0.008403361344537815 on epoch=67
05/20/2022 11:57:49 - INFO - __main__ - Step 960 Global step 960 Train loss 4.01 on epoch=68
05/20/2022 11:57:51 - INFO - __main__ - Step 970 Global step 970 Train loss 3.76 on epoch=69
05/20/2022 11:57:52 - INFO - __main__ - Step 980 Global step 980 Train loss 3.90 on epoch=69
05/20/2022 11:57:53 - INFO - __main__ - Step 990 Global step 990 Train loss 3.68 on epoch=70
05/20/2022 11:57:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.54 on epoch=71
05/20/2022 11:57:56 - INFO - __main__ - Global step 1000 Train loss 3.78 Classification-F1 0.02133884387405514 on epoch=71
05/20/2022 11:57:56 - INFO - __main__ - Saving model with best Classification-F1: 0.010551948051948054 -> 0.02133884387405514 on epoch=71, global_step=1000
05/20/2022 11:57:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.65 on epoch=72
05/20/2022 11:57:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.48 on epoch=72
05/20/2022 11:58:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.67 on epoch=73
05/20/2022 11:58:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.54 on epoch=74
05/20/2022 11:58:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.67 on epoch=74
05/20/2022 11:58:05 - INFO - __main__ - Global step 1050 Train loss 3.60 Classification-F1 0.018692796635061626 on epoch=74
05/20/2022 11:58:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.41 on epoch=75
05/20/2022 11:58:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.68 on epoch=76
05/20/2022 11:58:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.65 on epoch=77
05/20/2022 11:58:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.46 on epoch=77
05/20/2022 11:58:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.61 on epoch=78
05/20/2022 11:58:13 - INFO - __main__ - Global step 1100 Train loss 3.56 Classification-F1 0.01785945147289685 on epoch=78
05/20/2022 11:58:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.41 on epoch=79
05/20/2022 11:58:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.49 on epoch=79
05/20/2022 11:58:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.52 on epoch=80
05/20/2022 11:58:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.41 on epoch=81
05/20/2022 11:58:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.72 on epoch=82
05/20/2022 11:58:21 - INFO - __main__ - Global step 1150 Train loss 3.51 Classification-F1 0.021158827539195638 on epoch=82
05/20/2022 11:58:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.38 on epoch=82
05/20/2022 11:58:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.46 on epoch=83
05/20/2022 11:58:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.49 on epoch=84
05/20/2022 11:58:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.56 on epoch=84
05/20/2022 11:58:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.22 on epoch=85
05/20/2022 11:58:29 - INFO - __main__ - Global step 1200 Train loss 3.42 Classification-F1 0.02825489922264116 on epoch=85
05/20/2022 11:58:29 - INFO - __main__ - Saving model with best Classification-F1: 0.02133884387405514 -> 0.02825489922264116 on epoch=85, global_step=1200
05/20/2022 11:58:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.31 on epoch=86
05/20/2022 11:58:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.32 on epoch=87
05/20/2022 11:58:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.19 on epoch=87
05/20/2022 11:58:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.28 on epoch=88
05/20/2022 11:58:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.41 on epoch=89
05/20/2022 11:58:37 - INFO - __main__ - Global step 1250 Train loss 3.30 Classification-F1 0.0325978344554196 on epoch=89
05/20/2022 11:58:37 - INFO - __main__ - Saving model with best Classification-F1: 0.02825489922264116 -> 0.0325978344554196 on epoch=89, global_step=1250
05/20/2022 11:58:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.33 on epoch=89
05/20/2022 11:58:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.25 on epoch=90
05/20/2022 11:58:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.26 on epoch=91
05/20/2022 11:58:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.31 on epoch=92
05/20/2022 11:58:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.23 on epoch=92
05/20/2022 11:58:46 - INFO - __main__ - Global step 1300 Train loss 3.28 Classification-F1 0.020044802867383513 on epoch=92
05/20/2022 11:58:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.28 on epoch=93
05/20/2022 11:58:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.30 on epoch=94
05/20/2022 11:58:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.23 on epoch=94
05/20/2022 11:58:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.20 on epoch=95
05/20/2022 11:58:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.12 on epoch=96
05/20/2022 11:58:54 - INFO - __main__ - Global step 1350 Train loss 3.23 Classification-F1 0.02570638511814982 on epoch=96
05/20/2022 11:58:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.22 on epoch=97
05/20/2022 11:58:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.26 on epoch=97
05/20/2022 11:58:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.21 on epoch=98
05/20/2022 11:58:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.35 on epoch=99
05/20/2022 11:59:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.35 on epoch=99
05/20/2022 11:59:02 - INFO - __main__ - Global step 1400 Train loss 3.28 Classification-F1 0.03740617807554927 on epoch=99
05/20/2022 11:59:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0325978344554196 -> 0.03740617807554927 on epoch=99, global_step=1400
05/20/2022 11:59:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.01 on epoch=100
05/20/2022 11:59:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.24 on epoch=101
05/20/2022 11:59:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.20 on epoch=102
05/20/2022 11:59:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.03 on epoch=102
05/20/2022 11:59:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.11 on epoch=103
05/20/2022 11:59:10 - INFO - __main__ - Global step 1450 Train loss 3.12 Classification-F1 0.024716813032964233 on epoch=103
05/20/2022 11:59:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.16 on epoch=104
05/20/2022 11:59:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.97 on epoch=104
05/20/2022 11:59:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.94 on epoch=105
05/20/2022 11:59:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.11 on epoch=106
05/20/2022 11:59:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.07 on epoch=107
05/20/2022 11:59:18 - INFO - __main__ - Global step 1500 Train loss 3.05 Classification-F1 0.029645028651063915 on epoch=107
05/20/2022 11:59:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.87 on epoch=107
05/20/2022 11:59:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.95 on epoch=108
05/20/2022 11:59:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.14 on epoch=109
05/20/2022 11:59:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.04 on epoch=109
05/20/2022 11:59:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.03 on epoch=110
05/20/2022 11:59:26 - INFO - __main__ - Global step 1550 Train loss 3.01 Classification-F1 0.029594645311540765 on epoch=110
05/20/2022 11:59:28 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.14 on epoch=111
05/20/2022 11:59:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.93 on epoch=112
05/20/2022 11:59:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.87 on epoch=112
05/20/2022 11:59:32 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.06 on epoch=113
05/20/2022 11:59:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.00 on epoch=114
05/20/2022 11:59:35 - INFO - __main__ - Global step 1600 Train loss 3.00 Classification-F1 0.040725761307657864 on epoch=114
05/20/2022 11:59:35 - INFO - __main__ - Saving model with best Classification-F1: 0.03740617807554927 -> 0.040725761307657864 on epoch=114, global_step=1600
05/20/2022 11:59:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.01 on epoch=114
05/20/2022 11:59:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.89 on epoch=115
05/20/2022 11:59:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.89 on epoch=116
05/20/2022 11:59:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.00 on epoch=117
05/20/2022 11:59:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.84 on epoch=117
05/20/2022 11:59:43 - INFO - __main__ - Global step 1650 Train loss 2.93 Classification-F1 0.03234662659865313 on epoch=117
05/20/2022 11:59:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.97 on epoch=118
05/20/2022 11:59:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.04 on epoch=119
05/20/2022 11:59:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.91 on epoch=119
05/20/2022 11:59:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.70 on epoch=120
05/20/2022 11:59:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.04 on epoch=121
05/20/2022 11:59:51 - INFO - __main__ - Global step 1700 Train loss 2.93 Classification-F1 0.009685230024213076 on epoch=121
05/20/2022 11:59:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.02 on epoch=122
05/20/2022 11:59:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.91 on epoch=122
05/20/2022 11:59:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.85 on epoch=123
05/20/2022 11:59:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.90 on epoch=124
05/20/2022 11:59:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.94 on epoch=124
05/20/2022 11:59:59 - INFO - __main__ - Global step 1750 Train loss 2.93 Classification-F1 0.02530752167775761 on epoch=124
05/20/2022 12:00:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.92 on epoch=125
05/20/2022 12:00:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.99 on epoch=126
05/20/2022 12:00:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.81 on epoch=127
05/20/2022 12:00:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.74 on epoch=127
05/20/2022 12:00:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.01 on epoch=128
05/20/2022 12:00:08 - INFO - __main__ - Global step 1800 Train loss 2.89 Classification-F1 0.022360248447204967 on epoch=128
05/20/2022 12:00:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.82 on epoch=129
05/20/2022 12:00:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.74 on epoch=129
05/20/2022 12:00:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.87 on epoch=130
05/20/2022 12:00:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.91 on epoch=131
05/20/2022 12:00:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.97 on epoch=132
05/20/2022 12:00:16 - INFO - __main__ - Global step 1850 Train loss 2.86 Classification-F1 0.045566502463054194 on epoch=132
05/20/2022 12:00:16 - INFO - __main__ - Saving model with best Classification-F1: 0.040725761307657864 -> 0.045566502463054194 on epoch=132, global_step=1850
05/20/2022 12:00:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.78 on epoch=132
05/20/2022 12:00:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.94 on epoch=133
05/20/2022 12:00:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.81 on epoch=134
05/20/2022 12:00:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.85 on epoch=134
05/20/2022 12:00:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.70 on epoch=135
05/20/2022 12:00:24 - INFO - __main__ - Global step 1900 Train loss 2.82 Classification-F1 0.027167717850947664 on epoch=135
05/20/2022 12:00:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.76 on epoch=136
05/20/2022 12:00:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.69 on epoch=137
05/20/2022 12:00:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.69 on epoch=137
05/20/2022 12:00:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.81 on epoch=138
05/20/2022 12:00:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.72 on epoch=139
05/20/2022 12:00:32 - INFO - __main__ - Global step 1950 Train loss 2.74 Classification-F1 0.04412817015556742 on epoch=139
05/20/2022 12:00:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.89 on epoch=139
05/20/2022 12:00:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.53 on epoch=140
05/20/2022 12:00:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.71 on epoch=141
05/20/2022 12:00:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.72 on epoch=142
05/20/2022 12:00:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.64 on epoch=142
05/20/2022 12:00:41 - INFO - __main__ - Global step 2000 Train loss 2.70 Classification-F1 0.04027093596059113 on epoch=142
05/20/2022 12:00:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.85 on epoch=143
05/20/2022 12:00:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.74 on epoch=144
05/20/2022 12:00:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.62 on epoch=144
05/20/2022 12:00:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.55 on epoch=145
05/20/2022 12:00:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.76 on epoch=146
05/20/2022 12:00:49 - INFO - __main__ - Global step 2050 Train loss 2.71 Classification-F1 0.0298874017889298 on epoch=146
05/20/2022 12:00:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.71 on epoch=147
05/20/2022 12:00:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.44 on epoch=147
05/20/2022 12:00:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.73 on epoch=148
05/20/2022 12:00:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.69 on epoch=149
05/20/2022 12:00:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.78 on epoch=149
05/20/2022 12:00:57 - INFO - __main__ - Global step 2100 Train loss 2.67 Classification-F1 0.023067757080732054 on epoch=149
05/20/2022 12:00:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.57 on epoch=150
05/20/2022 12:01:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.77 on epoch=151
05/20/2022 12:01:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.74 on epoch=152
05/20/2022 12:01:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.71 on epoch=152
05/20/2022 12:01:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.76 on epoch=153
05/20/2022 12:01:05 - INFO - __main__ - Global step 2150 Train loss 2.71 Classification-F1 0.036413755948639666 on epoch=153
05/20/2022 12:01:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.71 on epoch=154
05/20/2022 12:01:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.88 on epoch=154
05/20/2022 12:01:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.40 on epoch=155
05/20/2022 12:01:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.75 on epoch=156
05/20/2022 12:01:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.72 on epoch=157
05/20/2022 12:01:13 - INFO - __main__ - Global step 2200 Train loss 2.69 Classification-F1 0.027220587231548136 on epoch=157
05/20/2022 12:01:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.55 on epoch=157
05/20/2022 12:01:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.65 on epoch=158
05/20/2022 12:01:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.55 on epoch=159
05/20/2022 12:01:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.67 on epoch=159
05/20/2022 12:01:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.59 on epoch=160
05/20/2022 12:01:22 - INFO - __main__ - Global step 2250 Train loss 2.60 Classification-F1 0.021284614921498135 on epoch=160
05/20/2022 12:01:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.65 on epoch=161
05/20/2022 12:01:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.74 on epoch=162
05/20/2022 12:01:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.52 on epoch=162
05/20/2022 12:01:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.81 on epoch=163
05/20/2022 12:01:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.53 on epoch=164
05/20/2022 12:01:30 - INFO - __main__ - Global step 2300 Train loss 2.65 Classification-F1 0.04231365021883736 on epoch=164
05/20/2022 12:01:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.76 on epoch=164
05/20/2022 12:01:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.42 on epoch=165
05/20/2022 12:01:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.66 on epoch=166
05/20/2022 12:01:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.68 on epoch=167
05/20/2022 12:01:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.70 on epoch=167
05/20/2022 12:01:38 - INFO - __main__ - Global step 2350 Train loss 2.64 Classification-F1 0.04769492568521971 on epoch=167
05/20/2022 12:01:38 - INFO - __main__ - Saving model with best Classification-F1: 0.045566502463054194 -> 0.04769492568521971 on epoch=167, global_step=2350
05/20/2022 12:01:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.51 on epoch=168
05/20/2022 12:01:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.47 on epoch=169
05/20/2022 12:01:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.69 on epoch=169
05/20/2022 12:01:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.22 on epoch=170
05/20/2022 12:01:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.79 on epoch=171
05/20/2022 12:01:46 - INFO - __main__ - Global step 2400 Train loss 2.53 Classification-F1 0.03735537213628994 on epoch=171
05/20/2022 12:01:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.65 on epoch=172
05/20/2022 12:01:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.56 on epoch=172
05/20/2022 12:01:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.61 on epoch=173
05/20/2022 12:01:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.46 on epoch=174
05/20/2022 12:01:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.60 on epoch=174
05/20/2022 12:01:54 - INFO - __main__ - Global step 2450 Train loss 2.58 Classification-F1 0.033191152567221584 on epoch=174
05/20/2022 12:01:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.38 on epoch=175
05/20/2022 12:01:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.66 on epoch=176
05/20/2022 12:01:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.55 on epoch=177
05/20/2022 12:02:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.58 on epoch=177
05/20/2022 12:02:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.58 on epoch=178
05/20/2022 12:02:03 - INFO - __main__ - Global step 2500 Train loss 2.55 Classification-F1 0.05581797664292635 on epoch=178
05/20/2022 12:02:03 - INFO - __main__ - Saving model with best Classification-F1: 0.04769492568521971 -> 0.05581797664292635 on epoch=178, global_step=2500
05/20/2022 12:02:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.61 on epoch=179
05/20/2022 12:02:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.52 on epoch=179
05/20/2022 12:02:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.39 on epoch=180
05/20/2022 12:02:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.44 on epoch=181
05/20/2022 12:02:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.45 on epoch=182
05/20/2022 12:02:11 - INFO - __main__ - Global step 2550 Train loss 2.48 Classification-F1 0.050119869256614866 on epoch=182
05/20/2022 12:02:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.36 on epoch=182
05/20/2022 12:02:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.45 on epoch=183
05/20/2022 12:02:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.45 on epoch=184
05/20/2022 12:02:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.41 on epoch=184
05/20/2022 12:02:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.54 on epoch=185
05/20/2022 12:02:19 - INFO - __main__ - Global step 2600 Train loss 2.44 Classification-F1 0.031312205520930926 on epoch=185
05/20/2022 12:02:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.60 on epoch=186
05/20/2022 12:02:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.41 on epoch=187
05/20/2022 12:02:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.38 on epoch=187
05/20/2022 12:02:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.39 on epoch=188
05/20/2022 12:02:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.53 on epoch=189
05/20/2022 12:02:27 - INFO - __main__ - Global step 2650 Train loss 2.46 Classification-F1 0.04898239607300094 on epoch=189
05/20/2022 12:02:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.43 on epoch=189
05/20/2022 12:02:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.31 on epoch=190
05/20/2022 12:02:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.49 on epoch=191
05/20/2022 12:02:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.52 on epoch=192
05/20/2022 12:02:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.34 on epoch=192
05/20/2022 12:02:35 - INFO - __main__ - Global step 2700 Train loss 2.42 Classification-F1 0.042943722943722944 on epoch=192
05/20/2022 12:02:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.43 on epoch=193
05/20/2022 12:02:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.34 on epoch=194
05/20/2022 12:02:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.45 on epoch=194
05/20/2022 12:02:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.38 on epoch=195
05/20/2022 12:02:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.40 on epoch=196
05/20/2022 12:02:44 - INFO - __main__ - Global step 2750 Train loss 2.40 Classification-F1 0.047283615261143344 on epoch=196
05/20/2022 12:02:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.36 on epoch=197
05/20/2022 12:02:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.37 on epoch=197
05/20/2022 12:02:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.52 on epoch=198
05/20/2022 12:02:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.46 on epoch=199
05/20/2022 12:02:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.41 on epoch=199
05/20/2022 12:02:52 - INFO - __main__ - Global step 2800 Train loss 2.42 Classification-F1 0.05426710092555489 on epoch=199
05/20/2022 12:02:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.29 on epoch=200
05/20/2022 12:02:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.67 on epoch=201
05/20/2022 12:02:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.39 on epoch=202
05/20/2022 12:02:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.38 on epoch=202
05/20/2022 12:02:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.46 on epoch=203
05/20/2022 12:03:00 - INFO - __main__ - Global step 2850 Train loss 2.44 Classification-F1 0.04893769101843637 on epoch=203
05/20/2022 12:03:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.43 on epoch=204
05/20/2022 12:03:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.30 on epoch=204
05/20/2022 12:03:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.19 on epoch=205
05/20/2022 12:03:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.46 on epoch=206
05/20/2022 12:03:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.44 on epoch=207
05/20/2022 12:03:08 - INFO - __main__ - Global step 2900 Train loss 2.36 Classification-F1 0.0196219715956558 on epoch=207
05/20/2022 12:03:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.19 on epoch=207
05/20/2022 12:03:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.37 on epoch=208
05/20/2022 12:03:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.41 on epoch=209
05/20/2022 12:03:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.48 on epoch=209
05/20/2022 12:03:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.34 on epoch=210
05/20/2022 12:03:17 - INFO - __main__ - Global step 2950 Train loss 2.36 Classification-F1 0.04166897619522721 on epoch=210
05/20/2022 12:03:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.24 on epoch=211
05/20/2022 12:03:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.40 on epoch=212
05/20/2022 12:03:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.47 on epoch=212
05/20/2022 12:03:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.45 on epoch=213
05/20/2022 12:03:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.27 on epoch=214
05/20/2022 12:03:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:03:24 - INFO - __main__ - Printing 3 examples
05/20/2022 12:03:24 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 12:03:24 - INFO - __main__ - ['Plant']
05/20/2022 12:03:24 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 12:03:24 - INFO - __main__ - ['Plant']
05/20/2022 12:03:24 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 12:03:24 - INFO - __main__ - ['Plant']
05/20/2022 12:03:24 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:03:24 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:03:24 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:03:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:03:24 - INFO - __main__ - Printing 3 examples
05/20/2022 12:03:24 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 12:03:24 - INFO - __main__ - ['Plant']
05/20/2022 12:03:24 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 12:03:24 - INFO - __main__ - ['Plant']
05/20/2022 12:03:24 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 12:03:24 - INFO - __main__ - ['Plant']
05/20/2022 12:03:24 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:03:25 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:03:25 - INFO - __main__ - Global step 3000 Train loss 2.36 Classification-F1 0.046092189346564796 on epoch=214
05/20/2022 12:03:25 - INFO - __main__ - save last model!
05/20/2022 12:03:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 12:03:25 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:03:25 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 12:03:25 - INFO - __main__ - Printing 3 examples
05/20/2022 12:03:25 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 12:03:25 - INFO - __main__ - ['Animal']
05/20/2022 12:03:25 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 12:03:25 - INFO - __main__ - ['Animal']
05/20/2022 12:03:25 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 12:03:25 - INFO - __main__ - ['Village']
05/20/2022 12:03:25 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:03:27 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:03:30 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:03:30 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 12:03:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:03:30 - INFO - __main__ - Starting training!
05/20/2022 12:04:00 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/20/2022 12:04:00 - INFO - __main__ - Classification-F1 on test data: 0.0403
05/20/2022 12:04:00 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.05581797664292635, test_performance=0.0402732922290327
05/20/2022 12:04:00 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/20/2022 12:04:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:04:01 - INFO - __main__ - Printing 3 examples
05/20/2022 12:04:01 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/20/2022 12:04:01 - INFO - __main__ - ['Plant']
05/20/2022 12:04:01 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/20/2022 12:04:01 - INFO - __main__ - ['Plant']
05/20/2022 12:04:01 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/20/2022 12:04:01 - INFO - __main__ - ['Plant']
05/20/2022 12:04:01 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:04:01 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:04:01 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:04:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:04:01 - INFO - __main__ - Printing 3 examples
05/20/2022 12:04:01 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/20/2022 12:04:01 - INFO - __main__ - ['Plant']
05/20/2022 12:04:01 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/20/2022 12:04:01 - INFO - __main__ - ['Plant']
05/20/2022 12:04:01 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/20/2022 12:04:01 - INFO - __main__ - ['Plant']
05/20/2022 12:04:01 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:04:01 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:04:01 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:04:08 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:04:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:04:08 - INFO - __main__ - Starting training!
05/20/2022 12:04:09 - INFO - __main__ - Step 10 Global step 10 Train loss 7.60 on epoch=0
05/20/2022 12:04:11 - INFO - __main__ - Step 20 Global step 20 Train loss 7.44 on epoch=1
05/20/2022 12:04:12 - INFO - __main__ - Step 30 Global step 30 Train loss 7.55 on epoch=2
05/20/2022 12:04:13 - INFO - __main__ - Step 40 Global step 40 Train loss 7.72 on epoch=2
05/20/2022 12:04:14 - INFO - __main__ - Step 50 Global step 50 Train loss 7.34 on epoch=3
05/20/2022 12:04:21 - INFO - __main__ - Global step 50 Train loss 7.53 Classification-F1 0.0 on epoch=3
05/20/2022 12:04:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 12:04:22 - INFO - __main__ - Step 60 Global step 60 Train loss 7.22 on epoch=4
05/20/2022 12:04:23 - INFO - __main__ - Step 70 Global step 70 Train loss 7.26 on epoch=4
05/20/2022 12:04:24 - INFO - __main__ - Step 80 Global step 80 Train loss 7.11 on epoch=5
05/20/2022 12:04:26 - INFO - __main__ - Step 90 Global step 90 Train loss 7.04 on epoch=6
05/20/2022 12:04:27 - INFO - __main__ - Step 100 Global step 100 Train loss 7.07 on epoch=7
05/20/2022 12:04:49 - INFO - __main__ - Global step 100 Train loss 7.14 Classification-F1 0.0 on epoch=7
05/20/2022 12:04:50 - INFO - __main__ - Step 110 Global step 110 Train loss 7.26 on epoch=7
05/20/2022 12:04:51 - INFO - __main__ - Step 120 Global step 120 Train loss 6.87 on epoch=8
05/20/2022 12:04:53 - INFO - __main__ - Step 130 Global step 130 Train loss 6.91 on epoch=9
05/20/2022 12:04:54 - INFO - __main__ - Step 140 Global step 140 Train loss 6.89 on epoch=9
05/20/2022 12:04:55 - INFO - __main__ - Step 150 Global step 150 Train loss 6.87 on epoch=10
05/20/2022 12:05:32 - INFO - __main__ - Global step 150 Train loss 6.96 Classification-F1 0.0 on epoch=10
05/20/2022 12:05:34 - INFO - __main__ - Step 160 Global step 160 Train loss 6.65 on epoch=11
05/20/2022 12:05:35 - INFO - __main__ - Step 170 Global step 170 Train loss 6.79 on epoch=12
05/20/2022 12:05:36 - INFO - __main__ - Step 180 Global step 180 Train loss 6.89 on epoch=12
05/20/2022 12:05:37 - INFO - __main__ - Step 190 Global step 190 Train loss 6.57 on epoch=13
05/20/2022 12:05:39 - INFO - __main__ - Step 200 Global step 200 Train loss 6.63 on epoch=14
05/20/2022 12:06:40 - INFO - __main__ - Global step 200 Train loss 6.71 Classification-F1 0.0 on epoch=14
05/20/2022 12:06:41 - INFO - __main__ - Step 210 Global step 210 Train loss 6.51 on epoch=14
05/20/2022 12:06:42 - INFO - __main__ - Step 220 Global step 220 Train loss 6.50 on epoch=15
05/20/2022 12:06:44 - INFO - __main__ - Step 230 Global step 230 Train loss 6.35 on epoch=16
05/20/2022 12:06:45 - INFO - __main__ - Step 240 Global step 240 Train loss 6.50 on epoch=17
05/20/2022 12:06:46 - INFO - __main__ - Step 250 Global step 250 Train loss 6.49 on epoch=17
05/20/2022 12:07:53 - INFO - __main__ - Global step 250 Train loss 6.47 Classification-F1 0.0 on epoch=17
05/20/2022 12:07:54 - INFO - __main__ - Step 260 Global step 260 Train loss 6.32 on epoch=18
05/20/2022 12:07:55 - INFO - __main__ - Step 270 Global step 270 Train loss 6.24 on epoch=19
05/20/2022 12:07:56 - INFO - __main__ - Step 280 Global step 280 Train loss 6.27 on epoch=19
05/20/2022 12:07:58 - INFO - __main__ - Step 290 Global step 290 Train loss 6.22 on epoch=20
05/20/2022 12:07:59 - INFO - __main__ - Step 300 Global step 300 Train loss 6.08 on epoch=21
05/20/2022 12:09:09 - INFO - __main__ - Global step 300 Train loss 6.23 Classification-F1 0.0 on epoch=21
05/20/2022 12:09:10 - INFO - __main__ - Step 310 Global step 310 Train loss 6.39 on epoch=22
05/20/2022 12:09:11 - INFO - __main__ - Step 320 Global step 320 Train loss 6.33 on epoch=22
05/20/2022 12:09:13 - INFO - __main__ - Step 330 Global step 330 Train loss 6.14 on epoch=23
05/20/2022 12:09:14 - INFO - __main__ - Step 340 Global step 340 Train loss 6.27 on epoch=24
05/20/2022 12:09:15 - INFO - __main__ - Step 350 Global step 350 Train loss 6.09 on epoch=24
05/20/2022 12:10:08 - INFO - __main__ - Global step 350 Train loss 6.24 Classification-F1 0.0 on epoch=24
05/20/2022 12:10:09 - INFO - __main__ - Step 360 Global step 360 Train loss 6.14 on epoch=25
05/20/2022 12:10:11 - INFO - __main__ - Step 370 Global step 370 Train loss 5.98 on epoch=26
05/20/2022 12:10:12 - INFO - __main__ - Step 380 Global step 380 Train loss 6.10 on epoch=27
05/20/2022 12:10:13 - INFO - __main__ - Step 390 Global step 390 Train loss 6.12 on epoch=27
05/20/2022 12:10:14 - INFO - __main__ - Step 400 Global step 400 Train loss 5.99 on epoch=28
05/20/2022 12:11:11 - INFO - __main__ - Global step 400 Train loss 6.07 Classification-F1 0.0 on epoch=28
05/20/2022 12:11:13 - INFO - __main__ - Step 410 Global step 410 Train loss 5.99 on epoch=29
05/20/2022 12:11:14 - INFO - __main__ - Step 420 Global step 420 Train loss 5.81 on epoch=29
05/20/2022 12:11:15 - INFO - __main__ - Step 430 Global step 430 Train loss 5.99 on epoch=30
05/20/2022 12:11:17 - INFO - __main__ - Step 440 Global step 440 Train loss 5.87 on epoch=31
05/20/2022 12:11:18 - INFO - __main__ - Step 450 Global step 450 Train loss 6.04 on epoch=32
05/20/2022 12:12:09 - INFO - __main__ - Global step 450 Train loss 5.94 Classification-F1 0.0 on epoch=32
05/20/2022 12:12:10 - INFO - __main__ - Step 460 Global step 460 Train loss 5.98 on epoch=32
05/20/2022 12:12:11 - INFO - __main__ - Step 470 Global step 470 Train loss 5.85 on epoch=33
05/20/2022 12:12:12 - INFO - __main__ - Step 480 Global step 480 Train loss 5.80 on epoch=34
05/20/2022 12:12:13 - INFO - __main__ - Step 490 Global step 490 Train loss 5.71 on epoch=34
05/20/2022 12:12:15 - INFO - __main__ - Step 500 Global step 500 Train loss 5.75 on epoch=35
05/20/2022 12:13:08 - INFO - __main__ - Global step 500 Train loss 5.82 Classification-F1 0.0 on epoch=35
05/20/2022 12:13:10 - INFO - __main__ - Step 510 Global step 510 Train loss 5.60 on epoch=36
05/20/2022 12:13:11 - INFO - __main__ - Step 520 Global step 520 Train loss 5.85 on epoch=37
05/20/2022 12:13:12 - INFO - __main__ - Step 530 Global step 530 Train loss 5.73 on epoch=37
05/20/2022 12:13:13 - INFO - __main__ - Step 540 Global step 540 Train loss 5.70 on epoch=38
05/20/2022 12:13:15 - INFO - __main__ - Step 550 Global step 550 Train loss 5.48 on epoch=39
05/20/2022 12:13:31 - INFO - __main__ - Global step 550 Train loss 5.67 Classification-F1 0.0 on epoch=39
05/20/2022 12:13:32 - INFO - __main__ - Step 560 Global step 560 Train loss 5.44 on epoch=39
05/20/2022 12:13:33 - INFO - __main__ - Step 570 Global step 570 Train loss 5.56 on epoch=40
05/20/2022 12:13:34 - INFO - __main__ - Step 580 Global step 580 Train loss 5.38 on epoch=41
05/20/2022 12:13:36 - INFO - __main__ - Step 590 Global step 590 Train loss 5.71 on epoch=42
05/20/2022 12:13:37 - INFO - __main__ - Step 600 Global step 600 Train loss 5.56 on epoch=42
05/20/2022 12:13:58 - INFO - __main__ - Global step 600 Train loss 5.53 Classification-F1 0.0056737588652482265 on epoch=42
05/20/2022 12:13:58 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0056737588652482265 on epoch=42, global_step=600
05/20/2022 12:13:59 - INFO - __main__ - Step 610 Global step 610 Train loss 5.51 on epoch=43
05/20/2022 12:14:01 - INFO - __main__ - Step 620 Global step 620 Train loss 5.48 on epoch=44
05/20/2022 12:14:02 - INFO - __main__ - Step 630 Global step 630 Train loss 5.43 on epoch=44
05/20/2022 12:14:03 - INFO - __main__ - Step 640 Global step 640 Train loss 5.45 on epoch=45
05/20/2022 12:14:04 - INFO - __main__ - Step 650 Global step 650 Train loss 5.16 on epoch=46
05/20/2022 12:14:11 - INFO - __main__ - Global step 650 Train loss 5.41 Classification-F1 0.004713804713804714 on epoch=46
05/20/2022 12:14:13 - INFO - __main__ - Step 660 Global step 660 Train loss 5.38 on epoch=47
05/20/2022 12:14:14 - INFO - __main__ - Step 670 Global step 670 Train loss 5.47 on epoch=47
05/20/2022 12:14:15 - INFO - __main__ - Step 680 Global step 680 Train loss 5.21 on epoch=48
05/20/2022 12:14:16 - INFO - __main__ - Step 690 Global step 690 Train loss 5.32 on epoch=49
05/20/2022 12:14:18 - INFO - __main__ - Step 700 Global step 700 Train loss 5.07 on epoch=49
05/20/2022 12:14:25 - INFO - __main__ - Global step 700 Train loss 5.29 Classification-F1 0.005952380952380953 on epoch=49
05/20/2022 12:14:25 - INFO - __main__ - Saving model with best Classification-F1: 0.0056737588652482265 -> 0.005952380952380953 on epoch=49, global_step=700
05/20/2022 12:14:26 - INFO - __main__ - Step 710 Global step 710 Train loss 5.28 on epoch=50
05/20/2022 12:14:28 - INFO - __main__ - Step 720 Global step 720 Train loss 5.05 on epoch=51
05/20/2022 12:14:29 - INFO - __main__ - Step 730 Global step 730 Train loss 5.24 on epoch=52
05/20/2022 12:14:30 - INFO - __main__ - Step 740 Global step 740 Train loss 5.28 on epoch=52
05/20/2022 12:14:31 - INFO - __main__ - Step 750 Global step 750 Train loss 5.09 on epoch=53
05/20/2022 12:14:42 - INFO - __main__ - Global step 750 Train loss 5.19 Classification-F1 0.00573394495412844 on epoch=53
05/20/2022 12:14:43 - INFO - __main__ - Step 760 Global step 760 Train loss 5.19 on epoch=54
05/20/2022 12:14:45 - INFO - __main__ - Step 770 Global step 770 Train loss 4.98 on epoch=54
05/20/2022 12:14:46 - INFO - __main__ - Step 780 Global step 780 Train loss 5.14 on epoch=55
05/20/2022 12:14:47 - INFO - __main__ - Step 790 Global step 790 Train loss 4.98 on epoch=56
05/20/2022 12:14:48 - INFO - __main__ - Step 800 Global step 800 Train loss 5.04 on epoch=57
05/20/2022 12:14:51 - INFO - __main__ - Global step 800 Train loss 5.06 Classification-F1 0.007446016381236037 on epoch=57
05/20/2022 12:14:51 - INFO - __main__ - Saving model with best Classification-F1: 0.005952380952380953 -> 0.007446016381236037 on epoch=57, global_step=800
05/20/2022 12:14:53 - INFO - __main__ - Step 810 Global step 810 Train loss 5.00 on epoch=57
05/20/2022 12:14:54 - INFO - __main__ - Step 820 Global step 820 Train loss 5.05 on epoch=58
05/20/2022 12:14:55 - INFO - __main__ - Step 830 Global step 830 Train loss 4.98 on epoch=59
05/20/2022 12:14:56 - INFO - __main__ - Step 840 Global step 840 Train loss 4.83 on epoch=59
05/20/2022 12:14:58 - INFO - __main__ - Step 850 Global step 850 Train loss 4.92 on epoch=60
05/20/2022 12:15:06 - INFO - __main__ - Global step 850 Train loss 4.96 Classification-F1 0.006211180124223602 on epoch=60
05/20/2022 12:15:07 - INFO - __main__ - Step 860 Global step 860 Train loss 4.83 on epoch=61
05/20/2022 12:15:08 - INFO - __main__ - Step 870 Global step 870 Train loss 4.95 on epoch=62
05/20/2022 12:15:10 - INFO - __main__ - Step 880 Global step 880 Train loss 4.94 on epoch=62
05/20/2022 12:15:11 - INFO - __main__ - Step 890 Global step 890 Train loss 4.79 on epoch=63
05/20/2022 12:15:12 - INFO - __main__ - Step 900 Global step 900 Train loss 4.92 on epoch=64
05/20/2022 12:15:15 - INFO - __main__ - Global step 900 Train loss 4.89 Classification-F1 0.007509386733416771 on epoch=64
05/20/2022 12:15:16 - INFO - __main__ - Saving model with best Classification-F1: 0.007446016381236037 -> 0.007509386733416771 on epoch=64, global_step=900
05/20/2022 12:15:17 - INFO - __main__ - Step 910 Global step 910 Train loss 4.81 on epoch=64
05/20/2022 12:15:18 - INFO - __main__ - Step 920 Global step 920 Train loss 4.87 on epoch=65
05/20/2022 12:15:19 - INFO - __main__ - Step 930 Global step 930 Train loss 4.68 on epoch=66
05/20/2022 12:15:20 - INFO - __main__ - Step 940 Global step 940 Train loss 4.84 on epoch=67
05/20/2022 12:15:22 - INFO - __main__ - Step 950 Global step 950 Train loss 4.77 on epoch=67
05/20/2022 12:15:24 - INFO - __main__ - Global step 950 Train loss 4.80 Classification-F1 0.009523809523809523 on epoch=67
05/20/2022 12:15:24 - INFO - __main__ - Saving model with best Classification-F1: 0.007509386733416771 -> 0.009523809523809523 on epoch=67, global_step=950
05/20/2022 12:15:25 - INFO - __main__ - Step 960 Global step 960 Train loss 4.83 on epoch=68
05/20/2022 12:15:27 - INFO - __main__ - Step 970 Global step 970 Train loss 4.81 on epoch=69
05/20/2022 12:15:28 - INFO - __main__ - Step 980 Global step 980 Train loss 4.78 on epoch=69
05/20/2022 12:15:29 - INFO - __main__ - Step 990 Global step 990 Train loss 4.75 on epoch=70
05/20/2022 12:15:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.70 on epoch=71
05/20/2022 12:15:33 - INFO - __main__ - Global step 1000 Train loss 4.77 Classification-F1 0.00892608089260809 on epoch=71
05/20/2022 12:15:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.75 on epoch=72
05/20/2022 12:15:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.71 on epoch=72
05/20/2022 12:15:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.71 on epoch=73
05/20/2022 12:15:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.72 on epoch=74
05/20/2022 12:15:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.60 on epoch=74
05/20/2022 12:15:41 - INFO - __main__ - Global step 1050 Train loss 4.70 Classification-F1 0.009523809523809523 on epoch=74
05/20/2022 12:15:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.63 on epoch=75
05/20/2022 12:15:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.52 on epoch=76
05/20/2022 12:15:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.75 on epoch=77
05/20/2022 12:15:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.58 on epoch=77
05/20/2022 12:15:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.52 on epoch=78
05/20/2022 12:15:49 - INFO - __main__ - Global step 1100 Train loss 4.60 Classification-F1 0.009523809523809523 on epoch=78
05/20/2022 12:15:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.48 on epoch=79
05/20/2022 12:15:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.62 on epoch=79
05/20/2022 12:15:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.57 on epoch=80
05/20/2022 12:15:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.55 on epoch=81
05/20/2022 12:15:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.55 on epoch=82
05/20/2022 12:15:58 - INFO - __main__ - Global step 1150 Train loss 4.55 Classification-F1 0.00892608089260809 on epoch=82
05/20/2022 12:16:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.52 on epoch=82
05/20/2022 12:16:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.53 on epoch=83
05/20/2022 12:16:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.55 on epoch=84
05/20/2022 12:16:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.29 on epoch=84
05/20/2022 12:16:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.34 on epoch=85
05/20/2022 12:16:07 - INFO - __main__ - Global step 1200 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=85
05/20/2022 12:16:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.42 on epoch=86
05/20/2022 12:16:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.38 on epoch=87
05/20/2022 12:16:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.34 on epoch=87
05/20/2022 12:16:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.48 on epoch=88
05/20/2022 12:16:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.47 on epoch=89
05/20/2022 12:16:15 - INFO - __main__ - Global step 1250 Train loss 4.42 Classification-F1 0.009523809523809523 on epoch=89
05/20/2022 12:16:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.25 on epoch=89
05/20/2022 12:16:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.31 on epoch=90
05/20/2022 12:16:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.29 on epoch=91
05/20/2022 12:16:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.33 on epoch=92
05/20/2022 12:16:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 4.22 on epoch=92
05/20/2022 12:16:23 - INFO - __main__ - Global step 1300 Train loss 4.28 Classification-F1 0.009523809523809523 on epoch=92
05/20/2022 12:16:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.24 on epoch=93
05/20/2022 12:16:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.42 on epoch=94
05/20/2022 12:16:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 4.10 on epoch=94
05/20/2022 12:16:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.05 on epoch=95
05/20/2022 12:16:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 4.05 on epoch=96
05/20/2022 12:16:31 - INFO - __main__ - Global step 1350 Train loss 4.17 Classification-F1 0.02009897221164827 on epoch=96
05/20/2022 12:16:31 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02009897221164827 on epoch=96, global_step=1350
05/20/2022 12:16:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 4.27 on epoch=97
05/20/2022 12:16:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 4.23 on epoch=97
05/20/2022 12:16:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 4.22 on epoch=98
05/20/2022 12:16:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 4.02 on epoch=99
05/20/2022 12:16:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 4.14 on epoch=99
05/20/2022 12:16:39 - INFO - __main__ - Global step 1400 Train loss 4.17 Classification-F1 0.015634944206372778 on epoch=99
05/20/2022 12:16:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 4.11 on epoch=100
05/20/2022 12:16:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 4.13 on epoch=101
05/20/2022 12:16:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 4.04 on epoch=102
05/20/2022 12:16:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 4.04 on epoch=102
05/20/2022 12:16:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 4.13 on epoch=103
05/20/2022 12:16:46 - INFO - __main__ - Global step 1450 Train loss 4.09 Classification-F1 0.010296010296010296 on epoch=103
05/20/2022 12:16:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 4.09 on epoch=104
05/20/2022 12:16:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 4.04 on epoch=104
05/20/2022 12:16:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 4.13 on epoch=105
05/20/2022 12:16:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 4.10 on epoch=106
05/20/2022 12:16:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 4.08 on epoch=107
05/20/2022 12:16:54 - INFO - __main__ - Global step 1500 Train loss 4.09 Classification-F1 0.015609152752009895 on epoch=107
05/20/2022 12:16:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.88 on epoch=107
05/20/2022 12:16:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 4.11 on epoch=108
05/20/2022 12:16:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 4.10 on epoch=109
05/20/2022 12:16:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 4.01 on epoch=109
05/20/2022 12:17:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.89 on epoch=110
05/20/2022 12:17:02 - INFO - __main__ - Global step 1550 Train loss 4.00 Classification-F1 0.015921262121870023 on epoch=110
05/20/2022 12:17:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 4.08 on epoch=111
05/20/2022 12:17:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 4.00 on epoch=112
05/20/2022 12:17:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.97 on epoch=112
05/20/2022 12:17:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 4.08 on epoch=113
05/20/2022 12:17:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.81 on epoch=114
05/20/2022 12:17:10 - INFO - __main__ - Global step 1600 Train loss 3.99 Classification-F1 0.010158730158730159 on epoch=114
05/20/2022 12:17:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.90 on epoch=114
05/20/2022 12:17:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.89 on epoch=115
05/20/2022 12:17:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.81 on epoch=116
05/20/2022 12:17:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.92 on epoch=117
05/20/2022 12:17:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.81 on epoch=117
05/20/2022 12:17:18 - INFO - __main__ - Global step 1650 Train loss 3.87 Classification-F1 0.009563658099222952 on epoch=117
05/20/2022 12:17:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.92 on epoch=118
05/20/2022 12:17:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.84 on epoch=119
05/20/2022 12:17:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.64 on epoch=119
05/20/2022 12:17:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.79 on epoch=120
05/20/2022 12:17:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.72 on epoch=121
05/20/2022 12:17:26 - INFO - __main__ - Global step 1700 Train loss 3.78 Classification-F1 0.009523809523809523 on epoch=121
05/20/2022 12:17:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.83 on epoch=122
05/20/2022 12:17:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.69 on epoch=122
05/20/2022 12:17:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.76 on epoch=123
05/20/2022 12:17:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.73 on epoch=124
05/20/2022 12:17:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.83 on epoch=124
05/20/2022 12:17:34 - INFO - __main__ - Global step 1750 Train loss 3.77 Classification-F1 0.019005478297513697 on epoch=124
05/20/2022 12:17:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.66 on epoch=125
05/20/2022 12:17:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.82 on epoch=126
05/20/2022 12:17:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.77 on epoch=127
05/20/2022 12:17:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.74 on epoch=127
05/20/2022 12:17:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.82 on epoch=128
05/20/2022 12:17:42 - INFO - __main__ - Global step 1800 Train loss 3.76 Classification-F1 0.013897866839043307 on epoch=128
05/20/2022 12:17:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.72 on epoch=129
05/20/2022 12:17:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.76 on epoch=129
05/20/2022 12:17:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.70 on epoch=130
05/20/2022 12:17:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.75 on epoch=131
05/20/2022 12:17:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.67 on epoch=132
05/20/2022 12:17:50 - INFO - __main__ - Global step 1850 Train loss 3.72 Classification-F1 0.009603841536614645 on epoch=132
05/20/2022 12:17:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.50 on epoch=132
05/20/2022 12:17:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.70 on epoch=133
05/20/2022 12:17:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.67 on epoch=134
05/20/2022 12:17:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.54 on epoch=134
05/20/2022 12:17:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.47 on epoch=135
05/20/2022 12:17:58 - INFO - __main__ - Global step 1900 Train loss 3.57 Classification-F1 0.01599953286035444 on epoch=135
05/20/2022 12:17:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.65 on epoch=136
05/20/2022 12:18:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.63 on epoch=137
05/20/2022 12:18:02 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.55 on epoch=137
05/20/2022 12:18:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.60 on epoch=138
05/20/2022 12:18:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.48 on epoch=139
05/20/2022 12:18:06 - INFO - __main__ - Global step 1950 Train loss 3.58 Classification-F1 0.015228818800247373 on epoch=139
05/20/2022 12:18:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.63 on epoch=139
05/20/2022 12:18:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.48 on epoch=140
05/20/2022 12:18:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.45 on epoch=141
05/20/2022 12:18:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.59 on epoch=142
05/20/2022 12:18:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.58 on epoch=142
05/20/2022 12:18:14 - INFO - __main__ - Global step 2000 Train loss 3.54 Classification-F1 0.015609152752009895 on epoch=142
05/20/2022 12:18:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.54 on epoch=143
05/20/2022 12:18:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.34 on epoch=144
05/20/2022 12:18:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.54 on epoch=144
05/20/2022 12:18:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.39 on epoch=145
05/20/2022 12:18:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.42 on epoch=146
05/20/2022 12:18:22 - INFO - __main__ - Global step 2050 Train loss 3.45 Classification-F1 0.010249839846252402 on epoch=146
05/20/2022 12:18:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.42 on epoch=147
05/20/2022 12:18:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.37 on epoch=147
05/20/2022 12:18:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.41 on epoch=148
05/20/2022 12:18:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.45 on epoch=149
05/20/2022 12:18:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.36 on epoch=149
05/20/2022 12:18:30 - INFO - __main__ - Global step 2100 Train loss 3.40 Classification-F1 0.02399566791890886 on epoch=149
05/20/2022 12:18:30 - INFO - __main__ - Saving model with best Classification-F1: 0.02009897221164827 -> 0.02399566791890886 on epoch=149, global_step=2100
05/20/2022 12:18:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.16 on epoch=150
05/20/2022 12:18:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.44 on epoch=151
05/20/2022 12:18:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.41 on epoch=152
05/20/2022 12:18:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.31 on epoch=152
05/20/2022 12:18:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.37 on epoch=153
05/20/2022 12:18:38 - INFO - __main__ - Global step 2150 Train loss 3.34 Classification-F1 0.020174346201743465 on epoch=153
05/20/2022 12:18:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.29 on epoch=154
05/20/2022 12:18:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.30 on epoch=154
05/20/2022 12:18:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.17 on epoch=155
05/20/2022 12:18:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.47 on epoch=156
05/20/2022 12:18:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.38 on epoch=157
05/20/2022 12:18:46 - INFO - __main__ - Global step 2200 Train loss 3.32 Classification-F1 0.019215714831873874 on epoch=157
05/20/2022 12:18:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.25 on epoch=157
05/20/2022 12:18:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.34 on epoch=158
05/20/2022 12:18:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 3.30 on epoch=159
05/20/2022 12:18:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.20 on epoch=159
05/20/2022 12:18:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 3.26 on epoch=160
05/20/2022 12:18:54 - INFO - __main__ - Global step 2250 Train loss 3.27 Classification-F1 0.016521110898620937 on epoch=160
05/20/2022 12:18:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.34 on epoch=161
05/20/2022 12:18:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.34 on epoch=162
05/20/2022 12:18:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.18 on epoch=162
05/20/2022 12:18:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 3.40 on epoch=163
05/20/2022 12:19:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.09 on epoch=164
05/20/2022 12:19:02 - INFO - __main__ - Global step 2300 Train loss 3.27 Classification-F1 0.024935224163651848 on epoch=164
05/20/2022 12:19:02 - INFO - __main__ - Saving model with best Classification-F1: 0.02399566791890886 -> 0.024935224163651848 on epoch=164, global_step=2300
05/20/2022 12:19:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.16 on epoch=164
05/20/2022 12:19:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.14 on epoch=165
05/20/2022 12:19:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 3.40 on epoch=166
05/20/2022 12:19:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.31 on epoch=167
05/20/2022 12:19:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.07 on epoch=167
05/20/2022 12:19:10 - INFO - __main__ - Global step 2350 Train loss 3.22 Classification-F1 0.028674388674388675 on epoch=167
05/20/2022 12:19:10 - INFO - __main__ - Saving model with best Classification-F1: 0.024935224163651848 -> 0.028674388674388675 on epoch=167, global_step=2350
05/20/2022 12:19:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.19 on epoch=168
05/20/2022 12:19:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 3.13 on epoch=169
05/20/2022 12:19:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 3.15 on epoch=169
05/20/2022 12:19:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 3.07 on epoch=170
05/20/2022 12:19:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 3.24 on epoch=171
05/20/2022 12:19:18 - INFO - __main__ - Global step 2400 Train loss 3.16 Classification-F1 0.0343266447040032 on epoch=171
05/20/2022 12:19:18 - INFO - __main__ - Saving model with best Classification-F1: 0.028674388674388675 -> 0.0343266447040032 on epoch=171, global_step=2400
05/20/2022 12:19:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.21 on epoch=172
05/20/2022 12:19:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.01 on epoch=172
05/20/2022 12:19:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.22 on epoch=173
05/20/2022 12:19:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 3.05 on epoch=174
05/20/2022 12:19:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.22 on epoch=174
05/20/2022 12:19:26 - INFO - __main__ - Global step 2450 Train loss 3.14 Classification-F1 0.023751561163714945 on epoch=174
05/20/2022 12:19:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 3.09 on epoch=175
05/20/2022 12:19:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 3.13 on epoch=176
05/20/2022 12:19:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 3.13 on epoch=177
05/20/2022 12:19:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 3.02 on epoch=177
05/20/2022 12:19:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.11 on epoch=178
05/20/2022 12:19:34 - INFO - __main__ - Global step 2500 Train loss 3.10 Classification-F1 0.0445169970822337 on epoch=178
05/20/2022 12:19:34 - INFO - __main__ - Saving model with best Classification-F1: 0.0343266447040032 -> 0.0445169970822337 on epoch=178, global_step=2500
05/20/2022 12:19:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 3.12 on epoch=179
05/20/2022 12:19:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 3.15 on epoch=179
05/20/2022 12:19:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 3.03 on epoch=180
05/20/2022 12:19:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.14 on epoch=181
05/20/2022 12:19:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.02 on epoch=182
05/20/2022 12:19:42 - INFO - __main__ - Global step 2550 Train loss 3.09 Classification-F1 0.022368421052631576 on epoch=182
05/20/2022 12:19:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.98 on epoch=182
05/20/2022 12:19:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 3.05 on epoch=183
05/20/2022 12:19:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 3.16 on epoch=184
05/20/2022 12:19:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.99 on epoch=184
05/20/2022 12:19:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 3.14 on epoch=185
05/20/2022 12:19:50 - INFO - __main__ - Global step 2600 Train loss 3.07 Classification-F1 0.032536199432751156 on epoch=185
05/20/2022 12:19:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 3.12 on epoch=186
05/20/2022 12:19:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 3.16 on epoch=187
05/20/2022 12:19:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.99 on epoch=187
05/20/2022 12:19:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 3.04 on epoch=188
05/20/2022 12:19:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.99 on epoch=189
05/20/2022 12:19:58 - INFO - __main__ - Global step 2650 Train loss 3.06 Classification-F1 0.026552742411773248 on epoch=189
05/20/2022 12:19:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 3.09 on epoch=189
05/20/2022 12:20:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 3.07 on epoch=190
05/20/2022 12:20:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 3.12 on epoch=191
05/20/2022 12:20:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 3.04 on epoch=192
05/20/2022 12:20:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.89 on epoch=192
05/20/2022 12:20:06 - INFO - __main__ - Global step 2700 Train loss 3.04 Classification-F1 0.025995564068958563 on epoch=192
05/20/2022 12:20:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 3.05 on epoch=193
05/20/2022 12:20:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.95 on epoch=194
05/20/2022 12:20:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.89 on epoch=194
05/20/2022 12:20:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.73 on epoch=195
05/20/2022 12:20:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/20/2022 12:20:14 - INFO - __main__ - Global step 2750 Train loss 2.91 Classification-F1 0.014339203423304804 on epoch=196
05/20/2022 12:20:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.87 on epoch=197
05/20/2022 12:20:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.97 on epoch=197
05/20/2022 12:20:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 3.02 on epoch=198
05/20/2022 12:20:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.95 on epoch=199
05/20/2022 12:20:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 3.06 on epoch=199
05/20/2022 12:20:22 - INFO - __main__ - Global step 2800 Train loss 2.97 Classification-F1 0.009563658099222952 on epoch=199
05/20/2022 12:20:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.83 on epoch=200
05/20/2022 12:20:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 3.07 on epoch=201
05/20/2022 12:20:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 3.03 on epoch=202
05/20/2022 12:20:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.95 on epoch=202
05/20/2022 12:20:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.95 on epoch=203
05/20/2022 12:20:31 - INFO - __main__ - Global step 2850 Train loss 2.97 Classification-F1 0.009523809523809523 on epoch=203
05/20/2022 12:20:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.79 on epoch=204
05/20/2022 12:20:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.90 on epoch=204
05/20/2022 12:20:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.75 on epoch=205
05/20/2022 12:20:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.99 on epoch=206
05/20/2022 12:20:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.97 on epoch=207
05/20/2022 12:20:38 - INFO - __main__ - Global step 2900 Train loss 2.88 Classification-F1 0.0291613990729035 on epoch=207
05/20/2022 12:20:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.79 on epoch=207
05/20/2022 12:20:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.96 on epoch=208
05/20/2022 12:20:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.98 on epoch=209
05/20/2022 12:20:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.88 on epoch=209
05/20/2022 12:20:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.76 on epoch=210
05/20/2022 12:20:46 - INFO - __main__ - Global step 2950 Train loss 2.88 Classification-F1 0.036080666570998066 on epoch=210
05/20/2022 12:20:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.89 on epoch=211
05/20/2022 12:20:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.80 on epoch=212
05/20/2022 12:20:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.83 on epoch=212
05/20/2022 12:20:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 3.01 on epoch=213
05/20/2022 12:20:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.78 on epoch=214
05/20/2022 12:20:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:20:54 - INFO - __main__ - Printing 3 examples
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 12:20:54 - INFO - __main__ - ['Company']
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 12:20:54 - INFO - __main__ - ['Company']
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 12:20:54 - INFO - __main__ - ['Company']
05/20/2022 12:20:54 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:20:54 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:20:54 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:20:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:20:54 - INFO - __main__ - Printing 3 examples
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 12:20:54 - INFO - __main__ - ['Company']
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 12:20:54 - INFO - __main__ - ['Company']
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 12:20:54 - INFO - __main__ - ['Company']
05/20/2022 12:20:54 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:20:54 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:20:54 - INFO - __main__ - Global step 3000 Train loss 2.86 Classification-F1 0.025317369666313125 on epoch=214
05/20/2022 12:20:54 - INFO - __main__ - save last model!
05/20/2022 12:20:54 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:20:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 12:20:54 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 12:20:54 - INFO - __main__ - Printing 3 examples
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 12:20:54 - INFO - __main__ - ['Animal']
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 12:20:54 - INFO - __main__ - ['Animal']
05/20/2022 12:20:54 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 12:20:54 - INFO - __main__ - ['Village']
05/20/2022 12:20:54 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:20:56 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:21:00 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 12:21:01 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:21:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:21:01 - INFO - __main__ - Starting training!
05/20/2022 12:21:29 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/20/2022 12:21:29 - INFO - __main__ - Classification-F1 on test data: 0.0202
05/20/2022 12:21:29 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.0445169970822337, test_performance=0.02022454943077747
05/20/2022 12:21:29 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/20/2022 12:21:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:21:30 - INFO - __main__ - Printing 3 examples
05/20/2022 12:21:30 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 12:21:30 - INFO - __main__ - ['Company']
05/20/2022 12:21:30 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 12:21:30 - INFO - __main__ - ['Company']
05/20/2022 12:21:30 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 12:21:30 - INFO - __main__ - ['Company']
05/20/2022 12:21:30 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:21:30 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:21:30 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:21:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:21:30 - INFO - __main__ - Printing 3 examples
05/20/2022 12:21:30 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 12:21:30 - INFO - __main__ - ['Company']
05/20/2022 12:21:30 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 12:21:30 - INFO - __main__ - ['Company']
05/20/2022 12:21:30 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 12:21:30 - INFO - __main__ - ['Company']
05/20/2022 12:21:30 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:21:30 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:21:30 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:21:36 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:21:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:21:36 - INFO - __main__ - Starting training!
05/20/2022 12:21:37 - INFO - __main__ - Step 10 Global step 10 Train loss 7.28 on epoch=0
05/20/2022 12:21:39 - INFO - __main__ - Step 20 Global step 20 Train loss 7.48 on epoch=1
05/20/2022 12:21:40 - INFO - __main__ - Step 30 Global step 30 Train loss 7.28 on epoch=2
05/20/2022 12:21:41 - INFO - __main__ - Step 40 Global step 40 Train loss 6.75 on epoch=2
05/20/2022 12:21:42 - INFO - __main__ - Step 50 Global step 50 Train loss 7.08 on epoch=3
05/20/2022 12:22:47 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/20/2022 12:22:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 12:22:48 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/20/2022 12:22:50 - INFO - __main__ - Step 70 Global step 70 Train loss 6.87 on epoch=4
05/20/2022 12:22:51 - INFO - __main__ - Step 80 Global step 80 Train loss 6.49 on epoch=5
05/20/2022 12:22:52 - INFO - __main__ - Step 90 Global step 90 Train loss 6.63 on epoch=6
05/20/2022 12:22:53 - INFO - __main__ - Step 100 Global step 100 Train loss 6.46 on epoch=7
05/20/2022 12:23:44 - INFO - __main__ - Global step 100 Train loss 6.64 Classification-F1 0.0 on epoch=7
05/20/2022 12:23:45 - INFO - __main__ - Step 110 Global step 110 Train loss 6.14 on epoch=7
05/20/2022 12:23:46 - INFO - __main__ - Step 120 Global step 120 Train loss 6.29 on epoch=8
05/20/2022 12:23:48 - INFO - __main__ - Step 130 Global step 130 Train loss 5.98 on epoch=9
05/20/2022 12:23:49 - INFO - __main__ - Step 140 Global step 140 Train loss 6.19 on epoch=9
05/20/2022 12:23:50 - INFO - __main__ - Step 150 Global step 150 Train loss 5.83 on epoch=10
05/20/2022 12:25:04 - INFO - __main__ - Global step 150 Train loss 6.08 Classification-F1 0.0 on epoch=10
05/20/2022 12:25:05 - INFO - __main__ - Step 160 Global step 160 Train loss 5.99 on epoch=11
05/20/2022 12:25:07 - INFO - __main__ - Step 170 Global step 170 Train loss 5.93 on epoch=12
05/20/2022 12:25:08 - INFO - __main__ - Step 180 Global step 180 Train loss 5.64 on epoch=12
05/20/2022 12:25:09 - INFO - __main__ - Step 190 Global step 190 Train loss 5.71 on epoch=13
05/20/2022 12:25:10 - INFO - __main__ - Step 200 Global step 200 Train loss 5.54 on epoch=14
05/20/2022 12:25:48 - INFO - __main__ - Global step 200 Train loss 5.76 Classification-F1 0.0 on epoch=14
05/20/2022 12:25:49 - INFO - __main__ - Step 210 Global step 210 Train loss 5.75 on epoch=14
05/20/2022 12:25:50 - INFO - __main__ - Step 220 Global step 220 Train loss 5.26 on epoch=15
05/20/2022 12:25:52 - INFO - __main__ - Step 230 Global step 230 Train loss 5.54 on epoch=16
05/20/2022 12:25:53 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=17
05/20/2022 12:25:54 - INFO - __main__ - Step 250 Global step 250 Train loss 5.24 on epoch=17
05/20/2022 12:26:49 - INFO - __main__ - Global step 250 Train loss 5.44 Classification-F1 0.0036215482118605704 on epoch=17
05/20/2022 12:26:49 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0036215482118605704 on epoch=17, global_step=250
05/20/2022 12:26:51 - INFO - __main__ - Step 260 Global step 260 Train loss 5.12 on epoch=18
05/20/2022 12:26:52 - INFO - __main__ - Step 270 Global step 270 Train loss 5.15 on epoch=19
05/20/2022 12:26:53 - INFO - __main__ - Step 280 Global step 280 Train loss 5.18 on epoch=19
05/20/2022 12:26:54 - INFO - __main__ - Step 290 Global step 290 Train loss 4.81 on epoch=20
05/20/2022 12:26:56 - INFO - __main__ - Step 300 Global step 300 Train loss 5.04 on epoch=21
05/20/2022 12:27:03 - INFO - __main__ - Global step 300 Train loss 5.06 Classification-F1 0.008113590263691683 on epoch=21
05/20/2022 12:27:03 - INFO - __main__ - Saving model with best Classification-F1: 0.0036215482118605704 -> 0.008113590263691683 on epoch=21, global_step=300
05/20/2022 12:27:04 - INFO - __main__ - Step 310 Global step 310 Train loss 4.93 on epoch=22
05/20/2022 12:27:05 - INFO - __main__ - Step 320 Global step 320 Train loss 4.79 on epoch=22
05/20/2022 12:27:07 - INFO - __main__ - Step 330 Global step 330 Train loss 4.68 on epoch=23
05/20/2022 12:27:08 - INFO - __main__ - Step 340 Global step 340 Train loss 4.45 on epoch=24
05/20/2022 12:27:09 - INFO - __main__ - Step 350 Global step 350 Train loss 4.61 on epoch=24
05/20/2022 12:27:12 - INFO - __main__ - Global step 350 Train loss 4.69 Classification-F1 0.009523809523809523 on epoch=24
05/20/2022 12:27:12 - INFO - __main__ - Saving model with best Classification-F1: 0.008113590263691683 -> 0.009523809523809523 on epoch=24, global_step=350
05/20/2022 12:27:13 - INFO - __main__ - Step 360 Global step 360 Train loss 4.52 on epoch=25
05/20/2022 12:27:14 - INFO - __main__ - Step 370 Global step 370 Train loss 4.37 on epoch=26
05/20/2022 12:27:15 - INFO - __main__ - Step 380 Global step 380 Train loss 4.51 on epoch=27
05/20/2022 12:27:17 - INFO - __main__ - Step 390 Global step 390 Train loss 4.33 on epoch=27
05/20/2022 12:27:18 - INFO - __main__ - Step 400 Global step 400 Train loss 4.40 on epoch=28
05/20/2022 12:27:20 - INFO - __main__ - Global step 400 Train loss 4.43 Classification-F1 0.009603841536614645 on epoch=28
05/20/2022 12:27:20 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009603841536614645 on epoch=28, global_step=400
05/20/2022 12:27:21 - INFO - __main__ - Step 410 Global step 410 Train loss 4.22 on epoch=29
05/20/2022 12:27:22 - INFO - __main__ - Step 420 Global step 420 Train loss 4.52 on epoch=29
05/20/2022 12:27:24 - INFO - __main__ - Step 430 Global step 430 Train loss 4.05 on epoch=30
05/20/2022 12:27:25 - INFO - __main__ - Step 440 Global step 440 Train loss 4.11 on epoch=31
05/20/2022 12:27:26 - INFO - __main__ - Step 450 Global step 450 Train loss 4.07 on epoch=32
05/20/2022 12:27:28 - INFO - __main__ - Global step 450 Train loss 4.19 Classification-F1 0.02676089201318559 on epoch=32
05/20/2022 12:27:28 - INFO - __main__ - Saving model with best Classification-F1: 0.009603841536614645 -> 0.02676089201318559 on epoch=32, global_step=450
05/20/2022 12:27:29 - INFO - __main__ - Step 460 Global step 460 Train loss 4.03 on epoch=32
05/20/2022 12:27:30 - INFO - __main__ - Step 470 Global step 470 Train loss 4.07 on epoch=33
05/20/2022 12:27:32 - INFO - __main__ - Step 480 Global step 480 Train loss 3.92 on epoch=34
05/20/2022 12:27:33 - INFO - __main__ - Step 490 Global step 490 Train loss 4.11 on epoch=34
05/20/2022 12:27:34 - INFO - __main__ - Step 500 Global step 500 Train loss 3.79 on epoch=35
05/20/2022 12:27:36 - INFO - __main__ - Global step 500 Train loss 3.98 Classification-F1 0.03431197040219596 on epoch=35
05/20/2022 12:27:36 - INFO - __main__ - Saving model with best Classification-F1: 0.02676089201318559 -> 0.03431197040219596 on epoch=35, global_step=500
05/20/2022 12:27:37 - INFO - __main__ - Step 510 Global step 510 Train loss 3.82 on epoch=36
05/20/2022 12:27:39 - INFO - __main__ - Step 520 Global step 520 Train loss 3.88 on epoch=37
05/20/2022 12:27:40 - INFO - __main__ - Step 530 Global step 530 Train loss 3.88 on epoch=37
05/20/2022 12:27:41 - INFO - __main__ - Step 540 Global step 540 Train loss 3.74 on epoch=38
05/20/2022 12:27:42 - INFO - __main__ - Step 550 Global step 550 Train loss 3.80 on epoch=39
05/20/2022 12:27:44 - INFO - __main__ - Global step 550 Train loss 3.83 Classification-F1 0.009523809523809523 on epoch=39
05/20/2022 12:27:45 - INFO - __main__ - Step 560 Global step 560 Train loss 3.88 on epoch=39
05/20/2022 12:27:47 - INFO - __main__ - Step 570 Global step 570 Train loss 3.74 on epoch=40
05/20/2022 12:27:48 - INFO - __main__ - Step 580 Global step 580 Train loss 3.75 on epoch=41
05/20/2022 12:27:49 - INFO - __main__ - Step 590 Global step 590 Train loss 3.57 on epoch=42
05/20/2022 12:27:50 - INFO - __main__ - Step 600 Global step 600 Train loss 3.68 on epoch=42
05/20/2022 12:27:52 - INFO - __main__ - Global step 600 Train loss 3.72 Classification-F1 0.02999268220516973 on epoch=42
05/20/2022 12:27:53 - INFO - __main__ - Step 610 Global step 610 Train loss 3.60 on epoch=43
05/20/2022 12:27:55 - INFO - __main__ - Step 620 Global step 620 Train loss 3.60 on epoch=44
05/20/2022 12:27:56 - INFO - __main__ - Step 630 Global step 630 Train loss 3.65 on epoch=44
05/20/2022 12:27:57 - INFO - __main__ - Step 640 Global step 640 Train loss 3.40 on epoch=45
05/20/2022 12:27:58 - INFO - __main__ - Step 650 Global step 650 Train loss 3.63 on epoch=46
05/20/2022 12:28:00 - INFO - __main__ - Global step 650 Train loss 3.58 Classification-F1 0.009523809523809523 on epoch=46
05/20/2022 12:28:01 - INFO - __main__ - Step 660 Global step 660 Train loss 3.47 on epoch=47
05/20/2022 12:28:03 - INFO - __main__ - Step 670 Global step 670 Train loss 3.49 on epoch=47
05/20/2022 12:28:04 - INFO - __main__ - Step 680 Global step 680 Train loss 3.38 on epoch=48
05/20/2022 12:28:05 - INFO - __main__ - Step 690 Global step 690 Train loss 3.39 on epoch=49
05/20/2022 12:28:06 - INFO - __main__ - Step 700 Global step 700 Train loss 3.36 on epoch=49
05/20/2022 12:28:08 - INFO - __main__ - Global step 700 Train loss 3.42 Classification-F1 0.017795193914596903 on epoch=49
05/20/2022 12:28:09 - INFO - __main__ - Step 710 Global step 710 Train loss 3.26 on epoch=50
05/20/2022 12:28:11 - INFO - __main__ - Step 720 Global step 720 Train loss 3.27 on epoch=51
05/20/2022 12:28:12 - INFO - __main__ - Step 730 Global step 730 Train loss 3.39 on epoch=52
05/20/2022 12:28:13 - INFO - __main__ - Step 740 Global step 740 Train loss 3.29 on epoch=52
05/20/2022 12:28:14 - INFO - __main__ - Step 750 Global step 750 Train loss 3.24 on epoch=53
05/20/2022 12:28:16 - INFO - __main__ - Global step 750 Train loss 3.29 Classification-F1 0.015657161358958345 on epoch=53
05/20/2022 12:28:18 - INFO - __main__ - Step 760 Global step 760 Train loss 3.19 on epoch=54
05/20/2022 12:28:19 - INFO - __main__ - Step 770 Global step 770 Train loss 3.35 on epoch=54
05/20/2022 12:28:20 - INFO - __main__ - Step 780 Global step 780 Train loss 3.34 on epoch=55
05/20/2022 12:28:21 - INFO - __main__ - Step 790 Global step 790 Train loss 3.26 on epoch=56
05/20/2022 12:28:23 - INFO - __main__ - Step 800 Global step 800 Train loss 3.06 on epoch=57
05/20/2022 12:28:24 - INFO - __main__ - Global step 800 Train loss 3.24 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 12:28:26 - INFO - __main__ - Step 810 Global step 810 Train loss 3.17 on epoch=57
05/20/2022 12:28:27 - INFO - __main__ - Step 820 Global step 820 Train loss 3.00 on epoch=58
05/20/2022 12:28:28 - INFO - __main__ - Step 830 Global step 830 Train loss 3.12 on epoch=59
05/20/2022 12:28:29 - INFO - __main__ - Step 840 Global step 840 Train loss 3.11 on epoch=59
05/20/2022 12:28:31 - INFO - __main__ - Step 850 Global step 850 Train loss 3.07 on epoch=60
05/20/2022 12:28:32 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.009563658099222952 on epoch=60
05/20/2022 12:28:34 - INFO - __main__ - Step 860 Global step 860 Train loss 2.94 on epoch=61
05/20/2022 12:28:35 - INFO - __main__ - Step 870 Global step 870 Train loss 3.16 on epoch=62
05/20/2022 12:28:36 - INFO - __main__ - Step 880 Global step 880 Train loss 3.01 on epoch=62
05/20/2022 12:28:37 - INFO - __main__ - Step 890 Global step 890 Train loss 3.01 on epoch=63
05/20/2022 12:28:39 - INFO - __main__ - Step 900 Global step 900 Train loss 3.07 on epoch=64
05/20/2022 12:28:41 - INFO - __main__ - Global step 900 Train loss 3.04 Classification-F1 0.009523809523809523 on epoch=64
05/20/2022 12:28:42 - INFO - __main__ - Step 910 Global step 910 Train loss 3.07 on epoch=64
05/20/2022 12:28:43 - INFO - __main__ - Step 920 Global step 920 Train loss 2.99 on epoch=65
05/20/2022 12:28:44 - INFO - __main__ - Step 930 Global step 930 Train loss 3.04 on epoch=66
05/20/2022 12:28:46 - INFO - __main__ - Step 940 Global step 940 Train loss 3.00 on epoch=67
05/20/2022 12:28:47 - INFO - __main__ - Step 950 Global step 950 Train loss 3.12 on epoch=67
05/20/2022 12:28:49 - INFO - __main__ - Global step 950 Train loss 3.04 Classification-F1 0.009726443768996961 on epoch=67
05/20/2022 12:28:50 - INFO - __main__ - Step 960 Global step 960 Train loss 2.83 on epoch=68
05/20/2022 12:28:51 - INFO - __main__ - Step 970 Global step 970 Train loss 2.75 on epoch=69
05/20/2022 12:28:52 - INFO - __main__ - Step 980 Global step 980 Train loss 2.80 on epoch=69
05/20/2022 12:28:54 - INFO - __main__ - Step 990 Global step 990 Train loss 2.83 on epoch=70
05/20/2022 12:28:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.01 on epoch=71
05/20/2022 12:28:57 - INFO - __main__ - Global step 1000 Train loss 2.84 Classification-F1 0.01800720288115246 on epoch=71
05/20/2022 12:28:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.95 on epoch=72
05/20/2022 12:28:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.94 on epoch=72
05/20/2022 12:29:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.91 on epoch=73
05/20/2022 12:29:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.88 on epoch=74
05/20/2022 12:29:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.88 on epoch=74
05/20/2022 12:29:05 - INFO - __main__ - Global step 1050 Train loss 2.91 Classification-F1 0.009894867037724181 on epoch=74
05/20/2022 12:29:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.91 on epoch=75
05/20/2022 12:29:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.66 on epoch=76
05/20/2022 12:29:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.75 on epoch=77
05/20/2022 12:29:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.83 on epoch=77
05/20/2022 12:29:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.86 on epoch=78
05/20/2022 12:29:14 - INFO - __main__ - Global step 1100 Train loss 2.80 Classification-F1 0.02989399980550423 on epoch=78
05/20/2022 12:29:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.80 on epoch=79
05/20/2022 12:29:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.70 on epoch=79
05/20/2022 12:29:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.80 on epoch=80
05/20/2022 12:29:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.76 on epoch=81
05/20/2022 12:29:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.83 on epoch=82
05/20/2022 12:29:22 - INFO - __main__ - Global step 1150 Train loss 2.78 Classification-F1 0.024187321579100227 on epoch=82
05/20/2022 12:29:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/20/2022 12:29:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.70 on epoch=83
05/20/2022 12:29:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.51 on epoch=84
05/20/2022 12:29:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.68 on epoch=84
05/20/2022 12:29:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.60 on epoch=85
05/20/2022 12:29:31 - INFO - __main__ - Global step 1200 Train loss 2.66 Classification-F1 0.031015037593984968 on epoch=85
05/20/2022 12:29:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.55 on epoch=86
05/20/2022 12:29:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.72 on epoch=87
05/20/2022 12:29:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.62 on epoch=87
05/20/2022 12:29:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.63 on epoch=88
05/20/2022 12:29:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.59 on epoch=89
05/20/2022 12:29:39 - INFO - __main__ - Global step 1250 Train loss 2.63 Classification-F1 0.023548964099097198 on epoch=89
05/20/2022 12:29:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.65 on epoch=89
05/20/2022 12:29:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.60 on epoch=90
05/20/2022 12:29:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.61 on epoch=91
05/20/2022 12:29:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.61 on epoch=92
05/20/2022 12:29:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.69 on epoch=92
05/20/2022 12:29:48 - INFO - __main__ - Global step 1300 Train loss 2.63 Classification-F1 0.02614980183775942 on epoch=92
05/20/2022 12:29:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.57 on epoch=93
05/20/2022 12:29:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.55 on epoch=94
05/20/2022 12:29:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.61 on epoch=94
05/20/2022 12:29:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.48 on epoch=95
05/20/2022 12:29:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.51 on epoch=96
05/20/2022 12:29:56 - INFO - __main__ - Global step 1350 Train loss 2.54 Classification-F1 0.014948084496956676 on epoch=96
05/20/2022 12:29:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.51 on epoch=97
05/20/2022 12:29:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.55 on epoch=97
05/20/2022 12:30:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.54 on epoch=98
05/20/2022 12:30:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.58 on epoch=99
05/20/2022 12:30:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.73 on epoch=99
05/20/2022 12:30:04 - INFO - __main__ - Global step 1400 Train loss 2.58 Classification-F1 0.03706672009617311 on epoch=99
05/20/2022 12:30:04 - INFO - __main__ - Saving model with best Classification-F1: 0.03431197040219596 -> 0.03706672009617311 on epoch=99, global_step=1400
05/20/2022 12:30:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.43 on epoch=100
05/20/2022 12:30:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.63 on epoch=101
05/20/2022 12:30:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.68 on epoch=102
05/20/2022 12:30:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.56 on epoch=102
05/20/2022 12:30:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.52 on epoch=103
05/20/2022 12:30:12 - INFO - __main__ - Global step 1450 Train loss 2.57 Classification-F1 0.02634125134125134 on epoch=103
05/20/2022 12:30:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.49 on epoch=104
05/20/2022 12:30:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.48 on epoch=104
05/20/2022 12:30:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.46 on epoch=105
05/20/2022 12:30:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.60 on epoch=106
05/20/2022 12:30:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.55 on epoch=107
05/20/2022 12:30:20 - INFO - __main__ - Global step 1500 Train loss 2.51 Classification-F1 0.013309671694764864 on epoch=107
05/20/2022 12:30:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.53 on epoch=107
05/20/2022 12:30:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.59 on epoch=108
05/20/2022 12:30:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.56 on epoch=109
05/20/2022 12:30:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=109
05/20/2022 12:30:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.54 on epoch=110
05/20/2022 12:30:29 - INFO - __main__ - Global step 1550 Train loss 2.55 Classification-F1 0.01713875205254516 on epoch=110
05/20/2022 12:30:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.49 on epoch=111
05/20/2022 12:30:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.51 on epoch=112
05/20/2022 12:30:32 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.54 on epoch=112
05/20/2022 12:30:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.45 on epoch=113
05/20/2022 12:30:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.44 on epoch=114
05/20/2022 12:30:37 - INFO - __main__ - Global step 1600 Train loss 2.48 Classification-F1 0.009920634920634922 on epoch=114
05/20/2022 12:30:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.35 on epoch=114
05/20/2022 12:30:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.51 on epoch=115
05/20/2022 12:30:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.43 on epoch=116
05/20/2022 12:30:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.42 on epoch=117
05/20/2022 12:30:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.43 on epoch=117
05/20/2022 12:30:45 - INFO - __main__ - Global step 1650 Train loss 2.43 Classification-F1 0.009523809523809523 on epoch=117
05/20/2022 12:30:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.40 on epoch=118
05/20/2022 12:30:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.47 on epoch=119
05/20/2022 12:30:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.30 on epoch=119
05/20/2022 12:30:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.45 on epoch=120
05/20/2022 12:30:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.29 on epoch=121
05/20/2022 12:30:53 - INFO - __main__ - Global step 1700 Train loss 2.38 Classification-F1 0.04844822402611347 on epoch=121
05/20/2022 12:30:53 - INFO - __main__ - Saving model with best Classification-F1: 0.03706672009617311 -> 0.04844822402611347 on epoch=121, global_step=1700
05/20/2022 12:30:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.31 on epoch=122
05/20/2022 12:30:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.34 on epoch=122
05/20/2022 12:30:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.40 on epoch=123
05/20/2022 12:30:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.26 on epoch=124
05/20/2022 12:30:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.39 on epoch=124
05/20/2022 12:31:01 - INFO - __main__ - Global step 1750 Train loss 2.34 Classification-F1 0.048214285714285716 on epoch=124
05/20/2022 12:31:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.37 on epoch=125
05/20/2022 12:31:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.28 on epoch=126
05/20/2022 12:31:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.33 on epoch=127
05/20/2022 12:31:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.31 on epoch=127
05/20/2022 12:31:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.36 on epoch=128
05/20/2022 12:31:09 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.023325027685492803 on epoch=128
05/20/2022 12:31:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.22 on epoch=129
05/20/2022 12:31:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.23 on epoch=129
05/20/2022 12:31:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.22 on epoch=130
05/20/2022 12:31:14 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.33 on epoch=131
05/20/2022 12:31:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.30 on epoch=132
05/20/2022 12:31:17 - INFO - __main__ - Global step 1850 Train loss 2.26 Classification-F1 0.020835310868533463 on epoch=132
05/20/2022 12:31:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.34 on epoch=132
05/20/2022 12:31:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.31 on epoch=133
05/20/2022 12:31:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.11 on epoch=134
05/20/2022 12:31:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.18 on epoch=134
05/20/2022 12:31:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.20 on epoch=135
05/20/2022 12:31:25 - INFO - __main__ - Global step 1900 Train loss 2.23 Classification-F1 0.025723806268919052 on epoch=135
05/20/2022 12:31:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.35 on epoch=136
05/20/2022 12:31:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.18 on epoch=137
05/20/2022 12:31:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.19 on epoch=137
05/20/2022 12:31:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.26 on epoch=138
05/20/2022 12:31:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.24 on epoch=139
05/20/2022 12:31:33 - INFO - __main__ - Global step 1950 Train loss 2.24 Classification-F1 0.022740065293256784 on epoch=139
05/20/2022 12:31:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.07 on epoch=139
05/20/2022 12:31:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.21 on epoch=140
05/20/2022 12:31:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.26 on epoch=141
05/20/2022 12:31:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.18 on epoch=142
05/20/2022 12:31:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.22 on epoch=142
05/20/2022 12:31:42 - INFO - __main__ - Global step 2000 Train loss 2.19 Classification-F1 0.02677775229942164 on epoch=142
05/20/2022 12:31:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.29 on epoch=143
05/20/2022 12:31:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.10 on epoch=144
05/20/2022 12:31:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.21 on epoch=144
05/20/2022 12:31:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.15 on epoch=145
05/20/2022 12:31:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.07 on epoch=146
05/20/2022 12:31:50 - INFO - __main__ - Global step 2050 Train loss 2.16 Classification-F1 0.03790954219525648 on epoch=146
05/20/2022 12:31:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.16 on epoch=147
05/20/2022 12:31:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.04 on epoch=147
05/20/2022 12:31:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.01 on epoch=148
05/20/2022 12:31:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.17 on epoch=149
05/20/2022 12:31:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.03 on epoch=149
05/20/2022 12:31:58 - INFO - __main__ - Global step 2100 Train loss 2.08 Classification-F1 0.03715874667209773 on epoch=149
05/20/2022 12:31:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.03 on epoch=150
05/20/2022 12:32:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.96 on epoch=151
05/20/2022 12:32:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.05 on epoch=152
05/20/2022 12:32:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.17 on epoch=152
05/20/2022 12:32:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.98 on epoch=153
05/20/2022 12:32:06 - INFO - __main__ - Global step 2150 Train loss 2.04 Classification-F1 0.03395922327520234 on epoch=153
05/20/2022 12:32:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.14 on epoch=154
05/20/2022 12:32:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.12 on epoch=154
05/20/2022 12:32:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.01 on epoch=155
05/20/2022 12:32:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.86 on epoch=156
05/20/2022 12:32:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.06 on epoch=157
05/20/2022 12:32:14 - INFO - __main__ - Global step 2200 Train loss 2.04 Classification-F1 0.05662044072948329 on epoch=157
05/20/2022 12:32:14 - INFO - __main__ - Saving model with best Classification-F1: 0.04844822402611347 -> 0.05662044072948329 on epoch=157, global_step=2200
05/20/2022 12:32:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.00 on epoch=157
05/20/2022 12:32:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.04 on epoch=158
05/20/2022 12:32:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.96 on epoch=159
05/20/2022 12:32:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.06 on epoch=159
05/20/2022 12:32:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.99 on epoch=160
05/20/2022 12:32:22 - INFO - __main__ - Global step 2250 Train loss 2.01 Classification-F1 0.062470170212105706 on epoch=160
05/20/2022 12:32:22 - INFO - __main__ - Saving model with best Classification-F1: 0.05662044072948329 -> 0.062470170212105706 on epoch=160, global_step=2250
05/20/2022 12:32:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.08 on epoch=161
05/20/2022 12:32:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.99 on epoch=162
05/20/2022 12:32:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.96 on epoch=162
05/20/2022 12:32:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.98 on epoch=163
05/20/2022 12:32:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.94 on epoch=164
05/20/2022 12:32:30 - INFO - __main__ - Global step 2300 Train loss 1.99 Classification-F1 0.04513179968892421 on epoch=164
05/20/2022 12:32:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.81 on epoch=164
05/20/2022 12:32:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.97 on epoch=165
05/20/2022 12:32:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.93 on epoch=166
05/20/2022 12:32:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.99 on epoch=167
05/20/2022 12:32:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.86 on epoch=167
05/20/2022 12:32:38 - INFO - __main__ - Global step 2350 Train loss 1.91 Classification-F1 0.07333057559506033 on epoch=167
05/20/2022 12:32:38 - INFO - __main__ - Saving model with best Classification-F1: 0.062470170212105706 -> 0.07333057559506033 on epoch=167, global_step=2350
05/20/2022 12:32:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.01 on epoch=168
05/20/2022 12:32:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.95 on epoch=169
05/20/2022 12:32:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.03 on epoch=169
05/20/2022 12:32:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.86 on epoch=170
05/20/2022 12:32:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.98 on epoch=171
05/20/2022 12:32:46 - INFO - __main__ - Global step 2400 Train loss 1.97 Classification-F1 0.04171852043902861 on epoch=171
05/20/2022 12:32:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.84 on epoch=172
05/20/2022 12:32:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.84 on epoch=172
05/20/2022 12:32:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.97 on epoch=173
05/20/2022 12:32:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.85 on epoch=174
05/20/2022 12:32:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.97 on epoch=174
05/20/2022 12:32:55 - INFO - __main__ - Global step 2450 Train loss 1.89 Classification-F1 0.06168731756967051 on epoch=174
05/20/2022 12:32:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.99 on epoch=175
05/20/2022 12:32:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.95 on epoch=176
05/20/2022 12:32:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.90 on epoch=177
05/20/2022 12:33:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.69 on epoch=177
05/20/2022 12:33:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.04 on epoch=178
05/20/2022 12:33:03 - INFO - __main__ - Global step 2500 Train loss 1.91 Classification-F1 0.07772376179317322 on epoch=178
05/20/2022 12:33:03 - INFO - __main__ - Saving model with best Classification-F1: 0.07333057559506033 -> 0.07772376179317322 on epoch=178, global_step=2500
05/20/2022 12:33:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.91 on epoch=179
05/20/2022 12:33:05 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.85 on epoch=179
05/20/2022 12:33:07 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.92 on epoch=180
05/20/2022 12:33:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.78 on epoch=181
05/20/2022 12:33:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.92 on epoch=182
05/20/2022 12:33:11 - INFO - __main__ - Global step 2550 Train loss 1.88 Classification-F1 0.08242901746991259 on epoch=182
05/20/2022 12:33:11 - INFO - __main__ - Saving model with best Classification-F1: 0.07772376179317322 -> 0.08242901746991259 on epoch=182, global_step=2550
05/20/2022 12:33:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.90 on epoch=182
05/20/2022 12:33:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.90 on epoch=183
05/20/2022 12:33:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.84 on epoch=184
05/20/2022 12:33:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.78 on epoch=184
05/20/2022 12:33:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.90 on epoch=185
05/20/2022 12:33:20 - INFO - __main__ - Global step 2600 Train loss 1.86 Classification-F1 0.05927219237988134 on epoch=185
05/20/2022 12:33:21 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.96 on epoch=186
05/20/2022 12:33:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.82 on epoch=187
05/20/2022 12:33:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.78 on epoch=187
05/20/2022 12:33:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.90 on epoch=188
05/20/2022 12:33:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.89 on epoch=189
05/20/2022 12:33:28 - INFO - __main__ - Global step 2650 Train loss 1.87 Classification-F1 0.06874328678839955 on epoch=189
05/20/2022 12:33:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.83 on epoch=189
05/20/2022 12:33:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.70 on epoch=190
05/20/2022 12:33:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.90 on epoch=191
05/20/2022 12:33:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.81 on epoch=192
05/20/2022 12:33:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.77 on epoch=192
05/20/2022 12:33:36 - INFO - __main__ - Global step 2700 Train loss 1.80 Classification-F1 0.07563898861438888 on epoch=192
05/20/2022 12:33:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.67 on epoch=193
05/20/2022 12:33:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.91 on epoch=194
05/20/2022 12:33:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.92 on epoch=194
05/20/2022 12:33:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.71 on epoch=195
05/20/2022 12:33:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.72 on epoch=196
05/20/2022 12:33:44 - INFO - __main__ - Global step 2750 Train loss 1.79 Classification-F1 0.04166666666666667 on epoch=196
05/20/2022 12:33:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.86 on epoch=197
05/20/2022 12:33:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.68 on epoch=197
05/20/2022 12:33:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.71 on epoch=198
05/20/2022 12:33:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.84 on epoch=199
05/20/2022 12:33:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.79 on epoch=199
05/20/2022 12:33:53 - INFO - __main__ - Global step 2800 Train loss 1.78 Classification-F1 0.048707804884355325 on epoch=199
05/20/2022 12:33:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.61 on epoch=200
05/20/2022 12:33:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.66 on epoch=201
05/20/2022 12:33:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.79 on epoch=202
05/20/2022 12:33:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.67 on epoch=202
05/20/2022 12:33:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.84 on epoch=203
05/20/2022 12:34:01 - INFO - __main__ - Global step 2850 Train loss 1.71 Classification-F1 0.04450504132370516 on epoch=203
05/20/2022 12:34:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.73 on epoch=204
05/20/2022 12:34:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.67 on epoch=204
05/20/2022 12:34:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.65 on epoch=205
05/20/2022 12:34:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.82 on epoch=206
05/20/2022 12:34:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.69 on epoch=207
05/20/2022 12:34:10 - INFO - __main__ - Global step 2900 Train loss 1.71 Classification-F1 0.047229053747522745 on epoch=207
05/20/2022 12:34:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.59 on epoch=207
05/20/2022 12:34:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.75 on epoch=208
05/20/2022 12:34:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.65 on epoch=209
05/20/2022 12:34:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.74 on epoch=209
05/20/2022 12:34:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.70 on epoch=210
05/20/2022 12:34:19 - INFO - __main__ - Global step 2950 Train loss 1.68 Classification-F1 0.036088164598356176 on epoch=210
05/20/2022 12:34:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.69 on epoch=211
05/20/2022 12:34:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.66 on epoch=212
05/20/2022 12:34:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.66 on epoch=212
05/20/2022 12:34:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.78 on epoch=213
05/20/2022 12:34:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.68 on epoch=214
05/20/2022 12:34:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:34:26 - INFO - __main__ - Printing 3 examples
05/20/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 12:34:26 - INFO - __main__ - ['Company']
05/20/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 12:34:26 - INFO - __main__ - ['Company']
05/20/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 12:34:26 - INFO - __main__ - ['Company']
05/20/2022 12:34:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:34:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:34:26 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:34:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:34:26 - INFO - __main__ - Printing 3 examples
05/20/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 12:34:26 - INFO - __main__ - ['Company']
05/20/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 12:34:26 - INFO - __main__ - ['Company']
05/20/2022 12:34:26 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 12:34:26 - INFO - __main__ - ['Company']
05/20/2022 12:34:26 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:34:26 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:34:27 - INFO - __main__ - Global step 3000 Train loss 1.69 Classification-F1 0.009685230024213076 on epoch=214
05/20/2022 12:34:27 - INFO - __main__ - save last model!
05/20/2022 12:34:27 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:34:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 12:34:27 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 12:34:27 - INFO - __main__ - Printing 3 examples
05/20/2022 12:34:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 12:34:27 - INFO - __main__ - ['Animal']
05/20/2022 12:34:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 12:34:27 - INFO - __main__ - ['Animal']
05/20/2022 12:34:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 12:34:27 - INFO - __main__ - ['Village']
05/20/2022 12:34:27 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:34:29 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:34:32 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 12:34:33 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:34:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:34:33 - INFO - __main__ - Starting training!
05/20/2022 12:35:01 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/20/2022 12:35:01 - INFO - __main__ - Classification-F1 on test data: 0.0120
05/20/2022 12:35:01 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.08242901746991259, test_performance=0.012025883515299303
05/20/2022 12:35:01 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/20/2022 12:35:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:35:02 - INFO - __main__ - Printing 3 examples
05/20/2022 12:35:02 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 12:35:02 - INFO - __main__ - ['Company']
05/20/2022 12:35:02 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 12:35:02 - INFO - __main__ - ['Company']
05/20/2022 12:35:02 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 12:35:02 - INFO - __main__ - ['Company']
05/20/2022 12:35:02 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:35:02 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:35:02 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:35:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:35:02 - INFO - __main__ - Printing 3 examples
05/20/2022 12:35:02 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 12:35:02 - INFO - __main__ - ['Company']
05/20/2022 12:35:02 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 12:35:02 - INFO - __main__ - ['Company']
05/20/2022 12:35:02 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 12:35:02 - INFO - __main__ - ['Company']
05/20/2022 12:35:02 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:35:02 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:35:03 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:35:08 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:35:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:35:08 - INFO - __main__ - Starting training!
05/20/2022 12:35:10 - INFO - __main__ - Step 10 Global step 10 Train loss 7.34 on epoch=0
05/20/2022 12:35:11 - INFO - __main__ - Step 20 Global step 20 Train loss 7.59 on epoch=1
05/20/2022 12:35:12 - INFO - __main__ - Step 30 Global step 30 Train loss 7.50 on epoch=2
05/20/2022 12:35:13 - INFO - __main__ - Step 40 Global step 40 Train loss 6.85 on epoch=2
05/20/2022 12:35:14 - INFO - __main__ - Step 50 Global step 50 Train loss 7.29 on epoch=3
05/20/2022 12:35:28 - INFO - __main__ - Global step 50 Train loss 7.32 Classification-F1 0.0 on epoch=3
05/20/2022 12:35:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 12:35:30 - INFO - __main__ - Step 60 Global step 60 Train loss 6.86 on epoch=4
05/20/2022 12:35:31 - INFO - __main__ - Step 70 Global step 70 Train loss 7.05 on epoch=4
05/20/2022 12:35:32 - INFO - __main__ - Step 80 Global step 80 Train loss 6.61 on epoch=5
05/20/2022 12:35:33 - INFO - __main__ - Step 90 Global step 90 Train loss 6.81 on epoch=6
05/20/2022 12:35:35 - INFO - __main__ - Step 100 Global step 100 Train loss 6.77 on epoch=7
05/20/2022 12:36:12 - INFO - __main__ - Global step 100 Train loss 6.82 Classification-F1 0.0 on epoch=7
05/20/2022 12:36:13 - INFO - __main__ - Step 110 Global step 110 Train loss 6.24 on epoch=7
05/20/2022 12:36:14 - INFO - __main__ - Step 120 Global step 120 Train loss 6.58 on epoch=8
05/20/2022 12:36:15 - INFO - __main__ - Step 130 Global step 130 Train loss 6.20 on epoch=9
05/20/2022 12:36:17 - INFO - __main__ - Step 140 Global step 140 Train loss 6.54 on epoch=9
05/20/2022 12:36:18 - INFO - __main__ - Step 150 Global step 150 Train loss 6.06 on epoch=10
05/20/2022 12:36:44 - INFO - __main__ - Global step 150 Train loss 6.32 Classification-F1 0.0 on epoch=10
05/20/2022 12:36:45 - INFO - __main__ - Step 160 Global step 160 Train loss 6.18 on epoch=11
05/20/2022 12:36:46 - INFO - __main__ - Step 170 Global step 170 Train loss 6.18 on epoch=12
05/20/2022 12:36:47 - INFO - __main__ - Step 180 Global step 180 Train loss 5.70 on epoch=12
05/20/2022 12:36:49 - INFO - __main__ - Step 190 Global step 190 Train loss 6.09 on epoch=13
05/20/2022 12:36:50 - INFO - __main__ - Step 200 Global step 200 Train loss 5.69 on epoch=14
05/20/2022 12:37:32 - INFO - __main__ - Global step 200 Train loss 5.97 Classification-F1 0.0 on epoch=14
05/20/2022 12:37:33 - INFO - __main__ - Step 210 Global step 210 Train loss 6.01 on epoch=14
05/20/2022 12:37:34 - INFO - __main__ - Step 220 Global step 220 Train loss 5.70 on epoch=15
05/20/2022 12:37:36 - INFO - __main__ - Step 230 Global step 230 Train loss 5.83 on epoch=16
05/20/2022 12:37:37 - INFO - __main__ - Step 240 Global step 240 Train loss 5.62 on epoch=17
05/20/2022 12:37:38 - INFO - __main__ - Step 250 Global step 250 Train loss 5.38 on epoch=17
05/20/2022 12:38:07 - INFO - __main__ - Global step 250 Train loss 5.71 Classification-F1 0.0 on epoch=17
05/20/2022 12:38:08 - INFO - __main__ - Step 260 Global step 260 Train loss 5.48 on epoch=18
05/20/2022 12:38:09 - INFO - __main__ - Step 270 Global step 270 Train loss 5.26 on epoch=19
05/20/2022 12:38:10 - INFO - __main__ - Step 280 Global step 280 Train loss 5.42 on epoch=19
05/20/2022 12:38:11 - INFO - __main__ - Step 290 Global step 290 Train loss 5.03 on epoch=20
05/20/2022 12:38:13 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/20/2022 12:38:27 - INFO - __main__ - Global step 300 Train loss 5.32 Classification-F1 0.0065832784726793945 on epoch=21
05/20/2022 12:38:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0065832784726793945 on epoch=21, global_step=300
05/20/2022 12:38:29 - INFO - __main__ - Step 310 Global step 310 Train loss 5.14 on epoch=22
05/20/2022 12:38:30 - INFO - __main__ - Step 320 Global step 320 Train loss 4.94 on epoch=22
05/20/2022 12:38:31 - INFO - __main__ - Step 330 Global step 330 Train loss 5.09 on epoch=23
05/20/2022 12:38:32 - INFO - __main__ - Step 340 Global step 340 Train loss 5.08 on epoch=24
05/20/2022 12:38:33 - INFO - __main__ - Step 350 Global step 350 Train loss 5.18 on epoch=24
05/20/2022 12:38:37 - INFO - __main__ - Global step 350 Train loss 5.09 Classification-F1 0.007231404958677684 on epoch=24
05/20/2022 12:38:37 - INFO - __main__ - Saving model with best Classification-F1: 0.0065832784726793945 -> 0.007231404958677684 on epoch=24, global_step=350
05/20/2022 12:38:38 - INFO - __main__ - Step 360 Global step 360 Train loss 4.86 on epoch=25
05/20/2022 12:38:39 - INFO - __main__ - Step 370 Global step 370 Train loss 5.03 on epoch=26
05/20/2022 12:38:41 - INFO - __main__ - Step 380 Global step 380 Train loss 4.98 on epoch=27
05/20/2022 12:38:42 - INFO - __main__ - Step 390 Global step 390 Train loss 4.62 on epoch=27
05/20/2022 12:38:43 - INFO - __main__ - Step 400 Global step 400 Train loss 4.77 on epoch=28
05/20/2022 12:38:46 - INFO - __main__ - Global step 400 Train loss 4.85 Classification-F1 0.0072028811524609835 on epoch=28
05/20/2022 12:38:47 - INFO - __main__ - Step 410 Global step 410 Train loss 4.67 on epoch=29
05/20/2022 12:38:48 - INFO - __main__ - Step 420 Global step 420 Train loss 4.82 on epoch=29
05/20/2022 12:38:49 - INFO - __main__ - Step 430 Global step 430 Train loss 4.47 on epoch=30
05/20/2022 12:38:50 - INFO - __main__ - Step 440 Global step 440 Train loss 4.63 on epoch=31
05/20/2022 12:38:52 - INFO - __main__ - Step 450 Global step 450 Train loss 4.56 on epoch=32
05/20/2022 12:38:54 - INFO - __main__ - Global step 450 Train loss 4.63 Classification-F1 0.008403361344537815 on epoch=32
05/20/2022 12:38:54 - INFO - __main__ - Saving model with best Classification-F1: 0.007231404958677684 -> 0.008403361344537815 on epoch=32, global_step=450
05/20/2022 12:38:55 - INFO - __main__ - Step 460 Global step 460 Train loss 4.42 on epoch=32
05/20/2022 12:38:56 - INFO - __main__ - Step 470 Global step 470 Train loss 4.47 on epoch=33
05/20/2022 12:38:58 - INFO - __main__ - Step 480 Global step 480 Train loss 4.34 on epoch=34
05/20/2022 12:38:59 - INFO - __main__ - Step 490 Global step 490 Train loss 4.36 on epoch=34
05/20/2022 12:39:00 - INFO - __main__ - Step 500 Global step 500 Train loss 4.24 on epoch=35
05/20/2022 12:39:02 - INFO - __main__ - Global step 500 Train loss 4.37 Classification-F1 0.009523809523809523 on epoch=35
05/20/2022 12:39:02 - INFO - __main__ - Saving model with best Classification-F1: 0.008403361344537815 -> 0.009523809523809523 on epoch=35, global_step=500
05/20/2022 12:39:03 - INFO - __main__ - Step 510 Global step 510 Train loss 4.31 on epoch=36
05/20/2022 12:39:05 - INFO - __main__ - Step 520 Global step 520 Train loss 4.16 on epoch=37
05/20/2022 12:39:06 - INFO - __main__ - Step 530 Global step 530 Train loss 4.08 on epoch=37
05/20/2022 12:39:07 - INFO - __main__ - Step 540 Global step 540 Train loss 4.08 on epoch=38
05/20/2022 12:39:08 - INFO - __main__ - Step 550 Global step 550 Train loss 4.08 on epoch=39
05/20/2022 12:39:10 - INFO - __main__ - Global step 550 Train loss 4.14 Classification-F1 0.009523809523809523 on epoch=39
05/20/2022 12:39:11 - INFO - __main__ - Step 560 Global step 560 Train loss 4.09 on epoch=39
05/20/2022 12:39:13 - INFO - __main__ - Step 570 Global step 570 Train loss 3.99 on epoch=40
05/20/2022 12:39:14 - INFO - __main__ - Step 580 Global step 580 Train loss 3.83 on epoch=41
05/20/2022 12:39:15 - INFO - __main__ - Step 590 Global step 590 Train loss 3.90 on epoch=42
05/20/2022 12:39:16 - INFO - __main__ - Step 600 Global step 600 Train loss 3.83 on epoch=42
05/20/2022 12:39:18 - INFO - __main__ - Global step 600 Train loss 3.93 Classification-F1 0.009523809523809523 on epoch=42
05/20/2022 12:39:19 - INFO - __main__ - Step 610 Global step 610 Train loss 3.84 on epoch=43
05/20/2022 12:39:21 - INFO - __main__ - Step 620 Global step 620 Train loss 3.72 on epoch=44
05/20/2022 12:39:22 - INFO - __main__ - Step 630 Global step 630 Train loss 3.88 on epoch=44
05/20/2022 12:39:23 - INFO - __main__ - Step 640 Global step 640 Train loss 3.58 on epoch=45
05/20/2022 12:39:24 - INFO - __main__ - Step 650 Global step 650 Train loss 3.71 on epoch=46
05/20/2022 12:39:26 - INFO - __main__ - Global step 650 Train loss 3.75 Classification-F1 0.009523809523809523 on epoch=46
05/20/2022 12:39:27 - INFO - __main__ - Step 660 Global step 660 Train loss 3.55 on epoch=47
05/20/2022 12:39:29 - INFO - __main__ - Step 670 Global step 670 Train loss 3.61 on epoch=47
05/20/2022 12:39:30 - INFO - __main__ - Step 680 Global step 680 Train loss 3.65 on epoch=48
05/20/2022 12:39:31 - INFO - __main__ - Step 690 Global step 690 Train loss 3.45 on epoch=49
05/20/2022 12:39:32 - INFO - __main__ - Step 700 Global step 700 Train loss 3.64 on epoch=49
05/20/2022 12:39:34 - INFO - __main__ - Global step 700 Train loss 3.58 Classification-F1 0.028485757121439276 on epoch=49
05/20/2022 12:39:34 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.028485757121439276 on epoch=49, global_step=700
05/20/2022 12:39:35 - INFO - __main__ - Step 710 Global step 710 Train loss 3.44 on epoch=50
05/20/2022 12:39:37 - INFO - __main__ - Step 720 Global step 720 Train loss 3.35 on epoch=51
05/20/2022 12:39:38 - INFO - __main__ - Step 730 Global step 730 Train loss 3.31 on epoch=52
05/20/2022 12:39:39 - INFO - __main__ - Step 740 Global step 740 Train loss 3.42 on epoch=52
05/20/2022 12:39:40 - INFO - __main__ - Step 750 Global step 750 Train loss 3.35 on epoch=53
05/20/2022 12:39:42 - INFO - __main__ - Global step 750 Train loss 3.37 Classification-F1 0.01800720288115246 on epoch=53
05/20/2022 12:39:43 - INFO - __main__ - Step 760 Global step 760 Train loss 3.24 on epoch=54
05/20/2022 12:39:45 - INFO - __main__ - Step 770 Global step 770 Train loss 3.32 on epoch=54
05/20/2022 12:39:46 - INFO - __main__ - Step 780 Global step 780 Train loss 3.18 on epoch=55
05/20/2022 12:39:47 - INFO - __main__ - Step 790 Global step 790 Train loss 3.26 on epoch=56
05/20/2022 12:39:48 - INFO - __main__ - Step 800 Global step 800 Train loss 3.18 on epoch=57
05/20/2022 12:39:50 - INFO - __main__ - Global step 800 Train loss 3.24 Classification-F1 0.025068946497517928 on epoch=57
05/20/2022 12:39:51 - INFO - __main__ - Step 810 Global step 810 Train loss 3.22 on epoch=57
05/20/2022 12:39:52 - INFO - __main__ - Step 820 Global step 820 Train loss 3.04 on epoch=58
05/20/2022 12:39:54 - INFO - __main__ - Step 830 Global step 830 Train loss 3.13 on epoch=59
05/20/2022 12:39:55 - INFO - __main__ - Step 840 Global step 840 Train loss 3.18 on epoch=59
05/20/2022 12:39:56 - INFO - __main__ - Step 850 Global step 850 Train loss 2.88 on epoch=60
05/20/2022 12:39:58 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.009563658099222952 on epoch=60
05/20/2022 12:39:59 - INFO - __main__ - Step 860 Global step 860 Train loss 2.98 on epoch=61
05/20/2022 12:40:00 - INFO - __main__ - Step 870 Global step 870 Train loss 2.89 on epoch=62
05/20/2022 12:40:02 - INFO - __main__ - Step 880 Global step 880 Train loss 3.02 on epoch=62
05/20/2022 12:40:03 - INFO - __main__ - Step 890 Global step 890 Train loss 3.03 on epoch=63
05/20/2022 12:40:04 - INFO - __main__ - Step 900 Global step 900 Train loss 2.96 on epoch=64
05/20/2022 12:40:06 - INFO - __main__ - Global step 900 Train loss 2.98 Classification-F1 0.024081089128564808 on epoch=64
05/20/2022 12:40:07 - INFO - __main__ - Step 910 Global step 910 Train loss 2.83 on epoch=64
05/20/2022 12:40:08 - INFO - __main__ - Step 920 Global step 920 Train loss 2.69 on epoch=65
05/20/2022 12:40:10 - INFO - __main__ - Step 930 Global step 930 Train loss 2.95 on epoch=66
05/20/2022 12:40:11 - INFO - __main__ - Step 940 Global step 940 Train loss 2.93 on epoch=67
05/20/2022 12:40:12 - INFO - __main__ - Step 950 Global step 950 Train loss 2.89 on epoch=67
05/20/2022 12:40:15 - INFO - __main__ - Global step 950 Train loss 2.86 Classification-F1 0.05508180344245918 on epoch=67
05/20/2022 12:40:15 - INFO - __main__ - Saving model with best Classification-F1: 0.028485757121439276 -> 0.05508180344245918 on epoch=67, global_step=950
05/20/2022 12:40:16 - INFO - __main__ - Step 960 Global step 960 Train loss 2.80 on epoch=68
05/20/2022 12:40:18 - INFO - __main__ - Step 970 Global step 970 Train loss 2.79 on epoch=69
05/20/2022 12:40:19 - INFO - __main__ - Step 980 Global step 980 Train loss 2.92 on epoch=69
05/20/2022 12:40:20 - INFO - __main__ - Step 990 Global step 990 Train loss 2.81 on epoch=70
05/20/2022 12:40:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.73 on epoch=71
05/20/2022 12:40:24 - INFO - __main__ - Global step 1000 Train loss 2.81 Classification-F1 0.07907107670654469 on epoch=71
05/20/2022 12:40:24 - INFO - __main__ - Saving model with best Classification-F1: 0.05508180344245918 -> 0.07907107670654469 on epoch=71, global_step=1000
05/20/2022 12:40:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.75 on epoch=72
05/20/2022 12:40:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.88 on epoch=72
05/20/2022 12:40:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.65 on epoch=73
05/20/2022 12:40:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.72 on epoch=74
05/20/2022 12:40:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.59 on epoch=74
05/20/2022 12:40:33 - INFO - __main__ - Global step 1050 Train loss 2.72 Classification-F1 0.046860500803379605 on epoch=74
05/20/2022 12:40:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.58 on epoch=75
05/20/2022 12:40:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.53 on epoch=76
05/20/2022 12:40:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.68 on epoch=77
05/20/2022 12:40:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.51 on epoch=77
05/20/2022 12:40:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.49 on epoch=78
05/20/2022 12:40:41 - INFO - __main__ - Global step 1100 Train loss 2.56 Classification-F1 0.048964630897404 on epoch=78
05/20/2022 12:40:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.55 on epoch=79
05/20/2022 12:40:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.61 on epoch=79
05/20/2022 12:40:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=80
05/20/2022 12:40:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.54 on epoch=81
05/20/2022 12:40:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.49 on epoch=82
05/20/2022 12:40:49 - INFO - __main__ - Global step 1150 Train loss 2.55 Classification-F1 0.04747840147294873 on epoch=82
05/20/2022 12:40:51 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.63 on epoch=82
05/20/2022 12:40:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.50 on epoch=83
05/20/2022 12:40:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.60 on epoch=84
05/20/2022 12:40:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.60 on epoch=84
05/20/2022 12:40:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.45 on epoch=85
05/20/2022 12:40:58 - INFO - __main__ - Global step 1200 Train loss 2.56 Classification-F1 0.07546270653121834 on epoch=85
05/20/2022 12:41:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.32 on epoch=86
05/20/2022 12:41:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.45 on epoch=87
05/20/2022 12:41:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.37 on epoch=87
05/20/2022 12:41:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.36 on epoch=88
05/20/2022 12:41:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.23 on epoch=89
05/20/2022 12:41:07 - INFO - __main__ - Global step 1250 Train loss 2.35 Classification-F1 0.059761348708217775 on epoch=89
05/20/2022 12:41:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.39 on epoch=89
05/20/2022 12:41:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.28 on epoch=90
05/20/2022 12:41:11 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.23 on epoch=91
05/20/2022 12:41:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.31 on epoch=92
05/20/2022 12:41:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.19 on epoch=92
05/20/2022 12:41:16 - INFO - __main__ - Global step 1300 Train loss 2.28 Classification-F1 0.055208935643718246 on epoch=92
05/20/2022 12:41:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.28 on epoch=93
05/20/2022 12:41:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.27 on epoch=94
05/20/2022 12:41:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.37 on epoch=94
05/20/2022 12:41:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.36 on epoch=95
05/20/2022 12:41:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.31 on epoch=96
05/20/2022 12:41:24 - INFO - __main__ - Global step 1350 Train loss 2.32 Classification-F1 0.0776048367620732 on epoch=96
05/20/2022 12:41:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.41 on epoch=97
05/20/2022 12:41:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.24 on epoch=97
05/20/2022 12:41:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.20 on epoch=98
05/20/2022 12:41:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.13 on epoch=99
05/20/2022 12:41:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.09 on epoch=99
05/20/2022 12:41:32 - INFO - __main__ - Global step 1400 Train loss 2.21 Classification-F1 0.07363172150112762 on epoch=99
05/20/2022 12:41:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.12 on epoch=100
05/20/2022 12:41:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.27 on epoch=101
05/20/2022 12:41:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.30 on epoch=102
05/20/2022 12:41:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.27 on epoch=102
05/20/2022 12:41:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.20 on epoch=103
05/20/2022 12:41:40 - INFO - __main__ - Global step 1450 Train loss 2.23 Classification-F1 0.07114280934156711 on epoch=103
05/20/2022 12:41:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.99 on epoch=104
05/20/2022 12:41:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.38 on epoch=104
05/20/2022 12:41:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.18 on epoch=105
05/20/2022 12:41:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.25 on epoch=106
05/20/2022 12:41:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.11 on epoch=107
05/20/2022 12:41:48 - INFO - __main__ - Global step 1500 Train loss 2.18 Classification-F1 0.08958019633051473 on epoch=107
05/20/2022 12:41:48 - INFO - __main__ - Saving model with best Classification-F1: 0.07907107670654469 -> 0.08958019633051473 on epoch=107, global_step=1500
05/20/2022 12:41:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.19 on epoch=107
05/20/2022 12:41:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.05 on epoch=108
05/20/2022 12:41:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.97 on epoch=109
05/20/2022 12:41:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.14 on epoch=109
05/20/2022 12:41:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.06 on epoch=110
05/20/2022 12:41:57 - INFO - __main__ - Global step 1550 Train loss 2.08 Classification-F1 0.1096157581140896 on epoch=110
05/20/2022 12:41:57 - INFO - __main__ - Saving model with best Classification-F1: 0.08958019633051473 -> 0.1096157581140896 on epoch=110, global_step=1550
05/20/2022 12:41:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.93 on epoch=111
05/20/2022 12:42:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.05 on epoch=112
05/20/2022 12:42:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.07 on epoch=112
05/20/2022 12:42:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.05 on epoch=113
05/20/2022 12:42:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.00 on epoch=114
05/20/2022 12:42:06 - INFO - __main__ - Global step 1600 Train loss 2.02 Classification-F1 0.11571149159003588 on epoch=114
05/20/2022 12:42:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1096157581140896 -> 0.11571149159003588 on epoch=114, global_step=1600
05/20/2022 12:42:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.16 on epoch=114
05/20/2022 12:42:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.89 on epoch=115
05/20/2022 12:42:10 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.08 on epoch=116
05/20/2022 12:42:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.09 on epoch=117
05/20/2022 12:42:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.25 on epoch=117
05/20/2022 12:42:15 - INFO - __main__ - Global step 1650 Train loss 2.10 Classification-F1 0.13002759632281005 on epoch=117
05/20/2022 12:42:15 - INFO - __main__ - Saving model with best Classification-F1: 0.11571149159003588 -> 0.13002759632281005 on epoch=117, global_step=1650
05/20/2022 12:42:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.83 on epoch=118
05/20/2022 12:42:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.87 on epoch=119
05/20/2022 12:42:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.07 on epoch=119
05/20/2022 12:42:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.00 on epoch=120
05/20/2022 12:42:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.03 on epoch=121
05/20/2022 12:42:23 - INFO - __main__ - Global step 1700 Train loss 1.96 Classification-F1 0.11659487521556487 on epoch=121
05/20/2022 12:42:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.99 on epoch=122
05/20/2022 12:42:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.97 on epoch=122
05/20/2022 12:42:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.09 on epoch=123
05/20/2022 12:42:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.96 on epoch=124
05/20/2022 12:42:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.12 on epoch=124
05/20/2022 12:42:31 - INFO - __main__ - Global step 1750 Train loss 2.03 Classification-F1 0.05395443823380785 on epoch=124
05/20/2022 12:42:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.93 on epoch=125
05/20/2022 12:42:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.01 on epoch=126
05/20/2022 12:42:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.24 on epoch=127
05/20/2022 12:42:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.27 on epoch=127
05/20/2022 12:42:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.21 on epoch=128
05/20/2022 12:42:39 - INFO - __main__ - Global step 1800 Train loss 2.13 Classification-F1 0.09902841519382874 on epoch=128
05/20/2022 12:42:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.03 on epoch=129
05/20/2022 12:42:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.03 on epoch=129
05/20/2022 12:42:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.90 on epoch=130
05/20/2022 12:42:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.97 on epoch=131
05/20/2022 12:42:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.11 on epoch=132
05/20/2022 12:42:47 - INFO - __main__ - Global step 1850 Train loss 2.01 Classification-F1 0.01821329390125149 on epoch=132
05/20/2022 12:42:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.92 on epoch=132
05/20/2022 12:42:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.80 on epoch=133
05/20/2022 12:42:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.98 on epoch=134
05/20/2022 12:42:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.90 on epoch=134
05/20/2022 12:42:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.87 on epoch=135
05/20/2022 12:42:56 - INFO - __main__ - Global step 1900 Train loss 1.89 Classification-F1 0.038769757374408534 on epoch=135
05/20/2022 12:42:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.00 on epoch=136
05/20/2022 12:42:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.91 on epoch=137
05/20/2022 12:43:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.98 on epoch=137
05/20/2022 12:43:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.96 on epoch=138
05/20/2022 12:43:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.88 on epoch=139
05/20/2022 12:43:04 - INFO - __main__ - Global step 1950 Train loss 1.95 Classification-F1 0.009726443768996961 on epoch=139
05/20/2022 12:43:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.29 on epoch=139
05/20/2022 12:43:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.97 on epoch=140
05/20/2022 12:43:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.97 on epoch=141
05/20/2022 12:43:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.95 on epoch=142
05/20/2022 12:43:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.97 on epoch=142
05/20/2022 12:43:13 - INFO - __main__ - Global step 2000 Train loss 2.03 Classification-F1 0.06975881261595547 on epoch=142
05/20/2022 12:43:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.00 on epoch=143
05/20/2022 12:43:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.79 on epoch=144
05/20/2022 12:43:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.94 on epoch=144
05/20/2022 12:43:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.72 on epoch=145
05/20/2022 12:43:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.90 on epoch=146
05/20/2022 12:43:22 - INFO - __main__ - Global step 2050 Train loss 1.87 Classification-F1 0.08109941452585301 on epoch=146
05/20/2022 12:43:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.89 on epoch=147
05/20/2022 12:43:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.82 on epoch=147
05/20/2022 12:43:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.79 on epoch=148
05/20/2022 12:43:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.73 on epoch=149
05/20/2022 12:43:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.87 on epoch=149
05/20/2022 12:43:31 - INFO - __main__ - Global step 2100 Train loss 1.82 Classification-F1 0.15528383316919533 on epoch=149
05/20/2022 12:43:31 - INFO - __main__ - Saving model with best Classification-F1: 0.13002759632281005 -> 0.15528383316919533 on epoch=149, global_step=2100
05/20/2022 12:43:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.69 on epoch=150
05/20/2022 12:43:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.89 on epoch=151
05/20/2022 12:43:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.75 on epoch=152
05/20/2022 12:43:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.74 on epoch=152
05/20/2022 12:43:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.99 on epoch=153
05/20/2022 12:43:39 - INFO - __main__ - Global step 2150 Train loss 1.81 Classification-F1 0.0957826363875423 on epoch=153
05/20/2022 12:43:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.73 on epoch=154
05/20/2022 12:43:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.33 on epoch=154
05/20/2022 12:43:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.00 on epoch=155
05/20/2022 12:43:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.03 on epoch=156
05/20/2022 12:43:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.14 on epoch=157
05/20/2022 12:43:47 - INFO - __main__ - Global step 2200 Train loss 2.05 Classification-F1 0.11688786827495667 on epoch=157
05/20/2022 12:43:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.09 on epoch=157
05/20/2022 12:43:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.95 on epoch=158
05/20/2022 12:43:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.92 on epoch=159
05/20/2022 12:43:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.98 on epoch=159
05/20/2022 12:43:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.88 on epoch=160
05/20/2022 12:43:56 - INFO - __main__ - Global step 2250 Train loss 1.97 Classification-F1 0.03043525102348632 on epoch=160
05/20/2022 12:43:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.07 on epoch=161
05/20/2022 12:43:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.91 on epoch=162
05/20/2022 12:44:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.87 on epoch=162
05/20/2022 12:44:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.75 on epoch=163
05/20/2022 12:44:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.83 on epoch=164
05/20/2022 12:44:04 - INFO - __main__ - Global step 2300 Train loss 1.88 Classification-F1 0.11716569533771395 on epoch=164
05/20/2022 12:44:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.83 on epoch=164
05/20/2022 12:44:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.61 on epoch=165
05/20/2022 12:44:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.75 on epoch=166
05/20/2022 12:44:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.82 on epoch=167
05/20/2022 12:44:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.61 on epoch=167
05/20/2022 12:44:12 - INFO - __main__ - Global step 2350 Train loss 1.72 Classification-F1 0.13881679049917098 on epoch=167
05/20/2022 12:44:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.70 on epoch=168
05/20/2022 12:44:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.68 on epoch=169
05/20/2022 12:44:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.73 on epoch=169
05/20/2022 12:44:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.62 on epoch=170
05/20/2022 12:44:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.72 on epoch=171
05/20/2022 12:44:21 - INFO - __main__ - Global step 2400 Train loss 1.69 Classification-F1 0.0956001046933549 on epoch=171
05/20/2022 12:44:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.69 on epoch=172
05/20/2022 12:44:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.67 on epoch=172
05/20/2022 12:44:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.66 on epoch=173
05/20/2022 12:44:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.54 on epoch=174
05/20/2022 12:44:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.74 on epoch=174
05/20/2022 12:44:30 - INFO - __main__ - Global step 2450 Train loss 1.66 Classification-F1 0.04853688056375626 on epoch=174
05/20/2022 12:44:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.68 on epoch=175
05/20/2022 12:44:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.72 on epoch=176
05/20/2022 12:44:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.79 on epoch=177
05/20/2022 12:44:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.79 on epoch=177
05/20/2022 12:44:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.76 on epoch=178
05/20/2022 12:44:39 - INFO - __main__ - Global step 2500 Train loss 1.75 Classification-F1 0.09196071249210445 on epoch=178
05/20/2022 12:44:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.69 on epoch=179
05/20/2022 12:44:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.72 on epoch=179
05/20/2022 12:44:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.63 on epoch=180
05/20/2022 12:44:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.70 on epoch=181
05/20/2022 12:44:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.56 on epoch=182
05/20/2022 12:44:48 - INFO - __main__ - Global step 2550 Train loss 1.66 Classification-F1 0.16868017576963074 on epoch=182
05/20/2022 12:44:48 - INFO - __main__ - Saving model with best Classification-F1: 0.15528383316919533 -> 0.16868017576963074 on epoch=182, global_step=2550
05/20/2022 12:44:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.62 on epoch=182
05/20/2022 12:44:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.62 on epoch=183
05/20/2022 12:44:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.52 on epoch=184
05/20/2022 12:44:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.64 on epoch=184
05/20/2022 12:44:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.59 on epoch=185
05/20/2022 12:44:56 - INFO - __main__ - Global step 2600 Train loss 1.60 Classification-F1 0.10489123348990428 on epoch=185
05/20/2022 12:44:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.75 on epoch=186
05/20/2022 12:44:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.64 on epoch=187
05/20/2022 12:45:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.56 on epoch=187
05/20/2022 12:45:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.57 on epoch=188
05/20/2022 12:45:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.51 on epoch=189
05/20/2022 12:45:04 - INFO - __main__ - Global step 2650 Train loss 1.60 Classification-F1 0.07845594378102116 on epoch=189
05/20/2022 12:45:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.70 on epoch=189
05/20/2022 12:45:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.58 on epoch=190
05/20/2022 12:45:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.57 on epoch=191
05/20/2022 12:45:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.59 on epoch=192
05/20/2022 12:45:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.47 on epoch=192
05/20/2022 12:45:12 - INFO - __main__ - Global step 2700 Train loss 1.58 Classification-F1 0.08701359744838008 on epoch=192
05/20/2022 12:45:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.58 on epoch=193
05/20/2022 12:45:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.67 on epoch=194
05/20/2022 12:45:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.85 on epoch=194
05/20/2022 12:45:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.55 on epoch=195
05/20/2022 12:45:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.58 on epoch=196
05/20/2022 12:45:21 - INFO - __main__ - Global step 2750 Train loss 1.64 Classification-F1 0.11014064944101198 on epoch=196
05/20/2022 12:45:22 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.66 on epoch=197
05/20/2022 12:45:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.61 on epoch=197
05/20/2022 12:45:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.58 on epoch=198
05/20/2022 12:45:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.63 on epoch=199
05/20/2022 12:45:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.59 on epoch=199
05/20/2022 12:45:29 - INFO - __main__ - Global step 2800 Train loss 1.61 Classification-F1 0.1179954810206911 on epoch=199
05/20/2022 12:45:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.51 on epoch=200
05/20/2022 12:45:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.65 on epoch=201
05/20/2022 12:45:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.58 on epoch=202
05/20/2022 12:45:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.50 on epoch=202
05/20/2022 12:45:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.66 on epoch=203
05/20/2022 12:45:37 - INFO - __main__ - Global step 2850 Train loss 1.58 Classification-F1 0.08898313871002947 on epoch=203
05/20/2022 12:45:39 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.53 on epoch=204
05/20/2022 12:45:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.56 on epoch=204
05/20/2022 12:45:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.47 on epoch=205
05/20/2022 12:45:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.53 on epoch=206
05/20/2022 12:45:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.49 on epoch=207
05/20/2022 12:45:45 - INFO - __main__ - Global step 2900 Train loss 1.51 Classification-F1 0.08250942605781315 on epoch=207
05/20/2022 12:45:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.54 on epoch=207
05/20/2022 12:45:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.66 on epoch=208
05/20/2022 12:45:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.47 on epoch=209
05/20/2022 12:45:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.68 on epoch=209
05/20/2022 12:45:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.48 on epoch=210
05/20/2022 12:45:53 - INFO - __main__ - Global step 2950 Train loss 1.56 Classification-F1 0.05943655657751823 on epoch=210
05/20/2022 12:45:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.59 on epoch=211
05/20/2022 12:45:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.48 on epoch=212
05/20/2022 12:45:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.63 on epoch=212
05/20/2022 12:45:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.57 on epoch=213
05/20/2022 12:46:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.68 on epoch=214
05/20/2022 12:46:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:46:01 - INFO - __main__ - Printing 3 examples
05/20/2022 12:46:01 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 12:46:01 - INFO - __main__ - ['Company']
05/20/2022 12:46:01 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 12:46:01 - INFO - __main__ - ['Company']
05/20/2022 12:46:01 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 12:46:01 - INFO - __main__ - ['Company']
05/20/2022 12:46:01 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:46:01 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:46:01 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:46:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:46:01 - INFO - __main__ - Printing 3 examples
05/20/2022 12:46:01 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 12:46:01 - INFO - __main__ - ['Company']
05/20/2022 12:46:01 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 12:46:01 - INFO - __main__ - ['Company']
05/20/2022 12:46:01 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 12:46:01 - INFO - __main__ - ['Company']
05/20/2022 12:46:01 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:46:01 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:46:01 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:46:01 - INFO - __main__ - Global step 3000 Train loss 1.59 Classification-F1 0.10468724074995853 on epoch=214
05/20/2022 12:46:01 - INFO - __main__ - save last model!
05/20/2022 12:46:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 12:46:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 12:46:02 - INFO - __main__ - Printing 3 examples
05/20/2022 12:46:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 12:46:02 - INFO - __main__ - ['Animal']
05/20/2022 12:46:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 12:46:02 - INFO - __main__ - ['Animal']
05/20/2022 12:46:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 12:46:02 - INFO - __main__ - ['Village']
05/20/2022 12:46:02 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:46:03 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:46:07 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 12:46:07 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:46:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:46:08 - INFO - __main__ - Starting training!
05/20/2022 12:46:38 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/20/2022 12:46:38 - INFO - __main__ - Classification-F1 on test data: 0.0784
05/20/2022 12:46:38 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.16868017576963074, test_performance=0.07841842630528417
05/20/2022 12:46:38 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/20/2022 12:46:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:46:39 - INFO - __main__ - Printing 3 examples
05/20/2022 12:46:39 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 12:46:39 - INFO - __main__ - ['Company']
05/20/2022 12:46:39 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 12:46:39 - INFO - __main__ - ['Company']
05/20/2022 12:46:39 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 12:46:39 - INFO - __main__ - ['Company']
05/20/2022 12:46:39 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:46:39 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:46:39 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:46:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:46:39 - INFO - __main__ - Printing 3 examples
05/20/2022 12:46:39 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 12:46:39 - INFO - __main__ - ['Company']
05/20/2022 12:46:39 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 12:46:39 - INFO - __main__ - ['Company']
05/20/2022 12:46:39 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 12:46:39 - INFO - __main__ - ['Company']
05/20/2022 12:46:39 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:46:40 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:46:40 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:46:46 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:46:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:46:46 - INFO - __main__ - Starting training!
05/20/2022 12:46:49 - INFO - __main__ - Step 10 Global step 10 Train loss 7.29 on epoch=0
05/20/2022 12:46:50 - INFO - __main__ - Step 20 Global step 20 Train loss 7.64 on epoch=1
05/20/2022 12:46:52 - INFO - __main__ - Step 30 Global step 30 Train loss 7.35 on epoch=2
05/20/2022 12:46:53 - INFO - __main__ - Step 40 Global step 40 Train loss 6.90 on epoch=2
05/20/2022 12:46:54 - INFO - __main__ - Step 50 Global step 50 Train loss 7.15 on epoch=3
05/20/2022 12:47:03 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/20/2022 12:47:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 12:47:04 - INFO - __main__ - Step 60 Global step 60 Train loss 6.90 on epoch=4
05/20/2022 12:47:05 - INFO - __main__ - Step 70 Global step 70 Train loss 7.04 on epoch=4
05/20/2022 12:47:07 - INFO - __main__ - Step 80 Global step 80 Train loss 6.57 on epoch=5
05/20/2022 12:47:08 - INFO - __main__ - Step 90 Global step 90 Train loss 6.85 on epoch=6
05/20/2022 12:47:09 - INFO - __main__ - Step 100 Global step 100 Train loss 6.84 on epoch=7
05/20/2022 12:48:04 - INFO - __main__ - Global step 100 Train loss 6.84 Classification-F1 0.0 on epoch=7
05/20/2022 12:48:05 - INFO - __main__ - Step 110 Global step 110 Train loss 6.28 on epoch=7
05/20/2022 12:48:07 - INFO - __main__ - Step 120 Global step 120 Train loss 6.59 on epoch=8
05/20/2022 12:48:08 - INFO - __main__ - Step 130 Global step 130 Train loss 6.31 on epoch=9
05/20/2022 12:48:09 - INFO - __main__ - Step 140 Global step 140 Train loss 6.49 on epoch=9
05/20/2022 12:48:10 - INFO - __main__ - Step 150 Global step 150 Train loss 6.06 on epoch=10
05/20/2022 12:49:19 - INFO - __main__ - Global step 150 Train loss 6.35 Classification-F1 0.0 on epoch=10
05/20/2022 12:49:21 - INFO - __main__ - Step 160 Global step 160 Train loss 6.45 on epoch=11
05/20/2022 12:49:22 - INFO - __main__ - Step 170 Global step 170 Train loss 6.22 on epoch=12
05/20/2022 12:49:23 - INFO - __main__ - Step 180 Global step 180 Train loss 5.85 on epoch=12
05/20/2022 12:49:24 - INFO - __main__ - Step 190 Global step 190 Train loss 6.10 on epoch=13
05/20/2022 12:49:26 - INFO - __main__ - Step 200 Global step 200 Train loss 5.99 on epoch=14
05/20/2022 12:50:06 - INFO - __main__ - Global step 200 Train loss 6.12 Classification-F1 0.0 on epoch=14
05/20/2022 12:50:07 - INFO - __main__ - Step 210 Global step 210 Train loss 6.13 on epoch=14
05/20/2022 12:50:08 - INFO - __main__ - Step 220 Global step 220 Train loss 5.73 on epoch=15
05/20/2022 12:50:09 - INFO - __main__ - Step 230 Global step 230 Train loss 6.13 on epoch=16
05/20/2022 12:50:11 - INFO - __main__ - Step 240 Global step 240 Train loss 6.02 on epoch=17
05/20/2022 12:50:12 - INFO - __main__ - Step 250 Global step 250 Train loss 5.66 on epoch=17
05/20/2022 12:51:12 - INFO - __main__ - Global step 250 Train loss 5.93 Classification-F1 0.0 on epoch=17
05/20/2022 12:51:14 - INFO - __main__ - Step 260 Global step 260 Train loss 5.88 on epoch=18
05/20/2022 12:51:15 - INFO - __main__ - Step 270 Global step 270 Train loss 5.65 on epoch=19
05/20/2022 12:51:16 - INFO - __main__ - Step 280 Global step 280 Train loss 5.84 on epoch=19
05/20/2022 12:51:17 - INFO - __main__ - Step 290 Global step 290 Train loss 5.53 on epoch=20
05/20/2022 12:51:19 - INFO - __main__ - Step 300 Global step 300 Train loss 5.82 on epoch=21
05/20/2022 12:51:43 - INFO - __main__ - Global step 300 Train loss 5.74 Classification-F1 0.0 on epoch=21
05/20/2022 12:51:44 - INFO - __main__ - Step 310 Global step 310 Train loss 5.72 on epoch=22
05/20/2022 12:51:45 - INFO - __main__ - Step 320 Global step 320 Train loss 5.49 on epoch=22
05/20/2022 12:51:47 - INFO - __main__ - Step 330 Global step 330 Train loss 5.70 on epoch=23
05/20/2022 12:51:48 - INFO - __main__ - Step 340 Global step 340 Train loss 5.55 on epoch=24
05/20/2022 12:51:49 - INFO - __main__ - Step 350 Global step 350 Train loss 5.62 on epoch=24
05/20/2022 12:52:03 - INFO - __main__ - Global step 350 Train loss 5.62 Classification-F1 0.0 on epoch=24
05/20/2022 12:52:04 - INFO - __main__ - Step 360 Global step 360 Train loss 5.40 on epoch=25
05/20/2022 12:52:05 - INFO - __main__ - Step 370 Global step 370 Train loss 5.43 on epoch=26
05/20/2022 12:52:06 - INFO - __main__ - Step 380 Global step 380 Train loss 5.48 on epoch=27
05/20/2022 12:52:08 - INFO - __main__ - Step 390 Global step 390 Train loss 5.19 on epoch=27
05/20/2022 12:52:09 - INFO - __main__ - Step 400 Global step 400 Train loss 5.44 on epoch=28
05/20/2022 12:52:13 - INFO - __main__ - Global step 400 Train loss 5.39 Classification-F1 0.0 on epoch=28
05/20/2022 12:52:14 - INFO - __main__ - Step 410 Global step 410 Train loss 5.10 on epoch=29
05/20/2022 12:52:15 - INFO - __main__ - Step 420 Global step 420 Train loss 5.43 on epoch=29
05/20/2022 12:52:17 - INFO - __main__ - Step 430 Global step 430 Train loss 5.11 on epoch=30
05/20/2022 12:52:18 - INFO - __main__ - Step 440 Global step 440 Train loss 5.28 on epoch=31
05/20/2022 12:52:19 - INFO - __main__ - Step 450 Global step 450 Train loss 5.17 on epoch=32
05/20/2022 12:52:22 - INFO - __main__ - Global step 450 Train loss 5.22 Classification-F1 0.005050505050505051 on epoch=32
05/20/2022 12:52:22 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005050505050505051 on epoch=32, global_step=450
05/20/2022 12:52:23 - INFO - __main__ - Step 460 Global step 460 Train loss 4.97 on epoch=32
05/20/2022 12:52:25 - INFO - __main__ - Step 470 Global step 470 Train loss 5.10 on epoch=33
05/20/2022 12:52:26 - INFO - __main__ - Step 480 Global step 480 Train loss 4.99 on epoch=34
05/20/2022 12:52:27 - INFO - __main__ - Step 490 Global step 490 Train loss 5.29 on epoch=34
05/20/2022 12:52:28 - INFO - __main__ - Step 500 Global step 500 Train loss 4.97 on epoch=35
05/20/2022 12:52:31 - INFO - __main__ - Global step 500 Train loss 5.06 Classification-F1 0.006521739130434782 on epoch=35
05/20/2022 12:52:31 - INFO - __main__ - Saving model with best Classification-F1: 0.005050505050505051 -> 0.006521739130434782 on epoch=35, global_step=500
05/20/2022 12:52:33 - INFO - __main__ - Step 510 Global step 510 Train loss 5.05 on epoch=36
05/20/2022 12:52:34 - INFO - __main__ - Step 520 Global step 520 Train loss 4.94 on epoch=37
05/20/2022 12:52:35 - INFO - __main__ - Step 530 Global step 530 Train loss 4.81 on epoch=37
05/20/2022 12:52:36 - INFO - __main__ - Step 540 Global step 540 Train loss 4.90 on epoch=38
05/20/2022 12:52:38 - INFO - __main__ - Step 550 Global step 550 Train loss 4.74 on epoch=39
05/20/2022 12:52:45 - INFO - __main__ - Global step 550 Train loss 4.89 Classification-F1 0.007183908045977012 on epoch=39
05/20/2022 12:52:45 - INFO - __main__ - Saving model with best Classification-F1: 0.006521739130434782 -> 0.007183908045977012 on epoch=39, global_step=550
05/20/2022 12:52:47 - INFO - __main__ - Step 560 Global step 560 Train loss 4.94 on epoch=39
05/20/2022 12:52:48 - INFO - __main__ - Step 570 Global step 570 Train loss 4.66 on epoch=40
05/20/2022 12:52:49 - INFO - __main__ - Step 580 Global step 580 Train loss 4.77 on epoch=41
05/20/2022 12:52:50 - INFO - __main__ - Step 590 Global step 590 Train loss 4.76 on epoch=42
05/20/2022 12:52:52 - INFO - __main__ - Step 600 Global step 600 Train loss 4.66 on epoch=42
05/20/2022 12:53:09 - INFO - __main__ - Global step 600 Train loss 4.76 Classification-F1 0.006410256410256411 on epoch=42
05/20/2022 12:53:10 - INFO - __main__ - Step 610 Global step 610 Train loss 4.65 on epoch=43
05/20/2022 12:53:11 - INFO - __main__ - Step 620 Global step 620 Train loss 4.39 on epoch=44
05/20/2022 12:53:12 - INFO - __main__ - Step 630 Global step 630 Train loss 4.76 on epoch=44
05/20/2022 12:53:14 - INFO - __main__ - Step 640 Global step 640 Train loss 4.42 on epoch=45
05/20/2022 12:53:15 - INFO - __main__ - Step 650 Global step 650 Train loss 5.00 on epoch=46
05/20/2022 12:53:27 - INFO - __main__ - Global step 650 Train loss 4.64 Classification-F1 0.00892608089260809 on epoch=46
05/20/2022 12:53:27 - INFO - __main__ - Saving model with best Classification-F1: 0.007183908045977012 -> 0.00892608089260809 on epoch=46, global_step=650
05/20/2022 12:53:28 - INFO - __main__ - Step 660 Global step 660 Train loss 4.49 on epoch=47
05/20/2022 12:53:30 - INFO - __main__ - Step 670 Global step 670 Train loss 4.38 on epoch=47
05/20/2022 12:53:31 - INFO - __main__ - Step 680 Global step 680 Train loss 4.43 on epoch=48
05/20/2022 12:53:32 - INFO - __main__ - Step 690 Global step 690 Train loss 4.30 on epoch=49
05/20/2022 12:53:33 - INFO - __main__ - Step 700 Global step 700 Train loss 4.70 on epoch=49
05/20/2022 12:53:35 - INFO - __main__ - Global step 700 Train loss 4.46 Classification-F1 0.009523809523809523 on epoch=49
05/20/2022 12:53:35 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=49, global_step=700
05/20/2022 12:53:37 - INFO - __main__ - Step 710 Global step 710 Train loss 4.27 on epoch=50
05/20/2022 12:53:38 - INFO - __main__ - Step 720 Global step 720 Train loss 4.39 on epoch=51
05/20/2022 12:53:39 - INFO - __main__ - Step 730 Global step 730 Train loss 4.46 on epoch=52
05/20/2022 12:53:40 - INFO - __main__ - Step 740 Global step 740 Train loss 4.26 on epoch=52
05/20/2022 12:53:42 - INFO - __main__ - Step 750 Global step 750 Train loss 4.29 on epoch=53
05/20/2022 12:53:44 - INFO - __main__ - Global step 750 Train loss 4.33 Classification-F1 0.01680672268907563 on epoch=53
05/20/2022 12:53:44 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01680672268907563 on epoch=53, global_step=750
05/20/2022 12:53:45 - INFO - __main__ - Step 760 Global step 760 Train loss 4.14 on epoch=54
05/20/2022 12:53:46 - INFO - __main__ - Step 770 Global step 770 Train loss 4.43 on epoch=54
05/20/2022 12:53:47 - INFO - __main__ - Step 780 Global step 780 Train loss 4.10 on epoch=55
05/20/2022 12:53:48 - INFO - __main__ - Step 790 Global step 790 Train loss 4.21 on epoch=56
05/20/2022 12:53:50 - INFO - __main__ - Step 800 Global step 800 Train loss 4.15 on epoch=57
05/20/2022 12:53:51 - INFO - __main__ - Global step 800 Train loss 4.21 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 12:53:53 - INFO - __main__ - Step 810 Global step 810 Train loss 4.08 on epoch=57
05/20/2022 12:53:54 - INFO - __main__ - Step 820 Global step 820 Train loss 4.19 on epoch=58
05/20/2022 12:53:55 - INFO - __main__ - Step 830 Global step 830 Train loss 4.15 on epoch=59
05/20/2022 12:53:56 - INFO - __main__ - Step 840 Global step 840 Train loss 4.08 on epoch=59
05/20/2022 12:53:58 - INFO - __main__ - Step 850 Global step 850 Train loss 4.00 on epoch=60
05/20/2022 12:54:00 - INFO - __main__ - Global step 850 Train loss 4.10 Classification-F1 0.02902852369017783 on epoch=60
05/20/2022 12:54:00 - INFO - __main__ - Saving model with best Classification-F1: 0.01680672268907563 -> 0.02902852369017783 on epoch=60, global_step=850
05/20/2022 12:54:01 - INFO - __main__ - Step 860 Global step 860 Train loss 4.07 on epoch=61
05/20/2022 12:54:02 - INFO - __main__ - Step 870 Global step 870 Train loss 3.97 on epoch=62
05/20/2022 12:54:03 - INFO - __main__ - Step 880 Global step 880 Train loss 4.09 on epoch=62
05/20/2022 12:54:05 - INFO - __main__ - Step 890 Global step 890 Train loss 4.04 on epoch=63
05/20/2022 12:54:06 - INFO - __main__ - Step 900 Global step 900 Train loss 4.01 on epoch=64
05/20/2022 12:54:08 - INFO - __main__ - Global step 900 Train loss 4.04 Classification-F1 0.01259538567150518 on epoch=64
05/20/2022 12:54:09 - INFO - __main__ - Step 910 Global step 910 Train loss 4.20 on epoch=64
05/20/2022 12:54:10 - INFO - __main__ - Step 920 Global step 920 Train loss 3.89 on epoch=65
05/20/2022 12:54:12 - INFO - __main__ - Step 930 Global step 930 Train loss 3.97 on epoch=66
05/20/2022 12:54:13 - INFO - __main__ - Step 940 Global step 940 Train loss 3.97 on epoch=67
05/20/2022 12:54:14 - INFO - __main__ - Step 950 Global step 950 Train loss 3.96 on epoch=67
05/20/2022 12:54:16 - INFO - __main__ - Global step 950 Train loss 4.00 Classification-F1 0.033948273948273947 on epoch=67
05/20/2022 12:54:16 - INFO - __main__ - Saving model with best Classification-F1: 0.02902852369017783 -> 0.033948273948273947 on epoch=67, global_step=950
05/20/2022 12:54:17 - INFO - __main__ - Step 960 Global step 960 Train loss 3.84 on epoch=68
05/20/2022 12:54:18 - INFO - __main__ - Step 970 Global step 970 Train loss 3.81 on epoch=69
05/20/2022 12:54:20 - INFO - __main__ - Step 980 Global step 980 Train loss 3.94 on epoch=69
05/20/2022 12:54:21 - INFO - __main__ - Step 990 Global step 990 Train loss 3.81 on epoch=70
05/20/2022 12:54:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.85 on epoch=71
05/20/2022 12:54:24 - INFO - __main__ - Global step 1000 Train loss 3.85 Classification-F1 0.027836117288370394 on epoch=71
05/20/2022 12:54:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.72 on epoch=72
05/20/2022 12:54:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.82 on epoch=72
05/20/2022 12:54:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.60 on epoch=73
05/20/2022 12:54:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.77 on epoch=74
05/20/2022 12:54:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.87 on epoch=74
05/20/2022 12:54:32 - INFO - __main__ - Global step 1050 Train loss 3.76 Classification-F1 0.03267599946156953 on epoch=74
05/20/2022 12:54:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.61 on epoch=75
05/20/2022 12:54:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.67 on epoch=76
05/20/2022 12:54:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.64 on epoch=77
05/20/2022 12:54:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.67 on epoch=77
05/20/2022 12:54:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.72 on epoch=78
05/20/2022 12:54:40 - INFO - __main__ - Global step 1100 Train loss 3.66 Classification-F1 0.02391395154553049 on epoch=78
05/20/2022 12:54:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.53 on epoch=79
05/20/2022 12:54:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.62 on epoch=79
05/20/2022 12:54:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.56 on epoch=80
05/20/2022 12:54:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.56 on epoch=81
05/20/2022 12:54:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.45 on epoch=82
05/20/2022 12:54:48 - INFO - __main__ - Global step 1150 Train loss 3.54 Classification-F1 0.030845335542797597 on epoch=82
05/20/2022 12:54:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.62 on epoch=82
05/20/2022 12:54:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.57 on epoch=83
05/20/2022 12:54:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.45 on epoch=84
05/20/2022 12:54:53 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.60 on epoch=84
05/20/2022 12:54:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.36 on epoch=85
05/20/2022 12:54:56 - INFO - __main__ - Global step 1200 Train loss 3.52 Classification-F1 0.037323322331073126 on epoch=85
05/20/2022 12:54:56 - INFO - __main__ - Saving model with best Classification-F1: 0.033948273948273947 -> 0.037323322331073126 on epoch=85, global_step=1200
05/20/2022 12:54:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.44 on epoch=86
05/20/2022 12:54:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.43 on epoch=87
05/20/2022 12:55:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.59 on epoch=87
05/20/2022 12:55:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.48 on epoch=88
05/20/2022 12:55:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.57 on epoch=89
05/20/2022 12:55:04 - INFO - __main__ - Global step 1250 Train loss 3.50 Classification-F1 0.022622375111545325 on epoch=89
05/20/2022 12:55:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.61 on epoch=89
05/20/2022 12:55:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.49 on epoch=90
05/20/2022 12:55:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.61 on epoch=91
05/20/2022 12:55:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.51 on epoch=92
05/20/2022 12:55:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.48 on epoch=92
05/20/2022 12:55:13 - INFO - __main__ - Global step 1300 Train loss 3.54 Classification-F1 0.012162759840778416 on epoch=92
05/20/2022 12:55:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.53 on epoch=93
05/20/2022 12:55:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.53 on epoch=94
05/20/2022 12:55:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.50 on epoch=94
05/20/2022 12:55:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.39 on epoch=95
05/20/2022 12:55:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.48 on epoch=96
05/20/2022 12:55:21 - INFO - __main__ - Global step 1350 Train loss 3.49 Classification-F1 0.02346962346962347 on epoch=96
05/20/2022 12:55:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.32 on epoch=97
05/20/2022 12:55:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.33 on epoch=97
05/20/2022 12:55:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.40 on epoch=98
05/20/2022 12:55:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.29 on epoch=99
05/20/2022 12:55:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.38 on epoch=99
05/20/2022 12:55:29 - INFO - __main__ - Global step 1400 Train loss 3.34 Classification-F1 0.03506898157814432 on epoch=99
05/20/2022 12:55:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.33 on epoch=100
05/20/2022 12:55:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.25 on epoch=101
05/20/2022 12:55:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.36 on epoch=102
05/20/2022 12:55:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.43 on epoch=102
05/20/2022 12:55:35 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.34 on epoch=103
05/20/2022 12:55:37 - INFO - __main__ - Global step 1450 Train loss 3.34 Classification-F1 0.04311540536381989 on epoch=103
05/20/2022 12:55:37 - INFO - __main__ - Saving model with best Classification-F1: 0.037323322331073126 -> 0.04311540536381989 on epoch=103, global_step=1450
05/20/2022 12:55:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.30 on epoch=104
05/20/2022 12:55:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.32 on epoch=104
05/20/2022 12:55:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.23 on epoch=105
05/20/2022 12:55:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.34 on epoch=106
05/20/2022 12:55:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.28 on epoch=107
05/20/2022 12:55:45 - INFO - __main__ - Global step 1500 Train loss 3.30 Classification-F1 0.045524454841225026 on epoch=107
05/20/2022 12:55:45 - INFO - __main__ - Saving model with best Classification-F1: 0.04311540536381989 -> 0.045524454841225026 on epoch=107, global_step=1500
05/20/2022 12:55:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.49 on epoch=107
05/20/2022 12:55:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.27 on epoch=108
05/20/2022 12:55:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.18 on epoch=109
05/20/2022 12:55:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.44 on epoch=109
05/20/2022 12:55:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.22 on epoch=110
05/20/2022 12:55:54 - INFO - __main__ - Global step 1550 Train loss 3.32 Classification-F1 0.02108428737348598 on epoch=110
05/20/2022 12:55:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.31 on epoch=111
05/20/2022 12:55:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.29 on epoch=112
05/20/2022 12:55:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.17 on epoch=112
05/20/2022 12:55:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.23 on epoch=113
05/20/2022 12:56:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.34 on epoch=114
05/20/2022 12:56:02 - INFO - __main__ - Global step 1600 Train loss 3.27 Classification-F1 0.04195208393000998 on epoch=114
05/20/2022 12:56:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.41 on epoch=114
05/20/2022 12:56:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.29 on epoch=115
05/20/2022 12:56:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.17 on epoch=116
05/20/2022 12:56:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.18 on epoch=117
05/20/2022 12:56:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.22 on epoch=117
05/20/2022 12:56:10 - INFO - __main__ - Global step 1650 Train loss 3.25 Classification-F1 0.04641714468542176 on epoch=117
05/20/2022 12:56:10 - INFO - __main__ - Saving model with best Classification-F1: 0.045524454841225026 -> 0.04641714468542176 on epoch=117, global_step=1650
05/20/2022 12:56:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.32 on epoch=118
05/20/2022 12:56:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.05 on epoch=119
05/20/2022 12:56:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.14 on epoch=119
05/20/2022 12:56:15 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.12 on epoch=120
05/20/2022 12:56:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.16 on epoch=121
05/20/2022 12:56:18 - INFO - __main__ - Global step 1700 Train loss 3.16 Classification-F1 0.046672016342300705 on epoch=121
05/20/2022 12:56:18 - INFO - __main__ - Saving model with best Classification-F1: 0.04641714468542176 -> 0.046672016342300705 on epoch=121, global_step=1700
05/20/2022 12:56:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.19 on epoch=122
05/20/2022 12:56:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.31 on epoch=122
05/20/2022 12:56:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.03 on epoch=123
05/20/2022 12:56:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.98 on epoch=124
05/20/2022 12:56:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.14 on epoch=124
05/20/2022 12:56:26 - INFO - __main__ - Global step 1750 Train loss 3.13 Classification-F1 0.03506934996676299 on epoch=124
05/20/2022 12:56:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.16 on epoch=125
05/20/2022 12:56:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.99 on epoch=126
05/20/2022 12:56:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.06 on epoch=127
05/20/2022 12:56:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.17 on epoch=127
05/20/2022 12:56:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.89 on epoch=128
05/20/2022 12:56:34 - INFO - __main__ - Global step 1800 Train loss 3.05 Classification-F1 0.027360160365086476 on epoch=128
05/20/2022 12:56:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.07 on epoch=129
05/20/2022 12:56:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.20 on epoch=129
05/20/2022 12:56:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.09 on epoch=130
05/20/2022 12:56:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.11 on epoch=131
05/20/2022 12:56:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.98 on epoch=132
05/20/2022 12:56:42 - INFO - __main__ - Global step 1850 Train loss 3.09 Classification-F1 0.04830607760239014 on epoch=132
05/20/2022 12:56:42 - INFO - __main__ - Saving model with best Classification-F1: 0.046672016342300705 -> 0.04830607760239014 on epoch=132, global_step=1850
05/20/2022 12:56:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.02 on epoch=132
05/20/2022 12:56:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.03 on epoch=133
05/20/2022 12:56:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.13 on epoch=134
05/20/2022 12:56:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.11 on epoch=134
05/20/2022 12:56:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.11 on epoch=135
05/20/2022 12:56:50 - INFO - __main__ - Global step 1900 Train loss 3.08 Classification-F1 0.021404899988164278 on epoch=135
05/20/2022 12:56:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.93 on epoch=136
05/20/2022 12:56:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.97 on epoch=137
05/20/2022 12:56:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.01 on epoch=137
05/20/2022 12:56:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.10 on epoch=138
05/20/2022 12:56:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.01 on epoch=139
05/20/2022 12:56:59 - INFO - __main__ - Global step 1950 Train loss 3.00 Classification-F1 0.00927643784786642 on epoch=139
05/20/2022 12:57:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.10 on epoch=139
05/20/2022 12:57:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.06 on epoch=140
05/20/2022 12:57:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.02 on epoch=141
05/20/2022 12:57:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.02 on epoch=142
05/20/2022 12:57:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.90 on epoch=142
05/20/2022 12:57:07 - INFO - __main__ - Global step 2000 Train loss 3.02 Classification-F1 0.013223249235222525 on epoch=142
05/20/2022 12:57:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.05 on epoch=143
05/20/2022 12:57:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.84 on epoch=144
05/20/2022 12:57:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.10 on epoch=144
05/20/2022 12:57:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.98 on epoch=145
05/20/2022 12:57:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.00 on epoch=146
05/20/2022 12:57:15 - INFO - __main__ - Global step 2050 Train loss 2.99 Classification-F1 0.018456213654292886 on epoch=146
05/20/2022 12:57:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.96 on epoch=147
05/20/2022 12:57:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.12 on epoch=147
05/20/2022 12:57:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.91 on epoch=148
05/20/2022 12:57:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.87 on epoch=149
05/20/2022 12:57:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.00 on epoch=149
05/20/2022 12:57:23 - INFO - __main__ - Global step 2100 Train loss 2.97 Classification-F1 0.013583638583638582 on epoch=149
05/20/2022 12:57:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.82 on epoch=150
05/20/2022 12:57:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.02 on epoch=151
05/20/2022 12:57:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.90 on epoch=152
05/20/2022 12:57:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.82 on epoch=152
05/20/2022 12:57:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.92 on epoch=153
05/20/2022 12:57:31 - INFO - __main__ - Global step 2150 Train loss 2.90 Classification-F1 0.03500566893424036 on epoch=153
05/20/2022 12:57:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.05 on epoch=154
05/20/2022 12:57:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.88 on epoch=154
05/20/2022 12:57:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.95 on epoch=155
05/20/2022 12:57:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.84 on epoch=156
05/20/2022 12:57:37 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.03 on epoch=157
05/20/2022 12:57:39 - INFO - __main__ - Global step 2200 Train loss 2.95 Classification-F1 0.04679183385534213 on epoch=157
05/20/2022 12:57:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.94 on epoch=157
05/20/2022 12:57:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.95 on epoch=158
05/20/2022 12:57:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.78 on epoch=159
05/20/2022 12:57:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.96 on epoch=159
05/20/2022 12:57:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.90 on epoch=160
05/20/2022 12:57:47 - INFO - __main__ - Global step 2250 Train loss 2.91 Classification-F1 0.024481792717086837 on epoch=160
05/20/2022 12:57:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.71 on epoch=161
05/20/2022 12:57:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.85 on epoch=162
05/20/2022 12:57:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.97 on epoch=162
05/20/2022 12:57:52 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.76 on epoch=163
05/20/2022 12:57:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.83 on epoch=164
05/20/2022 12:57:55 - INFO - __main__ - Global step 2300 Train loss 2.82 Classification-F1 0.046359587077960285 on epoch=164
05/20/2022 12:57:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.03 on epoch=164
05/20/2022 12:57:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.96 on epoch=165
05/20/2022 12:57:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.92 on epoch=166
05/20/2022 12:58:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.94 on epoch=167
05/20/2022 12:58:01 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.90 on epoch=167
05/20/2022 12:58:03 - INFO - __main__ - Global step 2350 Train loss 2.95 Classification-F1 0.05851316603196303 on epoch=167
05/20/2022 12:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.04830607760239014 -> 0.05851316603196303 on epoch=167, global_step=2350
05/20/2022 12:58:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.88 on epoch=168
05/20/2022 12:58:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.93 on epoch=169
05/20/2022 12:58:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.85 on epoch=169
05/20/2022 12:58:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.85 on epoch=170
05/20/2022 12:58:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.75 on epoch=171
05/20/2022 12:58:11 - INFO - __main__ - Global step 2400 Train loss 2.85 Classification-F1 0.02644981437551097 on epoch=171
05/20/2022 12:58:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.71 on epoch=172
05/20/2022 12:58:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.03 on epoch=172
05/20/2022 12:58:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.91 on epoch=173
05/20/2022 12:58:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.79 on epoch=174
05/20/2022 12:58:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.00 on epoch=174
05/20/2022 12:58:20 - INFO - __main__ - Global step 2450 Train loss 2.89 Classification-F1 0.016828087167070217 on epoch=174
05/20/2022 12:58:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.81 on epoch=175
05/20/2022 12:58:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.95 on epoch=176
05/20/2022 12:58:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.87 on epoch=177
05/20/2022 12:58:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.99 on epoch=177
05/20/2022 12:58:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.76 on epoch=178
05/20/2022 12:58:28 - INFO - __main__ - Global step 2500 Train loss 2.88 Classification-F1 0.009685230024213076 on epoch=178
05/20/2022 12:58:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.84 on epoch=179
05/20/2022 12:58:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.97 on epoch=179
05/20/2022 12:58:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.81 on epoch=180
05/20/2022 12:58:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.91 on epoch=181
05/20/2022 12:58:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.85 on epoch=182
05/20/2022 12:58:36 - INFO - __main__ - Global step 2550 Train loss 2.87 Classification-F1 0.009316770186335404 on epoch=182
05/20/2022 12:58:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.70 on epoch=182
05/20/2022 12:58:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.70 on epoch=183
05/20/2022 12:58:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.91 on epoch=184
05/20/2022 12:58:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.75 on epoch=184
05/20/2022 12:58:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.73 on epoch=185
05/20/2022 12:58:44 - INFO - __main__ - Global step 2600 Train loss 2.76 Classification-F1 0.015652173913043476 on epoch=185
05/20/2022 12:58:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.88 on epoch=186
05/20/2022 12:58:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.77 on epoch=187
05/20/2022 12:58:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.88 on epoch=187
05/20/2022 12:58:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.89 on epoch=188
05/20/2022 12:58:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.74 on epoch=189
05/20/2022 12:58:52 - INFO - __main__ - Global step 2650 Train loss 2.83 Classification-F1 0.009644364074743823 on epoch=189
05/20/2022 12:58:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.77 on epoch=189
05/20/2022 12:58:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.71 on epoch=190
05/20/2022 12:58:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.81 on epoch=191
05/20/2022 12:58:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.83 on epoch=192
05/20/2022 12:58:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.82 on epoch=192
05/20/2022 12:59:01 - INFO - __main__ - Global step 2700 Train loss 2.79 Classification-F1 0.025164835164835166 on epoch=192
05/20/2022 12:59:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.91 on epoch=193
05/20/2022 12:59:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.78 on epoch=194
05/20/2022 12:59:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.89 on epoch=194
05/20/2022 12:59:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.68 on epoch=195
05/20/2022 12:59:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/20/2022 12:59:09 - INFO - __main__ - Global step 2750 Train loss 2.84 Classification-F1 0.043001885338208326 on epoch=196
05/20/2022 12:59:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.79 on epoch=197
05/20/2022 12:59:12 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.79 on epoch=197
05/20/2022 12:59:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.72 on epoch=198
05/20/2022 12:59:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.68 on epoch=199
05/20/2022 12:59:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.78 on epoch=199
05/20/2022 12:59:17 - INFO - __main__ - Global step 2800 Train loss 2.75 Classification-F1 0.0189098998887653 on epoch=199
05/20/2022 12:59:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.80 on epoch=200
05/20/2022 12:59:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.73 on epoch=201
05/20/2022 12:59:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.84 on epoch=202
05/20/2022 12:59:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.78 on epoch=202
05/20/2022 12:59:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.68 on epoch=203
05/20/2022 12:59:26 - INFO - __main__ - Global step 2850 Train loss 2.76 Classification-F1 0.031145617667356802 on epoch=203
05/20/2022 12:59:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.63 on epoch=204
05/20/2022 12:59:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.76 on epoch=204
05/20/2022 12:59:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.68 on epoch=205
05/20/2022 12:59:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.65 on epoch=206
05/20/2022 12:59:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.76 on epoch=207
05/20/2022 12:59:34 - INFO - __main__ - Global step 2900 Train loss 2.69 Classification-F1 0.04006211180124224 on epoch=207
05/20/2022 12:59:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.78 on epoch=207
05/20/2022 12:59:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.57 on epoch=208
05/20/2022 12:59:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.65 on epoch=209
05/20/2022 12:59:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.71 on epoch=209
05/20/2022 12:59:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.60 on epoch=210
05/20/2022 12:59:43 - INFO - __main__ - Global step 2950 Train loss 2.66 Classification-F1 0.009523809523809523 on epoch=210
05/20/2022 12:59:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.68 on epoch=211
05/20/2022 12:59:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.93 on epoch=212
05/20/2022 12:59:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.74 on epoch=212
05/20/2022 12:59:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.68 on epoch=213
05/20/2022 12:59:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.69 on epoch=214
05/20/2022 12:59:51 - INFO - __main__ - Global step 3000 Train loss 2.74 Classification-F1 0.02791094586230164 on epoch=214
05/20/2022 12:59:51 - INFO - __main__ - save last model!
05/20/2022 12:59:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 12:59:51 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 12:59:51 - INFO - __main__ - Printing 3 examples
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 12:59:51 - INFO - __main__ - ['Animal']
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 12:59:51 - INFO - __main__ - ['Animal']
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 12:59:51 - INFO - __main__ - ['Village']
05/20/2022 12:59:51 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:59:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:59:51 - INFO - __main__ - Printing 3 examples
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 12:59:51 - INFO - __main__ - ['Company']
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 12:59:51 - INFO - __main__ - ['Company']
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 12:59:51 - INFO - __main__ - ['Company']
05/20/2022 12:59:51 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:59:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:59:51 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 12:59:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 12:59:51 - INFO - __main__ - Printing 3 examples
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 12:59:51 - INFO - __main__ - ['Company']
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 12:59:51 - INFO - __main__ - ['Company']
05/20/2022 12:59:51 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 12:59:51 - INFO - __main__ - ['Company']
05/20/2022 12:59:51 - INFO - __main__ - Tokenizing Input ...
05/20/2022 12:59:52 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:59:52 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 12:59:53 - INFO - __main__ - Tokenizing Output ...
05/20/2022 12:59:56 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 12:59:58 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 12:59:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 12:59:58 - INFO - __main__ - Starting training!
05/20/2022 13:00:28 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/20/2022 13:00:28 - INFO - __main__ - Classification-F1 on test data: 0.0245
05/20/2022 13:00:29 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.05851316603196303, test_performance=0.02453195594723706
05/20/2022 13:00:29 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/20/2022 13:00:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:00:30 - INFO - __main__ - Printing 3 examples
05/20/2022 13:00:30 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/20/2022 13:00:30 - INFO - __main__ - ['Company']
05/20/2022 13:00:30 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/20/2022 13:00:30 - INFO - __main__ - ['Company']
05/20/2022 13:00:30 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/20/2022 13:00:30 - INFO - __main__ - ['Company']
05/20/2022 13:00:30 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:00:30 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:00:30 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:00:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:00:30 - INFO - __main__ - Printing 3 examples
05/20/2022 13:00:30 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/20/2022 13:00:30 - INFO - __main__ - ['Company']
05/20/2022 13:00:30 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/20/2022 13:00:30 - INFO - __main__ - ['Company']
05/20/2022 13:00:30 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/20/2022 13:00:30 - INFO - __main__ - ['Company']
05/20/2022 13:00:30 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:00:30 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:00:30 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:00:36 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:00:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:00:37 - INFO - __main__ - Starting training!
05/20/2022 13:00:38 - INFO - __main__ - Step 10 Global step 10 Train loss 7.33 on epoch=0
05/20/2022 13:00:40 - INFO - __main__ - Step 20 Global step 20 Train loss 7.59 on epoch=1
05/20/2022 13:00:41 - INFO - __main__ - Step 30 Global step 30 Train loss 7.56 on epoch=2
05/20/2022 13:00:42 - INFO - __main__ - Step 40 Global step 40 Train loss 7.00 on epoch=2
05/20/2022 13:00:43 - INFO - __main__ - Step 50 Global step 50 Train loss 7.35 on epoch=3
05/20/2022 13:00:53 - INFO - __main__ - Global step 50 Train loss 7.37 Classification-F1 0.0 on epoch=3
05/20/2022 13:00:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 13:00:54 - INFO - __main__ - Step 60 Global step 60 Train loss 7.08 on epoch=4
05/20/2022 13:00:55 - INFO - __main__ - Step 70 Global step 70 Train loss 7.19 on epoch=4
05/20/2022 13:00:57 - INFO - __main__ - Step 80 Global step 80 Train loss 6.90 on epoch=5
05/20/2022 13:00:58 - INFO - __main__ - Step 90 Global step 90 Train loss 6.99 on epoch=6
05/20/2022 13:00:59 - INFO - __main__ - Step 100 Global step 100 Train loss 6.99 on epoch=7
05/20/2022 13:01:38 - INFO - __main__ - Global step 100 Train loss 7.03 Classification-F1 0.0 on epoch=7
05/20/2022 13:01:39 - INFO - __main__ - Step 110 Global step 110 Train loss 6.62 on epoch=7
05/20/2022 13:01:40 - INFO - __main__ - Step 120 Global step 120 Train loss 6.95 on epoch=8
05/20/2022 13:01:41 - INFO - __main__ - Step 130 Global step 130 Train loss 6.75 on epoch=9
05/20/2022 13:01:43 - INFO - __main__ - Step 140 Global step 140 Train loss 6.94 on epoch=9
05/20/2022 13:01:44 - INFO - __main__ - Step 150 Global step 150 Train loss 6.47 on epoch=10
05/20/2022 13:02:32 - INFO - __main__ - Global step 150 Train loss 6.74 Classification-F1 0.0 on epoch=10
05/20/2022 13:02:34 - INFO - __main__ - Step 160 Global step 160 Train loss 6.85 on epoch=11
05/20/2022 13:02:35 - INFO - __main__ - Step 170 Global step 170 Train loss 6.77 on epoch=12
05/20/2022 13:02:36 - INFO - __main__ - Step 180 Global step 180 Train loss 6.38 on epoch=12
05/20/2022 13:02:38 - INFO - __main__ - Step 190 Global step 190 Train loss 6.73 on epoch=13
05/20/2022 13:02:39 - INFO - __main__ - Step 200 Global step 200 Train loss 6.39 on epoch=14
05/20/2022 13:03:51 - INFO - __main__ - Global step 200 Train loss 6.62 Classification-F1 0.0 on epoch=14
05/20/2022 13:03:53 - INFO - __main__ - Step 210 Global step 210 Train loss 6.63 on epoch=14
05/20/2022 13:03:54 - INFO - __main__ - Step 220 Global step 220 Train loss 6.22 on epoch=15
05/20/2022 13:03:55 - INFO - __main__ - Step 230 Global step 230 Train loss 6.54 on epoch=16
05/20/2022 13:03:56 - INFO - __main__ - Step 240 Global step 240 Train loss 6.39 on epoch=17
05/20/2022 13:03:58 - INFO - __main__ - Step 250 Global step 250 Train loss 6.21 on epoch=17
05/20/2022 13:05:12 - INFO - __main__ - Global step 250 Train loss 6.40 Classification-F1 0.0 on epoch=17
05/20/2022 13:05:13 - INFO - __main__ - Step 260 Global step 260 Train loss 6.45 on epoch=18
05/20/2022 13:05:15 - INFO - __main__ - Step 270 Global step 270 Train loss 6.16 on epoch=19
05/20/2022 13:05:16 - INFO - __main__ - Step 280 Global step 280 Train loss 6.35 on epoch=19
05/20/2022 13:05:17 - INFO - __main__ - Step 290 Global step 290 Train loss 6.01 on epoch=20
05/20/2022 13:05:19 - INFO - __main__ - Step 300 Global step 300 Train loss 6.29 on epoch=21
05/20/2022 13:06:35 - INFO - __main__ - Global step 300 Train loss 6.25 Classification-F1 0.0 on epoch=21
05/20/2022 13:06:37 - INFO - __main__ - Step 310 Global step 310 Train loss 6.12 on epoch=22
05/20/2022 13:06:38 - INFO - __main__ - Step 320 Global step 320 Train loss 5.87 on epoch=22
05/20/2022 13:06:39 - INFO - __main__ - Step 330 Global step 330 Train loss 6.08 on epoch=23
05/20/2022 13:06:40 - INFO - __main__ - Step 340 Global step 340 Train loss 5.95 on epoch=24
05/20/2022 13:06:42 - INFO - __main__ - Step 350 Global step 350 Train loss 6.02 on epoch=24
05/20/2022 13:08:00 - INFO - __main__ - Global step 350 Train loss 6.01 Classification-F1 0.0 on epoch=24
05/20/2022 13:08:01 - INFO - __main__ - Step 360 Global step 360 Train loss 5.83 on epoch=25
05/20/2022 13:08:02 - INFO - __main__ - Step 370 Global step 370 Train loss 5.92 on epoch=26
05/20/2022 13:08:04 - INFO - __main__ - Step 380 Global step 380 Train loss 5.99 on epoch=27
05/20/2022 13:08:05 - INFO - __main__ - Step 390 Global step 390 Train loss 5.64 on epoch=27
05/20/2022 13:08:06 - INFO - __main__ - Step 400 Global step 400 Train loss 5.93 on epoch=28
05/20/2022 13:09:26 - INFO - __main__ - Global step 400 Train loss 5.86 Classification-F1 0.0 on epoch=28
05/20/2022 13:09:27 - INFO - __main__ - Step 410 Global step 410 Train loss 5.83 on epoch=29
05/20/2022 13:09:28 - INFO - __main__ - Step 420 Global step 420 Train loss 5.87 on epoch=29
05/20/2022 13:09:29 - INFO - __main__ - Step 430 Global step 430 Train loss 5.66 on epoch=30
05/20/2022 13:09:31 - INFO - __main__ - Step 440 Global step 440 Train loss 5.63 on epoch=31
05/20/2022 13:09:32 - INFO - __main__ - Step 450 Global step 450 Train loss 5.68 on epoch=32
05/20/2022 13:10:08 - INFO - __main__ - Global step 450 Train loss 5.73 Classification-F1 0.0 on epoch=32
05/20/2022 13:10:10 - INFO - __main__ - Step 460 Global step 460 Train loss 5.39 on epoch=32
05/20/2022 13:10:11 - INFO - __main__ - Step 470 Global step 470 Train loss 5.63 on epoch=33
05/20/2022 13:10:12 - INFO - __main__ - Step 480 Global step 480 Train loss 5.35 on epoch=34
05/20/2022 13:10:13 - INFO - __main__ - Step 490 Global step 490 Train loss 5.71 on epoch=34
05/20/2022 13:10:15 - INFO - __main__ - Step 500 Global step 500 Train loss 5.46 on epoch=35
05/20/2022 13:10:49 - INFO - __main__ - Global step 500 Train loss 5.51 Classification-F1 0.0 on epoch=35
05/20/2022 13:10:50 - INFO - __main__ - Step 510 Global step 510 Train loss 5.52 on epoch=36
05/20/2022 13:10:51 - INFO - __main__ - Step 520 Global step 520 Train loss 5.52 on epoch=37
05/20/2022 13:10:52 - INFO - __main__ - Step 530 Global step 530 Train loss 5.27 on epoch=37
05/20/2022 13:10:54 - INFO - __main__ - Step 540 Global step 540 Train loss 5.44 on epoch=38
05/20/2022 13:10:55 - INFO - __main__ - Step 550 Global step 550 Train loss 5.28 on epoch=39
05/20/2022 13:11:23 - INFO - __main__ - Global step 550 Train loss 5.41 Classification-F1 0.0009775171065493648 on epoch=39
05/20/2022 13:11:23 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0009775171065493648 on epoch=39, global_step=550
05/20/2022 13:11:24 - INFO - __main__ - Step 560 Global step 560 Train loss 5.44 on epoch=39
05/20/2022 13:11:26 - INFO - __main__ - Step 570 Global step 570 Train loss 5.22 on epoch=40
05/20/2022 13:11:27 - INFO - __main__ - Step 580 Global step 580 Train loss 5.32 on epoch=41
05/20/2022 13:11:28 - INFO - __main__ - Step 590 Global step 590 Train loss 5.28 on epoch=42
05/20/2022 13:11:29 - INFO - __main__ - Step 600 Global step 600 Train loss 5.19 on epoch=42
05/20/2022 13:11:42 - INFO - __main__ - Global step 600 Train loss 5.29 Classification-F1 0.002197802197802198 on epoch=42
05/20/2022 13:11:42 - INFO - __main__ - Saving model with best Classification-F1: 0.0009775171065493648 -> 0.002197802197802198 on epoch=42, global_step=600
05/20/2022 13:11:43 - INFO - __main__ - Step 610 Global step 610 Train loss 5.42 on epoch=43
05/20/2022 13:11:45 - INFO - __main__ - Step 620 Global step 620 Train loss 5.12 on epoch=44
05/20/2022 13:11:46 - INFO - __main__ - Step 630 Global step 630 Train loss 5.42 on epoch=44
05/20/2022 13:11:47 - INFO - __main__ - Step 640 Global step 640 Train loss 4.96 on epoch=45
05/20/2022 13:11:48 - INFO - __main__ - Step 650 Global step 650 Train loss 5.20 on epoch=46
05/20/2022 13:11:51 - INFO - __main__ - Global step 650 Train loss 5.22 Classification-F1 0.006284038542103057 on epoch=46
05/20/2022 13:11:51 - INFO - __main__ - Saving model with best Classification-F1: 0.002197802197802198 -> 0.006284038542103057 on epoch=46, global_step=650
05/20/2022 13:11:53 - INFO - __main__ - Step 660 Global step 660 Train loss 5.14 on epoch=47
05/20/2022 13:11:54 - INFO - __main__ - Step 670 Global step 670 Train loss 4.91 on epoch=47
05/20/2022 13:11:55 - INFO - __main__ - Step 680 Global step 680 Train loss 5.13 on epoch=48
05/20/2022 13:11:56 - INFO - __main__ - Step 690 Global step 690 Train loss 5.03 on epoch=49
05/20/2022 13:11:58 - INFO - __main__ - Step 700 Global step 700 Train loss 5.19 on epoch=49
05/20/2022 13:12:00 - INFO - __main__ - Global step 700 Train loss 5.08 Classification-F1 0.00640614990390775 on epoch=49
05/20/2022 13:12:00 - INFO - __main__ - Saving model with best Classification-F1: 0.006284038542103057 -> 0.00640614990390775 on epoch=49, global_step=700
05/20/2022 13:12:02 - INFO - __main__ - Step 710 Global step 710 Train loss 4.89 on epoch=50
05/20/2022 13:12:03 - INFO - __main__ - Step 720 Global step 720 Train loss 5.08 on epoch=51
05/20/2022 13:12:04 - INFO - __main__ - Step 730 Global step 730 Train loss 4.90 on epoch=52
05/20/2022 13:12:05 - INFO - __main__ - Step 740 Global step 740 Train loss 4.75 on epoch=52
05/20/2022 13:12:07 - INFO - __main__ - Step 750 Global step 750 Train loss 4.87 on epoch=53
05/20/2022 13:12:09 - INFO - __main__ - Global step 750 Train loss 4.90 Classification-F1 0.007942417473318442 on epoch=53
05/20/2022 13:12:09 - INFO - __main__ - Saving model with best Classification-F1: 0.00640614990390775 -> 0.007942417473318442 on epoch=53, global_step=750
05/20/2022 13:12:10 - INFO - __main__ - Step 760 Global step 760 Train loss 4.79 on epoch=54
05/20/2022 13:12:12 - INFO - __main__ - Step 770 Global step 770 Train loss 4.99 on epoch=54
05/20/2022 13:12:13 - INFO - __main__ - Step 780 Global step 780 Train loss 4.65 on epoch=55
05/20/2022 13:12:14 - INFO - __main__ - Step 790 Global step 790 Train loss 4.84 on epoch=56
05/20/2022 13:12:16 - INFO - __main__ - Step 800 Global step 800 Train loss 4.80 on epoch=57
05/20/2022 13:12:18 - INFO - __main__ - Global step 800 Train loss 4.81 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 13:12:18 - INFO - __main__ - Saving model with best Classification-F1: 0.007942417473318442 -> 0.009523809523809523 on epoch=57, global_step=800
05/20/2022 13:12:19 - INFO - __main__ - Step 810 Global step 810 Train loss 4.72 on epoch=57
05/20/2022 13:12:21 - INFO - __main__ - Step 820 Global step 820 Train loss 4.89 on epoch=58
05/20/2022 13:12:22 - INFO - __main__ - Step 830 Global step 830 Train loss 4.71 on epoch=59
05/20/2022 13:12:23 - INFO - __main__ - Step 840 Global step 840 Train loss 4.85 on epoch=59
05/20/2022 13:12:24 - INFO - __main__ - Step 850 Global step 850 Train loss 4.76 on epoch=60
05/20/2022 13:12:27 - INFO - __main__ - Global step 850 Train loss 4.79 Classification-F1 0.009523809523809523 on epoch=60
05/20/2022 13:12:28 - INFO - __main__ - Step 860 Global step 860 Train loss 4.79 on epoch=61
05/20/2022 13:12:29 - INFO - __main__ - Step 870 Global step 870 Train loss 4.70 on epoch=62
05/20/2022 13:12:31 - INFO - __main__ - Step 880 Global step 880 Train loss 4.53 on epoch=62
05/20/2022 13:12:32 - INFO - __main__ - Step 890 Global step 890 Train loss 4.64 on epoch=63
05/20/2022 13:12:33 - INFO - __main__ - Step 900 Global step 900 Train loss 4.61 on epoch=64
05/20/2022 13:12:35 - INFO - __main__ - Global step 900 Train loss 4.66 Classification-F1 0.009523809523809523 on epoch=64
05/20/2022 13:12:37 - INFO - __main__ - Step 910 Global step 910 Train loss 4.88 on epoch=64
05/20/2022 13:12:38 - INFO - __main__ - Step 920 Global step 920 Train loss 4.49 on epoch=65
05/20/2022 13:12:39 - INFO - __main__ - Step 930 Global step 930 Train loss 4.62 on epoch=66
05/20/2022 13:12:40 - INFO - __main__ - Step 940 Global step 940 Train loss 4.53 on epoch=67
05/20/2022 13:12:42 - INFO - __main__ - Step 950 Global step 950 Train loss 4.44 on epoch=67
05/20/2022 13:12:44 - INFO - __main__ - Global step 950 Train loss 4.59 Classification-F1 0.009523809523809523 on epoch=67
05/20/2022 13:12:45 - INFO - __main__ - Step 960 Global step 960 Train loss 4.53 on epoch=68
05/20/2022 13:12:46 - INFO - __main__ - Step 970 Global step 970 Train loss 4.39 on epoch=69
05/20/2022 13:12:47 - INFO - __main__ - Step 980 Global step 980 Train loss 4.67 on epoch=69
05/20/2022 13:12:49 - INFO - __main__ - Step 990 Global step 990 Train loss 4.48 on epoch=70
05/20/2022 13:12:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.59 on epoch=71
05/20/2022 13:12:52 - INFO - __main__ - Global step 1000 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=71
05/20/2022 13:12:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.29 on epoch=72
05/20/2022 13:12:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.26 on epoch=72
05/20/2022 13:12:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.47 on epoch=73
05/20/2022 13:12:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.23 on epoch=74
05/20/2022 13:12:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.45 on epoch=74
05/20/2022 13:13:00 - INFO - __main__ - Global step 1050 Train loss 4.34 Classification-F1 0.009523809523809523 on epoch=74
05/20/2022 13:13:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.29 on epoch=75
05/20/2022 13:13:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.27 on epoch=76
05/20/2022 13:13:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.28 on epoch=77
05/20/2022 13:13:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.14 on epoch=77
05/20/2022 13:13:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.25 on epoch=78
05/20/2022 13:13:08 - INFO - __main__ - Global step 1100 Train loss 4.24 Classification-F1 0.009523809523809523 on epoch=78
05/20/2022 13:13:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.27 on epoch=79
05/20/2022 13:13:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.28 on epoch=79
05/20/2022 13:13:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.00 on epoch=80
05/20/2022 13:13:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.22 on epoch=81
05/20/2022 13:13:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.17 on epoch=82
05/20/2022 13:13:16 - INFO - __main__ - Global step 1150 Train loss 4.19 Classification-F1 0.009523809523809523 on epoch=82
05/20/2022 13:13:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.26 on epoch=82
05/20/2022 13:13:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.04 on epoch=83
05/20/2022 13:13:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.11 on epoch=84
05/20/2022 13:13:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.11 on epoch=84
05/20/2022 13:13:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.01 on epoch=85
05/20/2022 13:13:25 - INFO - __main__ - Global step 1200 Train loss 4.11 Classification-F1 0.01796701944376077 on epoch=85
05/20/2022 13:13:25 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01796701944376077 on epoch=85, global_step=1200
05/20/2022 13:13:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.15 on epoch=86
05/20/2022 13:13:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.02 on epoch=87
05/20/2022 13:13:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.99 on epoch=87
05/20/2022 13:13:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.98 on epoch=88
05/20/2022 13:13:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.02 on epoch=89
05/20/2022 13:13:33 - INFO - __main__ - Global step 1250 Train loss 4.03 Classification-F1 0.029210814760686883 on epoch=89
05/20/2022 13:13:33 - INFO - __main__ - Saving model with best Classification-F1: 0.01796701944376077 -> 0.029210814760686883 on epoch=89, global_step=1250
05/20/2022 13:13:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.15 on epoch=89
05/20/2022 13:13:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.88 on epoch=90
05/20/2022 13:13:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.09 on epoch=91
05/20/2022 13:13:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.06 on epoch=92
05/20/2022 13:13:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.93 on epoch=92
05/20/2022 13:13:41 - INFO - __main__ - Global step 1300 Train loss 4.02 Classification-F1 0.016618075801749267 on epoch=92
05/20/2022 13:13:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.89 on epoch=93
05/20/2022 13:13:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.00 on epoch=94
05/20/2022 13:13:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.94 on epoch=94
05/20/2022 13:13:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.83 on epoch=95
05/20/2022 13:13:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.91 on epoch=96
05/20/2022 13:13:49 - INFO - __main__ - Global step 1350 Train loss 3.91 Classification-F1 0.01724307022940238 on epoch=96
05/20/2022 13:13:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.73 on epoch=97
05/20/2022 13:13:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.89 on epoch=97
05/20/2022 13:13:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.79 on epoch=98
05/20/2022 13:13:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.83 on epoch=99
05/20/2022 13:13:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.83 on epoch=99
05/20/2022 13:13:57 - INFO - __main__ - Global step 1400 Train loss 3.81 Classification-F1 0.013267418768749737 on epoch=99
05/20/2022 13:13:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.67 on epoch=100
05/20/2022 13:14:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.77 on epoch=101
05/20/2022 13:14:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.65 on epoch=102
05/20/2022 13:14:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.74 on epoch=102
05/20/2022 13:14:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.70 on epoch=103
05/20/2022 13:14:06 - INFO - __main__ - Global step 1450 Train loss 3.71 Classification-F1 0.009563658099222952 on epoch=103
05/20/2022 13:14:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.54 on epoch=104
05/20/2022 13:14:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.82 on epoch=104
05/20/2022 13:14:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.61 on epoch=105
05/20/2022 13:14:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.56 on epoch=106
05/20/2022 13:14:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.48 on epoch=107
05/20/2022 13:14:14 - INFO - __main__ - Global step 1500 Train loss 3.60 Classification-F1 0.009644364074743823 on epoch=107
05/20/2022 13:14:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.61 on epoch=107
05/20/2022 13:14:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.64 on epoch=108
05/20/2022 13:14:18 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.50 on epoch=109
05/20/2022 13:14:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.67 on epoch=109
05/20/2022 13:14:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.50 on epoch=110
05/20/2022 13:14:22 - INFO - __main__ - Global step 1550 Train loss 3.58 Classification-F1 0.009563658099222952 on epoch=110
05/20/2022 13:14:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.41 on epoch=111
05/20/2022 13:14:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.56 on epoch=112
05/20/2022 13:14:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.54 on epoch=112
05/20/2022 13:14:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.56 on epoch=113
05/20/2022 13:14:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.64 on epoch=114
05/20/2022 13:14:30 - INFO - __main__ - Global step 1600 Train loss 3.54 Classification-F1 0.017163161067225024 on epoch=114
05/20/2022 13:14:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.66 on epoch=114
05/20/2022 13:14:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.52 on epoch=115
05/20/2022 13:14:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.59 on epoch=116
05/20/2022 13:14:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.62 on epoch=117
05/20/2022 13:14:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.57 on epoch=117
05/20/2022 13:14:39 - INFO - __main__ - Global step 1650 Train loss 3.59 Classification-F1 0.024042555098455716 on epoch=117
05/20/2022 13:14:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.45 on epoch=118
05/20/2022 13:14:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.40 on epoch=119
05/20/2022 13:14:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.51 on epoch=119
05/20/2022 13:14:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.50 on epoch=120
05/20/2022 13:14:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.52 on epoch=121
05/20/2022 13:14:47 - INFO - __main__ - Global step 1700 Train loss 3.48 Classification-F1 0.024675324675324677 on epoch=121
05/20/2022 13:14:48 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.47 on epoch=122
05/20/2022 13:14:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.40 on epoch=122
05/20/2022 13:14:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.27 on epoch=123
05/20/2022 13:14:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.38 on epoch=124
05/20/2022 13:14:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.37 on epoch=124
05/20/2022 13:14:55 - INFO - __main__ - Global step 1750 Train loss 3.38 Classification-F1 0.03539319501264533 on epoch=124
05/20/2022 13:14:55 - INFO - __main__ - Saving model with best Classification-F1: 0.029210814760686883 -> 0.03539319501264533 on epoch=124, global_step=1750
05/20/2022 13:14:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.42 on epoch=125
05/20/2022 13:14:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.49 on epoch=126
05/20/2022 13:14:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.42 on epoch=127
05/20/2022 13:15:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.35 on epoch=127
05/20/2022 13:15:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.33 on epoch=128
05/20/2022 13:15:03 - INFO - __main__ - Global step 1800 Train loss 3.40 Classification-F1 0.020719040684715744 on epoch=128
05/20/2022 13:15:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.36 on epoch=129
05/20/2022 13:15:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.36 on epoch=129
05/20/2022 13:15:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.25 on epoch=130
05/20/2022 13:15:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.30 on epoch=131
05/20/2022 13:15:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.21 on epoch=132
05/20/2022 13:15:11 - INFO - __main__ - Global step 1850 Train loss 3.30 Classification-F1 0.04694632765972536 on epoch=132
05/20/2022 13:15:12 - INFO - __main__ - Saving model with best Classification-F1: 0.03539319501264533 -> 0.04694632765972536 on epoch=132, global_step=1850
05/20/2022 13:15:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.40 on epoch=132
05/20/2022 13:15:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.18 on epoch=133
05/20/2022 13:15:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.25 on epoch=134
05/20/2022 13:15:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.36 on epoch=134
05/20/2022 13:15:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.34 on epoch=135
05/20/2022 13:15:20 - INFO - __main__ - Global step 1900 Train loss 3.31 Classification-F1 0.027522268251751532 on epoch=135
05/20/2022 13:15:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.30 on epoch=136
05/20/2022 13:15:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.26 on epoch=137
05/20/2022 13:15:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.19 on epoch=137
05/20/2022 13:15:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.17 on epoch=138
05/20/2022 13:15:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.26 on epoch=139
05/20/2022 13:15:28 - INFO - __main__ - Global step 1950 Train loss 3.24 Classification-F1 0.00976800976800977 on epoch=139
05/20/2022 13:15:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.25 on epoch=139
05/20/2022 13:15:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.16 on epoch=140
05/20/2022 13:15:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.09 on epoch=141
05/20/2022 13:15:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.21 on epoch=142
05/20/2022 13:15:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.30 on epoch=142
05/20/2022 13:15:36 - INFO - __main__ - Global step 2000 Train loss 3.20 Classification-F1 0.010342598577892695 on epoch=142
05/20/2022 13:15:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.07 on epoch=143
05/20/2022 13:15:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.15 on epoch=144
05/20/2022 13:15:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.15 on epoch=144
05/20/2022 13:15:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.35 on epoch=145
05/20/2022 13:15:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.23 on epoch=146
05/20/2022 13:15:44 - INFO - __main__ - Global step 2050 Train loss 3.19 Classification-F1 0.04818032941072327 on epoch=146
05/20/2022 13:15:44 - INFO - __main__ - Saving model with best Classification-F1: 0.04694632765972536 -> 0.04818032941072327 on epoch=146, global_step=2050
05/20/2022 13:15:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.17 on epoch=147
05/20/2022 13:15:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.13 on epoch=147
05/20/2022 13:15:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.14 on epoch=148
05/20/2022 13:15:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.07 on epoch=149
05/20/2022 13:15:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.14 on epoch=149
05/20/2022 13:15:52 - INFO - __main__ - Global step 2100 Train loss 3.13 Classification-F1 0.0552718062260047 on epoch=149
05/20/2022 13:15:52 - INFO - __main__ - Saving model with best Classification-F1: 0.04818032941072327 -> 0.0552718062260047 on epoch=149, global_step=2100
05/20/2022 13:15:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.06 on epoch=150
05/20/2022 13:15:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.12 on epoch=151
05/20/2022 13:15:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.16 on epoch=152
05/20/2022 13:15:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.09 on epoch=152
05/20/2022 13:15:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.12 on epoch=153
05/20/2022 13:16:00 - INFO - __main__ - Global step 2150 Train loss 3.11 Classification-F1 0.03472338073035329 on epoch=153
05/20/2022 13:16:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.16 on epoch=154
05/20/2022 13:16:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.11 on epoch=154
05/20/2022 13:16:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.12 on epoch=155
05/20/2022 13:16:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.07 on epoch=156
05/20/2022 13:16:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.06 on epoch=157
05/20/2022 13:16:08 - INFO - __main__ - Global step 2200 Train loss 3.10 Classification-F1 0.022954485661667984 on epoch=157
05/20/2022 13:16:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.18 on epoch=157
05/20/2022 13:16:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.16 on epoch=158
05/20/2022 13:16:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.99 on epoch=159
05/20/2022 13:16:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.12 on epoch=159
05/20/2022 13:16:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.99 on epoch=160
05/20/2022 13:16:16 - INFO - __main__ - Global step 2250 Train loss 3.09 Classification-F1 0.02650290885585003 on epoch=160
05/20/2022 13:16:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.05 on epoch=161
05/20/2022 13:16:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.07 on epoch=162
05/20/2022 13:16:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.02 on epoch=162
05/20/2022 13:16:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.99 on epoch=163
05/20/2022 13:16:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.96 on epoch=164
05/20/2022 13:16:25 - INFO - __main__ - Global step 2300 Train loss 3.02 Classification-F1 0.020205600850762142 on epoch=164
05/20/2022 13:16:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.11 on epoch=164
05/20/2022 13:16:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.05 on epoch=165
05/20/2022 13:16:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.94 on epoch=166
05/20/2022 13:16:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.00 on epoch=167
05/20/2022 13:16:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.10 on epoch=167
05/20/2022 13:16:33 - INFO - __main__ - Global step 2350 Train loss 3.04 Classification-F1 0.019029314860184166 on epoch=167
05/20/2022 13:16:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.06 on epoch=168
05/20/2022 13:16:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.89 on epoch=169
05/20/2022 13:16:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.84 on epoch=169
05/20/2022 13:16:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.92 on epoch=170
05/20/2022 13:16:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 3.15 on epoch=171
05/20/2022 13:16:41 - INFO - __main__ - Global step 2400 Train loss 2.97 Classification-F1 0.022183117367887806 on epoch=171
05/20/2022 13:16:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.97 on epoch=172
05/20/2022 13:16:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.94 on epoch=172
05/20/2022 13:16:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.26 on epoch=173
05/20/2022 13:16:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.89 on epoch=174
05/20/2022 13:16:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.05 on epoch=174
05/20/2022 13:16:49 - INFO - __main__ - Global step 2450 Train loss 3.02 Classification-F1 0.014139581758629378 on epoch=174
05/20/2022 13:16:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.84 on epoch=175
05/20/2022 13:16:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.87 on epoch=176
05/20/2022 13:16:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.97 on epoch=177
05/20/2022 13:16:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.92 on epoch=177
05/20/2022 13:16:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.87 on epoch=178
05/20/2022 13:16:57 - INFO - __main__ - Global step 2500 Train loss 2.89 Classification-F1 0.01773445696686635 on epoch=178
05/20/2022 13:16:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.89 on epoch=179
05/20/2022 13:17:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.91 on epoch=179
05/20/2022 13:17:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.87 on epoch=180
05/20/2022 13:17:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.04 on epoch=181
05/20/2022 13:17:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.00 on epoch=182
05/20/2022 13:17:05 - INFO - __main__ - Global step 2550 Train loss 2.94 Classification-F1 0.025985125985125986 on epoch=182
05/20/2022 13:17:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.91 on epoch=182
05/20/2022 13:17:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.78 on epoch=183
05/20/2022 13:17:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.84 on epoch=184
05/20/2022 13:17:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.87 on epoch=184
05/20/2022 13:17:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.88 on epoch=185
05/20/2022 13:17:13 - INFO - __main__ - Global step 2600 Train loss 2.86 Classification-F1 0.0467401141743247 on epoch=185
05/20/2022 13:17:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.88 on epoch=186
05/20/2022 13:17:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.95 on epoch=187
05/20/2022 13:17:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 3.02 on epoch=187
05/20/2022 13:17:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.81 on epoch=188
05/20/2022 13:17:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.67 on epoch=189
05/20/2022 13:17:22 - INFO - __main__ - Global step 2650 Train loss 2.86 Classification-F1 0.02337600058231268 on epoch=189
05/20/2022 13:17:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.94 on epoch=189
05/20/2022 13:17:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.60 on epoch=190
05/20/2022 13:17:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.82 on epoch=191
05/20/2022 13:17:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.90 on epoch=192
05/20/2022 13:17:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.79 on epoch=192
05/20/2022 13:17:30 - INFO - __main__ - Global step 2700 Train loss 2.81 Classification-F1 0.03251112879292918 on epoch=192
05/20/2022 13:17:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.73 on epoch=193
05/20/2022 13:17:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.83 on epoch=194
05/20/2022 13:17:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.84 on epoch=194
05/20/2022 13:17:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.72 on epoch=195
05/20/2022 13:17:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.63 on epoch=196
05/20/2022 13:17:38 - INFO - __main__ - Global step 2750 Train loss 2.75 Classification-F1 0.019543650793650797 on epoch=196
05/20/2022 13:17:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.72 on epoch=197
05/20/2022 13:17:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.77 on epoch=197
05/20/2022 13:17:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.77 on epoch=198
05/20/2022 13:17:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.64 on epoch=199
05/20/2022 13:17:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.64 on epoch=199
05/20/2022 13:17:46 - INFO - __main__ - Global step 2800 Train loss 2.71 Classification-F1 0.016314435507505942 on epoch=199
05/20/2022 13:17:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.67 on epoch=200
05/20/2022 13:17:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.72 on epoch=201
05/20/2022 13:17:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.75 on epoch=202
05/20/2022 13:17:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.71 on epoch=202
05/20/2022 13:17:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.70 on epoch=203
05/20/2022 13:17:55 - INFO - __main__ - Global step 2850 Train loss 2.71 Classification-F1 0.04089140672991604 on epoch=203
05/20/2022 13:17:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.70 on epoch=204
05/20/2022 13:17:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.75 on epoch=204
05/20/2022 13:17:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.79 on epoch=205
05/20/2022 13:18:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.69 on epoch=206
05/20/2022 13:18:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.74 on epoch=207
05/20/2022 13:18:03 - INFO - __main__ - Global step 2900 Train loss 2.74 Classification-F1 0.01972558514931396 on epoch=207
05/20/2022 13:18:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.79 on epoch=207
05/20/2022 13:18:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.73 on epoch=208
05/20/2022 13:18:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.68 on epoch=209
05/20/2022 13:18:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.86 on epoch=209
05/20/2022 13:18:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.58 on epoch=210
05/20/2022 13:18:12 - INFO - __main__ - Global step 2950 Train loss 2.73 Classification-F1 0.040890652557319225 on epoch=210
05/20/2022 13:18:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.81 on epoch=211
05/20/2022 13:18:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.60 on epoch=212
05/20/2022 13:18:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.63 on epoch=212
05/20/2022 13:18:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.69 on epoch=213
05/20/2022 13:18:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.75 on epoch=214
05/20/2022 13:18:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:18:20 - INFO - __main__ - Printing 3 examples
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:18:20 - INFO - __main__ - ['Film']
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:18:20 - INFO - __main__ - ['Film']
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:18:20 - INFO - __main__ - ['Film']
05/20/2022 13:18:20 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:18:20 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:18:20 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:18:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:18:20 - INFO - __main__ - Printing 3 examples
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:18:20 - INFO - __main__ - ['Film']
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:18:20 - INFO - __main__ - ['Film']
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:18:20 - INFO - __main__ - ['Film']
05/20/2022 13:18:20 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:18:20 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:18:20 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:18:20 - INFO - __main__ - Global step 3000 Train loss 2.70 Classification-F1 0.01610070257611241 on epoch=214
05/20/2022 13:18:20 - INFO - __main__ - save last model!
05/20/2022 13:18:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 13:18:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 13:18:20 - INFO - __main__ - Printing 3 examples
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 13:18:20 - INFO - __main__ - ['Animal']
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 13:18:20 - INFO - __main__ - ['Animal']
05/20/2022 13:18:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 13:18:20 - INFO - __main__ - ['Village']
05/20/2022 13:18:20 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:18:22 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:18:26 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:18:26 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 13:18:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:18:26 - INFO - __main__ - Starting training!
05/20/2022 13:19:02 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/20/2022 13:19:02 - INFO - __main__ - Classification-F1 on test data: 0.0182
05/20/2022 13:19:02 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.0552718062260047, test_performance=0.018247439487849383
05/20/2022 13:19:02 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/20/2022 13:19:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:19:03 - INFO - __main__ - Printing 3 examples
05/20/2022 13:19:03 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:19:03 - INFO - __main__ - ['Film']
05/20/2022 13:19:03 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:19:03 - INFO - __main__ - ['Film']
05/20/2022 13:19:03 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:19:03 - INFO - __main__ - ['Film']
05/20/2022 13:19:03 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:19:03 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:19:03 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:19:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:19:03 - INFO - __main__ - Printing 3 examples
05/20/2022 13:19:03 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:19:03 - INFO - __main__ - ['Film']
05/20/2022 13:19:03 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:19:03 - INFO - __main__ - ['Film']
05/20/2022 13:19:03 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:19:03 - INFO - __main__ - ['Film']
05/20/2022 13:19:03 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:19:03 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:19:03 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:19:09 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:19:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:19:09 - INFO - __main__ - Starting training!
05/20/2022 13:19:11 - INFO - __main__ - Step 10 Global step 10 Train loss 7.39 on epoch=0
05/20/2022 13:19:12 - INFO - __main__ - Step 20 Global step 20 Train loss 7.49 on epoch=1
05/20/2022 13:19:13 - INFO - __main__ - Step 30 Global step 30 Train loss 6.92 on epoch=2
05/20/2022 13:19:14 - INFO - __main__ - Step 40 Global step 40 Train loss 7.17 on epoch=2
05/20/2022 13:19:16 - INFO - __main__ - Step 50 Global step 50 Train loss 6.78 on epoch=3
05/20/2022 13:20:09 - INFO - __main__ - Global step 50 Train loss 7.15 Classification-F1 0.0 on epoch=3
05/20/2022 13:20:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 13:20:10 - INFO - __main__ - Step 60 Global step 60 Train loss 6.74 on epoch=4
05/20/2022 13:20:11 - INFO - __main__ - Step 70 Global step 70 Train loss 6.64 on epoch=4
05/20/2022 13:20:12 - INFO - __main__ - Step 80 Global step 80 Train loss 6.55 on epoch=5
05/20/2022 13:20:13 - INFO - __main__ - Step 90 Global step 90 Train loss 6.30 on epoch=6
05/20/2022 13:20:15 - INFO - __main__ - Step 100 Global step 100 Train loss 6.15 on epoch=7
05/20/2022 13:21:12 - INFO - __main__ - Global step 100 Train loss 6.48 Classification-F1 0.0 on epoch=7
05/20/2022 13:21:13 - INFO - __main__ - Step 110 Global step 110 Train loss 6.19 on epoch=7
05/20/2022 13:21:14 - INFO - __main__ - Step 120 Global step 120 Train loss 5.97 on epoch=8
05/20/2022 13:21:15 - INFO - __main__ - Step 130 Global step 130 Train loss 5.77 on epoch=9
05/20/2022 13:21:16 - INFO - __main__ - Step 140 Global step 140 Train loss 5.93 on epoch=9
05/20/2022 13:21:18 - INFO - __main__ - Step 150 Global step 150 Train loss 5.76 on epoch=10
05/20/2022 13:21:43 - INFO - __main__ - Global step 150 Train loss 5.92 Classification-F1 0.0 on epoch=10
05/20/2022 13:21:45 - INFO - __main__ - Step 160 Global step 160 Train loss 5.74 on epoch=11
05/20/2022 13:21:46 - INFO - __main__ - Step 170 Global step 170 Train loss 5.66 on epoch=12
05/20/2022 13:21:47 - INFO - __main__ - Step 180 Global step 180 Train loss 5.62 on epoch=12
05/20/2022 13:21:48 - INFO - __main__ - Step 190 Global step 190 Train loss 5.42 on epoch=13
05/20/2022 13:21:50 - INFO - __main__ - Step 200 Global step 200 Train loss 5.39 on epoch=14
05/20/2022 13:21:59 - INFO - __main__ - Global step 200 Train loss 5.57 Classification-F1 0.0 on epoch=14
05/20/2022 13:22:00 - INFO - __main__ - Step 210 Global step 210 Train loss 5.44 on epoch=14
05/20/2022 13:22:01 - INFO - __main__ - Step 220 Global step 220 Train loss 5.49 on epoch=15
05/20/2022 13:22:03 - INFO - __main__ - Step 230 Global step 230 Train loss 5.27 on epoch=16
05/20/2022 13:22:04 - INFO - __main__ - Step 240 Global step 240 Train loss 5.17 on epoch=17
05/20/2022 13:22:05 - INFO - __main__ - Step 250 Global step 250 Train loss 5.17 on epoch=17
05/20/2022 13:22:13 - INFO - __main__ - Global step 250 Train loss 5.31 Classification-F1 0.005305039787798408 on epoch=17
05/20/2022 13:22:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005305039787798408 on epoch=17, global_step=250
05/20/2022 13:22:14 - INFO - __main__ - Step 260 Global step 260 Train loss 5.07 on epoch=18
05/20/2022 13:22:15 - INFO - __main__ - Step 270 Global step 270 Train loss 5.07 on epoch=19
05/20/2022 13:22:16 - INFO - __main__ - Step 280 Global step 280 Train loss 5.25 on epoch=19
05/20/2022 13:22:18 - INFO - __main__ - Step 290 Global step 290 Train loss 5.09 on epoch=20
05/20/2022 13:22:19 - INFO - __main__ - Step 300 Global step 300 Train loss 4.97 on epoch=21
05/20/2022 13:22:21 - INFO - __main__ - Global step 300 Train loss 5.09 Classification-F1 0.008771929824561405 on epoch=21
05/20/2022 13:22:21 - INFO - __main__ - Saving model with best Classification-F1: 0.005305039787798408 -> 0.008771929824561405 on epoch=21, global_step=300
05/20/2022 13:22:23 - INFO - __main__ - Step 310 Global step 310 Train loss 4.95 on epoch=22
05/20/2022 13:22:24 - INFO - __main__ - Step 320 Global step 320 Train loss 4.88 on epoch=22
05/20/2022 13:22:25 - INFO - __main__ - Step 330 Global step 330 Train loss 4.92 on epoch=23
05/20/2022 13:22:26 - INFO - __main__ - Step 340 Global step 340 Train loss 4.75 on epoch=24
05/20/2022 13:22:27 - INFO - __main__ - Step 350 Global step 350 Train loss 4.81 on epoch=24
05/20/2022 13:22:30 - INFO - __main__ - Global step 350 Train loss 4.86 Classification-F1 0.008963585434173669 on epoch=24
05/20/2022 13:22:30 - INFO - __main__ - Saving model with best Classification-F1: 0.008771929824561405 -> 0.008963585434173669 on epoch=24, global_step=350
05/20/2022 13:22:31 - INFO - __main__ - Step 360 Global step 360 Train loss 4.75 on epoch=25
05/20/2022 13:22:32 - INFO - __main__ - Step 370 Global step 370 Train loss 4.73 on epoch=26
05/20/2022 13:22:33 - INFO - __main__ - Step 380 Global step 380 Train loss 4.69 on epoch=27
05/20/2022 13:22:35 - INFO - __main__ - Step 390 Global step 390 Train loss 4.58 on epoch=27
05/20/2022 13:22:36 - INFO - __main__ - Step 400 Global step 400 Train loss 4.59 on epoch=28
05/20/2022 13:22:38 - INFO - __main__ - Global step 400 Train loss 4.67 Classification-F1 0.006508135168961201 on epoch=28
05/20/2022 13:22:40 - INFO - __main__ - Step 410 Global step 410 Train loss 4.56 on epoch=29
05/20/2022 13:22:41 - INFO - __main__ - Step 420 Global step 420 Train loss 4.61 on epoch=29
05/20/2022 13:22:42 - INFO - __main__ - Step 430 Global step 430 Train loss 4.52 on epoch=30
05/20/2022 13:22:43 - INFO - __main__ - Step 440 Global step 440 Train loss 4.35 on epoch=31
05/20/2022 13:22:44 - INFO - __main__ - Step 450 Global step 450 Train loss 4.37 on epoch=32
05/20/2022 13:22:47 - INFO - __main__ - Global step 450 Train loss 4.48 Classification-F1 0.009523809523809523 on epoch=32
05/20/2022 13:22:47 - INFO - __main__ - Saving model with best Classification-F1: 0.008963585434173669 -> 0.009523809523809523 on epoch=32, global_step=450
05/20/2022 13:22:48 - INFO - __main__ - Step 460 Global step 460 Train loss 4.33 on epoch=32
05/20/2022 13:22:49 - INFO - __main__ - Step 470 Global step 470 Train loss 4.27 on epoch=33
05/20/2022 13:22:50 - INFO - __main__ - Step 480 Global step 480 Train loss 4.20 on epoch=34
05/20/2022 13:22:52 - INFO - __main__ - Step 490 Global step 490 Train loss 4.34 on epoch=34
05/20/2022 13:22:53 - INFO - __main__ - Step 500 Global step 500 Train loss 4.23 on epoch=35
05/20/2022 13:22:55 - INFO - __main__ - Global step 500 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=35
05/20/2022 13:22:56 - INFO - __main__ - Step 510 Global step 510 Train loss 4.02 on epoch=36
05/20/2022 13:22:57 - INFO - __main__ - Step 520 Global step 520 Train loss 4.16 on epoch=37
05/20/2022 13:22:59 - INFO - __main__ - Step 530 Global step 530 Train loss 3.99 on epoch=37
05/20/2022 13:23:00 - INFO - __main__ - Step 540 Global step 540 Train loss 4.02 on epoch=38
05/20/2022 13:23:01 - INFO - __main__ - Step 550 Global step 550 Train loss 3.70 on epoch=39
05/20/2022 13:23:03 - INFO - __main__ - Global step 550 Train loss 3.98 Classification-F1 0.009523809523809523 on epoch=39
05/20/2022 13:23:04 - INFO - __main__ - Step 560 Global step 560 Train loss 3.90 on epoch=39
05/20/2022 13:23:05 - INFO - __main__ - Step 570 Global step 570 Train loss 3.85 on epoch=40
05/20/2022 13:23:07 - INFO - __main__ - Step 580 Global step 580 Train loss 3.55 on epoch=41
05/20/2022 13:23:08 - INFO - __main__ - Step 590 Global step 590 Train loss 3.77 on epoch=42
05/20/2022 13:23:09 - INFO - __main__ - Step 600 Global step 600 Train loss 3.60 on epoch=42
05/20/2022 13:23:11 - INFO - __main__ - Global step 600 Train loss 3.74 Classification-F1 0.024729891956782712 on epoch=42
05/20/2022 13:23:11 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024729891956782712 on epoch=42, global_step=600
05/20/2022 13:23:12 - INFO - __main__ - Step 610 Global step 610 Train loss 3.61 on epoch=43
05/20/2022 13:23:13 - INFO - __main__ - Step 620 Global step 620 Train loss 3.52 on epoch=44
05/20/2022 13:23:14 - INFO - __main__ - Step 630 Global step 630 Train loss 3.61 on epoch=44
05/20/2022 13:23:16 - INFO - __main__ - Step 640 Global step 640 Train loss 3.70 on epoch=45
05/20/2022 13:23:17 - INFO - __main__ - Step 650 Global step 650 Train loss 3.41 on epoch=46
05/20/2022 13:23:19 - INFO - __main__ - Global step 650 Train loss 3.57 Classification-F1 0.04756188189561539 on epoch=46
05/20/2022 13:23:19 - INFO - __main__ - Saving model with best Classification-F1: 0.024729891956782712 -> 0.04756188189561539 on epoch=46, global_step=650
05/20/2022 13:23:20 - INFO - __main__ - Step 660 Global step 660 Train loss 3.54 on epoch=47
05/20/2022 13:23:21 - INFO - __main__ - Step 670 Global step 670 Train loss 3.50 on epoch=47
05/20/2022 13:23:22 - INFO - __main__ - Step 680 Global step 680 Train loss 3.51 on epoch=48
05/20/2022 13:23:23 - INFO - __main__ - Step 690 Global step 690 Train loss 3.37 on epoch=49
05/20/2022 13:23:25 - INFO - __main__ - Step 700 Global step 700 Train loss 3.30 on epoch=49
05/20/2022 13:23:27 - INFO - __main__ - Global step 700 Train loss 3.44 Classification-F1 0.022575037920306462 on epoch=49
05/20/2022 13:23:28 - INFO - __main__ - Step 710 Global step 710 Train loss 3.44 on epoch=50
05/20/2022 13:23:29 - INFO - __main__ - Step 720 Global step 720 Train loss 3.18 on epoch=51
05/20/2022 13:23:30 - INFO - __main__ - Step 730 Global step 730 Train loss 3.42 on epoch=52
05/20/2022 13:23:31 - INFO - __main__ - Step 740 Global step 740 Train loss 3.30 on epoch=52
05/20/2022 13:23:32 - INFO - __main__ - Step 750 Global step 750 Train loss 3.18 on epoch=53
05/20/2022 13:23:34 - INFO - __main__ - Global step 750 Train loss 3.30 Classification-F1 0.01392136603404209 on epoch=53
05/20/2022 13:23:36 - INFO - __main__ - Step 760 Global step 760 Train loss 3.13 on epoch=54
05/20/2022 13:23:37 - INFO - __main__ - Step 770 Global step 770 Train loss 3.16 on epoch=54
05/20/2022 13:23:38 - INFO - __main__ - Step 780 Global step 780 Train loss 3.22 on epoch=55
05/20/2022 13:23:39 - INFO - __main__ - Step 790 Global step 790 Train loss 3.00 on epoch=56
05/20/2022 13:23:40 - INFO - __main__ - Step 800 Global step 800 Train loss 3.11 on epoch=57
05/20/2022 13:23:42 - INFO - __main__ - Global step 800 Train loss 3.12 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 13:23:43 - INFO - __main__ - Step 810 Global step 810 Train loss 3.14 on epoch=57
05/20/2022 13:23:45 - INFO - __main__ - Step 820 Global step 820 Train loss 3.12 on epoch=58
05/20/2022 13:23:46 - INFO - __main__ - Step 830 Global step 830 Train loss 3.00 on epoch=59
05/20/2022 13:23:47 - INFO - __main__ - Step 840 Global step 840 Train loss 3.10 on epoch=59
05/20/2022 13:23:48 - INFO - __main__ - Step 850 Global step 850 Train loss 3.22 on epoch=60
05/20/2022 13:23:50 - INFO - __main__ - Global step 850 Train loss 3.12 Classification-F1 0.04542263713996236 on epoch=60
05/20/2022 13:23:51 - INFO - __main__ - Step 860 Global step 860 Train loss 2.91 on epoch=61
05/20/2022 13:23:53 - INFO - __main__ - Step 870 Global step 870 Train loss 3.11 on epoch=62
05/20/2022 13:23:54 - INFO - __main__ - Step 880 Global step 880 Train loss 2.95 on epoch=62
05/20/2022 13:23:55 - INFO - __main__ - Step 890 Global step 890 Train loss 2.91 on epoch=63
05/20/2022 13:23:57 - INFO - __main__ - Step 900 Global step 900 Train loss 2.98 on epoch=64
05/20/2022 13:23:58 - INFO - __main__ - Global step 900 Train loss 2.97 Classification-F1 0.016965179052456817 on epoch=64
05/20/2022 13:24:00 - INFO - __main__ - Step 910 Global step 910 Train loss 2.89 on epoch=64
05/20/2022 13:24:01 - INFO - __main__ - Step 920 Global step 920 Train loss 3.02 on epoch=65
05/20/2022 13:24:02 - INFO - __main__ - Step 930 Global step 930 Train loss 2.87 on epoch=66
05/20/2022 13:24:03 - INFO - __main__ - Step 940 Global step 940 Train loss 2.94 on epoch=67
05/20/2022 13:24:05 - INFO - __main__ - Step 950 Global step 950 Train loss 2.86 on epoch=67
05/20/2022 13:24:07 - INFO - __main__ - Global step 950 Train loss 2.91 Classification-F1 0.026761069391260155 on epoch=67
05/20/2022 13:24:08 - INFO - __main__ - Step 960 Global step 960 Train loss 2.97 on epoch=68
05/20/2022 13:24:09 - INFO - __main__ - Step 970 Global step 970 Train loss 2.82 on epoch=69
05/20/2022 13:24:10 - INFO - __main__ - Step 980 Global step 980 Train loss 2.88 on epoch=69
05/20/2022 13:24:12 - INFO - __main__ - Step 990 Global step 990 Train loss 2.94 on epoch=70
05/20/2022 13:24:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.70 on epoch=71
05/20/2022 13:24:15 - INFO - __main__ - Global step 1000 Train loss 2.86 Classification-F1 0.014221829082510197 on epoch=71
05/20/2022 13:24:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.86 on epoch=72
05/20/2022 13:24:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.68 on epoch=72
05/20/2022 13:24:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.92 on epoch=73
05/20/2022 13:24:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.84 on epoch=74
05/20/2022 13:24:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.80 on epoch=74
05/20/2022 13:24:23 - INFO - __main__ - Global step 1050 Train loss 2.82 Classification-F1 0.02734234866563723 on epoch=74
05/20/2022 13:24:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.84 on epoch=75
05/20/2022 13:24:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.73 on epoch=76
05/20/2022 13:24:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.78 on epoch=77
05/20/2022 13:24:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.60 on epoch=77
05/20/2022 13:24:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.66 on epoch=78
05/20/2022 13:24:31 - INFO - __main__ - Global step 1100 Train loss 2.72 Classification-F1 0.024704618689581095 on epoch=78
05/20/2022 13:24:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.72 on epoch=79
05/20/2022 13:24:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.81 on epoch=79
05/20/2022 13:24:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.75 on epoch=80
05/20/2022 13:24:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.71 on epoch=81
05/20/2022 13:24:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.79 on epoch=82
05/20/2022 13:24:39 - INFO - __main__ - Global step 1150 Train loss 2.76 Classification-F1 0.0717237184952866 on epoch=82
05/20/2022 13:24:39 - INFO - __main__ - Saving model with best Classification-F1: 0.04756188189561539 -> 0.0717237184952866 on epoch=82, global_step=1150
05/20/2022 13:24:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/20/2022 13:24:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=83
05/20/2022 13:24:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.78 on epoch=84
05/20/2022 13:24:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.63 on epoch=84
05/20/2022 13:24:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.70 on epoch=85
05/20/2022 13:24:48 - INFO - __main__ - Global step 1200 Train loss 2.73 Classification-F1 0.07011087263188104 on epoch=85
05/20/2022 13:24:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.76 on epoch=86
05/20/2022 13:24:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.83 on epoch=87
05/20/2022 13:24:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.64 on epoch=87
05/20/2022 13:24:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.63 on epoch=88
05/20/2022 13:24:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.46 on epoch=89
05/20/2022 13:24:56 - INFO - __main__ - Global step 1250 Train loss 2.67 Classification-F1 0.04789395677949894 on epoch=89
05/20/2022 13:24:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.53 on epoch=89
05/20/2022 13:24:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.55 on epoch=90
05/20/2022 13:25:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.51 on epoch=91
05/20/2022 13:25:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.63 on epoch=92
05/20/2022 13:25:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.61 on epoch=92
05/20/2022 13:25:05 - INFO - __main__ - Global step 1300 Train loss 2.57 Classification-F1 0.009523809523809523 on epoch=92
05/20/2022 13:25:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.56 on epoch=93
05/20/2022 13:25:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.48 on epoch=94
05/20/2022 13:25:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.44 on epoch=94
05/20/2022 13:25:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.65 on epoch=95
05/20/2022 13:25:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.47 on epoch=96
05/20/2022 13:25:13 - INFO - __main__ - Global step 1350 Train loss 2.52 Classification-F1 0.039384214372349166 on epoch=96
05/20/2022 13:25:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.57 on epoch=97
05/20/2022 13:25:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.60 on epoch=97
05/20/2022 13:25:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.54 on epoch=98
05/20/2022 13:25:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.54 on epoch=99
05/20/2022 13:25:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.53 on epoch=99
05/20/2022 13:25:21 - INFO - __main__ - Global step 1400 Train loss 2.55 Classification-F1 0.04631297964631298 on epoch=99
05/20/2022 13:25:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.46 on epoch=100
05/20/2022 13:25:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.47 on epoch=101
05/20/2022 13:25:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.71 on epoch=102
05/20/2022 13:25:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.41 on epoch=102
05/20/2022 13:25:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.49 on epoch=103
05/20/2022 13:25:29 - INFO - __main__ - Global step 1450 Train loss 2.51 Classification-F1 0.04603658819275097 on epoch=103
05/20/2022 13:25:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.60 on epoch=104
05/20/2022 13:25:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.42 on epoch=104
05/20/2022 13:25:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.56 on epoch=105
05/20/2022 13:25:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.44 on epoch=106
05/20/2022 13:25:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.36 on epoch=107
05/20/2022 13:25:37 - INFO - __main__ - Global step 1500 Train loss 2.48 Classification-F1 0.04733882464028138 on epoch=107
05/20/2022 13:25:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.61 on epoch=107
05/20/2022 13:25:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.27 on epoch=108
05/20/2022 13:25:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.30 on epoch=109
05/20/2022 13:25:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.30 on epoch=109
05/20/2022 13:25:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.47 on epoch=110
05/20/2022 13:25:46 - INFO - __main__ - Global step 1550 Train loss 2.39 Classification-F1 0.04896407962842083 on epoch=110
05/20/2022 13:25:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.29 on epoch=111
05/20/2022 13:25:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.40 on epoch=112
05/20/2022 13:25:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.36 on epoch=112
05/20/2022 13:25:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.31 on epoch=113
05/20/2022 13:25:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.28 on epoch=114
05/20/2022 13:25:54 - INFO - __main__ - Global step 1600 Train loss 2.33 Classification-F1 0.03653731421499494 on epoch=114
05/20/2022 13:25:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.28 on epoch=114
05/20/2022 13:25:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.47 on epoch=115
05/20/2022 13:25:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.27 on epoch=116
05/20/2022 13:25:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.42 on epoch=117
05/20/2022 13:26:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.25 on epoch=117
05/20/2022 13:26:02 - INFO - __main__ - Global step 1650 Train loss 2.34 Classification-F1 0.025097956158000638 on epoch=117
05/20/2022 13:26:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.33 on epoch=118
05/20/2022 13:26:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.28 on epoch=119
05/20/2022 13:26:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.33 on epoch=119
05/20/2022 13:26:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.31 on epoch=120
05/20/2022 13:26:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.28 on epoch=121
05/20/2022 13:26:10 - INFO - __main__ - Global step 1700 Train loss 2.30 Classification-F1 0.018132626184802277 on epoch=121
05/20/2022 13:26:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.33 on epoch=122
05/20/2022 13:26:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.27 on epoch=122
05/20/2022 13:26:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.37 on epoch=123
05/20/2022 13:26:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.13 on epoch=124
05/20/2022 13:26:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.15 on epoch=124
05/20/2022 13:26:18 - INFO - __main__ - Global step 1750 Train loss 2.25 Classification-F1 0.05229575178641393 on epoch=124
05/20/2022 13:26:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.26 on epoch=125
05/20/2022 13:26:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.27 on epoch=126
05/20/2022 13:26:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.25 on epoch=127
05/20/2022 13:26:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.09 on epoch=127
05/20/2022 13:26:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.09 on epoch=128
05/20/2022 13:26:27 - INFO - __main__ - Global step 1800 Train loss 2.19 Classification-F1 0.017662951705504897 on epoch=128
05/20/2022 13:26:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.20 on epoch=129
05/20/2022 13:26:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.28 on epoch=129
05/20/2022 13:26:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.25 on epoch=130
05/20/2022 13:26:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.19 on epoch=131
05/20/2022 13:26:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.30 on epoch=132
05/20/2022 13:26:35 - INFO - __main__ - Global step 1850 Train loss 2.24 Classification-F1 0.07346803058325077 on epoch=132
05/20/2022 13:26:35 - INFO - __main__ - Saving model with best Classification-F1: 0.0717237184952866 -> 0.07346803058325077 on epoch=132, global_step=1850
05/20/2022 13:26:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.29 on epoch=132
05/20/2022 13:26:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.32 on epoch=133
05/20/2022 13:26:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.22 on epoch=134
05/20/2022 13:26:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.26 on epoch=134
05/20/2022 13:26:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.26 on epoch=135
05/20/2022 13:26:43 - INFO - __main__ - Global step 1900 Train loss 2.27 Classification-F1 0.04010450333979746 on epoch=135
05/20/2022 13:26:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.15 on epoch=136
05/20/2022 13:26:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.20 on epoch=137
05/20/2022 13:26:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.06 on epoch=137
05/20/2022 13:26:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.24 on epoch=138
05/20/2022 13:26:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.13 on epoch=139
05/20/2022 13:26:51 - INFO - __main__ - Global step 1950 Train loss 2.16 Classification-F1 0.03805075419622878 on epoch=139
05/20/2022 13:26:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.10 on epoch=139
05/20/2022 13:26:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.20 on epoch=140
05/20/2022 13:26:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.15 on epoch=141
05/20/2022 13:26:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.23 on epoch=142
05/20/2022 13:26:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.11 on epoch=142
05/20/2022 13:26:59 - INFO - __main__ - Global step 2000 Train loss 2.16 Classification-F1 0.03984319773793458 on epoch=142
05/20/2022 13:27:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.06 on epoch=143
05/20/2022 13:27:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.14 on epoch=144
05/20/2022 13:27:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.17 on epoch=144
05/20/2022 13:27:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.14 on epoch=145
05/20/2022 13:27:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.03 on epoch=146
05/20/2022 13:27:07 - INFO - __main__ - Global step 2050 Train loss 2.11 Classification-F1 0.03137844724172507 on epoch=146
05/20/2022 13:27:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.29 on epoch=147
05/20/2022 13:27:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.09 on epoch=147
05/20/2022 13:27:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.00 on epoch=148
05/20/2022 13:27:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.02 on epoch=149
05/20/2022 13:27:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.09 on epoch=149
05/20/2022 13:27:15 - INFO - __main__ - Global step 2100 Train loss 2.10 Classification-F1 0.05099846390168971 on epoch=149
05/20/2022 13:27:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.14 on epoch=150
05/20/2022 13:27:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.04 on epoch=151
05/20/2022 13:27:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.04 on epoch=152
05/20/2022 13:27:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.16 on epoch=152
05/20/2022 13:27:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.13 on epoch=153
05/20/2022 13:27:24 - INFO - __main__ - Global step 2150 Train loss 2.10 Classification-F1 0.009523809523809523 on epoch=153
05/20/2022 13:27:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.10 on epoch=154
05/20/2022 13:27:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.06 on epoch=154
05/20/2022 13:27:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.06 on epoch=155
05/20/2022 13:27:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.00 on epoch=156
05/20/2022 13:27:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.05 on epoch=157
05/20/2022 13:27:32 - INFO - __main__ - Global step 2200 Train loss 2.06 Classification-F1 0.022799860514724015 on epoch=157
05/20/2022 13:27:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.08 on epoch=157
05/20/2022 13:27:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.20 on epoch=158
05/20/2022 13:27:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.95 on epoch=159
05/20/2022 13:27:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.02 on epoch=159
05/20/2022 13:27:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.01 on epoch=160
05/20/2022 13:27:40 - INFO - __main__ - Global step 2250 Train loss 2.05 Classification-F1 0.015995994413260602 on epoch=160
05/20/2022 13:27:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.99 on epoch=161
05/20/2022 13:27:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.04 on epoch=162
05/20/2022 13:27:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.04 on epoch=162
05/20/2022 13:27:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.87 on epoch=163
05/20/2022 13:27:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.01 on epoch=164
05/20/2022 13:27:48 - INFO - __main__ - Global step 2300 Train loss 1.99 Classification-F1 0.014995334302641003 on epoch=164
05/20/2022 13:27:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.09 on epoch=164
05/20/2022 13:27:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.83 on epoch=165
05/20/2022 13:27:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.98 on epoch=166
05/20/2022 13:27:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.93 on epoch=167
05/20/2022 13:27:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.96 on epoch=167
05/20/2022 13:27:56 - INFO - __main__ - Global step 2350 Train loss 1.96 Classification-F1 0.028196969402999556 on epoch=167
05/20/2022 13:27:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.04 on epoch=168
05/20/2022 13:27:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.94 on epoch=169
05/20/2022 13:28:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.00 on epoch=169
05/20/2022 13:28:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.03 on epoch=170
05/20/2022 13:28:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.99 on epoch=171
05/20/2022 13:28:04 - INFO - __main__ - Global step 2400 Train loss 2.00 Classification-F1 0.027810728277003188 on epoch=171
05/20/2022 13:28:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.97 on epoch=172
05/20/2022 13:28:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.88 on epoch=172
05/20/2022 13:28:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.94 on epoch=173
05/20/2022 13:28:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.82 on epoch=174
05/20/2022 13:28:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.85 on epoch=174
05/20/2022 13:28:13 - INFO - __main__ - Global step 2450 Train loss 1.89 Classification-F1 0.009603841536614645 on epoch=174
05/20/2022 13:28:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.97 on epoch=175
05/20/2022 13:28:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.86 on epoch=176
05/20/2022 13:28:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.95 on epoch=177
05/20/2022 13:28:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.95 on epoch=177
05/20/2022 13:28:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.97 on epoch=178
05/20/2022 13:28:21 - INFO - __main__ - Global step 2500 Train loss 1.94 Classification-F1 0.05139314562064986 on epoch=178
05/20/2022 13:28:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.81 on epoch=179
05/20/2022 13:28:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.97 on epoch=179
05/20/2022 13:28:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.85 on epoch=180
05/20/2022 13:28:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.79 on epoch=181
05/20/2022 13:28:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.75 on epoch=182
05/20/2022 13:28:29 - INFO - __main__ - Global step 2550 Train loss 1.83 Classification-F1 0.02613400037812132 on epoch=182
05/20/2022 13:28:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.78 on epoch=182
05/20/2022 13:28:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.88 on epoch=183
05/20/2022 13:28:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.94 on epoch=184
05/20/2022 13:28:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.87 on epoch=184
05/20/2022 13:28:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.88 on epoch=185
05/20/2022 13:28:37 - INFO - __main__ - Global step 2600 Train loss 1.87 Classification-F1 0.021771609428138945 on epoch=185
05/20/2022 13:28:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.88 on epoch=186
05/20/2022 13:28:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.85 on epoch=187
05/20/2022 13:28:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.83 on epoch=187
05/20/2022 13:28:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.74 on epoch=188
05/20/2022 13:28:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.86 on epoch=189
05/20/2022 13:28:46 - INFO - __main__ - Global step 2650 Train loss 1.83 Classification-F1 0.02977867203219316 on epoch=189
05/20/2022 13:28:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.96 on epoch=189
05/20/2022 13:28:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.73 on epoch=190
05/20/2022 13:28:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.89 on epoch=191
05/20/2022 13:28:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.84 on epoch=192
05/20/2022 13:28:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.77 on epoch=192
05/20/2022 13:28:55 - INFO - __main__ - Global step 2700 Train loss 1.84 Classification-F1 0.03324269682217117 on epoch=192
05/20/2022 13:28:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.71 on epoch=193
05/20/2022 13:28:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.75 on epoch=194
05/20/2022 13:28:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.00 on epoch=194
05/20/2022 13:29:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.74 on epoch=195
05/20/2022 13:29:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.77 on epoch=196
05/20/2022 13:29:04 - INFO - __main__ - Global step 2750 Train loss 1.79 Classification-F1 0.05477356600952106 on epoch=196
05/20/2022 13:29:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.69 on epoch=197
05/20/2022 13:29:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.90 on epoch=197
05/20/2022 13:29:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.64 on epoch=198
05/20/2022 13:29:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.87 on epoch=199
05/20/2022 13:29:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.73 on epoch=199
05/20/2022 13:29:13 - INFO - __main__ - Global step 2800 Train loss 1.77 Classification-F1 0.0630140518787636 on epoch=199
05/20/2022 13:29:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.70 on epoch=200
05/20/2022 13:29:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.80 on epoch=201
05/20/2022 13:29:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.73 on epoch=202
05/20/2022 13:29:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.73 on epoch=202
05/20/2022 13:29:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.71 on epoch=203
05/20/2022 13:29:22 - INFO - __main__ - Global step 2850 Train loss 1.74 Classification-F1 0.04603778535817371 on epoch=203
05/20/2022 13:29:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.63 on epoch=204
05/20/2022 13:29:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.70 on epoch=204
05/20/2022 13:29:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.75 on epoch=205
05/20/2022 13:29:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.80 on epoch=206
05/20/2022 13:29:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.82 on epoch=207
05/20/2022 13:29:31 - INFO - __main__ - Global step 2900 Train loss 1.74 Classification-F1 0.03289108058393018 on epoch=207
05/20/2022 13:29:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.73 on epoch=207
05/20/2022 13:29:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.65 on epoch=208
05/20/2022 13:29:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.84 on epoch=209
05/20/2022 13:29:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.69 on epoch=209
05/20/2022 13:29:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.68 on epoch=210
05/20/2022 13:29:40 - INFO - __main__ - Global step 2950 Train loss 1.72 Classification-F1 0.049508387226489745 on epoch=210
05/20/2022 13:29:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.75 on epoch=211
05/20/2022 13:29:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.73 on epoch=212
05/20/2022 13:29:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.62 on epoch=212
05/20/2022 13:29:45 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.86 on epoch=213
05/20/2022 13:29:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.71 on epoch=214
05/20/2022 13:29:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:29:48 - INFO - __main__ - Printing 3 examples
05/20/2022 13:29:48 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:29:48 - INFO - __main__ - ['Film']
05/20/2022 13:29:48 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:29:48 - INFO - __main__ - ['Film']
05/20/2022 13:29:48 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:29:48 - INFO - __main__ - ['Film']
05/20/2022 13:29:48 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:29:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:29:49 - INFO - __main__ - Global step 3000 Train loss 1.73 Classification-F1 0.013777818819835624 on epoch=214
05/20/2022 13:29:49 - INFO - __main__ - save last model!
05/20/2022 13:29:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 13:29:49 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 13:29:49 - INFO - __main__ - Printing 3 examples
05/20/2022 13:29:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 13:29:49 - INFO - __main__ - ['Animal']
05/20/2022 13:29:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 13:29:49 - INFO - __main__ - ['Animal']
05/20/2022 13:29:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 13:29:49 - INFO - __main__ - ['Village']
05/20/2022 13:29:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:29:49 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:29:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:29:49 - INFO - __main__ - Printing 3 examples
05/20/2022 13:29:49 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:29:49 - INFO - __main__ - ['Film']
05/20/2022 13:29:49 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:29:49 - INFO - __main__ - ['Film']
05/20/2022 13:29:49 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:29:49 - INFO - __main__ - ['Film']
05/20/2022 13:29:49 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:29:49 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:29:49 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:29:51 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:29:54 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 13:29:54 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:29:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:29:55 - INFO - __main__ - Starting training!
05/20/2022 13:30:24 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/20/2022 13:30:24 - INFO - __main__ - Classification-F1 on test data: 0.0174
05/20/2022 13:30:24 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.07346803058325077, test_performance=0.017445121297461487
05/20/2022 13:30:24 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/20/2022 13:30:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:30:25 - INFO - __main__ - Printing 3 examples
05/20/2022 13:30:25 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:30:25 - INFO - __main__ - ['Film']
05/20/2022 13:30:25 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:30:25 - INFO - __main__ - ['Film']
05/20/2022 13:30:25 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:30:25 - INFO - __main__ - ['Film']
05/20/2022 13:30:25 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:30:25 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:30:25 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:30:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:30:25 - INFO - __main__ - Printing 3 examples
05/20/2022 13:30:25 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:30:25 - INFO - __main__ - ['Film']
05/20/2022 13:30:25 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:30:25 - INFO - __main__ - ['Film']
05/20/2022 13:30:25 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:30:25 - INFO - __main__ - ['Film']
05/20/2022 13:30:25 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:30:25 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:30:26 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:30:31 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:30:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:30:31 - INFO - __main__ - Starting training!
05/20/2022 13:30:33 - INFO - __main__ - Step 10 Global step 10 Train loss 7.36 on epoch=0
05/20/2022 13:30:34 - INFO - __main__ - Step 20 Global step 20 Train loss 7.47 on epoch=1
05/20/2022 13:30:35 - INFO - __main__ - Step 30 Global step 30 Train loss 7.10 on epoch=2
05/20/2022 13:30:36 - INFO - __main__ - Step 40 Global step 40 Train loss 7.12 on epoch=2
05/20/2022 13:30:38 - INFO - __main__ - Step 50 Global step 50 Train loss 6.78 on epoch=3
05/20/2022 13:30:59 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/20/2022 13:30:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 13:31:01 - INFO - __main__ - Step 60 Global step 60 Train loss 6.60 on epoch=4
05/20/2022 13:31:02 - INFO - __main__ - Step 70 Global step 70 Train loss 6.66 on epoch=4
05/20/2022 13:31:03 - INFO - __main__ - Step 80 Global step 80 Train loss 6.56 on epoch=5
05/20/2022 13:31:04 - INFO - __main__ - Step 90 Global step 90 Train loss 6.54 on epoch=6
05/20/2022 13:31:06 - INFO - __main__ - Step 100 Global step 100 Train loss 6.28 on epoch=7
05/20/2022 13:32:08 - INFO - __main__ - Global step 100 Train loss 6.53 Classification-F1 0.0 on epoch=7
05/20/2022 13:32:09 - INFO - __main__ - Step 110 Global step 110 Train loss 6.34 on epoch=7
05/20/2022 13:32:10 - INFO - __main__ - Step 120 Global step 120 Train loss 6.14 on epoch=8
05/20/2022 13:32:12 - INFO - __main__ - Step 130 Global step 130 Train loss 5.97 on epoch=9
05/20/2022 13:32:13 - INFO - __main__ - Step 140 Global step 140 Train loss 6.18 on epoch=9
05/20/2022 13:32:14 - INFO - __main__ - Step 150 Global step 150 Train loss 6.09 on epoch=10
05/20/2022 13:33:18 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/20/2022 13:33:20 - INFO - __main__ - Step 160 Global step 160 Train loss 6.10 on epoch=11
05/20/2022 13:33:21 - INFO - __main__ - Step 170 Global step 170 Train loss 5.93 on epoch=12
05/20/2022 13:33:22 - INFO - __main__ - Step 180 Global step 180 Train loss 5.97 on epoch=12
05/20/2022 13:33:23 - INFO - __main__ - Step 190 Global step 190 Train loss 5.72 on epoch=13
05/20/2022 13:33:25 - INFO - __main__ - Step 200 Global step 200 Train loss 5.78 on epoch=14
05/20/2022 13:34:34 - INFO - __main__ - Global step 200 Train loss 5.90 Classification-F1 0.0 on epoch=14
05/20/2022 13:34:35 - INFO - __main__ - Step 210 Global step 210 Train loss 5.86 on epoch=14
05/20/2022 13:34:37 - INFO - __main__ - Step 220 Global step 220 Train loss 5.79 on epoch=15
05/20/2022 13:34:38 - INFO - __main__ - Step 230 Global step 230 Train loss 5.92 on epoch=16
05/20/2022 13:34:39 - INFO - __main__ - Step 240 Global step 240 Train loss 5.60 on epoch=17
05/20/2022 13:34:40 - INFO - __main__ - Step 250 Global step 250 Train loss 5.54 on epoch=17
05/20/2022 13:35:24 - INFO - __main__ - Global step 250 Train loss 5.74 Classification-F1 0.0 on epoch=17
05/20/2022 13:35:25 - INFO - __main__ - Step 260 Global step 260 Train loss 5.58 on epoch=18
05/20/2022 13:35:26 - INFO - __main__ - Step 270 Global step 270 Train loss 5.52 on epoch=19
05/20/2022 13:35:28 - INFO - __main__ - Step 280 Global step 280 Train loss 5.63 on epoch=19
05/20/2022 13:35:29 - INFO - __main__ - Step 290 Global step 290 Train loss 5.53 on epoch=20
05/20/2022 13:35:30 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/20/2022 13:35:46 - INFO - __main__ - Global step 300 Train loss 5.54 Classification-F1 0.0 on epoch=21
05/20/2022 13:35:47 - INFO - __main__ - Step 310 Global step 310 Train loss 5.36 on epoch=22
05/20/2022 13:35:48 - INFO - __main__ - Step 320 Global step 320 Train loss 5.50 on epoch=22
05/20/2022 13:35:50 - INFO - __main__ - Step 330 Global step 330 Train loss 5.31 on epoch=23
05/20/2022 13:35:51 - INFO - __main__ - Step 340 Global step 340 Train loss 5.23 on epoch=24
05/20/2022 13:35:52 - INFO - __main__ - Step 350 Global step 350 Train loss 5.29 on epoch=24
05/20/2022 13:35:55 - INFO - __main__ - Global step 350 Train loss 5.34 Classification-F1 0.00538116591928251 on epoch=24
05/20/2022 13:35:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.00538116591928251 on epoch=24, global_step=350
05/20/2022 13:35:57 - INFO - __main__ - Step 360 Global step 360 Train loss 5.16 on epoch=25
05/20/2022 13:35:58 - INFO - __main__ - Step 370 Global step 370 Train loss 5.23 on epoch=26
05/20/2022 13:35:59 - INFO - __main__ - Step 380 Global step 380 Train loss 5.34 on epoch=27
05/20/2022 13:36:00 - INFO - __main__ - Step 390 Global step 390 Train loss 4.94 on epoch=27
05/20/2022 13:36:02 - INFO - __main__ - Step 400 Global step 400 Train loss 4.95 on epoch=28
05/20/2022 13:36:05 - INFO - __main__ - Global step 400 Train loss 5.12 Classification-F1 0.008438818565400845 on epoch=28
05/20/2022 13:36:05 - INFO - __main__ - Saving model with best Classification-F1: 0.00538116591928251 -> 0.008438818565400845 on epoch=28, global_step=400
05/20/2022 13:36:07 - INFO - __main__ - Step 410 Global step 410 Train loss 4.91 on epoch=29
05/20/2022 13:36:08 - INFO - __main__ - Step 420 Global step 420 Train loss 5.04 on epoch=29
05/20/2022 13:36:09 - INFO - __main__ - Step 430 Global step 430 Train loss 4.92 on epoch=30
05/20/2022 13:36:10 - INFO - __main__ - Step 440 Global step 440 Train loss 4.79 on epoch=31
05/20/2022 13:36:12 - INFO - __main__ - Step 450 Global step 450 Train loss 4.89 on epoch=32
05/20/2022 13:36:14 - INFO - __main__ - Global step 450 Train loss 4.91 Classification-F1 0.009523809523809523 on epoch=32
05/20/2022 13:36:14 - INFO - __main__ - Saving model with best Classification-F1: 0.008438818565400845 -> 0.009523809523809523 on epoch=32, global_step=450
05/20/2022 13:36:15 - INFO - __main__ - Step 460 Global step 460 Train loss 4.80 on epoch=32
05/20/2022 13:36:17 - INFO - __main__ - Step 470 Global step 470 Train loss 4.70 on epoch=33
05/20/2022 13:36:18 - INFO - __main__ - Step 480 Global step 480 Train loss 4.73 on epoch=34
05/20/2022 13:36:19 - INFO - __main__ - Step 490 Global step 490 Train loss 4.66 on epoch=34
05/20/2022 13:36:20 - INFO - __main__ - Step 500 Global step 500 Train loss 4.65 on epoch=35
05/20/2022 13:36:22 - INFO - __main__ - Global step 500 Train loss 4.71 Classification-F1 0.009523809523809523 on epoch=35
05/20/2022 13:36:23 - INFO - __main__ - Step 510 Global step 510 Train loss 4.50 on epoch=36
05/20/2022 13:36:25 - INFO - __main__ - Step 520 Global step 520 Train loss 4.69 on epoch=37
05/20/2022 13:36:26 - INFO - __main__ - Step 530 Global step 530 Train loss 4.44 on epoch=37
05/20/2022 13:36:27 - INFO - __main__ - Step 540 Global step 540 Train loss 4.41 on epoch=38
05/20/2022 13:36:28 - INFO - __main__ - Step 550 Global step 550 Train loss 4.46 on epoch=39
05/20/2022 13:36:30 - INFO - __main__ - Global step 550 Train loss 4.50 Classification-F1 0.009523809523809523 on epoch=39
05/20/2022 13:36:32 - INFO - __main__ - Step 560 Global step 560 Train loss 4.40 on epoch=39
05/20/2022 13:36:33 - INFO - __main__ - Step 570 Global step 570 Train loss 4.49 on epoch=40
05/20/2022 13:36:34 - INFO - __main__ - Step 580 Global step 580 Train loss 4.28 on epoch=41
05/20/2022 13:36:35 - INFO - __main__ - Step 590 Global step 590 Train loss 4.11 on epoch=42
05/20/2022 13:36:37 - INFO - __main__ - Step 600 Global step 600 Train loss 4.18 on epoch=42
05/20/2022 13:36:39 - INFO - __main__ - Global step 600 Train loss 4.29 Classification-F1 0.014082268421387245 on epoch=42
05/20/2022 13:36:39 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.014082268421387245 on epoch=42, global_step=600
05/20/2022 13:36:40 - INFO - __main__ - Step 610 Global step 610 Train loss 4.20 on epoch=43
05/20/2022 13:36:41 - INFO - __main__ - Step 620 Global step 620 Train loss 4.15 on epoch=44
05/20/2022 13:36:42 - INFO - __main__ - Step 630 Global step 630 Train loss 4.11 on epoch=44
05/20/2022 13:36:44 - INFO - __main__ - Step 640 Global step 640 Train loss 4.33 on epoch=45
05/20/2022 13:36:45 - INFO - __main__ - Step 650 Global step 650 Train loss 3.93 on epoch=46
05/20/2022 13:36:47 - INFO - __main__ - Global step 650 Train loss 4.14 Classification-F1 0.009696186166774399 on epoch=46
05/20/2022 13:36:48 - INFO - __main__ - Step 660 Global step 660 Train loss 4.14 on epoch=47
05/20/2022 13:36:49 - INFO - __main__ - Step 670 Global step 670 Train loss 4.04 on epoch=47
05/20/2022 13:36:51 - INFO - __main__ - Step 680 Global step 680 Train loss 3.97 on epoch=48
05/20/2022 13:36:52 - INFO - __main__ - Step 690 Global step 690 Train loss 3.96 on epoch=49
05/20/2022 13:36:53 - INFO - __main__ - Step 700 Global step 700 Train loss 3.91 on epoch=49
05/20/2022 13:36:55 - INFO - __main__ - Global step 700 Train loss 4.00 Classification-F1 0.016021112680937276 on epoch=49
05/20/2022 13:36:55 - INFO - __main__ - Saving model with best Classification-F1: 0.014082268421387245 -> 0.016021112680937276 on epoch=49, global_step=700
05/20/2022 13:36:56 - INFO - __main__ - Step 710 Global step 710 Train loss 3.92 on epoch=50
05/20/2022 13:36:57 - INFO - __main__ - Step 720 Global step 720 Train loss 3.76 on epoch=51
05/20/2022 13:36:59 - INFO - __main__ - Step 730 Global step 730 Train loss 3.83 on epoch=52
05/20/2022 13:37:00 - INFO - __main__ - Step 740 Global step 740 Train loss 3.84 on epoch=52
05/20/2022 13:37:01 - INFO - __main__ - Step 750 Global step 750 Train loss 3.83 on epoch=53
05/20/2022 13:37:03 - INFO - __main__ - Global step 750 Train loss 3.83 Classification-F1 0.022077595196145407 on epoch=53
05/20/2022 13:37:03 - INFO - __main__ - Saving model with best Classification-F1: 0.016021112680937276 -> 0.022077595196145407 on epoch=53, global_step=750
05/20/2022 13:37:04 - INFO - __main__ - Step 760 Global step 760 Train loss 3.67 on epoch=54
05/20/2022 13:37:06 - INFO - __main__ - Step 770 Global step 770 Train loss 3.57 on epoch=54
05/20/2022 13:37:07 - INFO - __main__ - Step 780 Global step 780 Train loss 3.81 on epoch=55
05/20/2022 13:37:08 - INFO - __main__ - Step 790 Global step 790 Train loss 3.66 on epoch=56
05/20/2022 13:37:09 - INFO - __main__ - Step 800 Global step 800 Train loss 3.46 on epoch=57
05/20/2022 13:37:11 - INFO - __main__ - Global step 800 Train loss 3.63 Classification-F1 0.009563658099222952 on epoch=57
05/20/2022 13:37:12 - INFO - __main__ - Step 810 Global step 810 Train loss 3.71 on epoch=57
05/20/2022 13:37:14 - INFO - __main__ - Step 820 Global step 820 Train loss 3.70 on epoch=58
05/20/2022 13:37:15 - INFO - __main__ - Step 830 Global step 830 Train loss 3.46 on epoch=59
05/20/2022 13:37:16 - INFO - __main__ - Step 840 Global step 840 Train loss 3.45 on epoch=59
05/20/2022 13:37:17 - INFO - __main__ - Step 850 Global step 850 Train loss 3.67 on epoch=60
05/20/2022 13:37:19 - INFO - __main__ - Global step 850 Train loss 3.60 Classification-F1 0.015243052328283296 on epoch=60
05/20/2022 13:37:20 - INFO - __main__ - Step 860 Global step 860 Train loss 3.34 on epoch=61
05/20/2022 13:37:22 - INFO - __main__ - Step 870 Global step 870 Train loss 3.45 on epoch=62
05/20/2022 13:37:23 - INFO - __main__ - Step 880 Global step 880 Train loss 3.44 on epoch=62
05/20/2022 13:37:24 - INFO - __main__ - Step 890 Global step 890 Train loss 3.37 on epoch=63
05/20/2022 13:37:25 - INFO - __main__ - Step 900 Global step 900 Train loss 3.28 on epoch=64
05/20/2022 13:37:27 - INFO - __main__ - Global step 900 Train loss 3.38 Classification-F1 0.008965929468021518 on epoch=64
05/20/2022 13:37:28 - INFO - __main__ - Step 910 Global step 910 Train loss 3.21 on epoch=64
05/20/2022 13:37:30 - INFO - __main__ - Step 920 Global step 920 Train loss 3.44 on epoch=65
05/20/2022 13:37:31 - INFO - __main__ - Step 930 Global step 930 Train loss 3.24 on epoch=66
05/20/2022 13:37:32 - INFO - __main__ - Step 940 Global step 940 Train loss 3.29 on epoch=67
05/20/2022 13:37:33 - INFO - __main__ - Step 950 Global step 950 Train loss 3.31 on epoch=67
05/20/2022 13:37:35 - INFO - __main__ - Global step 950 Train loss 3.30 Classification-F1 0.017540349473122583 on epoch=67
05/20/2022 13:37:37 - INFO - __main__ - Step 960 Global step 960 Train loss 3.22 on epoch=68
05/20/2022 13:37:38 - INFO - __main__ - Step 970 Global step 970 Train loss 3.28 on epoch=69
05/20/2022 13:37:39 - INFO - __main__ - Step 980 Global step 980 Train loss 2.96 on epoch=69
05/20/2022 13:37:40 - INFO - __main__ - Step 990 Global step 990 Train loss 3.24 on epoch=70
05/20/2022 13:37:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.15 on epoch=71
05/20/2022 13:37:43 - INFO - __main__ - Global step 1000 Train loss 3.17 Classification-F1 0.01216579655117861 on epoch=71
05/20/2022 13:37:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.22 on epoch=72
05/20/2022 13:37:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.15 on epoch=72
05/20/2022 13:37:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.14 on epoch=73
05/20/2022 13:37:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.25 on epoch=74
05/20/2022 13:37:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.03 on epoch=74
05/20/2022 13:37:51 - INFO - __main__ - Global step 1050 Train loss 3.16 Classification-F1 0.029260582241872675 on epoch=74
05/20/2022 13:37:51 - INFO - __main__ - Saving model with best Classification-F1: 0.022077595196145407 -> 0.029260582241872675 on epoch=74, global_step=1050
05/20/2022 13:37:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.15 on epoch=75
05/20/2022 13:37:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.14 on epoch=76
05/20/2022 13:37:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.01 on epoch=77
05/20/2022 13:37:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.96 on epoch=77
05/20/2022 13:37:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.94 on epoch=78
05/20/2022 13:38:00 - INFO - __main__ - Global step 1100 Train loss 3.04 Classification-F1 0.016664141796697472 on epoch=78
05/20/2022 13:38:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.00 on epoch=79
05/20/2022 13:38:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.92 on epoch=79
05/20/2022 13:38:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.11 on epoch=80
05/20/2022 13:38:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.85 on epoch=81
05/20/2022 13:38:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.03 on epoch=82
05/20/2022 13:38:08 - INFO - __main__ - Global step 1150 Train loss 2.98 Classification-F1 0.0228843736908253 on epoch=82
05/20/2022 13:38:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.03 on epoch=82
05/20/2022 13:38:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.95 on epoch=83
05/20/2022 13:38:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.01 on epoch=84
05/20/2022 13:38:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.84 on epoch=84
05/20/2022 13:38:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.00 on epoch=85
05/20/2022 13:38:16 - INFO - __main__ - Global step 1200 Train loss 2.97 Classification-F1 0.025842115775498452 on epoch=85
05/20/2022 13:38:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.95 on epoch=86
05/20/2022 13:38:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.05 on epoch=87
05/20/2022 13:38:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.88 on epoch=87
05/20/2022 13:38:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.94 on epoch=88
05/20/2022 13:38:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.75 on epoch=89
05/20/2022 13:38:24 - INFO - __main__ - Global step 1250 Train loss 2.92 Classification-F1 0.041557699594084174 on epoch=89
05/20/2022 13:38:25 - INFO - __main__ - Saving model with best Classification-F1: 0.029260582241872675 -> 0.041557699594084174 on epoch=89, global_step=1250
05/20/2022 13:38:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.86 on epoch=89
05/20/2022 13:38:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.00 on epoch=90
05/20/2022 13:38:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.83 on epoch=91
05/20/2022 13:38:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.91 on epoch=92
05/20/2022 13:38:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.89 on epoch=92
05/20/2022 13:38:33 - INFO - __main__ - Global step 1300 Train loss 2.90 Classification-F1 0.04131000578368999 on epoch=92
05/20/2022 13:38:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.96 on epoch=93
05/20/2022 13:38:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.66 on epoch=94
05/20/2022 13:38:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.82 on epoch=94
05/20/2022 13:38:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.96 on epoch=95
05/20/2022 13:38:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.81 on epoch=96
05/20/2022 13:38:41 - INFO - __main__ - Global step 1350 Train loss 2.84 Classification-F1 0.034306198438578926 on epoch=96
05/20/2022 13:38:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.87 on epoch=97
05/20/2022 13:38:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.82 on epoch=97
05/20/2022 13:38:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.86 on epoch=98
05/20/2022 13:38:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.82 on epoch=99
05/20/2022 13:38:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.63 on epoch=99
05/20/2022 13:38:49 - INFO - __main__ - Global step 1400 Train loss 2.80 Classification-F1 0.009937888198757764 on epoch=99
05/20/2022 13:38:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.93 on epoch=100
05/20/2022 13:38:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.73 on epoch=101
05/20/2022 13:38:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.82 on epoch=102
05/20/2022 13:38:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.81 on epoch=102
05/20/2022 13:38:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.71 on epoch=103
05/20/2022 13:38:58 - INFO - __main__ - Global step 1450 Train loss 2.80 Classification-F1 0.015154185022026432 on epoch=103
05/20/2022 13:38:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.77 on epoch=104
05/20/2022 13:39:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.83 on epoch=104
05/20/2022 13:39:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.87 on epoch=105
05/20/2022 13:39:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.73 on epoch=106
05/20/2022 13:39:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.73 on epoch=107
05/20/2022 13:39:06 - INFO - __main__ - Global step 1500 Train loss 2.78 Classification-F1 0.02032227032227032 on epoch=107
05/20/2022 13:39:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.67 on epoch=107
05/20/2022 13:39:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.82 on epoch=108
05/20/2022 13:39:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.64 on epoch=109
05/20/2022 13:39:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.69 on epoch=109
05/20/2022 13:39:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.76 on epoch=110
05/20/2022 13:39:14 - INFO - __main__ - Global step 1550 Train loss 2.72 Classification-F1 0.022980987266701555 on epoch=110
05/20/2022 13:39:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.52 on epoch=111
05/20/2022 13:39:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.66 on epoch=112
05/20/2022 13:39:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.53 on epoch=112
05/20/2022 13:39:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.69 on epoch=113
05/20/2022 13:39:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.55 on epoch=114
05/20/2022 13:39:22 - INFO - __main__ - Global step 1600 Train loss 2.59 Classification-F1 0.03183846228959011 on epoch=114
05/20/2022 13:39:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.53 on epoch=114
05/20/2022 13:39:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.72 on epoch=115
05/20/2022 13:39:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.43 on epoch=116
05/20/2022 13:39:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.65 on epoch=117
05/20/2022 13:39:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.61 on epoch=117
05/20/2022 13:39:31 - INFO - __main__ - Global step 1650 Train loss 2.59 Classification-F1 0.01767752715121136 on epoch=117
05/20/2022 13:39:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.76 on epoch=118
05/20/2022 13:39:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.53 on epoch=119
05/20/2022 13:39:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.49 on epoch=119
05/20/2022 13:39:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.74 on epoch=120
05/20/2022 13:39:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.44 on epoch=121
05/20/2022 13:39:39 - INFO - __main__ - Global step 1700 Train loss 2.59 Classification-F1 0.009937888198757764 on epoch=121
05/20/2022 13:39:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.70 on epoch=122
05/20/2022 13:39:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.41 on epoch=122
05/20/2022 13:39:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.67 on epoch=123
05/20/2022 13:39:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.57 on epoch=124
05/20/2022 13:39:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.52 on epoch=124
05/20/2022 13:39:47 - INFO - __main__ - Global step 1750 Train loss 2.57 Classification-F1 0.04742028246128682 on epoch=124
05/20/2022 13:39:47 - INFO - __main__ - Saving model with best Classification-F1: 0.041557699594084174 -> 0.04742028246128682 on epoch=124, global_step=1750
05/20/2022 13:39:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.67 on epoch=125
05/20/2022 13:39:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.59 on epoch=126
05/20/2022 13:39:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.67 on epoch=127
05/20/2022 13:39:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.52 on epoch=127
05/20/2022 13:39:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.70 on epoch=128
05/20/2022 13:39:55 - INFO - __main__ - Global step 1800 Train loss 2.63 Classification-F1 0.0653606488170099 on epoch=128
05/20/2022 13:39:56 - INFO - __main__ - Saving model with best Classification-F1: 0.04742028246128682 -> 0.0653606488170099 on epoch=128, global_step=1800
05/20/2022 13:39:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.45 on epoch=129
05/20/2022 13:39:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.48 on epoch=129
05/20/2022 13:39:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.62 on epoch=130
05/20/2022 13:40:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.46 on epoch=131
05/20/2022 13:40:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.68 on epoch=132
05/20/2022 13:40:04 - INFO - __main__ - Global step 1850 Train loss 2.54 Classification-F1 0.027562111801242233 on epoch=132
05/20/2022 13:40:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.52 on epoch=132
05/20/2022 13:40:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.45 on epoch=133
05/20/2022 13:40:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.59 on epoch=134
05/20/2022 13:40:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.36 on epoch=134
05/20/2022 13:40:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.58 on epoch=135
05/20/2022 13:40:12 - INFO - __main__ - Global step 1900 Train loss 2.50 Classification-F1 0.01728680676049097 on epoch=135
05/20/2022 13:40:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.46 on epoch=136
05/20/2022 13:40:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.57 on epoch=137
05/20/2022 13:40:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.57 on epoch=137
05/20/2022 13:40:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.49 on epoch=138
05/20/2022 13:40:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.42 on epoch=139
05/20/2022 13:40:20 - INFO - __main__ - Global step 1950 Train loss 2.51 Classification-F1 0.030137743170662756 on epoch=139
05/20/2022 13:40:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.29 on epoch=139
05/20/2022 13:40:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.73 on epoch=140
05/20/2022 13:40:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.46 on epoch=141
05/20/2022 13:40:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.47 on epoch=142
05/20/2022 13:40:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.49 on epoch=142
05/20/2022 13:40:29 - INFO - __main__ - Global step 2000 Train loss 2.49 Classification-F1 0.016910866910866913 on epoch=142
05/20/2022 13:40:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.32 on epoch=143
05/20/2022 13:40:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.28 on epoch=144
05/20/2022 13:40:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.47 on epoch=144
05/20/2022 13:40:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.64 on epoch=145
05/20/2022 13:40:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.35 on epoch=146
05/20/2022 13:40:37 - INFO - __main__ - Global step 2050 Train loss 2.41 Classification-F1 0.017052560934687776 on epoch=146
05/20/2022 13:40:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.51 on epoch=147
05/20/2022 13:40:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.30 on epoch=147
05/20/2022 13:40:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.39 on epoch=148
05/20/2022 13:40:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.32 on epoch=149
05/20/2022 13:40:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.33 on epoch=149
05/20/2022 13:40:45 - INFO - __main__ - Global step 2100 Train loss 2.37 Classification-F1 0.017704517704517704 on epoch=149
05/20/2022 13:40:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.67 on epoch=150
05/20/2022 13:40:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.39 on epoch=151
05/20/2022 13:40:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.46 on epoch=152
05/20/2022 13:40:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.37 on epoch=152
05/20/2022 13:40:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.42 on epoch=153
05/20/2022 13:40:54 - INFO - __main__ - Global step 2150 Train loss 2.46 Classification-F1 0.026077097505668938 on epoch=153
05/20/2022 13:40:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.33 on epoch=154
05/20/2022 13:40:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.23 on epoch=154
05/20/2022 13:40:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.26 on epoch=155
05/20/2022 13:40:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.26 on epoch=156
05/20/2022 13:41:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.41 on epoch=157
05/20/2022 13:41:02 - INFO - __main__ - Global step 2200 Train loss 2.30 Classification-F1 0.041230826194922146 on epoch=157
05/20/2022 13:41:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.10 on epoch=157
05/20/2022 13:41:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.23 on epoch=158
05/20/2022 13:41:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.45 on epoch=159
05/20/2022 13:41:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.29 on epoch=159
05/20/2022 13:41:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.35 on epoch=160
05/20/2022 13:41:10 - INFO - __main__ - Global step 2250 Train loss 2.28 Classification-F1 0.03471051365788208 on epoch=160
05/20/2022 13:41:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.28 on epoch=161
05/20/2022 13:41:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.28 on epoch=162
05/20/2022 13:41:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.25 on epoch=162
05/20/2022 13:41:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.26 on epoch=163
05/20/2022 13:41:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.39 on epoch=164
05/20/2022 13:41:18 - INFO - __main__ - Global step 2300 Train loss 2.29 Classification-F1 0.037531925050722045 on epoch=164
05/20/2022 13:41:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.38 on epoch=164
05/20/2022 13:41:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.29 on epoch=165
05/20/2022 13:41:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.11 on epoch=166
05/20/2022 13:41:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.37 on epoch=167
05/20/2022 13:41:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.20 on epoch=167
05/20/2022 13:41:27 - INFO - __main__ - Global step 2350 Train loss 2.27 Classification-F1 0.047017333369690696 on epoch=167
05/20/2022 13:41:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.24 on epoch=168
05/20/2022 13:41:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.23 on epoch=169
05/20/2022 13:41:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.14 on epoch=169
05/20/2022 13:41:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.25 on epoch=170
05/20/2022 13:41:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.30 on epoch=171
05/20/2022 13:41:35 - INFO - __main__ - Global step 2400 Train loss 2.23 Classification-F1 0.04487647559936717 on epoch=171
05/20/2022 13:41:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.30 on epoch=172
05/20/2022 13:41:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.13 on epoch=172
05/20/2022 13:41:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.22 on epoch=173
05/20/2022 13:41:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.23 on epoch=174
05/20/2022 13:41:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.22 on epoch=174
05/20/2022 13:41:44 - INFO - __main__ - Global step 2450 Train loss 2.22 Classification-F1 0.048135084421991006 on epoch=174
05/20/2022 13:41:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.22 on epoch=175
05/20/2022 13:41:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.96 on epoch=176
05/20/2022 13:41:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.15 on epoch=177
05/20/2022 13:41:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.07 on epoch=177
05/20/2022 13:41:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.23 on epoch=178
05/20/2022 13:41:52 - INFO - __main__ - Global step 2500 Train loss 2.12 Classification-F1 0.034098404378087 on epoch=178
05/20/2022 13:41:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.14 on epoch=179
05/20/2022 13:41:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.21 on epoch=179
05/20/2022 13:41:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.26 on epoch=180
05/20/2022 13:41:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.12 on epoch=181
05/20/2022 13:41:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.35 on epoch=182
05/20/2022 13:42:01 - INFO - __main__ - Global step 2550 Train loss 2.21 Classification-F1 0.02442466348241424 on epoch=182
05/20/2022 13:42:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.12 on epoch=182
05/20/2022 13:42:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.30 on epoch=183
05/20/2022 13:42:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.18 on epoch=184
05/20/2022 13:42:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.15 on epoch=184
05/20/2022 13:42:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.27 on epoch=185
05/20/2022 13:42:09 - INFO - __main__ - Global step 2600 Train loss 2.21 Classification-F1 0.04423105922929991 on epoch=185
05/20/2022 13:42:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.22 on epoch=186
05/20/2022 13:42:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.21 on epoch=187
05/20/2022 13:42:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.07 on epoch=187
05/20/2022 13:42:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.03 on epoch=188
05/20/2022 13:42:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.95 on epoch=189
05/20/2022 13:42:18 - INFO - __main__ - Global step 2650 Train loss 2.10 Classification-F1 0.07818484200616001 on epoch=189
05/20/2022 13:42:18 - INFO - __main__ - Saving model with best Classification-F1: 0.0653606488170099 -> 0.07818484200616001 on epoch=189, global_step=2650
05/20/2022 13:42:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.13 on epoch=189
05/20/2022 13:42:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.16 on epoch=190
05/20/2022 13:42:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.01 on epoch=191
05/20/2022 13:42:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.13 on epoch=192
05/20/2022 13:42:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.99 on epoch=192
05/20/2022 13:42:26 - INFO - __main__ - Global step 2700 Train loss 2.09 Classification-F1 0.061139459343052156 on epoch=192
05/20/2022 13:42:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.06 on epoch=193
05/20/2022 13:42:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.06 on epoch=194
05/20/2022 13:42:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.08 on epoch=194
05/20/2022 13:42:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.97 on epoch=195
05/20/2022 13:42:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.06 on epoch=196
05/20/2022 13:42:34 - INFO - __main__ - Global step 2750 Train loss 2.05 Classification-F1 0.06845545235638115 on epoch=196
05/20/2022 13:42:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.08 on epoch=197
05/20/2022 13:42:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.01 on epoch=197
05/20/2022 13:42:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.06 on epoch=198
05/20/2022 13:42:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.05 on epoch=199
05/20/2022 13:42:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.03 on epoch=199
05/20/2022 13:42:43 - INFO - __main__ - Global step 2800 Train loss 2.05 Classification-F1 0.0901874136374937 on epoch=199
05/20/2022 13:42:43 - INFO - __main__ - Saving model with best Classification-F1: 0.07818484200616001 -> 0.0901874136374937 on epoch=199, global_step=2800
05/20/2022 13:42:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.08 on epoch=200
05/20/2022 13:42:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.06 on epoch=201
05/20/2022 13:42:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.15 on epoch=202
05/20/2022 13:42:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.06 on epoch=202
05/20/2022 13:42:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.11 on epoch=203
05/20/2022 13:42:51 - INFO - __main__ - Global step 2850 Train loss 2.09 Classification-F1 0.08084187475288178 on epoch=203
05/20/2022 13:42:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.06 on epoch=204
05/20/2022 13:42:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.14 on epoch=204
05/20/2022 13:42:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.01 on epoch=205
05/20/2022 13:42:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.06 on epoch=206
05/20/2022 13:42:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.00 on epoch=207
05/20/2022 13:43:00 - INFO - __main__ - Global step 2900 Train loss 2.06 Classification-F1 0.0707468127342237 on epoch=207
05/20/2022 13:43:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.02 on epoch=207
05/20/2022 13:43:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.10 on epoch=208
05/20/2022 13:43:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.03 on epoch=209
05/20/2022 13:43:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.11 on epoch=209
05/20/2022 13:43:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.91 on epoch=210
05/20/2022 13:43:08 - INFO - __main__ - Global step 2950 Train loss 2.03 Classification-F1 0.08941591453169584 on epoch=210
05/20/2022 13:43:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.09 on epoch=211
05/20/2022 13:43:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.94 on epoch=212
05/20/2022 13:43:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.86 on epoch=212
05/20/2022 13:43:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.93 on epoch=213
05/20/2022 13:43:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.99 on epoch=214
05/20/2022 13:43:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:43:16 - INFO - __main__ - Printing 3 examples
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:43:16 - INFO - __main__ - ['Film']
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:43:16 - INFO - __main__ - ['Film']
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:43:16 - INFO - __main__ - ['Film']
05/20/2022 13:43:16 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:43:16 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:43:16 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:43:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:43:16 - INFO - __main__ - Printing 3 examples
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:43:16 - INFO - __main__ - ['Film']
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:43:16 - INFO - __main__ - ['Film']
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:43:16 - INFO - __main__ - ['Film']
05/20/2022 13:43:16 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:43:16 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:43:16 - INFO - __main__ - Global step 3000 Train loss 1.96 Classification-F1 0.06239911021037329 on epoch=214
05/20/2022 13:43:16 - INFO - __main__ - save last model!
05/20/2022 13:43:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 13:43:16 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 13:43:16 - INFO - __main__ - Printing 3 examples
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 13:43:16 - INFO - __main__ - ['Animal']
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 13:43:16 - INFO - __main__ - ['Animal']
05/20/2022 13:43:16 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 13:43:16 - INFO - __main__ - ['Village']
05/20/2022 13:43:16 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:43:16 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:43:18 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:43:21 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:43:22 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 13:43:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:43:22 - INFO - __main__ - Starting training!
05/20/2022 13:43:52 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/20/2022 13:43:52 - INFO - __main__ - Classification-F1 on test data: 0.0605
05/20/2022 13:43:52 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.0901874136374937, test_performance=0.06054021125330055
05/20/2022 13:43:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/20/2022 13:43:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:43:53 - INFO - __main__ - Printing 3 examples
05/20/2022 13:43:53 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:43:53 - INFO - __main__ - ['Film']
05/20/2022 13:43:53 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:43:53 - INFO - __main__ - ['Film']
05/20/2022 13:43:53 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:43:53 - INFO - __main__ - ['Film']
05/20/2022 13:43:53 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:43:53 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:43:53 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:43:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:43:53 - INFO - __main__ - Printing 3 examples
05/20/2022 13:43:53 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:43:53 - INFO - __main__ - ['Film']
05/20/2022 13:43:53 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:43:53 - INFO - __main__ - ['Film']
05/20/2022 13:43:53 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:43:53 - INFO - __main__ - ['Film']
05/20/2022 13:43:53 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:43:53 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:43:54 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:43:59 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:43:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:43:59 - INFO - __main__ - Starting training!
05/20/2022 13:44:01 - INFO - __main__ - Step 10 Global step 10 Train loss 7.43 on epoch=0
05/20/2022 13:44:02 - INFO - __main__ - Step 20 Global step 20 Train loss 7.35 on epoch=1
05/20/2022 13:44:03 - INFO - __main__ - Step 30 Global step 30 Train loss 7.04 on epoch=2
05/20/2022 13:44:04 - INFO - __main__ - Step 40 Global step 40 Train loss 7.27 on epoch=2
05/20/2022 13:44:06 - INFO - __main__ - Step 50 Global step 50 Train loss 6.91 on epoch=3
05/20/2022 13:44:16 - INFO - __main__ - Global step 50 Train loss 7.20 Classification-F1 0.0 on epoch=3
05/20/2022 13:44:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 13:44:17 - INFO - __main__ - Step 60 Global step 60 Train loss 6.77 on epoch=4
05/20/2022 13:44:18 - INFO - __main__ - Step 70 Global step 70 Train loss 6.97 on epoch=4
05/20/2022 13:44:20 - INFO - __main__ - Step 80 Global step 80 Train loss 6.76 on epoch=5
05/20/2022 13:44:21 - INFO - __main__ - Step 90 Global step 90 Train loss 6.68 on epoch=6
05/20/2022 13:44:22 - INFO - __main__ - Step 100 Global step 100 Train loss 6.56 on epoch=7
05/20/2022 13:44:45 - INFO - __main__ - Global step 100 Train loss 6.75 Classification-F1 0.0 on epoch=7
05/20/2022 13:44:46 - INFO - __main__ - Step 110 Global step 110 Train loss 6.59 on epoch=7
05/20/2022 13:44:47 - INFO - __main__ - Step 120 Global step 120 Train loss 6.38 on epoch=8
05/20/2022 13:44:48 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/20/2022 13:44:49 - INFO - __main__ - Step 140 Global step 140 Train loss 6.43 on epoch=9
05/20/2022 13:44:51 - INFO - __main__ - Step 150 Global step 150 Train loss 6.29 on epoch=10
05/20/2022 13:45:51 - INFO - __main__ - Global step 150 Train loss 6.41 Classification-F1 0.0 on epoch=10
05/20/2022 13:45:52 - INFO - __main__ - Step 160 Global step 160 Train loss 6.36 on epoch=11
05/20/2022 13:45:53 - INFO - __main__ - Step 170 Global step 170 Train loss 6.17 on epoch=12
05/20/2022 13:45:55 - INFO - __main__ - Step 180 Global step 180 Train loss 6.12 on epoch=12
05/20/2022 13:45:56 - INFO - __main__ - Step 190 Global step 190 Train loss 6.13 on epoch=13
05/20/2022 13:45:57 - INFO - __main__ - Step 200 Global step 200 Train loss 5.88 on epoch=14
05/20/2022 13:47:01 - INFO - __main__ - Global step 200 Train loss 6.13 Classification-F1 0.0 on epoch=14
05/20/2022 13:47:02 - INFO - __main__ - Step 210 Global step 210 Train loss 6.18 on epoch=14
05/20/2022 13:47:04 - INFO - __main__ - Step 220 Global step 220 Train loss 5.99 on epoch=15
05/20/2022 13:47:05 - INFO - __main__ - Step 230 Global step 230 Train loss 5.79 on epoch=16
05/20/2022 13:47:06 - INFO - __main__ - Step 240 Global step 240 Train loss 5.82 on epoch=17
05/20/2022 13:47:08 - INFO - __main__ - Step 250 Global step 250 Train loss 5.95 on epoch=17
05/20/2022 13:48:09 - INFO - __main__ - Global step 250 Train loss 5.95 Classification-F1 0.0 on epoch=17
05/20/2022 13:48:10 - INFO - __main__ - Step 260 Global step 260 Train loss 5.65 on epoch=18
05/20/2022 13:48:11 - INFO - __main__ - Step 270 Global step 270 Train loss 5.61 on epoch=19
05/20/2022 13:48:13 - INFO - __main__ - Step 280 Global step 280 Train loss 5.76 on epoch=19
05/20/2022 13:48:14 - INFO - __main__ - Step 290 Global step 290 Train loss 5.62 on epoch=20
05/20/2022 13:48:15 - INFO - __main__ - Step 300 Global step 300 Train loss 5.62 on epoch=21
05/20/2022 13:49:05 - INFO - __main__ - Global step 300 Train loss 5.65 Classification-F1 0.0 on epoch=21
05/20/2022 13:49:06 - INFO - __main__ - Step 310 Global step 310 Train loss 5.68 on epoch=22
05/20/2022 13:49:08 - INFO - __main__ - Step 320 Global step 320 Train loss 5.59 on epoch=22
05/20/2022 13:49:09 - INFO - __main__ - Step 330 Global step 330 Train loss 5.46 on epoch=23
05/20/2022 13:49:10 - INFO - __main__ - Step 340 Global step 340 Train loss 5.33 on epoch=24
05/20/2022 13:49:11 - INFO - __main__ - Step 350 Global step 350 Train loss 5.45 on epoch=24
05/20/2022 13:50:01 - INFO - __main__ - Global step 350 Train loss 5.50 Classification-F1 0.0 on epoch=24
05/20/2022 13:50:02 - INFO - __main__ - Step 360 Global step 360 Train loss 5.41 on epoch=25
05/20/2022 13:50:03 - INFO - __main__ - Step 370 Global step 370 Train loss 5.35 on epoch=26
05/20/2022 13:50:04 - INFO - __main__ - Step 380 Global step 380 Train loss 5.19 on epoch=27
05/20/2022 13:50:06 - INFO - __main__ - Step 390 Global step 390 Train loss 5.38 on epoch=27
05/20/2022 13:50:07 - INFO - __main__ - Step 400 Global step 400 Train loss 5.19 on epoch=28
05/20/2022 13:50:11 - INFO - __main__ - Global step 400 Train loss 5.30 Classification-F1 0.0 on epoch=28
05/20/2022 13:50:12 - INFO - __main__ - Step 410 Global step 410 Train loss 4.96 on epoch=29
05/20/2022 13:50:13 - INFO - __main__ - Step 420 Global step 420 Train loss 5.19 on epoch=29
05/20/2022 13:50:15 - INFO - __main__ - Step 430 Global step 430 Train loss 5.30 on epoch=30
05/20/2022 13:50:16 - INFO - __main__ - Step 440 Global step 440 Train loss 5.04 on epoch=31
05/20/2022 13:50:17 - INFO - __main__ - Step 450 Global step 450 Train loss 4.98 on epoch=32
05/20/2022 13:50:25 - INFO - __main__ - Global step 450 Train loss 5.09 Classification-F1 0.0038940809968847356 on epoch=32
05/20/2022 13:50:25 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0038940809968847356 on epoch=32, global_step=450
05/20/2022 13:50:26 - INFO - __main__ - Step 460 Global step 460 Train loss 5.17 on epoch=32
05/20/2022 13:50:27 - INFO - __main__ - Step 470 Global step 470 Train loss 5.17 on epoch=33
05/20/2022 13:50:29 - INFO - __main__ - Step 480 Global step 480 Train loss 4.96 on epoch=34
05/20/2022 13:50:30 - INFO - __main__ - Step 490 Global step 490 Train loss 5.08 on epoch=34
05/20/2022 13:50:31 - INFO - __main__ - Step 500 Global step 500 Train loss 5.04 on epoch=35
05/20/2022 13:50:33 - INFO - __main__ - Global step 500 Train loss 5.08 Classification-F1 0.00847457627118644 on epoch=35
05/20/2022 13:50:34 - INFO - __main__ - Saving model with best Classification-F1: 0.0038940809968847356 -> 0.00847457627118644 on epoch=35, global_step=500
05/20/2022 13:50:35 - INFO - __main__ - Step 510 Global step 510 Train loss 4.84 on epoch=36
05/20/2022 13:50:36 - INFO - __main__ - Step 520 Global step 520 Train loss 4.78 on epoch=37
05/20/2022 13:50:37 - INFO - __main__ - Step 530 Global step 530 Train loss 4.79 on epoch=37
05/20/2022 13:50:38 - INFO - __main__ - Step 540 Global step 540 Train loss 4.70 on epoch=38
05/20/2022 13:50:40 - INFO - __main__ - Step 550 Global step 550 Train loss 4.67 on epoch=39
05/20/2022 13:50:52 - INFO - __main__ - Global step 550 Train loss 4.76 Classification-F1 0.00597524541186513 on epoch=39
05/20/2022 13:50:53 - INFO - __main__ - Step 560 Global step 560 Train loss 4.81 on epoch=39
05/20/2022 13:50:54 - INFO - __main__ - Step 570 Global step 570 Train loss 4.65 on epoch=40
05/20/2022 13:50:56 - INFO - __main__ - Step 580 Global step 580 Train loss 4.70 on epoch=41
05/20/2022 13:50:57 - INFO - __main__ - Step 590 Global step 590 Train loss 4.58 on epoch=42
05/20/2022 13:50:58 - INFO - __main__ - Step 600 Global step 600 Train loss 4.68 on epoch=42
05/20/2022 13:51:00 - INFO - __main__ - Global step 600 Train loss 4.68 Classification-F1 0.00892608089260809 on epoch=42
05/20/2022 13:51:00 - INFO - __main__ - Saving model with best Classification-F1: 0.00847457627118644 -> 0.00892608089260809 on epoch=42, global_step=600
05/20/2022 13:51:02 - INFO - __main__ - Step 610 Global step 610 Train loss 4.59 on epoch=43
05/20/2022 13:51:03 - INFO - __main__ - Step 620 Global step 620 Train loss 4.43 on epoch=44
05/20/2022 13:51:04 - INFO - __main__ - Step 630 Global step 630 Train loss 4.57 on epoch=44
05/20/2022 13:51:05 - INFO - __main__ - Step 640 Global step 640 Train loss 4.62 on epoch=45
05/20/2022 13:51:06 - INFO - __main__ - Step 650 Global step 650 Train loss 4.50 on epoch=46
05/20/2022 13:51:08 - INFO - __main__ - Global step 650 Train loss 4.54 Classification-F1 0.009523809523809523 on epoch=46
05/20/2022 13:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=46, global_step=650
05/20/2022 13:51:10 - INFO - __main__ - Step 660 Global step 660 Train loss 4.59 on epoch=47
05/20/2022 13:51:11 - INFO - __main__ - Step 670 Global step 670 Train loss 4.40 on epoch=47
05/20/2022 13:51:12 - INFO - __main__ - Step 680 Global step 680 Train loss 4.49 on epoch=48
05/20/2022 13:51:13 - INFO - __main__ - Step 690 Global step 690 Train loss 4.30 on epoch=49
05/20/2022 13:51:15 - INFO - __main__ - Step 700 Global step 700 Train loss 4.44 on epoch=49
05/20/2022 13:51:16 - INFO - __main__ - Global step 700 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=49
05/20/2022 13:51:18 - INFO - __main__ - Step 710 Global step 710 Train loss 4.39 on epoch=50
05/20/2022 13:51:19 - INFO - __main__ - Step 720 Global step 720 Train loss 4.30 on epoch=51
05/20/2022 13:51:20 - INFO - __main__ - Step 730 Global step 730 Train loss 4.30 on epoch=52
05/20/2022 13:51:21 - INFO - __main__ - Step 740 Global step 740 Train loss 4.28 on epoch=52
05/20/2022 13:51:23 - INFO - __main__ - Step 750 Global step 750 Train loss 4.31 on epoch=53
05/20/2022 13:51:24 - INFO - __main__ - Global step 750 Train loss 4.31 Classification-F1 0.009523809523809523 on epoch=53
05/20/2022 13:51:26 - INFO - __main__ - Step 760 Global step 760 Train loss 4.17 on epoch=54
05/20/2022 13:51:27 - INFO - __main__ - Step 770 Global step 770 Train loss 4.21 on epoch=54
05/20/2022 13:51:28 - INFO - __main__ - Step 780 Global step 780 Train loss 4.35 on epoch=55
05/20/2022 13:51:29 - INFO - __main__ - Step 790 Global step 790 Train loss 4.16 on epoch=56
05/20/2022 13:51:30 - INFO - __main__ - Step 800 Global step 800 Train loss 4.04 on epoch=57
05/20/2022 13:51:32 - INFO - __main__ - Global step 800 Train loss 4.19 Classification-F1 0.009563658099222952 on epoch=57
05/20/2022 13:51:32 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009563658099222952 on epoch=57, global_step=800
05/20/2022 13:51:34 - INFO - __main__ - Step 810 Global step 810 Train loss 4.17 on epoch=57
05/20/2022 13:51:35 - INFO - __main__ - Step 820 Global step 820 Train loss 4.23 on epoch=58
05/20/2022 13:51:36 - INFO - __main__ - Step 830 Global step 830 Train loss 4.04 on epoch=59
05/20/2022 13:51:37 - INFO - __main__ - Step 840 Global step 840 Train loss 4.04 on epoch=59
05/20/2022 13:51:38 - INFO - __main__ - Step 850 Global step 850 Train loss 4.16 on epoch=60
05/20/2022 13:51:40 - INFO - __main__ - Global step 850 Train loss 4.13 Classification-F1 0.01540799189614267 on epoch=60
05/20/2022 13:51:40 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.01540799189614267 on epoch=60, global_step=850
05/20/2022 13:51:41 - INFO - __main__ - Step 860 Global step 860 Train loss 3.96 on epoch=61
05/20/2022 13:51:43 - INFO - __main__ - Step 870 Global step 870 Train loss 3.95 on epoch=62
05/20/2022 13:51:44 - INFO - __main__ - Step 880 Global step 880 Train loss 3.88 on epoch=62
05/20/2022 13:51:45 - INFO - __main__ - Step 890 Global step 890 Train loss 4.08 on epoch=63
05/20/2022 13:51:46 - INFO - __main__ - Step 900 Global step 900 Train loss 3.90 on epoch=64
05/20/2022 13:51:48 - INFO - __main__ - Global step 900 Train loss 3.96 Classification-F1 0.025388637400428116 on epoch=64
05/20/2022 13:51:48 - INFO - __main__ - Saving model with best Classification-F1: 0.01540799189614267 -> 0.025388637400428116 on epoch=64, global_step=900
05/20/2022 13:51:49 - INFO - __main__ - Step 910 Global step 910 Train loss 3.79 on epoch=64
05/20/2022 13:51:51 - INFO - __main__ - Step 920 Global step 920 Train loss 4.00 on epoch=65
05/20/2022 13:51:52 - INFO - __main__ - Step 930 Global step 930 Train loss 3.85 on epoch=66
05/20/2022 13:51:53 - INFO - __main__ - Step 940 Global step 940 Train loss 3.82 on epoch=67
05/20/2022 13:51:54 - INFO - __main__ - Step 950 Global step 950 Train loss 3.91 on epoch=67
05/20/2022 13:51:56 - INFO - __main__ - Global step 950 Train loss 3.87 Classification-F1 0.032004429678848284 on epoch=67
05/20/2022 13:51:56 - INFO - __main__ - Saving model with best Classification-F1: 0.025388637400428116 -> 0.032004429678848284 on epoch=67, global_step=950
05/20/2022 13:51:57 - INFO - __main__ - Step 960 Global step 960 Train loss 3.80 on epoch=68
05/20/2022 13:51:59 - INFO - __main__ - Step 970 Global step 970 Train loss 3.60 on epoch=69
05/20/2022 13:52:00 - INFO - __main__ - Step 980 Global step 980 Train loss 3.83 on epoch=69
05/20/2022 13:52:01 - INFO - __main__ - Step 990 Global step 990 Train loss 3.90 on epoch=70
05/20/2022 13:52:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.46 on epoch=71
05/20/2022 13:52:04 - INFO - __main__ - Global step 1000 Train loss 3.72 Classification-F1 0.016692785828740474 on epoch=71
05/20/2022 13:52:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.71 on epoch=72
05/20/2022 13:52:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.72 on epoch=72
05/20/2022 13:52:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.69 on epoch=73
05/20/2022 13:52:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.60 on epoch=74
05/20/2022 13:52:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.62 on epoch=74
05/20/2022 13:52:12 - INFO - __main__ - Global step 1050 Train loss 3.67 Classification-F1 0.03493897559023609 on epoch=74
05/20/2022 13:52:12 - INFO - __main__ - Saving model with best Classification-F1: 0.032004429678848284 -> 0.03493897559023609 on epoch=74, global_step=1050
05/20/2022 13:52:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.70 on epoch=75
05/20/2022 13:52:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.43 on epoch=76
05/20/2022 13:52:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.79 on epoch=77
05/20/2022 13:52:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.58 on epoch=77
05/20/2022 13:52:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.66 on epoch=78
05/20/2022 13:52:20 - INFO - __main__ - Global step 1100 Train loss 3.63 Classification-F1 0.017377860235003092 on epoch=78
05/20/2022 13:52:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.37 on epoch=79
05/20/2022 13:52:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.46 on epoch=79
05/20/2022 13:52:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.49 on epoch=80
05/20/2022 13:52:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.34 on epoch=81
05/20/2022 13:52:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.29 on epoch=82
05/20/2022 13:52:28 - INFO - __main__ - Global step 1150 Train loss 3.39 Classification-F1 0.021957671957671957 on epoch=82
05/20/2022 13:52:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.54 on epoch=82
05/20/2022 13:52:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.48 on epoch=83
05/20/2022 13:52:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.32 on epoch=84
05/20/2022 13:52:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.27 on epoch=84
05/20/2022 13:52:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.48 on epoch=85
05/20/2022 13:52:36 - INFO - __main__ - Global step 1200 Train loss 3.42 Classification-F1 0.012877180575200375 on epoch=85
05/20/2022 13:52:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.51 on epoch=86
05/20/2022 13:52:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.41 on epoch=87
05/20/2022 13:52:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.40 on epoch=87
05/20/2022 13:52:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.31 on epoch=88
05/20/2022 13:52:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.21 on epoch=89
05/20/2022 13:52:43 - INFO - __main__ - Global step 1250 Train loss 3.37 Classification-F1 0.031569494335451774 on epoch=89
05/20/2022 13:52:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.17 on epoch=89
05/20/2022 13:52:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.32 on epoch=90
05/20/2022 13:52:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.20 on epoch=91
05/20/2022 13:52:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.25 on epoch=92
05/20/2022 13:52:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.27 on epoch=92
05/20/2022 13:52:51 - INFO - __main__ - Global step 1300 Train loss 3.24 Classification-F1 0.04141254202830558 on epoch=92
05/20/2022 13:52:51 - INFO - __main__ - Saving model with best Classification-F1: 0.03493897559023609 -> 0.04141254202830558 on epoch=92, global_step=1300
05/20/2022 13:52:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.15 on epoch=93
05/20/2022 13:52:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.26 on epoch=94
05/20/2022 13:52:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.15 on epoch=94
05/20/2022 13:52:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.34 on epoch=95
05/20/2022 13:52:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.05 on epoch=96
05/20/2022 13:52:59 - INFO - __main__ - Global step 1350 Train loss 3.19 Classification-F1 0.017552515511699188 on epoch=96
05/20/2022 13:53:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.03 on epoch=97
05/20/2022 13:53:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.10 on epoch=97
05/20/2022 13:53:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.97 on epoch=98
05/20/2022 13:53:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.11 on epoch=99
05/20/2022 13:53:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.11 on epoch=99
05/20/2022 13:53:07 - INFO - __main__ - Global step 1400 Train loss 3.06 Classification-F1 0.047930038156995085 on epoch=99
05/20/2022 13:53:07 - INFO - __main__ - Saving model with best Classification-F1: 0.04141254202830558 -> 0.047930038156995085 on epoch=99, global_step=1400
05/20/2022 13:53:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.19 on epoch=100
05/20/2022 13:53:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.91 on epoch=101
05/20/2022 13:53:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.99 on epoch=102
05/20/2022 13:53:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.02 on epoch=102
05/20/2022 13:53:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.01 on epoch=103
05/20/2022 13:53:15 - INFO - __main__ - Global step 1450 Train loss 3.02 Classification-F1 0.02766318411794775 on epoch=103
05/20/2022 13:53:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.03 on epoch=104
05/20/2022 13:53:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.88 on epoch=104
05/20/2022 13:53:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.11 on epoch=105
05/20/2022 13:53:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.88 on epoch=106
05/20/2022 13:53:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.99 on epoch=107
05/20/2022 13:53:23 - INFO - __main__ - Global step 1500 Train loss 2.98 Classification-F1 0.05494765281999324 on epoch=107
05/20/2022 13:53:23 - INFO - __main__ - Saving model with best Classification-F1: 0.047930038156995085 -> 0.05494765281999324 on epoch=107, global_step=1500
05/20/2022 13:53:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.06 on epoch=107
05/20/2022 13:53:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.04 on epoch=108
05/20/2022 13:53:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.83 on epoch=109
05/20/2022 13:53:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.93 on epoch=109
05/20/2022 13:53:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.07 on epoch=110
05/20/2022 13:53:31 - INFO - __main__ - Global step 1550 Train loss 2.99 Classification-F1 0.03438228438228438 on epoch=110
05/20/2022 13:53:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.99 on epoch=111
05/20/2022 13:53:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.98 on epoch=112
05/20/2022 13:53:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.86 on epoch=112
05/20/2022 13:53:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.87 on epoch=113
05/20/2022 13:53:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.89 on epoch=114
05/20/2022 13:53:39 - INFO - __main__ - Global step 1600 Train loss 2.92 Classification-F1 0.04339544513457557 on epoch=114
05/20/2022 13:53:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.88 on epoch=114
05/20/2022 13:53:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.05 on epoch=115
05/20/2022 13:53:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.87 on epoch=116
05/20/2022 13:53:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.99 on epoch=117
05/20/2022 13:53:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.90 on epoch=117
05/20/2022 13:53:47 - INFO - __main__ - Global step 1650 Train loss 2.94 Classification-F1 0.033651672694394216 on epoch=117
05/20/2022 13:53:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.93 on epoch=118
05/20/2022 13:53:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.91 on epoch=119
05/20/2022 13:53:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.81 on epoch=119
05/20/2022 13:53:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.91 on epoch=120
05/20/2022 13:53:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.74 on epoch=121
05/20/2022 13:53:55 - INFO - __main__ - Global step 1700 Train loss 2.86 Classification-F1 0.048099280382744955 on epoch=121
05/20/2022 13:53:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.85 on epoch=122
05/20/2022 13:53:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.76 on epoch=122
05/20/2022 13:53:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.77 on epoch=123
05/20/2022 13:54:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.79 on epoch=124
05/20/2022 13:54:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.84 on epoch=124
05/20/2022 13:54:03 - INFO - __main__ - Global step 1750 Train loss 2.80 Classification-F1 0.04834505634566592 on epoch=124
05/20/2022 13:54:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.04 on epoch=125
05/20/2022 13:54:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.79 on epoch=126
05/20/2022 13:54:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.82 on epoch=127
05/20/2022 13:54:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.78 on epoch=127
05/20/2022 13:54:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.89 on epoch=128
05/20/2022 13:54:11 - INFO - __main__ - Global step 1800 Train loss 2.86 Classification-F1 0.04475408520150356 on epoch=128
05/20/2022 13:54:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.71 on epoch=129
05/20/2022 13:54:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.77 on epoch=129
05/20/2022 13:54:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.76 on epoch=130
05/20/2022 13:54:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.82 on epoch=131
05/20/2022 13:54:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.82 on epoch=132
05/20/2022 13:54:19 - INFO - __main__ - Global step 1850 Train loss 2.78 Classification-F1 0.02227791701475912 on epoch=132
05/20/2022 13:54:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.73 on epoch=132
05/20/2022 13:54:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.84 on epoch=133
05/20/2022 13:54:23 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.68 on epoch=134
05/20/2022 13:54:25 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.64 on epoch=134
05/20/2022 13:54:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.83 on epoch=135
05/20/2022 13:54:29 - INFO - __main__ - Global step 1900 Train loss 2.75 Classification-F1 0.009644364074743823 on epoch=135
05/20/2022 13:54:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.65 on epoch=136
05/20/2022 13:54:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.81 on epoch=137
05/20/2022 13:54:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.74 on epoch=137
05/20/2022 13:54:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.75 on epoch=138
05/20/2022 13:54:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.66 on epoch=139
05/20/2022 13:54:38 - INFO - __main__ - Global step 1950 Train loss 2.72 Classification-F1 0.03380307635626784 on epoch=139
05/20/2022 13:54:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.73 on epoch=139
05/20/2022 13:54:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.69 on epoch=140
05/20/2022 13:54:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.51 on epoch=141
05/20/2022 13:54:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.60 on epoch=142
05/20/2022 13:54:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.53 on epoch=142
05/20/2022 13:54:46 - INFO - __main__ - Global step 2000 Train loss 2.61 Classification-F1 0.009523809523809523 on epoch=142
05/20/2022 13:54:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.70 on epoch=143
05/20/2022 13:54:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.73 on epoch=144
05/20/2022 13:54:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.64 on epoch=144
05/20/2022 13:54:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.71 on epoch=145
05/20/2022 13:54:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.61 on epoch=146
05/20/2022 13:54:55 - INFO - __main__ - Global step 2050 Train loss 2.68 Classification-F1 0.009235209235209235 on epoch=146
05/20/2022 13:54:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.52 on epoch=147
05/20/2022 13:54:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.70 on epoch=147
05/20/2022 13:54:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.49 on epoch=148
05/20/2022 13:54:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.66 on epoch=149
05/20/2022 13:55:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.56 on epoch=149
05/20/2022 13:55:03 - INFO - __main__ - Global step 2100 Train loss 2.59 Classification-F1 0.009563658099222952 on epoch=149
05/20/2022 13:55:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.53 on epoch=150
05/20/2022 13:55:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.46 on epoch=151
05/20/2022 13:55:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.65 on epoch=152
05/20/2022 13:55:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.59 on epoch=152
05/20/2022 13:55:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.78 on epoch=153
05/20/2022 13:55:12 - INFO - __main__ - Global step 2150 Train loss 2.60 Classification-F1 0.009001406469760902 on epoch=153
05/20/2022 13:55:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.53 on epoch=154
05/20/2022 13:55:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.52 on epoch=154
05/20/2022 13:55:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.60 on epoch=155
05/20/2022 13:55:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.43 on epoch=156
05/20/2022 13:55:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.61 on epoch=157
05/20/2022 13:55:20 - INFO - __main__ - Global step 2200 Train loss 2.54 Classification-F1 0.009563658099222952 on epoch=157
05/20/2022 13:55:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.53 on epoch=157
05/20/2022 13:55:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.58 on epoch=158
05/20/2022 13:55:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.55 on epoch=159
05/20/2022 13:55:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.47 on epoch=159
05/20/2022 13:55:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.49 on epoch=160
05/20/2022 13:55:28 - INFO - __main__ - Global step 2250 Train loss 2.52 Classification-F1 0.0435077890805445 on epoch=160
05/20/2022 13:55:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.40 on epoch=161
05/20/2022 13:55:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.54 on epoch=162
05/20/2022 13:55:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.35 on epoch=162
05/20/2022 13:55:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.62 on epoch=163
05/20/2022 13:55:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.44 on epoch=164
05/20/2022 13:55:36 - INFO - __main__ - Global step 2300 Train loss 2.47 Classification-F1 0.01762173796072101 on epoch=164
05/20/2022 13:55:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.52 on epoch=164
05/20/2022 13:55:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.54 on epoch=165
05/20/2022 13:55:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.55 on epoch=166
05/20/2022 13:55:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.72 on epoch=167
05/20/2022 13:55:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.46 on epoch=167
05/20/2022 13:55:44 - INFO - __main__ - Global step 2350 Train loss 2.56 Classification-F1 0.009523809523809523 on epoch=167
05/20/2022 13:55:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.50 on epoch=168
05/20/2022 13:55:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.50 on epoch=169
05/20/2022 13:55:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.41 on epoch=169
05/20/2022 13:55:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.55 on epoch=170
05/20/2022 13:55:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.40 on epoch=171
05/20/2022 13:55:53 - INFO - __main__ - Global step 2400 Train loss 2.47 Classification-F1 0.04017250333039807 on epoch=171
05/20/2022 13:55:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.39 on epoch=172
05/20/2022 13:55:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.44 on epoch=172
05/20/2022 13:55:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.47 on epoch=173
05/20/2022 13:55:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.42 on epoch=174
05/20/2022 13:55:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.48 on epoch=174
05/20/2022 13:56:01 - INFO - __main__ - Global step 2450 Train loss 2.44 Classification-F1 0.061464262142871484 on epoch=174
05/20/2022 13:56:01 - INFO - __main__ - Saving model with best Classification-F1: 0.05494765281999324 -> 0.061464262142871484 on epoch=174, global_step=2450
05/20/2022 13:56:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.49 on epoch=175
05/20/2022 13:56:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.40 on epoch=176
05/20/2022 13:56:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.44 on epoch=177
05/20/2022 13:56:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.29 on epoch=177
05/20/2022 13:56:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.47 on epoch=178
05/20/2022 13:56:09 - INFO - __main__ - Global step 2500 Train loss 2.42 Classification-F1 0.04415255463887683 on epoch=178
05/20/2022 13:56:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.52 on epoch=179
05/20/2022 13:56:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.44 on epoch=179
05/20/2022 13:56:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.42 on epoch=180
05/20/2022 13:56:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.32 on epoch=181
05/20/2022 13:56:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.35 on epoch=182
05/20/2022 13:56:17 - INFO - __main__ - Global step 2550 Train loss 2.41 Classification-F1 0.009563658099222952 on epoch=182
05/20/2022 13:56:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.28 on epoch=182
05/20/2022 13:56:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.30 on epoch=183
05/20/2022 13:56:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.32 on epoch=184
05/20/2022 13:56:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.39 on epoch=184
05/20/2022 13:56:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.38 on epoch=185
05/20/2022 13:56:26 - INFO - __main__ - Global step 2600 Train loss 2.34 Classification-F1 0.02801300538217087 on epoch=185
05/20/2022 13:56:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.36 on epoch=186
05/20/2022 13:56:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.34 on epoch=187
05/20/2022 13:56:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.44 on epoch=187
05/20/2022 13:56:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.59 on epoch=188
05/20/2022 13:56:32 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.37 on epoch=189
05/20/2022 13:56:35 - INFO - __main__ - Global step 2650 Train loss 2.42 Classification-F1 0.03751951344398237 on epoch=189
05/20/2022 13:56:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.31 on epoch=189
05/20/2022 13:56:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.29 on epoch=190
05/20/2022 13:56:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.28 on epoch=191
05/20/2022 13:56:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.45 on epoch=192
05/20/2022 13:56:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.28 on epoch=192
05/20/2022 13:56:44 - INFO - __main__ - Global step 2700 Train loss 2.32 Classification-F1 0.018255578093306284 on epoch=192
05/20/2022 13:56:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.34 on epoch=193
05/20/2022 13:56:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.30 on epoch=194
05/20/2022 13:56:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.46 on epoch=194
05/20/2022 13:56:49 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.39 on epoch=195
05/20/2022 13:56:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.15 on epoch=196
05/20/2022 13:56:53 - INFO - __main__ - Global step 2750 Train loss 2.33 Classification-F1 0.04852607709750567 on epoch=196
05/20/2022 13:56:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.31 on epoch=197
05/20/2022 13:56:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.27 on epoch=197
05/20/2022 13:56:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.37 on epoch=198
05/20/2022 13:56:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.26 on epoch=199
05/20/2022 13:56:59 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.25 on epoch=199
05/20/2022 13:57:02 - INFO - __main__ - Global step 2800 Train loss 2.29 Classification-F1 0.026835822210475306 on epoch=199
05/20/2022 13:57:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.37 on epoch=200
05/20/2022 13:57:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.21 on epoch=201
05/20/2022 13:57:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.33 on epoch=202
05/20/2022 13:57:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.21 on epoch=202
05/20/2022 13:57:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.24 on epoch=203
05/20/2022 13:57:11 - INFO - __main__ - Global step 2850 Train loss 2.27 Classification-F1 0.028522039757994815 on epoch=203
05/20/2022 13:57:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.11 on epoch=204
05/20/2022 13:57:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.29 on epoch=204
05/20/2022 13:57:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.26 on epoch=205
05/20/2022 13:57:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.09 on epoch=206
05/20/2022 13:57:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.22 on epoch=207
05/20/2022 13:57:20 - INFO - __main__ - Global step 2900 Train loss 2.19 Classification-F1 0.030750761843198814 on epoch=207
05/20/2022 13:57:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.22 on epoch=207
05/20/2022 13:57:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.33 on epoch=208
05/20/2022 13:57:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.04 on epoch=209
05/20/2022 13:57:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.24 on epoch=209
05/20/2022 13:57:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.19 on epoch=210
05/20/2022 13:57:28 - INFO - __main__ - Global step 2950 Train loss 2.20 Classification-F1 0.03557417736382803 on epoch=210
05/20/2022 13:57:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.16 on epoch=211
05/20/2022 13:57:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.23 on epoch=212
05/20/2022 13:57:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.29 on epoch=212
05/20/2022 13:57:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.25 on epoch=213
05/20/2022 13:57:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.17 on epoch=214
05/20/2022 13:57:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:57:36 - INFO - __main__ - Printing 3 examples
05/20/2022 13:57:36 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:57:36 - INFO - __main__ - ['Film']
05/20/2022 13:57:36 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:57:36 - INFO - __main__ - ['Film']
05/20/2022 13:57:36 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:57:36 - INFO - __main__ - ['Film']
05/20/2022 13:57:36 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:57:36 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:57:36 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:57:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:57:36 - INFO - __main__ - Printing 3 examples
05/20/2022 13:57:36 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:57:36 - INFO - __main__ - ['Film']
05/20/2022 13:57:36 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:57:36 - INFO - __main__ - ['Film']
05/20/2022 13:57:36 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:57:36 - INFO - __main__ - ['Film']
05/20/2022 13:57:36 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:57:36 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:57:37 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:57:37 - INFO - __main__ - Global step 3000 Train loss 2.22 Classification-F1 0.032851719521665414 on epoch=214
05/20/2022 13:57:37 - INFO - __main__ - save last model!
05/20/2022 13:57:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 13:57:37 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 13:57:37 - INFO - __main__ - Printing 3 examples
05/20/2022 13:57:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 13:57:37 - INFO - __main__ - ['Animal']
05/20/2022 13:57:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 13:57:37 - INFO - __main__ - ['Animal']
05/20/2022 13:57:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 13:57:37 - INFO - __main__ - ['Village']
05/20/2022 13:57:37 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:57:39 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:57:42 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 13:57:43 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:57:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:57:43 - INFO - __main__ - Starting training!
05/20/2022 13:58:11 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/20/2022 13:58:11 - INFO - __main__ - Classification-F1 on test data: 0.0347
05/20/2022 13:58:11 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.061464262142871484, test_performance=0.0346654571503911
05/20/2022 13:58:11 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/20/2022 13:58:12 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:58:12 - INFO - __main__ - Printing 3 examples
05/20/2022 13:58:12 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/20/2022 13:58:12 - INFO - __main__ - ['Film']
05/20/2022 13:58:12 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/20/2022 13:58:12 - INFO - __main__ - ['Film']
05/20/2022 13:58:12 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/20/2022 13:58:12 - INFO - __main__ - ['Film']
05/20/2022 13:58:12 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:58:12 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:58:13 - INFO - __main__ - Loaded 224 examples from train data
05/20/2022 13:58:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/20/2022 13:58:13 - INFO - __main__ - Printing 3 examples
05/20/2022 13:58:13 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/20/2022 13:58:13 - INFO - __main__ - ['Film']
05/20/2022 13:58:13 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/20/2022 13:58:13 - INFO - __main__ - ['Film']
05/20/2022 13:58:13 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/20/2022 13:58:13 - INFO - __main__ - ['Film']
05/20/2022 13:58:13 - INFO - __main__ - Tokenizing Input ...
05/20/2022 13:58:13 - INFO - __main__ - Tokenizing Output ...
05/20/2022 13:58:13 - INFO - __main__ - Loaded 224 examples from dev data
05/20/2022 13:58:18 - INFO - __main__ - load prompt embedding from ckpt
05/20/2022 13:58:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/20/2022 13:58:18 - INFO - __main__ - Starting training!
05/20/2022 13:58:21 - INFO - __main__ - Step 10 Global step 10 Train loss 7.40 on epoch=0
05/20/2022 13:58:22 - INFO - __main__ - Step 20 Global step 20 Train loss 7.44 on epoch=1
05/20/2022 13:58:24 - INFO - __main__ - Step 30 Global step 30 Train loss 7.14 on epoch=2
05/20/2022 13:58:25 - INFO - __main__ - Step 40 Global step 40 Train loss 7.24 on epoch=2
05/20/2022 13:58:26 - INFO - __main__ - Step 50 Global step 50 Train loss 7.14 on epoch=3
05/20/2022 13:58:37 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/20/2022 13:58:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/20/2022 13:58:38 - INFO - __main__ - Step 60 Global step 60 Train loss 6.87 on epoch=4
05/20/2022 13:58:39 - INFO - __main__ - Step 70 Global step 70 Train loss 7.23 on epoch=4
05/20/2022 13:58:40 - INFO - __main__ - Step 80 Global step 80 Train loss 6.86 on epoch=5
05/20/2022 13:58:42 - INFO - __main__ - Step 90 Global step 90 Train loss 6.93 on epoch=6
05/20/2022 13:58:43 - INFO - __main__ - Step 100 Global step 100 Train loss 6.70 on epoch=7
05/20/2022 13:59:23 - INFO - __main__ - Global step 100 Train loss 6.92 Classification-F1 0.0 on epoch=7
05/20/2022 13:59:24 - INFO - __main__ - Step 110 Global step 110 Train loss 6.77 on epoch=7
05/20/2022 13:59:25 - INFO - __main__ - Step 120 Global step 120 Train loss 6.57 on epoch=8
05/20/2022 13:59:26 - INFO - __main__ - Step 130 Global step 130 Train loss 6.61 on epoch=9
05/20/2022 13:59:28 - INFO - __main__ - Step 140 Global step 140 Train loss 6.74 on epoch=9
05/20/2022 13:59:29 - INFO - __main__ - Step 150 Global step 150 Train loss 6.56 on epoch=10
05/20/2022 14:00:27 - INFO - __main__ - Global step 150 Train loss 6.65 Classification-F1 0.0 on epoch=10
05/20/2022 14:00:28 - INFO - __main__ - Step 160 Global step 160 Train loss 6.67 on epoch=11
05/20/2022 14:00:30 - INFO - __main__ - Step 170 Global step 170 Train loss 6.57 on epoch=12
05/20/2022 14:00:31 - INFO - __main__ - Step 180 Global step 180 Train loss 6.67 on epoch=12
05/20/2022 14:00:32 - INFO - __main__ - Step 190 Global step 190 Train loss 6.40 on epoch=13
05/20/2022 14:00:33 - INFO - __main__ - Step 200 Global step 200 Train loss 6.33 on epoch=14
05/20/2022 14:01:38 - INFO - __main__ - Global step 200 Train loss 6.53 Classification-F1 0.0 on epoch=14
05/20/2022 14:01:39 - INFO - __main__ - Step 210 Global step 210 Train loss 6.54 on epoch=14
05/20/2022 14:01:41 - INFO - __main__ - Step 220 Global step 220 Train loss 6.45 on epoch=15
05/20/2022 14:01:42 - INFO - __main__ - Step 230 Global step 230 Train loss 6.30 on epoch=16
05/20/2022 14:01:43 - INFO - __main__ - Step 240 Global step 240 Train loss 6.22 on epoch=17
05/20/2022 14:01:45 - INFO - __main__ - Step 250 Global step 250 Train loss 6.47 on epoch=17
05/20/2022 14:02:41 - INFO - __main__ - Global step 250 Train loss 6.39 Classification-F1 0.0 on epoch=17
05/20/2022 14:02:42 - INFO - __main__ - Step 260 Global step 260 Train loss 6.30 on epoch=18
05/20/2022 14:02:44 - INFO - __main__ - Step 270 Global step 270 Train loss 6.17 on epoch=19
05/20/2022 14:02:45 - INFO - __main__ - Step 280 Global step 280 Train loss 6.35 on epoch=19
05/20/2022 14:02:46 - INFO - __main__ - Step 290 Global step 290 Train loss 6.19 on epoch=20
05/20/2022 14:02:48 - INFO - __main__ - Step 300 Global step 300 Train loss 6.28 on epoch=21
05/20/2022 14:03:59 - INFO - __main__ - Global step 300 Train loss 6.26 Classification-F1 0.0 on epoch=21
05/20/2022 14:04:00 - INFO - __main__ - Step 310 Global step 310 Train loss 6.17 on epoch=22
05/20/2022 14:04:01 - INFO - __main__ - Step 320 Global step 320 Train loss 6.27 on epoch=22
05/20/2022 14:04:03 - INFO - __main__ - Step 330 Global step 330 Train loss 6.14 on epoch=23
05/20/2022 14:04:04 - INFO - __main__ - Step 340 Global step 340 Train loss 5.99 on epoch=24
05/20/2022 14:04:05 - INFO - __main__ - Step 350 Global step 350 Train loss 6.21 on epoch=24
05/20/2022 14:05:16 - INFO - __main__ - Global step 350 Train loss 6.16 Classification-F1 0.0 on epoch=24
05/20/2022 14:05:18 - INFO - __main__ - Step 360 Global step 360 Train loss 6.03 on epoch=25
05/20/2022 14:05:19 - INFO - __main__ - Step 370 Global step 370 Train loss 6.07 on epoch=26
05/20/2022 14:05:21 - INFO - __main__ - Step 380 Global step 380 Train loss 5.89 on epoch=27
05/20/2022 14:05:22 - INFO - __main__ - Step 390 Global step 390 Train loss 5.97 on epoch=27
05/20/2022 14:05:24 - INFO - __main__ - Step 400 Global step 400 Train loss 5.79 on epoch=28
05/20/2022 14:06:42 - INFO - __main__ - Global step 400 Train loss 5.95 Classification-F1 0.0 on epoch=28
05/20/2022 14:06:43 - INFO - __main__ - Step 410 Global step 410 Train loss 5.85 on epoch=29
05/20/2022 14:06:45 - INFO - __main__ - Step 420 Global step 420 Train loss 6.00 on epoch=29
05/20/2022 14:06:46 - INFO - __main__ - Step 430 Global step 430 Train loss 5.83 on epoch=30
05/20/2022 14:06:48 - INFO - __main__ - Step 440 Global step 440 Train loss 5.80 on epoch=31
05/20/2022 14:06:49 - INFO - __main__ - Step 450 Global step 450 Train loss 5.67 on epoch=32
05/20/2022 14:07:48 - INFO - __main__ - Global step 450 Train loss 5.83 Classification-F1 0.0 on epoch=32
05/20/2022 14:07:49 - INFO - __main__ - Step 460 Global step 460 Train loss 5.74 on epoch=32
05/20/2022 14:07:50 - INFO - __main__ - Step 470 Global step 470 Train loss 5.61 on epoch=33
05/20/2022 14:07:52 - INFO - __main__ - Step 480 Global step 480 Train loss 5.54 on epoch=34
05/20/2022 14:07:53 - INFO - __main__ - Step 490 Global step 490 Train loss 5.72 on epoch=34
05/20/2022 14:07:55 - INFO - __main__ - Step 500 Global step 500 Train loss 5.58 on epoch=35
05/20/2022 14:08:28 - INFO - __main__ - Global step 500 Train loss 5.64 Classification-F1 0.0019230769230769232 on epoch=35
05/20/2022 14:08:28 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0019230769230769232 on epoch=35, global_step=500
05/20/2022 14:08:29 - INFO - __main__ - Step 510 Global step 510 Train loss 5.59 on epoch=36
05/20/2022 14:08:31 - INFO - __main__ - Step 520 Global step 520 Train loss 5.54 on epoch=37
05/20/2022 14:08:32 - INFO - __main__ - Step 530 Global step 530 Train loss 5.57 on epoch=37
05/20/2022 14:08:33 - INFO - __main__ - Step 540 Global step 540 Train loss 5.40 on epoch=38
05/20/2022 14:08:35 - INFO - __main__ - Step 550 Global step 550 Train loss 5.38 on epoch=39
05/20/2022 14:09:01 - INFO - __main__ - Global step 550 Train loss 5.50 Classification-F1 0.003961516694963214 on epoch=39
05/20/2022 14:09:01 - INFO - __main__ - Saving model with best Classification-F1: 0.0019230769230769232 -> 0.003961516694963214 on epoch=39, global_step=550
05/20/2022 14:09:02 - INFO - __main__ - Step 560 Global step 560 Train loss 5.50 on epoch=39
05/20/2022 14:09:04 - INFO - __main__ - Step 570 Global step 570 Train loss 5.49 on epoch=40
05/20/2022 14:09:05 - INFO - __main__ - Step 580 Global step 580 Train loss 5.35 on epoch=41
05/20/2022 14:09:06 - INFO - __main__ - Step 590 Global step 590 Train loss 5.28 on epoch=42
05/20/2022 14:09:08 - INFO - __main__ - Step 600 Global step 600 Train loss 5.47 on epoch=42
05/20/2022 14:09:35 - INFO - __main__ - Global step 600 Train loss 5.42 Classification-F1 0.0026262036766851473 on epoch=42
05/20/2022 14:09:36 - INFO - __main__ - Step 610 Global step 610 Train loss 5.28 on epoch=43
05/20/2022 14:09:37 - INFO - __main__ - Step 620 Global step 620 Train loss 5.16 on epoch=44
05/20/2022 14:09:39 - INFO - __main__ - Step 630 Global step 630 Train loss 5.38 on epoch=44
05/20/2022 14:09:40 - INFO - __main__ - Step 640 Global step 640 Train loss 5.25 on epoch=45
05/20/2022 14:09:42 - INFO - __main__ - Step 650 Global step 650 Train loss 5.30 on epoch=46
05/20/2022 14:10:09 - INFO - __main__ - Global step 650 Train loss 5.27 Classification-F1 0.004222972972972973 on epoch=46
05/20/2022 14:10:10 - INFO - __main__ - Saving model with best Classification-F1: 0.003961516694963214 -> 0.004222972972972973 on epoch=46, global_step=650
05/20/2022 14:10:11 - INFO - __main__ - Step 660 Global step 660 Train loss 5.30 on epoch=47
05/20/2022 14:10:12 - INFO - __main__ - Step 670 Global step 670 Train loss 5.32 on epoch=47
05/20/2022 14:10:14 - INFO - __main__ - Step 680 Global step 680 Train loss 5.22 on epoch=48
05/20/2022 14:10:15 - INFO - __main__ - Step 690 Global step 690 Train loss 5.12 on epoch=49
05/20/2022 14:10:17 - INFO - __main__ - Step 700 Global step 700 Train loss 5.16 on epoch=49
05/20/2022 14:10:21 - INFO - __main__ - Global step 700 Train loss 5.22 Classification-F1 0.0071225071225071235 on epoch=49
05/20/2022 14:10:21 - INFO - __main__ - Saving model with best Classification-F1: 0.004222972972972973 -> 0.0071225071225071235 on epoch=49, global_step=700
05/20/2022 14:10:22 - INFO - __main__ - Step 710 Global step 710 Train loss 5.11 on epoch=50
05/20/2022 14:10:23 - INFO - __main__ - Step 720 Global step 720 Train loss 5.11 on epoch=51
05/20/2022 14:10:24 - INFO - __main__ - Step 730 Global step 730 Train loss 5.13 on epoch=52
05/20/2022 14:10:26 - INFO - __main__ - Step 740 Global step 740 Train loss 5.12 on epoch=52
05/20/2022 14:10:27 - INFO - __main__ - Step 750 Global step 750 Train loss 5.01 on epoch=53
05/20/2022 14:10:30 - INFO - __main__ - Global step 750 Train loss 5.10 Classification-F1 0.009523809523809523 on epoch=53
05/20/2022 14:10:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0071225071225071235 -> 0.009523809523809523 on epoch=53, global_step=750
05/20/2022 14:10:31 - INFO - __main__ - Step 760 Global step 760 Train loss 4.95 on epoch=54
05/20/2022 14:10:32 - INFO - __main__ - Step 770 Global step 770 Train loss 5.02 on epoch=54
05/20/2022 14:10:34 - INFO - __main__ - Step 780 Global step 780 Train loss 5.04 on epoch=55
05/20/2022 14:10:35 - INFO - __main__ - Step 790 Global step 790 Train loss 4.93 on epoch=56
05/20/2022 14:10:37 - INFO - __main__ - Step 800 Global step 800 Train loss 4.91 on epoch=57
05/20/2022 14:10:39 - INFO - __main__ - Global step 800 Train loss 4.97 Classification-F1 0.009523809523809523 on epoch=57
05/20/2022 14:10:40 - INFO - __main__ - Step 810 Global step 810 Train loss 4.95 on epoch=57
05/20/2022 14:10:42 - INFO - __main__ - Step 820 Global step 820 Train loss 4.89 on epoch=58
05/20/2022 14:10:43 - INFO - __main__ - Step 830 Global step 830 Train loss 4.81 on epoch=59
05/20/2022 14:10:45 - INFO - __main__ - Step 840 Global step 840 Train loss 4.93 on epoch=59
05/20/2022 14:10:46 - INFO - __main__ - Step 850 Global step 850 Train loss 4.95 on epoch=60
05/20/2022 14:10:49 - INFO - __main__ - Global step 850 Train loss 4.91 Classification-F1 0.009523809523809523 on epoch=60
05/20/2022 14:10:50 - INFO - __main__ - Step 860 Global step 860 Train loss 4.73 on epoch=61
05/20/2022 14:10:52 - INFO - __main__ - Step 870 Global step 870 Train loss 4.80 on epoch=62
05/20/2022 14:10:53 - INFO - __main__ - Step 880 Global step 880 Train loss 4.68 on epoch=62
05/20/2022 14:10:55 - INFO - __main__ - Step 890 Global step 890 Train loss 4.71 on epoch=63
05/20/2022 14:10:56 - INFO - __main__ - Step 900 Global step 900 Train loss 4.70 on epoch=64
05/20/2022 14:10:58 - INFO - __main__ - Global step 900 Train loss 4.73 Classification-F1 0.009523809523809523 on epoch=64
05/20/2022 14:11:00 - INFO - __main__ - Step 910 Global step 910 Train loss 4.82 on epoch=64
05/20/2022 14:11:01 - INFO - __main__ - Step 920 Global step 920 Train loss 4.75 on epoch=65
05/20/2022 14:11:02 - INFO - __main__ - Step 930 Global step 930 Train loss 4.59 on epoch=66
05/20/2022 14:11:04 - INFO - __main__ - Step 940 Global step 940 Train loss 4.64 on epoch=67
05/20/2022 14:11:05 - INFO - __main__ - Step 950 Global step 950 Train loss 4.70 on epoch=67
05/20/2022 14:11:08 - INFO - __main__ - Global step 950 Train loss 4.70 Classification-F1 0.009523809523809523 on epoch=67
05/20/2022 14:11:09 - INFO - __main__ - Step 960 Global step 960 Train loss 4.49 on epoch=68
05/20/2022 14:11:10 - INFO - __main__ - Step 970 Global step 970 Train loss 4.50 on epoch=69
05/20/2022 14:11:12 - INFO - __main__ - Step 980 Global step 980 Train loss 4.53 on epoch=69
05/20/2022 14:11:13 - INFO - __main__ - Step 990 Global step 990 Train loss 4.63 on epoch=70
05/20/2022 14:11:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.39 on epoch=71
05/20/2022 14:11:17 - INFO - __main__ - Global step 1000 Train loss 4.51 Classification-F1 0.009523809523809523 on epoch=71
05/20/2022 14:11:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.47 on epoch=72
05/20/2022 14:11:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.39 on epoch=72
05/20/2022 14:11:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.49 on epoch=73
05/20/2022 14:11:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.25 on epoch=74
05/20/2022 14:11:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.42 on epoch=74
05/20/2022 14:11:27 - INFO - __main__ - Global step 1050 Train loss 4.41 Classification-F1 0.009523809523809523 on epoch=74
05/20/2022 14:11:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.47 on epoch=75
05/20/2022 14:11:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.40 on epoch=76
05/20/2022 14:11:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.47 on epoch=77
05/20/2022 14:11:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.31 on epoch=77
05/20/2022 14:11:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.38 on epoch=78
05/20/2022 14:11:36 - INFO - __main__ - Global step 1100 Train loss 4.41 Classification-F1 0.009523809523809523 on epoch=78
05/20/2022 14:11:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.23 on epoch=79
05/20/2022 14:11:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.23 on epoch=79
05/20/2022 14:11:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.46 on epoch=80
05/20/2022 14:11:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.27 on epoch=81
05/20/2022 14:11:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.21 on epoch=82
05/20/2022 14:11:45 - INFO - __main__ - Global step 1150 Train loss 4.28 Classification-F1 0.009563658099222952 on epoch=82
05/20/2022 14:11:45 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009563658099222952 on epoch=82, global_step=1150
05/20/2022 14:11:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.20 on epoch=82
05/20/2022 14:11:48 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.28 on epoch=83
05/20/2022 14:11:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.06 on epoch=84
05/20/2022 14:11:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.17 on epoch=84
05/20/2022 14:11:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.38 on epoch=85
05/20/2022 14:11:54 - INFO - __main__ - Global step 1200 Train loss 4.22 Classification-F1 0.017104407565519775 on epoch=85
05/20/2022 14:11:54 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.017104407565519775 on epoch=85, global_step=1200
05/20/2022 14:11:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.06 on epoch=86
05/20/2022 14:11:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.06 on epoch=87
05/20/2022 14:11:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.09 on epoch=87
05/20/2022 14:12:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.10 on epoch=88
05/20/2022 14:12:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.02 on epoch=89
05/20/2022 14:12:04 - INFO - __main__ - Global step 1250 Train loss 4.07 Classification-F1 0.01761922888683452 on epoch=89
05/20/2022 14:12:04 - INFO - __main__ - Saving model with best Classification-F1: 0.017104407565519775 -> 0.01761922888683452 on epoch=89, global_step=1250
05/20/2022 14:12:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.02 on epoch=89
05/20/2022 14:12:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.31 on epoch=90
05/20/2022 14:12:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.87 on epoch=91
05/20/2022 14:12:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.10 on epoch=92
05/20/2022 14:12:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.99 on epoch=92
05/20/2022 14:12:14 - INFO - __main__ - Global step 1300 Train loss 4.06 Classification-F1 0.021873187930223786 on epoch=92
05/20/2022 14:12:14 - INFO - __main__ - Saving model with best Classification-F1: 0.01761922888683452 -> 0.021873187930223786 on epoch=92, global_step=1300
05/20/2022 14:12:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.04 on epoch=93
05/20/2022 14:12:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.82 on epoch=94
05/20/2022 14:12:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.95 on epoch=94
05/20/2022 14:12:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.03 on epoch=95
05/20/2022 14:12:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.83 on epoch=96
05/20/2022 14:12:23 - INFO - __main__ - Global step 1350 Train loss 3.93 Classification-F1 0.018614718614718615 on epoch=96
05/20/2022 14:12:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.93 on epoch=97
05/20/2022 14:12:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.96 on epoch=97
05/20/2022 14:12:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.91 on epoch=98
05/20/2022 14:12:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.80 on epoch=99
05/20/2022 14:12:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.74 on epoch=99
05/20/2022 14:12:32 - INFO - __main__ - Global step 1400 Train loss 3.87 Classification-F1 0.014901337247227659 on epoch=99
05/20/2022 14:12:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.93 on epoch=100
05/20/2022 14:12:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.64 on epoch=101
05/20/2022 14:12:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.73 on epoch=102
05/20/2022 14:12:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.72 on epoch=102
05/20/2022 14:12:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.80 on epoch=103
05/20/2022 14:12:41 - INFO - __main__ - Global step 1450 Train loss 3.76 Classification-F1 0.019930875576036868 on epoch=103
05/20/2022 14:12:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.65 on epoch=104
05/20/2022 14:12:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.72 on epoch=104
05/20/2022 14:12:45 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.83 on epoch=105
05/20/2022 14:12:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.65 on epoch=106
05/20/2022 14:12:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.65 on epoch=107
05/20/2022 14:12:50 - INFO - __main__ - Global step 1500 Train loss 3.70 Classification-F1 0.024521114427606305 on epoch=107
05/20/2022 14:12:50 - INFO - __main__ - Saving model with best Classification-F1: 0.021873187930223786 -> 0.024521114427606305 on epoch=107, global_step=1500
05/20/2022 14:12:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.77 on epoch=107
05/20/2022 14:12:53 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.71 on epoch=108
05/20/2022 14:12:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.65 on epoch=109
05/20/2022 14:12:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.56 on epoch=109
05/20/2022 14:12:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.68 on epoch=110
05/20/2022 14:12:59 - INFO - __main__ - Global step 1550 Train loss 3.67 Classification-F1 0.03806269982740571 on epoch=110
05/20/2022 14:12:59 - INFO - __main__ - Saving model with best Classification-F1: 0.024521114427606305 -> 0.03806269982740571 on epoch=110, global_step=1550
05/20/2022 14:13:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.58 on epoch=111
05/20/2022 14:13:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.69 on epoch=112
05/20/2022 14:13:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.68 on epoch=112
05/20/2022 14:13:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.53 on epoch=113
05/20/2022 14:13:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.67 on epoch=114
05/20/2022 14:13:08 - INFO - __main__ - Global step 1600 Train loss 3.63 Classification-F1 0.02168909092660188 on epoch=114
05/20/2022 14:13:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.52 on epoch=114
05/20/2022 14:13:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.71 on epoch=115
05/20/2022 14:13:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.55 on epoch=116
05/20/2022 14:13:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.61 on epoch=117
05/20/2022 14:13:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.45 on epoch=117
05/20/2022 14:13:17 - INFO - __main__ - Global step 1650 Train loss 3.57 Classification-F1 0.009563658099222952 on epoch=117
05/20/2022 14:13:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.67 on epoch=118
05/20/2022 14:13:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.47 on epoch=119
05/20/2022 14:13:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.43 on epoch=119
05/20/2022 14:13:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.70 on epoch=120
05/20/2022 14:13:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.55 on epoch=121
05/20/2022 14:13:26 - INFO - __main__ - Global step 1700 Train loss 3.56 Classification-F1 0.017704517704517704 on epoch=121
05/20/2022 14:13:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.62 on epoch=122
05/20/2022 14:13:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.47 on epoch=122
05/20/2022 14:13:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.70 on epoch=123
05/20/2022 14:13:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.44 on epoch=124
05/20/2022 14:13:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.44 on epoch=124
05/20/2022 14:13:34 - INFO - __main__ - Global step 1750 Train loss 3.53 Classification-F1 0.027118440539566906 on epoch=124
05/20/2022 14:13:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.65 on epoch=125
05/20/2022 14:13:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.43 on epoch=126
05/20/2022 14:13:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.45 on epoch=127
05/20/2022 14:13:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.29 on epoch=127
05/20/2022 14:13:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.54 on epoch=128
05/20/2022 14:13:43 - INFO - __main__ - Global step 1800 Train loss 3.47 Classification-F1 0.024031853828118684 on epoch=128
05/20/2022 14:13:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.37 on epoch=129
05/20/2022 14:13:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.50 on epoch=129
05/20/2022 14:13:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.61 on epoch=130
05/20/2022 14:13:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.37 on epoch=131
05/20/2022 14:13:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.53 on epoch=132
05/20/2022 14:13:51 - INFO - __main__ - Global step 1850 Train loss 3.48 Classification-F1 0.012161468360929278 on epoch=132
05/20/2022 14:13:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.48 on epoch=132
05/20/2022 14:13:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.55 on epoch=133
05/20/2022 14:13:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.42 on epoch=134
05/20/2022 14:13:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.36 on epoch=134
05/20/2022 14:13:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.47 on epoch=135
05/20/2022 14:14:00 - INFO - __main__ - Global step 1900 Train loss 3.46 Classification-F1 0.010249839846252402 on epoch=135
05/20/2022 14:14:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.31 on epoch=136
05/20/2022 14:14:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.41 on epoch=137
05/20/2022 14:14:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.34 on epoch=137
05/20/2022 14:14:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.39 on epoch=138
05/20/2022 14:14:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.45 on epoch=139
05/20/2022 14:14:09 - INFO - __main__ - Global step 1950 Train loss 3.38 Classification-F1 0.0206747275712793 on epoch=139
05/20/2022 14:14:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.39 on epoch=139
05/20/2022 14:14:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.58 on epoch=140
05/20/2022 14:14:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.33 on epoch=141
05/20/2022 14:14:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.32 on epoch=142
05/20/2022 14:14:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.40 on epoch=142
05/20/2022 14:14:18 - INFO - __main__ - Global step 2000 Train loss 3.40 Classification-F1 0.02703772418058133 on epoch=142
05/20/2022 14:14:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.35 on epoch=143
05/20/2022 14:14:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.27 on epoch=144
05/20/2022 14:14:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.24 on epoch=144
05/20/2022 14:14:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.38 on epoch=145
05/20/2022 14:14:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.23 on epoch=146
05/20/2022 14:14:27 - INFO - __main__ - Global step 2050 Train loss 3.30 Classification-F1 0.021442651969264186 on epoch=146
05/20/2022 14:14:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.40 on epoch=147
05/20/2022 14:14:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.14 on epoch=147
05/20/2022 14:14:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.46 on epoch=148
05/20/2022 14:14:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.26 on epoch=149
05/20/2022 14:14:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.35 on epoch=149
05/20/2022 14:14:36 - INFO - __main__ - Global step 2100 Train loss 3.32 Classification-F1 0.009563658099222952 on epoch=149
05/20/2022 14:14:37 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.43 on epoch=150
05/20/2022 14:14:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.20 on epoch=151
05/20/2022 14:14:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.21 on epoch=152
05/20/2022 14:14:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.22 on epoch=152
05/20/2022 14:14:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.36 on epoch=153
05/20/2022 14:14:44 - INFO - __main__ - Global step 2150 Train loss 3.28 Classification-F1 0.01544973544973545 on epoch=153
05/20/2022 14:14:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.24 on epoch=154
05/20/2022 14:14:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.17 on epoch=154
05/20/2022 14:14:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.35 on epoch=155
05/20/2022 14:14:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.03 on epoch=156
05/20/2022 14:14:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.18 on epoch=157
05/20/2022 14:14:53 - INFO - __main__ - Global step 2200 Train loss 3.19 Classification-F1 0.009563658099222952 on epoch=157
05/20/2022 14:14:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.17 on epoch=157
05/20/2022 14:14:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.18 on epoch=158
05/20/2022 14:14:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 3.17 on epoch=159
05/20/2022 14:14:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.13 on epoch=159
05/20/2022 14:15:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 3.21 on epoch=160
05/20/2022 14:15:02 - INFO - __main__ - Global step 2250 Train loss 3.17 Classification-F1 0.009523809523809523 on epoch=160
05/20/2022 14:15:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.12 on epoch=161
05/20/2022 14:15:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.33 on epoch=162
05/20/2022 14:15:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.04 on epoch=162
05/20/2022 14:15:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 3.16 on epoch=163
05/20/2022 14:15:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.12 on epoch=164
05/20/2022 14:15:12 - INFO - __main__ - Global step 2300 Train loss 3.15 Classification-F1 0.009563658099222952 on epoch=164
05/20/2022 14:15:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.08 on epoch=164
05/20/2022 14:15:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.26 on epoch=165
05/20/2022 14:15:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 3.22 on epoch=166
05/20/2022 14:15:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.09 on epoch=167
05/20/2022 14:15:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.13 on epoch=167
05/20/2022 14:15:21 - INFO - __main__ - Global step 2350 Train loss 3.16 Classification-F1 0.01796701944376077 on epoch=167
05/20/2022 14:15:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.15 on epoch=168
05/20/2022 14:15:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.98 on epoch=169
05/20/2022 14:15:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 3.08 on epoch=169
05/20/2022 14:15:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 3.23 on epoch=170
05/20/2022 14:15:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.92 on epoch=171
05/20/2022 14:15:30 - INFO - __main__ - Global step 2400 Train loss 3.07 Classification-F1 0.015272290381460687 on epoch=171
05/20/2022 14:15:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.19 on epoch=172
05/20/2022 14:15:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.00 on epoch=172
05/20/2022 14:15:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.14 on epoch=173
05/20/2022 14:15:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.99 on epoch=174
05/20/2022 14:15:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.07 on epoch=174
05/20/2022 14:15:39 - INFO - __main__ - Global step 2450 Train loss 3.08 Classification-F1 0.009523809523809523 on epoch=174
05/20/2022 14:15:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 3.14 on epoch=175
05/20/2022 14:15:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.92 on epoch=176
05/20/2022 14:15:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.99 on epoch=177
05/20/2022 14:15:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 3.21 on epoch=177
05/20/2022 14:15:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.11 on epoch=178
05/20/2022 14:15:48 - INFO - __main__ - Global step 2500 Train loss 3.07 Classification-F1 0.022317227286171384 on epoch=178
05/20/2022 14:15:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 3.07 on epoch=179
05/20/2022 14:15:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 3.04 on epoch=179
05/20/2022 14:15:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 3.12 on epoch=180
05/20/2022 14:15:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.11 on epoch=181
05/20/2022 14:15:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.08 on epoch=182
05/20/2022 14:15:58 - INFO - __main__ - Global step 2550 Train loss 3.08 Classification-F1 0.017580872011251757 on epoch=182
05/20/2022 14:15:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 3.01 on epoch=182
05/20/2022 14:16:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 3.11 on epoch=183
05/20/2022 14:16:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.79 on epoch=184
05/20/2022 14:16:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.93 on epoch=184
05/20/2022 14:16:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 3.12 on epoch=185
05/20/2022 14:16:06 - INFO - __main__ - Global step 2600 Train loss 2.99 Classification-F1 0.009644364074743823 on epoch=185
05/20/2022 14:16:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.86 on epoch=186
05/20/2022 14:16:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 3.07 on epoch=187
05/20/2022 14:16:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.84 on epoch=187
05/20/2022 14:16:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 3.02 on epoch=188
05/20/2022 14:16:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.95 on epoch=189
05/20/2022 14:16:15 - INFO - __main__ - Global step 2650 Train loss 2.95 Classification-F1 0.009041591320072331 on epoch=189
05/20/2022 14:16:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.95 on epoch=189
05/20/2022 14:16:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 3.11 on epoch=190
05/20/2022 14:16:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.99 on epoch=191
05/20/2022 14:16:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.98 on epoch=192
05/20/2022 14:16:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 3.03 on epoch=192
05/20/2022 14:16:24 - INFO - __main__ - Global step 2700 Train loss 3.01 Classification-F1 0.009523809523809523 on epoch=192
05/20/2022 14:16:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 3.06 on epoch=193
05/20/2022 14:16:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.96 on epoch=194
05/20/2022 14:16:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.93 on epoch=194
05/20/2022 14:16:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 3.11 on epoch=195
05/20/2022 14:16:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/20/2022 14:16:33 - INFO - __main__ - Global step 2750 Train loss 3.00 Classification-F1 0.009523809523809523 on epoch=196
05/20/2022 14:16:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 3.21 on epoch=197
05/20/2022 14:16:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.98 on epoch=197
05/20/2022 14:16:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 3.19 on epoch=198
05/20/2022 14:16:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.94 on epoch=199
05/20/2022 14:16:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.94 on epoch=199
05/20/2022 14:16:42 - INFO - __main__ - Global step 2800 Train loss 3.05 Classification-F1 0.0394118460156196 on epoch=199
05/20/2022 14:16:43 - INFO - __main__ - Saving model with best Classification-F1: 0.03806269982740571 -> 0.0394118460156196 on epoch=199, global_step=2800
05/20/2022 14:16:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 3.06 on epoch=200
05/20/2022 14:16:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.84 on epoch=201
05/20/2022 14:16:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.90 on epoch=202
05/20/2022 14:16:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 3.04 on epoch=202
05/20/2022 14:16:49 - INFO - __main__ - Step 2850 Global step 2850 Train loss 3.08 on epoch=203
05/20/2022 14:16:51 - INFO - __main__ - Global step 2850 Train loss 2.98 Classification-F1 0.04125036111791079 on epoch=203
05/20/2022 14:16:51 - INFO - __main__ - Saving model with best Classification-F1: 0.0394118460156196 -> 0.04125036111791079 on epoch=203, global_step=2850
05/20/2022 14:16:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.90 on epoch=204
05/20/2022 14:16:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.88 on epoch=204
05/20/2022 14:16:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 3.10 on epoch=205
05/20/2022 14:16:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.96 on epoch=206
05/20/2022 14:16:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.95 on epoch=207
05/20/2022 14:17:00 - INFO - __main__ - Global step 2900 Train loss 2.96 Classification-F1 0.0442352965116097 on epoch=207
05/20/2022 14:17:00 - INFO - __main__ - Saving model with best Classification-F1: 0.04125036111791079 -> 0.0442352965116097 on epoch=207, global_step=2900
05/20/2022 14:17:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.82 on epoch=207
05/20/2022 14:17:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 3.07 on epoch=208
05/20/2022 14:17:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.94 on epoch=209
05/20/2022 14:17:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.86 on epoch=209
05/20/2022 14:17:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 3.08 on epoch=210
05/20/2022 14:17:09 - INFO - __main__ - Global step 2950 Train loss 2.95 Classification-F1 0.05457669787448294 on epoch=210
05/20/2022 14:17:09 - INFO - __main__ - Saving model with best Classification-F1: 0.0442352965116097 -> 0.05457669787448294 on epoch=210, global_step=2950
05/20/2022 14:17:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.69 on epoch=211
05/20/2022 14:17:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.90 on epoch=212
05/20/2022 14:17:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.86 on epoch=212
05/20/2022 14:17:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.98 on epoch=213
05/20/2022 14:17:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.88 on epoch=214
05/20/2022 14:17:17 - INFO - __main__ - Global step 3000 Train loss 2.86 Classification-F1 0.020305480682839168 on epoch=214
05/20/2022 14:17:17 - INFO - __main__ - save last model!
05/20/2022 14:17:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/20/2022 14:17:17 - INFO - __main__ - Start tokenizing ... 3500 instances
05/20/2022 14:17:17 - INFO - __main__ - Printing 3 examples
05/20/2022 14:17:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/20/2022 14:17:17 - INFO - __main__ - ['Animal']
05/20/2022 14:17:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/20/2022 14:17:17 - INFO - __main__ - ['Animal']
05/20/2022 14:17:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/20/2022 14:17:17 - INFO - __main__ - ['Village']
05/20/2022 14:17:17 - INFO - __main__ - Tokenizing Input ...
05/20/2022 14:17:19 - INFO - __main__ - Tokenizing Output ...
05/20/2022 14:17:23 - INFO - __main__ - Loaded 3500 examples from test data
05/20/2022 14:17:52 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/20/2022 14:17:52 - INFO - __main__ - Classification-F1 on test data: 0.0272
05/20/2022 14:17:52 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.05457669787448294, test_performance=0.027175661431532258
05/29/2022 17:35:46 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/29/2022 17:35:46 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
05/29/2022 17:35:46 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-fomaml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='2,3')
05/29/2022 17:35:46 - INFO - __main__ - models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14
05/29/2022 17:35:47 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/29/2022 17:35:47 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/29/2022 17:35:47 - INFO - __main__ - args.device: cuda:0
05/29/2022 17:35:47 - INFO - __main__ - Using 2 gpus
05/29/2022 17:35:47 - INFO - __main__ - args.device: cuda:1
05/29/2022 17:35:47 - INFO - __main__ - Using 2 gpus
05/29/2022 17:35:47 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/29/2022 17:35:47 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/29/2022 17:35:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/29/2022 17:35:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:35:53 - INFO - __main__ - Printing 3 examples
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:35:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:35:53 - INFO - __main__ - Printing 3 examples
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:35:53 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 17:35:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:35:53 - INFO - __main__ - Printing 3 examples
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:35:53 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 17:35:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:35:53 - INFO - __main__ - Printing 3 examples
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 17:35:53 - INFO - __main__ - ['Animal']
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:35:53 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:35:53 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 17:35:54 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 17:35:59 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 17:36:00 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 17:36:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 17:36:00 - INFO - __main__ - Starting training!
05/29/2022 17:36:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 17:36:05 - INFO - __main__ - Starting training!
05/29/2022 17:36:07 - INFO - __main__ - Step 10 Global step 10 Train loss 7.27 on epoch=0
05/29/2022 17:36:08 - INFO - __main__ - Step 20 Global step 20 Train loss 7.27 on epoch=1
05/29/2022 17:36:09 - INFO - __main__ - Step 30 Global step 30 Train loss 6.96 on epoch=2
05/29/2022 17:36:11 - INFO - __main__ - Step 40 Global step 40 Train loss 6.94 on epoch=2
05/29/2022 17:36:12 - INFO - __main__ - Step 50 Global step 50 Train loss 6.87 on epoch=3
05/29/2022 17:37:00 - INFO - __main__ - Global step 50 Train loss 7.06 Classification-F1 0.0 on epoch=3
05/29/2022 17:37:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 17:37:01 - INFO - __main__ - Step 60 Global step 60 Train loss 6.61 on epoch=4
05/29/2022 17:37:02 - INFO - __main__ - Step 70 Global step 70 Train loss 6.73 on epoch=4
05/29/2022 17:37:04 - INFO - __main__ - Step 80 Global step 80 Train loss 6.51 on epoch=5
05/29/2022 17:37:05 - INFO - __main__ - Step 90 Global step 90 Train loss 6.22 on epoch=6
05/29/2022 17:37:06 - INFO - __main__ - Step 100 Global step 100 Train loss 6.19 on epoch=7
05/29/2022 17:38:07 - INFO - __main__ - Global step 100 Train loss 6.45 Classification-F1 0.0 on epoch=7
05/29/2022 17:38:08 - INFO - __main__ - Step 110 Global step 110 Train loss 6.21 on epoch=7
05/29/2022 17:38:10 - INFO - __main__ - Step 120 Global step 120 Train loss 6.12 on epoch=8
05/29/2022 17:38:11 - INFO - __main__ - Step 130 Global step 130 Train loss 5.88 on epoch=9
05/29/2022 17:38:12 - INFO - __main__ - Step 140 Global step 140 Train loss 6.11 on epoch=9
05/29/2022 17:38:13 - INFO - __main__ - Step 150 Global step 150 Train loss 6.02 on epoch=10
05/29/2022 17:38:46 - INFO - __main__ - Global step 150 Train loss 6.07 Classification-F1 0.0 on epoch=10
05/29/2022 17:38:47 - INFO - __main__ - Step 160 Global step 160 Train loss 5.87 on epoch=11
05/29/2022 17:38:48 - INFO - __main__ - Step 170 Global step 170 Train loss 5.65 on epoch=12
05/29/2022 17:38:49 - INFO - __main__ - Step 180 Global step 180 Train loss 5.76 on epoch=12
05/29/2022 17:38:51 - INFO - __main__ - Step 190 Global step 190 Train loss 5.65 on epoch=13
05/29/2022 17:38:52 - INFO - __main__ - Step 200 Global step 200 Train loss 5.54 on epoch=14
05/29/2022 17:40:01 - INFO - __main__ - Global step 200 Train loss 5.69 Classification-F1 0.0 on epoch=14
05/29/2022 17:40:02 - INFO - __main__ - Step 210 Global step 210 Train loss 5.63 on epoch=14
05/29/2022 17:40:03 - INFO - __main__ - Step 220 Global step 220 Train loss 5.43 on epoch=15
05/29/2022 17:40:05 - INFO - __main__ - Step 230 Global step 230 Train loss 5.51 on epoch=16
05/29/2022 17:40:06 - INFO - __main__ - Step 240 Global step 240 Train loss 5.26 on epoch=17
05/29/2022 17:40:07 - INFO - __main__ - Step 250 Global step 250 Train loss 5.33 on epoch=17
05/29/2022 17:40:44 - INFO - __main__ - Global step 250 Train loss 5.43 Classification-F1 0.0 on epoch=17
05/29/2022 17:40:45 - INFO - __main__ - Step 260 Global step 260 Train loss 5.27 on epoch=18
05/29/2022 17:40:46 - INFO - __main__ - Step 270 Global step 270 Train loss 5.16 on epoch=19
05/29/2022 17:40:48 - INFO - __main__ - Step 280 Global step 280 Train loss 5.10 on epoch=19
05/29/2022 17:40:49 - INFO - __main__ - Step 290 Global step 290 Train loss 5.18 on epoch=20
05/29/2022 17:40:50 - INFO - __main__ - Step 300 Global step 300 Train loss 5.00 on epoch=21
05/29/2022 17:41:02 - INFO - __main__ - Global step 300 Train loss 5.14 Classification-F1 0.005291005291005292 on epoch=21
05/29/2022 17:41:02 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005291005291005292 on epoch=21, global_step=300
05/29/2022 17:41:03 - INFO - __main__ - Step 310 Global step 310 Train loss 4.90 on epoch=22
05/29/2022 17:41:04 - INFO - __main__ - Step 320 Global step 320 Train loss 5.02 on epoch=22
05/29/2022 17:41:06 - INFO - __main__ - Step 330 Global step 330 Train loss 4.99 on epoch=23
05/29/2022 17:41:07 - INFO - __main__ - Step 340 Global step 340 Train loss 4.79 on epoch=24
05/29/2022 17:41:08 - INFO - __main__ - Step 350 Global step 350 Train loss 4.77 on epoch=24
05/29/2022 17:41:11 - INFO - __main__ - Global step 350 Train loss 4.90 Classification-F1 0.007352941176470587 on epoch=24
05/29/2022 17:41:11 - INFO - __main__ - Saving model with best Classification-F1: 0.005291005291005292 -> 0.007352941176470587 on epoch=24, global_step=350
05/29/2022 17:41:13 - INFO - __main__ - Step 360 Global step 360 Train loss 4.75 on epoch=25
05/29/2022 17:41:14 - INFO - __main__ - Step 370 Global step 370 Train loss 4.66 on epoch=26
05/29/2022 17:41:15 - INFO - __main__ - Step 380 Global step 380 Train loss 4.57 on epoch=27
05/29/2022 17:41:17 - INFO - __main__ - Step 390 Global step 390 Train loss 4.59 on epoch=27
05/29/2022 17:41:18 - INFO - __main__ - Step 400 Global step 400 Train loss 4.61 on epoch=28
05/29/2022 17:41:20 - INFO - __main__ - Global step 400 Train loss 4.63 Classification-F1 0.009523809523809523 on epoch=28
05/29/2022 17:41:20 - INFO - __main__ - Saving model with best Classification-F1: 0.007352941176470587 -> 0.009523809523809523 on epoch=28, global_step=400
05/29/2022 17:41:22 - INFO - __main__ - Step 410 Global step 410 Train loss 4.55 on epoch=29
05/29/2022 17:41:23 - INFO - __main__ - Step 420 Global step 420 Train loss 4.47 on epoch=29
05/29/2022 17:41:24 - INFO - __main__ - Step 430 Global step 430 Train loss 4.59 on epoch=30
05/29/2022 17:41:25 - INFO - __main__ - Step 440 Global step 440 Train loss 4.25 on epoch=31
05/29/2022 17:41:27 - INFO - __main__ - Step 450 Global step 450 Train loss 4.37 on epoch=32
05/29/2022 17:41:28 - INFO - __main__ - Global step 450 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=32
05/29/2022 17:41:30 - INFO - __main__ - Step 460 Global step 460 Train loss 4.23 on epoch=32
05/29/2022 17:41:31 - INFO - __main__ - Step 470 Global step 470 Train loss 4.23 on epoch=33
05/29/2022 17:41:32 - INFO - __main__ - Step 480 Global step 480 Train loss 4.08 on epoch=34
05/29/2022 17:41:33 - INFO - __main__ - Step 490 Global step 490 Train loss 4.17 on epoch=34
05/29/2022 17:41:35 - INFO - __main__ - Step 500 Global step 500 Train loss 4.00 on epoch=35
05/29/2022 17:41:36 - INFO - __main__ - Global step 500 Train loss 4.14 Classification-F1 0.009523809523809523 on epoch=35
05/29/2022 17:41:38 - INFO - __main__ - Step 510 Global step 510 Train loss 3.94 on epoch=36
05/29/2022 17:41:39 - INFO - __main__ - Step 520 Global step 520 Train loss 3.94 on epoch=37
05/29/2022 17:41:40 - INFO - __main__ - Step 530 Global step 530 Train loss 4.06 on epoch=37
05/29/2022 17:41:41 - INFO - __main__ - Step 540 Global step 540 Train loss 3.75 on epoch=38
05/29/2022 17:41:43 - INFO - __main__ - Step 550 Global step 550 Train loss 3.82 on epoch=39
05/29/2022 17:41:44 - INFO - __main__ - Global step 550 Train loss 3.90 Classification-F1 0.010025062656641603 on epoch=39
05/29/2022 17:41:45 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.010025062656641603 on epoch=39, global_step=550
05/29/2022 17:41:46 - INFO - __main__ - Step 560 Global step 560 Train loss 3.70 on epoch=39
05/29/2022 17:41:47 - INFO - __main__ - Step 570 Global step 570 Train loss 3.94 on epoch=40
05/29/2022 17:41:48 - INFO - __main__ - Step 580 Global step 580 Train loss 3.47 on epoch=41
05/29/2022 17:41:50 - INFO - __main__ - Step 590 Global step 590 Train loss 3.58 on epoch=42
05/29/2022 17:41:51 - INFO - __main__ - Step 600 Global step 600 Train loss 3.65 on epoch=42
05/29/2022 17:41:53 - INFO - __main__ - Global step 600 Train loss 3.67 Classification-F1 0.018887743776755988 on epoch=42
05/29/2022 17:41:53 - INFO - __main__ - Saving model with best Classification-F1: 0.010025062656641603 -> 0.018887743776755988 on epoch=42, global_step=600
05/29/2022 17:41:54 - INFO - __main__ - Step 610 Global step 610 Train loss 3.51 on epoch=43
05/29/2022 17:41:55 - INFO - __main__ - Step 620 Global step 620 Train loss 3.68 on epoch=44
05/29/2022 17:41:57 - INFO - __main__ - Step 630 Global step 630 Train loss 3.39 on epoch=44
05/29/2022 17:41:58 - INFO - __main__ - Step 640 Global step 640 Train loss 3.54 on epoch=45
05/29/2022 17:41:59 - INFO - __main__ - Step 650 Global step 650 Train loss 3.44 on epoch=46
05/29/2022 17:42:01 - INFO - __main__ - Global step 650 Train loss 3.51 Classification-F1 0.027956989247311832 on epoch=46
05/29/2022 17:42:01 - INFO - __main__ - Saving model with best Classification-F1: 0.018887743776755988 -> 0.027956989247311832 on epoch=46, global_step=650
05/29/2022 17:42:02 - INFO - __main__ - Step 660 Global step 660 Train loss 3.52 on epoch=47
05/29/2022 17:42:04 - INFO - __main__ - Step 670 Global step 670 Train loss 3.47 on epoch=47
05/29/2022 17:42:05 - INFO - __main__ - Step 680 Global step 680 Train loss 3.36 on epoch=48
05/29/2022 17:42:06 - INFO - __main__ - Step 690 Global step 690 Train loss 3.31 on epoch=49
05/29/2022 17:42:07 - INFO - __main__ - Step 700 Global step 700 Train loss 3.34 on epoch=49
05/29/2022 17:42:09 - INFO - __main__ - Global step 700 Train loss 3.40 Classification-F1 0.020337301587301588 on epoch=49
05/29/2022 17:42:10 - INFO - __main__ - Step 710 Global step 710 Train loss 3.23 on epoch=50
05/29/2022 17:42:12 - INFO - __main__ - Step 720 Global step 720 Train loss 3.26 on epoch=51
05/29/2022 17:42:13 - INFO - __main__ - Step 730 Global step 730 Train loss 3.12 on epoch=52
05/29/2022 17:42:14 - INFO - __main__ - Step 740 Global step 740 Train loss 3.50 on epoch=52
05/29/2022 17:42:15 - INFO - __main__ - Step 750 Global step 750 Train loss 3.07 on epoch=53
05/29/2022 17:42:17 - INFO - __main__ - Global step 750 Train loss 3.24 Classification-F1 0.022669796663604715 on epoch=53
05/29/2022 17:42:18 - INFO - __main__ - Step 760 Global step 760 Train loss 3.37 on epoch=54
05/29/2022 17:42:20 - INFO - __main__ - Step 770 Global step 770 Train loss 3.16 on epoch=54
05/29/2022 17:42:21 - INFO - __main__ - Step 780 Global step 780 Train loss 3.28 on epoch=55
05/29/2022 17:42:22 - INFO - __main__ - Step 790 Global step 790 Train loss 3.12 on epoch=56
05/29/2022 17:42:23 - INFO - __main__ - Step 800 Global step 800 Train loss 3.16 on epoch=57
05/29/2022 17:42:25 - INFO - __main__ - Global step 800 Train loss 3.22 Classification-F1 0.029869573672629705 on epoch=57
05/29/2022 17:42:25 - INFO - __main__ - Saving model with best Classification-F1: 0.027956989247311832 -> 0.029869573672629705 on epoch=57, global_step=800
05/29/2022 17:42:27 - INFO - __main__ - Step 810 Global step 810 Train loss 3.18 on epoch=57
05/29/2022 17:42:28 - INFO - __main__ - Step 820 Global step 820 Train loss 3.01 on epoch=58
05/29/2022 17:42:29 - INFO - __main__ - Step 830 Global step 830 Train loss 3.15 on epoch=59
05/29/2022 17:42:31 - INFO - __main__ - Step 840 Global step 840 Train loss 3.00 on epoch=59
05/29/2022 17:42:32 - INFO - __main__ - Step 850 Global step 850 Train loss 3.08 on epoch=60
05/29/2022 17:42:34 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.047294246554072286 on epoch=60
05/29/2022 17:42:34 - INFO - __main__ - Saving model with best Classification-F1: 0.029869573672629705 -> 0.047294246554072286 on epoch=60, global_step=850
05/29/2022 17:42:35 - INFO - __main__ - Step 860 Global step 860 Train loss 3.01 on epoch=61
05/29/2022 17:42:37 - INFO - __main__ - Step 870 Global step 870 Train loss 3.03 on epoch=62
05/29/2022 17:42:38 - INFO - __main__ - Step 880 Global step 880 Train loss 3.11 on epoch=62
05/29/2022 17:42:39 - INFO - __main__ - Step 890 Global step 890 Train loss 3.14 on epoch=63
05/29/2022 17:42:40 - INFO - __main__ - Step 900 Global step 900 Train loss 3.04 on epoch=64
05/29/2022 17:42:42 - INFO - __main__ - Global step 900 Train loss 3.06 Classification-F1 0.04571456323477886 on epoch=64
05/29/2022 17:42:43 - INFO - __main__ - Step 910 Global step 910 Train loss 2.88 on epoch=64
05/29/2022 17:42:45 - INFO - __main__ - Step 920 Global step 920 Train loss 3.04 on epoch=65
05/29/2022 17:42:46 - INFO - __main__ - Step 930 Global step 930 Train loss 2.85 on epoch=66
05/29/2022 17:42:47 - INFO - __main__ - Step 940 Global step 940 Train loss 2.81 on epoch=67
05/29/2022 17:42:48 - INFO - __main__ - Step 950 Global step 950 Train loss 2.92 on epoch=67
05/29/2022 17:42:50 - INFO - __main__ - Global step 950 Train loss 2.90 Classification-F1 0.05722270245125096 on epoch=67
05/29/2022 17:42:50 - INFO - __main__ - Saving model with best Classification-F1: 0.047294246554072286 -> 0.05722270245125096 on epoch=67, global_step=950
05/29/2022 17:42:51 - INFO - __main__ - Step 960 Global step 960 Train loss 2.72 on epoch=68
05/29/2022 17:42:53 - INFO - __main__ - Step 970 Global step 970 Train loss 2.97 on epoch=69
05/29/2022 17:42:54 - INFO - __main__ - Step 980 Global step 980 Train loss 2.64 on epoch=69
05/29/2022 17:42:55 - INFO - __main__ - Step 990 Global step 990 Train loss 2.87 on epoch=70
05/29/2022 17:42:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.70 on epoch=71
05/29/2022 17:42:59 - INFO - __main__ - Global step 1000 Train loss 2.78 Classification-F1 0.06777881146408957 on epoch=71
05/29/2022 17:42:59 - INFO - __main__ - Saving model with best Classification-F1: 0.05722270245125096 -> 0.06777881146408957 on epoch=71, global_step=1000
05/29/2022 17:43:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.78 on epoch=72
05/29/2022 17:43:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.69 on epoch=72
05/29/2022 17:43:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.78 on epoch=73
05/29/2022 17:43:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.80 on epoch=74
05/29/2022 17:43:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.45 on epoch=74
05/29/2022 17:43:07 - INFO - __main__ - Global step 1050 Train loss 2.70 Classification-F1 0.06117963720703446 on epoch=74
05/29/2022 17:43:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.94 on epoch=75
05/29/2022 17:43:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.56 on epoch=76
05/29/2022 17:43:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.67 on epoch=77
05/29/2022 17:43:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.87 on epoch=77
05/29/2022 17:43:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.65 on epoch=78
05/29/2022 17:43:15 - INFO - __main__ - Global step 1100 Train loss 2.74 Classification-F1 0.055416841223292844 on epoch=78
05/29/2022 17:43:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.84 on epoch=79
05/29/2022 17:43:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.63 on epoch=79
05/29/2022 17:43:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.78 on epoch=80
05/29/2022 17:43:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.62 on epoch=81
05/29/2022 17:43:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.79 on epoch=82
05/29/2022 17:43:24 - INFO - __main__ - Global step 1150 Train loss 2.73 Classification-F1 0.036294517807122846 on epoch=82
05/29/2022 17:43:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.72 on epoch=82
05/29/2022 17:43:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.59 on epoch=83
05/29/2022 17:43:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.70 on epoch=84
05/29/2022 17:43:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.60 on epoch=84
05/29/2022 17:43:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.67 on epoch=85
05/29/2022 17:43:32 - INFO - __main__ - Global step 1200 Train loss 2.66 Classification-F1 0.037661792905081495 on epoch=85
05/29/2022 17:43:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.42 on epoch=86
05/29/2022 17:43:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.53 on epoch=87
05/29/2022 17:43:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.60 on epoch=87
05/29/2022 17:43:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.52 on epoch=88
05/29/2022 17:43:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.63 on epoch=89
05/29/2022 17:43:40 - INFO - __main__ - Global step 1250 Train loss 2.54 Classification-F1 0.04100095279575462 on epoch=89
05/29/2022 17:43:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.55 on epoch=89
05/29/2022 17:43:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.38 on epoch=90
05/29/2022 17:43:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.45 on epoch=91
05/29/2022 17:43:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.38 on epoch=92
05/29/2022 17:43:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.71 on epoch=92
05/29/2022 17:43:50 - INFO - __main__ - Global step 1300 Train loss 2.49 Classification-F1 0.036953856502728685 on epoch=92
05/29/2022 17:43:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.65 on epoch=93
05/29/2022 17:43:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.64 on epoch=94
05/29/2022 17:43:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.38 on epoch=94
05/29/2022 17:43:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.45 on epoch=95
05/29/2022 17:43:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.44 on epoch=96
05/29/2022 17:43:58 - INFO - __main__ - Global step 1350 Train loss 2.51 Classification-F1 0.03842364532019704 on epoch=96
05/29/2022 17:43:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.54 on epoch=97
05/29/2022 17:44:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.56 on epoch=97
05/29/2022 17:44:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.65 on epoch=98
05/29/2022 17:44:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.56 on epoch=99
05/29/2022 17:44:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.39 on epoch=99
05/29/2022 17:44:07 - INFO - __main__ - Global step 1400 Train loss 2.54 Classification-F1 0.06573914150640493 on epoch=99
05/29/2022 17:44:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.54 on epoch=100
05/29/2022 17:44:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.48 on epoch=101
05/29/2022 17:44:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.42 on epoch=102
05/29/2022 17:44:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.46 on epoch=102
05/29/2022 17:44:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.49 on epoch=103
05/29/2022 17:44:15 - INFO - __main__ - Global step 1450 Train loss 2.48 Classification-F1 0.05746239783334139 on epoch=103
05/29/2022 17:44:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.52 on epoch=104
05/29/2022 17:44:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.30 on epoch=104
05/29/2022 17:44:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.43 on epoch=105
05/29/2022 17:44:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.34 on epoch=106
05/29/2022 17:44:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.35 on epoch=107
05/29/2022 17:44:23 - INFO - __main__ - Global step 1500 Train loss 2.39 Classification-F1 0.08818117246125592 on epoch=107
05/29/2022 17:44:23 - INFO - __main__ - Saving model with best Classification-F1: 0.06777881146408957 -> 0.08818117246125592 on epoch=107, global_step=1500
05/29/2022 17:44:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.24 on epoch=107
05/29/2022 17:44:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.29 on epoch=108
05/29/2022 17:44:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.40 on epoch=109
05/29/2022 17:44:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.20 on epoch=109
05/29/2022 17:44:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.37 on epoch=110
05/29/2022 17:44:32 - INFO - __main__ - Global step 1550 Train loss 2.30 Classification-F1 0.04395149364093463 on epoch=110
05/29/2022 17:44:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.31 on epoch=111
05/29/2022 17:44:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.30 on epoch=112
05/29/2022 17:44:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.40 on epoch=112
05/29/2022 17:44:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.30 on epoch=113
05/29/2022 17:44:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.19 on epoch=114
05/29/2022 17:44:41 - INFO - __main__ - Global step 1600 Train loss 2.30 Classification-F1 0.009563658099222952 on epoch=114
05/29/2022 17:44:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.38 on epoch=114
05/29/2022 17:44:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.20 on epoch=115
05/29/2022 17:44:45 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.31 on epoch=116
05/29/2022 17:44:46 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.20 on epoch=117
05/29/2022 17:44:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.10 on epoch=117
05/29/2022 17:44:49 - INFO - __main__ - Global step 1650 Train loss 2.24 Classification-F1 0.08235901140766592 on epoch=117
05/29/2022 17:44:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.10 on epoch=118
05/29/2022 17:44:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.16 on epoch=119
05/29/2022 17:44:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.09 on epoch=119
05/29/2022 17:44:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.21 on epoch=120
05/29/2022 17:44:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.13 on epoch=121
05/29/2022 17:44:57 - INFO - __main__ - Global step 1700 Train loss 2.14 Classification-F1 0.0758425587398516 on epoch=121
05/29/2022 17:44:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.04 on epoch=122
05/29/2022 17:45:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.14 on epoch=122
05/29/2022 17:45:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.10 on epoch=123
05/29/2022 17:45:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.25 on epoch=124
05/29/2022 17:45:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.05 on epoch=124
05/29/2022 17:45:07 - INFO - __main__ - Global step 1750 Train loss 2.12 Classification-F1 0.09199202343127434 on epoch=124
05/29/2022 17:45:07 - INFO - __main__ - Saving model with best Classification-F1: 0.08818117246125592 -> 0.09199202343127434 on epoch=124, global_step=1750
05/29/2022 17:45:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.01 on epoch=125
05/29/2022 17:45:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.96 on epoch=126
05/29/2022 17:45:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.10 on epoch=127
05/29/2022 17:45:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.10 on epoch=127
05/29/2022 17:45:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.00 on epoch=128
05/29/2022 17:45:15 - INFO - __main__ - Global step 1800 Train loss 2.03 Classification-F1 0.04276155217331688 on epoch=128
05/29/2022 17:45:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.10 on epoch=129
05/29/2022 17:45:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.01 on epoch=129
05/29/2022 17:45:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.16 on epoch=130
05/29/2022 17:45:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.91 on epoch=131
05/29/2022 17:45:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.09 on epoch=132
05/29/2022 17:45:24 - INFO - __main__ - Global step 1850 Train loss 2.05 Classification-F1 0.0772836966954614 on epoch=132
05/29/2022 17:45:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.00 on epoch=132
05/29/2022 17:45:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.97 on epoch=133
05/29/2022 17:45:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.93 on epoch=134
05/29/2022 17:45:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.03 on epoch=134
05/29/2022 17:45:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.08 on epoch=135
05/29/2022 17:45:33 - INFO - __main__ - Global step 1900 Train loss 2.00 Classification-F1 0.1358986016399465 on epoch=135
05/29/2022 17:45:33 - INFO - __main__ - Saving model with best Classification-F1: 0.09199202343127434 -> 0.1358986016399465 on epoch=135, global_step=1900
05/29/2022 17:45:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.02 on epoch=136
05/29/2022 17:45:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.95 on epoch=137
05/29/2022 17:45:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.95 on epoch=137
05/29/2022 17:45:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.01 on epoch=138
05/29/2022 17:45:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.00 on epoch=139
05/29/2022 17:45:42 - INFO - __main__ - Global step 1950 Train loss 1.99 Classification-F1 0.13749163350492255 on epoch=139
05/29/2022 17:45:42 - INFO - __main__ - Saving model with best Classification-F1: 0.1358986016399465 -> 0.13749163350492255 on epoch=139, global_step=1950
05/29/2022 17:45:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.90 on epoch=139
05/29/2022 17:45:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.98 on epoch=140
05/29/2022 17:45:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.00 on epoch=141
05/29/2022 17:45:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.99 on epoch=142
05/29/2022 17:45:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.97 on epoch=142
05/29/2022 17:45:51 - INFO - __main__ - Global step 2000 Train loss 1.97 Classification-F1 0.07585988360132458 on epoch=142
05/29/2022 17:45:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.94 on epoch=143
05/29/2022 17:45:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.82 on epoch=144
05/29/2022 17:45:55 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.91 on epoch=144
05/29/2022 17:45:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.83 on epoch=145
05/29/2022 17:45:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.84 on epoch=146
05/29/2022 17:46:00 - INFO - __main__ - Global step 2050 Train loss 1.87 Classification-F1 0.06060839360939062 on epoch=146
05/29/2022 17:46:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.76 on epoch=147
05/29/2022 17:46:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.92 on epoch=147
05/29/2022 17:46:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.84 on epoch=148
05/29/2022 17:46:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.83 on epoch=149
05/29/2022 17:46:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.92 on epoch=149
05/29/2022 17:46:09 - INFO - __main__ - Global step 2100 Train loss 1.85 Classification-F1 0.1467214031078043 on epoch=149
05/29/2022 17:46:09 - INFO - __main__ - Saving model with best Classification-F1: 0.13749163350492255 -> 0.1467214031078043 on epoch=149, global_step=2100
05/29/2022 17:46:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.81 on epoch=150
05/29/2022 17:46:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.79 on epoch=151
05/29/2022 17:46:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.70 on epoch=152
05/29/2022 17:46:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.83 on epoch=152
05/29/2022 17:46:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.75 on epoch=153
05/29/2022 17:46:18 - INFO - __main__ - Global step 2150 Train loss 1.78 Classification-F1 0.18730469328380228 on epoch=153
05/29/2022 17:46:18 - INFO - __main__ - Saving model with best Classification-F1: 0.1467214031078043 -> 0.18730469328380228 on epoch=153, global_step=2150
05/29/2022 17:46:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.84 on epoch=154
05/29/2022 17:46:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.70 on epoch=154
05/29/2022 17:46:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.90 on epoch=155
05/29/2022 17:46:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.82 on epoch=156
05/29/2022 17:46:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.78 on epoch=157
05/29/2022 17:46:27 - INFO - __main__ - Global step 2200 Train loss 1.81 Classification-F1 0.2156707433079219 on epoch=157
05/29/2022 17:46:27 - INFO - __main__ - Saving model with best Classification-F1: 0.18730469328380228 -> 0.2156707433079219 on epoch=157, global_step=2200
05/29/2022 17:46:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.76 on epoch=157
05/29/2022 17:46:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.71 on epoch=158
05/29/2022 17:46:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.81 on epoch=159
05/29/2022 17:46:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.72 on epoch=159
05/29/2022 17:46:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.89 on epoch=160
05/29/2022 17:46:36 - INFO - __main__ - Global step 2250 Train loss 1.78 Classification-F1 0.23713464290581981 on epoch=160
05/29/2022 17:46:36 - INFO - __main__ - Saving model with best Classification-F1: 0.2156707433079219 -> 0.23713464290581981 on epoch=160, global_step=2250
05/29/2022 17:46:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.75 on epoch=161
05/29/2022 17:46:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.69 on epoch=162
05/29/2022 17:46:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.57 on epoch=162
05/29/2022 17:46:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.83 on epoch=163
05/29/2022 17:46:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.71 on epoch=164
05/29/2022 17:46:45 - INFO - __main__ - Global step 2300 Train loss 1.71 Classification-F1 0.24540822757444516 on epoch=164
05/29/2022 17:46:45 - INFO - __main__ - Saving model with best Classification-F1: 0.23713464290581981 -> 0.24540822757444516 on epoch=164, global_step=2300
05/29/2022 17:46:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.65 on epoch=164
05/29/2022 17:46:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.67 on epoch=165
05/29/2022 17:46:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.66 on epoch=166
05/29/2022 17:46:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.71 on epoch=167
05/29/2022 17:46:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.69 on epoch=167
05/29/2022 17:46:54 - INFO - __main__ - Global step 2350 Train loss 1.67 Classification-F1 0.20157112512872594 on epoch=167
05/29/2022 17:46:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.63 on epoch=168
05/29/2022 17:46:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.71 on epoch=169
05/29/2022 17:46:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.69 on epoch=169
05/29/2022 17:46:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.72 on epoch=170
05/29/2022 17:47:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.78 on epoch=171
05/29/2022 17:47:03 - INFO - __main__ - Global step 2400 Train loss 1.70 Classification-F1 0.2670019335999158 on epoch=171
05/29/2022 17:47:03 - INFO - __main__ - Saving model with best Classification-F1: 0.24540822757444516 -> 0.2670019335999158 on epoch=171, global_step=2400
05/29/2022 17:47:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.66 on epoch=172
05/29/2022 17:47:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.57 on epoch=172
05/29/2022 17:47:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.69 on epoch=173
05/29/2022 17:47:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.49 on epoch=174
05/29/2022 17:47:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.63 on epoch=174
05/29/2022 17:47:12 - INFO - __main__ - Global step 2450 Train loss 1.61 Classification-F1 0.20804672747358435 on epoch=174
05/29/2022 17:47:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.55 on epoch=175
05/29/2022 17:47:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.55 on epoch=176
05/29/2022 17:47:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.59 on epoch=177
05/29/2022 17:47:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.58 on epoch=177
05/29/2022 17:47:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.59 on epoch=178
05/29/2022 17:47:21 - INFO - __main__ - Global step 2500 Train loss 1.57 Classification-F1 0.30142174721450904 on epoch=178
05/29/2022 17:47:22 - INFO - __main__ - Saving model with best Classification-F1: 0.2670019335999158 -> 0.30142174721450904 on epoch=178, global_step=2500
05/29/2022 17:47:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.64 on epoch=179
05/29/2022 17:47:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.51 on epoch=179
05/29/2022 17:47:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.56 on epoch=180
05/29/2022 17:47:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.71 on epoch=181
05/29/2022 17:47:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.61 on epoch=182
05/29/2022 17:47:30 - INFO - __main__ - Global step 2550 Train loss 1.60 Classification-F1 0.183016358755275 on epoch=182
05/29/2022 17:47:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.69 on epoch=182
05/29/2022 17:47:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.63 on epoch=183
05/29/2022 17:47:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.55 on epoch=184
05/29/2022 17:47:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.63 on epoch=184
05/29/2022 17:47:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.58 on epoch=185
05/29/2022 17:47:39 - INFO - __main__ - Global step 2600 Train loss 1.61 Classification-F1 0.18653851870108443 on epoch=185
05/29/2022 17:47:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.59 on epoch=186
05/29/2022 17:47:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.58 on epoch=187
05/29/2022 17:47:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.54 on epoch=187
05/29/2022 17:47:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.64 on epoch=188
05/29/2022 17:47:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.39 on epoch=189
05/29/2022 17:47:48 - INFO - __main__ - Global step 2650 Train loss 1.55 Classification-F1 0.28334397491229685 on epoch=189
05/29/2022 17:47:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.54 on epoch=189
05/29/2022 17:47:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.65 on epoch=190
05/29/2022 17:47:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.49 on epoch=191
05/29/2022 17:47:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.59 on epoch=192
05/29/2022 17:47:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.44 on epoch=192
05/29/2022 17:47:57 - INFO - __main__ - Global step 2700 Train loss 1.54 Classification-F1 0.25181042980421653 on epoch=192
05/29/2022 17:47:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.55 on epoch=193
05/29/2022 17:48:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.49 on epoch=194
05/29/2022 17:48:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.54 on epoch=194
05/29/2022 17:48:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.43 on epoch=195
05/29/2022 17:48:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.59 on epoch=196
05/29/2022 17:48:06 - INFO - __main__ - Global step 2750 Train loss 1.52 Classification-F1 0.24703446691735118 on epoch=196
05/29/2022 17:48:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.35 on epoch=197
05/29/2022 17:48:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.37 on epoch=197
05/29/2022 17:48:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.52 on epoch=198
05/29/2022 17:48:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.47 on epoch=199
05/29/2022 17:48:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.53 on epoch=199
05/29/2022 17:48:16 - INFO - __main__ - Global step 2800 Train loss 1.45 Classification-F1 0.2813225879160257 on epoch=199
05/29/2022 17:48:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.48 on epoch=200
05/29/2022 17:48:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.47 on epoch=201
05/29/2022 17:48:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.42 on epoch=202
05/29/2022 17:48:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.47 on epoch=202
05/29/2022 17:48:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.51 on epoch=203
05/29/2022 17:48:25 - INFO - __main__ - Global step 2850 Train loss 1.47 Classification-F1 0.3463450938633764 on epoch=203
05/29/2022 17:48:25 - INFO - __main__ - Saving model with best Classification-F1: 0.30142174721450904 -> 0.3463450938633764 on epoch=203, global_step=2850
05/29/2022 17:48:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.53 on epoch=204
05/29/2022 17:48:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.41 on epoch=204
05/29/2022 17:48:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.39 on epoch=205
05/29/2022 17:48:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.48 on epoch=206
05/29/2022 17:48:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.36 on epoch=207
05/29/2022 17:48:35 - INFO - __main__ - Global step 2900 Train loss 1.43 Classification-F1 0.37502529902529896 on epoch=207
05/29/2022 17:48:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3463450938633764 -> 0.37502529902529896 on epoch=207, global_step=2900
05/29/2022 17:48:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.33 on epoch=207
05/29/2022 17:48:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.33 on epoch=208
05/29/2022 17:48:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.38 on epoch=209
05/29/2022 17:48:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.32 on epoch=209
05/29/2022 17:48:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.36 on epoch=210
05/29/2022 17:48:44 - INFO - __main__ - Global step 2950 Train loss 1.34 Classification-F1 0.3392752506331597 on epoch=210
05/29/2022 17:48:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.40 on epoch=211
05/29/2022 17:48:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.38 on epoch=212
05/29/2022 17:48:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.29 on epoch=212
05/29/2022 17:48:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.44 on epoch=213
05/29/2022 17:48:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.39 on epoch=214
05/29/2022 17:48:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:48:52 - INFO - __main__ - Printing 3 examples
05/29/2022 17:48:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 17:48:52 - INFO - __main__ - ['Animal']
05/29/2022 17:48:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 17:48:52 - INFO - __main__ - ['Animal']
05/29/2022 17:48:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 17:48:52 - INFO - __main__ - ['Animal']
05/29/2022 17:48:52 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:48:52 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:48:52 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 17:48:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:48:52 - INFO - __main__ - Printing 3 examples
05/29/2022 17:48:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 17:48:52 - INFO - __main__ - ['Animal']
05/29/2022 17:48:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 17:48:52 - INFO - __main__ - ['Animal']
05/29/2022 17:48:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 17:48:52 - INFO - __main__ - ['Animal']
05/29/2022 17:48:52 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:48:52 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:48:52 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 17:48:54 - INFO - __main__ - Global step 3000 Train loss 1.38 Classification-F1 0.3952647899862215 on epoch=214
05/29/2022 17:48:54 - INFO - __main__ - Saving model with best Classification-F1: 0.37502529902529896 -> 0.3952647899862215 on epoch=214, global_step=3000
05/29/2022 17:48:54 - INFO - __main__ - save last model!
05/29/2022 17:48:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 17:48:54 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 17:48:54 - INFO - __main__ - Printing 3 examples
05/29/2022 17:48:54 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 17:48:54 - INFO - __main__ - ['Animal']
05/29/2022 17:48:54 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 17:48:54 - INFO - __main__ - ['Animal']
05/29/2022 17:48:54 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 17:48:54 - INFO - __main__ - ['Village']
05/29/2022 17:48:54 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:48:55 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:48:58 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 17:48:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 17:48:58 - INFO - __main__ - Starting training!
05/29/2022 17:48:59 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 17:49:52 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/29/2022 17:49:52 - INFO - __main__ - Classification-F1 on test data: 0.3192
05/29/2022 17:49:52 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.3952647899862215, test_performance=0.3192215004932146
05/29/2022 17:49:52 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/29/2022 17:49:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:49:53 - INFO - __main__ - Printing 3 examples
05/29/2022 17:49:53 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 17:49:53 - INFO - __main__ - ['Animal']
05/29/2022 17:49:53 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 17:49:53 - INFO - __main__ - ['Animal']
05/29/2022 17:49:53 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 17:49:53 - INFO - __main__ - ['Animal']
05/29/2022 17:49:53 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:49:53 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:49:54 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 17:49:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 17:49:54 - INFO - __main__ - Printing 3 examples
05/29/2022 17:49:54 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 17:49:54 - INFO - __main__ - ['Animal']
05/29/2022 17:49:54 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 17:49:54 - INFO - __main__ - ['Animal']
05/29/2022 17:49:54 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 17:49:54 - INFO - __main__ - ['Animal']
05/29/2022 17:49:54 - INFO - __main__ - Tokenizing Input ...
05/29/2022 17:49:54 - INFO - __main__ - Tokenizing Output ...
05/29/2022 17:49:54 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 17:49:59 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 17:49:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 17:49:59 - INFO - __main__ - Starting training!
05/29/2022 17:50:01 - INFO - __main__ - Step 10 Global step 10 Train loss 7.37 on epoch=0
05/29/2022 17:50:02 - INFO - __main__ - Step 20 Global step 20 Train loss 7.34 on epoch=1
05/29/2022 17:50:04 - INFO - __main__ - Step 30 Global step 30 Train loss 7.08 on epoch=2
05/29/2022 17:50:05 - INFO - __main__ - Step 40 Global step 40 Train loss 6.93 on epoch=2
05/29/2022 17:50:06 - INFO - __main__ - Step 50 Global step 50 Train loss 6.92 on epoch=3
05/29/2022 17:50:30 - INFO - __main__ - Global step 50 Train loss 7.13 Classification-F1 0.0 on epoch=3
05/29/2022 17:50:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 17:50:31 - INFO - __main__ - Step 60 Global step 60 Train loss 6.60 on epoch=4
05/29/2022 17:50:33 - INFO - __main__ - Step 70 Global step 70 Train loss 6.65 on epoch=4
05/29/2022 17:50:34 - INFO - __main__ - Step 80 Global step 80 Train loss 6.44 on epoch=5
05/29/2022 17:50:35 - INFO - __main__ - Step 90 Global step 90 Train loss 6.25 on epoch=6
05/29/2022 17:50:37 - INFO - __main__ - Step 100 Global step 100 Train loss 6.28 on epoch=7
05/29/2022 17:51:17 - INFO - __main__ - Global step 100 Train loss 6.45 Classification-F1 0.0 on epoch=7
05/29/2022 17:51:18 - INFO - __main__ - Step 110 Global step 110 Train loss 6.31 on epoch=7
05/29/2022 17:51:19 - INFO - __main__ - Step 120 Global step 120 Train loss 6.17 on epoch=8
05/29/2022 17:51:21 - INFO - __main__ - Step 130 Global step 130 Train loss 6.08 on epoch=9
05/29/2022 17:51:22 - INFO - __main__ - Step 140 Global step 140 Train loss 6.16 on epoch=9
05/29/2022 17:51:23 - INFO - __main__ - Step 150 Global step 150 Train loss 5.99 on epoch=10
05/29/2022 17:52:32 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/29/2022 17:52:33 - INFO - __main__ - Step 160 Global step 160 Train loss 5.96 on epoch=11
05/29/2022 17:52:35 - INFO - __main__ - Step 170 Global step 170 Train loss 5.91 on epoch=12
05/29/2022 17:52:36 - INFO - __main__ - Step 180 Global step 180 Train loss 5.74 on epoch=12
05/29/2022 17:52:37 - INFO - __main__ - Step 190 Global step 190 Train loss 5.77 on epoch=13
05/29/2022 17:52:38 - INFO - __main__ - Step 200 Global step 200 Train loss 5.56 on epoch=14
05/29/2022 17:53:13 - INFO - __main__ - Global step 200 Train loss 5.79 Classification-F1 0.0 on epoch=14
05/29/2022 17:53:14 - INFO - __main__ - Step 210 Global step 210 Train loss 5.68 on epoch=14
05/29/2022 17:53:16 - INFO - __main__ - Step 220 Global step 220 Train loss 5.52 on epoch=15
05/29/2022 17:53:17 - INFO - __main__ - Step 230 Global step 230 Train loss 5.51 on epoch=16
05/29/2022 17:53:18 - INFO - __main__ - Step 240 Global step 240 Train loss 5.38 on epoch=17
05/29/2022 17:53:20 - INFO - __main__ - Step 250 Global step 250 Train loss 5.38 on epoch=17
05/29/2022 17:53:47 - INFO - __main__ - Global step 250 Train loss 5.49 Classification-F1 0.0 on epoch=17
05/29/2022 17:53:48 - INFO - __main__ - Step 260 Global step 260 Train loss 5.32 on epoch=18
05/29/2022 17:53:49 - INFO - __main__ - Step 270 Global step 270 Train loss 5.40 on epoch=19
05/29/2022 17:53:51 - INFO - __main__ - Step 280 Global step 280 Train loss 5.25 on epoch=19
05/29/2022 17:53:52 - INFO - __main__ - Step 290 Global step 290 Train loss 5.20 on epoch=20
05/29/2022 17:53:53 - INFO - __main__ - Step 300 Global step 300 Train loss 5.13 on epoch=21
05/29/2022 17:54:13 - INFO - __main__ - Global step 300 Train loss 5.26 Classification-F1 0.0 on epoch=21
05/29/2022 17:54:15 - INFO - __main__ - Step 310 Global step 310 Train loss 4.99 on epoch=22
05/29/2022 17:54:16 - INFO - __main__ - Step 320 Global step 320 Train loss 5.00 on epoch=22
05/29/2022 17:54:17 - INFO - __main__ - Step 330 Global step 330 Train loss 4.91 on epoch=23
05/29/2022 17:54:19 - INFO - __main__ - Step 340 Global step 340 Train loss 4.90 on epoch=24
05/29/2022 17:54:20 - INFO - __main__ - Step 350 Global step 350 Train loss 5.00 on epoch=24
05/29/2022 17:54:22 - INFO - __main__ - Global step 350 Train loss 4.96 Classification-F1 0.01215277777777778 on epoch=24
05/29/2022 17:54:22 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.01215277777777778 on epoch=24, global_step=350
05/29/2022 17:54:24 - INFO - __main__ - Step 360 Global step 360 Train loss 4.91 on epoch=25
05/29/2022 17:54:25 - INFO - __main__ - Step 370 Global step 370 Train loss 4.87 on epoch=26
05/29/2022 17:54:26 - INFO - __main__ - Step 380 Global step 380 Train loss 4.76 on epoch=27
05/29/2022 17:54:27 - INFO - __main__ - Step 390 Global step 390 Train loss 4.75 on epoch=27
05/29/2022 17:54:29 - INFO - __main__ - Step 400 Global step 400 Train loss 4.82 on epoch=28
05/29/2022 17:54:31 - INFO - __main__ - Global step 400 Train loss 4.82 Classification-F1 0.007729468599033816 on epoch=28
05/29/2022 17:54:32 - INFO - __main__ - Step 410 Global step 410 Train loss 4.68 on epoch=29
05/29/2022 17:54:34 - INFO - __main__ - Step 420 Global step 420 Train loss 4.65 on epoch=29
05/29/2022 17:54:35 - INFO - __main__ - Step 430 Global step 430 Train loss 4.70 on epoch=30
05/29/2022 17:54:36 - INFO - __main__ - Step 440 Global step 440 Train loss 4.45 on epoch=31
05/29/2022 17:54:37 - INFO - __main__ - Step 450 Global step 450 Train loss 4.47 on epoch=32
05/29/2022 17:54:40 - INFO - __main__ - Global step 450 Train loss 4.59 Classification-F1 0.00892608089260809 on epoch=32
05/29/2022 17:54:41 - INFO - __main__ - Step 460 Global step 460 Train loss 4.58 on epoch=32
05/29/2022 17:54:42 - INFO - __main__ - Step 470 Global step 470 Train loss 4.52 on epoch=33
05/29/2022 17:54:43 - INFO - __main__ - Step 480 Global step 480 Train loss 4.45 on epoch=34
05/29/2022 17:54:45 - INFO - __main__ - Step 490 Global step 490 Train loss 4.33 on epoch=34
05/29/2022 17:54:46 - INFO - __main__ - Step 500 Global step 500 Train loss 4.47 on epoch=35
05/29/2022 17:54:48 - INFO - __main__ - Global step 500 Train loss 4.47 Classification-F1 0.009523809523809523 on epoch=35
05/29/2022 17:54:49 - INFO - __main__ - Step 510 Global step 510 Train loss 4.27 on epoch=36
05/29/2022 17:54:50 - INFO - __main__ - Step 520 Global step 520 Train loss 4.44 on epoch=37
05/29/2022 17:54:52 - INFO - __main__ - Step 530 Global step 530 Train loss 4.27 on epoch=37
05/29/2022 17:54:53 - INFO - __main__ - Step 540 Global step 540 Train loss 4.14 on epoch=38
05/29/2022 17:54:54 - INFO - __main__ - Step 550 Global step 550 Train loss 4.22 on epoch=39
05/29/2022 17:54:56 - INFO - __main__ - Global step 550 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=39
05/29/2022 17:54:57 - INFO - __main__ - Step 560 Global step 560 Train loss 4.17 on epoch=39
05/29/2022 17:54:59 - INFO - __main__ - Step 570 Global step 570 Train loss 4.06 on epoch=40
05/29/2022 17:55:00 - INFO - __main__ - Step 580 Global step 580 Train loss 3.98 on epoch=41
05/29/2022 17:55:01 - INFO - __main__ - Step 590 Global step 590 Train loss 3.99 on epoch=42
05/29/2022 17:55:02 - INFO - __main__ - Step 600 Global step 600 Train loss 4.09 on epoch=42
05/29/2022 17:55:04 - INFO - __main__ - Global step 600 Train loss 4.06 Classification-F1 0.009523809523809523 on epoch=42
05/29/2022 17:55:05 - INFO - __main__ - Step 610 Global step 610 Train loss 3.90 on epoch=43
05/29/2022 17:55:07 - INFO - __main__ - Step 620 Global step 620 Train loss 3.77 on epoch=44
05/29/2022 17:55:08 - INFO - __main__ - Step 630 Global step 630 Train loss 3.80 on epoch=44
05/29/2022 17:55:09 - INFO - __main__ - Step 640 Global step 640 Train loss 3.90 on epoch=45
05/29/2022 17:55:10 - INFO - __main__ - Step 650 Global step 650 Train loss 3.71 on epoch=46
05/29/2022 17:55:12 - INFO - __main__ - Global step 650 Train loss 3.81 Classification-F1 0.009523809523809523 on epoch=46
05/29/2022 17:55:14 - INFO - __main__ - Step 660 Global step 660 Train loss 3.63 on epoch=47
05/29/2022 17:55:15 - INFO - __main__ - Step 670 Global step 670 Train loss 3.64 on epoch=47
05/29/2022 17:55:16 - INFO - __main__ - Step 680 Global step 680 Train loss 3.67 on epoch=48
05/29/2022 17:55:17 - INFO - __main__ - Step 690 Global step 690 Train loss 3.72 on epoch=49
05/29/2022 17:55:19 - INFO - __main__ - Step 700 Global step 700 Train loss 3.55 on epoch=49
05/29/2022 17:55:21 - INFO - __main__ - Global step 700 Train loss 3.64 Classification-F1 0.024408468244084682 on epoch=49
05/29/2022 17:55:21 - INFO - __main__ - Saving model with best Classification-F1: 0.01215277777777778 -> 0.024408468244084682 on epoch=49, global_step=700
05/29/2022 17:55:22 - INFO - __main__ - Step 710 Global step 710 Train loss 3.68 on epoch=50
05/29/2022 17:55:23 - INFO - __main__ - Step 720 Global step 720 Train loss 3.56 on epoch=51
05/29/2022 17:55:24 - INFO - __main__ - Step 730 Global step 730 Train loss 3.49 on epoch=52
05/29/2022 17:55:26 - INFO - __main__ - Step 740 Global step 740 Train loss 3.46 on epoch=52
05/29/2022 17:55:27 - INFO - __main__ - Step 750 Global step 750 Train loss 3.36 on epoch=53
05/29/2022 17:55:29 - INFO - __main__ - Global step 750 Train loss 3.51 Classification-F1 0.025960798985678952 on epoch=53
05/29/2022 17:55:29 - INFO - __main__ - Saving model with best Classification-F1: 0.024408468244084682 -> 0.025960798985678952 on epoch=53, global_step=750
05/29/2022 17:55:30 - INFO - __main__ - Step 760 Global step 760 Train loss 3.37 on epoch=54
05/29/2022 17:55:31 - INFO - __main__ - Step 770 Global step 770 Train loss 3.45 on epoch=54
05/29/2022 17:55:33 - INFO - __main__ - Step 780 Global step 780 Train loss 3.50 on epoch=55
05/29/2022 17:55:34 - INFO - __main__ - Step 790 Global step 790 Train loss 3.35 on epoch=56
05/29/2022 17:55:35 - INFO - __main__ - Step 800 Global step 800 Train loss 3.30 on epoch=57
05/29/2022 17:55:37 - INFO - __main__ - Global step 800 Train loss 3.39 Classification-F1 0.028797581150674156 on epoch=57
05/29/2022 17:55:37 - INFO - __main__ - Saving model with best Classification-F1: 0.025960798985678952 -> 0.028797581150674156 on epoch=57, global_step=800
05/29/2022 17:55:38 - INFO - __main__ - Step 810 Global step 810 Train loss 3.43 on epoch=57
05/29/2022 17:55:39 - INFO - __main__ - Step 820 Global step 820 Train loss 3.23 on epoch=58
05/29/2022 17:55:41 - INFO - __main__ - Step 830 Global step 830 Train loss 3.39 on epoch=59
05/29/2022 17:55:42 - INFO - __main__ - Step 840 Global step 840 Train loss 3.34 on epoch=59
05/29/2022 17:55:43 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/29/2022 17:55:45 - INFO - __main__ - Global step 850 Train loss 3.32 Classification-F1 0.024344964816523453 on epoch=60
05/29/2022 17:55:46 - INFO - __main__ - Step 860 Global step 860 Train loss 3.15 on epoch=61
05/29/2022 17:55:48 - INFO - __main__ - Step 870 Global step 870 Train loss 3.24 on epoch=62
05/29/2022 17:55:49 - INFO - __main__ - Step 880 Global step 880 Train loss 3.32 on epoch=62
05/29/2022 17:55:50 - INFO - __main__ - Step 890 Global step 890 Train loss 3.16 on epoch=63
05/29/2022 17:55:51 - INFO - __main__ - Step 900 Global step 900 Train loss 3.35 on epoch=64
05/29/2022 17:55:53 - INFO - __main__ - Global step 900 Train loss 3.24 Classification-F1 0.009726443768996961 on epoch=64
05/29/2022 17:55:55 - INFO - __main__ - Step 910 Global step 910 Train loss 3.23 on epoch=64
05/29/2022 17:55:56 - INFO - __main__ - Step 920 Global step 920 Train loss 3.27 on epoch=65
05/29/2022 17:55:57 - INFO - __main__ - Step 930 Global step 930 Train loss 3.23 on epoch=66
05/29/2022 17:55:58 - INFO - __main__ - Step 940 Global step 940 Train loss 3.08 on epoch=67
05/29/2022 17:56:00 - INFO - __main__ - Step 950 Global step 950 Train loss 3.14 on epoch=67
05/29/2022 17:56:02 - INFO - __main__ - Global step 950 Train loss 3.19 Classification-F1 0.03988684582743989 on epoch=67
05/29/2022 17:56:02 - INFO - __main__ - Saving model with best Classification-F1: 0.028797581150674156 -> 0.03988684582743989 on epoch=67, global_step=950
05/29/2022 17:56:03 - INFO - __main__ - Step 960 Global step 960 Train loss 3.18 on epoch=68
05/29/2022 17:56:04 - INFO - __main__ - Step 970 Global step 970 Train loss 3.37 on epoch=69
05/29/2022 17:56:05 - INFO - __main__ - Step 980 Global step 980 Train loss 3.08 on epoch=69
05/29/2022 17:56:06 - INFO - __main__ - Step 990 Global step 990 Train loss 3.08 on epoch=70
05/29/2022 17:56:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.00 on epoch=71
05/29/2022 17:56:10 - INFO - __main__ - Global step 1000 Train loss 3.14 Classification-F1 0.009563658099222952 on epoch=71
05/29/2022 17:56:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.06 on epoch=72
05/29/2022 17:56:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.16 on epoch=72
05/29/2022 17:56:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.99 on epoch=73
05/29/2022 17:56:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.22 on epoch=74
05/29/2022 17:56:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.98 on epoch=74
05/29/2022 17:56:17 - INFO - __main__ - Global step 1050 Train loss 3.08 Classification-F1 0.03559501611080259 on epoch=74
05/29/2022 17:56:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.13 on epoch=75
05/29/2022 17:56:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.96 on epoch=76
05/29/2022 17:56:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.00 on epoch=77
05/29/2022 17:56:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.10 on epoch=77
05/29/2022 17:56:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.97 on epoch=78
05/29/2022 17:56:25 - INFO - __main__ - Global step 1100 Train loss 3.03 Classification-F1 0.024012158054711248 on epoch=78
05/29/2022 17:56:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.11 on epoch=79
05/29/2022 17:56:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.89 on epoch=79
05/29/2022 17:56:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.02 on epoch=80
05/29/2022 17:56:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.90 on epoch=81
05/29/2022 17:56:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.99 on epoch=82
05/29/2022 17:56:33 - INFO - __main__ - Global step 1150 Train loss 2.98 Classification-F1 0.03926738212577846 on epoch=82
05/29/2022 17:56:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.03 on epoch=82
05/29/2022 17:56:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.01 on epoch=83
05/29/2022 17:56:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.92 on epoch=84
05/29/2022 17:56:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.85 on epoch=84
05/29/2022 17:56:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.08 on epoch=85
05/29/2022 17:56:41 - INFO - __main__ - Global step 1200 Train loss 2.98 Classification-F1 0.05591070884161431 on epoch=85
05/29/2022 17:56:41 - INFO - __main__ - Saving model with best Classification-F1: 0.03988684582743989 -> 0.05591070884161431 on epoch=85, global_step=1200
05/29/2022 17:56:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.97 on epoch=86
05/29/2022 17:56:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.03 on epoch=87
05/29/2022 17:56:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.75 on epoch=87
05/29/2022 17:56:46 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.93 on epoch=88
05/29/2022 17:56:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.01 on epoch=89
05/29/2022 17:56:49 - INFO - __main__ - Global step 1250 Train loss 2.94 Classification-F1 0.012645502645502646 on epoch=89
05/29/2022 17:56:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.85 on epoch=89
05/29/2022 17:56:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.98 on epoch=90
05/29/2022 17:56:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.78 on epoch=91
05/29/2022 17:56:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.84 on epoch=92
05/29/2022 17:56:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.96 on epoch=92
05/29/2022 17:56:57 - INFO - __main__ - Global step 1300 Train loss 2.88 Classification-F1 0.02854864433811802 on epoch=92
05/29/2022 17:56:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.72 on epoch=93
05/29/2022 17:57:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.87 on epoch=94
05/29/2022 17:57:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.80 on epoch=94
05/29/2022 17:57:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.93 on epoch=95
05/29/2022 17:57:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.77 on epoch=96
05/29/2022 17:57:05 - INFO - __main__ - Global step 1350 Train loss 2.82 Classification-F1 0.0503467087318019 on epoch=96
05/29/2022 17:57:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.79 on epoch=97
05/29/2022 17:57:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.81 on epoch=97
05/29/2022 17:57:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.51 on epoch=98
05/29/2022 17:57:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.80 on epoch=99
05/29/2022 17:57:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.60 on epoch=99
05/29/2022 17:57:13 - INFO - __main__ - Global step 1400 Train loss 2.70 Classification-F1 0.05899651301474002 on epoch=99
05/29/2022 17:57:13 - INFO - __main__ - Saving model with best Classification-F1: 0.05591070884161431 -> 0.05899651301474002 on epoch=99, global_step=1400
05/29/2022 17:57:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.79 on epoch=100
05/29/2022 17:57:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.70 on epoch=101
05/29/2022 17:57:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.68 on epoch=102
05/29/2022 17:57:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.83 on epoch=102
05/29/2022 17:57:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.62 on epoch=103
05/29/2022 17:57:21 - INFO - __main__ - Global step 1450 Train loss 2.72 Classification-F1 0.06075578556781564 on epoch=103
05/29/2022 17:57:21 - INFO - __main__ - Saving model with best Classification-F1: 0.05899651301474002 -> 0.06075578556781564 on epoch=103, global_step=1450
05/29/2022 17:57:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.81 on epoch=104
05/29/2022 17:57:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.69 on epoch=104
05/29/2022 17:57:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.90 on epoch=105
05/29/2022 17:57:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.69 on epoch=106
05/29/2022 17:57:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.59 on epoch=107
05/29/2022 17:57:29 - INFO - __main__ - Global step 1500 Train loss 2.74 Classification-F1 0.06039103118789736 on epoch=107
05/29/2022 17:57:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.90 on epoch=107
05/29/2022 17:57:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.76 on epoch=108
05/29/2022 17:57:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.89 on epoch=109
05/29/2022 17:57:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.84 on epoch=109
05/29/2022 17:57:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.79 on epoch=110
05/29/2022 17:57:37 - INFO - __main__ - Global step 1550 Train loss 2.84 Classification-F1 0.045434429746823636 on epoch=110
05/29/2022 17:57:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.68 on epoch=111
05/29/2022 17:57:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.71 on epoch=112
05/29/2022 17:57:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.86 on epoch=112
05/29/2022 17:57:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.85 on epoch=113
05/29/2022 17:57:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.91 on epoch=114
05/29/2022 17:57:45 - INFO - __main__ - Global step 1600 Train loss 2.80 Classification-F1 0.034115464367565206 on epoch=114
05/29/2022 17:57:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.70 on epoch=114
05/29/2022 17:57:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.90 on epoch=115
05/29/2022 17:57:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.69 on epoch=116
05/29/2022 17:57:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.66 on epoch=117
05/29/2022 17:57:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.70 on epoch=117
05/29/2022 17:57:53 - INFO - __main__ - Global step 1650 Train loss 2.73 Classification-F1 0.05213988549536723 on epoch=117
05/29/2022 17:57:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.69 on epoch=118
05/29/2022 17:57:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.78 on epoch=119
05/29/2022 17:57:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.75 on epoch=119
05/29/2022 17:57:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.76 on epoch=120
05/29/2022 17:57:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.61 on epoch=121
05/29/2022 17:58:01 - INFO - __main__ - Global step 1700 Train loss 2.72 Classification-F1 0.04008525852585259 on epoch=121
05/29/2022 17:58:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.55 on epoch=122
05/29/2022 17:58:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.66 on epoch=122
05/29/2022 17:58:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.66 on epoch=123
05/29/2022 17:58:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.77 on epoch=124
05/29/2022 17:58:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.62 on epoch=124
05/29/2022 17:58:09 - INFO - __main__ - Global step 1750 Train loss 2.65 Classification-F1 0.03936439147706753 on epoch=124
05/29/2022 17:58:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.57 on epoch=125
05/29/2022 17:58:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.57 on epoch=126
05/29/2022 17:58:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.69 on epoch=127
05/29/2022 17:58:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.64 on epoch=127
05/29/2022 17:58:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.63 on epoch=128
05/29/2022 17:58:18 - INFO - __main__ - Global step 1800 Train loss 2.62 Classification-F1 0.04099675712578939 on epoch=128
05/29/2022 17:58:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.63 on epoch=129
05/29/2022 17:58:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.57 on epoch=129
05/29/2022 17:58:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.79 on epoch=130
05/29/2022 17:58:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.49 on epoch=131
05/29/2022 17:58:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.43 on epoch=132
05/29/2022 17:58:26 - INFO - __main__ - Global step 1850 Train loss 2.58 Classification-F1 0.06432599621454112 on epoch=132
05/29/2022 17:58:26 - INFO - __main__ - Saving model with best Classification-F1: 0.06075578556781564 -> 0.06432599621454112 on epoch=132, global_step=1850
05/29/2022 17:58:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.60 on epoch=132
05/29/2022 17:58:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.45 on epoch=133
05/29/2022 17:58:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.55 on epoch=134
05/29/2022 17:58:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.42 on epoch=134
05/29/2022 17:58:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.60 on epoch=135
05/29/2022 17:58:34 - INFO - __main__ - Global step 1900 Train loss 2.52 Classification-F1 0.06273607345035916 on epoch=135
05/29/2022 17:58:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.51 on epoch=136
05/29/2022 17:58:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.50 on epoch=137
05/29/2022 17:58:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.52 on epoch=137
05/29/2022 17:58:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.44 on epoch=138
05/29/2022 17:58:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.53 on epoch=139
05/29/2022 17:58:42 - INFO - __main__ - Global step 1950 Train loss 2.50 Classification-F1 0.07868985103654184 on epoch=139
05/29/2022 17:58:42 - INFO - __main__ - Saving model with best Classification-F1: 0.06432599621454112 -> 0.07868985103654184 on epoch=139, global_step=1950
05/29/2022 17:58:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.38 on epoch=139
05/29/2022 17:58:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.52 on epoch=140
05/29/2022 17:58:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.42 on epoch=141
05/29/2022 17:58:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.49 on epoch=142
05/29/2022 17:58:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.58 on epoch=142
05/29/2022 17:58:50 - INFO - __main__ - Global step 2000 Train loss 2.48 Classification-F1 0.03327922077922078 on epoch=142
05/29/2022 17:58:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.38 on epoch=143
05/29/2022 17:58:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.49 on epoch=144
05/29/2022 17:58:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.38 on epoch=144
05/29/2022 17:58:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.39 on epoch=145
05/29/2022 17:58:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.35 on epoch=146
05/29/2022 17:58:58 - INFO - __main__ - Global step 2050 Train loss 2.40 Classification-F1 0.03295707407856941 on epoch=146
05/29/2022 17:58:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.41 on epoch=147
05/29/2022 17:59:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.26 on epoch=147
05/29/2022 17:59:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.22 on epoch=148
05/29/2022 17:59:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.52 on epoch=149
05/29/2022 17:59:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.41 on epoch=149
05/29/2022 17:59:06 - INFO - __main__ - Global step 2100 Train loss 2.37 Classification-F1 0.03571428571428571 on epoch=149
05/29/2022 17:59:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.41 on epoch=150
05/29/2022 17:59:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.30 on epoch=151
05/29/2022 17:59:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.30 on epoch=152
05/29/2022 17:59:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.51 on epoch=152
05/29/2022 17:59:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.42 on epoch=153
05/29/2022 17:59:14 - INFO - __main__ - Global step 2150 Train loss 2.39 Classification-F1 0.056014266171584906 on epoch=153
05/29/2022 17:59:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.42 on epoch=154
05/29/2022 17:59:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.32 on epoch=154
05/29/2022 17:59:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.45 on epoch=155
05/29/2022 17:59:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.13 on epoch=156
05/29/2022 17:59:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.20 on epoch=157
05/29/2022 17:59:22 - INFO - __main__ - Global step 2200 Train loss 2.30 Classification-F1 0.021790041747276247 on epoch=157
05/29/2022 17:59:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.33 on epoch=157
05/29/2022 17:59:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.31 on epoch=158
05/29/2022 17:59:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.29 on epoch=159
05/29/2022 17:59:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.39 on epoch=159
05/29/2022 17:59:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.28 on epoch=160
05/29/2022 17:59:30 - INFO - __main__ - Global step 2250 Train loss 2.32 Classification-F1 0.08729050081403379 on epoch=160
05/29/2022 17:59:30 - INFO - __main__ - Saving model with best Classification-F1: 0.07868985103654184 -> 0.08729050081403379 on epoch=160, global_step=2250
05/29/2022 17:59:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.26 on epoch=161
05/29/2022 17:59:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.31 on epoch=162
05/29/2022 17:59:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.33 on epoch=162
05/29/2022 17:59:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.30 on epoch=163
05/29/2022 17:59:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.23 on epoch=164
05/29/2022 17:59:38 - INFO - __main__ - Global step 2300 Train loss 2.28 Classification-F1 0.027275864232385972 on epoch=164
05/29/2022 17:59:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.14 on epoch=164
05/29/2022 17:59:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.33 on epoch=165
05/29/2022 17:59:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.25 on epoch=166
05/29/2022 17:59:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.26 on epoch=167
05/29/2022 17:59:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.31 on epoch=167
05/29/2022 17:59:46 - INFO - __main__ - Global step 2350 Train loss 2.26 Classification-F1 0.025114283467927625 on epoch=167
05/29/2022 17:59:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.08 on epoch=168
05/29/2022 17:59:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.14 on epoch=169
05/29/2022 17:59:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.07 on epoch=169
05/29/2022 17:59:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.19 on epoch=170
05/29/2022 17:59:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.17 on epoch=171
05/29/2022 17:59:55 - INFO - __main__ - Global step 2400 Train loss 2.13 Classification-F1 0.11498029508593534 on epoch=171
05/29/2022 17:59:55 - INFO - __main__ - Saving model with best Classification-F1: 0.08729050081403379 -> 0.11498029508593534 on epoch=171, global_step=2400
05/29/2022 17:59:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.19 on epoch=172
05/29/2022 17:59:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.16 on epoch=172
05/29/2022 17:59:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.07 on epoch=173
05/29/2022 18:00:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.11 on epoch=174
05/29/2022 18:00:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.02 on epoch=174
05/29/2022 18:00:03 - INFO - __main__ - Global step 2450 Train loss 2.11 Classification-F1 0.05520253017161674 on epoch=174
05/29/2022 18:00:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.25 on epoch=175
05/29/2022 18:00:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.03 on epoch=176
05/29/2022 18:00:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.01 on epoch=177
05/29/2022 18:00:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.14 on epoch=177
05/29/2022 18:00:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.10 on epoch=178
05/29/2022 18:00:11 - INFO - __main__ - Global step 2500 Train loss 2.10 Classification-F1 0.07884223923683185 on epoch=178
05/29/2022 18:00:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.04 on epoch=179
05/29/2022 18:00:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.06 on epoch=179
05/29/2022 18:00:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.07 on epoch=180
05/29/2022 18:00:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.98 on epoch=181
05/29/2022 18:00:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.18 on epoch=182
05/29/2022 18:00:19 - INFO - __main__ - Global step 2550 Train loss 2.07 Classification-F1 0.07902730984867065 on epoch=182
05/29/2022 18:00:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.02 on epoch=182
05/29/2022 18:00:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.01 on epoch=183
05/29/2022 18:00:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.03 on epoch=184
05/29/2022 18:00:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.06 on epoch=184
05/29/2022 18:00:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.09 on epoch=185
05/29/2022 18:00:27 - INFO - __main__ - Global step 2600 Train loss 2.04 Classification-F1 0.038448712818460726 on epoch=185
05/29/2022 18:00:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.95 on epoch=186
05/29/2022 18:00:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.94 on epoch=187
05/29/2022 18:00:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.92 on epoch=187
05/29/2022 18:00:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.97 on epoch=188
05/29/2022 18:00:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.04 on epoch=189
05/29/2022 18:00:36 - INFO - __main__ - Global step 2650 Train loss 1.97 Classification-F1 0.03574597540879706 on epoch=189
05/29/2022 18:00:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.90 on epoch=189
05/29/2022 18:00:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.04 on epoch=190
05/29/2022 18:00:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.03 on epoch=191
05/29/2022 18:00:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.03 on epoch=192
05/29/2022 18:00:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.87 on epoch=192
05/29/2022 18:00:44 - INFO - __main__ - Global step 2700 Train loss 1.97 Classification-F1 0.04159743338627463 on epoch=192
05/29/2022 18:00:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.89 on epoch=193
05/29/2022 18:00:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.01 on epoch=194
05/29/2022 18:00:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.88 on epoch=194
05/29/2022 18:00:49 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.01 on epoch=195
05/29/2022 18:00:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.69 on epoch=196
05/29/2022 18:00:52 - INFO - __main__ - Global step 2750 Train loss 1.90 Classification-F1 0.07502613948805328 on epoch=196
05/29/2022 18:00:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.94 on epoch=197
05/29/2022 18:00:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.92 on epoch=197
05/29/2022 18:00:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.96 on epoch=198
05/29/2022 18:00:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.68 on epoch=199
05/29/2022 18:00:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.71 on epoch=199
05/29/2022 18:01:00 - INFO - __main__ - Global step 2800 Train loss 1.84 Classification-F1 0.04879460556152286 on epoch=199
05/29/2022 18:01:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.92 on epoch=200
05/29/2022 18:01:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.89 on epoch=201
05/29/2022 18:01:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.75 on epoch=202
05/29/2022 18:01:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.68 on epoch=202
05/29/2022 18:01:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.98 on epoch=203
05/29/2022 18:01:08 - INFO - __main__ - Global step 2850 Train loss 1.84 Classification-F1 0.07830965417019801 on epoch=203
05/29/2022 18:01:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.71 on epoch=204
05/29/2022 18:01:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.70 on epoch=204
05/29/2022 18:01:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.68 on epoch=205
05/29/2022 18:01:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.88 on epoch=206
05/29/2022 18:01:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.85 on epoch=207
05/29/2022 18:01:16 - INFO - __main__ - Global step 2900 Train loss 1.77 Classification-F1 0.08540829098120564 on epoch=207
05/29/2022 18:01:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.75 on epoch=207
05/29/2022 18:01:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.66 on epoch=208
05/29/2022 18:01:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.77 on epoch=209
05/29/2022 18:01:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.83 on epoch=209
05/29/2022 18:01:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.83 on epoch=210
05/29/2022 18:01:24 - INFO - __main__ - Global step 2950 Train loss 1.77 Classification-F1 0.05729429231733379 on epoch=210
05/29/2022 18:01:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.82 on epoch=211
05/29/2022 18:01:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.73 on epoch=212
05/29/2022 18:01:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.65 on epoch=212
05/29/2022 18:01:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.65 on epoch=213
05/29/2022 18:01:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.71 on epoch=214
05/29/2022 18:01:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:01:31 - INFO - __main__ - Printing 3 examples
05/29/2022 18:01:31 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 18:01:31 - INFO - __main__ - ['Animal']
05/29/2022 18:01:31 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 18:01:31 - INFO - __main__ - ['Animal']
05/29/2022 18:01:31 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 18:01:31 - INFO - __main__ - ['Animal']
05/29/2022 18:01:31 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:01:31 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:01:32 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:01:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:01:32 - INFO - __main__ - Printing 3 examples
05/29/2022 18:01:32 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 18:01:32 - INFO - __main__ - ['Animal']
05/29/2022 18:01:32 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 18:01:32 - INFO - __main__ - ['Animal']
05/29/2022 18:01:32 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 18:01:32 - INFO - __main__ - ['Animal']
05/29/2022 18:01:32 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:01:32 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:01:32 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:01:33 - INFO - __main__ - Global step 3000 Train loss 1.71 Classification-F1 0.10399315101612874 on epoch=214
05/29/2022 18:01:33 - INFO - __main__ - save last model!
05/29/2022 18:01:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 18:01:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 18:01:33 - INFO - __main__ - Printing 3 examples
05/29/2022 18:01:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 18:01:33 - INFO - __main__ - ['Animal']
05/29/2022 18:01:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 18:01:33 - INFO - __main__ - ['Animal']
05/29/2022 18:01:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 18:01:33 - INFO - __main__ - ['Village']
05/29/2022 18:01:33 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:01:34 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:01:38 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 18:01:38 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:01:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:01:38 - INFO - __main__ - Starting training!
05/29/2022 18:02:22 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/29/2022 18:02:22 - INFO - __main__ - Classification-F1 on test data: 0.0803
05/29/2022 18:02:22 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.11498029508593534, test_performance=0.08025207598044115
05/29/2022 18:02:22 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/29/2022 18:02:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:02:23 - INFO - __main__ - Printing 3 examples
05/29/2022 18:02:23 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 18:02:23 - INFO - __main__ - ['Animal']
05/29/2022 18:02:23 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 18:02:23 - INFO - __main__ - ['Animal']
05/29/2022 18:02:23 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 18:02:23 - INFO - __main__ - ['Animal']
05/29/2022 18:02:23 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:02:23 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:02:23 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:02:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:02:23 - INFO - __main__ - Printing 3 examples
05/29/2022 18:02:23 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 18:02:23 - INFO - __main__ - ['Animal']
05/29/2022 18:02:23 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 18:02:23 - INFO - __main__ - ['Animal']
05/29/2022 18:02:23 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 18:02:23 - INFO - __main__ - ['Animal']
05/29/2022 18:02:23 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:02:24 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:02:24 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:02:29 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:02:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:02:29 - INFO - __main__ - Starting training!
05/29/2022 18:02:31 - INFO - __main__ - Step 10 Global step 10 Train loss 7.34 on epoch=0
05/29/2022 18:02:32 - INFO - __main__ - Step 20 Global step 20 Train loss 7.31 on epoch=1
05/29/2022 18:02:34 - INFO - __main__ - Step 30 Global step 30 Train loss 7.12 on epoch=2
05/29/2022 18:02:35 - INFO - __main__ - Step 40 Global step 40 Train loss 7.04 on epoch=2
05/29/2022 18:02:37 - INFO - __main__ - Step 50 Global step 50 Train loss 7.03 on epoch=3
05/29/2022 18:02:59 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/29/2022 18:02:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 18:03:00 - INFO - __main__ - Step 60 Global step 60 Train loss 6.63 on epoch=4
05/29/2022 18:03:02 - INFO - __main__ - Step 70 Global step 70 Train loss 6.95 on epoch=4
05/29/2022 18:03:03 - INFO - __main__ - Step 80 Global step 80 Train loss 6.78 on epoch=5
05/29/2022 18:03:05 - INFO - __main__ - Step 90 Global step 90 Train loss 6.72 on epoch=6
05/29/2022 18:03:06 - INFO - __main__ - Step 100 Global step 100 Train loss 6.57 on epoch=7
05/29/2022 18:04:01 - INFO - __main__ - Global step 100 Train loss 6.73 Classification-F1 0.0 on epoch=7
05/29/2022 18:04:02 - INFO - __main__ - Step 110 Global step 110 Train loss 6.53 on epoch=7
05/29/2022 18:04:03 - INFO - __main__ - Step 120 Global step 120 Train loss 6.48 on epoch=8
05/29/2022 18:04:05 - INFO - __main__ - Step 130 Global step 130 Train loss 6.39 on epoch=9
05/29/2022 18:04:06 - INFO - __main__ - Step 140 Global step 140 Train loss 6.45 on epoch=9
05/29/2022 18:04:07 - INFO - __main__ - Step 150 Global step 150 Train loss 6.37 on epoch=10
05/29/2022 18:04:41 - INFO - __main__ - Global step 150 Train loss 6.45 Classification-F1 0.0 on epoch=10
05/29/2022 18:04:42 - INFO - __main__ - Step 160 Global step 160 Train loss 6.39 on epoch=11
05/29/2022 18:04:43 - INFO - __main__ - Step 170 Global step 170 Train loss 6.15 on epoch=12
05/29/2022 18:04:45 - INFO - __main__ - Step 180 Global step 180 Train loss 6.09 on epoch=12
05/29/2022 18:04:46 - INFO - __main__ - Step 190 Global step 190 Train loss 6.24 on epoch=13
05/29/2022 18:04:47 - INFO - __main__ - Step 200 Global step 200 Train loss 6.02 on epoch=14
05/29/2022 18:05:17 - INFO - __main__ - Global step 200 Train loss 6.18 Classification-F1 0.0 on epoch=14
05/29/2022 18:05:18 - INFO - __main__ - Step 210 Global step 210 Train loss 6.26 on epoch=14
05/29/2022 18:05:20 - INFO - __main__ - Step 220 Global step 220 Train loss 6.20 on epoch=15
05/29/2022 18:05:21 - INFO - __main__ - Step 230 Global step 230 Train loss 6.08 on epoch=16
05/29/2022 18:05:22 - INFO - __main__ - Step 240 Global step 240 Train loss 5.89 on epoch=17
05/29/2022 18:05:23 - INFO - __main__ - Step 250 Global step 250 Train loss 5.94 on epoch=17
05/29/2022 18:06:18 - INFO - __main__ - Global step 250 Train loss 6.07 Classification-F1 0.0 on epoch=17
05/29/2022 18:06:19 - INFO - __main__ - Step 260 Global step 260 Train loss 5.95 on epoch=18
05/29/2022 18:06:21 - INFO - __main__ - Step 270 Global step 270 Train loss 5.73 on epoch=19
05/29/2022 18:06:22 - INFO - __main__ - Step 280 Global step 280 Train loss 5.78 on epoch=19
05/29/2022 18:06:23 - INFO - __main__ - Step 290 Global step 290 Train loss 5.74 on epoch=20
05/29/2022 18:06:24 - INFO - __main__ - Step 300 Global step 300 Train loss 5.59 on epoch=21
05/29/2022 18:06:59 - INFO - __main__ - Global step 300 Train loss 5.76 Classification-F1 0.0 on epoch=21
05/29/2022 18:07:00 - INFO - __main__ - Step 310 Global step 310 Train loss 5.58 on epoch=22
05/29/2022 18:07:01 - INFO - __main__ - Step 320 Global step 320 Train loss 5.66 on epoch=22
05/29/2022 18:07:03 - INFO - __main__ - Step 330 Global step 330 Train loss 5.60 on epoch=23
05/29/2022 18:07:04 - INFO - __main__ - Step 340 Global step 340 Train loss 5.46 on epoch=24
05/29/2022 18:07:05 - INFO - __main__ - Step 350 Global step 350 Train loss 5.70 on epoch=24
05/29/2022 18:07:44 - INFO - __main__ - Global step 350 Train loss 5.60 Classification-F1 0.0 on epoch=24
05/29/2022 18:07:45 - INFO - __main__ - Step 360 Global step 360 Train loss 5.53 on epoch=25
05/29/2022 18:07:46 - INFO - __main__ - Step 370 Global step 370 Train loss 5.51 on epoch=26
05/29/2022 18:07:47 - INFO - __main__ - Step 380 Global step 380 Train loss 5.45 on epoch=27
05/29/2022 18:07:49 - INFO - __main__ - Step 390 Global step 390 Train loss 5.47 on epoch=27
05/29/2022 18:07:50 - INFO - __main__ - Step 400 Global step 400 Train loss 5.40 on epoch=28
05/29/2022 18:08:01 - INFO - __main__ - Global step 400 Train loss 5.47 Classification-F1 0.0 on epoch=28
05/29/2022 18:08:02 - INFO - __main__ - Step 410 Global step 410 Train loss 5.40 on epoch=29
05/29/2022 18:08:04 - INFO - __main__ - Step 420 Global step 420 Train loss 5.23 on epoch=29
05/29/2022 18:08:05 - INFO - __main__ - Step 430 Global step 430 Train loss 5.28 on epoch=30
05/29/2022 18:08:06 - INFO - __main__ - Step 440 Global step 440 Train loss 5.34 on epoch=31
05/29/2022 18:08:07 - INFO - __main__ - Step 450 Global step 450 Train loss 5.18 on epoch=32
05/29/2022 18:08:20 - INFO - __main__ - Global step 450 Train loss 5.28 Classification-F1 0.0 on epoch=32
05/29/2022 18:08:22 - INFO - __main__ - Step 460 Global step 460 Train loss 5.28 on epoch=32
05/29/2022 18:08:23 - INFO - __main__ - Step 470 Global step 470 Train loss 5.14 on epoch=33
05/29/2022 18:08:24 - INFO - __main__ - Step 480 Global step 480 Train loss 5.04 on epoch=34
05/29/2022 18:08:25 - INFO - __main__ - Step 490 Global step 490 Train loss 5.14 on epoch=34
05/29/2022 18:08:27 - INFO - __main__ - Step 500 Global step 500 Train loss 5.21 on epoch=35
05/29/2022 18:08:35 - INFO - __main__ - Global step 500 Train loss 5.16 Classification-F1 0.0 on epoch=35
05/29/2022 18:08:36 - INFO - __main__ - Step 510 Global step 510 Train loss 5.03 on epoch=36
05/29/2022 18:08:37 - INFO - __main__ - Step 520 Global step 520 Train loss 4.89 on epoch=37
05/29/2022 18:08:38 - INFO - __main__ - Step 530 Global step 530 Train loss 5.06 on epoch=37
05/29/2022 18:08:40 - INFO - __main__ - Step 540 Global step 540 Train loss 4.91 on epoch=38
05/29/2022 18:08:41 - INFO - __main__ - Step 550 Global step 550 Train loss 5.00 on epoch=39
05/29/2022 18:08:44 - INFO - __main__ - Global step 550 Train loss 4.98 Classification-F1 0.004166666666666667 on epoch=39
05/29/2022 18:08:44 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.004166666666666667 on epoch=39, global_step=550
05/29/2022 18:08:45 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/29/2022 18:08:46 - INFO - __main__ - Step 570 Global step 570 Train loss 4.90 on epoch=40
05/29/2022 18:08:47 - INFO - __main__ - Step 580 Global step 580 Train loss 4.81 on epoch=41
05/29/2022 18:08:49 - INFO - __main__ - Step 590 Global step 590 Train loss 4.81 on epoch=42
05/29/2022 18:08:50 - INFO - __main__ - Step 600 Global step 600 Train loss 4.78 on epoch=42
05/29/2022 18:08:52 - INFO - __main__ - Global step 600 Train loss 4.88 Classification-F1 0.010912698412698416 on epoch=42
05/29/2022 18:08:52 - INFO - __main__ - Saving model with best Classification-F1: 0.004166666666666667 -> 0.010912698412698416 on epoch=42, global_step=600
05/29/2022 18:08:54 - INFO - __main__ - Step 610 Global step 610 Train loss 4.85 on epoch=43
05/29/2022 18:08:55 - INFO - __main__ - Step 620 Global step 620 Train loss 4.66 on epoch=44
05/29/2022 18:08:56 - INFO - __main__ - Step 630 Global step 630 Train loss 4.94 on epoch=44
05/29/2022 18:08:57 - INFO - __main__ - Step 640 Global step 640 Train loss 4.66 on epoch=45
05/29/2022 18:08:59 - INFO - __main__ - Step 650 Global step 650 Train loss 4.70 on epoch=46
05/29/2022 18:09:01 - INFO - __main__ - Global step 650 Train loss 4.76 Classification-F1 0.007352941176470588 on epoch=46
05/29/2022 18:09:02 - INFO - __main__ - Step 660 Global step 660 Train loss 4.61 on epoch=47
05/29/2022 18:09:04 - INFO - __main__ - Step 670 Global step 670 Train loss 4.68 on epoch=47
05/29/2022 18:09:05 - INFO - __main__ - Step 680 Global step 680 Train loss 4.60 on epoch=48
05/29/2022 18:09:06 - INFO - __main__ - Step 690 Global step 690 Train loss 4.43 on epoch=49
05/29/2022 18:09:07 - INFO - __main__ - Step 700 Global step 700 Train loss 4.56 on epoch=49
05/29/2022 18:09:10 - INFO - __main__ - Global step 700 Train loss 4.58 Classification-F1 0.00903954802259887 on epoch=49
05/29/2022 18:09:11 - INFO - __main__ - Step 710 Global step 710 Train loss 4.55 on epoch=50
05/29/2022 18:09:12 - INFO - __main__ - Step 720 Global step 720 Train loss 4.33 on epoch=51
05/29/2022 18:09:13 - INFO - __main__ - Step 730 Global step 730 Train loss 4.45 on epoch=52
05/29/2022 18:09:15 - INFO - __main__ - Step 740 Global step 740 Train loss 4.42 on epoch=52
05/29/2022 18:09:16 - INFO - __main__ - Step 750 Global step 750 Train loss 4.34 on epoch=53
05/29/2022 18:09:18 - INFO - __main__ - Global step 750 Train loss 4.42 Classification-F1 0.00892608089260809 on epoch=53
05/29/2022 18:09:20 - INFO - __main__ - Step 760 Global step 760 Train loss 4.43 on epoch=54
05/29/2022 18:09:21 - INFO - __main__ - Step 770 Global step 770 Train loss 4.29 on epoch=54
05/29/2022 18:09:22 - INFO - __main__ - Step 780 Global step 780 Train loss 4.28 on epoch=55
05/29/2022 18:09:23 - INFO - __main__ - Step 790 Global step 790 Train loss 4.22 on epoch=56
05/29/2022 18:09:25 - INFO - __main__ - Step 800 Global step 800 Train loss 4.15 on epoch=57
05/29/2022 18:09:27 - INFO - __main__ - Global step 800 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 18:09:28 - INFO - __main__ - Step 810 Global step 810 Train loss 4.24 on epoch=57
05/29/2022 18:09:29 - INFO - __main__ - Step 820 Global step 820 Train loss 4.05 on epoch=58
05/29/2022 18:09:30 - INFO - __main__ - Step 830 Global step 830 Train loss 4.15 on epoch=59
05/29/2022 18:09:32 - INFO - __main__ - Step 840 Global step 840 Train loss 4.00 on epoch=59
05/29/2022 18:09:33 - INFO - __main__ - Step 850 Global step 850 Train loss 4.05 on epoch=60
05/29/2022 18:09:35 - INFO - __main__ - Global step 850 Train loss 4.10 Classification-F1 0.009523809523809523 on epoch=60
05/29/2022 18:09:36 - INFO - __main__ - Step 860 Global step 860 Train loss 4.00 on epoch=61
05/29/2022 18:09:37 - INFO - __main__ - Step 870 Global step 870 Train loss 3.88 on epoch=62
05/29/2022 18:09:38 - INFO - __main__ - Step 880 Global step 880 Train loss 3.88 on epoch=62
05/29/2022 18:09:40 - INFO - __main__ - Step 890 Global step 890 Train loss 3.89 on epoch=63
05/29/2022 18:09:41 - INFO - __main__ - Step 900 Global step 900 Train loss 3.95 on epoch=64
05/29/2022 18:09:43 - INFO - __main__ - Global step 900 Train loss 3.92 Classification-F1 0.009523809523809523 on epoch=64
05/29/2022 18:09:44 - INFO - __main__ - Step 910 Global step 910 Train loss 3.87 on epoch=64
05/29/2022 18:09:45 - INFO - __main__ - Step 920 Global step 920 Train loss 3.96 on epoch=65
05/29/2022 18:09:47 - INFO - __main__ - Step 930 Global step 930 Train loss 3.76 on epoch=66
05/29/2022 18:09:48 - INFO - __main__ - Step 940 Global step 940 Train loss 3.61 on epoch=67
05/29/2022 18:09:49 - INFO - __main__ - Step 950 Global step 950 Train loss 3.79 on epoch=67
05/29/2022 18:09:51 - INFO - __main__ - Global step 950 Train loss 3.80 Classification-F1 0.019513819513819513 on epoch=67
05/29/2022 18:09:51 - INFO - __main__ - Saving model with best Classification-F1: 0.010912698412698416 -> 0.019513819513819513 on epoch=67, global_step=950
05/29/2022 18:09:52 - INFO - __main__ - Step 960 Global step 960 Train loss 3.62 on epoch=68
05/29/2022 18:09:53 - INFO - __main__ - Step 970 Global step 970 Train loss 3.70 on epoch=69
05/29/2022 18:09:55 - INFO - __main__ - Step 980 Global step 980 Train loss 3.75 on epoch=69
05/29/2022 18:09:56 - INFO - __main__ - Step 990 Global step 990 Train loss 3.81 on epoch=70
05/29/2022 18:09:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.55 on epoch=71
05/29/2022 18:09:59 - INFO - __main__ - Global step 1000 Train loss 3.69 Classification-F1 0.02487557352826814 on epoch=71
05/29/2022 18:09:59 - INFO - __main__ - Saving model with best Classification-F1: 0.019513819513819513 -> 0.02487557352826814 on epoch=71, global_step=1000
05/29/2022 18:10:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.43 on epoch=72
05/29/2022 18:10:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.51 on epoch=72
05/29/2022 18:10:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.50 on epoch=73
05/29/2022 18:10:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.52 on epoch=74
05/29/2022 18:10:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.49 on epoch=74
05/29/2022 18:10:07 - INFO - __main__ - Global step 1050 Train loss 3.49 Classification-F1 0.029365079365079365 on epoch=74
05/29/2022 18:10:07 - INFO - __main__ - Saving model with best Classification-F1: 0.02487557352826814 -> 0.029365079365079365 on epoch=74, global_step=1050
05/29/2022 18:10:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.42 on epoch=75
05/29/2022 18:10:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.29 on epoch=76
05/29/2022 18:10:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.29 on epoch=77
05/29/2022 18:10:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.34 on epoch=77
05/29/2022 18:10:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.25 on epoch=78
05/29/2022 18:10:15 - INFO - __main__ - Global step 1100 Train loss 3.32 Classification-F1 0.029725376664152172 on epoch=78
05/29/2022 18:10:15 - INFO - __main__ - Saving model with best Classification-F1: 0.029365079365079365 -> 0.029725376664152172 on epoch=78, global_step=1100
05/29/2022 18:10:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.46 on epoch=79
05/29/2022 18:10:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.18 on epoch=79
05/29/2022 18:10:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.31 on epoch=80
05/29/2022 18:10:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.15 on epoch=81
05/29/2022 18:10:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.27 on epoch=82
05/29/2022 18:10:23 - INFO - __main__ - Global step 1150 Train loss 3.28 Classification-F1 0.05411477411477412 on epoch=82
05/29/2022 18:10:23 - INFO - __main__ - Saving model with best Classification-F1: 0.029725376664152172 -> 0.05411477411477412 on epoch=82, global_step=1150
05/29/2022 18:10:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.26 on epoch=82
05/29/2022 18:10:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.14 on epoch=83
05/29/2022 18:10:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.37 on epoch=84
05/29/2022 18:10:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.13 on epoch=84
05/29/2022 18:10:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.33 on epoch=85
05/29/2022 18:10:32 - INFO - __main__ - Global step 1200 Train loss 3.24 Classification-F1 0.03407632123584524 on epoch=85
05/29/2022 18:10:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.07 on epoch=86
05/29/2022 18:10:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.19 on epoch=87
05/29/2022 18:10:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.24 on epoch=87
05/29/2022 18:10:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.05 on epoch=88
05/29/2022 18:10:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.16 on epoch=89
05/29/2022 18:10:40 - INFO - __main__ - Global step 1250 Train loss 3.14 Classification-F1 0.009523809523809523 on epoch=89
05/29/2022 18:10:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.20 on epoch=89
05/29/2022 18:10:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.15 on epoch=90
05/29/2022 18:10:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.00 on epoch=91
05/29/2022 18:10:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.97 on epoch=92
05/29/2022 18:10:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.12 on epoch=92
05/29/2022 18:10:48 - INFO - __main__ - Global step 1300 Train loss 3.09 Classification-F1 0.025522521901082982 on epoch=92
05/29/2022 18:10:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.03 on epoch=93
05/29/2022 18:10:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.13 on epoch=94
05/29/2022 18:10:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.12 on epoch=94
05/29/2022 18:10:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.22 on epoch=95
05/29/2022 18:10:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.02 on epoch=96
05/29/2022 18:10:56 - INFO - __main__ - Global step 1350 Train loss 3.11 Classification-F1 0.03929584434002696 on epoch=96
05/29/2022 18:10:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.05 on epoch=97
05/29/2022 18:10:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.03 on epoch=97
05/29/2022 18:11:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.07 on epoch=98
05/29/2022 18:11:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.22 on epoch=99
05/29/2022 18:11:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.84 on epoch=99
05/29/2022 18:11:04 - INFO - __main__ - Global step 1400 Train loss 3.04 Classification-F1 0.04978446674098848 on epoch=99
05/29/2022 18:11:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.99 on epoch=100
05/29/2022 18:11:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.87 on epoch=101
05/29/2022 18:11:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.98 on epoch=102
05/29/2022 18:11:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.99 on epoch=102
05/29/2022 18:11:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.99 on epoch=103
05/29/2022 18:11:13 - INFO - __main__ - Global step 1450 Train loss 2.97 Classification-F1 0.04846696398715437 on epoch=103
05/29/2022 18:11:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.18 on epoch=104
05/29/2022 18:11:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.93 on epoch=104
05/29/2022 18:11:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.98 on epoch=105
05/29/2022 18:11:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.71 on epoch=106
05/29/2022 18:11:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.93 on epoch=107
05/29/2022 18:11:21 - INFO - __main__ - Global step 1500 Train loss 2.95 Classification-F1 0.08564914993196823 on epoch=107
05/29/2022 18:11:21 - INFO - __main__ - Saving model with best Classification-F1: 0.05411477411477412 -> 0.08564914993196823 on epoch=107, global_step=1500
05/29/2022 18:11:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.94 on epoch=107
05/29/2022 18:11:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.81 on epoch=108
05/29/2022 18:11:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.93 on epoch=109
05/29/2022 18:11:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.90 on epoch=109
05/29/2022 18:11:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.96 on epoch=110
05/29/2022 18:11:29 - INFO - __main__ - Global step 1550 Train loss 2.91 Classification-F1 0.07037050172601314 on epoch=110
05/29/2022 18:11:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.95 on epoch=111
05/29/2022 18:11:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.89 on epoch=112
05/29/2022 18:11:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.89 on epoch=112
05/29/2022 18:11:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.80 on epoch=113
05/29/2022 18:11:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.80 on epoch=114
05/29/2022 18:11:38 - INFO - __main__ - Global step 1600 Train loss 2.86 Classification-F1 0.05826422254269592 on epoch=114
05/29/2022 18:11:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.66 on epoch=114
05/29/2022 18:11:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.92 on epoch=115
05/29/2022 18:11:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.76 on epoch=116
05/29/2022 18:11:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.80 on epoch=117
05/29/2022 18:11:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.87 on epoch=117
05/29/2022 18:11:47 - INFO - __main__ - Global step 1650 Train loss 2.80 Classification-F1 0.025524530857245906 on epoch=117
05/29/2022 18:11:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.73 on epoch=118
05/29/2022 18:11:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.90 on epoch=119
05/29/2022 18:11:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.73 on epoch=119
05/29/2022 18:11:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.77 on epoch=120
05/29/2022 18:11:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.73 on epoch=121
05/29/2022 18:11:55 - INFO - __main__ - Global step 1700 Train loss 2.77 Classification-F1 0.00976800976800977 on epoch=121
05/29/2022 18:11:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.78 on epoch=122
05/29/2022 18:11:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.86 on epoch=122
05/29/2022 18:11:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.63 on epoch=123
05/29/2022 18:12:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.76 on epoch=124
05/29/2022 18:12:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.58 on epoch=124
05/29/2022 18:12:04 - INFO - __main__ - Global step 1750 Train loss 2.72 Classification-F1 0.01762173796072101 on epoch=124
05/29/2022 18:12:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.82 on epoch=125
05/29/2022 18:12:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.62 on epoch=126
05/29/2022 18:12:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.67 on epoch=127
05/29/2022 18:12:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.62 on epoch=127
05/29/2022 18:12:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.58 on epoch=128
05/29/2022 18:12:12 - INFO - __main__ - Global step 1800 Train loss 2.66 Classification-F1 0.023302308635023684 on epoch=128
05/29/2022 18:12:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.80 on epoch=129
05/29/2022 18:12:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.56 on epoch=129
05/29/2022 18:12:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.57 on epoch=130
05/29/2022 18:12:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.62 on epoch=131
05/29/2022 18:12:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.60 on epoch=132
05/29/2022 18:12:21 - INFO - __main__ - Global step 1850 Train loss 2.63 Classification-F1 0.043428293795023686 on epoch=132
05/29/2022 18:12:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.84 on epoch=132
05/29/2022 18:12:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.65 on epoch=133
05/29/2022 18:12:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.81 on epoch=134
05/29/2022 18:12:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.65 on epoch=134
05/29/2022 18:12:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.72 on epoch=135
05/29/2022 18:12:29 - INFO - __main__ - Global step 1900 Train loss 2.73 Classification-F1 0.06727584426591747 on epoch=135
05/29/2022 18:12:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.64 on epoch=136
05/29/2022 18:12:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.49 on epoch=137
05/29/2022 18:12:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.80 on epoch=137
05/29/2022 18:12:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.48 on epoch=138
05/29/2022 18:12:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.80 on epoch=139
05/29/2022 18:12:38 - INFO - __main__ - Global step 1950 Train loss 2.64 Classification-F1 0.06319981878900258 on epoch=139
05/29/2022 18:12:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.63 on epoch=139
05/29/2022 18:12:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.62 on epoch=140
05/29/2022 18:12:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.41 on epoch=141
05/29/2022 18:12:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.54 on epoch=142
05/29/2022 18:12:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.68 on epoch=142
05/29/2022 18:12:46 - INFO - __main__ - Global step 2000 Train loss 2.58 Classification-F1 0.04786390080507728 on epoch=142
05/29/2022 18:12:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.59 on epoch=143
05/29/2022 18:12:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.63 on epoch=144
05/29/2022 18:12:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.48 on epoch=144
05/29/2022 18:12:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.68 on epoch=145
05/29/2022 18:12:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.59 on epoch=146
05/29/2022 18:12:55 - INFO - __main__ - Global step 2050 Train loss 2.59 Classification-F1 0.06245020530734816 on epoch=146
05/29/2022 18:12:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.58 on epoch=147
05/29/2022 18:12:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.60 on epoch=147
05/29/2022 18:12:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.42 on epoch=148
05/29/2022 18:13:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.56 on epoch=149
05/29/2022 18:13:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.50 on epoch=149
05/29/2022 18:13:03 - INFO - __main__ - Global step 2100 Train loss 2.53 Classification-F1 0.05118303502926768 on epoch=149
05/29/2022 18:13:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.66 on epoch=150
05/29/2022 18:13:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.32 on epoch=151
05/29/2022 18:13:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.57 on epoch=152
05/29/2022 18:13:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.63 on epoch=152
05/29/2022 18:13:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.51 on epoch=153
05/29/2022 18:13:12 - INFO - __main__ - Global step 2150 Train loss 2.54 Classification-F1 0.09707065103769727 on epoch=153
05/29/2022 18:13:12 - INFO - __main__ - Saving model with best Classification-F1: 0.08564914993196823 -> 0.09707065103769727 on epoch=153, global_step=2150
05/29/2022 18:13:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.59 on epoch=154
05/29/2022 18:13:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.41 on epoch=154
05/29/2022 18:13:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.55 on epoch=155
05/29/2022 18:13:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.30 on epoch=156
05/29/2022 18:13:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.45 on epoch=157
05/29/2022 18:13:20 - INFO - __main__ - Global step 2200 Train loss 2.46 Classification-F1 0.05982916714960914 on epoch=157
05/29/2022 18:13:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.55 on epoch=157
05/29/2022 18:13:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.39 on epoch=158
05/29/2022 18:13:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.38 on epoch=159
05/29/2022 18:13:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.48 on epoch=159
05/29/2022 18:13:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.56 on epoch=160
05/29/2022 18:13:29 - INFO - __main__ - Global step 2250 Train loss 2.47 Classification-F1 0.10385655513247835 on epoch=160
05/29/2022 18:13:29 - INFO - __main__ - Saving model with best Classification-F1: 0.09707065103769727 -> 0.10385655513247835 on epoch=160, global_step=2250
05/29/2022 18:13:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.34 on epoch=161
05/29/2022 18:13:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.35 on epoch=162
05/29/2022 18:13:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.35 on epoch=162
05/29/2022 18:13:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.39 on epoch=163
05/29/2022 18:13:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.54 on epoch=164
05/29/2022 18:13:37 - INFO - __main__ - Global step 2300 Train loss 2.39 Classification-F1 0.08221492080322121 on epoch=164
05/29/2022 18:13:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.15 on epoch=164
05/29/2022 18:13:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.45 on epoch=165
05/29/2022 18:13:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.24 on epoch=166
05/29/2022 18:13:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.35 on epoch=167
05/29/2022 18:13:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.35 on epoch=167
05/29/2022 18:13:46 - INFO - __main__ - Global step 2350 Train loss 2.31 Classification-F1 0.07818671263237269 on epoch=167
05/29/2022 18:13:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.40 on epoch=168
05/29/2022 18:13:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.51 on epoch=169
05/29/2022 18:13:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.33 on epoch=169
05/29/2022 18:13:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.42 on epoch=170
05/29/2022 18:13:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.28 on epoch=171
05/29/2022 18:13:55 - INFO - __main__ - Global step 2400 Train loss 2.39 Classification-F1 0.10707891534243065 on epoch=171
05/29/2022 18:13:55 - INFO - __main__ - Saving model with best Classification-F1: 0.10385655513247835 -> 0.10707891534243065 on epoch=171, global_step=2400
05/29/2022 18:13:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.31 on epoch=172
05/29/2022 18:13:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.40 on epoch=172
05/29/2022 18:13:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.26 on epoch=173
05/29/2022 18:14:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.35 on epoch=174
05/29/2022 18:14:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.22 on epoch=174
05/29/2022 18:14:03 - INFO - __main__ - Global step 2450 Train loss 2.31 Classification-F1 0.05883116883116883 on epoch=174
05/29/2022 18:14:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.34 on epoch=175
05/29/2022 18:14:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.21 on epoch=176
05/29/2022 18:14:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.28 on epoch=177
05/29/2022 18:14:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.28 on epoch=177
05/29/2022 18:14:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.07 on epoch=178
05/29/2022 18:14:11 - INFO - __main__ - Global step 2500 Train loss 2.24 Classification-F1 0.09106216645207921 on epoch=178
05/29/2022 18:14:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.20 on epoch=179
05/29/2022 18:14:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.13 on epoch=179
05/29/2022 18:14:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.38 on epoch=180
05/29/2022 18:14:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.22 on epoch=181
05/29/2022 18:14:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.26 on epoch=182
05/29/2022 18:14:20 - INFO - __main__ - Global step 2550 Train loss 2.24 Classification-F1 0.06731175228712175 on epoch=182
05/29/2022 18:14:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.31 on epoch=182
05/29/2022 18:14:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.24 on epoch=183
05/29/2022 18:14:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.43 on epoch=184
05/29/2022 18:14:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.17 on epoch=184
05/29/2022 18:14:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.31 on epoch=185
05/29/2022 18:14:29 - INFO - __main__ - Global step 2600 Train loss 2.29 Classification-F1 0.07487822293792444 on epoch=185
05/29/2022 18:14:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.18 on epoch=186
05/29/2022 18:14:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.15 on epoch=187
05/29/2022 18:14:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.22 on epoch=187
05/29/2022 18:14:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.16 on epoch=188
05/29/2022 18:14:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.29 on epoch=189
05/29/2022 18:14:37 - INFO - __main__ - Global step 2650 Train loss 2.20 Classification-F1 0.06955624355005159 on epoch=189
05/29/2022 18:14:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.10 on epoch=189
05/29/2022 18:14:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.36 on epoch=190
05/29/2022 18:14:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.10 on epoch=191
05/29/2022 18:14:43 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.12 on epoch=192
05/29/2022 18:14:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.28 on epoch=192
05/29/2022 18:14:46 - INFO - __main__ - Global step 2700 Train loss 2.19 Classification-F1 0.0835267073862512 on epoch=192
05/29/2022 18:14:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.17 on epoch=193
05/29/2022 18:14:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.31 on epoch=194
05/29/2022 18:14:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.23 on epoch=194
05/29/2022 18:14:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.15 on epoch=195
05/29/2022 18:14:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.08 on epoch=196
05/29/2022 18:14:55 - INFO - __main__ - Global step 2750 Train loss 2.19 Classification-F1 0.06294671265491915 on epoch=196
05/29/2022 18:14:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.24 on epoch=197
05/29/2022 18:14:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.94 on epoch=197
05/29/2022 18:14:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.09 on epoch=198
05/29/2022 18:15:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.06 on epoch=199
05/29/2022 18:15:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.05 on epoch=199
05/29/2022 18:15:03 - INFO - __main__ - Global step 2800 Train loss 2.07 Classification-F1 0.07226724640931244 on epoch=199
05/29/2022 18:15:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.29 on epoch=200
05/29/2022 18:15:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.05 on epoch=201
05/29/2022 18:15:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.05 on epoch=202
05/29/2022 18:15:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.10 on epoch=202
05/29/2022 18:15:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.11 on epoch=203
05/29/2022 18:15:12 - INFO - __main__ - Global step 2850 Train loss 2.12 Classification-F1 0.1245345068987809 on epoch=203
05/29/2022 18:15:12 - INFO - __main__ - Saving model with best Classification-F1: 0.10707891534243065 -> 0.1245345068987809 on epoch=203, global_step=2850
05/29/2022 18:15:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.98 on epoch=204
05/29/2022 18:15:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.02 on epoch=204
05/29/2022 18:15:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.11 on epoch=205
05/29/2022 18:15:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.86 on epoch=206
05/29/2022 18:15:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.10 on epoch=207
05/29/2022 18:15:21 - INFO - __main__ - Global step 2900 Train loss 2.01 Classification-F1 0.0700057800898137 on epoch=207
05/29/2022 18:15:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.01 on epoch=207
05/29/2022 18:15:24 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.07 on epoch=208
05/29/2022 18:15:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.11 on epoch=209
05/29/2022 18:15:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.09 on epoch=209
05/29/2022 18:15:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.10 on epoch=210
05/29/2022 18:15:30 - INFO - __main__ - Global step 2950 Train loss 2.08 Classification-F1 0.11344172969559967 on epoch=210
05/29/2022 18:15:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.00 on epoch=211
05/29/2022 18:15:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.98 on epoch=212
05/29/2022 18:15:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.08 on epoch=212
05/29/2022 18:15:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.86 on epoch=213
05/29/2022 18:15:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.97 on epoch=214
05/29/2022 18:15:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:15:38 - INFO - __main__ - Printing 3 examples
05/29/2022 18:15:38 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 18:15:38 - INFO - __main__ - ['Animal']
05/29/2022 18:15:38 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 18:15:38 - INFO - __main__ - ['Animal']
05/29/2022 18:15:38 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 18:15:38 - INFO - __main__ - ['Animal']
05/29/2022 18:15:38 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:15:38 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:15:38 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:15:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:15:38 - INFO - __main__ - Printing 3 examples
05/29/2022 18:15:38 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 18:15:38 - INFO - __main__ - ['Animal']
05/29/2022 18:15:38 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 18:15:38 - INFO - __main__ - ['Animal']
05/29/2022 18:15:38 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 18:15:38 - INFO - __main__ - ['Animal']
05/29/2022 18:15:38 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:15:38 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:15:38 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:15:39 - INFO - __main__ - Global step 3000 Train loss 1.98 Classification-F1 0.11477437776457383 on epoch=214
05/29/2022 18:15:39 - INFO - __main__ - save last model!
05/29/2022 18:15:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 18:15:39 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 18:15:39 - INFO - __main__ - Printing 3 examples
05/29/2022 18:15:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 18:15:39 - INFO - __main__ - ['Animal']
05/29/2022 18:15:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 18:15:39 - INFO - __main__ - ['Animal']
05/29/2022 18:15:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 18:15:39 - INFO - __main__ - ['Village']
05/29/2022 18:15:39 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:15:41 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:15:44 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:15:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:15:44 - INFO - __main__ - Starting training!
05/29/2022 18:15:44 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 18:16:25 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/29/2022 18:16:25 - INFO - __main__ - Classification-F1 on test data: 0.1187
05/29/2022 18:16:26 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.1245345068987809, test_performance=0.1187355508716266
05/29/2022 18:16:26 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/29/2022 18:16:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:16:27 - INFO - __main__ - Printing 3 examples
05/29/2022 18:16:27 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/29/2022 18:16:27 - INFO - __main__ - ['Animal']
05/29/2022 18:16:27 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/29/2022 18:16:27 - INFO - __main__ - ['Animal']
05/29/2022 18:16:27 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/29/2022 18:16:27 - INFO - __main__ - ['Animal']
05/29/2022 18:16:27 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:16:27 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:16:27 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:16:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:16:27 - INFO - __main__ - Printing 3 examples
05/29/2022 18:16:27 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/29/2022 18:16:27 - INFO - __main__ - ['Animal']
05/29/2022 18:16:27 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/29/2022 18:16:27 - INFO - __main__ - ['Animal']
05/29/2022 18:16:27 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/29/2022 18:16:27 - INFO - __main__ - ['Animal']
05/29/2022 18:16:27 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:16:27 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:16:27 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:16:32 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:16:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:16:33 - INFO - __main__ - Starting training!
05/29/2022 18:16:34 - INFO - __main__ - Step 10 Global step 10 Train loss 7.32 on epoch=0
05/29/2022 18:16:36 - INFO - __main__ - Step 20 Global step 20 Train loss 7.28 on epoch=1
05/29/2022 18:16:37 - INFO - __main__ - Step 30 Global step 30 Train loss 7.17 on epoch=2
05/29/2022 18:16:38 - INFO - __main__ - Step 40 Global step 40 Train loss 7.08 on epoch=2
05/29/2022 18:16:39 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/29/2022 18:16:55 - INFO - __main__ - Global step 50 Train loss 7.18 Classification-F1 0.0 on epoch=3
05/29/2022 18:16:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 18:16:56 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/29/2022 18:16:57 - INFO - __main__ - Step 70 Global step 70 Train loss 7.07 on epoch=4
05/29/2022 18:16:58 - INFO - __main__ - Step 80 Global step 80 Train loss 6.81 on epoch=5
05/29/2022 18:16:59 - INFO - __main__ - Step 90 Global step 90 Train loss 6.80 on epoch=6
05/29/2022 18:17:01 - INFO - __main__ - Step 100 Global step 100 Train loss 6.53 on epoch=7
05/29/2022 18:17:47 - INFO - __main__ - Global step 100 Train loss 6.79 Classification-F1 0.0 on epoch=7
05/29/2022 18:17:48 - INFO - __main__ - Step 110 Global step 110 Train loss 6.64 on epoch=7
05/29/2022 18:17:49 - INFO - __main__ - Step 120 Global step 120 Train loss 6.59 on epoch=8
05/29/2022 18:17:50 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/29/2022 18:17:52 - INFO - __main__ - Step 140 Global step 140 Train loss 6.56 on epoch=9
05/29/2022 18:17:53 - INFO - __main__ - Step 150 Global step 150 Train loss 6.49 on epoch=10
05/29/2022 18:18:48 - INFO - __main__ - Global step 150 Train loss 6.53 Classification-F1 0.0 on epoch=10
05/29/2022 18:18:49 - INFO - __main__ - Step 160 Global step 160 Train loss 6.37 on epoch=11
05/29/2022 18:18:50 - INFO - __main__ - Step 170 Global step 170 Train loss 6.26 on epoch=12
05/29/2022 18:18:52 - INFO - __main__ - Step 180 Global step 180 Train loss 6.31 on epoch=12
05/29/2022 18:18:53 - INFO - __main__ - Step 190 Global step 190 Train loss 6.25 on epoch=13
05/29/2022 18:18:55 - INFO - __main__ - Step 200 Global step 200 Train loss 6.05 on epoch=14
05/29/2022 18:19:54 - INFO - __main__ - Global step 200 Train loss 6.25 Classification-F1 0.0 on epoch=14
05/29/2022 18:19:55 - INFO - __main__ - Step 210 Global step 210 Train loss 6.32 on epoch=14
05/29/2022 18:19:57 - INFO - __main__ - Step 220 Global step 220 Train loss 6.15 on epoch=15
05/29/2022 18:19:58 - INFO - __main__ - Step 230 Global step 230 Train loss 6.10 on epoch=16
05/29/2022 18:20:00 - INFO - __main__ - Step 240 Global step 240 Train loss 6.01 on epoch=17
05/29/2022 18:20:01 - INFO - __main__ - Step 250 Global step 250 Train loss 5.84 on epoch=17
05/29/2022 18:20:49 - INFO - __main__ - Global step 250 Train loss 6.09 Classification-F1 0.0 on epoch=17
05/29/2022 18:20:50 - INFO - __main__ - Step 260 Global step 260 Train loss 5.96 on epoch=18
05/29/2022 18:20:52 - INFO - __main__ - Step 270 Global step 270 Train loss 5.82 on epoch=19
05/29/2022 18:20:53 - INFO - __main__ - Step 280 Global step 280 Train loss 5.96 on epoch=19
05/29/2022 18:20:54 - INFO - __main__ - Step 290 Global step 290 Train loss 5.99 on epoch=20
05/29/2022 18:20:55 - INFO - __main__ - Step 300 Global step 300 Train loss 5.72 on epoch=21
05/29/2022 18:21:47 - INFO - __main__ - Global step 300 Train loss 5.89 Classification-F1 0.0 on epoch=21
05/29/2022 18:21:48 - INFO - __main__ - Step 310 Global step 310 Train loss 5.87 on epoch=22
05/29/2022 18:21:49 - INFO - __main__ - Step 320 Global step 320 Train loss 5.91 on epoch=22
05/29/2022 18:21:51 - INFO - __main__ - Step 330 Global step 330 Train loss 5.85 on epoch=23
05/29/2022 18:21:52 - INFO - __main__ - Step 340 Global step 340 Train loss 5.67 on epoch=24
05/29/2022 18:21:53 - INFO - __main__ - Step 350 Global step 350 Train loss 5.80 on epoch=24
05/29/2022 18:22:23 - INFO - __main__ - Global step 350 Train loss 5.82 Classification-F1 0.0 on epoch=24
05/29/2022 18:22:24 - INFO - __main__ - Step 360 Global step 360 Train loss 5.87 on epoch=25
05/29/2022 18:22:26 - INFO - __main__ - Step 370 Global step 370 Train loss 5.68 on epoch=26
05/29/2022 18:22:27 - INFO - __main__ - Step 380 Global step 380 Train loss 5.62 on epoch=27
05/29/2022 18:22:28 - INFO - __main__ - Step 390 Global step 390 Train loss 5.56 on epoch=27
05/29/2022 18:22:29 - INFO - __main__ - Step 400 Global step 400 Train loss 5.65 on epoch=28
05/29/2022 18:23:06 - INFO - __main__ - Global step 400 Train loss 5.68 Classification-F1 0.0 on epoch=28
05/29/2022 18:23:07 - INFO - __main__ - Step 410 Global step 410 Train loss 5.55 on epoch=29
05/29/2022 18:23:08 - INFO - __main__ - Step 420 Global step 420 Train loss 5.60 on epoch=29
05/29/2022 18:23:10 - INFO - __main__ - Step 430 Global step 430 Train loss 5.55 on epoch=30
05/29/2022 18:23:11 - INFO - __main__ - Step 440 Global step 440 Train loss 5.46 on epoch=31
05/29/2022 18:23:12 - INFO - __main__ - Step 450 Global step 450 Train loss 5.49 on epoch=32
05/29/2022 18:23:48 - INFO - __main__ - Global step 450 Train loss 5.53 Classification-F1 0.0 on epoch=32
05/29/2022 18:23:49 - INFO - __main__ - Step 460 Global step 460 Train loss 5.40 on epoch=32
05/29/2022 18:23:50 - INFO - __main__ - Step 470 Global step 470 Train loss 5.31 on epoch=33
05/29/2022 18:23:51 - INFO - __main__ - Step 480 Global step 480 Train loss 5.30 on epoch=34
05/29/2022 18:23:53 - INFO - __main__ - Step 490 Global step 490 Train loss 5.41 on epoch=34
05/29/2022 18:23:54 - INFO - __main__ - Step 500 Global step 500 Train loss 5.43 on epoch=35
05/29/2022 18:24:27 - INFO - __main__ - Global step 500 Train loss 5.37 Classification-F1 0.0 on epoch=35
05/29/2022 18:24:28 - INFO - __main__ - Step 510 Global step 510 Train loss 5.32 on epoch=36
05/29/2022 18:24:29 - INFO - __main__ - Step 520 Global step 520 Train loss 5.16 on epoch=37
05/29/2022 18:24:30 - INFO - __main__ - Step 530 Global step 530 Train loss 5.29 on epoch=37
05/29/2022 18:24:32 - INFO - __main__ - Step 540 Global step 540 Train loss 5.30 on epoch=38
05/29/2022 18:24:33 - INFO - __main__ - Step 550 Global step 550 Train loss 5.10 on epoch=39
05/29/2022 18:25:11 - INFO - __main__ - Global step 550 Train loss 5.24 Classification-F1 0.0 on epoch=39
05/29/2022 18:25:12 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/29/2022 18:25:13 - INFO - __main__ - Step 570 Global step 570 Train loss 5.13 on epoch=40
05/29/2022 18:25:15 - INFO - __main__ - Step 580 Global step 580 Train loss 5.19 on epoch=41
05/29/2022 18:25:16 - INFO - __main__ - Step 590 Global step 590 Train loss 4.99 on epoch=42
05/29/2022 18:25:17 - INFO - __main__ - Step 600 Global step 600 Train loss 5.05 on epoch=42
05/29/2022 18:25:21 - INFO - __main__ - Global step 600 Train loss 5.09 Classification-F1 0.0011305822498586774 on epoch=42
05/29/2022 18:25:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0011305822498586774 on epoch=42, global_step=600
05/29/2022 18:25:23 - INFO - __main__ - Step 610 Global step 610 Train loss 5.06 on epoch=43
05/29/2022 18:25:24 - INFO - __main__ - Step 620 Global step 620 Train loss 5.01 on epoch=44
05/29/2022 18:25:25 - INFO - __main__ - Step 630 Global step 630 Train loss 5.00 on epoch=44
05/29/2022 18:25:26 - INFO - __main__ - Step 640 Global step 640 Train loss 5.13 on epoch=45
05/29/2022 18:25:28 - INFO - __main__ - Step 650 Global step 650 Train loss 4.92 on epoch=46
05/29/2022 18:25:31 - INFO - __main__ - Global step 650 Train loss 5.02 Classification-F1 0.005887681159420291 on epoch=46
05/29/2022 18:25:31 - INFO - __main__ - Saving model with best Classification-F1: 0.0011305822498586774 -> 0.005887681159420291 on epoch=46, global_step=650
05/29/2022 18:25:32 - INFO - __main__ - Step 660 Global step 660 Train loss 4.86 on epoch=47
05/29/2022 18:25:33 - INFO - __main__ - Step 670 Global step 670 Train loss 4.80 on epoch=47
05/29/2022 18:25:34 - INFO - __main__ - Step 680 Global step 680 Train loss 4.85 on epoch=48
05/29/2022 18:25:36 - INFO - __main__ - Step 690 Global step 690 Train loss 4.76 on epoch=49
05/29/2022 18:25:37 - INFO - __main__ - Step 700 Global step 700 Train loss 4.90 on epoch=49
05/29/2022 18:25:39 - INFO - __main__ - Global step 700 Train loss 4.83 Classification-F1 0.007629947544110634 on epoch=49
05/29/2022 18:25:39 - INFO - __main__ - Saving model with best Classification-F1: 0.005887681159420291 -> 0.007629947544110634 on epoch=49, global_step=700
05/29/2022 18:25:41 - INFO - __main__ - Step 710 Global step 710 Train loss 4.86 on epoch=50
05/29/2022 18:25:42 - INFO - __main__ - Step 720 Global step 720 Train loss 4.79 on epoch=51
05/29/2022 18:25:43 - INFO - __main__ - Step 730 Global step 730 Train loss 4.71 on epoch=52
05/29/2022 18:25:44 - INFO - __main__ - Step 740 Global step 740 Train loss 4.82 on epoch=52
05/29/2022 18:25:46 - INFO - __main__ - Step 750 Global step 750 Train loss 4.77 on epoch=53
05/29/2022 18:25:48 - INFO - __main__ - Global step 750 Train loss 4.79 Classification-F1 0.009523809523809523 on epoch=53
05/29/2022 18:25:48 - INFO - __main__ - Saving model with best Classification-F1: 0.007629947544110634 -> 0.009523809523809523 on epoch=53, global_step=750
05/29/2022 18:25:49 - INFO - __main__ - Step 760 Global step 760 Train loss 4.77 on epoch=54
05/29/2022 18:25:50 - INFO - __main__ - Step 770 Global step 770 Train loss 4.86 on epoch=54
05/29/2022 18:25:52 - INFO - __main__ - Step 780 Global step 780 Train loss 4.68 on epoch=55
05/29/2022 18:25:53 - INFO - __main__ - Step 790 Global step 790 Train loss 4.62 on epoch=56
05/29/2022 18:25:54 - INFO - __main__ - Step 800 Global step 800 Train loss 4.63 on epoch=57
05/29/2022 18:25:57 - INFO - __main__ - Global step 800 Train loss 4.71 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 18:25:58 - INFO - __main__ - Step 810 Global step 810 Train loss 4.82 on epoch=57
05/29/2022 18:25:59 - INFO - __main__ - Step 820 Global step 820 Train loss 4.81 on epoch=58
05/29/2022 18:26:00 - INFO - __main__ - Step 830 Global step 830 Train loss 4.61 on epoch=59
05/29/2022 18:26:02 - INFO - __main__ - Step 840 Global step 840 Train loss 4.61 on epoch=59
05/29/2022 18:26:03 - INFO - __main__ - Step 850 Global step 850 Train loss 4.67 on epoch=60
05/29/2022 18:26:05 - INFO - __main__ - Global step 850 Train loss 4.71 Classification-F1 0.008438818565400845 on epoch=60
05/29/2022 18:26:07 - INFO - __main__ - Step 860 Global step 860 Train loss 4.56 on epoch=61
05/29/2022 18:26:08 - INFO - __main__ - Step 870 Global step 870 Train loss 4.61 on epoch=62
05/29/2022 18:26:09 - INFO - __main__ - Step 880 Global step 880 Train loss 4.58 on epoch=62
05/29/2022 18:26:10 - INFO - __main__ - Step 890 Global step 890 Train loss 4.46 on epoch=63
05/29/2022 18:26:12 - INFO - __main__ - Step 900 Global step 900 Train loss 4.52 on epoch=64
05/29/2022 18:26:14 - INFO - __main__ - Global step 900 Train loss 4.55 Classification-F1 0.009523809523809523 on epoch=64
05/29/2022 18:26:15 - INFO - __main__ - Step 910 Global step 910 Train loss 4.53 on epoch=64
05/29/2022 18:26:16 - INFO - __main__ - Step 920 Global step 920 Train loss 4.63 on epoch=65
05/29/2022 18:26:18 - INFO - __main__ - Step 930 Global step 930 Train loss 4.56 on epoch=66
05/29/2022 18:26:19 - INFO - __main__ - Step 940 Global step 940 Train loss 4.48 on epoch=67
05/29/2022 18:26:20 - INFO - __main__ - Step 950 Global step 950 Train loss 4.46 on epoch=67
05/29/2022 18:26:23 - INFO - __main__ - Global step 950 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=67
05/29/2022 18:26:24 - INFO - __main__ - Step 960 Global step 960 Train loss 4.43 on epoch=68
05/29/2022 18:26:25 - INFO - __main__ - Step 970 Global step 970 Train loss 4.49 on epoch=69
05/29/2022 18:26:27 - INFO - __main__ - Step 980 Global step 980 Train loss 4.48 on epoch=69
05/29/2022 18:26:28 - INFO - __main__ - Step 990 Global step 990 Train loss 4.42 on epoch=70
05/29/2022 18:26:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.26 on epoch=71
05/29/2022 18:26:31 - INFO - __main__ - Global step 1000 Train loss 4.42 Classification-F1 0.009523809523809523 on epoch=71
05/29/2022 18:26:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.31 on epoch=72
05/29/2022 18:26:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.35 on epoch=72
05/29/2022 18:26:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.28 on epoch=73
05/29/2022 18:26:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.38 on epoch=74
05/29/2022 18:26:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.17 on epoch=74
05/29/2022 18:26:39 - INFO - __main__ - Global step 1050 Train loss 4.30 Classification-F1 0.009523809523809523 on epoch=74
05/29/2022 18:26:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.31 on epoch=75
05/29/2022 18:26:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.21 on epoch=76
05/29/2022 18:26:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.18 on epoch=77
05/29/2022 18:26:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.20 on epoch=77
05/29/2022 18:26:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.15 on epoch=78
05/29/2022 18:26:47 - INFO - __main__ - Global step 1100 Train loss 4.21 Classification-F1 0.009523809523809523 on epoch=78
05/29/2022 18:26:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.11 on epoch=79
05/29/2022 18:26:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.23 on epoch=79
05/29/2022 18:26:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.18 on epoch=80
05/29/2022 18:26:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.09 on epoch=81
05/29/2022 18:26:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.99 on epoch=82
05/29/2022 18:26:56 - INFO - __main__ - Global step 1150 Train loss 4.12 Classification-F1 0.009523809523809523 on epoch=82
05/29/2022 18:26:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.01 on epoch=82
05/29/2022 18:26:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.09 on epoch=83
05/29/2022 18:26:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.11 on epoch=84
05/29/2022 18:27:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.93 on epoch=84
05/29/2022 18:27:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.02 on epoch=85
05/29/2022 18:27:04 - INFO - __main__ - Global step 1200 Train loss 4.03 Classification-F1 0.009523809523809523 on epoch=85
05/29/2022 18:27:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.84 on epoch=86
05/29/2022 18:27:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.89 on epoch=87
05/29/2022 18:27:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.01 on epoch=87
05/29/2022 18:27:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.76 on epoch=88
05/29/2022 18:27:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.93 on epoch=89
05/29/2022 18:27:12 - INFO - __main__ - Global step 1250 Train loss 3.89 Classification-F1 0.009523809523809523 on epoch=89
05/29/2022 18:27:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.75 on epoch=89
05/29/2022 18:27:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.81 on epoch=90
05/29/2022 18:27:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.77 on epoch=91
05/29/2022 18:27:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.71 on epoch=92
05/29/2022 18:27:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.91 on epoch=92
05/29/2022 18:27:20 - INFO - __main__ - Global step 1300 Train loss 3.79 Classification-F1 0.016529164857432336 on epoch=92
05/29/2022 18:27:20 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.016529164857432336 on epoch=92, global_step=1300
05/29/2022 18:27:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.72 on epoch=93
05/29/2022 18:27:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.93 on epoch=94
05/29/2022 18:27:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.75 on epoch=94
05/29/2022 18:27:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.70 on epoch=95
05/29/2022 18:27:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.56 on epoch=96
05/29/2022 18:27:28 - INFO - __main__ - Global step 1350 Train loss 3.73 Classification-F1 0.03280840955910984 on epoch=96
05/29/2022 18:27:28 - INFO - __main__ - Saving model with best Classification-F1: 0.016529164857432336 -> 0.03280840955910984 on epoch=96, global_step=1350
05/29/2022 18:27:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.58 on epoch=97
05/29/2022 18:27:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.68 on epoch=97
05/29/2022 18:27:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.69 on epoch=98
05/29/2022 18:27:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.60 on epoch=99
05/29/2022 18:27:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.56 on epoch=99
05/29/2022 18:27:36 - INFO - __main__ - Global step 1400 Train loss 3.62 Classification-F1 0.026693806269296183 on epoch=99
05/29/2022 18:27:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.60 on epoch=100
05/29/2022 18:27:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.58 on epoch=101
05/29/2022 18:27:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.62 on epoch=102
05/29/2022 18:27:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.70 on epoch=102
05/29/2022 18:27:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.55 on epoch=103
05/29/2022 18:27:44 - INFO - __main__ - Global step 1450 Train loss 3.61 Classification-F1 0.02290105231281702 on epoch=103
05/29/2022 18:27:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.51 on epoch=104
05/29/2022 18:27:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.61 on epoch=104
05/29/2022 18:27:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.53 on epoch=105
05/29/2022 18:27:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.37 on epoch=106
05/29/2022 18:27:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.43 on epoch=107
05/29/2022 18:27:52 - INFO - __main__ - Global step 1500 Train loss 3.49 Classification-F1 0.026546250684181722 on epoch=107
05/29/2022 18:27:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.52 on epoch=107
05/29/2022 18:27:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.43 on epoch=108
05/29/2022 18:27:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.36 on epoch=109
05/29/2022 18:27:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.41 on epoch=109
05/29/2022 18:27:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.56 on epoch=110
05/29/2022 18:28:01 - INFO - __main__ - Global step 1550 Train loss 3.46 Classification-F1 0.035238095238095235 on epoch=110
05/29/2022 18:28:01 - INFO - __main__ - Saving model with best Classification-F1: 0.03280840955910984 -> 0.035238095238095235 on epoch=110, global_step=1550
05/29/2022 18:28:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.35 on epoch=111
05/29/2022 18:28:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.43 on epoch=112
05/29/2022 18:28:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.39 on epoch=112
05/29/2022 18:28:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.37 on epoch=113
05/29/2022 18:28:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.51 on epoch=114
05/29/2022 18:28:09 - INFO - __main__ - Global step 1600 Train loss 3.41 Classification-F1 0.03236663086287146 on epoch=114
05/29/2022 18:28:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.37 on epoch=114
05/29/2022 18:28:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.43 on epoch=115
05/29/2022 18:28:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.08 on epoch=116
05/29/2022 18:28:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.24 on epoch=117
05/29/2022 18:28:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.38 on epoch=117
05/29/2022 18:28:17 - INFO - __main__ - Global step 1650 Train loss 3.30 Classification-F1 0.02875124542022761 on epoch=117
05/29/2022 18:28:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.14 on epoch=118
05/29/2022 18:28:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.39 on epoch=119
05/29/2022 18:28:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.17 on epoch=119
05/29/2022 18:28:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.29 on epoch=120
05/29/2022 18:28:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.04 on epoch=121
05/29/2022 18:28:25 - INFO - __main__ - Global step 1700 Train loss 3.21 Classification-F1 0.034864588037049685 on epoch=121
05/29/2022 18:28:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.21 on epoch=122
05/29/2022 18:28:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.37 on epoch=122
05/29/2022 18:28:28 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.24 on epoch=123
05/29/2022 18:28:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.22 on epoch=124
05/29/2022 18:28:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.14 on epoch=124
05/29/2022 18:28:33 - INFO - __main__ - Global step 1750 Train loss 3.23 Classification-F1 0.030305850644833692 on epoch=124
05/29/2022 18:28:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.18 on epoch=125
05/29/2022 18:28:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.15 on epoch=126
05/29/2022 18:28:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.14 on epoch=127
05/29/2022 18:28:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.07 on epoch=127
05/29/2022 18:28:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.16 on epoch=128
05/29/2022 18:28:41 - INFO - __main__ - Global step 1800 Train loss 3.14 Classification-F1 0.027354627354627355 on epoch=128
05/29/2022 18:28:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.20 on epoch=129
05/29/2022 18:28:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.06 on epoch=129
05/29/2022 18:28:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.13 on epoch=130
05/29/2022 18:28:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.07 on epoch=131
05/29/2022 18:28:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.12 on epoch=132
05/29/2022 18:28:49 - INFO - __main__ - Global step 1850 Train loss 3.12 Classification-F1 0.02105711849957374 on epoch=132
05/29/2022 18:28:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.32 on epoch=132
05/29/2022 18:28:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.11 on epoch=133
05/29/2022 18:28:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.10 on epoch=134
05/29/2022 18:28:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.06 on epoch=134
05/29/2022 18:28:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.29 on epoch=135
05/29/2022 18:28:57 - INFO - __main__ - Global step 1900 Train loss 3.17 Classification-F1 0.02007459412022817 on epoch=135
05/29/2022 18:28:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.15 on epoch=136
05/29/2022 18:29:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.20 on epoch=137
05/29/2022 18:29:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.08 on epoch=137
05/29/2022 18:29:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.04 on epoch=138
05/29/2022 18:29:03 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.26 on epoch=139
05/29/2022 18:29:05 - INFO - __main__ - Global step 1950 Train loss 3.15 Classification-F1 0.03648724566965637 on epoch=139
05/29/2022 18:29:05 - INFO - __main__ - Saving model with best Classification-F1: 0.035238095238095235 -> 0.03648724566965637 on epoch=139, global_step=1950
05/29/2022 18:29:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.19 on epoch=139
05/29/2022 18:29:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.10 on epoch=140
05/29/2022 18:29:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.96 on epoch=141
05/29/2022 18:29:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.98 on epoch=142
05/29/2022 18:29:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.16 on epoch=142
05/29/2022 18:29:14 - INFO - __main__ - Global step 2000 Train loss 3.08 Classification-F1 0.015692848897927776 on epoch=142
05/29/2022 18:29:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.04 on epoch=143
05/29/2022 18:29:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.11 on epoch=144
05/29/2022 18:29:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.85 on epoch=144
05/29/2022 18:29:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.15 on epoch=145
05/29/2022 18:29:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.95 on epoch=146
05/29/2022 18:29:22 - INFO - __main__ - Global step 2050 Train loss 3.02 Classification-F1 0.02801120448179272 on epoch=146
05/29/2022 18:29:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.93 on epoch=147
05/29/2022 18:29:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.03 on epoch=147
05/29/2022 18:29:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.89 on epoch=148
05/29/2022 18:29:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.04 on epoch=149
05/29/2022 18:29:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.84 on epoch=149
05/29/2022 18:29:30 - INFO - __main__ - Global step 2100 Train loss 2.94 Classification-F1 0.05282334260649523 on epoch=149
05/29/2022 18:29:30 - INFO - __main__ - Saving model with best Classification-F1: 0.03648724566965637 -> 0.05282334260649523 on epoch=149, global_step=2100
05/29/2022 18:29:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.10 on epoch=150
05/29/2022 18:29:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.04 on epoch=151
05/29/2022 18:29:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.11 on epoch=152
05/29/2022 18:29:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.11 on epoch=152
05/29/2022 18:29:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.93 on epoch=153
05/29/2022 18:29:38 - INFO - __main__ - Global step 2150 Train loss 3.06 Classification-F1 0.0335785055162676 on epoch=153
05/29/2022 18:29:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.07 on epoch=154
05/29/2022 18:29:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.82 on epoch=154
05/29/2022 18:29:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.06 on epoch=155
05/29/2022 18:29:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.82 on epoch=156
05/29/2022 18:29:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.08 on epoch=157
05/29/2022 18:29:46 - INFO - __main__ - Global step 2200 Train loss 2.97 Classification-F1 0.05222320668626014 on epoch=157
05/29/2022 18:29:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.09 on epoch=157
05/29/2022 18:29:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.00 on epoch=158
05/29/2022 18:29:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.95 on epoch=159
05/29/2022 18:29:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.78 on epoch=159
05/29/2022 18:29:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.88 on epoch=160
05/29/2022 18:29:54 - INFO - __main__ - Global step 2250 Train loss 2.94 Classification-F1 0.03360454275786084 on epoch=160
05/29/2022 18:29:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.92 on epoch=161
05/29/2022 18:29:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.81 on epoch=162
05/29/2022 18:29:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.94 on epoch=162
05/29/2022 18:29:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.97 on epoch=163
05/29/2022 18:30:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.00 on epoch=164
05/29/2022 18:30:03 - INFO - __main__ - Global step 2300 Train loss 2.93 Classification-F1 0.025419902474264042 on epoch=164
05/29/2022 18:30:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.94 on epoch=164
05/29/2022 18:30:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.84 on epoch=165
05/29/2022 18:30:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.81 on epoch=166
05/29/2022 18:30:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.77 on epoch=167
05/29/2022 18:30:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.94 on epoch=167
05/29/2022 18:30:11 - INFO - __main__ - Global step 2350 Train loss 2.86 Classification-F1 0.02132343846629561 on epoch=167
05/29/2022 18:30:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.72 on epoch=168
05/29/2022 18:30:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.87 on epoch=169
05/29/2022 18:30:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.75 on epoch=169
05/29/2022 18:30:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.94 on epoch=170
05/29/2022 18:30:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.83 on epoch=171
05/29/2022 18:30:20 - INFO - __main__ - Global step 2400 Train loss 2.82 Classification-F1 0.02429906542056075 on epoch=171
05/29/2022 18:30:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.76 on epoch=172
05/29/2022 18:30:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.85 on epoch=172
05/29/2022 18:30:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.74 on epoch=173
05/29/2022 18:30:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.98 on epoch=174
05/29/2022 18:30:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.78 on epoch=174
05/29/2022 18:30:28 - INFO - __main__ - Global step 2450 Train loss 2.82 Classification-F1 0.017163161067225024 on epoch=174
05/29/2022 18:30:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.94 on epoch=175
05/29/2022 18:30:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.76 on epoch=176
05/29/2022 18:30:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.86 on epoch=177
05/29/2022 18:30:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.82 on epoch=177
05/29/2022 18:30:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.76 on epoch=178
05/29/2022 18:30:36 - INFO - __main__ - Global step 2500 Train loss 2.83 Classification-F1 0.044128059656009966 on epoch=178
05/29/2022 18:30:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.86 on epoch=179
05/29/2022 18:30:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.62 on epoch=179
05/29/2022 18:30:40 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.88 on epoch=180
05/29/2022 18:30:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.62 on epoch=181
05/29/2022 18:30:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.77 on epoch=182
05/29/2022 18:30:45 - INFO - __main__ - Global step 2550 Train loss 2.75 Classification-F1 0.021150560680893358 on epoch=182
05/29/2022 18:30:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.90 on epoch=182
05/29/2022 18:30:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.63 on epoch=183
05/29/2022 18:30:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.94 on epoch=184
05/29/2022 18:30:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.64 on epoch=184
05/29/2022 18:30:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.75 on epoch=185
05/29/2022 18:30:53 - INFO - __main__ - Global step 2600 Train loss 2.77 Classification-F1 0.032607801184990126 on epoch=185
05/29/2022 18:30:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.86 on epoch=186
05/29/2022 18:30:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.81 on epoch=187
05/29/2022 18:30:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.82 on epoch=187
05/29/2022 18:30:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.64 on epoch=188
05/29/2022 18:30:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.88 on epoch=189
05/29/2022 18:31:01 - INFO - __main__ - Global step 2650 Train loss 2.80 Classification-F1 0.03222432312829384 on epoch=189
05/29/2022 18:31:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.72 on epoch=189
05/29/2022 18:31:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.88 on epoch=190
05/29/2022 18:31:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.76 on epoch=191
05/29/2022 18:31:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.69 on epoch=192
05/29/2022 18:31:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.88 on epoch=192
05/29/2022 18:31:10 - INFO - __main__ - Global step 2700 Train loss 2.78 Classification-F1 0.026421404682274247 on epoch=192
05/29/2022 18:31:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.68 on epoch=193
05/29/2022 18:31:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.97 on epoch=194
05/29/2022 18:31:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.55 on epoch=194
05/29/2022 18:31:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.81 on epoch=195
05/29/2022 18:31:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.61 on epoch=196
05/29/2022 18:31:18 - INFO - __main__ - Global step 2750 Train loss 2.73 Classification-F1 0.03294548588666236 on epoch=196
05/29/2022 18:31:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.68 on epoch=197
05/29/2022 18:31:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.70 on epoch=197
05/29/2022 18:31:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.67 on epoch=198
05/29/2022 18:31:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.86 on epoch=199
05/29/2022 18:31:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.63 on epoch=199
05/29/2022 18:31:26 - INFO - __main__ - Global step 2800 Train loss 2.71 Classification-F1 0.03410553410553411 on epoch=199
05/29/2022 18:31:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.76 on epoch=200
05/29/2022 18:31:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.71 on epoch=201
05/29/2022 18:31:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.75 on epoch=202
05/29/2022 18:31:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.71 on epoch=202
05/29/2022 18:31:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.74 on epoch=203
05/29/2022 18:31:35 - INFO - __main__ - Global step 2850 Train loss 2.73 Classification-F1 0.02498635347150077 on epoch=203
05/29/2022 18:31:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.86 on epoch=204
05/29/2022 18:31:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.67 on epoch=204
05/29/2022 18:31:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.83 on epoch=205
05/29/2022 18:31:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.63 on epoch=206
05/29/2022 18:31:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.63 on epoch=207
05/29/2022 18:31:43 - INFO - __main__ - Global step 2900 Train loss 2.72 Classification-F1 0.05059829687270593 on epoch=207
05/29/2022 18:31:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.84 on epoch=207
05/29/2022 18:31:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.64 on epoch=208
05/29/2022 18:31:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.70 on epoch=209
05/29/2022 18:31:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.69 on epoch=209
05/29/2022 18:31:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.75 on epoch=210
05/29/2022 18:31:51 - INFO - __main__ - Global step 2950 Train loss 2.73 Classification-F1 0.048593706488443335 on epoch=210
05/29/2022 18:31:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.62 on epoch=211
05/29/2022 18:31:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.76 on epoch=212
05/29/2022 18:31:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.69 on epoch=212
05/29/2022 18:31:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.56 on epoch=213
05/29/2022 18:31:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.80 on epoch=214
05/29/2022 18:31:59 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:31:59 - INFO - __main__ - Printing 3 examples
05/29/2022 18:31:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 18:31:59 - INFO - __main__ - ['Animal']
05/29/2022 18:31:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 18:31:59 - INFO - __main__ - ['Animal']
05/29/2022 18:31:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 18:31:59 - INFO - __main__ - ['Animal']
05/29/2022 18:31:59 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:31:59 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:31:59 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:31:59 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:31:59 - INFO - __main__ - Printing 3 examples
05/29/2022 18:31:59 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 18:31:59 - INFO - __main__ - ['Animal']
05/29/2022 18:31:59 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 18:31:59 - INFO - __main__ - ['Animal']
05/29/2022 18:31:59 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 18:31:59 - INFO - __main__ - ['Animal']
05/29/2022 18:31:59 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:31:59 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:32:00 - INFO - __main__ - Global step 3000 Train loss 2.68 Classification-F1 0.038407839624878155 on epoch=214
05/29/2022 18:32:00 - INFO - __main__ - save last model!
05/29/2022 18:32:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 18:32:00 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 18:32:00 - INFO - __main__ - Printing 3 examples
05/29/2022 18:32:00 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 18:32:00 - INFO - __main__ - ['Animal']
05/29/2022 18:32:00 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 18:32:00 - INFO - __main__ - ['Animal']
05/29/2022 18:32:00 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 18:32:00 - INFO - __main__ - ['Village']
05/29/2022 18:32:00 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:32:00 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:32:02 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:32:05 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 18:32:06 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:32:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:32:06 - INFO - __main__ - Starting training!
05/29/2022 18:32:34 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/29/2022 18:32:35 - INFO - __main__ - Classification-F1 on test data: 0.0261
05/29/2022 18:32:35 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.05282334260649523, test_performance=0.026080949988889202
05/29/2022 18:32:35 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/29/2022 18:32:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:32:36 - INFO - __main__ - Printing 3 examples
05/29/2022 18:32:36 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 18:32:36 - INFO - __main__ - ['Animal']
05/29/2022 18:32:36 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 18:32:36 - INFO - __main__ - ['Animal']
05/29/2022 18:32:36 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 18:32:36 - INFO - __main__ - ['Animal']
05/29/2022 18:32:36 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:32:36 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:32:36 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:32:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:32:36 - INFO - __main__ - Printing 3 examples
05/29/2022 18:32:36 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 18:32:36 - INFO - __main__ - ['Animal']
05/29/2022 18:32:36 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 18:32:36 - INFO - __main__ - ['Animal']
05/29/2022 18:32:36 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 18:32:36 - INFO - __main__ - ['Animal']
05/29/2022 18:32:36 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:32:36 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:32:36 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:32:42 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:32:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:32:43 - INFO - __main__ - Starting training!
05/29/2022 18:32:44 - INFO - __main__ - Step 10 Global step 10 Train loss 7.31 on epoch=0
05/29/2022 18:32:45 - INFO - __main__ - Step 20 Global step 20 Train loss 7.37 on epoch=1
05/29/2022 18:32:47 - INFO - __main__ - Step 30 Global step 30 Train loss 7.08 on epoch=2
05/29/2022 18:32:48 - INFO - __main__ - Step 40 Global step 40 Train loss 6.84 on epoch=2
05/29/2022 18:32:49 - INFO - __main__ - Step 50 Global step 50 Train loss 6.81 on epoch=3
05/29/2022 18:33:09 - INFO - __main__ - Global step 50 Train loss 7.08 Classification-F1 0.0 on epoch=3
05/29/2022 18:33:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 18:33:10 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/29/2022 18:33:11 - INFO - __main__ - Step 70 Global step 70 Train loss 6.59 on epoch=4
05/29/2022 18:33:12 - INFO - __main__ - Step 80 Global step 80 Train loss 6.41 on epoch=5
05/29/2022 18:33:14 - INFO - __main__ - Step 90 Global step 90 Train loss 6.44 on epoch=6
05/29/2022 18:33:15 - INFO - __main__ - Step 100 Global step 100 Train loss 6.24 on epoch=7
05/29/2022 18:34:24 - INFO - __main__ - Global step 100 Train loss 6.49 Classification-F1 0.0 on epoch=7
05/29/2022 18:34:25 - INFO - __main__ - Step 110 Global step 110 Train loss 6.08 on epoch=7
05/29/2022 18:34:26 - INFO - __main__ - Step 120 Global step 120 Train loss 6.11 on epoch=8
05/29/2022 18:34:27 - INFO - __main__ - Step 130 Global step 130 Train loss 6.16 on epoch=9
05/29/2022 18:34:29 - INFO - __main__ - Step 140 Global step 140 Train loss 5.96 on epoch=9
05/29/2022 18:34:30 - INFO - __main__ - Step 150 Global step 150 Train loss 5.80 on epoch=10
05/29/2022 18:35:47 - INFO - __main__ - Global step 150 Train loss 6.02 Classification-F1 0.0 on epoch=10
05/29/2022 18:35:48 - INFO - __main__ - Step 160 Global step 160 Train loss 5.90 on epoch=11
05/29/2022 18:35:50 - INFO - __main__ - Step 170 Global step 170 Train loss 5.66 on epoch=12
05/29/2022 18:35:51 - INFO - __main__ - Step 180 Global step 180 Train loss 5.61 on epoch=12
05/29/2022 18:35:52 - INFO - __main__ - Step 190 Global step 190 Train loss 5.63 on epoch=13
05/29/2022 18:35:53 - INFO - __main__ - Step 200 Global step 200 Train loss 5.64 on epoch=14
05/29/2022 18:36:50 - INFO - __main__ - Global step 200 Train loss 5.69 Classification-F1 0.0 on epoch=14
05/29/2022 18:36:51 - INFO - __main__ - Step 210 Global step 210 Train loss 5.43 on epoch=14
05/29/2022 18:36:52 - INFO - __main__ - Step 220 Global step 220 Train loss 5.26 on epoch=15
05/29/2022 18:36:54 - INFO - __main__ - Step 230 Global step 230 Train loss 5.54 on epoch=16
05/29/2022 18:36:55 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=17
05/29/2022 18:36:56 - INFO - __main__ - Step 250 Global step 250 Train loss 5.43 on epoch=17
05/29/2022 18:37:27 - INFO - __main__ - Global step 250 Train loss 5.41 Classification-F1 0.0 on epoch=17
05/29/2022 18:37:28 - INFO - __main__ - Step 260 Global step 260 Train loss 5.26 on epoch=18
05/29/2022 18:37:29 - INFO - __main__ - Step 270 Global step 270 Train loss 5.33 on epoch=19
05/29/2022 18:37:31 - INFO - __main__ - Step 280 Global step 280 Train loss 5.28 on epoch=19
05/29/2022 18:37:32 - INFO - __main__ - Step 290 Global step 290 Train loss 5.01 on epoch=20
05/29/2022 18:37:33 - INFO - __main__ - Step 300 Global step 300 Train loss 5.24 on epoch=21
05/29/2022 18:38:04 - INFO - __main__ - Global step 300 Train loss 5.23 Classification-F1 0.0 on epoch=21
05/29/2022 18:38:06 - INFO - __main__ - Step 310 Global step 310 Train loss 5.03 on epoch=22
05/29/2022 18:38:07 - INFO - __main__ - Step 320 Global step 320 Train loss 4.87 on epoch=22
05/29/2022 18:38:08 - INFO - __main__ - Step 330 Global step 330 Train loss 4.94 on epoch=23
05/29/2022 18:38:10 - INFO - __main__ - Step 340 Global step 340 Train loss 4.83 on epoch=24
05/29/2022 18:38:11 - INFO - __main__ - Step 350 Global step 350 Train loss 4.96 on epoch=24
05/29/2022 18:38:17 - INFO - __main__ - Global step 350 Train loss 4.93 Classification-F1 0.007532956685499058 on epoch=24
05/29/2022 18:38:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.007532956685499058 on epoch=24, global_step=350
05/29/2022 18:38:18 - INFO - __main__ - Step 360 Global step 360 Train loss 4.66 on epoch=25
05/29/2022 18:38:20 - INFO - __main__ - Step 370 Global step 370 Train loss 4.72 on epoch=26
05/29/2022 18:38:21 - INFO - __main__ - Step 380 Global step 380 Train loss 4.74 on epoch=27
05/29/2022 18:38:22 - INFO - __main__ - Step 390 Global step 390 Train loss 4.60 on epoch=27
05/29/2022 18:38:23 - INFO - __main__ - Step 400 Global step 400 Train loss 4.66 on epoch=28
05/29/2022 18:38:26 - INFO - __main__ - Global step 400 Train loss 4.68 Classification-F1 0.00847457627118644 on epoch=28
05/29/2022 18:38:26 - INFO - __main__ - Saving model with best Classification-F1: 0.007532956685499058 -> 0.00847457627118644 on epoch=28, global_step=400
05/29/2022 18:38:27 - INFO - __main__ - Step 410 Global step 410 Train loss 4.52 on epoch=29
05/29/2022 18:38:28 - INFO - __main__ - Step 420 Global step 420 Train loss 4.52 on epoch=29
05/29/2022 18:38:30 - INFO - __main__ - Step 430 Global step 430 Train loss 4.22 on epoch=30
05/29/2022 18:38:31 - INFO - __main__ - Step 440 Global step 440 Train loss 4.39 on epoch=31
05/29/2022 18:38:32 - INFO - __main__ - Step 450 Global step 450 Train loss 4.55 on epoch=32
05/29/2022 18:38:34 - INFO - __main__ - Global step 450 Train loss 4.44 Classification-F1 0.009523809523809523 on epoch=32
05/29/2022 18:38:34 - INFO - __main__ - Saving model with best Classification-F1: 0.00847457627118644 -> 0.009523809523809523 on epoch=32, global_step=450
05/29/2022 18:38:35 - INFO - __main__ - Step 460 Global step 460 Train loss 4.33 on epoch=32
05/29/2022 18:38:37 - INFO - __main__ - Step 470 Global step 470 Train loss 4.32 on epoch=33
05/29/2022 18:38:38 - INFO - __main__ - Step 480 Global step 480 Train loss 4.36 on epoch=34
05/29/2022 18:38:39 - INFO - __main__ - Step 490 Global step 490 Train loss 4.21 on epoch=34
05/29/2022 18:38:40 - INFO - __main__ - Step 500 Global step 500 Train loss 4.22 on epoch=35
05/29/2022 18:38:42 - INFO - __main__ - Global step 500 Train loss 4.29 Classification-F1 0.00935672514619883 on epoch=35
05/29/2022 18:38:43 - INFO - __main__ - Step 510 Global step 510 Train loss 4.18 on epoch=36
05/29/2022 18:38:45 - INFO - __main__ - Step 520 Global step 520 Train loss 4.23 on epoch=37
05/29/2022 18:38:46 - INFO - __main__ - Step 530 Global step 530 Train loss 3.96 on epoch=37
05/29/2022 18:38:47 - INFO - __main__ - Step 540 Global step 540 Train loss 4.21 on epoch=38
05/29/2022 18:38:48 - INFO - __main__ - Step 550 Global step 550 Train loss 4.02 on epoch=39
05/29/2022 18:38:50 - INFO - __main__ - Global step 550 Train loss 4.12 Classification-F1 0.02746283698664651 on epoch=39
05/29/2022 18:38:50 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02746283698664651 on epoch=39, global_step=550
05/29/2022 18:38:52 - INFO - __main__ - Step 560 Global step 560 Train loss 4.02 on epoch=39
05/29/2022 18:38:53 - INFO - __main__ - Step 570 Global step 570 Train loss 4.01 on epoch=40
05/29/2022 18:38:54 - INFO - __main__ - Step 580 Global step 580 Train loss 4.00 on epoch=41
05/29/2022 18:38:55 - INFO - __main__ - Step 590 Global step 590 Train loss 4.07 on epoch=42
05/29/2022 18:38:56 - INFO - __main__ - Step 600 Global step 600 Train loss 3.84 on epoch=42
05/29/2022 18:38:58 - INFO - __main__ - Global step 600 Train loss 3.99 Classification-F1 0.0331370404158758 on epoch=42
05/29/2022 18:38:58 - INFO - __main__ - Saving model with best Classification-F1: 0.02746283698664651 -> 0.0331370404158758 on epoch=42, global_step=600
05/29/2022 18:39:00 - INFO - __main__ - Step 610 Global step 610 Train loss 3.89 on epoch=43
05/29/2022 18:39:01 - INFO - __main__ - Step 620 Global step 620 Train loss 3.92 on epoch=44
05/29/2022 18:39:02 - INFO - __main__ - Step 630 Global step 630 Train loss 3.96 on epoch=44
05/29/2022 18:39:03 - INFO - __main__ - Step 640 Global step 640 Train loss 3.82 on epoch=45
05/29/2022 18:39:05 - INFO - __main__ - Step 650 Global step 650 Train loss 3.82 on epoch=46
05/29/2022 18:39:06 - INFO - __main__ - Global step 650 Train loss 3.88 Classification-F1 0.02450451334379906 on epoch=46
05/29/2022 18:39:08 - INFO - __main__ - Step 660 Global step 660 Train loss 3.88 on epoch=47
05/29/2022 18:39:09 - INFO - __main__ - Step 670 Global step 670 Train loss 3.77 on epoch=47
05/29/2022 18:39:10 - INFO - __main__ - Step 680 Global step 680 Train loss 3.80 on epoch=48
05/29/2022 18:39:11 - INFO - __main__ - Step 690 Global step 690 Train loss 3.63 on epoch=49
05/29/2022 18:39:12 - INFO - __main__ - Step 700 Global step 700 Train loss 3.58 on epoch=49
05/29/2022 18:39:14 - INFO - __main__ - Global step 700 Train loss 3.73 Classification-F1 0.0359047619047619 on epoch=49
05/29/2022 18:39:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0331370404158758 -> 0.0359047619047619 on epoch=49, global_step=700
05/29/2022 18:39:16 - INFO - __main__ - Step 710 Global step 710 Train loss 3.48 on epoch=50
05/29/2022 18:39:17 - INFO - __main__ - Step 720 Global step 720 Train loss 3.51 on epoch=51
05/29/2022 18:39:18 - INFO - __main__ - Step 730 Global step 730 Train loss 3.66 on epoch=52
05/29/2022 18:39:19 - INFO - __main__ - Step 740 Global step 740 Train loss 3.42 on epoch=52
05/29/2022 18:39:21 - INFO - __main__ - Step 750 Global step 750 Train loss 3.40 on epoch=53
05/29/2022 18:39:23 - INFO - __main__ - Global step 750 Train loss 3.50 Classification-F1 0.020648259303721488 on epoch=53
05/29/2022 18:39:24 - INFO - __main__ - Step 760 Global step 760 Train loss 3.51 on epoch=54
05/29/2022 18:39:25 - INFO - __main__ - Step 770 Global step 770 Train loss 3.58 on epoch=54
05/29/2022 18:39:27 - INFO - __main__ - Step 780 Global step 780 Train loss 3.18 on epoch=55
05/29/2022 18:39:28 - INFO - __main__ - Step 790 Global step 790 Train loss 3.34 on epoch=56
05/29/2022 18:39:29 - INFO - __main__ - Step 800 Global step 800 Train loss 3.55 on epoch=57
05/29/2022 18:39:31 - INFO - __main__ - Global step 800 Train loss 3.43 Classification-F1 0.02895090490510338 on epoch=57
05/29/2022 18:39:32 - INFO - __main__ - Step 810 Global step 810 Train loss 3.20 on epoch=57
05/29/2022 18:39:34 - INFO - __main__ - Step 820 Global step 820 Train loss 3.43 on epoch=58
05/29/2022 18:39:35 - INFO - __main__ - Step 830 Global step 830 Train loss 3.24 on epoch=59
05/29/2022 18:39:36 - INFO - __main__ - Step 840 Global step 840 Train loss 3.32 on epoch=59
05/29/2022 18:39:37 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/29/2022 18:39:39 - INFO - __main__ - Global step 850 Train loss 3.28 Classification-F1 0.03400444147124499 on epoch=60
05/29/2022 18:39:41 - INFO - __main__ - Step 860 Global step 860 Train loss 3.31 on epoch=61
05/29/2022 18:39:42 - INFO - __main__ - Step 870 Global step 870 Train loss 3.33 on epoch=62
05/29/2022 18:39:43 - INFO - __main__ - Step 880 Global step 880 Train loss 3.16 on epoch=62
05/29/2022 18:39:44 - INFO - __main__ - Step 890 Global step 890 Train loss 3.15 on epoch=63
05/29/2022 18:39:46 - INFO - __main__ - Step 900 Global step 900 Train loss 3.12 on epoch=64
05/29/2022 18:39:48 - INFO - __main__ - Global step 900 Train loss 3.21 Classification-F1 0.009563658099222952 on epoch=64
05/29/2022 18:39:49 - INFO - __main__ - Step 910 Global step 910 Train loss 3.05 on epoch=64
05/29/2022 18:39:50 - INFO - __main__ - Step 920 Global step 920 Train loss 3.01 on epoch=65
05/29/2022 18:39:51 - INFO - __main__ - Step 930 Global step 930 Train loss 3.10 on epoch=66
05/29/2022 18:39:53 - INFO - __main__ - Step 940 Global step 940 Train loss 3.20 on epoch=67
05/29/2022 18:39:54 - INFO - __main__ - Step 950 Global step 950 Train loss 3.10 on epoch=67
05/29/2022 18:39:56 - INFO - __main__ - Global step 950 Train loss 3.09 Classification-F1 0.05680868838763576 on epoch=67
05/29/2022 18:39:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0359047619047619 -> 0.05680868838763576 on epoch=67, global_step=950
05/29/2022 18:39:57 - INFO - __main__ - Step 960 Global step 960 Train loss 2.94 on epoch=68
05/29/2022 18:39:58 - INFO - __main__ - Step 970 Global step 970 Train loss 3.03 on epoch=69
05/29/2022 18:40:00 - INFO - __main__ - Step 980 Global step 980 Train loss 3.03 on epoch=69
05/29/2022 18:40:01 - INFO - __main__ - Step 990 Global step 990 Train loss 2.93 on epoch=70
05/29/2022 18:40:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.06 on epoch=71
05/29/2022 18:40:04 - INFO - __main__ - Global step 1000 Train loss 3.00 Classification-F1 0.060031803579098666 on epoch=71
05/29/2022 18:40:04 - INFO - __main__ - Saving model with best Classification-F1: 0.05680868838763576 -> 0.060031803579098666 on epoch=71, global_step=1000
05/29/2022 18:40:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.02 on epoch=72
05/29/2022 18:40:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.85 on epoch=72
05/29/2022 18:40:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.75 on epoch=73
05/29/2022 18:40:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.77 on epoch=74
05/29/2022 18:40:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.94 on epoch=74
05/29/2022 18:40:12 - INFO - __main__ - Global step 1050 Train loss 2.87 Classification-F1 0.026546934865900384 on epoch=74
05/29/2022 18:40:14 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.83 on epoch=75
05/29/2022 18:40:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.97 on epoch=76
05/29/2022 18:40:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.98 on epoch=77
05/29/2022 18:40:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.75 on epoch=77
05/29/2022 18:40:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.79 on epoch=78
05/29/2022 18:40:21 - INFO - __main__ - Global step 1100 Train loss 2.86 Classification-F1 0.031990231990231995 on epoch=78
05/29/2022 18:40:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.87 on epoch=79
05/29/2022 18:40:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.91 on epoch=79
05/29/2022 18:40:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.81 on epoch=80
05/29/2022 18:40:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.66 on epoch=81
05/29/2022 18:40:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.96 on epoch=82
05/29/2022 18:40:29 - INFO - __main__ - Global step 1150 Train loss 2.84 Classification-F1 0.024805603752972173 on epoch=82
05/29/2022 18:40:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/29/2022 18:40:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.86 on epoch=83
05/29/2022 18:40:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.78 on epoch=84
05/29/2022 18:40:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.91 on epoch=84
05/29/2022 18:40:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.78 on epoch=85
05/29/2022 18:40:37 - INFO - __main__ - Global step 1200 Train loss 2.82 Classification-F1 0.037926169499120276 on epoch=85
05/29/2022 18:40:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.79 on epoch=86
05/29/2022 18:40:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.86 on epoch=87
05/29/2022 18:40:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.71 on epoch=87
05/29/2022 18:40:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.67 on epoch=88
05/29/2022 18:40:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.69 on epoch=89
05/29/2022 18:40:45 - INFO - __main__ - Global step 1250 Train loss 2.74 Classification-F1 0.013344472291840714 on epoch=89
05/29/2022 18:40:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.82 on epoch=89
05/29/2022 18:40:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.66 on epoch=90
05/29/2022 18:40:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.64 on epoch=91
05/29/2022 18:40:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.82 on epoch=92
05/29/2022 18:40:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.67 on epoch=92
05/29/2022 18:40:54 - INFO - __main__ - Global step 1300 Train loss 2.72 Classification-F1 0.01728680676049097 on epoch=92
05/29/2022 18:40:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.79 on epoch=93
05/29/2022 18:40:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.62 on epoch=94
05/29/2022 18:40:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.84 on epoch=94
05/29/2022 18:40:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.68 on epoch=95
05/29/2022 18:41:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.72 on epoch=96
05/29/2022 18:41:03 - INFO - __main__ - Global step 1350 Train loss 2.73 Classification-F1 0.01719986240110079 on epoch=96
05/29/2022 18:41:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.83 on epoch=97
05/29/2022 18:41:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.62 on epoch=97
05/29/2022 18:41:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.72 on epoch=98
05/29/2022 18:41:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.65 on epoch=99
05/29/2022 18:41:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.76 on epoch=99
05/29/2022 18:41:11 - INFO - __main__ - Global step 1400 Train loss 2.71 Classification-F1 0.045825946981274325 on epoch=99
05/29/2022 18:41:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.71 on epoch=100
05/29/2022 18:41:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.55 on epoch=101
05/29/2022 18:41:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.69 on epoch=102
05/29/2022 18:41:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.50 on epoch=102
05/29/2022 18:41:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.52 on epoch=103
05/29/2022 18:41:20 - INFO - __main__ - Global step 1450 Train loss 2.59 Classification-F1 0.04442200471587681 on epoch=103
05/29/2022 18:41:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.55 on epoch=104
05/29/2022 18:41:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.51 on epoch=104
05/29/2022 18:41:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.38 on epoch=105
05/29/2022 18:41:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.42 on epoch=106
05/29/2022 18:41:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.71 on epoch=107
05/29/2022 18:41:28 - INFO - __main__ - Global step 1500 Train loss 2.52 Classification-F1 0.03651726226529376 on epoch=107
05/29/2022 18:41:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.58 on epoch=107
05/29/2022 18:41:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.52 on epoch=108
05/29/2022 18:41:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.58 on epoch=109
05/29/2022 18:41:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.57 on epoch=109
05/29/2022 18:41:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.52 on epoch=110
05/29/2022 18:41:36 - INFO - __main__ - Global step 1550 Train loss 2.56 Classification-F1 0.014835973915257802 on epoch=110
05/29/2022 18:41:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.49 on epoch=111
05/29/2022 18:41:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.51 on epoch=112
05/29/2022 18:41:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.37 on epoch=112
05/29/2022 18:41:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.55 on epoch=113
05/29/2022 18:41:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.58 on epoch=114
05/29/2022 18:41:45 - INFO - __main__ - Global step 1600 Train loss 2.50 Classification-F1 0.009523809523809523 on epoch=114
05/29/2022 18:41:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.55 on epoch=114
05/29/2022 18:41:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.36 on epoch=115
05/29/2022 18:41:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.25 on epoch=116
05/29/2022 18:41:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.55 on epoch=117
05/29/2022 18:41:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.39 on epoch=117
05/29/2022 18:41:53 - INFO - __main__ - Global step 1650 Train loss 2.42 Classification-F1 0.009523809523809523 on epoch=117
05/29/2022 18:41:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.46 on epoch=118
05/29/2022 18:41:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.39 on epoch=119
05/29/2022 18:41:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.44 on epoch=119
05/29/2022 18:41:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.21 on epoch=120
05/29/2022 18:42:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.47 on epoch=121
05/29/2022 18:42:02 - INFO - __main__ - Global step 1700 Train loss 2.39 Classification-F1 0.009563658099222952 on epoch=121
05/29/2022 18:42:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.41 on epoch=122
05/29/2022 18:42:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.26 on epoch=122
05/29/2022 18:42:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.44 on epoch=123
05/29/2022 18:42:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.37 on epoch=124
05/29/2022 18:42:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.45 on epoch=124
05/29/2022 18:42:10 - INFO - __main__ - Global step 1750 Train loss 2.39 Classification-F1 0.029976649365859333 on epoch=124
05/29/2022 18:42:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.30 on epoch=125
05/29/2022 18:42:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.38 on epoch=126
05/29/2022 18:42:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.55 on epoch=127
05/29/2022 18:42:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.25 on epoch=127
05/29/2022 18:42:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.42 on epoch=128
05/29/2022 18:42:19 - INFO - __main__ - Global step 1800 Train loss 2.38 Classification-F1 0.021886046995217297 on epoch=128
05/29/2022 18:42:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.57 on epoch=129
05/29/2022 18:42:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.54 on epoch=129
05/29/2022 18:42:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.19 on epoch=130
05/29/2022 18:42:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.33 on epoch=131
05/29/2022 18:42:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.40 on epoch=132
05/29/2022 18:42:27 - INFO - __main__ - Global step 1850 Train loss 2.40 Classification-F1 0.042642069496289445 on epoch=132
05/29/2022 18:42:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.35 on epoch=132
05/29/2022 18:42:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.20 on epoch=133
05/29/2022 18:42:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.24 on epoch=134
05/29/2022 18:42:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.25 on epoch=134
05/29/2022 18:42:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.12 on epoch=135
05/29/2022 18:42:35 - INFO - __main__ - Global step 1900 Train loss 2.23 Classification-F1 0.03963713631905852 on epoch=135
05/29/2022 18:42:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.34 on epoch=136
05/29/2022 18:42:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.44 on epoch=137
05/29/2022 18:42:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.15 on epoch=137
05/29/2022 18:42:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.16 on epoch=138
05/29/2022 18:42:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.26 on epoch=139
05/29/2022 18:42:44 - INFO - __main__ - Global step 1950 Train loss 2.27 Classification-F1 0.01834124954329558 on epoch=139
05/29/2022 18:42:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.14 on epoch=139
05/29/2022 18:42:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.11 on epoch=140
05/29/2022 18:42:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.06 on epoch=141
05/29/2022 18:42:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.26 on epoch=142
05/29/2022 18:42:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.20 on epoch=142
05/29/2022 18:42:52 - INFO - __main__ - Global step 2000 Train loss 2.15 Classification-F1 0.027881608783864423 on epoch=142
05/29/2022 18:42:53 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.14 on epoch=143
05/29/2022 18:42:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.19 on epoch=144
05/29/2022 18:42:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.20 on epoch=144
05/29/2022 18:42:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.10 on epoch=145
05/29/2022 18:42:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.95 on epoch=146
05/29/2022 18:43:01 - INFO - __main__ - Global step 2050 Train loss 2.12 Classification-F1 0.02495113257445096 on epoch=146
05/29/2022 18:43:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.22 on epoch=147
05/29/2022 18:43:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.12 on epoch=147
05/29/2022 18:43:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.10 on epoch=148
05/29/2022 18:43:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.16 on epoch=149
05/29/2022 18:43:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.30 on epoch=149
05/29/2022 18:43:09 - INFO - __main__ - Global step 2100 Train loss 2.18 Classification-F1 0.024543794455298886 on epoch=149
05/29/2022 18:43:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.21 on epoch=150
05/29/2022 18:43:12 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.18 on epoch=151
05/29/2022 18:43:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.16 on epoch=152
05/29/2022 18:43:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.04 on epoch=152
05/29/2022 18:43:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.03 on epoch=153
05/29/2022 18:43:17 - INFO - __main__ - Global step 2150 Train loss 2.12 Classification-F1 0.009563658099222952 on epoch=153
05/29/2022 18:43:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.24 on epoch=154
05/29/2022 18:43:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.99 on epoch=154
05/29/2022 18:43:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.08 on epoch=155
05/29/2022 18:43:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.09 on epoch=156
05/29/2022 18:43:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.08 on epoch=157
05/29/2022 18:43:26 - INFO - __main__ - Global step 2200 Train loss 2.10 Classification-F1 0.029605169078853293 on epoch=157
05/29/2022 18:43:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.93 on epoch=157
05/29/2022 18:43:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.04 on epoch=158
05/29/2022 18:43:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.11 on epoch=159
05/29/2022 18:43:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.99 on epoch=159
05/29/2022 18:43:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.98 on epoch=160
05/29/2022 18:43:35 - INFO - __main__ - Global step 2250 Train loss 2.01 Classification-F1 0.02123885083526339 on epoch=160
05/29/2022 18:43:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.00 on epoch=161
05/29/2022 18:43:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.23 on epoch=162
05/29/2022 18:43:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.05 on epoch=162
05/29/2022 18:43:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.85 on epoch=163
05/29/2022 18:43:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.04 on epoch=164
05/29/2022 18:43:43 - INFO - __main__ - Global step 2300 Train loss 2.03 Classification-F1 0.009726443768996961 on epoch=164
05/29/2022 18:43:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.97 on epoch=164
05/29/2022 18:43:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.96 on epoch=165
05/29/2022 18:43:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.98 on epoch=166
05/29/2022 18:43:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.05 on epoch=167
05/29/2022 18:43:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.95 on epoch=167
05/29/2022 18:43:52 - INFO - __main__ - Global step 2350 Train loss 1.98 Classification-F1 0.009644364074743823 on epoch=167
05/29/2022 18:43:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.05 on epoch=168
05/29/2022 18:43:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.00 on epoch=169
05/29/2022 18:43:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.85 on epoch=169
05/29/2022 18:43:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.92 on epoch=170
05/29/2022 18:43:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.90 on epoch=171
05/29/2022 18:44:01 - INFO - __main__ - Global step 2400 Train loss 1.94 Classification-F1 0.009563658099222952 on epoch=171
05/29/2022 18:44:02 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.95 on epoch=172
05/29/2022 18:44:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.91 on epoch=172
05/29/2022 18:44:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.84 on epoch=173
05/29/2022 18:44:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.91 on epoch=174
05/29/2022 18:44:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.88 on epoch=174
05/29/2022 18:44:09 - INFO - __main__ - Global step 2450 Train loss 1.90 Classification-F1 0.031085082525517876 on epoch=174
05/29/2022 18:44:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.89 on epoch=175
05/29/2022 18:44:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.84 on epoch=176
05/29/2022 18:44:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.83 on epoch=177
05/29/2022 18:44:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.92 on epoch=177
05/29/2022 18:44:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.85 on epoch=178
05/29/2022 18:44:18 - INFO - __main__ - Global step 2500 Train loss 1.86 Classification-F1 0.024212759014521128 on epoch=178
05/29/2022 18:44:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.89 on epoch=179
05/29/2022 18:44:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.78 on epoch=179
05/29/2022 18:44:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.81 on epoch=180
05/29/2022 18:44:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.92 on epoch=181
05/29/2022 18:44:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.91 on epoch=182
05/29/2022 18:44:27 - INFO - __main__ - Global step 2550 Train loss 1.86 Classification-F1 0.027898027898027897 on epoch=182
05/29/2022 18:44:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.91 on epoch=182
05/29/2022 18:44:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.88 on epoch=183
05/29/2022 18:44:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.87 on epoch=184
05/29/2022 18:44:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.85 on epoch=184
05/29/2022 18:44:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.76 on epoch=185
05/29/2022 18:44:35 - INFO - __main__ - Global step 2600 Train loss 1.85 Classification-F1 0.02358662613981763 on epoch=185
05/29/2022 18:44:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.90 on epoch=186
05/29/2022 18:44:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.83 on epoch=187
05/29/2022 18:44:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.76 on epoch=187
05/29/2022 18:44:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.80 on epoch=188
05/29/2022 18:44:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.91 on epoch=189
05/29/2022 18:44:43 - INFO - __main__ - Global step 2650 Train loss 1.84 Classification-F1 0.024117497132662164 on epoch=189
05/29/2022 18:44:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.72 on epoch=189
05/29/2022 18:44:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.80 on epoch=190
05/29/2022 18:44:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.82 on epoch=191
05/29/2022 18:44:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.77 on epoch=192
05/29/2022 18:44:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.83 on epoch=192
05/29/2022 18:44:52 - INFO - __main__ - Global step 2700 Train loss 1.79 Classification-F1 0.016570730856445143 on epoch=192
05/29/2022 18:44:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.80 on epoch=193
05/29/2022 18:44:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.85 on epoch=194
05/29/2022 18:44:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.79 on epoch=194
05/29/2022 18:44:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.81 on epoch=195
05/29/2022 18:44:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.86 on epoch=196
05/29/2022 18:45:00 - INFO - __main__ - Global step 2750 Train loss 1.82 Classification-F1 0.009685230024213076 on epoch=196
05/29/2022 18:45:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.84 on epoch=197
05/29/2022 18:45:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.79 on epoch=197
05/29/2022 18:45:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.88 on epoch=198
05/29/2022 18:45:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.83 on epoch=199
05/29/2022 18:45:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.84 on epoch=199
05/29/2022 18:45:09 - INFO - __main__ - Global step 2800 Train loss 1.84 Classification-F1 0.00976800976800977 on epoch=199
05/29/2022 18:45:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.65 on epoch=200
05/29/2022 18:45:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.79 on epoch=201
05/29/2022 18:45:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.69 on epoch=202
05/29/2022 18:45:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.92 on epoch=202
05/29/2022 18:45:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.78 on epoch=203
05/29/2022 18:45:18 - INFO - __main__ - Global step 2850 Train loss 1.76 Classification-F1 0.025558245897228944 on epoch=203
05/29/2022 18:45:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.82 on epoch=204
05/29/2022 18:45:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.74 on epoch=204
05/29/2022 18:45:22 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.71 on epoch=205
05/29/2022 18:45:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.85 on epoch=206
05/29/2022 18:45:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.71 on epoch=207
05/29/2022 18:45:26 - INFO - __main__ - Global step 2900 Train loss 1.77 Classification-F1 0.01800720288115246 on epoch=207
05/29/2022 18:45:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.62 on epoch=207
05/29/2022 18:45:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.79 on epoch=208
05/29/2022 18:45:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.67 on epoch=209
05/29/2022 18:45:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.71 on epoch=209
05/29/2022 18:45:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.68 on epoch=210
05/29/2022 18:45:35 - INFO - __main__ - Global step 2950 Train loss 1.69 Classification-F1 0.04142420226812241 on epoch=210
05/29/2022 18:45:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.69 on epoch=211
05/29/2022 18:45:37 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.84 on epoch=212
05/29/2022 18:45:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.76 on epoch=212
05/29/2022 18:45:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.77 on epoch=213
05/29/2022 18:45:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.77 on epoch=214
05/29/2022 18:45:42 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:45:42 - INFO - __main__ - Printing 3 examples
05/29/2022 18:45:42 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 18:45:42 - INFO - __main__ - ['Animal']
05/29/2022 18:45:42 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 18:45:42 - INFO - __main__ - ['Animal']
05/29/2022 18:45:42 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 18:45:42 - INFO - __main__ - ['Animal']
05/29/2022 18:45:42 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:45:42 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:45:42 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:45:42 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:45:42 - INFO - __main__ - Printing 3 examples
05/29/2022 18:45:42 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 18:45:42 - INFO - __main__ - ['Animal']
05/29/2022 18:45:42 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 18:45:42 - INFO - __main__ - ['Animal']
05/29/2022 18:45:42 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 18:45:42 - INFO - __main__ - ['Animal']
05/29/2022 18:45:42 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:45:43 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:45:43 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:45:43 - INFO - __main__ - Global step 3000 Train loss 1.77 Classification-F1 0.01804772541928164 on epoch=214
05/29/2022 18:45:43 - INFO - __main__ - save last model!
05/29/2022 18:45:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 18:45:43 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 18:45:43 - INFO - __main__ - Printing 3 examples
05/29/2022 18:45:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 18:45:43 - INFO - __main__ - ['Animal']
05/29/2022 18:45:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 18:45:43 - INFO - __main__ - ['Animal']
05/29/2022 18:45:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 18:45:43 - INFO - __main__ - ['Village']
05/29/2022 18:45:43 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:45:45 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:45:48 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:45:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:45:48 - INFO - __main__ - Starting training!
05/29/2022 18:45:49 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 18:46:26 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/29/2022 18:46:26 - INFO - __main__ - Classification-F1 on test data: 0.0106
05/29/2022 18:46:26 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.060031803579098666, test_performance=0.010601200001071525
05/29/2022 18:46:27 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/29/2022 18:46:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:46:27 - INFO - __main__ - Printing 3 examples
05/29/2022 18:46:27 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 18:46:27 - INFO - __main__ - ['Animal']
05/29/2022 18:46:27 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 18:46:27 - INFO - __main__ - ['Animal']
05/29/2022 18:46:27 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 18:46:27 - INFO - __main__ - ['Animal']
05/29/2022 18:46:27 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:46:28 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:46:28 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:46:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:46:28 - INFO - __main__ - Printing 3 examples
05/29/2022 18:46:28 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 18:46:28 - INFO - __main__ - ['Animal']
05/29/2022 18:46:28 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 18:46:28 - INFO - __main__ - ['Animal']
05/29/2022 18:46:28 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 18:46:28 - INFO - __main__ - ['Animal']
05/29/2022 18:46:28 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:46:28 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:46:28 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:46:34 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:46:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:46:34 - INFO - __main__ - Starting training!
05/29/2022 18:46:36 - INFO - __main__ - Step 10 Global step 10 Train loss 7.41 on epoch=0
05/29/2022 18:46:37 - INFO - __main__ - Step 20 Global step 20 Train loss 7.46 on epoch=1
05/29/2022 18:46:39 - INFO - __main__ - Step 30 Global step 30 Train loss 7.09 on epoch=2
05/29/2022 18:46:40 - INFO - __main__ - Step 40 Global step 40 Train loss 6.98 on epoch=2
05/29/2022 18:46:41 - INFO - __main__ - Step 50 Global step 50 Train loss 6.86 on epoch=3
05/29/2022 18:47:06 - INFO - __main__ - Global step 50 Train loss 7.16 Classification-F1 0.0 on epoch=3
05/29/2022 18:47:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 18:47:07 - INFO - __main__ - Step 60 Global step 60 Train loss 6.86 on epoch=4
05/29/2022 18:47:09 - INFO - __main__ - Step 70 Global step 70 Train loss 6.79 on epoch=4
05/29/2022 18:47:10 - INFO - __main__ - Step 80 Global step 80 Train loss 6.50 on epoch=5
05/29/2022 18:47:11 - INFO - __main__ - Step 90 Global step 90 Train loss 6.58 on epoch=6
05/29/2022 18:47:12 - INFO - __main__ - Step 100 Global step 100 Train loss 6.51 on epoch=7
05/29/2022 18:48:19 - INFO - __main__ - Global step 100 Train loss 6.65 Classification-F1 0.0 on epoch=7
05/29/2022 18:48:20 - INFO - __main__ - Step 110 Global step 110 Train loss 6.40 on epoch=7
05/29/2022 18:48:21 - INFO - __main__ - Step 120 Global step 120 Train loss 6.30 on epoch=8
05/29/2022 18:48:22 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/29/2022 18:48:24 - INFO - __main__ - Step 140 Global step 140 Train loss 6.27 on epoch=9
05/29/2022 18:48:25 - INFO - __main__ - Step 150 Global step 150 Train loss 5.96 on epoch=10
05/29/2022 18:49:37 - INFO - __main__ - Global step 150 Train loss 6.26 Classification-F1 0.0 on epoch=10
05/29/2022 18:49:38 - INFO - __main__ - Step 160 Global step 160 Train loss 6.31 on epoch=11
05/29/2022 18:49:40 - INFO - __main__ - Step 170 Global step 170 Train loss 6.02 on epoch=12
05/29/2022 18:49:41 - INFO - __main__ - Step 180 Global step 180 Train loss 5.85 on epoch=12
05/29/2022 18:49:42 - INFO - __main__ - Step 190 Global step 190 Train loss 5.84 on epoch=13
05/29/2022 18:49:44 - INFO - __main__ - Step 200 Global step 200 Train loss 5.98 on epoch=14
05/29/2022 18:50:54 - INFO - __main__ - Global step 200 Train loss 6.00 Classification-F1 0.0 on epoch=14
05/29/2022 18:50:55 - INFO - __main__ - Step 210 Global step 210 Train loss 5.86 on epoch=14
05/29/2022 18:50:56 - INFO - __main__ - Step 220 Global step 220 Train loss 5.49 on epoch=15
05/29/2022 18:50:57 - INFO - __main__ - Step 230 Global step 230 Train loss 5.74 on epoch=16
05/29/2022 18:50:59 - INFO - __main__ - Step 240 Global step 240 Train loss 5.50 on epoch=17
05/29/2022 18:51:00 - INFO - __main__ - Step 250 Global step 250 Train loss 5.51 on epoch=17
05/29/2022 18:51:28 - INFO - __main__ - Global step 250 Train loss 5.62 Classification-F1 0.0019157088122605363 on epoch=17
05/29/2022 18:51:28 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0019157088122605363 on epoch=17, global_step=250
05/29/2022 18:51:29 - INFO - __main__ - Step 260 Global step 260 Train loss 5.37 on epoch=18
05/29/2022 18:51:30 - INFO - __main__ - Step 270 Global step 270 Train loss 5.54 on epoch=19
05/29/2022 18:51:31 - INFO - __main__ - Step 280 Global step 280 Train loss 5.62 on epoch=19
05/29/2022 18:51:33 - INFO - __main__ - Step 290 Global step 290 Train loss 5.30 on epoch=20
05/29/2022 18:51:34 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/29/2022 18:51:51 - INFO - __main__ - Global step 300 Train loss 5.45 Classification-F1 0.0037993920972644382 on epoch=21
05/29/2022 18:51:51 - INFO - __main__ - Saving model with best Classification-F1: 0.0019157088122605363 -> 0.0037993920972644382 on epoch=21, global_step=300
05/29/2022 18:51:52 - INFO - __main__ - Step 310 Global step 310 Train loss 5.30 on epoch=22
05/29/2022 18:51:53 - INFO - __main__ - Step 320 Global step 320 Train loss 5.25 on epoch=22
05/29/2022 18:51:55 - INFO - __main__ - Step 330 Global step 330 Train loss 5.18 on epoch=23
05/29/2022 18:51:56 - INFO - __main__ - Step 340 Global step 340 Train loss 5.22 on epoch=24
05/29/2022 18:51:57 - INFO - __main__ - Step 350 Global step 350 Train loss 5.04 on epoch=24
05/29/2022 18:52:05 - INFO - __main__ - Global step 350 Train loss 5.20 Classification-F1 0.008695652173913044 on epoch=24
05/29/2022 18:52:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0037993920972644382 -> 0.008695652173913044 on epoch=24, global_step=350
05/29/2022 18:52:06 - INFO - __main__ - Step 360 Global step 360 Train loss 4.77 on epoch=25
05/29/2022 18:52:07 - INFO - __main__ - Step 370 Global step 370 Train loss 5.00 on epoch=26
05/29/2022 18:52:08 - INFO - __main__ - Step 380 Global step 380 Train loss 4.96 on epoch=27
05/29/2022 18:52:10 - INFO - __main__ - Step 390 Global step 390 Train loss 4.81 on epoch=27
05/29/2022 18:52:11 - INFO - __main__ - Step 400 Global step 400 Train loss 4.80 on epoch=28
05/29/2022 18:52:19 - INFO - __main__ - Global step 400 Train loss 4.87 Classification-F1 0.008658008658008658 on epoch=28
05/29/2022 18:52:20 - INFO - __main__ - Step 410 Global step 410 Train loss 4.80 on epoch=29
05/29/2022 18:52:21 - INFO - __main__ - Step 420 Global step 420 Train loss 4.80 on epoch=29
05/29/2022 18:52:22 - INFO - __main__ - Step 430 Global step 430 Train loss 4.71 on epoch=30
05/29/2022 18:52:23 - INFO - __main__ - Step 440 Global step 440 Train loss 4.72 on epoch=31
05/29/2022 18:52:25 - INFO - __main__ - Step 450 Global step 450 Train loss 4.77 on epoch=32
05/29/2022 18:52:27 - INFO - __main__ - Global step 450 Train loss 4.76 Classification-F1 0.009523809523809523 on epoch=32
05/29/2022 18:52:27 - INFO - __main__ - Saving model with best Classification-F1: 0.008695652173913044 -> 0.009523809523809523 on epoch=32, global_step=450
05/29/2022 18:52:28 - INFO - __main__ - Step 460 Global step 460 Train loss 4.44 on epoch=32
05/29/2022 18:52:29 - INFO - __main__ - Step 470 Global step 470 Train loss 4.66 on epoch=33
05/29/2022 18:52:30 - INFO - __main__ - Step 480 Global step 480 Train loss 4.44 on epoch=34
05/29/2022 18:52:32 - INFO - __main__ - Step 490 Global step 490 Train loss 4.52 on epoch=34
05/29/2022 18:52:33 - INFO - __main__ - Step 500 Global step 500 Train loss 4.23 on epoch=35
05/29/2022 18:52:35 - INFO - __main__ - Global step 500 Train loss 4.46 Classification-F1 0.009523809523809523 on epoch=35
05/29/2022 18:52:36 - INFO - __main__ - Step 510 Global step 510 Train loss 4.35 on epoch=36
05/29/2022 18:52:37 - INFO - __main__ - Step 520 Global step 520 Train loss 4.39 on epoch=37
05/29/2022 18:52:38 - INFO - __main__ - Step 530 Global step 530 Train loss 4.21 on epoch=37
05/29/2022 18:52:40 - INFO - __main__ - Step 540 Global step 540 Train loss 4.21 on epoch=38
05/29/2022 18:52:41 - INFO - __main__ - Step 550 Global step 550 Train loss 4.08 on epoch=39
05/29/2022 18:52:43 - INFO - __main__ - Global step 550 Train loss 4.25 Classification-F1 0.013888762148104212 on epoch=39
05/29/2022 18:52:43 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.013888762148104212 on epoch=39, global_step=550
05/29/2022 18:52:44 - INFO - __main__ - Step 560 Global step 560 Train loss 4.16 on epoch=39
05/29/2022 18:52:45 - INFO - __main__ - Step 570 Global step 570 Train loss 3.98 on epoch=40
05/29/2022 18:52:46 - INFO - __main__ - Step 580 Global step 580 Train loss 3.97 on epoch=41
05/29/2022 18:52:48 - INFO - __main__ - Step 590 Global step 590 Train loss 4.03 on epoch=42
05/29/2022 18:52:49 - INFO - __main__ - Step 600 Global step 600 Train loss 3.78 on epoch=42
05/29/2022 18:52:51 - INFO - __main__ - Global step 600 Train loss 3.99 Classification-F1 0.014366007682124954 on epoch=42
05/29/2022 18:52:51 - INFO - __main__ - Saving model with best Classification-F1: 0.013888762148104212 -> 0.014366007682124954 on epoch=42, global_step=600
05/29/2022 18:52:52 - INFO - __main__ - Step 610 Global step 610 Train loss 3.96 on epoch=43
05/29/2022 18:52:53 - INFO - __main__ - Step 620 Global step 620 Train loss 3.75 on epoch=44
05/29/2022 18:52:54 - INFO - __main__ - Step 630 Global step 630 Train loss 3.87 on epoch=44
05/29/2022 18:52:56 - INFO - __main__ - Step 640 Global step 640 Train loss 3.72 on epoch=45
05/29/2022 18:52:57 - INFO - __main__ - Step 650 Global step 650 Train loss 3.85 on epoch=46
05/29/2022 18:52:59 - INFO - __main__ - Global step 650 Train loss 3.83 Classification-F1 0.01900200021054848 on epoch=46
05/29/2022 18:52:59 - INFO - __main__ - Saving model with best Classification-F1: 0.014366007682124954 -> 0.01900200021054848 on epoch=46, global_step=650
05/29/2022 18:53:00 - INFO - __main__ - Step 660 Global step 660 Train loss 3.83 on epoch=47
05/29/2022 18:53:01 - INFO - __main__ - Step 670 Global step 670 Train loss 3.52 on epoch=47
05/29/2022 18:53:02 - INFO - __main__ - Step 680 Global step 680 Train loss 3.68 on epoch=48
05/29/2022 18:53:04 - INFO - __main__ - Step 690 Global step 690 Train loss 3.69 on epoch=49
05/29/2022 18:53:05 - INFO - __main__ - Step 700 Global step 700 Train loss 3.71 on epoch=49
05/29/2022 18:53:07 - INFO - __main__ - Global step 700 Train loss 3.69 Classification-F1 0.009726443768996961 on epoch=49
05/29/2022 18:53:08 - INFO - __main__ - Step 710 Global step 710 Train loss 3.65 on epoch=50
05/29/2022 18:53:09 - INFO - __main__ - Step 720 Global step 720 Train loss 3.66 on epoch=51
05/29/2022 18:53:10 - INFO - __main__ - Step 730 Global step 730 Train loss 3.66 on epoch=52
05/29/2022 18:53:12 - INFO - __main__ - Step 740 Global step 740 Train loss 3.52 on epoch=52
05/29/2022 18:53:13 - INFO - __main__ - Step 750 Global step 750 Train loss 3.61 on epoch=53
05/29/2022 18:53:15 - INFO - __main__ - Global step 750 Train loss 3.62 Classification-F1 0.022755022755022756 on epoch=53
05/29/2022 18:53:15 - INFO - __main__ - Saving model with best Classification-F1: 0.01900200021054848 -> 0.022755022755022756 on epoch=53, global_step=750
05/29/2022 18:53:16 - INFO - __main__ - Step 760 Global step 760 Train loss 3.46 on epoch=54
05/29/2022 18:53:17 - INFO - __main__ - Step 770 Global step 770 Train loss 3.54 on epoch=54
05/29/2022 18:53:18 - INFO - __main__ - Step 780 Global step 780 Train loss 3.35 on epoch=55
05/29/2022 18:53:20 - INFO - __main__ - Step 790 Global step 790 Train loss 3.33 on epoch=56
05/29/2022 18:53:21 - INFO - __main__ - Step 800 Global step 800 Train loss 3.63 on epoch=57
05/29/2022 18:53:23 - INFO - __main__ - Global step 800 Train loss 3.46 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 18:53:24 - INFO - __main__ - Step 810 Global step 810 Train loss 3.30 on epoch=57
05/29/2022 18:53:25 - INFO - __main__ - Step 820 Global step 820 Train loss 3.34 on epoch=58
05/29/2022 18:53:26 - INFO - __main__ - Step 830 Global step 830 Train loss 3.37 on epoch=59
05/29/2022 18:53:28 - INFO - __main__ - Step 840 Global step 840 Train loss 3.28 on epoch=59
05/29/2022 18:53:29 - INFO - __main__ - Step 850 Global step 850 Train loss 3.20 on epoch=60
05/29/2022 18:53:31 - INFO - __main__ - Global step 850 Train loss 3.30 Classification-F1 0.010342598577892695 on epoch=60
05/29/2022 18:53:32 - INFO - __main__ - Step 860 Global step 860 Train loss 3.17 on epoch=61
05/29/2022 18:53:33 - INFO - __main__ - Step 870 Global step 870 Train loss 3.31 on epoch=62
05/29/2022 18:53:34 - INFO - __main__ - Step 880 Global step 880 Train loss 3.21 on epoch=62
05/29/2022 18:53:36 - INFO - __main__ - Step 890 Global step 890 Train loss 3.22 on epoch=63
05/29/2022 18:53:37 - INFO - __main__ - Step 900 Global step 900 Train loss 3.25 on epoch=64
05/29/2022 18:53:39 - INFO - __main__ - Global step 900 Train loss 3.23 Classification-F1 0.027015437392795882 on epoch=64
05/29/2022 18:53:39 - INFO - __main__ - Saving model with best Classification-F1: 0.022755022755022756 -> 0.027015437392795882 on epoch=64, global_step=900
05/29/2022 18:53:40 - INFO - __main__ - Step 910 Global step 910 Train loss 3.23 on epoch=64
05/29/2022 18:53:41 - INFO - __main__ - Step 920 Global step 920 Train loss 2.98 on epoch=65
05/29/2022 18:53:42 - INFO - __main__ - Step 930 Global step 930 Train loss 3.14 on epoch=66
05/29/2022 18:53:44 - INFO - __main__ - Step 940 Global step 940 Train loss 3.43 on epoch=67
05/29/2022 18:53:45 - INFO - __main__ - Step 950 Global step 950 Train loss 3.11 on epoch=67
05/29/2022 18:53:47 - INFO - __main__ - Global step 950 Train loss 3.18 Classification-F1 0.009523809523809523 on epoch=67
05/29/2022 18:53:48 - INFO - __main__ - Step 960 Global step 960 Train loss 3.02 on epoch=68
05/29/2022 18:53:49 - INFO - __main__ - Step 970 Global step 970 Train loss 3.09 on epoch=69
05/29/2022 18:53:51 - INFO - __main__ - Step 980 Global step 980 Train loss 3.19 on epoch=69
05/29/2022 18:53:52 - INFO - __main__ - Step 990 Global step 990 Train loss 3.00 on epoch=70
05/29/2022 18:53:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.00 on epoch=71
05/29/2022 18:53:55 - INFO - __main__ - Global step 1000 Train loss 3.06 Classification-F1 0.05026372121545007 on epoch=71
05/29/2022 18:53:55 - INFO - __main__ - Saving model with best Classification-F1: 0.027015437392795882 -> 0.05026372121545007 on epoch=71, global_step=1000
05/29/2022 18:53:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.25 on epoch=72
05/29/2022 18:53:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.95 on epoch=72
05/29/2022 18:53:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.04 on epoch=73
05/29/2022 18:54:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.95 on epoch=74
05/29/2022 18:54:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.98 on epoch=74
05/29/2022 18:54:03 - INFO - __main__ - Global step 1050 Train loss 3.03 Classification-F1 0.04220175308400969 on epoch=74
05/29/2022 18:54:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.86 on epoch=75
05/29/2022 18:54:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.91 on epoch=76
05/29/2022 18:54:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.11 on epoch=77
05/29/2022 18:54:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.76 on epoch=77
05/29/2022 18:54:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.85 on epoch=78
05/29/2022 18:54:11 - INFO - __main__ - Global step 1100 Train loss 2.90 Classification-F1 0.04597517464338154 on epoch=78
05/29/2022 18:54:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.94 on epoch=79
05/29/2022 18:54:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.99 on epoch=79
05/29/2022 18:54:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.93 on epoch=80
05/29/2022 18:54:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.83 on epoch=81
05/29/2022 18:54:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.01 on epoch=82
05/29/2022 18:54:19 - INFO - __main__ - Global step 1150 Train loss 2.94 Classification-F1 0.038212094653812444 on epoch=82
05/29/2022 18:54:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.86 on epoch=82
05/29/2022 18:54:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.82 on epoch=83
05/29/2022 18:54:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.72 on epoch=84
05/29/2022 18:54:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.87 on epoch=84
05/29/2022 18:54:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.75 on epoch=85
05/29/2022 18:54:27 - INFO - __main__ - Global step 1200 Train loss 2.80 Classification-F1 0.021293236782902136 on epoch=85
05/29/2022 18:54:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.62 on epoch=86
05/29/2022 18:54:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.94 on epoch=87
05/29/2022 18:54:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.66 on epoch=87
05/29/2022 18:54:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.68 on epoch=88
05/29/2022 18:54:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.81 on epoch=89
05/29/2022 18:54:35 - INFO - __main__ - Global step 1250 Train loss 2.74 Classification-F1 0.01835419482478306 on epoch=89
05/29/2022 18:54:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.82 on epoch=89
05/29/2022 18:54:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.73 on epoch=90
05/29/2022 18:54:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.75 on epoch=91
05/29/2022 18:54:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.87 on epoch=92
05/29/2022 18:54:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.72 on epoch=92
05/29/2022 18:54:43 - INFO - __main__ - Global step 1300 Train loss 2.78 Classification-F1 0.05359660311493018 on epoch=92
05/29/2022 18:54:43 - INFO - __main__ - Saving model with best Classification-F1: 0.05026372121545007 -> 0.05359660311493018 on epoch=92, global_step=1300
05/29/2022 18:54:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.88 on epoch=93
05/29/2022 18:54:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.88 on epoch=94
05/29/2022 18:54:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.87 on epoch=94
05/29/2022 18:54:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.76 on epoch=95
05/29/2022 18:54:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.68 on epoch=96
05/29/2022 18:54:51 - INFO - __main__ - Global step 1350 Train loss 2.81 Classification-F1 0.05269536019536019 on epoch=96
05/29/2022 18:54:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.83 on epoch=97
05/29/2022 18:54:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.61 on epoch=97
05/29/2022 18:54:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.68 on epoch=98
05/29/2022 18:54:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.54 on epoch=99
05/29/2022 18:54:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.79 on epoch=99
05/29/2022 18:54:59 - INFO - __main__ - Global step 1400 Train loss 2.69 Classification-F1 0.02796451914098973 on epoch=99
05/29/2022 18:55:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.69 on epoch=100
05/29/2022 18:55:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.77 on epoch=101
05/29/2022 18:55:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.78 on epoch=102
05/29/2022 18:55:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.69 on epoch=102
05/29/2022 18:55:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.80 on epoch=103
05/29/2022 18:55:07 - INFO - __main__ - Global step 1450 Train loss 2.75 Classification-F1 0.04128609263787635 on epoch=103
05/29/2022 18:55:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.62 on epoch=104
05/29/2022 18:55:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.69 on epoch=104
05/29/2022 18:55:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.69 on epoch=105
05/29/2022 18:55:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.58 on epoch=106
05/29/2022 18:55:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.76 on epoch=107
05/29/2022 18:55:15 - INFO - __main__ - Global step 1500 Train loss 2.67 Classification-F1 0.016683433936955063 on epoch=107
05/29/2022 18:55:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.68 on epoch=107
05/29/2022 18:55:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.66 on epoch=108
05/29/2022 18:55:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.47 on epoch=109
05/29/2022 18:55:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=109
05/29/2022 18:55:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.62 on epoch=110
05/29/2022 18:55:23 - INFO - __main__ - Global step 1550 Train loss 2.60 Classification-F1 0.016495956873315364 on epoch=110
05/29/2022 18:55:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.53 on epoch=111
05/29/2022 18:55:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.50 on epoch=112
05/29/2022 18:55:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.56 on epoch=112
05/29/2022 18:55:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.67 on epoch=113
05/29/2022 18:55:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.72 on epoch=114
05/29/2022 18:55:32 - INFO - __main__ - Global step 1600 Train loss 2.60 Classification-F1 0.05855550246854594 on epoch=114
05/29/2022 18:55:32 - INFO - __main__ - Saving model with best Classification-F1: 0.05359660311493018 -> 0.05855550246854594 on epoch=114, global_step=1600
05/29/2022 18:55:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.75 on epoch=114
05/29/2022 18:55:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.41 on epoch=115
05/29/2022 18:55:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.42 on epoch=116
05/29/2022 18:55:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.52 on epoch=117
05/29/2022 18:55:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.60 on epoch=117
05/29/2022 18:55:40 - INFO - __main__ - Global step 1650 Train loss 2.54 Classification-F1 0.045989010989010995 on epoch=117
05/29/2022 18:55:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.55 on epoch=118
05/29/2022 18:55:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.63 on epoch=119
05/29/2022 18:55:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.62 on epoch=119
05/29/2022 18:55:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.48 on epoch=120
05/29/2022 18:55:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.46 on epoch=121
05/29/2022 18:55:48 - INFO - __main__ - Global step 1700 Train loss 2.55 Classification-F1 0.015653235653235655 on epoch=121
05/29/2022 18:55:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.69 on epoch=122
05/29/2022 18:55:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.42 on epoch=122
05/29/2022 18:55:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.47 on epoch=123
05/29/2022 18:55:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.45 on epoch=124
05/29/2022 18:55:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.52 on epoch=124
05/29/2022 18:55:56 - INFO - __main__ - Global step 1750 Train loss 2.51 Classification-F1 0.023436680764794295 on epoch=124
05/29/2022 18:55:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.39 on epoch=125
05/29/2022 18:55:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.63 on epoch=126
05/29/2022 18:56:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.55 on epoch=127
05/29/2022 18:56:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.65 on epoch=127
05/29/2022 18:56:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.39 on epoch=128
05/29/2022 18:56:04 - INFO - __main__ - Global step 1800 Train loss 2.52 Classification-F1 0.019892421011823997 on epoch=128
05/29/2022 18:56:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.44 on epoch=129
05/29/2022 18:56:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.54 on epoch=129
05/29/2022 18:56:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.50 on epoch=130
05/29/2022 18:56:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.29 on epoch=131
05/29/2022 18:56:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.50 on epoch=132
05/29/2022 18:56:13 - INFO - __main__ - Global step 1850 Train loss 2.45 Classification-F1 0.03524025556027518 on epoch=132
05/29/2022 18:56:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.24 on epoch=132
05/29/2022 18:56:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.30 on epoch=133
05/29/2022 18:56:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.31 on epoch=134
05/29/2022 18:56:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.41 on epoch=134
05/29/2022 18:56:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.31 on epoch=135
05/29/2022 18:56:21 - INFO - __main__ - Global step 1900 Train loss 2.32 Classification-F1 0.035707445321468724 on epoch=135
05/29/2022 18:56:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.35 on epoch=136
05/29/2022 18:56:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.47 on epoch=137
05/29/2022 18:56:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.35 on epoch=137
05/29/2022 18:56:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.49 on epoch=138
05/29/2022 18:56:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.47 on epoch=139
05/29/2022 18:56:29 - INFO - __main__ - Global step 1950 Train loss 2.43 Classification-F1 0.019965996774052926 on epoch=139
05/29/2022 18:56:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.44 on epoch=139
05/29/2022 18:56:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.33 on epoch=140
05/29/2022 18:56:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.29 on epoch=141
05/29/2022 18:56:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.38 on epoch=142
05/29/2022 18:56:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.22 on epoch=142
05/29/2022 18:56:37 - INFO - __main__ - Global step 2000 Train loss 2.33 Classification-F1 0.009523809523809523 on epoch=142
05/29/2022 18:56:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.23 on epoch=143
05/29/2022 18:56:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.41 on epoch=144
05/29/2022 18:56:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.36 on epoch=144
05/29/2022 18:56:42 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.39 on epoch=145
05/29/2022 18:56:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.40 on epoch=146
05/29/2022 18:56:45 - INFO - __main__ - Global step 2050 Train loss 2.36 Classification-F1 0.0401387914285009 on epoch=146
05/29/2022 18:56:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.16 on epoch=147
05/29/2022 18:56:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.26 on epoch=147
05/29/2022 18:56:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.21 on epoch=148
05/29/2022 18:56:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.30 on epoch=149
05/29/2022 18:56:51 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.28 on epoch=149
05/29/2022 18:56:53 - INFO - __main__ - Global step 2100 Train loss 2.24 Classification-F1 0.02457716701902748 on epoch=149
05/29/2022 18:56:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.20 on epoch=150
05/29/2022 18:56:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.19 on epoch=151
05/29/2022 18:56:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.47 on epoch=152
05/29/2022 18:56:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.40 on epoch=152
05/29/2022 18:57:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.16 on epoch=153
05/29/2022 18:57:01 - INFO - __main__ - Global step 2150 Train loss 2.28 Classification-F1 0.017371013741249674 on epoch=153
05/29/2022 18:57:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.29 on epoch=154
05/29/2022 18:57:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.26 on epoch=154
05/29/2022 18:57:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.30 on epoch=155
05/29/2022 18:57:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.26 on epoch=156
05/29/2022 18:57:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.33 on epoch=157
05/29/2022 18:57:10 - INFO - __main__ - Global step 2200 Train loss 2.29 Classification-F1 0.009852216748768473 on epoch=157
05/29/2022 18:57:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.20 on epoch=157
05/29/2022 18:57:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.24 on epoch=158
05/29/2022 18:57:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.25 on epoch=159
05/29/2022 18:57:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.30 on epoch=159
05/29/2022 18:57:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.30 on epoch=160
05/29/2022 18:57:18 - INFO - __main__ - Global step 2250 Train loss 2.26 Classification-F1 0.023715052598236166 on epoch=160
05/29/2022 18:57:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.21 on epoch=161
05/29/2022 18:57:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.30 on epoch=162
05/29/2022 18:57:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.14 on epoch=162
05/29/2022 18:57:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.17 on epoch=163
05/29/2022 18:57:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.22 on epoch=164
05/29/2022 18:57:26 - INFO - __main__ - Global step 2300 Train loss 2.21 Classification-F1 0.066307911535387 on epoch=164
05/29/2022 18:57:26 - INFO - __main__ - Saving model with best Classification-F1: 0.05855550246854594 -> 0.066307911535387 on epoch=164, global_step=2300
05/29/2022 18:57:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.35 on epoch=164
05/29/2022 18:57:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.17 on epoch=165
05/29/2022 18:57:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.18 on epoch=166
05/29/2022 18:57:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.21 on epoch=167
05/29/2022 18:57:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.00 on epoch=167
05/29/2022 18:57:34 - INFO - __main__ - Global step 2350 Train loss 2.18 Classification-F1 0.03553433630857859 on epoch=167
05/29/2022 18:57:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.10 on epoch=168
05/29/2022 18:57:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.17 on epoch=169
05/29/2022 18:57:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.14 on epoch=169
05/29/2022 18:57:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.20 on epoch=170
05/29/2022 18:57:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.96 on epoch=171
05/29/2022 18:57:42 - INFO - __main__ - Global step 2400 Train loss 2.11 Classification-F1 0.0472108710255262 on epoch=171
05/29/2022 18:57:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.24 on epoch=172
05/29/2022 18:57:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.17 on epoch=172
05/29/2022 18:57:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.18 on epoch=173
05/29/2022 18:57:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.07 on epoch=174
05/29/2022 18:57:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.16 on epoch=174
05/29/2022 18:57:50 - INFO - __main__ - Global step 2450 Train loss 2.16 Classification-F1 0.04377074341301089 on epoch=174
05/29/2022 18:57:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.01 on epoch=175
05/29/2022 18:57:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.09 on epoch=176
05/29/2022 18:57:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.08 on epoch=177
05/29/2022 18:57:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.05 on epoch=177
05/29/2022 18:57:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.20 on epoch=178
05/29/2022 18:57:59 - INFO - __main__ - Global step 2500 Train loss 2.09 Classification-F1 0.02943967060508414 on epoch=178
05/29/2022 18:58:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.14 on epoch=179
05/29/2022 18:58:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.15 on epoch=179
05/29/2022 18:58:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.11 on epoch=180
05/29/2022 18:58:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.05 on epoch=181
05/29/2022 18:58:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.10 on epoch=182
05/29/2022 18:58:07 - INFO - __main__ - Global step 2550 Train loss 2.11 Classification-F1 0.061005356199864205 on epoch=182
05/29/2022 18:58:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.02 on epoch=182
05/29/2022 18:58:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.06 on epoch=183
05/29/2022 18:58:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.10 on epoch=184
05/29/2022 18:58:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.10 on epoch=184
05/29/2022 18:58:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.97 on epoch=185
05/29/2022 18:58:14 - INFO - __main__ - Global step 2600 Train loss 2.05 Classification-F1 0.02266225639191847 on epoch=185
05/29/2022 18:58:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.13 on epoch=186
05/29/2022 18:58:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.23 on epoch=187
05/29/2022 18:58:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.16 on epoch=187
05/29/2022 18:58:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.08 on epoch=188
05/29/2022 18:58:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.19 on epoch=189
05/29/2022 18:58:22 - INFO - __main__ - Global step 2650 Train loss 2.16 Classification-F1 0.043887626552153045 on epoch=189
05/29/2022 18:58:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.11 on epoch=189
05/29/2022 18:58:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.91 on epoch=190
05/29/2022 18:58:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.93 on epoch=191
05/29/2022 18:58:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.00 on epoch=192
05/29/2022 18:58:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.04 on epoch=192
05/29/2022 18:58:30 - INFO - __main__ - Global step 2700 Train loss 2.00 Classification-F1 0.04007709954210692 on epoch=192
05/29/2022 18:58:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.07 on epoch=193
05/29/2022 18:58:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.04 on epoch=194
05/29/2022 18:58:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.08 on epoch=194
05/29/2022 18:58:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.97 on epoch=195
05/29/2022 18:58:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.99 on epoch=196
05/29/2022 18:58:38 - INFO - __main__ - Global step 2750 Train loss 2.03 Classification-F1 0.0347377660741716 on epoch=196
05/29/2022 18:58:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.12 on epoch=197
05/29/2022 18:58:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.85 on epoch=197
05/29/2022 18:58:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.03 on epoch=198
05/29/2022 18:58:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.03 on epoch=199
05/29/2022 18:58:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.09 on epoch=199
05/29/2022 18:58:46 - INFO - __main__ - Global step 2800 Train loss 2.02 Classification-F1 0.0401556097125957 on epoch=199
05/29/2022 18:58:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.95 on epoch=200
05/29/2022 18:58:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.89 on epoch=201
05/29/2022 18:58:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.07 on epoch=202
05/29/2022 18:58:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.93 on epoch=202
05/29/2022 18:58:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.92 on epoch=203
05/29/2022 18:58:54 - INFO - __main__ - Global step 2850 Train loss 1.95 Classification-F1 0.0336038961038961 on epoch=203
05/29/2022 18:58:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.90 on epoch=204
05/29/2022 18:58:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.09 on epoch=204
05/29/2022 18:58:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.03 on epoch=205
05/29/2022 18:58:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.96 on epoch=206
05/29/2022 18:59:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.85 on epoch=207
05/29/2022 18:59:02 - INFO - __main__ - Global step 2900 Train loss 1.97 Classification-F1 0.02634920634920635 on epoch=207
05/29/2022 18:59:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.00 on epoch=207
05/29/2022 18:59:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.93 on epoch=208
05/29/2022 18:59:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.90 on epoch=209
05/29/2022 18:59:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.00 on epoch=209
05/29/2022 18:59:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.03 on epoch=210
05/29/2022 18:59:10 - INFO - __main__ - Global step 2950 Train loss 1.97 Classification-F1 0.029290452037233152 on epoch=210
05/29/2022 18:59:12 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.86 on epoch=211
05/29/2022 18:59:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.92 on epoch=212
05/29/2022 18:59:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.85 on epoch=212
05/29/2022 18:59:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.83 on epoch=213
05/29/2022 18:59:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.99 on epoch=214
05/29/2022 18:59:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:59:18 - INFO - __main__ - Printing 3 examples
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:59:18 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:59:18 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:59:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:59:18 - INFO - __main__ - Printing 3 examples
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:59:18 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:59:18 - INFO - __main__ - Global step 3000 Train loss 1.89 Classification-F1 0.009726443768996961 on epoch=214
05/29/2022 18:59:18 - INFO - __main__ - save last model!
05/29/2022 18:59:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 18:59:18 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 18:59:18 - INFO - __main__ - Printing 3 examples
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 18:59:18 - INFO - __main__ - ['Animal']
05/29/2022 18:59:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 18:59:18 - INFO - __main__ - ['Village']
05/29/2022 18:59:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:59:18 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 18:59:20 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:59:24 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 18:59:24 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 18:59:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 18:59:25 - INFO - __main__ - Starting training!
05/29/2022 18:59:54 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/29/2022 18:59:54 - INFO - __main__ - Classification-F1 on test data: 0.0160
05/29/2022 18:59:54 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.066307911535387, test_performance=0.016044697001440494
05/29/2022 18:59:54 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/29/2022 18:59:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:59:55 - INFO - __main__ - Printing 3 examples
05/29/2022 18:59:55 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 18:59:55 - INFO - __main__ - ['Animal']
05/29/2022 18:59:55 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 18:59:55 - INFO - __main__ - ['Animal']
05/29/2022 18:59:55 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 18:59:55 - INFO - __main__ - ['Animal']
05/29/2022 18:59:55 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:59:55 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:59:55 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 18:59:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 18:59:55 - INFO - __main__ - Printing 3 examples
05/29/2022 18:59:55 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 18:59:55 - INFO - __main__ - ['Animal']
05/29/2022 18:59:55 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 18:59:55 - INFO - __main__ - ['Animal']
05/29/2022 18:59:55 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 18:59:55 - INFO - __main__ - ['Animal']
05/29/2022 18:59:55 - INFO - __main__ - Tokenizing Input ...
05/29/2022 18:59:55 - INFO - __main__ - Tokenizing Output ...
05/29/2022 18:59:55 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:00:01 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:00:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:00:02 - INFO - __main__ - Starting training!
05/29/2022 19:00:03 - INFO - __main__ - Step 10 Global step 10 Train loss 7.07 on epoch=0
05/29/2022 19:00:04 - INFO - __main__ - Step 20 Global step 20 Train loss 7.55 on epoch=1
05/29/2022 19:00:06 - INFO - __main__ - Step 30 Global step 30 Train loss 7.25 on epoch=2
05/29/2022 19:00:07 - INFO - __main__ - Step 40 Global step 40 Train loss 7.14 on epoch=2
05/29/2022 19:00:08 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/29/2022 19:00:18 - INFO - __main__ - Global step 50 Train loss 7.22 Classification-F1 0.0 on epoch=3
05/29/2022 19:00:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 19:00:19 - INFO - __main__ - Step 60 Global step 60 Train loss 7.20 on epoch=4
05/29/2022 19:00:21 - INFO - __main__ - Step 70 Global step 70 Train loss 7.16 on epoch=4
05/29/2022 19:00:22 - INFO - __main__ - Step 80 Global step 80 Train loss 6.73 on epoch=5
05/29/2022 19:00:23 - INFO - __main__ - Step 90 Global step 90 Train loss 7.00 on epoch=6
05/29/2022 19:00:24 - INFO - __main__ - Step 100 Global step 100 Train loss 6.76 on epoch=7
05/29/2022 19:01:00 - INFO - __main__ - Global step 100 Train loss 6.97 Classification-F1 0.0 on epoch=7
05/29/2022 19:01:01 - INFO - __main__ - Step 110 Global step 110 Train loss 6.71 on epoch=7
05/29/2022 19:01:02 - INFO - __main__ - Step 120 Global step 120 Train loss 6.64 on epoch=8
05/29/2022 19:01:03 - INFO - __main__ - Step 130 Global step 130 Train loss 6.80 on epoch=9
05/29/2022 19:01:05 - INFO - __main__ - Step 140 Global step 140 Train loss 6.68 on epoch=9
05/29/2022 19:01:06 - INFO - __main__ - Step 150 Global step 150 Train loss 6.34 on epoch=10
05/29/2022 19:02:13 - INFO - __main__ - Global step 150 Train loss 6.63 Classification-F1 0.0 on epoch=10
05/29/2022 19:02:15 - INFO - __main__ - Step 160 Global step 160 Train loss 6.55 on epoch=11
05/29/2022 19:02:16 - INFO - __main__ - Step 170 Global step 170 Train loss 6.28 on epoch=12
05/29/2022 19:02:17 - INFO - __main__ - Step 180 Global step 180 Train loss 6.35 on epoch=12
05/29/2022 19:02:18 - INFO - __main__ - Step 190 Global step 190 Train loss 6.28 on epoch=13
05/29/2022 19:02:20 - INFO - __main__ - Step 200 Global step 200 Train loss 6.41 on epoch=14
05/29/2022 19:03:18 - INFO - __main__ - Global step 200 Train loss 6.38 Classification-F1 0.0 on epoch=14
05/29/2022 19:03:19 - INFO - __main__ - Step 210 Global step 210 Train loss 6.34 on epoch=14
05/29/2022 19:03:20 - INFO - __main__ - Step 220 Global step 220 Train loss 6.07 on epoch=15
05/29/2022 19:03:22 - INFO - __main__ - Step 230 Global step 230 Train loss 6.32 on epoch=16
05/29/2022 19:03:23 - INFO - __main__ - Step 240 Global step 240 Train loss 6.12 on epoch=17
05/29/2022 19:03:24 - INFO - __main__ - Step 250 Global step 250 Train loss 6.07 on epoch=17
05/29/2022 19:04:22 - INFO - __main__ - Global step 250 Train loss 6.18 Classification-F1 0.0 on epoch=17
05/29/2022 19:04:23 - INFO - __main__ - Step 260 Global step 260 Train loss 5.99 on epoch=18
05/29/2022 19:04:25 - INFO - __main__ - Step 270 Global step 270 Train loss 6.14 on epoch=19
05/29/2022 19:04:26 - INFO - __main__ - Step 280 Global step 280 Train loss 6.20 on epoch=19
05/29/2022 19:04:27 - INFO - __main__ - Step 290 Global step 290 Train loss 5.90 on epoch=20
05/29/2022 19:04:28 - INFO - __main__ - Step 300 Global step 300 Train loss 6.08 on epoch=21
05/29/2022 19:05:20 - INFO - __main__ - Global step 300 Train loss 6.06 Classification-F1 0.0 on epoch=21
05/29/2022 19:05:22 - INFO - __main__ - Step 310 Global step 310 Train loss 5.98 on epoch=22
05/29/2022 19:05:23 - INFO - __main__ - Step 320 Global step 320 Train loss 5.87 on epoch=22
05/29/2022 19:05:24 - INFO - __main__ - Step 330 Global step 330 Train loss 5.85 on epoch=23
05/29/2022 19:05:25 - INFO - __main__ - Step 340 Global step 340 Train loss 5.86 on epoch=24
05/29/2022 19:05:27 - INFO - __main__ - Step 350 Global step 350 Train loss 5.83 on epoch=24
05/29/2022 19:06:04 - INFO - __main__ - Global step 350 Train loss 5.88 Classification-F1 0.0 on epoch=24
05/29/2022 19:06:06 - INFO - __main__ - Step 360 Global step 360 Train loss 5.63 on epoch=25
05/29/2022 19:06:07 - INFO - __main__ - Step 370 Global step 370 Train loss 5.71 on epoch=26
05/29/2022 19:06:08 - INFO - __main__ - Step 380 Global step 380 Train loss 5.62 on epoch=27
05/29/2022 19:06:09 - INFO - __main__ - Step 390 Global step 390 Train loss 5.48 on epoch=27
05/29/2022 19:06:11 - INFO - __main__ - Step 400 Global step 400 Train loss 5.54 on epoch=28
05/29/2022 19:06:32 - INFO - __main__ - Global step 400 Train loss 5.60 Classification-F1 0.0 on epoch=28
05/29/2022 19:06:33 - INFO - __main__ - Step 410 Global step 410 Train loss 5.64 on epoch=29
05/29/2022 19:06:34 - INFO - __main__ - Step 420 Global step 420 Train loss 5.63 on epoch=29
05/29/2022 19:06:36 - INFO - __main__ - Step 430 Global step 430 Train loss 5.47 on epoch=30
05/29/2022 19:06:37 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=31
05/29/2022 19:06:38 - INFO - __main__ - Step 450 Global step 450 Train loss 5.41 on epoch=32
05/29/2022 19:06:43 - INFO - __main__ - Global step 450 Train loss 5.55 Classification-F1 0.0052417006406523005 on epoch=32
05/29/2022 19:06:43 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0052417006406523005 on epoch=32, global_step=450
05/29/2022 19:06:45 - INFO - __main__ - Step 460 Global step 460 Train loss 5.36 on epoch=32
05/29/2022 19:06:46 - INFO - __main__ - Step 470 Global step 470 Train loss 5.42 on epoch=33
05/29/2022 19:06:47 - INFO - __main__ - Step 480 Global step 480 Train loss 5.34 on epoch=34
05/29/2022 19:06:49 - INFO - __main__ - Step 490 Global step 490 Train loss 5.44 on epoch=34
05/29/2022 19:06:50 - INFO - __main__ - Step 500 Global step 500 Train loss 5.02 on epoch=35
05/29/2022 19:07:11 - INFO - __main__ - Global step 500 Train loss 5.32 Classification-F1 0.006913580246913581 on epoch=35
05/29/2022 19:07:11 - INFO - __main__ - Saving model with best Classification-F1: 0.0052417006406523005 -> 0.006913580246913581 on epoch=35, global_step=500
05/29/2022 19:07:12 - INFO - __main__ - Step 510 Global step 510 Train loss 5.28 on epoch=36
05/29/2022 19:07:13 - INFO - __main__ - Step 520 Global step 520 Train loss 5.16 on epoch=37
05/29/2022 19:07:14 - INFO - __main__ - Step 530 Global step 530 Train loss 5.16 on epoch=37
05/29/2022 19:07:16 - INFO - __main__ - Step 540 Global step 540 Train loss 5.13 on epoch=38
05/29/2022 19:07:17 - INFO - __main__ - Step 550 Global step 550 Train loss 5.24 on epoch=39
05/29/2022 19:07:28 - INFO - __main__ - Global step 550 Train loss 5.19 Classification-F1 0.0071135430916552675 on epoch=39
05/29/2022 19:07:28 - INFO - __main__ - Saving model with best Classification-F1: 0.006913580246913581 -> 0.0071135430916552675 on epoch=39, global_step=550
05/29/2022 19:07:29 - INFO - __main__ - Step 560 Global step 560 Train loss 5.11 on epoch=39
05/29/2022 19:07:30 - INFO - __main__ - Step 570 Global step 570 Train loss 5.01 on epoch=40
05/29/2022 19:07:32 - INFO - __main__ - Step 580 Global step 580 Train loss 4.96 on epoch=41
05/29/2022 19:07:33 - INFO - __main__ - Step 590 Global step 590 Train loss 4.89 on epoch=42
05/29/2022 19:07:34 - INFO - __main__ - Step 600 Global step 600 Train loss 4.91 on epoch=42
05/29/2022 19:07:42 - INFO - __main__ - Global step 600 Train loss 4.97 Classification-F1 0.008849557522123895 on epoch=42
05/29/2022 19:07:42 - INFO - __main__ - Saving model with best Classification-F1: 0.0071135430916552675 -> 0.008849557522123895 on epoch=42, global_step=600
05/29/2022 19:07:44 - INFO - __main__ - Step 610 Global step 610 Train loss 4.86 on epoch=43
05/29/2022 19:07:45 - INFO - __main__ - Step 620 Global step 620 Train loss 4.79 on epoch=44
05/29/2022 19:07:46 - INFO - __main__ - Step 630 Global step 630 Train loss 4.81 on epoch=44
05/29/2022 19:07:47 - INFO - __main__ - Step 640 Global step 640 Train loss 4.78 on epoch=45
05/29/2022 19:07:49 - INFO - __main__ - Step 650 Global step 650 Train loss 4.75 on epoch=46
05/29/2022 19:07:51 - INFO - __main__ - Global step 650 Train loss 4.80 Classification-F1 0.009523809523809523 on epoch=46
05/29/2022 19:07:51 - INFO - __main__ - Saving model with best Classification-F1: 0.008849557522123895 -> 0.009523809523809523 on epoch=46, global_step=650
05/29/2022 19:07:52 - INFO - __main__ - Step 660 Global step 660 Train loss 4.64 on epoch=47
05/29/2022 19:07:54 - INFO - __main__ - Step 670 Global step 670 Train loss 4.49 on epoch=47
05/29/2022 19:07:55 - INFO - __main__ - Step 680 Global step 680 Train loss 4.61 on epoch=48
05/29/2022 19:07:56 - INFO - __main__ - Step 690 Global step 690 Train loss 4.52 on epoch=49
05/29/2022 19:07:57 - INFO - __main__ - Step 700 Global step 700 Train loss 4.73 on epoch=49
05/29/2022 19:08:00 - INFO - __main__ - Global step 700 Train loss 4.60 Classification-F1 0.039432362563755166 on epoch=49
05/29/2022 19:08:00 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.039432362563755166 on epoch=49, global_step=700
05/29/2022 19:08:01 - INFO - __main__ - Step 710 Global step 710 Train loss 4.32 on epoch=50
05/29/2022 19:08:02 - INFO - __main__ - Step 720 Global step 720 Train loss 4.55 on epoch=51
05/29/2022 19:08:04 - INFO - __main__ - Step 730 Global step 730 Train loss 4.39 on epoch=52
05/29/2022 19:08:05 - INFO - __main__ - Step 740 Global step 740 Train loss 4.24 on epoch=52
05/29/2022 19:08:06 - INFO - __main__ - Step 750 Global step 750 Train loss 4.30 on epoch=53
05/29/2022 19:08:13 - INFO - __main__ - Global step 750 Train loss 4.36 Classification-F1 0.02242063492063492 on epoch=53
05/29/2022 19:08:14 - INFO - __main__ - Step 760 Global step 760 Train loss 4.25 on epoch=54
05/29/2022 19:08:16 - INFO - __main__ - Step 770 Global step 770 Train loss 4.32 on epoch=54
05/29/2022 19:08:17 - INFO - __main__ - Step 780 Global step 780 Train loss 4.30 on epoch=55
05/29/2022 19:08:18 - INFO - __main__ - Step 790 Global step 790 Train loss 4.29 on epoch=56
05/29/2022 19:08:19 - INFO - __main__ - Step 800 Global step 800 Train loss 4.27 on epoch=57
05/29/2022 19:08:21 - INFO - __main__ - Global step 800 Train loss 4.29 Classification-F1 0.03304131889356419 on epoch=57
05/29/2022 19:08:23 - INFO - __main__ - Step 810 Global step 810 Train loss 4.10 on epoch=57
05/29/2022 19:08:24 - INFO - __main__ - Step 820 Global step 820 Train loss 4.19 on epoch=58
05/29/2022 19:08:25 - INFO - __main__ - Step 830 Global step 830 Train loss 4.21 on epoch=59
05/29/2022 19:08:26 - INFO - __main__ - Step 840 Global step 840 Train loss 4.33 on epoch=59
05/29/2022 19:08:28 - INFO - __main__ - Step 850 Global step 850 Train loss 4.08 on epoch=60
05/29/2022 19:08:29 - INFO - __main__ - Global step 850 Train loss 4.18 Classification-F1 0.022795082945458883 on epoch=60
05/29/2022 19:08:31 - INFO - __main__ - Step 860 Global step 860 Train loss 4.03 on epoch=61
05/29/2022 19:08:32 - INFO - __main__ - Step 870 Global step 870 Train loss 4.10 on epoch=62
05/29/2022 19:08:33 - INFO - __main__ - Step 880 Global step 880 Train loss 4.03 on epoch=62
05/29/2022 19:08:34 - INFO - __main__ - Step 890 Global step 890 Train loss 4.21 on epoch=63
05/29/2022 19:08:36 - INFO - __main__ - Step 900 Global step 900 Train loss 4.12 on epoch=64
05/29/2022 19:08:38 - INFO - __main__ - Global step 900 Train loss 4.10 Classification-F1 0.02463023701961755 on epoch=64
05/29/2022 19:08:39 - INFO - __main__ - Step 910 Global step 910 Train loss 4.09 on epoch=64
05/29/2022 19:08:40 - INFO - __main__ - Step 920 Global step 920 Train loss 4.03 on epoch=65
05/29/2022 19:08:41 - INFO - __main__ - Step 930 Global step 930 Train loss 4.04 on epoch=66
05/29/2022 19:08:43 - INFO - __main__ - Step 940 Global step 940 Train loss 4.16 on epoch=67
05/29/2022 19:08:44 - INFO - __main__ - Step 950 Global step 950 Train loss 4.01 on epoch=67
05/29/2022 19:08:46 - INFO - __main__ - Global step 950 Train loss 4.07 Classification-F1 0.009644364074743823 on epoch=67
05/29/2022 19:08:47 - INFO - __main__ - Step 960 Global step 960 Train loss 4.06 on epoch=68
05/29/2022 19:08:48 - INFO - __main__ - Step 970 Global step 970 Train loss 4.11 on epoch=69
05/29/2022 19:08:50 - INFO - __main__ - Step 980 Global step 980 Train loss 3.87 on epoch=69
05/29/2022 19:08:51 - INFO - __main__ - Step 990 Global step 990 Train loss 3.88 on epoch=70
05/29/2022 19:08:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.97 on epoch=71
05/29/2022 19:08:54 - INFO - __main__ - Global step 1000 Train loss 3.98 Classification-F1 0.02633573323228496 on epoch=71
05/29/2022 19:08:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.91 on epoch=72
05/29/2022 19:08:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.82 on epoch=72
05/29/2022 19:08:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.05 on epoch=73
05/29/2022 19:08:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.84 on epoch=74
05/29/2022 19:09:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.83 on epoch=74
05/29/2022 19:09:02 - INFO - __main__ - Global step 1050 Train loss 3.89 Classification-F1 0.040131068134059915 on epoch=74
05/29/2022 19:09:02 - INFO - __main__ - Saving model with best Classification-F1: 0.039432362563755166 -> 0.040131068134059915 on epoch=74, global_step=1050
05/29/2022 19:09:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.83 on epoch=75
05/29/2022 19:09:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.81 on epoch=76
05/29/2022 19:09:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.85 on epoch=77
05/29/2022 19:09:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.73 on epoch=77
05/29/2022 19:09:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.75 on epoch=78
05/29/2022 19:09:10 - INFO - __main__ - Global step 1100 Train loss 3.80 Classification-F1 0.0431586552475853 on epoch=78
05/29/2022 19:09:10 - INFO - __main__ - Saving model with best Classification-F1: 0.040131068134059915 -> 0.0431586552475853 on epoch=78, global_step=1100
05/29/2022 19:09:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.76 on epoch=79
05/29/2022 19:09:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.73 on epoch=79
05/29/2022 19:09:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.64 on epoch=80
05/29/2022 19:09:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.62 on epoch=81
05/29/2022 19:09:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.89 on epoch=82
05/29/2022 19:09:18 - INFO - __main__ - Global step 1150 Train loss 3.73 Classification-F1 0.030568975790757673 on epoch=82
05/29/2022 19:09:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.76 on epoch=82
05/29/2022 19:09:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.69 on epoch=83
05/29/2022 19:09:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.56 on epoch=84
05/29/2022 19:09:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.75 on epoch=84
05/29/2022 19:09:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.59 on epoch=85
05/29/2022 19:09:27 - INFO - __main__ - Global step 1200 Train loss 3.67 Classification-F1 0.04690474137774552 on epoch=85
05/29/2022 19:09:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0431586552475853 -> 0.04690474137774552 on epoch=85, global_step=1200
05/29/2022 19:09:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.54 on epoch=86
05/29/2022 19:09:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.62 on epoch=87
05/29/2022 19:09:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.52 on epoch=87
05/29/2022 19:09:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.51 on epoch=88
05/29/2022 19:09:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.77 on epoch=89
05/29/2022 19:09:35 - INFO - __main__ - Global step 1250 Train loss 3.59 Classification-F1 0.04433647900324923 on epoch=89
05/29/2022 19:09:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.52 on epoch=89
05/29/2022 19:09:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.62 on epoch=90
05/29/2022 19:09:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.37 on epoch=91
05/29/2022 19:09:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.58 on epoch=92
05/29/2022 19:09:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.38 on epoch=92
05/29/2022 19:09:43 - INFO - __main__ - Global step 1300 Train loss 3.49 Classification-F1 0.053134431705860276 on epoch=92
05/29/2022 19:09:43 - INFO - __main__ - Saving model with best Classification-F1: 0.04690474137774552 -> 0.053134431705860276 on epoch=92, global_step=1300
05/29/2022 19:09:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.52 on epoch=93
05/29/2022 19:09:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.35 on epoch=94
05/29/2022 19:09:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.30 on epoch=94
05/29/2022 19:09:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.25 on epoch=95
05/29/2022 19:09:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.20 on epoch=96
05/29/2022 19:09:51 - INFO - __main__ - Global step 1350 Train loss 3.33 Classification-F1 0.07162035412336056 on epoch=96
05/29/2022 19:09:51 - INFO - __main__ - Saving model with best Classification-F1: 0.053134431705860276 -> 0.07162035412336056 on epoch=96, global_step=1350
05/29/2022 19:09:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.31 on epoch=97
05/29/2022 19:09:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.13 on epoch=97
05/29/2022 19:09:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.42 on epoch=98
05/29/2022 19:09:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.27 on epoch=99
05/29/2022 19:09:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.28 on epoch=99
05/29/2022 19:10:00 - INFO - __main__ - Global step 1400 Train loss 3.28 Classification-F1 0.01647479158396189 on epoch=99
05/29/2022 19:10:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.29 on epoch=100
05/29/2022 19:10:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.18 on epoch=101
05/29/2022 19:10:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.41 on epoch=102
05/29/2022 19:10:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.12 on epoch=102
05/29/2022 19:10:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.31 on epoch=103
05/29/2022 19:10:08 - INFO - __main__ - Global step 1450 Train loss 3.26 Classification-F1 0.026077097505668938 on epoch=103
05/29/2022 19:10:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.26 on epoch=104
05/29/2022 19:10:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.29 on epoch=104
05/29/2022 19:10:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.21 on epoch=105
05/29/2022 19:10:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.32 on epoch=106
05/29/2022 19:10:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.33 on epoch=107
05/29/2022 19:10:16 - INFO - __main__ - Global step 1500 Train loss 3.28 Classification-F1 0.06912981755087018 on epoch=107
05/29/2022 19:10:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.22 on epoch=107
05/29/2022 19:10:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.20 on epoch=108
05/29/2022 19:10:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.18 on epoch=109
05/29/2022 19:10:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.09 on epoch=109
05/29/2022 19:10:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.93 on epoch=110
05/29/2022 19:10:24 - INFO - __main__ - Global step 1550 Train loss 3.12 Classification-F1 0.028641137380618447 on epoch=110
05/29/2022 19:10:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.16 on epoch=111
05/29/2022 19:10:27 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.16 on epoch=112
05/29/2022 19:10:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.14 on epoch=112
05/29/2022 19:10:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.14 on epoch=113
05/29/2022 19:10:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.05 on epoch=114
05/29/2022 19:10:33 - INFO - __main__ - Global step 1600 Train loss 3.13 Classification-F1 0.025325249463180495 on epoch=114
05/29/2022 19:10:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.07 on epoch=114
05/29/2022 19:10:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.12 on epoch=115
05/29/2022 19:10:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.05 on epoch=116
05/29/2022 19:10:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.27 on epoch=117
05/29/2022 19:10:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.99 on epoch=117
05/29/2022 19:10:41 - INFO - __main__ - Global step 1650 Train loss 3.10 Classification-F1 0.03382939524243872 on epoch=117
05/29/2022 19:10:42 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.07 on epoch=118
05/29/2022 19:10:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.98 on epoch=119
05/29/2022 19:10:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.05 on epoch=119
05/29/2022 19:10:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.09 on epoch=120
05/29/2022 19:10:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.01 on epoch=121
05/29/2022 19:10:49 - INFO - __main__ - Global step 1700 Train loss 3.04 Classification-F1 0.0460601205772301 on epoch=121
05/29/2022 19:10:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.06 on epoch=122
05/29/2022 19:10:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.95 on epoch=122
05/29/2022 19:10:53 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.00 on epoch=123
05/29/2022 19:10:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.92 on epoch=124
05/29/2022 19:10:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.08 on epoch=124
05/29/2022 19:10:57 - INFO - __main__ - Global step 1750 Train loss 3.00 Classification-F1 0.027011403230915422 on epoch=124
05/29/2022 19:10:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.00 on epoch=125
05/29/2022 19:11:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.83 on epoch=126
05/29/2022 19:11:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.13 on epoch=127
05/29/2022 19:11:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.95 on epoch=127
05/29/2022 19:11:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.11 on epoch=128
05/29/2022 19:11:06 - INFO - __main__ - Global step 1800 Train loss 3.00 Classification-F1 0.038018389173851364 on epoch=128
05/29/2022 19:11:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.94 on epoch=129
05/29/2022 19:11:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.98 on epoch=129
05/29/2022 19:11:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.90 on epoch=130
05/29/2022 19:11:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.06 on epoch=131
05/29/2022 19:11:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.94 on epoch=132
05/29/2022 19:11:14 - INFO - __main__ - Global step 1850 Train loss 2.96 Classification-F1 0.028639301206952513 on epoch=132
05/29/2022 19:11:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.82 on epoch=132
05/29/2022 19:11:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.85 on epoch=133
05/29/2022 19:11:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.05 on epoch=134
05/29/2022 19:11:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.95 on epoch=134
05/29/2022 19:11:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.91 on epoch=135
05/29/2022 19:11:22 - INFO - __main__ - Global step 1900 Train loss 2.92 Classification-F1 0.043307643326087435 on epoch=135
05/29/2022 19:11:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.84 on epoch=136
05/29/2022 19:11:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.96 on epoch=137
05/29/2022 19:11:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.74 on epoch=137
05/29/2022 19:11:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.86 on epoch=138
05/29/2022 19:11:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.87 on epoch=139
05/29/2022 19:11:30 - INFO - __main__ - Global step 1950 Train loss 2.86 Classification-F1 0.028763164033385868 on epoch=139
05/29/2022 19:11:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.80 on epoch=139
05/29/2022 19:11:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.82 on epoch=140
05/29/2022 19:11:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.76 on epoch=141
05/29/2022 19:11:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.92 on epoch=142
05/29/2022 19:11:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.87 on epoch=142
05/29/2022 19:11:39 - INFO - __main__ - Global step 2000 Train loss 2.83 Classification-F1 0.009685230024213076 on epoch=142
05/29/2022 19:11:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.74 on epoch=143
05/29/2022 19:11:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.88 on epoch=144
05/29/2022 19:11:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.90 on epoch=144
05/29/2022 19:11:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.85 on epoch=145
05/29/2022 19:11:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.93 on epoch=146
05/29/2022 19:11:47 - INFO - __main__ - Global step 2050 Train loss 2.86 Classification-F1 0.09203906713558196 on epoch=146
05/29/2022 19:11:47 - INFO - __main__ - Saving model with best Classification-F1: 0.07162035412336056 -> 0.09203906713558196 on epoch=146, global_step=2050
05/29/2022 19:11:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.05 on epoch=147
05/29/2022 19:11:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.74 on epoch=147
05/29/2022 19:11:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.95 on epoch=148
05/29/2022 19:11:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.71 on epoch=149
05/29/2022 19:11:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.93 on epoch=149
05/29/2022 19:11:55 - INFO - __main__ - Global step 2100 Train loss 2.88 Classification-F1 0.11475159985029049 on epoch=149
05/29/2022 19:11:55 - INFO - __main__ - Saving model with best Classification-F1: 0.09203906713558196 -> 0.11475159985029049 on epoch=149, global_step=2100
05/29/2022 19:11:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.90 on epoch=150
05/29/2022 19:11:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.94 on epoch=151
05/29/2022 19:11:59 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.89 on epoch=152
05/29/2022 19:12:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.77 on epoch=152
05/29/2022 19:12:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.86 on epoch=153
05/29/2022 19:12:03 - INFO - __main__ - Global step 2150 Train loss 2.87 Classification-F1 0.08647727892810438 on epoch=153
05/29/2022 19:12:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.83 on epoch=154
05/29/2022 19:12:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.85 on epoch=154
05/29/2022 19:12:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.84 on epoch=155
05/29/2022 19:12:08 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.69 on epoch=156
05/29/2022 19:12:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.72 on epoch=157
05/29/2022 19:12:12 - INFO - __main__ - Global step 2200 Train loss 2.79 Classification-F1 0.09641713589853433 on epoch=157
05/29/2022 19:12:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.76 on epoch=157
05/29/2022 19:12:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.74 on epoch=158
05/29/2022 19:12:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.84 on epoch=159
05/29/2022 19:12:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.85 on epoch=159
05/29/2022 19:12:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.72 on epoch=160
05/29/2022 19:12:20 - INFO - __main__ - Global step 2250 Train loss 2.78 Classification-F1 0.03529973862454681 on epoch=160
05/29/2022 19:12:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.80 on epoch=161
05/29/2022 19:12:22 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.84 on epoch=162
05/29/2022 19:12:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.71 on epoch=162
05/29/2022 19:12:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.72 on epoch=163
05/29/2022 19:12:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.84 on epoch=164
05/29/2022 19:12:28 - INFO - __main__ - Global step 2300 Train loss 2.78 Classification-F1 0.028737776778689442 on epoch=164
05/29/2022 19:12:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.78 on epoch=164
05/29/2022 19:12:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.65 on epoch=165
05/29/2022 19:12:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.59 on epoch=166
05/29/2022 19:12:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.72 on epoch=167
05/29/2022 19:12:35 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.76 on epoch=167
05/29/2022 19:12:36 - INFO - __main__ - Global step 2350 Train loss 2.70 Classification-F1 0.026439719397465873 on epoch=167
05/29/2022 19:12:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.71 on epoch=168
05/29/2022 19:12:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.76 on epoch=169
05/29/2022 19:12:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.74 on epoch=169
05/29/2022 19:12:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.73 on epoch=170
05/29/2022 19:12:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.69 on epoch=171
05/29/2022 19:12:45 - INFO - __main__ - Global step 2400 Train loss 2.73 Classification-F1 0.066728321763488 on epoch=171
05/29/2022 19:12:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.83 on epoch=172
05/29/2022 19:12:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.54 on epoch=172
05/29/2022 19:12:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.75 on epoch=173
05/29/2022 19:12:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.76 on epoch=174
05/29/2022 19:12:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.67 on epoch=174
05/29/2022 19:12:53 - INFO - __main__ - Global step 2450 Train loss 2.71 Classification-F1 0.03537794419525866 on epoch=174
05/29/2022 19:12:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.71 on epoch=175
05/29/2022 19:12:55 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.55 on epoch=176
05/29/2022 19:12:57 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.75 on epoch=177
05/29/2022 19:12:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.66 on epoch=177
05/29/2022 19:12:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.62 on epoch=178
05/29/2022 19:13:01 - INFO - __main__ - Global step 2500 Train loss 2.66 Classification-F1 0.041590329313543596 on epoch=178
05/29/2022 19:13:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.57 on epoch=179
05/29/2022 19:13:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.51 on epoch=179
05/29/2022 19:13:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.56 on epoch=180
05/29/2022 19:13:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.59 on epoch=181
05/29/2022 19:13:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.60 on epoch=182
05/29/2022 19:13:09 - INFO - __main__ - Global step 2550 Train loss 2.57 Classification-F1 0.04276572208084004 on epoch=182
05/29/2022 19:13:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.55 on epoch=182
05/29/2022 19:13:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.62 on epoch=183
05/29/2022 19:13:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.58 on epoch=184
05/29/2022 19:13:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.68 on epoch=184
05/29/2022 19:13:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.60 on epoch=185
05/29/2022 19:13:18 - INFO - __main__ - Global step 2600 Train loss 2.61 Classification-F1 0.08188048222530982 on epoch=185
05/29/2022 19:13:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.47 on epoch=186
05/29/2022 19:13:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.69 on epoch=187
05/29/2022 19:13:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.61 on epoch=187
05/29/2022 19:13:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.69 on epoch=188
05/29/2022 19:13:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.48 on epoch=189
05/29/2022 19:13:26 - INFO - __main__ - Global step 2650 Train loss 2.59 Classification-F1 0.05094296084743619 on epoch=189
05/29/2022 19:13:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.67 on epoch=189
05/29/2022 19:13:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.46 on epoch=190
05/29/2022 19:13:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.39 on epoch=191
05/29/2022 19:13:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.63 on epoch=192
05/29/2022 19:13:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.46 on epoch=192
05/29/2022 19:13:34 - INFO - __main__ - Global step 2700 Train loss 2.52 Classification-F1 0.022683702280114838 on epoch=192
05/29/2022 19:13:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.67 on epoch=193
05/29/2022 19:13:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.42 on epoch=194
05/29/2022 19:13:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.56 on epoch=194
05/29/2022 19:13:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.48 on epoch=195
05/29/2022 19:13:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.50 on epoch=196
05/29/2022 19:13:42 - INFO - __main__ - Global step 2750 Train loss 2.53 Classification-F1 0.06769773474561605 on epoch=196
05/29/2022 19:13:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.64 on epoch=197
05/29/2022 19:13:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.54 on epoch=197
05/29/2022 19:13:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.48 on epoch=198
05/29/2022 19:13:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.53 on epoch=199
05/29/2022 19:13:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.59 on epoch=199
05/29/2022 19:13:51 - INFO - __main__ - Global step 2800 Train loss 2.56 Classification-F1 0.03835345940609098 on epoch=199
05/29/2022 19:13:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.49 on epoch=200
05/29/2022 19:13:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.42 on epoch=201
05/29/2022 19:13:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.63 on epoch=202
05/29/2022 19:13:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.45 on epoch=202
05/29/2022 19:13:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.43 on epoch=203
05/29/2022 19:13:59 - INFO - __main__ - Global step 2850 Train loss 2.48 Classification-F1 0.08288145257526543 on epoch=203
05/29/2022 19:14:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.39 on epoch=204
05/29/2022 19:14:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.52 on epoch=204
05/29/2022 19:14:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.34 on epoch=205
05/29/2022 19:14:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.37 on epoch=206
05/29/2022 19:14:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.52 on epoch=207
05/29/2022 19:14:07 - INFO - __main__ - Global step 2900 Train loss 2.43 Classification-F1 0.07635537619504891 on epoch=207
05/29/2022 19:14:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.41 on epoch=207
05/29/2022 19:14:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.37 on epoch=208
05/29/2022 19:14:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.36 on epoch=209
05/29/2022 19:14:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.52 on epoch=209
05/29/2022 19:14:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.54 on epoch=210
05/29/2022 19:14:15 - INFO - __main__ - Global step 2950 Train loss 2.44 Classification-F1 0.0671126319004925 on epoch=210
05/29/2022 19:14:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.31 on epoch=211
05/29/2022 19:14:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.39 on epoch=212
05/29/2022 19:14:19 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.48 on epoch=212
05/29/2022 19:14:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.34 on epoch=213
05/29/2022 19:14:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.31 on epoch=214
05/29/2022 19:14:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:14:23 - INFO - __main__ - Printing 3 examples
05/29/2022 19:14:23 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 19:14:23 - INFO - __main__ - ['Animal']
05/29/2022 19:14:23 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 19:14:23 - INFO - __main__ - ['Animal']
05/29/2022 19:14:23 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 19:14:23 - INFO - __main__ - ['Animal']
05/29/2022 19:14:23 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:14:23 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:14:23 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:14:23 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:14:23 - INFO - __main__ - Printing 3 examples
05/29/2022 19:14:23 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 19:14:23 - INFO - __main__ - ['Animal']
05/29/2022 19:14:23 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 19:14:23 - INFO - __main__ - ['Animal']
05/29/2022 19:14:23 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 19:14:23 - INFO - __main__ - ['Animal']
05/29/2022 19:14:23 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:14:24 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:14:24 - INFO - __main__ - Global step 3000 Train loss 2.37 Classification-F1 0.061276374956762365 on epoch=214
05/29/2022 19:14:24 - INFO - __main__ - save last model!
05/29/2022 19:14:24 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:14:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 19:14:24 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 19:14:24 - INFO - __main__ - Printing 3 examples
05/29/2022 19:14:24 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 19:14:24 - INFO - __main__ - ['Animal']
05/29/2022 19:14:24 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 19:14:24 - INFO - __main__ - ['Animal']
05/29/2022 19:14:24 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 19:14:24 - INFO - __main__ - ['Village']
05/29/2022 19:14:24 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:14:26 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:14:29 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:14:29 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 19:14:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:14:29 - INFO - __main__ - Starting training!
05/29/2022 19:14:58 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/29/2022 19:14:58 - INFO - __main__ - Classification-F1 on test data: 0.0609
05/29/2022 19:14:59 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.11475159985029049, test_performance=0.060856417022197344
05/29/2022 19:14:59 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/29/2022 19:15:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:15:00 - INFO - __main__ - Printing 3 examples
05/29/2022 19:15:00 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/29/2022 19:15:00 - INFO - __main__ - ['Animal']
05/29/2022 19:15:00 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/29/2022 19:15:00 - INFO - __main__ - ['Animal']
05/29/2022 19:15:00 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/29/2022 19:15:00 - INFO - __main__ - ['Animal']
05/29/2022 19:15:00 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:15:00 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:15:00 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:15:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:15:00 - INFO - __main__ - Printing 3 examples
05/29/2022 19:15:00 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/29/2022 19:15:00 - INFO - __main__ - ['Animal']
05/29/2022 19:15:00 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/29/2022 19:15:00 - INFO - __main__ - ['Animal']
05/29/2022 19:15:00 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/29/2022 19:15:00 - INFO - __main__ - ['Animal']
05/29/2022 19:15:00 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:15:00 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:15:00 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:15:06 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:15:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:15:07 - INFO - __main__ - Starting training!
05/29/2022 19:15:08 - INFO - __main__ - Step 10 Global step 10 Train loss 7.24 on epoch=0
05/29/2022 19:15:09 - INFO - __main__ - Step 20 Global step 20 Train loss 7.52 on epoch=1
05/29/2022 19:15:11 - INFO - __main__ - Step 30 Global step 30 Train loss 7.24 on epoch=2
05/29/2022 19:15:12 - INFO - __main__ - Step 40 Global step 40 Train loss 7.26 on epoch=2
05/29/2022 19:15:13 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/29/2022 19:15:21 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/29/2022 19:15:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 19:15:22 - INFO - __main__ - Step 60 Global step 60 Train loss 7.30 on epoch=4
05/29/2022 19:15:23 - INFO - __main__ - Step 70 Global step 70 Train loss 7.12 on epoch=4
05/29/2022 19:15:25 - INFO - __main__ - Step 80 Global step 80 Train loss 6.84 on epoch=5
05/29/2022 19:15:26 - INFO - __main__ - Step 90 Global step 90 Train loss 7.03 on epoch=6
05/29/2022 19:15:27 - INFO - __main__ - Step 100 Global step 100 Train loss 6.93 on epoch=7
05/29/2022 19:15:37 - INFO - __main__ - Global step 100 Train loss 7.05 Classification-F1 0.0 on epoch=7
05/29/2022 19:15:38 - INFO - __main__ - Step 110 Global step 110 Train loss 6.84 on epoch=7
05/29/2022 19:15:39 - INFO - __main__ - Step 120 Global step 120 Train loss 6.65 on epoch=8
05/29/2022 19:15:41 - INFO - __main__ - Step 130 Global step 130 Train loss 6.90 on epoch=9
05/29/2022 19:15:42 - INFO - __main__ - Step 140 Global step 140 Train loss 6.88 on epoch=9
05/29/2022 19:15:43 - INFO - __main__ - Step 150 Global step 150 Train loss 6.53 on epoch=10
05/29/2022 19:16:00 - INFO - __main__ - Global step 150 Train loss 6.76 Classification-F1 0.0 on epoch=10
05/29/2022 19:16:01 - INFO - __main__ - Step 160 Global step 160 Train loss 6.74 on epoch=11
05/29/2022 19:16:02 - INFO - __main__ - Step 170 Global step 170 Train loss 6.51 on epoch=12
05/29/2022 19:16:04 - INFO - __main__ - Step 180 Global step 180 Train loss 6.50 on epoch=12
05/29/2022 19:16:05 - INFO - __main__ - Step 190 Global step 190 Train loss 6.41 on epoch=13
05/29/2022 19:16:06 - INFO - __main__ - Step 200 Global step 200 Train loss 6.55 on epoch=14
05/29/2022 19:16:45 - INFO - __main__ - Global step 200 Train loss 6.54 Classification-F1 0.0 on epoch=14
05/29/2022 19:16:46 - INFO - __main__ - Step 210 Global step 210 Train loss 6.39 on epoch=14
05/29/2022 19:16:47 - INFO - __main__ - Step 220 Global step 220 Train loss 6.15 on epoch=15
05/29/2022 19:16:48 - INFO - __main__ - Step 230 Global step 230 Train loss 6.46 on epoch=16
05/29/2022 19:16:50 - INFO - __main__ - Step 240 Global step 240 Train loss 6.23 on epoch=17
05/29/2022 19:16:51 - INFO - __main__ - Step 250 Global step 250 Train loss 6.14 on epoch=17
05/29/2022 19:17:44 - INFO - __main__ - Global step 250 Train loss 6.27 Classification-F1 0.0 on epoch=17
05/29/2022 19:17:45 - INFO - __main__ - Step 260 Global step 260 Train loss 5.99 on epoch=18
05/29/2022 19:17:47 - INFO - __main__ - Step 270 Global step 270 Train loss 6.31 on epoch=19
05/29/2022 19:17:48 - INFO - __main__ - Step 280 Global step 280 Train loss 6.14 on epoch=19
05/29/2022 19:17:49 - INFO - __main__ - Step 290 Global step 290 Train loss 5.88 on epoch=20
05/29/2022 19:17:50 - INFO - __main__ - Step 300 Global step 300 Train loss 5.97 on epoch=21
05/29/2022 19:18:43 - INFO - __main__ - Global step 300 Train loss 6.06 Classification-F1 0.0 on epoch=21
05/29/2022 19:18:44 - INFO - __main__ - Step 310 Global step 310 Train loss 6.01 on epoch=22
05/29/2022 19:18:45 - INFO - __main__ - Step 320 Global step 320 Train loss 5.80 on epoch=22
05/29/2022 19:18:46 - INFO - __main__ - Step 330 Global step 330 Train loss 5.82 on epoch=23
05/29/2022 19:18:48 - INFO - __main__ - Step 340 Global step 340 Train loss 5.82 on epoch=24
05/29/2022 19:18:49 - INFO - __main__ - Step 350 Global step 350 Train loss 5.83 on epoch=24
05/29/2022 19:19:37 - INFO - __main__ - Global step 350 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/29/2022 19:19:38 - INFO - __main__ - Step 360 Global step 360 Train loss 5.63 on epoch=25
05/29/2022 19:19:39 - INFO - __main__ - Step 370 Global step 370 Train loss 5.92 on epoch=26
05/29/2022 19:19:40 - INFO - __main__ - Step 380 Global step 380 Train loss 5.72 on epoch=27
05/29/2022 19:19:42 - INFO - __main__ - Step 390 Global step 390 Train loss 5.59 on epoch=27
05/29/2022 19:19:43 - INFO - __main__ - Step 400 Global step 400 Train loss 5.65 on epoch=28
05/29/2022 19:20:07 - INFO - __main__ - Global step 400 Train loss 5.70 Classification-F1 0.0 on epoch=28
05/29/2022 19:20:08 - INFO - __main__ - Step 410 Global step 410 Train loss 5.62 on epoch=29
05/29/2022 19:20:09 - INFO - __main__ - Step 420 Global step 420 Train loss 5.68 on epoch=29
05/29/2022 19:20:10 - INFO - __main__ - Step 430 Global step 430 Train loss 5.45 on epoch=30
05/29/2022 19:20:12 - INFO - __main__ - Step 440 Global step 440 Train loss 5.58 on epoch=31
05/29/2022 19:20:13 - INFO - __main__ - Step 450 Global step 450 Train loss 5.49 on epoch=32
05/29/2022 19:20:42 - INFO - __main__ - Global step 450 Train loss 5.56 Classification-F1 0.0017841213202497768 on epoch=32
05/29/2022 19:20:42 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0017841213202497768 on epoch=32, global_step=450
05/29/2022 19:20:43 - INFO - __main__ - Step 460 Global step 460 Train loss 5.46 on epoch=32
05/29/2022 19:20:45 - INFO - __main__ - Step 470 Global step 470 Train loss 5.45 on epoch=33
05/29/2022 19:20:46 - INFO - __main__ - Step 480 Global step 480 Train loss 5.56 on epoch=34
05/29/2022 19:20:47 - INFO - __main__ - Step 490 Global step 490 Train loss 5.40 on epoch=34
05/29/2022 19:20:48 - INFO - __main__ - Step 500 Global step 500 Train loss 5.30 on epoch=35
05/29/2022 19:20:55 - INFO - __main__ - Global step 500 Train loss 5.43 Classification-F1 0.009009009009009007 on epoch=35
05/29/2022 19:20:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0017841213202497768 -> 0.009009009009009007 on epoch=35, global_step=500
05/29/2022 19:20:56 - INFO - __main__ - Step 510 Global step 510 Train loss 5.37 on epoch=36
05/29/2022 19:20:57 - INFO - __main__ - Step 520 Global step 520 Train loss 5.29 on epoch=37
05/29/2022 19:20:58 - INFO - __main__ - Step 530 Global step 530 Train loss 5.19 on epoch=37
05/29/2022 19:21:00 - INFO - __main__ - Step 540 Global step 540 Train loss 5.20 on epoch=38
05/29/2022 19:21:01 - INFO - __main__ - Step 550 Global step 550 Train loss 5.36 on epoch=39
05/29/2022 19:21:03 - INFO - __main__ - Global step 550 Train loss 5.28 Classification-F1 0.006511123168746609 on epoch=39
05/29/2022 19:21:05 - INFO - __main__ - Step 560 Global step 560 Train loss 5.41 on epoch=39
05/29/2022 19:21:06 - INFO - __main__ - Step 570 Global step 570 Train loss 5.09 on epoch=40
05/29/2022 19:21:07 - INFO - __main__ - Step 580 Global step 580 Train loss 5.23 on epoch=41
05/29/2022 19:21:08 - INFO - __main__ - Step 590 Global step 590 Train loss 5.24 on epoch=42
05/29/2022 19:21:10 - INFO - __main__ - Step 600 Global step 600 Train loss 5.00 on epoch=42
05/29/2022 19:21:13 - INFO - __main__ - Global step 600 Train loss 5.19 Classification-F1 0.006796941376380628 on epoch=42
05/29/2022 19:21:14 - INFO - __main__ - Step 610 Global step 610 Train loss 5.13 on epoch=43
05/29/2022 19:21:15 - INFO - __main__ - Step 620 Global step 620 Train loss 5.20 on epoch=44
05/29/2022 19:21:17 - INFO - __main__ - Step 630 Global step 630 Train loss 5.08 on epoch=44
05/29/2022 19:21:18 - INFO - __main__ - Step 640 Global step 640 Train loss 4.86 on epoch=45
05/29/2022 19:21:19 - INFO - __main__ - Step 650 Global step 650 Train loss 5.04 on epoch=46
05/29/2022 19:21:22 - INFO - __main__ - Global step 650 Train loss 5.06 Classification-F1 0.008403361344537816 on epoch=46
05/29/2022 19:21:23 - INFO - __main__ - Step 660 Global step 660 Train loss 4.99 on epoch=47
05/29/2022 19:21:24 - INFO - __main__ - Step 670 Global step 670 Train loss 4.98 on epoch=47
05/29/2022 19:21:25 - INFO - __main__ - Step 680 Global step 680 Train loss 4.91 on epoch=48
05/29/2022 19:21:26 - INFO - __main__ - Step 690 Global step 690 Train loss 5.03 on epoch=49
05/29/2022 19:21:28 - INFO - __main__ - Step 700 Global step 700 Train loss 5.04 on epoch=49
05/29/2022 19:21:35 - INFO - __main__ - Global step 700 Train loss 4.99 Classification-F1 0.008733624454148471 on epoch=49
05/29/2022 19:21:37 - INFO - __main__ - Step 710 Global step 710 Train loss 4.70 on epoch=50
05/29/2022 19:21:38 - INFO - __main__ - Step 720 Global step 720 Train loss 4.85 on epoch=51
05/29/2022 19:21:39 - INFO - __main__ - Step 730 Global step 730 Train loss 4.86 on epoch=52
05/29/2022 19:21:40 - INFO - __main__ - Step 740 Global step 740 Train loss 4.85 on epoch=52
05/29/2022 19:21:42 - INFO - __main__ - Step 750 Global step 750 Train loss 4.80 on epoch=53
05/29/2022 19:21:50 - INFO - __main__ - Global step 750 Train loss 4.81 Classification-F1 0.006763285024154588 on epoch=53
05/29/2022 19:21:51 - INFO - __main__ - Step 760 Global step 760 Train loss 4.87 on epoch=54
05/29/2022 19:21:52 - INFO - __main__ - Step 770 Global step 770 Train loss 4.94 on epoch=54
05/29/2022 19:21:53 - INFO - __main__ - Step 780 Global step 780 Train loss 4.58 on epoch=55
05/29/2022 19:21:55 - INFO - __main__ - Step 790 Global step 790 Train loss 4.87 on epoch=56
05/29/2022 19:21:56 - INFO - __main__ - Step 800 Global step 800 Train loss 4.77 on epoch=57
05/29/2022 19:21:58 - INFO - __main__ - Global step 800 Train loss 4.81 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 19:21:58 - INFO - __main__ - Saving model with best Classification-F1: 0.009009009009009007 -> 0.009523809523809523 on epoch=57, global_step=800
05/29/2022 19:22:00 - INFO - __main__ - Step 810 Global step 810 Train loss 4.60 on epoch=57
05/29/2022 19:22:01 - INFO - __main__ - Step 820 Global step 820 Train loss 4.76 on epoch=58
05/29/2022 19:22:02 - INFO - __main__ - Step 830 Global step 830 Train loss 4.73 on epoch=59
05/29/2022 19:22:04 - INFO - __main__ - Step 840 Global step 840 Train loss 4.73 on epoch=59
05/29/2022 19:22:05 - INFO - __main__ - Step 850 Global step 850 Train loss 4.48 on epoch=60
05/29/2022 19:22:07 - INFO - __main__ - Global step 850 Train loss 4.66 Classification-F1 0.009523809523809523 on epoch=60
05/29/2022 19:22:09 - INFO - __main__ - Step 860 Global step 860 Train loss 4.54 on epoch=61
05/29/2022 19:22:10 - INFO - __main__ - Step 870 Global step 870 Train loss 4.67 on epoch=62
05/29/2022 19:22:11 - INFO - __main__ - Step 880 Global step 880 Train loss 4.46 on epoch=62
05/29/2022 19:22:12 - INFO - __main__ - Step 890 Global step 890 Train loss 4.64 on epoch=63
05/29/2022 19:22:14 - INFO - __main__ - Step 900 Global step 900 Train loss 4.63 on epoch=64
05/29/2022 19:22:16 - INFO - __main__ - Global step 900 Train loss 4.59 Classification-F1 0.009523809523809523 on epoch=64
05/29/2022 19:22:17 - INFO - __main__ - Step 910 Global step 910 Train loss 4.55 on epoch=64
05/29/2022 19:22:19 - INFO - __main__ - Step 920 Global step 920 Train loss 4.36 on epoch=65
05/29/2022 19:22:20 - INFO - __main__ - Step 930 Global step 930 Train loss 4.51 on epoch=66
05/29/2022 19:22:21 - INFO - __main__ - Step 940 Global step 940 Train loss 4.65 on epoch=67
05/29/2022 19:22:22 - INFO - __main__ - Step 950 Global step 950 Train loss 4.33 on epoch=67
05/29/2022 19:22:25 - INFO - __main__ - Global step 950 Train loss 4.48 Classification-F1 0.009523809523809523 on epoch=67
05/29/2022 19:22:26 - INFO - __main__ - Step 960 Global step 960 Train loss 4.56 on epoch=68
05/29/2022 19:22:27 - INFO - __main__ - Step 970 Global step 970 Train loss 4.38 on epoch=69
05/29/2022 19:22:28 - INFO - __main__ - Step 980 Global step 980 Train loss 4.55 on epoch=69
05/29/2022 19:22:30 - INFO - __main__ - Step 990 Global step 990 Train loss 4.22 on epoch=70
05/29/2022 19:22:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.29 on epoch=71
05/29/2022 19:22:33 - INFO - __main__ - Global step 1000 Train loss 4.40 Classification-F1 0.009523809523809523 on epoch=71
05/29/2022 19:22:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.34 on epoch=72
05/29/2022 19:22:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.32 on epoch=72
05/29/2022 19:22:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.29 on epoch=73
05/29/2022 19:22:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.33 on epoch=74
05/29/2022 19:22:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.39 on epoch=74
05/29/2022 19:22:41 - INFO - __main__ - Global step 1050 Train loss 4.34 Classification-F1 0.009523809523809523 on epoch=74
05/29/2022 19:22:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.21 on epoch=75
05/29/2022 19:22:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.36 on epoch=76
05/29/2022 19:22:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.34 on epoch=77
05/29/2022 19:22:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.07 on epoch=77
05/29/2022 19:22:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.12 on epoch=78
05/29/2022 19:22:50 - INFO - __main__ - Global step 1100 Train loss 4.22 Classification-F1 0.009523809523809523 on epoch=78
05/29/2022 19:22:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.32 on epoch=79
05/29/2022 19:22:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.42 on epoch=79
05/29/2022 19:22:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.07 on epoch=80
05/29/2022 19:22:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.27 on epoch=81
05/29/2022 19:22:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.37 on epoch=82
05/29/2022 19:22:58 - INFO - __main__ - Global step 1150 Train loss 4.29 Classification-F1 0.009523809523809523 on epoch=82
05/29/2022 19:22:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.05 on epoch=82
05/29/2022 19:23:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.16 on epoch=83
05/29/2022 19:23:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.16 on epoch=84
05/29/2022 19:23:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.15 on epoch=84
05/29/2022 19:23:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.00 on epoch=85
05/29/2022 19:23:06 - INFO - __main__ - Global step 1200 Train loss 4.10 Classification-F1 0.009523809523809523 on epoch=85
05/29/2022 19:23:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.98 on epoch=86
05/29/2022 19:23:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.07 on epoch=87
05/29/2022 19:23:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.87 on epoch=87
05/29/2022 19:23:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.01 on epoch=88
05/29/2022 19:23:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.90 on epoch=89
05/29/2022 19:23:14 - INFO - __main__ - Global step 1250 Train loss 3.96 Classification-F1 0.024250609334642948 on epoch=89
05/29/2022 19:23:14 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024250609334642948 on epoch=89, global_step=1250
05/29/2022 19:23:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.07 on epoch=89
05/29/2022 19:23:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.74 on epoch=90
05/29/2022 19:23:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.82 on epoch=91
05/29/2022 19:23:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.02 on epoch=92
05/29/2022 19:23:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.79 on epoch=92
05/29/2022 19:23:23 - INFO - __main__ - Global step 1300 Train loss 3.89 Classification-F1 0.02283922973578146 on epoch=92
05/29/2022 19:23:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.89 on epoch=93
05/29/2022 19:23:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.80 on epoch=94
05/29/2022 19:23:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.94 on epoch=94
05/29/2022 19:23:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.78 on epoch=95
05/29/2022 19:23:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.69 on epoch=96
05/29/2022 19:23:31 - INFO - __main__ - Global step 1350 Train loss 3.82 Classification-F1 0.02564102564102564 on epoch=96
05/29/2022 19:23:31 - INFO - __main__ - Saving model with best Classification-F1: 0.024250609334642948 -> 0.02564102564102564 on epoch=96, global_step=1350
05/29/2022 19:23:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.90 on epoch=97
05/29/2022 19:23:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.68 on epoch=97
05/29/2022 19:23:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.66 on epoch=98
05/29/2022 19:23:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.63 on epoch=99
05/29/2022 19:23:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.68 on epoch=99
05/29/2022 19:23:39 - INFO - __main__ - Global step 1400 Train loss 3.71 Classification-F1 0.009523809523809523 on epoch=99
05/29/2022 19:23:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.69 on epoch=100
05/29/2022 19:23:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.69 on epoch=101
05/29/2022 19:23:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.77 on epoch=102
05/29/2022 19:23:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.59 on epoch=102
05/29/2022 19:23:45 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.74 on epoch=103
05/29/2022 19:23:47 - INFO - __main__ - Global step 1450 Train loss 3.70 Classification-F1 0.009603841536614645 on epoch=103
05/29/2022 19:23:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.53 on epoch=104
05/29/2022 19:23:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.70 on epoch=104
05/29/2022 19:23:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.60 on epoch=105
05/29/2022 19:23:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.49 on epoch=106
05/29/2022 19:23:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.72 on epoch=107
05/29/2022 19:23:55 - INFO - __main__ - Global step 1500 Train loss 3.61 Classification-F1 0.056913863278115144 on epoch=107
05/29/2022 19:23:55 - INFO - __main__ - Saving model with best Classification-F1: 0.02564102564102564 -> 0.056913863278115144 on epoch=107, global_step=1500
05/29/2022 19:23:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.56 on epoch=107
05/29/2022 19:23:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.65 on epoch=108
05/29/2022 19:23:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.54 on epoch=109
05/29/2022 19:24:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.61 on epoch=109
05/29/2022 19:24:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.50 on epoch=110
05/29/2022 19:24:04 - INFO - __main__ - Global step 1550 Train loss 3.57 Classification-F1 0.009523809523809523 on epoch=110
05/29/2022 19:24:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.50 on epoch=111
05/29/2022 19:24:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.73 on epoch=112
05/29/2022 19:24:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.55 on epoch=112
05/29/2022 19:24:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.51 on epoch=113
05/29/2022 19:24:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.54 on epoch=114
05/29/2022 19:24:12 - INFO - __main__ - Global step 1600 Train loss 3.57 Classification-F1 0.009685230024213076 on epoch=114
05/29/2022 19:24:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.52 on epoch=114
05/29/2022 19:24:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.50 on epoch=115
05/29/2022 19:24:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.45 on epoch=116
05/29/2022 19:24:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.55 on epoch=117
05/29/2022 19:24:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.49 on epoch=117
05/29/2022 19:24:20 - INFO - __main__ - Global step 1650 Train loss 3.50 Classification-F1 0.02079365079365079 on epoch=117
05/29/2022 19:24:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.59 on epoch=118
05/29/2022 19:24:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.40 on epoch=119
05/29/2022 19:24:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.35 on epoch=119
05/29/2022 19:24:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.31 on epoch=120
05/29/2022 19:24:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.46 on epoch=121
05/29/2022 19:24:28 - INFO - __main__ - Global step 1700 Train loss 3.42 Classification-F1 0.04756952589464906 on epoch=121
05/29/2022 19:24:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.50 on epoch=122
05/29/2022 19:24:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.18 on epoch=122
05/29/2022 19:24:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.41 on epoch=123
05/29/2022 19:24:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.34 on epoch=124
05/29/2022 19:24:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.47 on epoch=124
05/29/2022 19:24:37 - INFO - __main__ - Global step 1750 Train loss 3.38 Classification-F1 0.031830914183855356 on epoch=124
05/29/2022 19:24:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.32 on epoch=125
05/29/2022 19:24:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.21 on epoch=126
05/29/2022 19:24:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.63 on epoch=127
05/29/2022 19:24:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.17 on epoch=127
05/29/2022 19:24:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.46 on epoch=128
05/29/2022 19:24:45 - INFO - __main__ - Global step 1800 Train loss 3.36 Classification-F1 0.020149832084732627 on epoch=128
05/29/2022 19:24:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.27 on epoch=129
05/29/2022 19:24:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.28 on epoch=129
05/29/2022 19:24:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.13 on epoch=130
05/29/2022 19:24:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.23 on epoch=131
05/29/2022 19:24:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.42 on epoch=132
05/29/2022 19:24:53 - INFO - __main__ - Global step 1850 Train loss 3.26 Classification-F1 0.03038179768949 on epoch=132
05/29/2022 19:24:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.21 on epoch=132
05/29/2022 19:24:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.42 on epoch=133
05/29/2022 19:24:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.19 on epoch=134
05/29/2022 19:24:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.42 on epoch=134
05/29/2022 19:25:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.13 on epoch=135
05/29/2022 19:25:02 - INFO - __main__ - Global step 1900 Train loss 3.27 Classification-F1 0.014436821040594627 on epoch=135
05/29/2022 19:25:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.26 on epoch=136
05/29/2022 19:25:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.26 on epoch=137
05/29/2022 19:25:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.09 on epoch=137
05/29/2022 19:25:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.25 on epoch=138
05/29/2022 19:25:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.25 on epoch=139
05/29/2022 19:25:10 - INFO - __main__ - Global step 1950 Train loss 3.22 Classification-F1 0.04897682914921132 on epoch=139
05/29/2022 19:25:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.23 on epoch=139
05/29/2022 19:25:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.01 on epoch=140
05/29/2022 19:25:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.06 on epoch=141
05/29/2022 19:25:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.30 on epoch=142
05/29/2022 19:25:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.10 on epoch=142
05/29/2022 19:25:18 - INFO - __main__ - Global step 2000 Train loss 3.14 Classification-F1 0.009523809523809523 on epoch=142
05/29/2022 19:25:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.23 on epoch=143
05/29/2022 19:25:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.25 on epoch=144
05/29/2022 19:25:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.18 on epoch=144
05/29/2022 19:25:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.05 on epoch=145
05/29/2022 19:25:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.05 on epoch=146
05/29/2022 19:25:26 - INFO - __main__ - Global step 2050 Train loss 3.15 Classification-F1 0.017456685191238965 on epoch=146
05/29/2022 19:25:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.19 on epoch=147
05/29/2022 19:25:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.03 on epoch=147
05/29/2022 19:25:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.15 on epoch=148
05/29/2022 19:25:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.24 on epoch=149
05/29/2022 19:25:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.17 on epoch=149
05/29/2022 19:25:34 - INFO - __main__ - Global step 2100 Train loss 3.16 Classification-F1 0.009603841536614645 on epoch=149
05/29/2022 19:25:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.06 on epoch=150
05/29/2022 19:25:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.16 on epoch=151
05/29/2022 19:25:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.01 on epoch=152
05/29/2022 19:25:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.25 on epoch=152
05/29/2022 19:25:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.99 on epoch=153
05/29/2022 19:25:43 - INFO - __main__ - Global step 2150 Train loss 3.09 Classification-F1 0.009523809523809523 on epoch=153
05/29/2022 19:25:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.00 on epoch=154
05/29/2022 19:25:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.03 on epoch=154
05/29/2022 19:25:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.02 on epoch=155
05/29/2022 19:25:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.88 on epoch=156
05/29/2022 19:25:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.05 on epoch=157
05/29/2022 19:25:51 - INFO - __main__ - Global step 2200 Train loss 3.00 Classification-F1 0.009563658099222952 on epoch=157
05/29/2022 19:25:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.85 on epoch=157
05/29/2022 19:25:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.02 on epoch=158
05/29/2022 19:25:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.92 on epoch=159
05/29/2022 19:25:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.98 on epoch=159
05/29/2022 19:25:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.84 on epoch=160
05/29/2022 19:25:59 - INFO - __main__ - Global step 2250 Train loss 2.92 Classification-F1 0.035132841015193955 on epoch=160
05/29/2022 19:26:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.86 on epoch=161
05/29/2022 19:26:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.03 on epoch=162
05/29/2022 19:26:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.90 on epoch=162
05/29/2022 19:26:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.95 on epoch=163
05/29/2022 19:26:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.10 on epoch=164
05/29/2022 19:26:08 - INFO - __main__ - Global step 2300 Train loss 2.97 Classification-F1 0.03645958383353341 on epoch=164
05/29/2022 19:26:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.00 on epoch=164
05/29/2022 19:26:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.06 on epoch=165
05/29/2022 19:26:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.79 on epoch=166
05/29/2022 19:26:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.03 on epoch=167
05/29/2022 19:26:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.85 on epoch=167
05/29/2022 19:26:16 - INFO - __main__ - Global step 2350 Train loss 2.95 Classification-F1 0.021386655489082806 on epoch=167
05/29/2022 19:26:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.83 on epoch=168
05/29/2022 19:26:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.95 on epoch=169
05/29/2022 19:26:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.93 on epoch=169
05/29/2022 19:26:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.95 on epoch=170
05/29/2022 19:26:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.76 on epoch=171
05/29/2022 19:26:24 - INFO - __main__ - Global step 2400 Train loss 2.89 Classification-F1 0.03701404249993591 on epoch=171
05/29/2022 19:26:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.07 on epoch=172
05/29/2022 19:26:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.96 on epoch=172
05/29/2022 19:26:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.89 on epoch=173
05/29/2022 19:26:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.80 on epoch=174
05/29/2022 19:26:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.94 on epoch=174
05/29/2022 19:26:33 - INFO - __main__ - Global step 2450 Train loss 2.93 Classification-F1 0.03170590243333451 on epoch=174
05/29/2022 19:26:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.78 on epoch=175
05/29/2022 19:26:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.81 on epoch=176
05/29/2022 19:26:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 3.01 on epoch=177
05/29/2022 19:26:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.83 on epoch=177
05/29/2022 19:26:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.03 on epoch=178
05/29/2022 19:26:41 - INFO - __main__ - Global step 2500 Train loss 2.89 Classification-F1 0.04703336290526692 on epoch=178
05/29/2022 19:26:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.69 on epoch=179
05/29/2022 19:26:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.88 on epoch=179
05/29/2022 19:26:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.64 on epoch=180
05/29/2022 19:26:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.80 on epoch=181
05/29/2022 19:26:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.90 on epoch=182
05/29/2022 19:26:49 - INFO - __main__ - Global step 2550 Train loss 2.78 Classification-F1 0.023472527472527475 on epoch=182
05/29/2022 19:26:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.76 on epoch=182
05/29/2022 19:26:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.91 on epoch=183
05/29/2022 19:26:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.58 on epoch=184
05/29/2022 19:26:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.91 on epoch=184
05/29/2022 19:26:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.57 on epoch=185
05/29/2022 19:26:57 - INFO - __main__ - Global step 2600 Train loss 2.75 Classification-F1 0.02255701582552742 on epoch=185
05/29/2022 19:26:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.65 on epoch=186
05/29/2022 19:27:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.88 on epoch=187
05/29/2022 19:27:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.69 on epoch=187
05/29/2022 19:27:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.82 on epoch=188
05/29/2022 19:27:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.67 on epoch=189
05/29/2022 19:27:06 - INFO - __main__ - Global step 2650 Train loss 2.74 Classification-F1 0.028641801548205486 on epoch=189
05/29/2022 19:27:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.74 on epoch=189
05/29/2022 19:27:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.77 on epoch=190
05/29/2022 19:27:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.67 on epoch=191
05/29/2022 19:27:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.90 on epoch=192
05/29/2022 19:27:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.66 on epoch=192
05/29/2022 19:27:14 - INFO - __main__ - Global step 2700 Train loss 2.75 Classification-F1 0.030124594640723673 on epoch=192
05/29/2022 19:27:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.76 on epoch=193
05/29/2022 19:27:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.73 on epoch=194
05/29/2022 19:27:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.61 on epoch=194
05/29/2022 19:27:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.66 on epoch=195
05/29/2022 19:27:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.68 on epoch=196
05/29/2022 19:27:22 - INFO - __main__ - Global step 2750 Train loss 2.69 Classification-F1 0.023376623376623377 on epoch=196
05/29/2022 19:27:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.81 on epoch=197
05/29/2022 19:27:25 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.81 on epoch=197
05/29/2022 19:27:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.76 on epoch=198
05/29/2022 19:27:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.71 on epoch=199
05/29/2022 19:27:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.72 on epoch=199
05/29/2022 19:27:31 - INFO - __main__ - Global step 2800 Train loss 2.76 Classification-F1 0.05061488009838082 on epoch=199
05/29/2022 19:27:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.62 on epoch=200
05/29/2022 19:27:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.54 on epoch=201
05/29/2022 19:27:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.90 on epoch=202
05/29/2022 19:27:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.68 on epoch=202
05/29/2022 19:27:37 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.69 on epoch=203
05/29/2022 19:27:39 - INFO - __main__ - Global step 2850 Train loss 2.68 Classification-F1 0.04377715307947866 on epoch=203
05/29/2022 19:27:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.68 on epoch=204
05/29/2022 19:27:42 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.73 on epoch=204
05/29/2022 19:27:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.71 on epoch=205
05/29/2022 19:27:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.64 on epoch=206
05/29/2022 19:27:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.87 on epoch=207
05/29/2022 19:27:47 - INFO - __main__ - Global step 2900 Train loss 2.73 Classification-F1 0.02614048073551755 on epoch=207
05/29/2022 19:27:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.46 on epoch=207
05/29/2022 19:27:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.52 on epoch=208
05/29/2022 19:27:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.54 on epoch=209
05/29/2022 19:27:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.63 on epoch=209
05/29/2022 19:27:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.49 on epoch=210
05/29/2022 19:27:56 - INFO - __main__ - Global step 2950 Train loss 2.53 Classification-F1 0.03708272511383691 on epoch=210
05/29/2022 19:27:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.56 on epoch=211
05/29/2022 19:27:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.74 on epoch=212
05/29/2022 19:27:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.59 on epoch=212
05/29/2022 19:28:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.59 on epoch=213
05/29/2022 19:28:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.81 on epoch=214
05/29/2022 19:28:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:28:03 - INFO - __main__ - Printing 3 examples
05/29/2022 19:28:03 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 19:28:03 - INFO - __main__ - ['Plant']
05/29/2022 19:28:03 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 19:28:03 - INFO - __main__ - ['Plant']
05/29/2022 19:28:03 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 19:28:03 - INFO - __main__ - ['Plant']
05/29/2022 19:28:03 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:28:03 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:28:04 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:28:04 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:28:04 - INFO - __main__ - Printing 3 examples
05/29/2022 19:28:04 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 19:28:04 - INFO - __main__ - ['Plant']
05/29/2022 19:28:04 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 19:28:04 - INFO - __main__ - ['Plant']
05/29/2022 19:28:04 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 19:28:04 - INFO - __main__ - ['Plant']
05/29/2022 19:28:04 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:28:04 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:28:04 - INFO - __main__ - Global step 3000 Train loss 2.66 Classification-F1 0.01840291559917728 on epoch=214
05/29/2022 19:28:04 - INFO - __main__ - save last model!
05/29/2022 19:28:04 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:28:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 19:28:04 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 19:28:04 - INFO - __main__ - Printing 3 examples
05/29/2022 19:28:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 19:28:04 - INFO - __main__ - ['Animal']
05/29/2022 19:28:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 19:28:04 - INFO - __main__ - ['Animal']
05/29/2022 19:28:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 19:28:04 - INFO - __main__ - ['Village']
05/29/2022 19:28:04 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:28:06 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:28:09 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:28:09 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 19:28:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:28:09 - INFO - __main__ - Starting training!
05/29/2022 19:28:38 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/29/2022 19:28:38 - INFO - __main__ - Classification-F1 on test data: 0.0300
05/29/2022 19:28:39 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.056913863278115144, test_performance=0.029997895534535614
05/29/2022 19:28:39 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/29/2022 19:28:39 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:28:39 - INFO - __main__ - Printing 3 examples
05/29/2022 19:28:39 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 19:28:39 - INFO - __main__ - ['Plant']
05/29/2022 19:28:39 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 19:28:39 - INFO - __main__ - ['Plant']
05/29/2022 19:28:39 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 19:28:39 - INFO - __main__ - ['Plant']
05/29/2022 19:28:39 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:28:40 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:28:40 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:28:40 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:28:40 - INFO - __main__ - Printing 3 examples
05/29/2022 19:28:40 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 19:28:40 - INFO - __main__ - ['Plant']
05/29/2022 19:28:40 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 19:28:40 - INFO - __main__ - ['Plant']
05/29/2022 19:28:40 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 19:28:40 - INFO - __main__ - ['Plant']
05/29/2022 19:28:40 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:28:40 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:28:40 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:28:45 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:28:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:28:46 - INFO - __main__ - Starting training!
05/29/2022 19:28:47 - INFO - __main__ - Step 10 Global step 10 Train loss 7.57 on epoch=0
05/29/2022 19:28:48 - INFO - __main__ - Step 20 Global step 20 Train loss 7.39 on epoch=1
05/29/2022 19:28:50 - INFO - __main__ - Step 30 Global step 30 Train loss 7.35 on epoch=2
05/29/2022 19:28:51 - INFO - __main__ - Step 40 Global step 40 Train loss 7.42 on epoch=2
05/29/2022 19:28:52 - INFO - __main__ - Step 50 Global step 50 Train loss 7.01 on epoch=3
05/29/2022 19:29:54 - INFO - __main__ - Global step 50 Train loss 7.35 Classification-F1 0.0 on epoch=3
05/29/2022 19:29:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 19:29:55 - INFO - __main__ - Step 60 Global step 60 Train loss 6.80 on epoch=4
05/29/2022 19:29:56 - INFO - __main__ - Step 70 Global step 70 Train loss 6.79 on epoch=4
05/29/2022 19:29:58 - INFO - __main__ - Step 80 Global step 80 Train loss 6.74 on epoch=5
05/29/2022 19:29:59 - INFO - __main__ - Step 90 Global step 90 Train loss 6.38 on epoch=6
05/29/2022 19:30:00 - INFO - __main__ - Step 100 Global step 100 Train loss 6.52 on epoch=7
05/29/2022 19:31:04 - INFO - __main__ - Global step 100 Train loss 6.65 Classification-F1 0.0 on epoch=7
05/29/2022 19:31:05 - INFO - __main__ - Step 110 Global step 110 Train loss 6.41 on epoch=7
05/29/2022 19:31:07 - INFO - __main__ - Step 120 Global step 120 Train loss 6.21 on epoch=8
05/29/2022 19:31:08 - INFO - __main__ - Step 130 Global step 130 Train loss 6.10 on epoch=9
05/29/2022 19:31:09 - INFO - __main__ - Step 140 Global step 140 Train loss 5.99 on epoch=9
05/29/2022 19:31:10 - INFO - __main__ - Step 150 Global step 150 Train loss 5.98 on epoch=10
05/29/2022 19:31:55 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/29/2022 19:31:56 - INFO - __main__ - Step 160 Global step 160 Train loss 5.78 on epoch=11
05/29/2022 19:31:58 - INFO - __main__ - Step 170 Global step 170 Train loss 6.06 on epoch=12
05/29/2022 19:31:59 - INFO - __main__ - Step 180 Global step 180 Train loss 5.82 on epoch=12
05/29/2022 19:32:00 - INFO - __main__ - Step 190 Global step 190 Train loss 5.63 on epoch=13
05/29/2022 19:32:01 - INFO - __main__ - Step 200 Global step 200 Train loss 5.61 on epoch=14
05/29/2022 19:32:21 - INFO - __main__ - Global step 200 Train loss 5.78 Classification-F1 0.0027359781121751026 on epoch=14
05/29/2022 19:32:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0027359781121751026 on epoch=14, global_step=200
05/29/2022 19:32:23 - INFO - __main__ - Step 210 Global step 210 Train loss 5.62 on epoch=14
05/29/2022 19:32:24 - INFO - __main__ - Step 220 Global step 220 Train loss 5.50 on epoch=15
05/29/2022 19:32:25 - INFO - __main__ - Step 230 Global step 230 Train loss 5.31 on epoch=16
05/29/2022 19:32:26 - INFO - __main__ - Step 240 Global step 240 Train loss 5.31 on epoch=17
05/29/2022 19:32:28 - INFO - __main__ - Step 250 Global step 250 Train loss 5.42 on epoch=17
05/29/2022 19:32:32 - INFO - __main__ - Global step 250 Train loss 5.43 Classification-F1 0.006493506493506495 on epoch=17
05/29/2022 19:32:32 - INFO - __main__ - Saving model with best Classification-F1: 0.0027359781121751026 -> 0.006493506493506495 on epoch=17, global_step=250
05/29/2022 19:32:33 - INFO - __main__ - Step 260 Global step 260 Train loss 5.20 on epoch=18
05/29/2022 19:32:34 - INFO - __main__ - Step 270 Global step 270 Train loss 5.26 on epoch=19
05/29/2022 19:32:35 - INFO - __main__ - Step 280 Global step 280 Train loss 5.14 on epoch=19
05/29/2022 19:32:37 - INFO - __main__ - Step 290 Global step 290 Train loss 5.04 on epoch=20
05/29/2022 19:32:38 - INFO - __main__ - Step 300 Global step 300 Train loss 5.00 on epoch=21
05/29/2022 19:32:41 - INFO - __main__ - Global step 300 Train loss 5.13 Classification-F1 0.00892608089260809 on epoch=21
05/29/2022 19:32:41 - INFO - __main__ - Saving model with best Classification-F1: 0.006493506493506495 -> 0.00892608089260809 on epoch=21, global_step=300
05/29/2022 19:32:42 - INFO - __main__ - Step 310 Global step 310 Train loss 5.13 on epoch=22
05/29/2022 19:32:44 - INFO - __main__ - Step 320 Global step 320 Train loss 5.00 on epoch=22
05/29/2022 19:32:45 - INFO - __main__ - Step 330 Global step 330 Train loss 4.83 on epoch=23
05/29/2022 19:32:46 - INFO - __main__ - Step 340 Global step 340 Train loss 4.81 on epoch=24
05/29/2022 19:32:47 - INFO - __main__ - Step 350 Global step 350 Train loss 4.57 on epoch=24
05/29/2022 19:32:50 - INFO - __main__ - Global step 350 Train loss 4.87 Classification-F1 0.009523809523809523 on epoch=24
05/29/2022 19:32:50 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=24, global_step=350
05/29/2022 19:32:51 - INFO - __main__ - Step 360 Global step 360 Train loss 4.67 on epoch=25
05/29/2022 19:32:52 - INFO - __main__ - Step 370 Global step 370 Train loss 4.46 on epoch=26
05/29/2022 19:32:54 - INFO - __main__ - Step 380 Global step 380 Train loss 4.61 on epoch=27
05/29/2022 19:32:55 - INFO - __main__ - Step 390 Global step 390 Train loss 4.61 on epoch=27
05/29/2022 19:32:56 - INFO - __main__ - Step 400 Global step 400 Train loss 4.69 on epoch=28
05/29/2022 19:32:58 - INFO - __main__ - Global step 400 Train loss 4.61 Classification-F1 0.009523809523809523 on epoch=28
05/29/2022 19:32:59 - INFO - __main__ - Step 410 Global step 410 Train loss 4.39 on epoch=29
05/29/2022 19:33:01 - INFO - __main__ - Step 420 Global step 420 Train loss 4.34 on epoch=29
05/29/2022 19:33:02 - INFO - __main__ - Step 430 Global step 430 Train loss 4.40 on epoch=30
05/29/2022 19:33:03 - INFO - __main__ - Step 440 Global step 440 Train loss 4.35 on epoch=31
05/29/2022 19:33:05 - INFO - __main__ - Step 450 Global step 450 Train loss 4.39 on epoch=32
05/29/2022 19:33:07 - INFO - __main__ - Global step 450 Train loss 4.37 Classification-F1 0.03533285516707069 on epoch=32
05/29/2022 19:33:07 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.03533285516707069 on epoch=32, global_step=450
05/29/2022 19:33:08 - INFO - __main__ - Step 460 Global step 460 Train loss 4.08 on epoch=32
05/29/2022 19:33:09 - INFO - __main__ - Step 470 Global step 470 Train loss 4.19 on epoch=33
05/29/2022 19:33:10 - INFO - __main__ - Step 480 Global step 480 Train loss 4.23 on epoch=34
05/29/2022 19:33:12 - INFO - __main__ - Step 490 Global step 490 Train loss 3.99 on epoch=34
05/29/2022 19:33:13 - INFO - __main__ - Step 500 Global step 500 Train loss 3.89 on epoch=35
05/29/2022 19:33:15 - INFO - __main__ - Global step 500 Train loss 4.08 Classification-F1 0.026969988291503193 on epoch=35
05/29/2022 19:33:16 - INFO - __main__ - Step 510 Global step 510 Train loss 3.93 on epoch=36
05/29/2022 19:33:17 - INFO - __main__ - Step 520 Global step 520 Train loss 4.00 on epoch=37
05/29/2022 19:33:19 - INFO - __main__ - Step 530 Global step 530 Train loss 3.81 on epoch=37
05/29/2022 19:33:20 - INFO - __main__ - Step 540 Global step 540 Train loss 3.95 on epoch=38
05/29/2022 19:33:21 - INFO - __main__ - Step 550 Global step 550 Train loss 3.69 on epoch=39
05/29/2022 19:33:23 - INFO - __main__ - Global step 550 Train loss 3.88 Classification-F1 0.01935875608681676 on epoch=39
05/29/2022 19:33:24 - INFO - __main__ - Step 560 Global step 560 Train loss 3.71 on epoch=39
05/29/2022 19:33:26 - INFO - __main__ - Step 570 Global step 570 Train loss 3.68 on epoch=40
05/29/2022 19:33:27 - INFO - __main__ - Step 580 Global step 580 Train loss 3.63 on epoch=41
05/29/2022 19:33:28 - INFO - __main__ - Step 590 Global step 590 Train loss 3.78 on epoch=42
05/29/2022 19:33:30 - INFO - __main__ - Step 600 Global step 600 Train loss 3.49 on epoch=42
05/29/2022 19:33:31 - INFO - __main__ - Global step 600 Train loss 3.66 Classification-F1 0.027561317052249977 on epoch=42
05/29/2022 19:33:33 - INFO - __main__ - Step 610 Global step 610 Train loss 3.62 on epoch=43
05/29/2022 19:33:34 - INFO - __main__ - Step 620 Global step 620 Train loss 3.63 on epoch=44
05/29/2022 19:33:35 - INFO - __main__ - Step 630 Global step 630 Train loss 3.50 on epoch=44
05/29/2022 19:33:37 - INFO - __main__ - Step 640 Global step 640 Train loss 3.47 on epoch=45
05/29/2022 19:33:38 - INFO - __main__ - Step 650 Global step 650 Train loss 3.53 on epoch=46
05/29/2022 19:33:40 - INFO - __main__ - Global step 650 Train loss 3.55 Classification-F1 0.020625885742164812 on epoch=46
05/29/2022 19:33:41 - INFO - __main__ - Step 660 Global step 660 Train loss 3.56 on epoch=47
05/29/2022 19:33:42 - INFO - __main__ - Step 670 Global step 670 Train loss 3.34 on epoch=47
05/29/2022 19:33:43 - INFO - __main__ - Step 680 Global step 680 Train loss 3.50 on epoch=48
05/29/2022 19:33:45 - INFO - __main__ - Step 690 Global step 690 Train loss 3.35 on epoch=49
05/29/2022 19:33:46 - INFO - __main__ - Step 700 Global step 700 Train loss 3.40 on epoch=49
05/29/2022 19:33:48 - INFO - __main__ - Global step 700 Train loss 3.43 Classification-F1 0.07079211716892876 on epoch=49
05/29/2022 19:33:48 - INFO - __main__ - Saving model with best Classification-F1: 0.03533285516707069 -> 0.07079211716892876 on epoch=49, global_step=700
05/29/2022 19:33:49 - INFO - __main__ - Step 710 Global step 710 Train loss 3.31 on epoch=50
05/29/2022 19:33:50 - INFO - __main__ - Step 720 Global step 720 Train loss 3.38 on epoch=51
05/29/2022 19:33:52 - INFO - __main__ - Step 730 Global step 730 Train loss 3.40 on epoch=52
05/29/2022 19:33:53 - INFO - __main__ - Step 740 Global step 740 Train loss 3.13 on epoch=52
05/29/2022 19:33:54 - INFO - __main__ - Step 750 Global step 750 Train loss 3.33 on epoch=53
05/29/2022 19:33:56 - INFO - __main__ - Global step 750 Train loss 3.31 Classification-F1 0.051475778947435526 on epoch=53
05/29/2022 19:33:57 - INFO - __main__ - Step 760 Global step 760 Train loss 3.29 on epoch=54
05/29/2022 19:33:59 - INFO - __main__ - Step 770 Global step 770 Train loss 3.17 on epoch=54
05/29/2022 19:34:00 - INFO - __main__ - Step 780 Global step 780 Train loss 3.23 on epoch=55
05/29/2022 19:34:01 - INFO - __main__ - Step 790 Global step 790 Train loss 3.34 on epoch=56
05/29/2022 19:34:02 - INFO - __main__ - Step 800 Global step 800 Train loss 3.25 on epoch=57
05/29/2022 19:34:04 - INFO - __main__ - Global step 800 Train loss 3.26 Classification-F1 0.032079459002535934 on epoch=57
05/29/2022 19:34:05 - INFO - __main__ - Step 810 Global step 810 Train loss 3.08 on epoch=57
05/29/2022 19:34:07 - INFO - __main__ - Step 820 Global step 820 Train loss 3.21 on epoch=58
05/29/2022 19:34:08 - INFO - __main__ - Step 830 Global step 830 Train loss 3.18 on epoch=59
05/29/2022 19:34:09 - INFO - __main__ - Step 840 Global step 840 Train loss 3.23 on epoch=59
05/29/2022 19:34:10 - INFO - __main__ - Step 850 Global step 850 Train loss 3.07 on epoch=60
05/29/2022 19:34:12 - INFO - __main__ - Global step 850 Train loss 3.15 Classification-F1 0.04134848202644813 on epoch=60
05/29/2022 19:34:14 - INFO - __main__ - Step 860 Global step 860 Train loss 3.17 on epoch=61
05/29/2022 19:34:15 - INFO - __main__ - Step 870 Global step 870 Train loss 3.26 on epoch=62
05/29/2022 19:34:16 - INFO - __main__ - Step 880 Global step 880 Train loss 2.92 on epoch=62
05/29/2022 19:34:17 - INFO - __main__ - Step 890 Global step 890 Train loss 3.12 on epoch=63
05/29/2022 19:34:19 - INFO - __main__ - Step 900 Global step 900 Train loss 3.10 on epoch=64
05/29/2022 19:34:21 - INFO - __main__ - Global step 900 Train loss 3.11 Classification-F1 0.029592629592629597 on epoch=64
05/29/2022 19:34:22 - INFO - __main__ - Step 910 Global step 910 Train loss 3.02 on epoch=64
05/29/2022 19:34:23 - INFO - __main__ - Step 920 Global step 920 Train loss 3.03 on epoch=65
05/29/2022 19:34:25 - INFO - __main__ - Step 930 Global step 930 Train loss 3.19 on epoch=66
05/29/2022 19:34:26 - INFO - __main__ - Step 940 Global step 940 Train loss 3.01 on epoch=67
05/29/2022 19:34:27 - INFO - __main__ - Step 950 Global step 950 Train loss 3.02 on epoch=67
05/29/2022 19:34:29 - INFO - __main__ - Global step 950 Train loss 3.05 Classification-F1 0.05177824467358462 on epoch=67
05/29/2022 19:34:30 - INFO - __main__ - Step 960 Global step 960 Train loss 3.10 on epoch=68
05/29/2022 19:34:32 - INFO - __main__ - Step 970 Global step 970 Train loss 2.93 on epoch=69
05/29/2022 19:34:33 - INFO - __main__ - Step 980 Global step 980 Train loss 2.98 on epoch=69
05/29/2022 19:34:34 - INFO - __main__ - Step 990 Global step 990 Train loss 2.92 on epoch=70
05/29/2022 19:34:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.02 on epoch=71
05/29/2022 19:34:37 - INFO - __main__ - Global step 1000 Train loss 2.99 Classification-F1 0.046340774654445714 on epoch=71
05/29/2022 19:34:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.11 on epoch=72
05/29/2022 19:34:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.89 on epoch=72
05/29/2022 19:34:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.02 on epoch=73
05/29/2022 19:34:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.01 on epoch=74
05/29/2022 19:34:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.95 on epoch=74
05/29/2022 19:34:46 - INFO - __main__ - Global step 1050 Train loss 3.00 Classification-F1 0.04162431256027315 on epoch=74
05/29/2022 19:34:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.79 on epoch=75
05/29/2022 19:34:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.04 on epoch=76
05/29/2022 19:34:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.95 on epoch=77
05/29/2022 19:34:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.68 on epoch=77
05/29/2022 19:34:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.77 on epoch=78
05/29/2022 19:34:54 - INFO - __main__ - Global step 1100 Train loss 2.85 Classification-F1 0.02476678251326139 on epoch=78
05/29/2022 19:34:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.94 on epoch=79
05/29/2022 19:34:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.84 on epoch=79
05/29/2022 19:34:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.65 on epoch=80
05/29/2022 19:34:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.00 on epoch=81
05/29/2022 19:35:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.91 on epoch=82
05/29/2022 19:35:02 - INFO - __main__ - Global step 1150 Train loss 2.87 Classification-F1 0.03142285566782211 on epoch=82
05/29/2022 19:35:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.74 on epoch=82
05/29/2022 19:35:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.90 on epoch=83
05/29/2022 19:35:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.73 on epoch=84
05/29/2022 19:35:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.89 on epoch=84
05/29/2022 19:35:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.72 on epoch=85
05/29/2022 19:35:10 - INFO - __main__ - Global step 1200 Train loss 2.80 Classification-F1 0.04982771652722391 on epoch=85
05/29/2022 19:35:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.77 on epoch=86
05/29/2022 19:35:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.89 on epoch=87
05/29/2022 19:35:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.78 on epoch=87
05/29/2022 19:35:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.87 on epoch=88
05/29/2022 19:35:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.67 on epoch=89
05/29/2022 19:35:19 - INFO - __main__ - Global step 1250 Train loss 2.80 Classification-F1 0.04095367420839119 on epoch=89
05/29/2022 19:35:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.83 on epoch=89
05/29/2022 19:35:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.62 on epoch=90
05/29/2022 19:35:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.79 on epoch=91
05/29/2022 19:35:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.76 on epoch=92
05/29/2022 19:35:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.59 on epoch=92
05/29/2022 19:35:27 - INFO - __main__ - Global step 1300 Train loss 2.72 Classification-F1 0.04871858668883503 on epoch=92
05/29/2022 19:35:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.69 on epoch=93
05/29/2022 19:35:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.71 on epoch=94
05/29/2022 19:35:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.62 on epoch=94
05/29/2022 19:35:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.55 on epoch=95
05/29/2022 19:35:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.89 on epoch=96
05/29/2022 19:35:35 - INFO - __main__ - Global step 1350 Train loss 2.69 Classification-F1 0.044776292583310125 on epoch=96
05/29/2022 19:35:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.63 on epoch=97
05/29/2022 19:35:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.69 on epoch=97
05/29/2022 19:35:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.57 on epoch=98
05/29/2022 19:35:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.51 on epoch=99
05/29/2022 19:35:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.55 on epoch=99
05/29/2022 19:35:43 - INFO - __main__ - Global step 1400 Train loss 2.59 Classification-F1 0.043598641305520665 on epoch=99
05/29/2022 19:35:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.34 on epoch=100
05/29/2022 19:35:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.71 on epoch=101
05/29/2022 19:35:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.55 on epoch=102
05/29/2022 19:35:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.41 on epoch=102
05/29/2022 19:35:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.56 on epoch=103
05/29/2022 19:35:52 - INFO - __main__ - Global step 1450 Train loss 2.51 Classification-F1 0.055157706978596434 on epoch=103
05/29/2022 19:35:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.55 on epoch=104
05/29/2022 19:35:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.57 on epoch=104
05/29/2022 19:35:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.45 on epoch=105
05/29/2022 19:35:57 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.54 on epoch=106
05/29/2022 19:35:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.46 on epoch=107
05/29/2022 19:36:00 - INFO - __main__ - Global step 1500 Train loss 2.51 Classification-F1 0.04579863376285171 on epoch=107
05/29/2022 19:36:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.39 on epoch=107
05/29/2022 19:36:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.54 on epoch=108
05/29/2022 19:36:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.57 on epoch=109
05/29/2022 19:36:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.37 on epoch=109
05/29/2022 19:36:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.42 on epoch=110
05/29/2022 19:36:08 - INFO - __main__ - Global step 1550 Train loss 2.46 Classification-F1 0.08420627340464937 on epoch=110
05/29/2022 19:36:08 - INFO - __main__ - Saving model with best Classification-F1: 0.07079211716892876 -> 0.08420627340464937 on epoch=110, global_step=1550
05/29/2022 19:36:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.57 on epoch=111
05/29/2022 19:36:11 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.63 on epoch=112
05/29/2022 19:36:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.33 on epoch=112
05/29/2022 19:36:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.58 on epoch=113
05/29/2022 19:36:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.52 on epoch=114
05/29/2022 19:36:16 - INFO - __main__ - Global step 1600 Train loss 2.53 Classification-F1 0.08191283506409557 on epoch=114
05/29/2022 19:36:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.47 on epoch=114
05/29/2022 19:36:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=115
05/29/2022 19:36:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.57 on epoch=116
05/29/2022 19:36:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.39 on epoch=117
05/29/2022 19:36:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.50 on epoch=117
05/29/2022 19:36:25 - INFO - __main__ - Global step 1650 Train loss 2.44 Classification-F1 0.04409073623802994 on epoch=117
05/29/2022 19:36:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.45 on epoch=118
05/29/2022 19:36:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.42 on epoch=119
05/29/2022 19:36:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.37 on epoch=119
05/29/2022 19:36:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.39 on epoch=120
05/29/2022 19:36:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.51 on epoch=121
05/29/2022 19:36:33 - INFO - __main__ - Global step 1700 Train loss 2.43 Classification-F1 0.09792532397574416 on epoch=121
05/29/2022 19:36:33 - INFO - __main__ - Saving model with best Classification-F1: 0.08420627340464937 -> 0.09792532397574416 on epoch=121, global_step=1700
05/29/2022 19:36:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.45 on epoch=122
05/29/2022 19:36:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.33 on epoch=122
05/29/2022 19:36:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.44 on epoch=123
05/29/2022 19:36:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.38 on epoch=124
05/29/2022 19:36:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.19 on epoch=124
05/29/2022 19:36:41 - INFO - __main__ - Global step 1750 Train loss 2.36 Classification-F1 0.051051999747267325 on epoch=124
05/29/2022 19:36:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.16 on epoch=125
05/29/2022 19:36:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.55 on epoch=126
05/29/2022 19:36:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.48 on epoch=127
05/29/2022 19:36:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.19 on epoch=127
05/29/2022 19:36:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.30 on epoch=128
05/29/2022 19:36:50 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.07094516594516594 on epoch=128
05/29/2022 19:36:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.32 on epoch=129
05/29/2022 19:36:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.40 on epoch=129
05/29/2022 19:36:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.29 on epoch=130
05/29/2022 19:36:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.41 on epoch=131
05/29/2022 19:36:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.31 on epoch=132
05/29/2022 19:36:58 - INFO - __main__ - Global step 1850 Train loss 2.35 Classification-F1 0.06932476694381455 on epoch=132
05/29/2022 19:36:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.19 on epoch=132
05/29/2022 19:37:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.37 on epoch=133
05/29/2022 19:37:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.32 on epoch=134
05/29/2022 19:37:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.37 on epoch=134
05/29/2022 19:37:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.26 on epoch=135
05/29/2022 19:37:06 - INFO - __main__ - Global step 1900 Train loss 2.30 Classification-F1 0.042841462619943635 on epoch=135
05/29/2022 19:37:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.33 on epoch=136
05/29/2022 19:37:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.30 on epoch=137
05/29/2022 19:37:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.14 on epoch=137
05/29/2022 19:37:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.28 on epoch=138
05/29/2022 19:37:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.36 on epoch=139
05/29/2022 19:37:14 - INFO - __main__ - Global step 1950 Train loss 2.28 Classification-F1 0.08516601421100457 on epoch=139
05/29/2022 19:37:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.27 on epoch=139
05/29/2022 19:37:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.04 on epoch=140
05/29/2022 19:37:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.22 on epoch=141
05/29/2022 19:37:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.20 on epoch=142
05/29/2022 19:37:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.12 on epoch=142
05/29/2022 19:37:23 - INFO - __main__ - Global step 2000 Train loss 2.17 Classification-F1 0.039463635382002725 on epoch=142
05/29/2022 19:37:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.20 on epoch=143
05/29/2022 19:37:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.34 on epoch=144
05/29/2022 19:37:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.10 on epoch=144
05/29/2022 19:37:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.17 on epoch=145
05/29/2022 19:37:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.15 on epoch=146
05/29/2022 19:37:31 - INFO - __main__ - Global step 2050 Train loss 2.19 Classification-F1 0.05369386108950537 on epoch=146
05/29/2022 19:37:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.30 on epoch=147
05/29/2022 19:37:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.24 on epoch=147
05/29/2022 19:37:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.22 on epoch=148
05/29/2022 19:37:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.34 on epoch=149
05/29/2022 19:37:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.16 on epoch=149
05/29/2022 19:37:39 - INFO - __main__ - Global step 2100 Train loss 2.25 Classification-F1 0.02848831840428479 on epoch=149
05/29/2022 19:37:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.16 on epoch=150
05/29/2022 19:37:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.33 on epoch=151
05/29/2022 19:37:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.07 on epoch=152
05/29/2022 19:37:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.17 on epoch=152
05/29/2022 19:37:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.14 on epoch=153
05/29/2022 19:37:48 - INFO - __main__ - Global step 2150 Train loss 2.17 Classification-F1 0.06874547612950507 on epoch=153
05/29/2022 19:37:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.23 on epoch=154
05/29/2022 19:37:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.22 on epoch=154
05/29/2022 19:37:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.18 on epoch=155
05/29/2022 19:37:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.07 on epoch=156
05/29/2022 19:37:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.19 on epoch=157
05/29/2022 19:37:56 - INFO - __main__ - Global step 2200 Train loss 2.18 Classification-F1 0.03404810199942045 on epoch=157
05/29/2022 19:37:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.12 on epoch=157
05/29/2022 19:37:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.20 on epoch=158
05/29/2022 19:38:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.11 on epoch=159
05/29/2022 19:38:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.02 on epoch=159
05/29/2022 19:38:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.12 on epoch=160
05/29/2022 19:38:05 - INFO - __main__ - Global step 2250 Train loss 2.11 Classification-F1 0.08554525990012071 on epoch=160
05/29/2022 19:38:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.12 on epoch=161
05/29/2022 19:38:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.18 on epoch=162
05/29/2022 19:38:09 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.17 on epoch=162
05/29/2022 19:38:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.99 on epoch=163
05/29/2022 19:38:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.26 on epoch=164
05/29/2022 19:38:14 - INFO - __main__ - Global step 2300 Train loss 2.14 Classification-F1 0.07306821053428718 on epoch=164
05/29/2022 19:38:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.11 on epoch=164
05/29/2022 19:38:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.16 on epoch=165
05/29/2022 19:38:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.19 on epoch=166
05/29/2022 19:38:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.10 on epoch=167
05/29/2022 19:38:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.13 on epoch=167
05/29/2022 19:38:22 - INFO - __main__ - Global step 2350 Train loss 2.14 Classification-F1 0.08106761401291554 on epoch=167
05/29/2022 19:38:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.12 on epoch=168
05/29/2022 19:38:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.20 on epoch=169
05/29/2022 19:38:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.19 on epoch=169
05/29/2022 19:38:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.16 on epoch=170
05/29/2022 19:38:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.99 on epoch=171
05/29/2022 19:38:31 - INFO - __main__ - Global step 2400 Train loss 2.13 Classification-F1 0.1279972743356626 on epoch=171
05/29/2022 19:38:31 - INFO - __main__ - Saving model with best Classification-F1: 0.09792532397574416 -> 0.1279972743356626 on epoch=171, global_step=2400
05/29/2022 19:38:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.12 on epoch=172
05/29/2022 19:38:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.11 on epoch=172
05/29/2022 19:38:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.10 on epoch=173
05/29/2022 19:38:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.12 on epoch=174
05/29/2022 19:38:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.12 on epoch=174
05/29/2022 19:38:39 - INFO - __main__ - Global step 2450 Train loss 2.11 Classification-F1 0.08636073050262648 on epoch=174
05/29/2022 19:38:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.08 on epoch=175
05/29/2022 19:38:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.00 on epoch=176
05/29/2022 19:38:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.09 on epoch=177
05/29/2022 19:38:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.04 on epoch=177
05/29/2022 19:38:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.04 on epoch=178
05/29/2022 19:38:48 - INFO - __main__ - Global step 2500 Train loss 2.05 Classification-F1 0.08215098154857191 on epoch=178
05/29/2022 19:38:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.03 on epoch=179
05/29/2022 19:38:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.01 on epoch=179
05/29/2022 19:38:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.97 on epoch=180
05/29/2022 19:38:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.00 on epoch=181
05/29/2022 19:38:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.19 on epoch=182
05/29/2022 19:38:57 - INFO - __main__ - Global step 2550 Train loss 2.04 Classification-F1 0.0767401832527883 on epoch=182
05/29/2022 19:38:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.17 on epoch=182
05/29/2022 19:38:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.00 on epoch=183
05/29/2022 19:39:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.18 on epoch=184
05/29/2022 19:39:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.04 on epoch=184
05/29/2022 19:39:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.06 on epoch=185
05/29/2022 19:39:05 - INFO - __main__ - Global step 2600 Train loss 2.09 Classification-F1 0.11065121574539484 on epoch=185
05/29/2022 19:39:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.10 on epoch=186
05/29/2022 19:39:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.15 on epoch=187
05/29/2022 19:39:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.01 on epoch=187
05/29/2022 19:39:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.99 on epoch=188
05/29/2022 19:39:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.01 on epoch=189
05/29/2022 19:39:14 - INFO - __main__ - Global step 2650 Train loss 2.05 Classification-F1 0.12183472710166829 on epoch=189
05/29/2022 19:39:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.06 on epoch=189
05/29/2022 19:39:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.91 on epoch=190
05/29/2022 19:39:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.14 on epoch=191
05/29/2022 19:39:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.99 on epoch=192
05/29/2022 19:39:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.87 on epoch=192
05/29/2022 19:39:23 - INFO - __main__ - Global step 2700 Train loss 1.99 Classification-F1 0.06381159092780327 on epoch=192
05/29/2022 19:39:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.88 on epoch=193
05/29/2022 19:39:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.14 on epoch=194
05/29/2022 19:39:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.93 on epoch=194
05/29/2022 19:39:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.91 on epoch=195
05/29/2022 19:39:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.02 on epoch=196
05/29/2022 19:39:31 - INFO - __main__ - Global step 2750 Train loss 1.98 Classification-F1 0.09709732377799606 on epoch=196
05/29/2022 19:39:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.89 on epoch=197
05/29/2022 19:39:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.95 on epoch=197
05/29/2022 19:39:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.01 on epoch=198
05/29/2022 19:39:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.95 on epoch=199
05/29/2022 19:39:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.89 on epoch=199
05/29/2022 19:39:40 - INFO - __main__ - Global step 2800 Train loss 1.94 Classification-F1 0.032428955188632834 on epoch=199
05/29/2022 19:39:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.93 on epoch=200
05/29/2022 19:39:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.88 on epoch=201
05/29/2022 19:39:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.17 on epoch=202
05/29/2022 19:39:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.97 on epoch=202
05/29/2022 19:39:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.18 on epoch=203
05/29/2022 19:39:49 - INFO - __main__ - Global step 2850 Train loss 2.03 Classification-F1 0.06377555283497695 on epoch=203
05/29/2022 19:39:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.04 on epoch=204
05/29/2022 19:39:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.76 on epoch=204
05/29/2022 19:39:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.95 on epoch=205
05/29/2022 19:39:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.90 on epoch=206
05/29/2022 19:39:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.93 on epoch=207
05/29/2022 19:39:58 - INFO - __main__ - Global step 2900 Train loss 1.91 Classification-F1 0.1095378255541595 on epoch=207
05/29/2022 19:39:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.92 on epoch=207
05/29/2022 19:40:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.91 on epoch=208
05/29/2022 19:40:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.88 on epoch=209
05/29/2022 19:40:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.84 on epoch=209
05/29/2022 19:40:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.80 on epoch=210
05/29/2022 19:40:06 - INFO - __main__ - Global step 2950 Train loss 1.87 Classification-F1 0.14703579757647153 on epoch=210
05/29/2022 19:40:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1279972743356626 -> 0.14703579757647153 on epoch=210, global_step=2950
05/29/2022 19:40:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.94 on epoch=211
05/29/2022 19:40:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.74 on epoch=212
05/29/2022 19:40:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.85 on epoch=212
05/29/2022 19:40:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.82 on epoch=213
05/29/2022 19:40:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.97 on epoch=214
05/29/2022 19:40:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:40:14 - INFO - __main__ - Printing 3 examples
05/29/2022 19:40:14 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 19:40:14 - INFO - __main__ - ['Plant']
05/29/2022 19:40:14 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 19:40:14 - INFO - __main__ - ['Plant']
05/29/2022 19:40:14 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 19:40:14 - INFO - __main__ - ['Plant']
05/29/2022 19:40:14 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:40:14 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:40:14 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:40:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:40:14 - INFO - __main__ - Printing 3 examples
05/29/2022 19:40:14 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 19:40:14 - INFO - __main__ - ['Plant']
05/29/2022 19:40:14 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 19:40:14 - INFO - __main__ - ['Plant']
05/29/2022 19:40:14 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 19:40:14 - INFO - __main__ - ['Plant']
05/29/2022 19:40:14 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:40:14 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:40:15 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:40:15 - INFO - __main__ - Global step 3000 Train loss 1.86 Classification-F1 0.1746100375231241 on epoch=214
05/29/2022 19:40:15 - INFO - __main__ - Saving model with best Classification-F1: 0.14703579757647153 -> 0.1746100375231241 on epoch=214, global_step=3000
05/29/2022 19:40:15 - INFO - __main__ - save last model!
05/29/2022 19:40:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 19:40:15 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 19:40:15 - INFO - __main__ - Printing 3 examples
05/29/2022 19:40:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 19:40:15 - INFO - __main__ - ['Animal']
05/29/2022 19:40:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 19:40:15 - INFO - __main__ - ['Animal']
05/29/2022 19:40:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 19:40:15 - INFO - __main__ - ['Village']
05/29/2022 19:40:15 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:40:17 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:40:20 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:40:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:40:20 - INFO - __main__ - Starting training!
05/29/2022 19:40:21 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 19:41:07 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/29/2022 19:41:07 - INFO - __main__ - Classification-F1 on test data: 0.1394
05/29/2022 19:41:07 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.1746100375231241, test_performance=0.1394210518472774
05/29/2022 19:41:07 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/29/2022 19:41:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:41:08 - INFO - __main__ - Printing 3 examples
05/29/2022 19:41:08 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 19:41:08 - INFO - __main__ - ['Plant']
05/29/2022 19:41:08 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 19:41:08 - INFO - __main__ - ['Plant']
05/29/2022 19:41:08 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 19:41:08 - INFO - __main__ - ['Plant']
05/29/2022 19:41:08 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:41:08 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:41:09 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:41:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:41:09 - INFO - __main__ - Printing 3 examples
05/29/2022 19:41:09 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 19:41:09 - INFO - __main__ - ['Plant']
05/29/2022 19:41:09 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 19:41:09 - INFO - __main__ - ['Plant']
05/29/2022 19:41:09 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 19:41:09 - INFO - __main__ - ['Plant']
05/29/2022 19:41:09 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:41:09 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:41:09 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:41:14 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:41:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:41:15 - INFO - __main__ - Starting training!
05/29/2022 19:41:16 - INFO - __main__ - Step 10 Global step 10 Train loss 7.78 on epoch=0
05/29/2022 19:41:17 - INFO - __main__ - Step 20 Global step 20 Train loss 7.39 on epoch=1
05/29/2022 19:41:19 - INFO - __main__ - Step 30 Global step 30 Train loss 7.39 on epoch=2
05/29/2022 19:41:20 - INFO - __main__ - Step 40 Global step 40 Train loss 7.36 on epoch=2
05/29/2022 19:41:21 - INFO - __main__ - Step 50 Global step 50 Train loss 7.05 on epoch=3
05/29/2022 19:41:42 - INFO - __main__ - Global step 50 Train loss 7.39 Classification-F1 0.0 on epoch=3
05/29/2022 19:41:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 19:41:43 - INFO - __main__ - Step 60 Global step 60 Train loss 6.89 on epoch=4
05/29/2022 19:41:44 - INFO - __main__ - Step 70 Global step 70 Train loss 6.72 on epoch=4
05/29/2022 19:41:46 - INFO - __main__ - Step 80 Global step 80 Train loss 6.76 on epoch=5
05/29/2022 19:41:47 - INFO - __main__ - Step 90 Global step 90 Train loss 6.58 on epoch=6
05/29/2022 19:41:48 - INFO - __main__ - Step 100 Global step 100 Train loss 6.77 on epoch=7
05/29/2022 19:42:51 - INFO - __main__ - Global step 100 Train loss 6.74 Classification-F1 0.0 on epoch=7
05/29/2022 19:42:52 - INFO - __main__ - Step 110 Global step 110 Train loss 6.59 on epoch=7
05/29/2022 19:42:53 - INFO - __main__ - Step 120 Global step 120 Train loss 6.38 on epoch=8
05/29/2022 19:42:54 - INFO - __main__ - Step 130 Global step 130 Train loss 6.48 on epoch=9
05/29/2022 19:42:56 - INFO - __main__ - Step 140 Global step 140 Train loss 6.15 on epoch=9
05/29/2022 19:42:57 - INFO - __main__ - Step 150 Global step 150 Train loss 6.16 on epoch=10
05/29/2022 19:43:46 - INFO - __main__ - Global step 150 Train loss 6.35 Classification-F1 0.0 on epoch=10
05/29/2022 19:43:47 - INFO - __main__ - Step 160 Global step 160 Train loss 6.02 on epoch=11
05/29/2022 19:43:48 - INFO - __main__ - Step 170 Global step 170 Train loss 6.21 on epoch=12
05/29/2022 19:43:50 - INFO - __main__ - Step 180 Global step 180 Train loss 6.09 on epoch=12
05/29/2022 19:43:51 - INFO - __main__ - Step 190 Global step 190 Train loss 5.96 on epoch=13
05/29/2022 19:43:52 - INFO - __main__ - Step 200 Global step 200 Train loss 5.87 on epoch=14
05/29/2022 19:45:06 - INFO - __main__ - Global step 200 Train loss 6.03 Classification-F1 0.0 on epoch=14
05/29/2022 19:45:07 - INFO - __main__ - Step 210 Global step 210 Train loss 5.92 on epoch=14
05/29/2022 19:45:09 - INFO - __main__ - Step 220 Global step 220 Train loss 5.88 on epoch=15
05/29/2022 19:45:10 - INFO - __main__ - Step 230 Global step 230 Train loss 5.65 on epoch=16
05/29/2022 19:45:11 - INFO - __main__ - Step 240 Global step 240 Train loss 5.83 on epoch=17
05/29/2022 19:45:12 - INFO - __main__ - Step 250 Global step 250 Train loss 5.82 on epoch=17
05/29/2022 19:46:06 - INFO - __main__ - Global step 250 Train loss 5.82 Classification-F1 0.0 on epoch=17
05/29/2022 19:46:07 - INFO - __main__ - Step 260 Global step 260 Train loss 5.72 on epoch=18
05/29/2022 19:46:08 - INFO - __main__ - Step 270 Global step 270 Train loss 5.64 on epoch=19
05/29/2022 19:46:10 - INFO - __main__ - Step 280 Global step 280 Train loss 5.60 on epoch=19
05/29/2022 19:46:11 - INFO - __main__ - Step 290 Global step 290 Train loss 5.65 on epoch=20
05/29/2022 19:46:12 - INFO - __main__ - Step 300 Global step 300 Train loss 5.44 on epoch=21
05/29/2022 19:46:32 - INFO - __main__ - Global step 300 Train loss 5.61 Classification-F1 0.001670843776106934 on epoch=21
05/29/2022 19:46:32 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.001670843776106934 on epoch=21, global_step=300
05/29/2022 19:46:33 - INFO - __main__ - Step 310 Global step 310 Train loss 5.40 on epoch=22
05/29/2022 19:46:34 - INFO - __main__ - Step 320 Global step 320 Train loss 5.33 on epoch=22
05/29/2022 19:46:36 - INFO - __main__ - Step 330 Global step 330 Train loss 5.28 on epoch=23
05/29/2022 19:46:37 - INFO - __main__ - Step 340 Global step 340 Train loss 5.20 on epoch=24
05/29/2022 19:46:38 - INFO - __main__ - Step 350 Global step 350 Train loss 5.01 on epoch=24
05/29/2022 19:46:41 - INFO - __main__ - Global step 350 Train loss 5.24 Classification-F1 0.006211180124223603 on epoch=24
05/29/2022 19:46:41 - INFO - __main__ - Saving model with best Classification-F1: 0.001670843776106934 -> 0.006211180124223603 on epoch=24, global_step=350
05/29/2022 19:46:43 - INFO - __main__ - Step 360 Global step 360 Train loss 5.03 on epoch=25
05/29/2022 19:46:44 - INFO - __main__ - Step 370 Global step 370 Train loss 4.90 on epoch=26
05/29/2022 19:46:45 - INFO - __main__ - Step 380 Global step 380 Train loss 5.11 on epoch=27
05/29/2022 19:46:46 - INFO - __main__ - Step 390 Global step 390 Train loss 5.03 on epoch=27
05/29/2022 19:46:48 - INFO - __main__ - Step 400 Global step 400 Train loss 4.84 on epoch=28
05/29/2022 19:46:50 - INFO - __main__ - Global step 400 Train loss 4.98 Classification-F1 0.009523809523809523 on epoch=28
05/29/2022 19:46:50 - INFO - __main__ - Saving model with best Classification-F1: 0.006211180124223603 -> 0.009523809523809523 on epoch=28, global_step=400
05/29/2022 19:46:51 - INFO - __main__ - Step 410 Global step 410 Train loss 4.97 on epoch=29
05/29/2022 19:46:53 - INFO - __main__ - Step 420 Global step 420 Train loss 4.91 on epoch=29
05/29/2022 19:46:54 - INFO - __main__ - Step 430 Global step 430 Train loss 4.85 on epoch=30
05/29/2022 19:46:55 - INFO - __main__ - Step 440 Global step 440 Train loss 4.63 on epoch=31
05/29/2022 19:46:56 - INFO - __main__ - Step 450 Global step 450 Train loss 4.77 on epoch=32
05/29/2022 19:46:59 - INFO - __main__ - Global step 450 Train loss 4.83 Classification-F1 0.009523809523809523 on epoch=32
05/29/2022 19:47:00 - INFO - __main__ - Step 460 Global step 460 Train loss 4.83 on epoch=32
05/29/2022 19:47:01 - INFO - __main__ - Step 470 Global step 470 Train loss 4.56 on epoch=33
05/29/2022 19:47:02 - INFO - __main__ - Step 480 Global step 480 Train loss 4.49 on epoch=34
05/29/2022 19:47:04 - INFO - __main__ - Step 490 Global step 490 Train loss 4.41 on epoch=34
05/29/2022 19:47:05 - INFO - __main__ - Step 500 Global step 500 Train loss 4.37 on epoch=35
05/29/2022 19:47:07 - INFO - __main__ - Global step 500 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=35
05/29/2022 19:47:08 - INFO - __main__ - Step 510 Global step 510 Train loss 4.23 on epoch=36
05/29/2022 19:47:09 - INFO - __main__ - Step 520 Global step 520 Train loss 4.44 on epoch=37
05/29/2022 19:47:11 - INFO - __main__ - Step 530 Global step 530 Train loss 4.23 on epoch=37
05/29/2022 19:47:12 - INFO - __main__ - Step 540 Global step 540 Train loss 4.16 on epoch=38
05/29/2022 19:47:13 - INFO - __main__ - Step 550 Global step 550 Train loss 4.06 on epoch=39
05/29/2022 19:47:15 - INFO - __main__ - Global step 550 Train loss 4.22 Classification-F1 0.0200271395816761 on epoch=39
05/29/2022 19:47:15 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.0200271395816761 on epoch=39, global_step=550
05/29/2022 19:47:16 - INFO - __main__ - Step 560 Global step 560 Train loss 3.96 on epoch=39
05/29/2022 19:47:17 - INFO - __main__ - Step 570 Global step 570 Train loss 3.89 on epoch=40
05/29/2022 19:47:19 - INFO - __main__ - Step 580 Global step 580 Train loss 3.95 on epoch=41
05/29/2022 19:47:20 - INFO - __main__ - Step 590 Global step 590 Train loss 3.90 on epoch=42
05/29/2022 19:47:21 - INFO - __main__ - Step 600 Global step 600 Train loss 3.78 on epoch=42
05/29/2022 19:47:23 - INFO - __main__ - Global step 600 Train loss 3.90 Classification-F1 0.023094829698603287 on epoch=42
05/29/2022 19:47:23 - INFO - __main__ - Saving model with best Classification-F1: 0.0200271395816761 -> 0.023094829698603287 on epoch=42, global_step=600
05/29/2022 19:47:24 - INFO - __main__ - Step 610 Global step 610 Train loss 3.91 on epoch=43
05/29/2022 19:47:25 - INFO - __main__ - Step 620 Global step 620 Train loss 3.59 on epoch=44
05/29/2022 19:47:27 - INFO - __main__ - Step 630 Global step 630 Train loss 3.67 on epoch=44
05/29/2022 19:47:28 - INFO - __main__ - Step 640 Global step 640 Train loss 3.72 on epoch=45
05/29/2022 19:47:29 - INFO - __main__ - Step 650 Global step 650 Train loss 3.62 on epoch=46
05/29/2022 19:47:31 - INFO - __main__ - Global step 650 Train loss 3.70 Classification-F1 0.026227058329052446 on epoch=46
05/29/2022 19:47:31 - INFO - __main__ - Saving model with best Classification-F1: 0.023094829698603287 -> 0.026227058329052446 on epoch=46, global_step=650
05/29/2022 19:47:33 - INFO - __main__ - Step 660 Global step 660 Train loss 3.69 on epoch=47
05/29/2022 19:47:34 - INFO - __main__ - Step 670 Global step 670 Train loss 3.32 on epoch=47
05/29/2022 19:47:35 - INFO - __main__ - Step 680 Global step 680 Train loss 3.62 on epoch=48
05/29/2022 19:47:36 - INFO - __main__ - Step 690 Global step 690 Train loss 3.45 on epoch=49
05/29/2022 19:47:38 - INFO - __main__ - Step 700 Global step 700 Train loss 3.58 on epoch=49
05/29/2022 19:47:39 - INFO - __main__ - Global step 700 Train loss 3.53 Classification-F1 0.03942182933779572 on epoch=49
05/29/2022 19:47:39 - INFO - __main__ - Saving model with best Classification-F1: 0.026227058329052446 -> 0.03942182933779572 on epoch=49, global_step=700
05/29/2022 19:47:41 - INFO - __main__ - Step 710 Global step 710 Train loss 3.25 on epoch=50
05/29/2022 19:47:42 - INFO - __main__ - Step 720 Global step 720 Train loss 3.36 on epoch=51
05/29/2022 19:47:43 - INFO - __main__ - Step 730 Global step 730 Train loss 3.44 on epoch=52
05/29/2022 19:47:44 - INFO - __main__ - Step 740 Global step 740 Train loss 3.26 on epoch=52
05/29/2022 19:47:45 - INFO - __main__ - Step 750 Global step 750 Train loss 3.36 on epoch=53
05/29/2022 19:47:47 - INFO - __main__ - Global step 750 Train loss 3.33 Classification-F1 0.04128577441655533 on epoch=53
05/29/2022 19:47:47 - INFO - __main__ - Saving model with best Classification-F1: 0.03942182933779572 -> 0.04128577441655533 on epoch=53, global_step=750
05/29/2022 19:47:49 - INFO - __main__ - Step 760 Global step 760 Train loss 3.07 on epoch=54
05/29/2022 19:47:50 - INFO - __main__ - Step 770 Global step 770 Train loss 3.12 on epoch=54
05/29/2022 19:47:51 - INFO - __main__ - Step 780 Global step 780 Train loss 3.26 on epoch=55
05/29/2022 19:47:52 - INFO - __main__ - Step 790 Global step 790 Train loss 3.23 on epoch=56
05/29/2022 19:47:54 - INFO - __main__ - Step 800 Global step 800 Train loss 3.20 on epoch=57
05/29/2022 19:47:55 - INFO - __main__ - Global step 800 Train loss 3.18 Classification-F1 0.04330958948816501 on epoch=57
05/29/2022 19:47:56 - INFO - __main__ - Saving model with best Classification-F1: 0.04128577441655533 -> 0.04330958948816501 on epoch=57, global_step=800
05/29/2022 19:47:57 - INFO - __main__ - Step 810 Global step 810 Train loss 3.15 on epoch=57
05/29/2022 19:47:58 - INFO - __main__ - Step 820 Global step 820 Train loss 3.13 on epoch=58
05/29/2022 19:47:59 - INFO - __main__ - Step 830 Global step 830 Train loss 3.08 on epoch=59
05/29/2022 19:48:01 - INFO - __main__ - Step 840 Global step 840 Train loss 3.02 on epoch=59
05/29/2022 19:48:02 - INFO - __main__ - Step 850 Global step 850 Train loss 2.89 on epoch=60
05/29/2022 19:48:04 - INFO - __main__ - Global step 850 Train loss 3.06 Classification-F1 0.025749621205767736 on epoch=60
05/29/2022 19:48:05 - INFO - __main__ - Step 860 Global step 860 Train loss 3.19 on epoch=61
05/29/2022 19:48:06 - INFO - __main__ - Step 870 Global step 870 Train loss 3.20 on epoch=62
05/29/2022 19:48:07 - INFO - __main__ - Step 880 Global step 880 Train loss 2.77 on epoch=62
05/29/2022 19:48:09 - INFO - __main__ - Step 890 Global step 890 Train loss 2.92 on epoch=63
05/29/2022 19:48:10 - INFO - __main__ - Step 900 Global step 900 Train loss 2.99 on epoch=64
05/29/2022 19:48:12 - INFO - __main__ - Global step 900 Train loss 3.01 Classification-F1 0.030619195381172224 on epoch=64
05/29/2022 19:48:13 - INFO - __main__ - Step 910 Global step 910 Train loss 2.95 on epoch=64
05/29/2022 19:48:14 - INFO - __main__ - Step 920 Global step 920 Train loss 2.80 on epoch=65
05/29/2022 19:48:15 - INFO - __main__ - Step 930 Global step 930 Train loss 2.95 on epoch=66
05/29/2022 19:48:17 - INFO - __main__ - Step 940 Global step 940 Train loss 2.91 on epoch=67
05/29/2022 19:48:18 - INFO - __main__ - Step 950 Global step 950 Train loss 2.97 on epoch=67
05/29/2022 19:48:20 - INFO - __main__ - Global step 950 Train loss 2.91 Classification-F1 0.009523809523809523 on epoch=67
05/29/2022 19:48:21 - INFO - __main__ - Step 960 Global step 960 Train loss 3.03 on epoch=68
05/29/2022 19:48:22 - INFO - __main__ - Step 970 Global step 970 Train loss 2.95 on epoch=69
05/29/2022 19:48:23 - INFO - __main__ - Step 980 Global step 980 Train loss 2.86 on epoch=69
05/29/2022 19:48:25 - INFO - __main__ - Step 990 Global step 990 Train loss 2.64 on epoch=70
05/29/2022 19:48:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.98 on epoch=71
05/29/2022 19:48:28 - INFO - __main__ - Global step 1000 Train loss 2.89 Classification-F1 0.04597201523431032 on epoch=71
05/29/2022 19:48:28 - INFO - __main__ - Saving model with best Classification-F1: 0.04330958948816501 -> 0.04597201523431032 on epoch=71, global_step=1000
05/29/2022 19:48:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.05 on epoch=72
05/29/2022 19:48:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.94 on epoch=72
05/29/2022 19:48:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.97 on epoch=73
05/29/2022 19:48:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.79 on epoch=74
05/29/2022 19:48:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.74 on epoch=74
05/29/2022 19:48:36 - INFO - __main__ - Global step 1050 Train loss 2.90 Classification-F1 0.030529383470559942 on epoch=74
05/29/2022 19:48:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.54 on epoch=75
05/29/2022 19:48:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.83 on epoch=76
05/29/2022 19:48:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.93 on epoch=77
05/29/2022 19:48:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.87 on epoch=77
05/29/2022 19:48:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.69 on epoch=78
05/29/2022 19:48:44 - INFO - __main__ - Global step 1100 Train loss 2.77 Classification-F1 0.042616774594823985 on epoch=78
05/29/2022 19:48:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.87 on epoch=79
05/29/2022 19:48:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.73 on epoch=79
05/29/2022 19:48:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=80
05/29/2022 19:48:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.77 on epoch=81
05/29/2022 19:48:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.71 on epoch=82
05/29/2022 19:48:52 - INFO - __main__ - Global step 1150 Train loss 2.72 Classification-F1 0.009603841536614645 on epoch=82
05/29/2022 19:48:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.47 on epoch=82
05/29/2022 19:48:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=83
05/29/2022 19:48:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.77 on epoch=84
05/29/2022 19:48:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.78 on epoch=84
05/29/2022 19:48:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.63 on epoch=85
05/29/2022 19:49:00 - INFO - __main__ - Global step 1200 Train loss 2.68 Classification-F1 0.01684981684981685 on epoch=85
05/29/2022 19:49:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.80 on epoch=86
05/29/2022 19:49:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.67 on epoch=87
05/29/2022 19:49:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.51 on epoch=87
05/29/2022 19:49:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.68 on epoch=88
05/29/2022 19:49:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.71 on epoch=89
05/29/2022 19:49:08 - INFO - __main__ - Global step 1250 Train loss 2.67 Classification-F1 0.04071046005002686 on epoch=89
05/29/2022 19:49:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.52 on epoch=89
05/29/2022 19:49:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.37 on epoch=90
05/29/2022 19:49:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.63 on epoch=91
05/29/2022 19:49:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.60 on epoch=92
05/29/2022 19:49:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.68 on epoch=92
05/29/2022 19:49:16 - INFO - __main__ - Global step 1300 Train loss 2.56 Classification-F1 0.03548410668615272 on epoch=92
05/29/2022 19:49:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.67 on epoch=93
05/29/2022 19:49:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.46 on epoch=94
05/29/2022 19:49:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.65 on epoch=94
05/29/2022 19:49:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.41 on epoch=95
05/29/2022 19:49:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.72 on epoch=96
05/29/2022 19:49:24 - INFO - __main__ - Global step 1350 Train loss 2.58 Classification-F1 0.01859857243389967 on epoch=96
05/29/2022 19:49:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.52 on epoch=97
05/29/2022 19:49:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.36 on epoch=97
05/29/2022 19:49:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.51 on epoch=98
05/29/2022 19:49:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.64 on epoch=99
05/29/2022 19:49:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.49 on epoch=99
05/29/2022 19:49:32 - INFO - __main__ - Global step 1400 Train loss 2.51 Classification-F1 0.017540349473122583 on epoch=99
05/29/2022 19:49:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.36 on epoch=100
05/29/2022 19:49:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.61 on epoch=101
05/29/2022 19:49:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.43 on epoch=102
05/29/2022 19:49:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.46 on epoch=102
05/29/2022 19:49:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.51 on epoch=103
05/29/2022 19:49:40 - INFO - __main__ - Global step 1450 Train loss 2.47 Classification-F1 0.009981285090455396 on epoch=103
05/29/2022 19:49:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.57 on epoch=104
05/29/2022 19:49:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.39 on epoch=104
05/29/2022 19:49:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.39 on epoch=105
05/29/2022 19:49:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.52 on epoch=106
05/29/2022 19:49:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.50 on epoch=107
05/29/2022 19:49:48 - INFO - __main__ - Global step 1500 Train loss 2.47 Classification-F1 0.009563658099222952 on epoch=107
05/29/2022 19:49:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.37 on epoch=107
05/29/2022 19:49:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.46 on epoch=108
05/29/2022 19:49:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.46 on epoch=109
05/29/2022 19:49:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.44 on epoch=109
05/29/2022 19:49:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.31 on epoch=110
05/29/2022 19:49:56 - INFO - __main__ - Global step 1550 Train loss 2.41 Classification-F1 0.00976800976800977 on epoch=110
05/29/2022 19:49:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.71 on epoch=111
05/29/2022 19:49:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.45 on epoch=112
05/29/2022 19:50:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.38 on epoch=112
05/29/2022 19:50:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.44 on epoch=113
05/29/2022 19:50:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.46 on epoch=114
05/29/2022 19:50:04 - INFO - __main__ - Global step 1600 Train loss 2.49 Classification-F1 0.02539843523616343 on epoch=114
05/29/2022 19:50:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.39 on epoch=114
05/29/2022 19:50:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.27 on epoch=115
05/29/2022 19:50:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.54 on epoch=116
05/29/2022 19:50:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.46 on epoch=117
05/29/2022 19:50:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.42 on epoch=117
05/29/2022 19:50:12 - INFO - __main__ - Global step 1650 Train loss 2.42 Classification-F1 0.03448045885020675 on epoch=117
05/29/2022 19:50:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.38 on epoch=118
05/29/2022 19:50:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.40 on epoch=119
05/29/2022 19:50:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.36 on epoch=119
05/29/2022 19:50:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.26 on epoch=120
05/29/2022 19:50:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.43 on epoch=121
05/29/2022 19:50:20 - INFO - __main__ - Global step 1700 Train loss 2.37 Classification-F1 0.03299880671908943 on epoch=121
05/29/2022 19:50:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.34 on epoch=122
05/29/2022 19:50:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.42 on epoch=122
05/29/2022 19:50:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.38 on epoch=123
05/29/2022 19:50:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.33 on epoch=124
05/29/2022 19:50:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.44 on epoch=124
05/29/2022 19:50:28 - INFO - __main__ - Global step 1750 Train loss 2.38 Classification-F1 0.009644364074743823 on epoch=124
05/29/2022 19:50:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.19 on epoch=125
05/29/2022 19:50:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.38 on epoch=126
05/29/2022 19:50:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.32 on epoch=127
05/29/2022 19:50:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.35 on epoch=127
05/29/2022 19:50:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.41 on epoch=128
05/29/2022 19:50:37 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.009563658099222952 on epoch=128
05/29/2022 19:50:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.53 on epoch=129
05/29/2022 19:50:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.26 on epoch=129
05/29/2022 19:50:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.29 on epoch=130
05/29/2022 19:50:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.44 on epoch=131
05/29/2022 19:50:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.28 on epoch=132
05/29/2022 19:50:45 - INFO - __main__ - Global step 1850 Train loss 2.36 Classification-F1 0.01821329390125149 on epoch=132
05/29/2022 19:50:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.24 on epoch=132
05/29/2022 19:50:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.30 on epoch=133
05/29/2022 19:50:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.20 on epoch=134
05/29/2022 19:50:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.31 on epoch=134
05/29/2022 19:50:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.17 on epoch=135
05/29/2022 19:50:53 - INFO - __main__ - Global step 1900 Train loss 2.24 Classification-F1 0.0173015873015873 on epoch=135
05/29/2022 19:50:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.34 on epoch=136
05/29/2022 19:50:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.45 on epoch=137
05/29/2022 19:50:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.17 on epoch=137
05/29/2022 19:50:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.26 on epoch=138
05/29/2022 19:50:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.28 on epoch=139
05/29/2022 19:51:01 - INFO - __main__ - Global step 1950 Train loss 2.30 Classification-F1 0.03815945890551342 on epoch=139
05/29/2022 19:51:02 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.24 on epoch=139
05/29/2022 19:51:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.12 on epoch=140
05/29/2022 19:51:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.34 on epoch=141
05/29/2022 19:51:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.19 on epoch=142
05/29/2022 19:51:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.11 on epoch=142
05/29/2022 19:51:09 - INFO - __main__ - Global step 2000 Train loss 2.20 Classification-F1 0.03237537026533056 on epoch=142
05/29/2022 19:51:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.27 on epoch=143
05/29/2022 19:51:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.30 on epoch=144
05/29/2022 19:51:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.21 on epoch=144
05/29/2022 19:51:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.16 on epoch=145
05/29/2022 19:51:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.23 on epoch=146
05/29/2022 19:51:17 - INFO - __main__ - Global step 2050 Train loss 2.23 Classification-F1 0.031266119501413614 on epoch=146
05/29/2022 19:51:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.09 on epoch=147
05/29/2022 19:51:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.17 on epoch=147
05/29/2022 19:51:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.14 on epoch=148
05/29/2022 19:51:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.17 on epoch=149
05/29/2022 19:51:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.28 on epoch=149
05/29/2022 19:51:25 - INFO - __main__ - Global step 2100 Train loss 2.17 Classification-F1 0.047908962382646594 on epoch=149
05/29/2022 19:51:25 - INFO - __main__ - Saving model with best Classification-F1: 0.04597201523431032 -> 0.047908962382646594 on epoch=149, global_step=2100
05/29/2022 19:51:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.12 on epoch=150
05/29/2022 19:51:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.21 on epoch=151
05/29/2022 19:51:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.16 on epoch=152
05/29/2022 19:51:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.13 on epoch=152
05/29/2022 19:51:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.14 on epoch=153
05/29/2022 19:51:33 - INFO - __main__ - Global step 2150 Train loss 2.15 Classification-F1 0.040203935408440264 on epoch=153
05/29/2022 19:51:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.17 on epoch=154
05/29/2022 19:51:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.14 on epoch=154
05/29/2022 19:51:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.07 on epoch=155
05/29/2022 19:51:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.20 on epoch=156
05/29/2022 19:51:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.19 on epoch=157
05/29/2022 19:51:42 - INFO - __main__ - Global step 2200 Train loss 2.15 Classification-F1 0.04658091524450971 on epoch=157
05/29/2022 19:51:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.11 on epoch=157
05/29/2022 19:51:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.13 on epoch=158
05/29/2022 19:51:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.35 on epoch=159
05/29/2022 19:51:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.09 on epoch=159
05/29/2022 19:51:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.99 on epoch=160
05/29/2022 19:51:50 - INFO - __main__ - Global step 2250 Train loss 2.13 Classification-F1 0.03142928223640453 on epoch=160
05/29/2022 19:51:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.15 on epoch=161
05/29/2022 19:51:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.13 on epoch=162
05/29/2022 19:51:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.94 on epoch=162
05/29/2022 19:51:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.16 on epoch=163
05/29/2022 19:51:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.10 on epoch=164
05/29/2022 19:51:58 - INFO - __main__ - Global step 2300 Train loss 2.10 Classification-F1 0.02653453274246962 on epoch=164
05/29/2022 19:51:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.95 on epoch=164
05/29/2022 19:52:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.14 on epoch=165
05/29/2022 19:52:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.14 on epoch=166
05/29/2022 19:52:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.97 on epoch=167
05/29/2022 19:52:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.98 on epoch=167
05/29/2022 19:52:06 - INFO - __main__ - Global step 2350 Train loss 2.03 Classification-F1 0.02191401320321181 on epoch=167
05/29/2022 19:52:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.04 on epoch=168
05/29/2022 19:52:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.17 on epoch=169
05/29/2022 19:52:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.05 on epoch=169
05/29/2022 19:52:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.94 on epoch=170
05/29/2022 19:52:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.14 on epoch=171
05/29/2022 19:52:14 - INFO - __main__ - Global step 2400 Train loss 2.07 Classification-F1 0.06162667804206133 on epoch=171
05/29/2022 19:52:14 - INFO - __main__ - Saving model with best Classification-F1: 0.047908962382646594 -> 0.06162667804206133 on epoch=171, global_step=2400
05/29/2022 19:52:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.08 on epoch=172
05/29/2022 19:52:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.06 on epoch=172
05/29/2022 19:52:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.03 on epoch=173
05/29/2022 19:52:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.25 on epoch=174
05/29/2022 19:52:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.04 on epoch=174
05/29/2022 19:52:22 - INFO - __main__ - Global step 2450 Train loss 2.09 Classification-F1 0.06436763743985287 on epoch=174
05/29/2022 19:52:22 - INFO - __main__ - Saving model with best Classification-F1: 0.06162667804206133 -> 0.06436763743985287 on epoch=174, global_step=2450
05/29/2022 19:52:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.00 on epoch=175
05/29/2022 19:52:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.16 on epoch=176
05/29/2022 19:52:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.08 on epoch=177
05/29/2022 19:52:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.10 on epoch=177
05/29/2022 19:52:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.06 on epoch=178
05/29/2022 19:52:30 - INFO - __main__ - Global step 2500 Train loss 2.08 Classification-F1 0.03567792771041884 on epoch=178
05/29/2022 19:52:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.07 on epoch=179
05/29/2022 19:52:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.03 on epoch=179
05/29/2022 19:52:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.98 on epoch=180
05/29/2022 19:52:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.07 on epoch=181
05/29/2022 19:52:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.02 on epoch=182
05/29/2022 19:52:38 - INFO - __main__ - Global step 2550 Train loss 2.03 Classification-F1 0.06633062282805793 on epoch=182
05/29/2022 19:52:38 - INFO - __main__ - Saving model with best Classification-F1: 0.06436763743985287 -> 0.06633062282805793 on epoch=182, global_step=2550
05/29/2022 19:52:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.96 on epoch=182
05/29/2022 19:52:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.10 on epoch=183
05/29/2022 19:52:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.07 on epoch=184
05/29/2022 19:52:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.88 on epoch=184
05/29/2022 19:52:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.89 on epoch=185
05/29/2022 19:52:46 - INFO - __main__ - Global step 2600 Train loss 1.98 Classification-F1 0.05829225322812231 on epoch=185
05/29/2022 19:52:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.04 on epoch=186
05/29/2022 19:52:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.06 on epoch=187
05/29/2022 19:52:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.01 on epoch=187
05/29/2022 19:52:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.91 on epoch=188
05/29/2022 19:52:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.95 on epoch=189
05/29/2022 19:52:54 - INFO - __main__ - Global step 2650 Train loss 1.99 Classification-F1 0.05541127650661119 on epoch=189
05/29/2022 19:52:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.04 on epoch=189
05/29/2022 19:52:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.94 on epoch=190
05/29/2022 19:52:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.77 on epoch=191
05/29/2022 19:52:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.97 on epoch=192
05/29/2022 19:53:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.04 on epoch=192
05/29/2022 19:53:02 - INFO - __main__ - Global step 2700 Train loss 1.95 Classification-F1 0.05029732751317736 on epoch=192
05/29/2022 19:53:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.92 on epoch=193
05/29/2022 19:53:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.04 on epoch=194
05/29/2022 19:53:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.01 on epoch=194
05/29/2022 19:53:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.81 on epoch=195
05/29/2022 19:53:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.97 on epoch=196
05/29/2022 19:53:10 - INFO - __main__ - Global step 2750 Train loss 1.95 Classification-F1 0.06288139392173114 on epoch=196
05/29/2022 19:53:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.90 on epoch=197
05/29/2022 19:53:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.83 on epoch=197
05/29/2022 19:53:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.89 on epoch=198
05/29/2022 19:53:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.89 on epoch=199
05/29/2022 19:53:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.88 on epoch=199
05/29/2022 19:53:18 - INFO - __main__ - Global step 2800 Train loss 1.88 Classification-F1 0.06757184355223571 on epoch=199
05/29/2022 19:53:19 - INFO - __main__ - Saving model with best Classification-F1: 0.06633062282805793 -> 0.06757184355223571 on epoch=199, global_step=2800
05/29/2022 19:53:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.95 on epoch=200
05/29/2022 19:53:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.94 on epoch=201
05/29/2022 19:53:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.98 on epoch=202
05/29/2022 19:53:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.81 on epoch=202
05/29/2022 19:53:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.82 on epoch=203
05/29/2022 19:53:27 - INFO - __main__ - Global step 2850 Train loss 1.90 Classification-F1 0.08760807839209815 on epoch=203
05/29/2022 19:53:27 - INFO - __main__ - Saving model with best Classification-F1: 0.06757184355223571 -> 0.08760807839209815 on epoch=203, global_step=2850
05/29/2022 19:53:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.87 on epoch=204
05/29/2022 19:53:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.96 on epoch=204
05/29/2022 19:53:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.81 on epoch=205
05/29/2022 19:53:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.86 on epoch=206
05/29/2022 19:53:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.80 on epoch=207
05/29/2022 19:53:35 - INFO - __main__ - Global step 2900 Train loss 1.86 Classification-F1 0.09128023537141387 on epoch=207
05/29/2022 19:53:35 - INFO - __main__ - Saving model with best Classification-F1: 0.08760807839209815 -> 0.09128023537141387 on epoch=207, global_step=2900
05/29/2022 19:53:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.81 on epoch=207
05/29/2022 19:53:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.80 on epoch=208
05/29/2022 19:53:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.82 on epoch=209
05/29/2022 19:53:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.84 on epoch=209
05/29/2022 19:53:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.77 on epoch=210
05/29/2022 19:53:43 - INFO - __main__ - Global step 2950 Train loss 1.81 Classification-F1 0.07217303302729187 on epoch=210
05/29/2022 19:53:44 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.91 on epoch=211
05/29/2022 19:53:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.99 on epoch=212
05/29/2022 19:53:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.92 on epoch=212
05/29/2022 19:53:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.74 on epoch=213
05/29/2022 19:53:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.80 on epoch=214
05/29/2022 19:53:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:53:50 - INFO - __main__ - Printing 3 examples
05/29/2022 19:53:50 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 19:53:50 - INFO - __main__ - ['Plant']
05/29/2022 19:53:50 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 19:53:50 - INFO - __main__ - ['Plant']
05/29/2022 19:53:50 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 19:53:50 - INFO - __main__ - ['Plant']
05/29/2022 19:53:50 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:53:50 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:53:50 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:53:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:53:50 - INFO - __main__ - Printing 3 examples
05/29/2022 19:53:50 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 19:53:50 - INFO - __main__ - ['Plant']
05/29/2022 19:53:50 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 19:53:50 - INFO - __main__ - ['Plant']
05/29/2022 19:53:50 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 19:53:50 - INFO - __main__ - ['Plant']
05/29/2022 19:53:50 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:53:51 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:53:51 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:53:51 - INFO - __main__ - Global step 3000 Train loss 1.87 Classification-F1 0.04565594353683502 on epoch=214
05/29/2022 19:53:51 - INFO - __main__ - save last model!
05/29/2022 19:53:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 19:53:51 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 19:53:51 - INFO - __main__ - Printing 3 examples
05/29/2022 19:53:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 19:53:51 - INFO - __main__ - ['Animal']
05/29/2022 19:53:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 19:53:51 - INFO - __main__ - ['Animal']
05/29/2022 19:53:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 19:53:51 - INFO - __main__ - ['Village']
05/29/2022 19:53:51 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:53:53 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:53:56 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:53:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:53:56 - INFO - __main__ - Starting training!
05/29/2022 19:53:56 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 19:54:27 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/29/2022 19:54:27 - INFO - __main__ - Classification-F1 on test data: 0.0481
05/29/2022 19:54:27 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.09128023537141387, test_performance=0.04810263099986528
05/29/2022 19:54:27 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/29/2022 19:54:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:54:28 - INFO - __main__ - Printing 3 examples
05/29/2022 19:54:28 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 19:54:28 - INFO - __main__ - ['Plant']
05/29/2022 19:54:28 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 19:54:28 - INFO - __main__ - ['Plant']
05/29/2022 19:54:28 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 19:54:28 - INFO - __main__ - ['Plant']
05/29/2022 19:54:28 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:54:28 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:54:28 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 19:54:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 19:54:28 - INFO - __main__ - Printing 3 examples
05/29/2022 19:54:28 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 19:54:28 - INFO - __main__ - ['Plant']
05/29/2022 19:54:28 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 19:54:28 - INFO - __main__ - ['Plant']
05/29/2022 19:54:28 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 19:54:28 - INFO - __main__ - ['Plant']
05/29/2022 19:54:28 - INFO - __main__ - Tokenizing Input ...
05/29/2022 19:54:28 - INFO - __main__ - Tokenizing Output ...
05/29/2022 19:54:29 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 19:54:35 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 19:54:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 19:54:35 - INFO - __main__ - Starting training!
05/29/2022 19:54:37 - INFO - __main__ - Step 10 Global step 10 Train loss 7.74 on epoch=0
05/29/2022 19:54:38 - INFO - __main__ - Step 20 Global step 20 Train loss 7.41 on epoch=1
05/29/2022 19:54:39 - INFO - __main__ - Step 30 Global step 30 Train loss 7.65 on epoch=2
05/29/2022 19:54:40 - INFO - __main__ - Step 40 Global step 40 Train loss 7.47 on epoch=2
05/29/2022 19:54:41 - INFO - __main__ - Step 50 Global step 50 Train loss 7.26 on epoch=3
05/29/2022 19:54:50 - INFO - __main__ - Global step 50 Train loss 7.51 Classification-F1 0.0 on epoch=3
05/29/2022 19:54:50 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 19:54:52 - INFO - __main__ - Step 60 Global step 60 Train loss 7.30 on epoch=4
05/29/2022 19:54:53 - INFO - __main__ - Step 70 Global step 70 Train loss 7.07 on epoch=4
05/29/2022 19:54:54 - INFO - __main__ - Step 80 Global step 80 Train loss 7.14 on epoch=5
05/29/2022 19:54:55 - INFO - __main__ - Step 90 Global step 90 Train loss 6.97 on epoch=6
05/29/2022 19:54:57 - INFO - __main__ - Step 100 Global step 100 Train loss 7.04 on epoch=7
05/29/2022 19:55:56 - INFO - __main__ - Global step 100 Train loss 7.10 Classification-F1 0.0 on epoch=7
05/29/2022 19:55:58 - INFO - __main__ - Step 110 Global step 110 Train loss 7.12 on epoch=7
05/29/2022 19:55:59 - INFO - __main__ - Step 120 Global step 120 Train loss 6.70 on epoch=8
05/29/2022 19:56:00 - INFO - __main__ - Step 130 Global step 130 Train loss 6.77 on epoch=9
05/29/2022 19:56:01 - INFO - __main__ - Step 140 Global step 140 Train loss 6.68 on epoch=9
05/29/2022 19:56:03 - INFO - __main__ - Step 150 Global step 150 Train loss 6.67 on epoch=10
05/29/2022 19:57:16 - INFO - __main__ - Global step 150 Train loss 6.79 Classification-F1 0.0 on epoch=10
05/29/2022 19:57:17 - INFO - __main__ - Step 160 Global step 160 Train loss 6.48 on epoch=11
05/29/2022 19:57:18 - INFO - __main__ - Step 170 Global step 170 Train loss 6.59 on epoch=12
05/29/2022 19:57:20 - INFO - __main__ - Step 180 Global step 180 Train loss 6.62 on epoch=12
05/29/2022 19:57:21 - INFO - __main__ - Step 190 Global step 190 Train loss 6.37 on epoch=13
05/29/2022 19:57:22 - INFO - __main__ - Step 200 Global step 200 Train loss 6.38 on epoch=14
05/29/2022 19:58:10 - INFO - __main__ - Global step 200 Train loss 6.49 Classification-F1 0.0 on epoch=14
05/29/2022 19:58:12 - INFO - __main__ - Step 210 Global step 210 Train loss 6.33 on epoch=14
05/29/2022 19:58:13 - INFO - __main__ - Step 220 Global step 220 Train loss 6.35 on epoch=15
05/29/2022 19:58:14 - INFO - __main__ - Step 230 Global step 230 Train loss 6.10 on epoch=16
05/29/2022 19:58:15 - INFO - __main__ - Step 240 Global step 240 Train loss 6.30 on epoch=17
05/29/2022 19:58:17 - INFO - __main__ - Step 250 Global step 250 Train loss 6.19 on epoch=17
05/29/2022 19:59:07 - INFO - __main__ - Global step 250 Train loss 6.26 Classification-F1 0.0 on epoch=17
05/29/2022 19:59:08 - INFO - __main__ - Step 260 Global step 260 Train loss 6.18 on epoch=18
05/29/2022 19:59:09 - INFO - __main__ - Step 270 Global step 270 Train loss 6.12 on epoch=19
05/29/2022 19:59:11 - INFO - __main__ - Step 280 Global step 280 Train loss 5.94 on epoch=19
05/29/2022 19:59:12 - INFO - __main__ - Step 290 Global step 290 Train loss 5.96 on epoch=20
05/29/2022 19:59:13 - INFO - __main__ - Step 300 Global step 300 Train loss 5.96 on epoch=21
05/29/2022 20:00:18 - INFO - __main__ - Global step 300 Train loss 6.03 Classification-F1 0.0 on epoch=21
05/29/2022 20:00:20 - INFO - __main__ - Step 310 Global step 310 Train loss 6.02 on epoch=22
05/29/2022 20:00:21 - INFO - __main__ - Step 320 Global step 320 Train loss 6.03 on epoch=22
05/29/2022 20:00:22 - INFO - __main__ - Step 330 Global step 330 Train loss 5.73 on epoch=23
05/29/2022 20:00:23 - INFO - __main__ - Step 340 Global step 340 Train loss 5.73 on epoch=24
05/29/2022 20:00:25 - INFO - __main__ - Step 350 Global step 350 Train loss 5.77 on epoch=24
05/29/2022 20:01:07 - INFO - __main__ - Global step 350 Train loss 5.86 Classification-F1 0.0 on epoch=24
05/29/2022 20:01:08 - INFO - __main__ - Step 360 Global step 360 Train loss 5.53 on epoch=25
05/29/2022 20:01:09 - INFO - __main__ - Step 370 Global step 370 Train loss 5.70 on epoch=26
05/29/2022 20:01:10 - INFO - __main__ - Step 380 Global step 380 Train loss 5.71 on epoch=27
05/29/2022 20:01:12 - INFO - __main__ - Step 390 Global step 390 Train loss 5.69 on epoch=27
05/29/2022 20:01:13 - INFO - __main__ - Step 400 Global step 400 Train loss 5.53 on epoch=28
05/29/2022 20:02:22 - INFO - __main__ - Global step 400 Train loss 5.63 Classification-F1 0.0 on epoch=28
05/29/2022 20:02:24 - INFO - __main__ - Step 410 Global step 410 Train loss 5.64 on epoch=29
05/29/2022 20:02:25 - INFO - __main__ - Step 420 Global step 420 Train loss 5.48 on epoch=29
05/29/2022 20:02:26 - INFO - __main__ - Step 430 Global step 430 Train loss 5.49 on epoch=30
05/29/2022 20:02:27 - INFO - __main__ - Step 440 Global step 440 Train loss 5.38 on epoch=31
05/29/2022 20:02:29 - INFO - __main__ - Step 450 Global step 450 Train loss 5.32 on epoch=32
05/29/2022 20:03:40 - INFO - __main__ - Global step 450 Train loss 5.46 Classification-F1 0.0 on epoch=32
05/29/2022 20:03:41 - INFO - __main__ - Step 460 Global step 460 Train loss 5.43 on epoch=32
05/29/2022 20:03:42 - INFO - __main__ - Step 470 Global step 470 Train loss 5.33 on epoch=33
05/29/2022 20:03:43 - INFO - __main__ - Step 480 Global step 480 Train loss 5.38 on epoch=34
05/29/2022 20:03:45 - INFO - __main__ - Step 490 Global step 490 Train loss 5.24 on epoch=34
05/29/2022 20:03:46 - INFO - __main__ - Step 500 Global step 500 Train loss 5.12 on epoch=35
05/29/2022 20:04:35 - INFO - __main__ - Global step 500 Train loss 5.30 Classification-F1 0.0 on epoch=35
05/29/2022 20:04:36 - INFO - __main__ - Step 510 Global step 510 Train loss 5.14 on epoch=36
05/29/2022 20:04:37 - INFO - __main__ - Step 520 Global step 520 Train loss 5.22 on epoch=37
05/29/2022 20:04:39 - INFO - __main__ - Step 530 Global step 530 Train loss 5.14 on epoch=37
05/29/2022 20:04:40 - INFO - __main__ - Step 540 Global step 540 Train loss 5.02 on epoch=38
05/29/2022 20:04:41 - INFO - __main__ - Step 550 Global step 550 Train loss 5.01 on epoch=39
05/29/2022 20:04:52 - INFO - __main__ - Global step 550 Train loss 5.10 Classification-F1 0.0 on epoch=39
05/29/2022 20:04:53 - INFO - __main__ - Step 560 Global step 560 Train loss 5.00 on epoch=39
05/29/2022 20:04:55 - INFO - __main__ - Step 570 Global step 570 Train loss 4.98 on epoch=40
05/29/2022 20:04:56 - INFO - __main__ - Step 580 Global step 580 Train loss 4.91 on epoch=41
05/29/2022 20:04:57 - INFO - __main__ - Step 590 Global step 590 Train loss 5.16 on epoch=42
05/29/2022 20:04:58 - INFO - __main__ - Step 600 Global step 600 Train loss 5.00 on epoch=42
05/29/2022 20:05:06 - INFO - __main__ - Global step 600 Train loss 5.01 Classification-F1 0.0 on epoch=42
05/29/2022 20:05:08 - INFO - __main__ - Step 610 Global step 610 Train loss 4.83 on epoch=43
05/29/2022 20:05:09 - INFO - __main__ - Step 620 Global step 620 Train loss 4.76 on epoch=44
05/29/2022 20:05:10 - INFO - __main__ - Step 630 Global step 630 Train loss 4.78 on epoch=44
05/29/2022 20:05:11 - INFO - __main__ - Step 640 Global step 640 Train loss 4.79 on epoch=45
05/29/2022 20:05:13 - INFO - __main__ - Step 650 Global step 650 Train loss 4.73 on epoch=46
05/29/2022 20:05:15 - INFO - __main__ - Global step 650 Train loss 4.78 Classification-F1 0.010551948051948054 on epoch=46
05/29/2022 20:05:15 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.010551948051948054 on epoch=46, global_step=650
05/29/2022 20:05:16 - INFO - __main__ - Step 660 Global step 660 Train loss 4.65 on epoch=47
05/29/2022 20:05:18 - INFO - __main__ - Step 670 Global step 670 Train loss 4.73 on epoch=47
05/29/2022 20:05:19 - INFO - __main__ - Step 680 Global step 680 Train loss 4.60 on epoch=48
05/29/2022 20:05:20 - INFO - __main__ - Step 690 Global step 690 Train loss 4.53 on epoch=49
05/29/2022 20:05:21 - INFO - __main__ - Step 700 Global step 700 Train loss 4.64 on epoch=49
05/29/2022 20:05:23 - INFO - __main__ - Global step 700 Train loss 4.63 Classification-F1 0.009006473402758232 on epoch=49
05/29/2022 20:05:24 - INFO - __main__ - Step 710 Global step 710 Train loss 4.57 on epoch=50
05/29/2022 20:05:26 - INFO - __main__ - Step 720 Global step 720 Train loss 4.44 on epoch=51
05/29/2022 20:05:27 - INFO - __main__ - Step 730 Global step 730 Train loss 4.56 on epoch=52
05/29/2022 20:05:28 - INFO - __main__ - Step 740 Global step 740 Train loss 4.48 on epoch=52
05/29/2022 20:05:29 - INFO - __main__ - Step 750 Global step 750 Train loss 4.22 on epoch=53
05/29/2022 20:05:31 - INFO - __main__ - Global step 750 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=53
05/29/2022 20:05:33 - INFO - __main__ - Step 760 Global step 760 Train loss 4.20 on epoch=54
05/29/2022 20:05:34 - INFO - __main__ - Step 770 Global step 770 Train loss 4.25 on epoch=54
05/29/2022 20:05:35 - INFO - __main__ - Step 780 Global step 780 Train loss 4.29 on epoch=55
05/29/2022 20:05:36 - INFO - __main__ - Step 790 Global step 790 Train loss 4.20 on epoch=56
05/29/2022 20:05:38 - INFO - __main__ - Step 800 Global step 800 Train loss 4.21 on epoch=57
05/29/2022 20:05:39 - INFO - __main__ - Global step 800 Train loss 4.23 Classification-F1 0.008438818565400845 on epoch=57
05/29/2022 20:05:41 - INFO - __main__ - Step 810 Global step 810 Train loss 4.12 on epoch=57
05/29/2022 20:05:42 - INFO - __main__ - Step 820 Global step 820 Train loss 4.10 on epoch=58
05/29/2022 20:05:43 - INFO - __main__ - Step 830 Global step 830 Train loss 4.13 on epoch=59
05/29/2022 20:05:44 - INFO - __main__ - Step 840 Global step 840 Train loss 3.90 on epoch=59
05/29/2022 20:05:46 - INFO - __main__ - Step 850 Global step 850 Train loss 3.88 on epoch=60
05/29/2022 20:05:48 - INFO - __main__ - Global step 850 Train loss 4.03 Classification-F1 0.00892608089260809 on epoch=60
05/29/2022 20:05:49 - INFO - __main__ - Step 860 Global step 860 Train loss 3.96 on epoch=61
05/29/2022 20:05:50 - INFO - __main__ - Step 870 Global step 870 Train loss 3.83 on epoch=62
05/29/2022 20:05:51 - INFO - __main__ - Step 880 Global step 880 Train loss 3.85 on epoch=62
05/29/2022 20:05:53 - INFO - __main__ - Step 890 Global step 890 Train loss 3.84 on epoch=63
05/29/2022 20:05:54 - INFO - __main__ - Step 900 Global step 900 Train loss 4.04 on epoch=64
05/29/2022 20:05:56 - INFO - __main__ - Global step 900 Train loss 3.90 Classification-F1 0.009563658099222952 on epoch=64
05/29/2022 20:05:57 - INFO - __main__ - Step 910 Global step 910 Train loss 3.89 on epoch=64
05/29/2022 20:05:58 - INFO - __main__ - Step 920 Global step 920 Train loss 3.71 on epoch=65
05/29/2022 20:05:59 - INFO - __main__ - Step 930 Global step 930 Train loss 3.83 on epoch=66
05/29/2022 20:06:01 - INFO - __main__ - Step 940 Global step 940 Train loss 3.79 on epoch=67
05/29/2022 20:06:02 - INFO - __main__ - Step 950 Global step 950 Train loss 3.78 on epoch=67
05/29/2022 20:06:04 - INFO - __main__ - Global step 950 Train loss 3.80 Classification-F1 0.008403361344537815 on epoch=67
05/29/2022 20:06:05 - INFO - __main__ - Step 960 Global step 960 Train loss 4.01 on epoch=68
05/29/2022 20:06:06 - INFO - __main__ - Step 970 Global step 970 Train loss 3.76 on epoch=69
05/29/2022 20:06:08 - INFO - __main__ - Step 980 Global step 980 Train loss 3.90 on epoch=69
05/29/2022 20:06:09 - INFO - __main__ - Step 990 Global step 990 Train loss 3.68 on epoch=70
05/29/2022 20:06:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.54 on epoch=71
05/29/2022 20:06:12 - INFO - __main__ - Global step 1000 Train loss 3.78 Classification-F1 0.02133884387405514 on epoch=71
05/29/2022 20:06:12 - INFO - __main__ - Saving model with best Classification-F1: 0.010551948051948054 -> 0.02133884387405514 on epoch=71, global_step=1000
05/29/2022 20:06:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.65 on epoch=72
05/29/2022 20:06:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.48 on epoch=72
05/29/2022 20:06:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.67 on epoch=73
05/29/2022 20:06:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.54 on epoch=74
05/29/2022 20:06:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.67 on epoch=74
05/29/2022 20:06:20 - INFO - __main__ - Global step 1050 Train loss 3.60 Classification-F1 0.018692796635061626 on epoch=74
05/29/2022 20:06:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.41 on epoch=75
05/29/2022 20:06:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.68 on epoch=76
05/29/2022 20:06:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.65 on epoch=77
05/29/2022 20:06:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.46 on epoch=77
05/29/2022 20:06:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.61 on epoch=78
05/29/2022 20:06:28 - INFO - __main__ - Global step 1100 Train loss 3.56 Classification-F1 0.01785945147289685 on epoch=78
05/29/2022 20:06:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.41 on epoch=79
05/29/2022 20:06:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.49 on epoch=79
05/29/2022 20:06:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.52 on epoch=80
05/29/2022 20:06:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.41 on epoch=81
05/29/2022 20:06:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.72 on epoch=82
05/29/2022 20:06:36 - INFO - __main__ - Global step 1150 Train loss 3.51 Classification-F1 0.021158827539195638 on epoch=82
05/29/2022 20:06:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.38 on epoch=82
05/29/2022 20:06:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.46 on epoch=83
05/29/2022 20:06:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.49 on epoch=84
05/29/2022 20:06:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.56 on epoch=84
05/29/2022 20:06:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.22 on epoch=85
05/29/2022 20:06:45 - INFO - __main__ - Global step 1200 Train loss 3.42 Classification-F1 0.02825489922264116 on epoch=85
05/29/2022 20:06:45 - INFO - __main__ - Saving model with best Classification-F1: 0.02133884387405514 -> 0.02825489922264116 on epoch=85, global_step=1200
05/29/2022 20:06:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.31 on epoch=86
05/29/2022 20:06:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.32 on epoch=87
05/29/2022 20:06:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.19 on epoch=87
05/29/2022 20:06:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.28 on epoch=88
05/29/2022 20:06:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.41 on epoch=89
05/29/2022 20:06:53 - INFO - __main__ - Global step 1250 Train loss 3.30 Classification-F1 0.0325978344554196 on epoch=89
05/29/2022 20:06:53 - INFO - __main__ - Saving model with best Classification-F1: 0.02825489922264116 -> 0.0325978344554196 on epoch=89, global_step=1250
05/29/2022 20:06:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.33 on epoch=89
05/29/2022 20:06:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.25 on epoch=90
05/29/2022 20:06:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.26 on epoch=91
05/29/2022 20:06:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.31 on epoch=92
05/29/2022 20:06:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.23 on epoch=92
05/29/2022 20:07:01 - INFO - __main__ - Global step 1300 Train loss 3.28 Classification-F1 0.020044802867383513 on epoch=92
05/29/2022 20:07:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.28 on epoch=93
05/29/2022 20:07:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.30 on epoch=94
05/29/2022 20:07:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.23 on epoch=94
05/29/2022 20:07:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.20 on epoch=95
05/29/2022 20:07:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.12 on epoch=96
05/29/2022 20:07:09 - INFO - __main__ - Global step 1350 Train loss 3.23 Classification-F1 0.02570638511814982 on epoch=96
05/29/2022 20:07:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.22 on epoch=97
05/29/2022 20:07:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.26 on epoch=97
05/29/2022 20:07:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.21 on epoch=98
05/29/2022 20:07:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.35 on epoch=99
05/29/2022 20:07:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.35 on epoch=99
05/29/2022 20:07:17 - INFO - __main__ - Global step 1400 Train loss 3.28 Classification-F1 0.03740617807554927 on epoch=99
05/29/2022 20:07:17 - INFO - __main__ - Saving model with best Classification-F1: 0.0325978344554196 -> 0.03740617807554927 on epoch=99, global_step=1400
05/29/2022 20:07:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.01 on epoch=100
05/29/2022 20:07:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.24 on epoch=101
05/29/2022 20:07:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.20 on epoch=102
05/29/2022 20:07:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.03 on epoch=102
05/29/2022 20:07:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.11 on epoch=103
05/29/2022 20:07:25 - INFO - __main__ - Global step 1450 Train loss 3.12 Classification-F1 0.024716813032964233 on epoch=103
05/29/2022 20:07:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.16 on epoch=104
05/29/2022 20:07:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.97 on epoch=104
05/29/2022 20:07:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.94 on epoch=105
05/29/2022 20:07:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.11 on epoch=106
05/29/2022 20:07:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.07 on epoch=107
05/29/2022 20:07:33 - INFO - __main__ - Global step 1500 Train loss 3.05 Classification-F1 0.029645028651063915 on epoch=107
05/29/2022 20:07:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.87 on epoch=107
05/29/2022 20:07:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.95 on epoch=108
05/29/2022 20:07:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.14 on epoch=109
05/29/2022 20:07:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.04 on epoch=109
05/29/2022 20:07:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.03 on epoch=110
05/29/2022 20:07:42 - INFO - __main__ - Global step 1550 Train loss 3.01 Classification-F1 0.029594645311540765 on epoch=110
05/29/2022 20:07:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.14 on epoch=111
05/29/2022 20:07:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.93 on epoch=112
05/29/2022 20:07:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.87 on epoch=112
05/29/2022 20:07:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.06 on epoch=113
05/29/2022 20:07:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.00 on epoch=114
05/29/2022 20:07:50 - INFO - __main__ - Global step 1600 Train loss 3.00 Classification-F1 0.040725761307657864 on epoch=114
05/29/2022 20:07:50 - INFO - __main__ - Saving model with best Classification-F1: 0.03740617807554927 -> 0.040725761307657864 on epoch=114, global_step=1600
05/29/2022 20:07:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.01 on epoch=114
05/29/2022 20:07:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.89 on epoch=115
05/29/2022 20:07:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.89 on epoch=116
05/29/2022 20:07:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.00 on epoch=117
05/29/2022 20:07:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.84 on epoch=117
05/29/2022 20:07:58 - INFO - __main__ - Global step 1650 Train loss 2.93 Classification-F1 0.03234662659865313 on epoch=117
05/29/2022 20:07:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.97 on epoch=118
05/29/2022 20:08:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.04 on epoch=119
05/29/2022 20:08:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.91 on epoch=119
05/29/2022 20:08:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.70 on epoch=120
05/29/2022 20:08:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.04 on epoch=121
05/29/2022 20:08:06 - INFO - __main__ - Global step 1700 Train loss 2.93 Classification-F1 0.009685230024213076 on epoch=121
05/29/2022 20:08:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.02 on epoch=122
05/29/2022 20:08:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.91 on epoch=122
05/29/2022 20:08:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.85 on epoch=123
05/29/2022 20:08:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.90 on epoch=124
05/29/2022 20:08:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.94 on epoch=124
05/29/2022 20:08:14 - INFO - __main__ - Global step 1750 Train loss 2.93 Classification-F1 0.02530752167775761 on epoch=124
05/29/2022 20:08:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.92 on epoch=125
05/29/2022 20:08:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.99 on epoch=126
05/29/2022 20:08:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.81 on epoch=127
05/29/2022 20:08:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.74 on epoch=127
05/29/2022 20:08:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.01 on epoch=128
05/29/2022 20:08:22 - INFO - __main__ - Global step 1800 Train loss 2.89 Classification-F1 0.022360248447204967 on epoch=128
05/29/2022 20:08:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.82 on epoch=129
05/29/2022 20:08:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.74 on epoch=129
05/29/2022 20:08:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.87 on epoch=130
05/29/2022 20:08:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.91 on epoch=131
05/29/2022 20:08:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.97 on epoch=132
05/29/2022 20:08:30 - INFO - __main__ - Global step 1850 Train loss 2.86 Classification-F1 0.045566502463054194 on epoch=132
05/29/2022 20:08:30 - INFO - __main__ - Saving model with best Classification-F1: 0.040725761307657864 -> 0.045566502463054194 on epoch=132, global_step=1850
05/29/2022 20:08:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.78 on epoch=132
05/29/2022 20:08:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.94 on epoch=133
05/29/2022 20:08:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.81 on epoch=134
05/29/2022 20:08:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.85 on epoch=134
05/29/2022 20:08:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.70 on epoch=135
05/29/2022 20:08:39 - INFO - __main__ - Global step 1900 Train loss 2.82 Classification-F1 0.027167717850947664 on epoch=135
05/29/2022 20:08:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.76 on epoch=136
05/29/2022 20:08:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.69 on epoch=137
05/29/2022 20:08:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.69 on epoch=137
05/29/2022 20:08:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.81 on epoch=138
05/29/2022 20:08:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.72 on epoch=139
05/29/2022 20:08:47 - INFO - __main__ - Global step 1950 Train loss 2.74 Classification-F1 0.04412817015556742 on epoch=139
05/29/2022 20:08:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.89 on epoch=139
05/29/2022 20:08:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.53 on epoch=140
05/29/2022 20:08:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.71 on epoch=141
05/29/2022 20:08:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.72 on epoch=142
05/29/2022 20:08:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.64 on epoch=142
05/29/2022 20:08:55 - INFO - __main__ - Global step 2000 Train loss 2.70 Classification-F1 0.04027093596059113 on epoch=142
05/29/2022 20:08:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.85 on epoch=143
05/29/2022 20:08:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.74 on epoch=144
05/29/2022 20:08:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.62 on epoch=144
05/29/2022 20:09:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.55 on epoch=145
05/29/2022 20:09:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.76 on epoch=146
05/29/2022 20:09:03 - INFO - __main__ - Global step 2050 Train loss 2.71 Classification-F1 0.0298874017889298 on epoch=146
05/29/2022 20:09:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.71 on epoch=147
05/29/2022 20:09:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.44 on epoch=147
05/29/2022 20:09:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.73 on epoch=148
05/29/2022 20:09:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.69 on epoch=149
05/29/2022 20:09:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.78 on epoch=149
05/29/2022 20:09:11 - INFO - __main__ - Global step 2100 Train loss 2.67 Classification-F1 0.023067757080732054 on epoch=149
05/29/2022 20:09:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.57 on epoch=150
05/29/2022 20:09:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.77 on epoch=151
05/29/2022 20:09:15 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.74 on epoch=152
05/29/2022 20:09:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.71 on epoch=152
05/29/2022 20:09:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.76 on epoch=153
05/29/2022 20:09:19 - INFO - __main__ - Global step 2150 Train loss 2.71 Classification-F1 0.036413755948639666 on epoch=153
05/29/2022 20:09:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.71 on epoch=154
05/29/2022 20:09:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.88 on epoch=154
05/29/2022 20:09:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.40 on epoch=155
05/29/2022 20:09:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.75 on epoch=156
05/29/2022 20:09:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.72 on epoch=157
05/29/2022 20:09:27 - INFO - __main__ - Global step 2200 Train loss 2.69 Classification-F1 0.027220587231548136 on epoch=157
05/29/2022 20:09:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.55 on epoch=157
05/29/2022 20:09:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.65 on epoch=158
05/29/2022 20:09:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.55 on epoch=159
05/29/2022 20:09:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.67 on epoch=159
05/29/2022 20:09:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.59 on epoch=160
05/29/2022 20:09:35 - INFO - __main__ - Global step 2250 Train loss 2.60 Classification-F1 0.021284614921498135 on epoch=160
05/29/2022 20:09:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.65 on epoch=161
05/29/2022 20:09:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.74 on epoch=162
05/29/2022 20:09:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.52 on epoch=162
05/29/2022 20:09:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.81 on epoch=163
05/29/2022 20:09:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.53 on epoch=164
05/29/2022 20:09:43 - INFO - __main__ - Global step 2300 Train loss 2.65 Classification-F1 0.04231365021883736 on epoch=164
05/29/2022 20:09:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.76 on epoch=164
05/29/2022 20:09:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.42 on epoch=165
05/29/2022 20:09:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.66 on epoch=166
05/29/2022 20:09:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.68 on epoch=167
05/29/2022 20:09:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.70 on epoch=167
05/29/2022 20:09:52 - INFO - __main__ - Global step 2350 Train loss 2.64 Classification-F1 0.04769492568521971 on epoch=167
05/29/2022 20:09:52 - INFO - __main__ - Saving model with best Classification-F1: 0.045566502463054194 -> 0.04769492568521971 on epoch=167, global_step=2350
05/29/2022 20:09:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.51 on epoch=168
05/29/2022 20:09:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.47 on epoch=169
05/29/2022 20:09:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.69 on epoch=169
05/29/2022 20:09:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.22 on epoch=170
05/29/2022 20:09:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.79 on epoch=171
05/29/2022 20:10:00 - INFO - __main__ - Global step 2400 Train loss 2.53 Classification-F1 0.03735537213628994 on epoch=171
05/29/2022 20:10:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.65 on epoch=172
05/29/2022 20:10:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.56 on epoch=172
05/29/2022 20:10:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.61 on epoch=173
05/29/2022 20:10:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.46 on epoch=174
05/29/2022 20:10:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.60 on epoch=174
05/29/2022 20:10:08 - INFO - __main__ - Global step 2450 Train loss 2.58 Classification-F1 0.033191152567221584 on epoch=174
05/29/2022 20:10:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.38 on epoch=175
05/29/2022 20:10:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.66 on epoch=176
05/29/2022 20:10:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.55 on epoch=177
05/29/2022 20:10:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.58 on epoch=177
05/29/2022 20:10:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.58 on epoch=178
05/29/2022 20:10:16 - INFO - __main__ - Global step 2500 Train loss 2.55 Classification-F1 0.05581797664292635 on epoch=178
05/29/2022 20:10:16 - INFO - __main__ - Saving model with best Classification-F1: 0.04769492568521971 -> 0.05581797664292635 on epoch=178, global_step=2500
05/29/2022 20:10:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.61 on epoch=179
05/29/2022 20:10:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.52 on epoch=179
05/29/2022 20:10:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.39 on epoch=180
05/29/2022 20:10:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.44 on epoch=181
05/29/2022 20:10:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.45 on epoch=182
05/29/2022 20:10:24 - INFO - __main__ - Global step 2550 Train loss 2.48 Classification-F1 0.050119869256614866 on epoch=182
05/29/2022 20:10:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.36 on epoch=182
05/29/2022 20:10:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.45 on epoch=183
05/29/2022 20:10:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.45 on epoch=184
05/29/2022 20:10:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.41 on epoch=184
05/29/2022 20:10:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.54 on epoch=185
05/29/2022 20:10:32 - INFO - __main__ - Global step 2600 Train loss 2.44 Classification-F1 0.031312205520930926 on epoch=185
05/29/2022 20:10:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.60 on epoch=186
05/29/2022 20:10:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.41 on epoch=187
05/29/2022 20:10:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.38 on epoch=187
05/29/2022 20:10:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.39 on epoch=188
05/29/2022 20:10:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.53 on epoch=189
05/29/2022 20:10:40 - INFO - __main__ - Global step 2650 Train loss 2.46 Classification-F1 0.04898239607300094 on epoch=189
05/29/2022 20:10:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.43 on epoch=189
05/29/2022 20:10:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.31 on epoch=190
05/29/2022 20:10:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.49 on epoch=191
05/29/2022 20:10:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.52 on epoch=192
05/29/2022 20:10:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.34 on epoch=192
05/29/2022 20:10:48 - INFO - __main__ - Global step 2700 Train loss 2.42 Classification-F1 0.042943722943722944 on epoch=192
05/29/2022 20:10:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.43 on epoch=193
05/29/2022 20:10:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.34 on epoch=194
05/29/2022 20:10:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.45 on epoch=194
05/29/2022 20:10:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.38 on epoch=195
05/29/2022 20:10:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.40 on epoch=196
05/29/2022 20:10:57 - INFO - __main__ - Global step 2750 Train loss 2.40 Classification-F1 0.047283615261143344 on epoch=196
05/29/2022 20:10:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.36 on epoch=197
05/29/2022 20:10:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.37 on epoch=197
05/29/2022 20:11:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.52 on epoch=198
05/29/2022 20:11:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.46 on epoch=199
05/29/2022 20:11:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.41 on epoch=199
05/29/2022 20:11:05 - INFO - __main__ - Global step 2800 Train loss 2.42 Classification-F1 0.05426710092555489 on epoch=199
05/29/2022 20:11:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.29 on epoch=200
05/29/2022 20:11:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.67 on epoch=201
05/29/2022 20:11:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.39 on epoch=202
05/29/2022 20:11:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.38 on epoch=202
05/29/2022 20:11:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.46 on epoch=203
05/29/2022 20:11:13 - INFO - __main__ - Global step 2850 Train loss 2.44 Classification-F1 0.04893769101843637 on epoch=203
05/29/2022 20:11:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.43 on epoch=204
05/29/2022 20:11:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.30 on epoch=204
05/29/2022 20:11:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.19 on epoch=205
05/29/2022 20:11:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.46 on epoch=206
05/29/2022 20:11:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.44 on epoch=207
05/29/2022 20:11:21 - INFO - __main__ - Global step 2900 Train loss 2.36 Classification-F1 0.0196219715956558 on epoch=207
05/29/2022 20:11:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.19 on epoch=207
05/29/2022 20:11:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.37 on epoch=208
05/29/2022 20:11:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.41 on epoch=209
05/29/2022 20:11:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.48 on epoch=209
05/29/2022 20:11:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.34 on epoch=210
05/29/2022 20:11:29 - INFO - __main__ - Global step 2950 Train loss 2.36 Classification-F1 0.04166897619522721 on epoch=210
05/29/2022 20:11:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.24 on epoch=211
05/29/2022 20:11:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.40 on epoch=212
05/29/2022 20:11:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.47 on epoch=212
05/29/2022 20:11:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.45 on epoch=213
05/29/2022 20:11:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.27 on epoch=214
05/29/2022 20:11:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:11:37 - INFO - __main__ - Printing 3 examples
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 20:11:37 - INFO - __main__ - ['Plant']
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 20:11:37 - INFO - __main__ - ['Plant']
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 20:11:37 - INFO - __main__ - ['Plant']
05/29/2022 20:11:37 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:11:37 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:11:37 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:11:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:11:37 - INFO - __main__ - Printing 3 examples
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 20:11:37 - INFO - __main__ - ['Plant']
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 20:11:37 - INFO - __main__ - ['Plant']
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 20:11:37 - INFO - __main__ - ['Plant']
05/29/2022 20:11:37 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:11:37 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:11:37 - INFO - __main__ - Global step 3000 Train loss 2.36 Classification-F1 0.046092189346564796 on epoch=214
05/29/2022 20:11:37 - INFO - __main__ - save last model!
05/29/2022 20:11:37 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:11:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 20:11:37 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 20:11:37 - INFO - __main__ - Printing 3 examples
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 20:11:37 - INFO - __main__ - ['Animal']
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 20:11:37 - INFO - __main__ - ['Animal']
05/29/2022 20:11:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 20:11:37 - INFO - __main__ - ['Village']
05/29/2022 20:11:37 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:11:39 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:11:43 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 20:11:43 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:11:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:11:44 - INFO - __main__ - Starting training!
05/29/2022 20:12:13 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/29/2022 20:12:13 - INFO - __main__ - Classification-F1 on test data: 0.0403
05/29/2022 20:12:13 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.05581797664292635, test_performance=0.0402732922290327
05/29/2022 20:12:13 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/29/2022 20:12:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:12:14 - INFO - __main__ - Printing 3 examples
05/29/2022 20:12:14 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/29/2022 20:12:14 - INFO - __main__ - ['Plant']
05/29/2022 20:12:14 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/29/2022 20:12:14 - INFO - __main__ - ['Plant']
05/29/2022 20:12:14 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/29/2022 20:12:14 - INFO - __main__ - ['Plant']
05/29/2022 20:12:14 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:12:14 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:12:15 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:12:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:12:15 - INFO - __main__ - Printing 3 examples
05/29/2022 20:12:15 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/29/2022 20:12:15 - INFO - __main__ - ['Plant']
05/29/2022 20:12:15 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/29/2022 20:12:15 - INFO - __main__ - ['Plant']
05/29/2022 20:12:15 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/29/2022 20:12:15 - INFO - __main__ - ['Plant']
05/29/2022 20:12:15 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:12:15 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:12:15 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:12:20 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:12:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:12:21 - INFO - __main__ - Starting training!
05/29/2022 20:12:22 - INFO - __main__ - Step 10 Global step 10 Train loss 7.60 on epoch=0
05/29/2022 20:12:23 - INFO - __main__ - Step 20 Global step 20 Train loss 7.44 on epoch=1
05/29/2022 20:12:25 - INFO - __main__ - Step 30 Global step 30 Train loss 7.55 on epoch=2
05/29/2022 20:12:26 - INFO - __main__ - Step 40 Global step 40 Train loss 7.72 on epoch=2
05/29/2022 20:12:27 - INFO - __main__ - Step 50 Global step 50 Train loss 7.34 on epoch=3
05/29/2022 20:12:34 - INFO - __main__ - Global step 50 Train loss 7.53 Classification-F1 0.0 on epoch=3
05/29/2022 20:12:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 20:12:35 - INFO - __main__ - Step 60 Global step 60 Train loss 7.22 on epoch=4
05/29/2022 20:12:36 - INFO - __main__ - Step 70 Global step 70 Train loss 7.26 on epoch=4
05/29/2022 20:12:37 - INFO - __main__ - Step 80 Global step 80 Train loss 7.11 on epoch=5
05/29/2022 20:12:39 - INFO - __main__ - Step 90 Global step 90 Train loss 7.04 on epoch=6
05/29/2022 20:12:40 - INFO - __main__ - Step 100 Global step 100 Train loss 7.07 on epoch=7
05/29/2022 20:13:03 - INFO - __main__ - Global step 100 Train loss 7.14 Classification-F1 0.0 on epoch=7
05/29/2022 20:13:04 - INFO - __main__ - Step 110 Global step 110 Train loss 7.26 on epoch=7
05/29/2022 20:13:05 - INFO - __main__ - Step 120 Global step 120 Train loss 6.87 on epoch=8
05/29/2022 20:13:06 - INFO - __main__ - Step 130 Global step 130 Train loss 6.91 on epoch=9
05/29/2022 20:13:08 - INFO - __main__ - Step 140 Global step 140 Train loss 6.89 on epoch=9
05/29/2022 20:13:09 - INFO - __main__ - Step 150 Global step 150 Train loss 6.87 on epoch=10
05/29/2022 20:13:47 - INFO - __main__ - Global step 150 Train loss 6.96 Classification-F1 0.0 on epoch=10
05/29/2022 20:13:48 - INFO - __main__ - Step 160 Global step 160 Train loss 6.65 on epoch=11
05/29/2022 20:13:50 - INFO - __main__ - Step 170 Global step 170 Train loss 6.79 on epoch=12
05/29/2022 20:13:51 - INFO - __main__ - Step 180 Global step 180 Train loss 6.89 on epoch=12
05/29/2022 20:13:52 - INFO - __main__ - Step 190 Global step 190 Train loss 6.57 on epoch=13
05/29/2022 20:13:54 - INFO - __main__ - Step 200 Global step 200 Train loss 6.63 on epoch=14
05/29/2022 20:14:56 - INFO - __main__ - Global step 200 Train loss 6.71 Classification-F1 0.0 on epoch=14
05/29/2022 20:14:57 - INFO - __main__ - Step 210 Global step 210 Train loss 6.51 on epoch=14
05/29/2022 20:14:58 - INFO - __main__ - Step 220 Global step 220 Train loss 6.50 on epoch=15
05/29/2022 20:14:59 - INFO - __main__ - Step 230 Global step 230 Train loss 6.35 on epoch=16
05/29/2022 20:15:01 - INFO - __main__ - Step 240 Global step 240 Train loss 6.50 on epoch=17
05/29/2022 20:15:02 - INFO - __main__ - Step 250 Global step 250 Train loss 6.49 on epoch=17
05/29/2022 20:16:09 - INFO - __main__ - Global step 250 Train loss 6.47 Classification-F1 0.0 on epoch=17
05/29/2022 20:16:10 - INFO - __main__ - Step 260 Global step 260 Train loss 6.32 on epoch=18
05/29/2022 20:16:11 - INFO - __main__ - Step 270 Global step 270 Train loss 6.24 on epoch=19
05/29/2022 20:16:13 - INFO - __main__ - Step 280 Global step 280 Train loss 6.27 on epoch=19
05/29/2022 20:16:14 - INFO - __main__ - Step 290 Global step 290 Train loss 6.22 on epoch=20
05/29/2022 20:16:15 - INFO - __main__ - Step 300 Global step 300 Train loss 6.08 on epoch=21
05/29/2022 20:17:26 - INFO - __main__ - Global step 300 Train loss 6.23 Classification-F1 0.0 on epoch=21
05/29/2022 20:17:28 - INFO - __main__ - Step 310 Global step 310 Train loss 6.39 on epoch=22
05/29/2022 20:17:29 - INFO - __main__ - Step 320 Global step 320 Train loss 6.33 on epoch=22
05/29/2022 20:17:30 - INFO - __main__ - Step 330 Global step 330 Train loss 6.14 on epoch=23
05/29/2022 20:17:31 - INFO - __main__ - Step 340 Global step 340 Train loss 6.27 on epoch=24
05/29/2022 20:17:33 - INFO - __main__ - Step 350 Global step 350 Train loss 6.09 on epoch=24
05/29/2022 20:18:27 - INFO - __main__ - Global step 350 Train loss 6.24 Classification-F1 0.0 on epoch=24
05/29/2022 20:18:28 - INFO - __main__ - Step 360 Global step 360 Train loss 6.14 on epoch=25
05/29/2022 20:18:29 - INFO - __main__ - Step 370 Global step 370 Train loss 5.98 on epoch=26
05/29/2022 20:18:30 - INFO - __main__ - Step 380 Global step 380 Train loss 6.10 on epoch=27
05/29/2022 20:18:32 - INFO - __main__ - Step 390 Global step 390 Train loss 6.12 on epoch=27
05/29/2022 20:18:33 - INFO - __main__ - Step 400 Global step 400 Train loss 5.99 on epoch=28
05/29/2022 20:19:31 - INFO - __main__ - Global step 400 Train loss 6.07 Classification-F1 0.0 on epoch=28
05/29/2022 20:19:32 - INFO - __main__ - Step 410 Global step 410 Train loss 5.99 on epoch=29
05/29/2022 20:19:33 - INFO - __main__ - Step 420 Global step 420 Train loss 5.81 on epoch=29
05/29/2022 20:19:35 - INFO - __main__ - Step 430 Global step 430 Train loss 5.99 on epoch=30
05/29/2022 20:19:36 - INFO - __main__ - Step 440 Global step 440 Train loss 5.87 on epoch=31
05/29/2022 20:19:37 - INFO - __main__ - Step 450 Global step 450 Train loss 6.04 on epoch=32
05/29/2022 20:20:29 - INFO - __main__ - Global step 450 Train loss 5.94 Classification-F1 0.0 on epoch=32
05/29/2022 20:20:30 - INFO - __main__ - Step 460 Global step 460 Train loss 5.98 on epoch=32
05/29/2022 20:20:31 - INFO - __main__ - Step 470 Global step 470 Train loss 5.85 on epoch=33
05/29/2022 20:20:33 - INFO - __main__ - Step 480 Global step 480 Train loss 5.80 on epoch=34
05/29/2022 20:20:34 - INFO - __main__ - Step 490 Global step 490 Train loss 5.71 on epoch=34
05/29/2022 20:20:35 - INFO - __main__ - Step 500 Global step 500 Train loss 5.75 on epoch=35
05/29/2022 20:21:30 - INFO - __main__ - Global step 500 Train loss 5.82 Classification-F1 0.0 on epoch=35
05/29/2022 20:21:31 - INFO - __main__ - Step 510 Global step 510 Train loss 5.60 on epoch=36
05/29/2022 20:21:32 - INFO - __main__ - Step 520 Global step 520 Train loss 5.85 on epoch=37
05/29/2022 20:21:34 - INFO - __main__ - Step 530 Global step 530 Train loss 5.73 on epoch=37
05/29/2022 20:21:35 - INFO - __main__ - Step 540 Global step 540 Train loss 5.70 on epoch=38
05/29/2022 20:21:36 - INFO - __main__ - Step 550 Global step 550 Train loss 5.48 on epoch=39
05/29/2022 20:21:53 - INFO - __main__ - Global step 550 Train loss 5.67 Classification-F1 0.0 on epoch=39
05/29/2022 20:21:54 - INFO - __main__ - Step 560 Global step 560 Train loss 5.44 on epoch=39
05/29/2022 20:21:55 - INFO - __main__ - Step 570 Global step 570 Train loss 5.56 on epoch=40
05/29/2022 20:21:56 - INFO - __main__ - Step 580 Global step 580 Train loss 5.38 on epoch=41
05/29/2022 20:21:58 - INFO - __main__ - Step 590 Global step 590 Train loss 5.71 on epoch=42
05/29/2022 20:21:59 - INFO - __main__ - Step 600 Global step 600 Train loss 5.56 on epoch=42
05/29/2022 20:22:21 - INFO - __main__ - Global step 600 Train loss 5.53 Classification-F1 0.0056737588652482265 on epoch=42
05/29/2022 20:22:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0056737588652482265 on epoch=42, global_step=600
05/29/2022 20:22:22 - INFO - __main__ - Step 610 Global step 610 Train loss 5.51 on epoch=43
05/29/2022 20:22:23 - INFO - __main__ - Step 620 Global step 620 Train loss 5.48 on epoch=44
05/29/2022 20:22:25 - INFO - __main__ - Step 630 Global step 630 Train loss 5.43 on epoch=44
05/29/2022 20:22:26 - INFO - __main__ - Step 640 Global step 640 Train loss 5.45 on epoch=45
05/29/2022 20:22:27 - INFO - __main__ - Step 650 Global step 650 Train loss 5.16 on epoch=46
05/29/2022 20:22:34 - INFO - __main__ - Global step 650 Train loss 5.41 Classification-F1 0.004713804713804714 on epoch=46
05/29/2022 20:22:35 - INFO - __main__ - Step 660 Global step 660 Train loss 5.38 on epoch=47
05/29/2022 20:22:37 - INFO - __main__ - Step 670 Global step 670 Train loss 5.47 on epoch=47
05/29/2022 20:22:38 - INFO - __main__ - Step 680 Global step 680 Train loss 5.21 on epoch=48
05/29/2022 20:22:39 - INFO - __main__ - Step 690 Global step 690 Train loss 5.32 on epoch=49
05/29/2022 20:22:40 - INFO - __main__ - Step 700 Global step 700 Train loss 5.07 on epoch=49
05/29/2022 20:22:48 - INFO - __main__ - Global step 700 Train loss 5.29 Classification-F1 0.005952380952380953 on epoch=49
05/29/2022 20:22:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0056737588652482265 -> 0.005952380952380953 on epoch=49, global_step=700
05/29/2022 20:22:49 - INFO - __main__ - Step 710 Global step 710 Train loss 5.28 on epoch=50
05/29/2022 20:22:51 - INFO - __main__ - Step 720 Global step 720 Train loss 5.05 on epoch=51
05/29/2022 20:22:52 - INFO - __main__ - Step 730 Global step 730 Train loss 5.24 on epoch=52
05/29/2022 20:22:53 - INFO - __main__ - Step 740 Global step 740 Train loss 5.28 on epoch=52
05/29/2022 20:22:54 - INFO - __main__ - Step 750 Global step 750 Train loss 5.09 on epoch=53
05/29/2022 20:23:05 - INFO - __main__ - Global step 750 Train loss 5.19 Classification-F1 0.00573394495412844 on epoch=53
05/29/2022 20:23:07 - INFO - __main__ - Step 760 Global step 760 Train loss 5.19 on epoch=54
05/29/2022 20:23:08 - INFO - __main__ - Step 770 Global step 770 Train loss 4.98 on epoch=54
05/29/2022 20:23:09 - INFO - __main__ - Step 780 Global step 780 Train loss 5.14 on epoch=55
05/29/2022 20:23:10 - INFO - __main__ - Step 790 Global step 790 Train loss 4.98 on epoch=56
05/29/2022 20:23:12 - INFO - __main__ - Step 800 Global step 800 Train loss 5.04 on epoch=57
05/29/2022 20:23:15 - INFO - __main__ - Global step 800 Train loss 5.06 Classification-F1 0.007446016381236037 on epoch=57
05/29/2022 20:23:15 - INFO - __main__ - Saving model with best Classification-F1: 0.005952380952380953 -> 0.007446016381236037 on epoch=57, global_step=800
05/29/2022 20:23:16 - INFO - __main__ - Step 810 Global step 810 Train loss 5.00 on epoch=57
05/29/2022 20:23:17 - INFO - __main__ - Step 820 Global step 820 Train loss 5.05 on epoch=58
05/29/2022 20:23:19 - INFO - __main__ - Step 830 Global step 830 Train loss 4.98 on epoch=59
05/29/2022 20:23:20 - INFO - __main__ - Step 840 Global step 840 Train loss 4.83 on epoch=59
05/29/2022 20:23:21 - INFO - __main__ - Step 850 Global step 850 Train loss 4.92 on epoch=60
05/29/2022 20:23:30 - INFO - __main__ - Global step 850 Train loss 4.96 Classification-F1 0.006211180124223602 on epoch=60
05/29/2022 20:23:31 - INFO - __main__ - Step 860 Global step 860 Train loss 4.83 on epoch=61
05/29/2022 20:23:32 - INFO - __main__ - Step 870 Global step 870 Train loss 4.95 on epoch=62
05/29/2022 20:23:33 - INFO - __main__ - Step 880 Global step 880 Train loss 4.94 on epoch=62
05/29/2022 20:23:35 - INFO - __main__ - Step 890 Global step 890 Train loss 4.79 on epoch=63
05/29/2022 20:23:36 - INFO - __main__ - Step 900 Global step 900 Train loss 4.92 on epoch=64
05/29/2022 20:23:39 - INFO - __main__ - Global step 900 Train loss 4.89 Classification-F1 0.007509386733416771 on epoch=64
05/29/2022 20:23:39 - INFO - __main__ - Saving model with best Classification-F1: 0.007446016381236037 -> 0.007509386733416771 on epoch=64, global_step=900
05/29/2022 20:23:41 - INFO - __main__ - Step 910 Global step 910 Train loss 4.81 on epoch=64
05/29/2022 20:23:42 - INFO - __main__ - Step 920 Global step 920 Train loss 4.87 on epoch=65
05/29/2022 20:23:43 - INFO - __main__ - Step 930 Global step 930 Train loss 4.68 on epoch=66
05/29/2022 20:23:44 - INFO - __main__ - Step 940 Global step 940 Train loss 4.84 on epoch=67
05/29/2022 20:23:46 - INFO - __main__ - Step 950 Global step 950 Train loss 4.77 on epoch=67
05/29/2022 20:23:48 - INFO - __main__ - Global step 950 Train loss 4.80 Classification-F1 0.009523809523809523 on epoch=67
05/29/2022 20:23:48 - INFO - __main__ - Saving model with best Classification-F1: 0.007509386733416771 -> 0.009523809523809523 on epoch=67, global_step=950
05/29/2022 20:23:49 - INFO - __main__ - Step 960 Global step 960 Train loss 4.83 on epoch=68
05/29/2022 20:23:51 - INFO - __main__ - Step 970 Global step 970 Train loss 4.81 on epoch=69
05/29/2022 20:23:52 - INFO - __main__ - Step 980 Global step 980 Train loss 4.78 on epoch=69
05/29/2022 20:23:53 - INFO - __main__ - Step 990 Global step 990 Train loss 4.75 on epoch=70
05/29/2022 20:23:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.70 on epoch=71
05/29/2022 20:23:58 - INFO - __main__ - Global step 1000 Train loss 4.77 Classification-F1 0.00892608089260809 on epoch=71
05/29/2022 20:23:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.75 on epoch=72
05/29/2022 20:24:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.71 on epoch=72
05/29/2022 20:24:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.71 on epoch=73
05/29/2022 20:24:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.72 on epoch=74
05/29/2022 20:24:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.60 on epoch=74
05/29/2022 20:24:06 - INFO - __main__ - Global step 1050 Train loss 4.70 Classification-F1 0.009523809523809523 on epoch=74
05/29/2022 20:24:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.63 on epoch=75
05/29/2022 20:24:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.52 on epoch=76
05/29/2022 20:24:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.75 on epoch=77
05/29/2022 20:24:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.58 on epoch=77
05/29/2022 20:24:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.52 on epoch=78
05/29/2022 20:24:14 - INFO - __main__ - Global step 1100 Train loss 4.60 Classification-F1 0.009523809523809523 on epoch=78
05/29/2022 20:24:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.48 on epoch=79
05/29/2022 20:24:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.62 on epoch=79
05/29/2022 20:24:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.57 on epoch=80
05/29/2022 20:24:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.55 on epoch=81
05/29/2022 20:24:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.55 on epoch=82
05/29/2022 20:24:23 - INFO - __main__ - Global step 1150 Train loss 4.55 Classification-F1 0.00892608089260809 on epoch=82
05/29/2022 20:24:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.52 on epoch=82
05/29/2022 20:24:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.53 on epoch=83
05/29/2022 20:24:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.55 on epoch=84
05/29/2022 20:24:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.29 on epoch=84
05/29/2022 20:24:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.34 on epoch=85
05/29/2022 20:24:31 - INFO - __main__ - Global step 1200 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=85
05/29/2022 20:24:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.42 on epoch=86
05/29/2022 20:24:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.38 on epoch=87
05/29/2022 20:24:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.34 on epoch=87
05/29/2022 20:24:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.48 on epoch=88
05/29/2022 20:24:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.47 on epoch=89
05/29/2022 20:24:40 - INFO - __main__ - Global step 1250 Train loss 4.42 Classification-F1 0.009523809523809523 on epoch=89
05/29/2022 20:24:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.25 on epoch=89
05/29/2022 20:24:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.31 on epoch=90
05/29/2022 20:24:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.29 on epoch=91
05/29/2022 20:24:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.33 on epoch=92
05/29/2022 20:24:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 4.22 on epoch=92
05/29/2022 20:24:48 - INFO - __main__ - Global step 1300 Train loss 4.28 Classification-F1 0.009523809523809523 on epoch=92
05/29/2022 20:24:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.24 on epoch=93
05/29/2022 20:24:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.42 on epoch=94
05/29/2022 20:24:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 4.10 on epoch=94
05/29/2022 20:24:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.05 on epoch=95
05/29/2022 20:24:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 4.05 on epoch=96
05/29/2022 20:24:56 - INFO - __main__ - Global step 1350 Train loss 4.17 Classification-F1 0.02009897221164827 on epoch=96
05/29/2022 20:24:56 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02009897221164827 on epoch=96, global_step=1350
05/29/2022 20:24:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 4.27 on epoch=97
05/29/2022 20:24:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 4.23 on epoch=97
05/29/2022 20:25:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 4.22 on epoch=98
05/29/2022 20:25:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 4.02 on epoch=99
05/29/2022 20:25:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 4.14 on epoch=99
05/29/2022 20:25:04 - INFO - __main__ - Global step 1400 Train loss 4.17 Classification-F1 0.015634944206372778 on epoch=99
05/29/2022 20:25:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 4.11 on epoch=100
05/29/2022 20:25:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 4.13 on epoch=101
05/29/2022 20:25:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 4.04 on epoch=102
05/29/2022 20:25:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 4.04 on epoch=102
05/29/2022 20:25:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 4.13 on epoch=103
05/29/2022 20:25:13 - INFO - __main__ - Global step 1450 Train loss 4.09 Classification-F1 0.010296010296010296 on epoch=103
05/29/2022 20:25:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 4.09 on epoch=104
05/29/2022 20:25:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 4.04 on epoch=104
05/29/2022 20:25:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 4.13 on epoch=105
05/29/2022 20:25:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 4.10 on epoch=106
05/29/2022 20:25:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 4.08 on epoch=107
05/29/2022 20:25:21 - INFO - __main__ - Global step 1500 Train loss 4.09 Classification-F1 0.015609152752009895 on epoch=107
05/29/2022 20:25:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.88 on epoch=107
05/29/2022 20:25:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 4.11 on epoch=108
05/29/2022 20:25:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 4.10 on epoch=109
05/29/2022 20:25:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 4.01 on epoch=109
05/29/2022 20:25:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.89 on epoch=110
05/29/2022 20:25:29 - INFO - __main__ - Global step 1550 Train loss 4.00 Classification-F1 0.015921262121870023 on epoch=110
05/29/2022 20:25:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 4.08 on epoch=111
05/29/2022 20:25:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 4.00 on epoch=112
05/29/2022 20:25:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.97 on epoch=112
05/29/2022 20:25:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 4.08 on epoch=113
05/29/2022 20:25:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.81 on epoch=114
05/29/2022 20:25:37 - INFO - __main__ - Global step 1600 Train loss 3.99 Classification-F1 0.010158730158730159 on epoch=114
05/29/2022 20:25:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.90 on epoch=114
05/29/2022 20:25:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.89 on epoch=115
05/29/2022 20:25:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.81 on epoch=116
05/29/2022 20:25:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.92 on epoch=117
05/29/2022 20:25:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.81 on epoch=117
05/29/2022 20:25:45 - INFO - __main__ - Global step 1650 Train loss 3.87 Classification-F1 0.009563658099222952 on epoch=117
05/29/2022 20:25:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.92 on epoch=118
05/29/2022 20:25:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.84 on epoch=119
05/29/2022 20:25:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.64 on epoch=119
05/29/2022 20:25:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.79 on epoch=120
05/29/2022 20:25:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.72 on epoch=121
05/29/2022 20:25:54 - INFO - __main__ - Global step 1700 Train loss 3.78 Classification-F1 0.009523809523809523 on epoch=121
05/29/2022 20:25:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.83 on epoch=122
05/29/2022 20:25:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.69 on epoch=122
05/29/2022 20:25:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.76 on epoch=123
05/29/2022 20:25:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.73 on epoch=124
05/29/2022 20:26:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.83 on epoch=124
05/29/2022 20:26:02 - INFO - __main__ - Global step 1750 Train loss 3.77 Classification-F1 0.019005478297513697 on epoch=124
05/29/2022 20:26:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.66 on epoch=125
05/29/2022 20:26:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.82 on epoch=126
05/29/2022 20:26:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.77 on epoch=127
05/29/2022 20:26:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.74 on epoch=127
05/29/2022 20:26:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.82 on epoch=128
05/29/2022 20:26:10 - INFO - __main__ - Global step 1800 Train loss 3.76 Classification-F1 0.013897866839043307 on epoch=128
05/29/2022 20:26:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.72 on epoch=129
05/29/2022 20:26:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.76 on epoch=129
05/29/2022 20:26:14 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.70 on epoch=130
05/29/2022 20:26:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.75 on epoch=131
05/29/2022 20:26:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.67 on epoch=132
05/29/2022 20:26:18 - INFO - __main__ - Global step 1850 Train loss 3.72 Classification-F1 0.009603841536614645 on epoch=132
05/29/2022 20:26:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.50 on epoch=132
05/29/2022 20:26:21 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.70 on epoch=133
05/29/2022 20:26:22 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.67 on epoch=134
05/29/2022 20:26:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.54 on epoch=134
05/29/2022 20:26:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.47 on epoch=135
05/29/2022 20:26:26 - INFO - __main__ - Global step 1900 Train loss 3.57 Classification-F1 0.01599953286035444 on epoch=135
05/29/2022 20:26:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.65 on epoch=136
05/29/2022 20:26:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.63 on epoch=137
05/29/2022 20:26:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.55 on epoch=137
05/29/2022 20:26:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.60 on epoch=138
05/29/2022 20:26:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.48 on epoch=139
05/29/2022 20:26:35 - INFO - __main__ - Global step 1950 Train loss 3.58 Classification-F1 0.015228818800247373 on epoch=139
05/29/2022 20:26:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.63 on epoch=139
05/29/2022 20:26:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.48 on epoch=140
05/29/2022 20:26:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.45 on epoch=141
05/29/2022 20:26:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.59 on epoch=142
05/29/2022 20:26:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.58 on epoch=142
05/29/2022 20:26:43 - INFO - __main__ - Global step 2000 Train loss 3.54 Classification-F1 0.015609152752009895 on epoch=142
05/29/2022 20:26:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.54 on epoch=143
05/29/2022 20:26:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.34 on epoch=144
05/29/2022 20:26:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.54 on epoch=144
05/29/2022 20:26:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.39 on epoch=145
05/29/2022 20:26:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.42 on epoch=146
05/29/2022 20:26:52 - INFO - __main__ - Global step 2050 Train loss 3.45 Classification-F1 0.010249839846252402 on epoch=146
05/29/2022 20:26:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.42 on epoch=147
05/29/2022 20:26:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.37 on epoch=147
05/29/2022 20:26:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.41 on epoch=148
05/29/2022 20:26:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.45 on epoch=149
05/29/2022 20:26:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.36 on epoch=149
05/29/2022 20:27:00 - INFO - __main__ - Global step 2100 Train loss 3.40 Classification-F1 0.02399566791890886 on epoch=149
05/29/2022 20:27:00 - INFO - __main__ - Saving model with best Classification-F1: 0.02009897221164827 -> 0.02399566791890886 on epoch=149, global_step=2100
05/29/2022 20:27:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.16 on epoch=150
05/29/2022 20:27:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.44 on epoch=151
05/29/2022 20:27:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.41 on epoch=152
05/29/2022 20:27:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.31 on epoch=152
05/29/2022 20:27:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.37 on epoch=153
05/29/2022 20:27:08 - INFO - __main__ - Global step 2150 Train loss 3.34 Classification-F1 0.020174346201743465 on epoch=153
05/29/2022 20:27:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.29 on epoch=154
05/29/2022 20:27:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.30 on epoch=154
05/29/2022 20:27:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.17 on epoch=155
05/29/2022 20:27:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.47 on epoch=156
05/29/2022 20:27:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.38 on epoch=157
05/29/2022 20:27:16 - INFO - __main__ - Global step 2200 Train loss 3.32 Classification-F1 0.019215714831873874 on epoch=157
05/29/2022 20:27:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.25 on epoch=157
05/29/2022 20:27:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.34 on epoch=158
05/29/2022 20:27:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 3.30 on epoch=159
05/29/2022 20:27:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.20 on epoch=159
05/29/2022 20:27:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 3.26 on epoch=160
05/29/2022 20:27:25 - INFO - __main__ - Global step 2250 Train loss 3.27 Classification-F1 0.016521110898620937 on epoch=160
05/29/2022 20:27:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.34 on epoch=161
05/29/2022 20:27:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.34 on epoch=162
05/29/2022 20:27:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.18 on epoch=162
05/29/2022 20:27:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 3.40 on epoch=163
05/29/2022 20:27:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.09 on epoch=164
05/29/2022 20:27:33 - INFO - __main__ - Global step 2300 Train loss 3.27 Classification-F1 0.024935224163651848 on epoch=164
05/29/2022 20:27:33 - INFO - __main__ - Saving model with best Classification-F1: 0.02399566791890886 -> 0.024935224163651848 on epoch=164, global_step=2300
05/29/2022 20:27:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.16 on epoch=164
05/29/2022 20:27:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.14 on epoch=165
05/29/2022 20:27:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 3.40 on epoch=166
05/29/2022 20:27:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.31 on epoch=167
05/29/2022 20:27:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.07 on epoch=167
05/29/2022 20:27:41 - INFO - __main__ - Global step 2350 Train loss 3.22 Classification-F1 0.028674388674388675 on epoch=167
05/29/2022 20:27:41 - INFO - __main__ - Saving model with best Classification-F1: 0.024935224163651848 -> 0.028674388674388675 on epoch=167, global_step=2350
05/29/2022 20:27:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.19 on epoch=168
05/29/2022 20:27:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 3.13 on epoch=169
05/29/2022 20:27:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 3.15 on epoch=169
05/29/2022 20:27:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 3.07 on epoch=170
05/29/2022 20:27:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 3.24 on epoch=171
05/29/2022 20:27:50 - INFO - __main__ - Global step 2400 Train loss 3.16 Classification-F1 0.0343266447040032 on epoch=171
05/29/2022 20:27:50 - INFO - __main__ - Saving model with best Classification-F1: 0.028674388674388675 -> 0.0343266447040032 on epoch=171, global_step=2400
05/29/2022 20:27:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.21 on epoch=172
05/29/2022 20:27:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.01 on epoch=172
05/29/2022 20:27:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.22 on epoch=173
05/29/2022 20:27:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 3.05 on epoch=174
05/29/2022 20:27:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.22 on epoch=174
05/29/2022 20:27:58 - INFO - __main__ - Global step 2450 Train loss 3.14 Classification-F1 0.023751561163714945 on epoch=174
05/29/2022 20:27:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 3.09 on epoch=175
05/29/2022 20:28:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 3.13 on epoch=176
05/29/2022 20:28:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 3.13 on epoch=177
05/29/2022 20:28:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 3.02 on epoch=177
05/29/2022 20:28:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.11 on epoch=178
05/29/2022 20:28:06 - INFO - __main__ - Global step 2500 Train loss 3.10 Classification-F1 0.0445169970822337 on epoch=178
05/29/2022 20:28:06 - INFO - __main__ - Saving model with best Classification-F1: 0.0343266447040032 -> 0.0445169970822337 on epoch=178, global_step=2500
05/29/2022 20:28:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 3.12 on epoch=179
05/29/2022 20:28:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 3.15 on epoch=179
05/29/2022 20:28:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 3.03 on epoch=180
05/29/2022 20:28:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.14 on epoch=181
05/29/2022 20:28:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.02 on epoch=182
05/29/2022 20:28:15 - INFO - __main__ - Global step 2550 Train loss 3.09 Classification-F1 0.022368421052631576 on epoch=182
05/29/2022 20:28:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.98 on epoch=182
05/29/2022 20:28:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 3.05 on epoch=183
05/29/2022 20:28:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 3.16 on epoch=184
05/29/2022 20:28:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.99 on epoch=184
05/29/2022 20:28:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 3.14 on epoch=185
05/29/2022 20:28:23 - INFO - __main__ - Global step 2600 Train loss 3.07 Classification-F1 0.032536199432751156 on epoch=185
05/29/2022 20:28:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 3.12 on epoch=186
05/29/2022 20:28:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 3.16 on epoch=187
05/29/2022 20:28:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.99 on epoch=187
05/29/2022 20:28:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 3.04 on epoch=188
05/29/2022 20:28:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.99 on epoch=189
05/29/2022 20:28:31 - INFO - __main__ - Global step 2650 Train loss 3.06 Classification-F1 0.026552742411773248 on epoch=189
05/29/2022 20:28:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 3.09 on epoch=189
05/29/2022 20:28:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 3.07 on epoch=190
05/29/2022 20:28:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 3.12 on epoch=191
05/29/2022 20:28:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 3.04 on epoch=192
05/29/2022 20:28:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.89 on epoch=192
05/29/2022 20:28:40 - INFO - __main__ - Global step 2700 Train loss 3.04 Classification-F1 0.025995564068958563 on epoch=192
05/29/2022 20:28:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 3.05 on epoch=193
05/29/2022 20:28:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.95 on epoch=194
05/29/2022 20:28:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.89 on epoch=194
05/29/2022 20:28:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.73 on epoch=195
05/29/2022 20:28:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/29/2022 20:28:48 - INFO - __main__ - Global step 2750 Train loss 2.91 Classification-F1 0.014339203423304804 on epoch=196
05/29/2022 20:28:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.87 on epoch=197
05/29/2022 20:28:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.97 on epoch=197
05/29/2022 20:28:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 3.02 on epoch=198
05/29/2022 20:28:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.95 on epoch=199
05/29/2022 20:28:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 3.06 on epoch=199
05/29/2022 20:28:56 - INFO - __main__ - Global step 2800 Train loss 2.97 Classification-F1 0.009563658099222952 on epoch=199
05/29/2022 20:28:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.83 on epoch=200
05/29/2022 20:28:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 3.07 on epoch=201
05/29/2022 20:29:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 3.03 on epoch=202
05/29/2022 20:29:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.95 on epoch=202
05/29/2022 20:29:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.95 on epoch=203
05/29/2022 20:29:04 - INFO - __main__ - Global step 2850 Train loss 2.97 Classification-F1 0.009523809523809523 on epoch=203
05/29/2022 20:29:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.79 on epoch=204
05/29/2022 20:29:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.90 on epoch=204
05/29/2022 20:29:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.75 on epoch=205
05/29/2022 20:29:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.99 on epoch=206
05/29/2022 20:29:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.97 on epoch=207
05/29/2022 20:29:13 - INFO - __main__ - Global step 2900 Train loss 2.88 Classification-F1 0.0291613990729035 on epoch=207
05/29/2022 20:29:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.79 on epoch=207
05/29/2022 20:29:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.96 on epoch=208
05/29/2022 20:29:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.98 on epoch=209
05/29/2022 20:29:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.88 on epoch=209
05/29/2022 20:29:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.76 on epoch=210
05/29/2022 20:29:21 - INFO - __main__ - Global step 2950 Train loss 2.88 Classification-F1 0.036080666570998066 on epoch=210
05/29/2022 20:29:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.89 on epoch=211
05/29/2022 20:29:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.80 on epoch=212
05/29/2022 20:29:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.83 on epoch=212
05/29/2022 20:29:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 3.01 on epoch=213
05/29/2022 20:29:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.78 on epoch=214
05/29/2022 20:29:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:29:29 - INFO - __main__ - Printing 3 examples
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 20:29:29 - INFO - __main__ - ['Company']
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 20:29:29 - INFO - __main__ - ['Company']
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 20:29:29 - INFO - __main__ - ['Company']
05/29/2022 20:29:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:29:29 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:29:29 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:29:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:29:29 - INFO - __main__ - Printing 3 examples
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 20:29:29 - INFO - __main__ - ['Company']
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 20:29:29 - INFO - __main__ - ['Company']
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 20:29:29 - INFO - __main__ - ['Company']
05/29/2022 20:29:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:29:29 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:29:29 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:29:29 - INFO - __main__ - Global step 3000 Train loss 2.86 Classification-F1 0.025317369666313125 on epoch=214
05/29/2022 20:29:29 - INFO - __main__ - save last model!
05/29/2022 20:29:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 20:29:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 20:29:29 - INFO - __main__ - Printing 3 examples
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 20:29:29 - INFO - __main__ - ['Animal']
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 20:29:29 - INFO - __main__ - ['Animal']
05/29/2022 20:29:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 20:29:29 - INFO - __main__ - ['Village']
05/29/2022 20:29:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:29:31 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:29:34 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:29:34 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 20:29:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:29:35 - INFO - __main__ - Starting training!
05/29/2022 20:30:04 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/29/2022 20:30:04 - INFO - __main__ - Classification-F1 on test data: 0.0202
05/29/2022 20:30:04 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.0445169970822337, test_performance=0.02022454943077747
05/29/2022 20:30:04 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/29/2022 20:30:05 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:30:05 - INFO - __main__ - Printing 3 examples
05/29/2022 20:30:05 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 20:30:05 - INFO - __main__ - ['Company']
05/29/2022 20:30:05 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 20:30:05 - INFO - __main__ - ['Company']
05/29/2022 20:30:05 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 20:30:05 - INFO - __main__ - ['Company']
05/29/2022 20:30:05 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:30:05 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:30:05 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:30:05 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:30:05 - INFO - __main__ - Printing 3 examples
05/29/2022 20:30:05 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 20:30:05 - INFO - __main__ - ['Company']
05/29/2022 20:30:05 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 20:30:05 - INFO - __main__ - ['Company']
05/29/2022 20:30:05 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 20:30:05 - INFO - __main__ - ['Company']
05/29/2022 20:30:05 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:30:05 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:30:05 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:30:11 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:30:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:30:11 - INFO - __main__ - Starting training!
05/29/2022 20:30:12 - INFO - __main__ - Step 10 Global step 10 Train loss 7.28 on epoch=0
05/29/2022 20:30:14 - INFO - __main__ - Step 20 Global step 20 Train loss 7.48 on epoch=1
05/29/2022 20:30:15 - INFO - __main__ - Step 30 Global step 30 Train loss 7.28 on epoch=2
05/29/2022 20:30:16 - INFO - __main__ - Step 40 Global step 40 Train loss 6.75 on epoch=2
05/29/2022 20:30:17 - INFO - __main__ - Step 50 Global step 50 Train loss 7.08 on epoch=3
05/29/2022 20:31:23 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/29/2022 20:31:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 20:31:25 - INFO - __main__ - Step 60 Global step 60 Train loss 6.76 on epoch=4
05/29/2022 20:31:26 - INFO - __main__ - Step 70 Global step 70 Train loss 6.87 on epoch=4
05/29/2022 20:31:27 - INFO - __main__ - Step 80 Global step 80 Train loss 6.49 on epoch=5
05/29/2022 20:31:28 - INFO - __main__ - Step 90 Global step 90 Train loss 6.63 on epoch=6
05/29/2022 20:31:30 - INFO - __main__ - Step 100 Global step 100 Train loss 6.46 on epoch=7
05/29/2022 20:32:22 - INFO - __main__ - Global step 100 Train loss 6.64 Classification-F1 0.0 on epoch=7
05/29/2022 20:32:23 - INFO - __main__ - Step 110 Global step 110 Train loss 6.14 on epoch=7
05/29/2022 20:32:24 - INFO - __main__ - Step 120 Global step 120 Train loss 6.29 on epoch=8
05/29/2022 20:32:25 - INFO - __main__ - Step 130 Global step 130 Train loss 5.98 on epoch=9
05/29/2022 20:32:27 - INFO - __main__ - Step 140 Global step 140 Train loss 6.19 on epoch=9
05/29/2022 20:32:28 - INFO - __main__ - Step 150 Global step 150 Train loss 5.83 on epoch=10
05/29/2022 20:33:44 - INFO - __main__ - Global step 150 Train loss 6.08 Classification-F1 0.0 on epoch=10
05/29/2022 20:33:45 - INFO - __main__ - Step 160 Global step 160 Train loss 5.99 on epoch=11
05/29/2022 20:33:46 - INFO - __main__ - Step 170 Global step 170 Train loss 5.93 on epoch=12
05/29/2022 20:33:47 - INFO - __main__ - Step 180 Global step 180 Train loss 5.64 on epoch=12
05/29/2022 20:33:49 - INFO - __main__ - Step 190 Global step 190 Train loss 5.71 on epoch=13
05/29/2022 20:33:50 - INFO - __main__ - Step 200 Global step 200 Train loss 5.54 on epoch=14
05/29/2022 20:34:28 - INFO - __main__ - Global step 200 Train loss 5.76 Classification-F1 0.0 on epoch=14
05/29/2022 20:34:30 - INFO - __main__ - Step 210 Global step 210 Train loss 5.75 on epoch=14
05/29/2022 20:34:31 - INFO - __main__ - Step 220 Global step 220 Train loss 5.26 on epoch=15
05/29/2022 20:34:32 - INFO - __main__ - Step 230 Global step 230 Train loss 5.54 on epoch=16
05/29/2022 20:34:33 - INFO - __main__ - Step 240 Global step 240 Train loss 5.41 on epoch=17
05/29/2022 20:34:35 - INFO - __main__ - Step 250 Global step 250 Train loss 5.24 on epoch=17
05/29/2022 20:35:31 - INFO - __main__ - Global step 250 Train loss 5.44 Classification-F1 0.0036215482118605704 on epoch=17
05/29/2022 20:35:31 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0036215482118605704 on epoch=17, global_step=250
05/29/2022 20:35:33 - INFO - __main__ - Step 260 Global step 260 Train loss 5.12 on epoch=18
05/29/2022 20:35:34 - INFO - __main__ - Step 270 Global step 270 Train loss 5.15 on epoch=19
05/29/2022 20:35:35 - INFO - __main__ - Step 280 Global step 280 Train loss 5.18 on epoch=19
05/29/2022 20:35:37 - INFO - __main__ - Step 290 Global step 290 Train loss 4.81 on epoch=20
05/29/2022 20:35:38 - INFO - __main__ - Step 300 Global step 300 Train loss 5.04 on epoch=21
05/29/2022 20:35:45 - INFO - __main__ - Global step 300 Train loss 5.06 Classification-F1 0.008113590263691683 on epoch=21
05/29/2022 20:35:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0036215482118605704 -> 0.008113590263691683 on epoch=21, global_step=300
05/29/2022 20:35:47 - INFO - __main__ - Step 310 Global step 310 Train loss 4.93 on epoch=22
05/29/2022 20:35:48 - INFO - __main__ - Step 320 Global step 320 Train loss 4.79 on epoch=22
05/29/2022 20:35:49 - INFO - __main__ - Step 330 Global step 330 Train loss 4.68 on epoch=23
05/29/2022 20:35:50 - INFO - __main__ - Step 340 Global step 340 Train loss 4.45 on epoch=24
05/29/2022 20:35:52 - INFO - __main__ - Step 350 Global step 350 Train loss 4.61 on epoch=24
05/29/2022 20:35:54 - INFO - __main__ - Global step 350 Train loss 4.69 Classification-F1 0.009523809523809523 on epoch=24
05/29/2022 20:35:54 - INFO - __main__ - Saving model with best Classification-F1: 0.008113590263691683 -> 0.009523809523809523 on epoch=24, global_step=350
05/29/2022 20:35:55 - INFO - __main__ - Step 360 Global step 360 Train loss 4.52 on epoch=25
05/29/2022 20:35:57 - INFO - __main__ - Step 370 Global step 370 Train loss 4.37 on epoch=26
05/29/2022 20:35:58 - INFO - __main__ - Step 380 Global step 380 Train loss 4.51 on epoch=27
05/29/2022 20:35:59 - INFO - __main__ - Step 390 Global step 390 Train loss 4.33 on epoch=27
05/29/2022 20:36:00 - INFO - __main__ - Step 400 Global step 400 Train loss 4.40 on epoch=28
05/29/2022 20:36:02 - INFO - __main__ - Global step 400 Train loss 4.43 Classification-F1 0.009603841536614645 on epoch=28
05/29/2022 20:36:03 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009603841536614645 on epoch=28, global_step=400
05/29/2022 20:36:04 - INFO - __main__ - Step 410 Global step 410 Train loss 4.22 on epoch=29
05/29/2022 20:36:05 - INFO - __main__ - Step 420 Global step 420 Train loss 4.52 on epoch=29
05/29/2022 20:36:06 - INFO - __main__ - Step 430 Global step 430 Train loss 4.05 on epoch=30
05/29/2022 20:36:08 - INFO - __main__ - Step 440 Global step 440 Train loss 4.11 on epoch=31
05/29/2022 20:36:09 - INFO - __main__ - Step 450 Global step 450 Train loss 4.07 on epoch=32
05/29/2022 20:36:11 - INFO - __main__ - Global step 450 Train loss 4.19 Classification-F1 0.02676089201318559 on epoch=32
05/29/2022 20:36:11 - INFO - __main__ - Saving model with best Classification-F1: 0.009603841536614645 -> 0.02676089201318559 on epoch=32, global_step=450
05/29/2022 20:36:12 - INFO - __main__ - Step 460 Global step 460 Train loss 4.03 on epoch=32
05/29/2022 20:36:13 - INFO - __main__ - Step 470 Global step 470 Train loss 4.07 on epoch=33
05/29/2022 20:36:15 - INFO - __main__ - Step 480 Global step 480 Train loss 3.92 on epoch=34
05/29/2022 20:36:16 - INFO - __main__ - Step 490 Global step 490 Train loss 4.11 on epoch=34
05/29/2022 20:36:17 - INFO - __main__ - Step 500 Global step 500 Train loss 3.79 on epoch=35
05/29/2022 20:36:19 - INFO - __main__ - Global step 500 Train loss 3.98 Classification-F1 0.03431197040219596 on epoch=35
05/29/2022 20:36:19 - INFO - __main__ - Saving model with best Classification-F1: 0.02676089201318559 -> 0.03431197040219596 on epoch=35, global_step=500
05/29/2022 20:36:20 - INFO - __main__ - Step 510 Global step 510 Train loss 3.82 on epoch=36
05/29/2022 20:36:22 - INFO - __main__ - Step 520 Global step 520 Train loss 3.88 on epoch=37
05/29/2022 20:36:23 - INFO - __main__ - Step 530 Global step 530 Train loss 3.88 on epoch=37
05/29/2022 20:36:24 - INFO - __main__ - Step 540 Global step 540 Train loss 3.74 on epoch=38
05/29/2022 20:36:25 - INFO - __main__ - Step 550 Global step 550 Train loss 3.80 on epoch=39
05/29/2022 20:36:27 - INFO - __main__ - Global step 550 Train loss 3.83 Classification-F1 0.009523809523809523 on epoch=39
05/29/2022 20:36:28 - INFO - __main__ - Step 560 Global step 560 Train loss 3.88 on epoch=39
05/29/2022 20:36:30 - INFO - __main__ - Step 570 Global step 570 Train loss 3.74 on epoch=40
05/29/2022 20:36:31 - INFO - __main__ - Step 580 Global step 580 Train loss 3.75 on epoch=41
05/29/2022 20:36:32 - INFO - __main__ - Step 590 Global step 590 Train loss 3.57 on epoch=42
05/29/2022 20:36:34 - INFO - __main__ - Step 600 Global step 600 Train loss 3.68 on epoch=42
05/29/2022 20:36:35 - INFO - __main__ - Global step 600 Train loss 3.72 Classification-F1 0.02999268220516973 on epoch=42
05/29/2022 20:36:37 - INFO - __main__ - Step 610 Global step 610 Train loss 3.60 on epoch=43
05/29/2022 20:36:38 - INFO - __main__ - Step 620 Global step 620 Train loss 3.60 on epoch=44
05/29/2022 20:36:39 - INFO - __main__ - Step 630 Global step 630 Train loss 3.65 on epoch=44
05/29/2022 20:36:40 - INFO - __main__ - Step 640 Global step 640 Train loss 3.40 on epoch=45
05/29/2022 20:36:42 - INFO - __main__ - Step 650 Global step 650 Train loss 3.63 on epoch=46
05/29/2022 20:36:44 - INFO - __main__ - Global step 650 Train loss 3.58 Classification-F1 0.009523809523809523 on epoch=46
05/29/2022 20:36:45 - INFO - __main__ - Step 660 Global step 660 Train loss 3.47 on epoch=47
05/29/2022 20:36:46 - INFO - __main__ - Step 670 Global step 670 Train loss 3.49 on epoch=47
05/29/2022 20:36:48 - INFO - __main__ - Step 680 Global step 680 Train loss 3.38 on epoch=48
05/29/2022 20:36:49 - INFO - __main__ - Step 690 Global step 690 Train loss 3.39 on epoch=49
05/29/2022 20:36:50 - INFO - __main__ - Step 700 Global step 700 Train loss 3.36 on epoch=49
05/29/2022 20:36:52 - INFO - __main__ - Global step 700 Train loss 3.42 Classification-F1 0.017795193914596903 on epoch=49
05/29/2022 20:36:53 - INFO - __main__ - Step 710 Global step 710 Train loss 3.26 on epoch=50
05/29/2022 20:36:54 - INFO - __main__ - Step 720 Global step 720 Train loss 3.27 on epoch=51
05/29/2022 20:36:56 - INFO - __main__ - Step 730 Global step 730 Train loss 3.39 on epoch=52
05/29/2022 20:36:57 - INFO - __main__ - Step 740 Global step 740 Train loss 3.29 on epoch=52
05/29/2022 20:36:58 - INFO - __main__ - Step 750 Global step 750 Train loss 3.24 on epoch=53
05/29/2022 20:37:00 - INFO - __main__ - Global step 750 Train loss 3.29 Classification-F1 0.015657161358958345 on epoch=53
05/29/2022 20:37:01 - INFO - __main__ - Step 760 Global step 760 Train loss 3.19 on epoch=54
05/29/2022 20:37:03 - INFO - __main__ - Step 770 Global step 770 Train loss 3.35 on epoch=54
05/29/2022 20:37:04 - INFO - __main__ - Step 780 Global step 780 Train loss 3.34 on epoch=55
05/29/2022 20:37:05 - INFO - __main__ - Step 790 Global step 790 Train loss 3.26 on epoch=56
05/29/2022 20:37:06 - INFO - __main__ - Step 800 Global step 800 Train loss 3.06 on epoch=57
05/29/2022 20:37:08 - INFO - __main__ - Global step 800 Train loss 3.24 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 20:37:10 - INFO - __main__ - Step 810 Global step 810 Train loss 3.17 on epoch=57
05/29/2022 20:37:11 - INFO - __main__ - Step 820 Global step 820 Train loss 3.00 on epoch=58
05/29/2022 20:37:12 - INFO - __main__ - Step 830 Global step 830 Train loss 3.12 on epoch=59
05/29/2022 20:37:13 - INFO - __main__ - Step 840 Global step 840 Train loss 3.11 on epoch=59
05/29/2022 20:37:15 - INFO - __main__ - Step 850 Global step 850 Train loss 3.07 on epoch=60
05/29/2022 20:37:16 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.009563658099222952 on epoch=60
05/29/2022 20:37:18 - INFO - __main__ - Step 860 Global step 860 Train loss 2.94 on epoch=61
05/29/2022 20:37:19 - INFO - __main__ - Step 870 Global step 870 Train loss 3.16 on epoch=62
05/29/2022 20:37:20 - INFO - __main__ - Step 880 Global step 880 Train loss 3.01 on epoch=62
05/29/2022 20:37:22 - INFO - __main__ - Step 890 Global step 890 Train loss 3.01 on epoch=63
05/29/2022 20:37:23 - INFO - __main__ - Step 900 Global step 900 Train loss 3.07 on epoch=64
05/29/2022 20:37:25 - INFO - __main__ - Global step 900 Train loss 3.04 Classification-F1 0.009523809523809523 on epoch=64
05/29/2022 20:37:26 - INFO - __main__ - Step 910 Global step 910 Train loss 3.07 on epoch=64
05/29/2022 20:37:27 - INFO - __main__ - Step 920 Global step 920 Train loss 2.99 on epoch=65
05/29/2022 20:37:28 - INFO - __main__ - Step 930 Global step 930 Train loss 3.04 on epoch=66
05/29/2022 20:37:30 - INFO - __main__ - Step 940 Global step 940 Train loss 3.00 on epoch=67
05/29/2022 20:37:31 - INFO - __main__ - Step 950 Global step 950 Train loss 3.12 on epoch=67
05/29/2022 20:37:33 - INFO - __main__ - Global step 950 Train loss 3.04 Classification-F1 0.009726443768996961 on epoch=67
05/29/2022 20:37:34 - INFO - __main__ - Step 960 Global step 960 Train loss 2.83 on epoch=68
05/29/2022 20:37:36 - INFO - __main__ - Step 970 Global step 970 Train loss 2.75 on epoch=69
05/29/2022 20:37:37 - INFO - __main__ - Step 980 Global step 980 Train loss 2.80 on epoch=69
05/29/2022 20:37:38 - INFO - __main__ - Step 990 Global step 990 Train loss 2.83 on epoch=70
05/29/2022 20:37:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.01 on epoch=71
05/29/2022 20:37:41 - INFO - __main__ - Global step 1000 Train loss 2.84 Classification-F1 0.01800720288115246 on epoch=71
05/29/2022 20:37:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.95 on epoch=72
05/29/2022 20:37:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.94 on epoch=72
05/29/2022 20:37:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.91 on epoch=73
05/29/2022 20:37:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.88 on epoch=74
05/29/2022 20:37:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.88 on epoch=74
05/29/2022 20:37:50 - INFO - __main__ - Global step 1050 Train loss 2.91 Classification-F1 0.009894867037724181 on epoch=74
05/29/2022 20:37:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.91 on epoch=75
05/29/2022 20:37:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.66 on epoch=76
05/29/2022 20:37:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.75 on epoch=77
05/29/2022 20:37:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.83 on epoch=77
05/29/2022 20:37:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.86 on epoch=78
05/29/2022 20:37:59 - INFO - __main__ - Global step 1100 Train loss 2.80 Classification-F1 0.02989399980550423 on epoch=78
05/29/2022 20:38:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.80 on epoch=79
05/29/2022 20:38:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.70 on epoch=79
05/29/2022 20:38:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.80 on epoch=80
05/29/2022 20:38:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.76 on epoch=81
05/29/2022 20:38:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.83 on epoch=82
05/29/2022 20:38:07 - INFO - __main__ - Global step 1150 Train loss 2.78 Classification-F1 0.024187321579100227 on epoch=82
05/29/2022 20:38:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/29/2022 20:38:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.70 on epoch=83
05/29/2022 20:38:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.51 on epoch=84
05/29/2022 20:38:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.68 on epoch=84
05/29/2022 20:38:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.60 on epoch=85
05/29/2022 20:38:16 - INFO - __main__ - Global step 1200 Train loss 2.66 Classification-F1 0.031015037593984968 on epoch=85
05/29/2022 20:38:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.55 on epoch=86
05/29/2022 20:38:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.72 on epoch=87
05/29/2022 20:38:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.62 on epoch=87
05/29/2022 20:38:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.63 on epoch=88
05/29/2022 20:38:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.59 on epoch=89
05/29/2022 20:38:24 - INFO - __main__ - Global step 1250 Train loss 2.63 Classification-F1 0.023548964099097198 on epoch=89
05/29/2022 20:38:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.65 on epoch=89
05/29/2022 20:38:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.60 on epoch=90
05/29/2022 20:38:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.61 on epoch=91
05/29/2022 20:38:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.61 on epoch=92
05/29/2022 20:38:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.69 on epoch=92
05/29/2022 20:38:33 - INFO - __main__ - Global step 1300 Train loss 2.63 Classification-F1 0.02614980183775942 on epoch=92
05/29/2022 20:38:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.57 on epoch=93
05/29/2022 20:38:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.55 on epoch=94
05/29/2022 20:38:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.61 on epoch=94
05/29/2022 20:38:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.48 on epoch=95
05/29/2022 20:38:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.51 on epoch=96
05/29/2022 20:38:41 - INFO - __main__ - Global step 1350 Train loss 2.54 Classification-F1 0.014948084496956676 on epoch=96
05/29/2022 20:38:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.51 on epoch=97
05/29/2022 20:38:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.55 on epoch=97
05/29/2022 20:38:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.54 on epoch=98
05/29/2022 20:38:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.58 on epoch=99
05/29/2022 20:38:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.73 on epoch=99
05/29/2022 20:38:49 - INFO - __main__ - Global step 1400 Train loss 2.58 Classification-F1 0.03706672009617311 on epoch=99
05/29/2022 20:38:49 - INFO - __main__ - Saving model with best Classification-F1: 0.03431197040219596 -> 0.03706672009617311 on epoch=99, global_step=1400
05/29/2022 20:38:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.43 on epoch=100
05/29/2022 20:38:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.63 on epoch=101
05/29/2022 20:38:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.68 on epoch=102
05/29/2022 20:38:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.56 on epoch=102
05/29/2022 20:38:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.52 on epoch=103
05/29/2022 20:38:58 - INFO - __main__ - Global step 1450 Train loss 2.57 Classification-F1 0.02634125134125134 on epoch=103
05/29/2022 20:38:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.49 on epoch=104
05/29/2022 20:39:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.48 on epoch=104
05/29/2022 20:39:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.46 on epoch=105
05/29/2022 20:39:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.60 on epoch=106
05/29/2022 20:39:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.55 on epoch=107
05/29/2022 20:39:06 - INFO - __main__ - Global step 1500 Train loss 2.51 Classification-F1 0.013309671694764864 on epoch=107
05/29/2022 20:39:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.53 on epoch=107
05/29/2022 20:39:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.59 on epoch=108
05/29/2022 20:39:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.56 on epoch=109
05/29/2022 20:39:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.55 on epoch=109
05/29/2022 20:39:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.54 on epoch=110
05/29/2022 20:39:15 - INFO - __main__ - Global step 1550 Train loss 2.55 Classification-F1 0.01713875205254516 on epoch=110
05/29/2022 20:39:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.49 on epoch=111
05/29/2022 20:39:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.51 on epoch=112
05/29/2022 20:39:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.54 on epoch=112
05/29/2022 20:39:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.45 on epoch=113
05/29/2022 20:39:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.44 on epoch=114
05/29/2022 20:39:23 - INFO - __main__ - Global step 1600 Train loss 2.48 Classification-F1 0.009920634920634922 on epoch=114
05/29/2022 20:39:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.35 on epoch=114
05/29/2022 20:39:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.51 on epoch=115
05/29/2022 20:39:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.43 on epoch=116
05/29/2022 20:39:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.42 on epoch=117
05/29/2022 20:39:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.43 on epoch=117
05/29/2022 20:39:31 - INFO - __main__ - Global step 1650 Train loss 2.43 Classification-F1 0.009523809523809523 on epoch=117
05/29/2022 20:39:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.40 on epoch=118
05/29/2022 20:39:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.47 on epoch=119
05/29/2022 20:39:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.30 on epoch=119
05/29/2022 20:39:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.45 on epoch=120
05/29/2022 20:39:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.29 on epoch=121
05/29/2022 20:39:40 - INFO - __main__ - Global step 1700 Train loss 2.38 Classification-F1 0.04844822402611347 on epoch=121
05/29/2022 20:39:40 - INFO - __main__ - Saving model with best Classification-F1: 0.03706672009617311 -> 0.04844822402611347 on epoch=121, global_step=1700
05/29/2022 20:39:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.31 on epoch=122
05/29/2022 20:39:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.34 on epoch=122
05/29/2022 20:39:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.40 on epoch=123
05/29/2022 20:39:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.26 on epoch=124
05/29/2022 20:39:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.39 on epoch=124
05/29/2022 20:39:48 - INFO - __main__ - Global step 1750 Train loss 2.34 Classification-F1 0.048214285714285716 on epoch=124
05/29/2022 20:39:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.37 on epoch=125
05/29/2022 20:39:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.28 on epoch=126
05/29/2022 20:39:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.33 on epoch=127
05/29/2022 20:39:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.31 on epoch=127
05/29/2022 20:39:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.36 on epoch=128
05/29/2022 20:39:56 - INFO - __main__ - Global step 1800 Train loss 2.33 Classification-F1 0.023325027685492803 on epoch=128
05/29/2022 20:39:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.22 on epoch=129
05/29/2022 20:39:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.23 on epoch=129
05/29/2022 20:40:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.22 on epoch=130
05/29/2022 20:40:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.33 on epoch=131
05/29/2022 20:40:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.30 on epoch=132
05/29/2022 20:40:04 - INFO - __main__ - Global step 1850 Train loss 2.26 Classification-F1 0.020835310868533463 on epoch=132
05/29/2022 20:40:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.34 on epoch=132
05/29/2022 20:40:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.31 on epoch=133
05/29/2022 20:40:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.11 on epoch=134
05/29/2022 20:40:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.18 on epoch=134
05/29/2022 20:40:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.20 on epoch=135
05/29/2022 20:40:13 - INFO - __main__ - Global step 1900 Train loss 2.23 Classification-F1 0.025723806268919052 on epoch=135
05/29/2022 20:40:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.35 on epoch=136
05/29/2022 20:40:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.18 on epoch=137
05/29/2022 20:40:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.19 on epoch=137
05/29/2022 20:40:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.26 on epoch=138
05/29/2022 20:40:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.24 on epoch=139
05/29/2022 20:40:21 - INFO - __main__ - Global step 1950 Train loss 2.24 Classification-F1 0.022740065293256784 on epoch=139
05/29/2022 20:40:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.07 on epoch=139
05/29/2022 20:40:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.21 on epoch=140
05/29/2022 20:40:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.26 on epoch=141
05/29/2022 20:40:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.18 on epoch=142
05/29/2022 20:40:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.22 on epoch=142
05/29/2022 20:40:29 - INFO - __main__ - Global step 2000 Train loss 2.19 Classification-F1 0.02677775229942164 on epoch=142
05/29/2022 20:40:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.29 on epoch=143
05/29/2022 20:40:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.10 on epoch=144
05/29/2022 20:40:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.21 on epoch=144
05/29/2022 20:40:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.15 on epoch=145
05/29/2022 20:40:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.07 on epoch=146
05/29/2022 20:40:37 - INFO - __main__ - Global step 2050 Train loss 2.16 Classification-F1 0.03790954219525648 on epoch=146
05/29/2022 20:40:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.16 on epoch=147
05/29/2022 20:40:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.04 on epoch=147
05/29/2022 20:40:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.01 on epoch=148
05/29/2022 20:40:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.17 on epoch=149
05/29/2022 20:40:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.03 on epoch=149
05/29/2022 20:40:46 - INFO - __main__ - Global step 2100 Train loss 2.08 Classification-F1 0.03715874667209773 on epoch=149
05/29/2022 20:40:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.03 on epoch=150
05/29/2022 20:40:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.96 on epoch=151
05/29/2022 20:40:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.05 on epoch=152
05/29/2022 20:40:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.17 on epoch=152
05/29/2022 20:40:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.98 on epoch=153
05/29/2022 20:40:54 - INFO - __main__ - Global step 2150 Train loss 2.04 Classification-F1 0.03395922327520234 on epoch=153
05/29/2022 20:40:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.14 on epoch=154
05/29/2022 20:40:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.12 on epoch=154
05/29/2022 20:40:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.01 on epoch=155
05/29/2022 20:40:59 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.86 on epoch=156
05/29/2022 20:41:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.06 on epoch=157
05/29/2022 20:41:02 - INFO - __main__ - Global step 2200 Train loss 2.04 Classification-F1 0.05662044072948329 on epoch=157
05/29/2022 20:41:02 - INFO - __main__ - Saving model with best Classification-F1: 0.04844822402611347 -> 0.05662044072948329 on epoch=157, global_step=2200
05/29/2022 20:41:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.00 on epoch=157
05/29/2022 20:41:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.04 on epoch=158
05/29/2022 20:41:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.96 on epoch=159
05/29/2022 20:41:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.06 on epoch=159
05/29/2022 20:41:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.99 on epoch=160
05/29/2022 20:41:10 - INFO - __main__ - Global step 2250 Train loss 2.01 Classification-F1 0.062470170212105706 on epoch=160
05/29/2022 20:41:10 - INFO - __main__ - Saving model with best Classification-F1: 0.05662044072948329 -> 0.062470170212105706 on epoch=160, global_step=2250
05/29/2022 20:41:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.08 on epoch=161
05/29/2022 20:41:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.99 on epoch=162
05/29/2022 20:41:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.96 on epoch=162
05/29/2022 20:41:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.98 on epoch=163
05/29/2022 20:41:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.94 on epoch=164
05/29/2022 20:41:19 - INFO - __main__ - Global step 2300 Train loss 1.99 Classification-F1 0.04513179968892421 on epoch=164
05/29/2022 20:41:20 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.81 on epoch=164
05/29/2022 20:41:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.97 on epoch=165
05/29/2022 20:41:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.93 on epoch=166
05/29/2022 20:41:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.99 on epoch=167
05/29/2022 20:41:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.86 on epoch=167
05/29/2022 20:41:27 - INFO - __main__ - Global step 2350 Train loss 1.91 Classification-F1 0.07333057559506033 on epoch=167
05/29/2022 20:41:27 - INFO - __main__ - Saving model with best Classification-F1: 0.062470170212105706 -> 0.07333057559506033 on epoch=167, global_step=2350
05/29/2022 20:41:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.01 on epoch=168
05/29/2022 20:41:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.95 on epoch=169
05/29/2022 20:41:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.03 on epoch=169
05/29/2022 20:41:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.86 on epoch=170
05/29/2022 20:41:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.98 on epoch=171
05/29/2022 20:41:35 - INFO - __main__ - Global step 2400 Train loss 1.97 Classification-F1 0.04171852043902861 on epoch=171
05/29/2022 20:41:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.84 on epoch=172
05/29/2022 20:41:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.84 on epoch=172
05/29/2022 20:41:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.97 on epoch=173
05/29/2022 20:41:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.85 on epoch=174
05/29/2022 20:41:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.97 on epoch=174
05/29/2022 20:41:44 - INFO - __main__ - Global step 2450 Train loss 1.89 Classification-F1 0.06168731756967051 on epoch=174
05/29/2022 20:41:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.99 on epoch=175
05/29/2022 20:41:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.95 on epoch=176
05/29/2022 20:41:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.90 on epoch=177
05/29/2022 20:41:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.69 on epoch=177
05/29/2022 20:41:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.04 on epoch=178
05/29/2022 20:41:52 - INFO - __main__ - Global step 2500 Train loss 1.91 Classification-F1 0.07772376179317322 on epoch=178
05/29/2022 20:41:52 - INFO - __main__ - Saving model with best Classification-F1: 0.07333057559506033 -> 0.07772376179317322 on epoch=178, global_step=2500
05/29/2022 20:41:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.91 on epoch=179
05/29/2022 20:41:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.85 on epoch=179
05/29/2022 20:41:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.92 on epoch=180
05/29/2022 20:41:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.78 on epoch=181
05/29/2022 20:41:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.92 on epoch=182
05/29/2022 20:42:01 - INFO - __main__ - Global step 2550 Train loss 1.88 Classification-F1 0.08242901746991259 on epoch=182
05/29/2022 20:42:01 - INFO - __main__ - Saving model with best Classification-F1: 0.07772376179317322 -> 0.08242901746991259 on epoch=182, global_step=2550
05/29/2022 20:42:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.90 on epoch=182
05/29/2022 20:42:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.90 on epoch=183
05/29/2022 20:42:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.84 on epoch=184
05/29/2022 20:42:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.78 on epoch=184
05/29/2022 20:42:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.90 on epoch=185
05/29/2022 20:42:10 - INFO - __main__ - Global step 2600 Train loss 1.86 Classification-F1 0.05927219237988134 on epoch=185
05/29/2022 20:42:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.96 on epoch=186
05/29/2022 20:42:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.82 on epoch=187
05/29/2022 20:42:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.78 on epoch=187
05/29/2022 20:42:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.90 on epoch=188
05/29/2022 20:42:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.89 on epoch=189
05/29/2022 20:42:18 - INFO - __main__ - Global step 2650 Train loss 1.87 Classification-F1 0.06874328678839955 on epoch=189
05/29/2022 20:42:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.83 on epoch=189
05/29/2022 20:42:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.70 on epoch=190
05/29/2022 20:42:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.90 on epoch=191
05/29/2022 20:42:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.81 on epoch=192
05/29/2022 20:42:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.77 on epoch=192
05/29/2022 20:42:26 - INFO - __main__ - Global step 2700 Train loss 1.80 Classification-F1 0.07563898861438888 on epoch=192
05/29/2022 20:42:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.67 on epoch=193
05/29/2022 20:42:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.91 on epoch=194
05/29/2022 20:42:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.92 on epoch=194
05/29/2022 20:42:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.71 on epoch=195
05/29/2022 20:42:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.72 on epoch=196
05/29/2022 20:42:35 - INFO - __main__ - Global step 2750 Train loss 1.79 Classification-F1 0.04166666666666667 on epoch=196
05/29/2022 20:42:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.86 on epoch=197
05/29/2022 20:42:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.68 on epoch=197
05/29/2022 20:42:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.71 on epoch=198
05/29/2022 20:42:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.84 on epoch=199
05/29/2022 20:42:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.79 on epoch=199
05/29/2022 20:42:44 - INFO - __main__ - Global step 2800 Train loss 1.78 Classification-F1 0.048707804884355325 on epoch=199
05/29/2022 20:42:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.61 on epoch=200
05/29/2022 20:42:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.66 on epoch=201
05/29/2022 20:42:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.79 on epoch=202
05/29/2022 20:42:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.67 on epoch=202
05/29/2022 20:42:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.84 on epoch=203
05/29/2022 20:42:53 - INFO - __main__ - Global step 2850 Train loss 1.71 Classification-F1 0.04450504132370516 on epoch=203
05/29/2022 20:42:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.73 on epoch=204
05/29/2022 20:42:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.67 on epoch=204
05/29/2022 20:42:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.65 on epoch=205
05/29/2022 20:42:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.82 on epoch=206
05/29/2022 20:42:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.69 on epoch=207
05/29/2022 20:43:01 - INFO - __main__ - Global step 2900 Train loss 1.71 Classification-F1 0.047229053747522745 on epoch=207
05/29/2022 20:43:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.59 on epoch=207
05/29/2022 20:43:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.75 on epoch=208
05/29/2022 20:43:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.65 on epoch=209
05/29/2022 20:43:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.74 on epoch=209
05/29/2022 20:43:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.70 on epoch=210
05/29/2022 20:43:10 - INFO - __main__ - Global step 2950 Train loss 1.68 Classification-F1 0.036088164598356176 on epoch=210
05/29/2022 20:43:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.69 on epoch=211
05/29/2022 20:43:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.66 on epoch=212
05/29/2022 20:43:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.66 on epoch=212
05/29/2022 20:43:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.78 on epoch=213
05/29/2022 20:43:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.68 on epoch=214
05/29/2022 20:43:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:43:18 - INFO - __main__ - Printing 3 examples
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 20:43:18 - INFO - __main__ - ['Company']
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 20:43:18 - INFO - __main__ - ['Company']
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 20:43:18 - INFO - __main__ - ['Company']
05/29/2022 20:43:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:43:18 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:43:18 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:43:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:43:18 - INFO - __main__ - Printing 3 examples
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 20:43:18 - INFO - __main__ - ['Company']
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 20:43:18 - INFO - __main__ - ['Company']
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 20:43:18 - INFO - __main__ - ['Company']
05/29/2022 20:43:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:43:18 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:43:18 - INFO - __main__ - Global step 3000 Train loss 1.69 Classification-F1 0.009685230024213076 on epoch=214
05/29/2022 20:43:18 - INFO - __main__ - save last model!
05/29/2022 20:43:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 20:43:18 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 20:43:18 - INFO - __main__ - Printing 3 examples
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 20:43:18 - INFO - __main__ - ['Animal']
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 20:43:18 - INFO - __main__ - ['Animal']
05/29/2022 20:43:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 20:43:18 - INFO - __main__ - ['Village']
05/29/2022 20:43:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:43:18 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:43:20 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:43:24 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 20:43:24 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:43:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:43:25 - INFO - __main__ - Starting training!
05/29/2022 20:43:53 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/29/2022 20:43:53 - INFO - __main__ - Classification-F1 on test data: 0.0120
05/29/2022 20:43:53 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.08242901746991259, test_performance=0.012025883515299303
05/29/2022 20:43:53 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/29/2022 20:43:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:43:54 - INFO - __main__ - Printing 3 examples
05/29/2022 20:43:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 20:43:54 - INFO - __main__ - ['Company']
05/29/2022 20:43:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 20:43:54 - INFO - __main__ - ['Company']
05/29/2022 20:43:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 20:43:54 - INFO - __main__ - ['Company']
05/29/2022 20:43:54 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:43:54 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:43:54 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:43:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:43:54 - INFO - __main__ - Printing 3 examples
05/29/2022 20:43:54 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 20:43:54 - INFO - __main__ - ['Company']
05/29/2022 20:43:54 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 20:43:54 - INFO - __main__ - ['Company']
05/29/2022 20:43:54 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 20:43:54 - INFO - __main__ - ['Company']
05/29/2022 20:43:54 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:43:54 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:43:55 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:44:00 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:44:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:44:00 - INFO - __main__ - Starting training!
05/29/2022 20:44:02 - INFO - __main__ - Step 10 Global step 10 Train loss 7.34 on epoch=0
05/29/2022 20:44:03 - INFO - __main__ - Step 20 Global step 20 Train loss 7.59 on epoch=1
05/29/2022 20:44:04 - INFO - __main__ - Step 30 Global step 30 Train loss 7.50 on epoch=2
05/29/2022 20:44:06 - INFO - __main__ - Step 40 Global step 40 Train loss 6.85 on epoch=2
05/29/2022 20:44:07 - INFO - __main__ - Step 50 Global step 50 Train loss 7.29 on epoch=3
05/29/2022 20:44:20 - INFO - __main__ - Global step 50 Train loss 7.32 Classification-F1 0.0 on epoch=3
05/29/2022 20:44:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 20:44:22 - INFO - __main__ - Step 60 Global step 60 Train loss 6.86 on epoch=4
05/29/2022 20:44:23 - INFO - __main__ - Step 70 Global step 70 Train loss 7.05 on epoch=4
05/29/2022 20:44:24 - INFO - __main__ - Step 80 Global step 80 Train loss 6.61 on epoch=5
05/29/2022 20:44:26 - INFO - __main__ - Step 90 Global step 90 Train loss 6.81 on epoch=6
05/29/2022 20:44:27 - INFO - __main__ - Step 100 Global step 100 Train loss 6.77 on epoch=7
05/29/2022 20:45:05 - INFO - __main__ - Global step 100 Train loss 6.82 Classification-F1 0.0 on epoch=7
05/29/2022 20:45:06 - INFO - __main__ - Step 110 Global step 110 Train loss 6.24 on epoch=7
05/29/2022 20:45:08 - INFO - __main__ - Step 120 Global step 120 Train loss 6.58 on epoch=8
05/29/2022 20:45:09 - INFO - __main__ - Step 130 Global step 130 Train loss 6.20 on epoch=9
05/29/2022 20:45:10 - INFO - __main__ - Step 140 Global step 140 Train loss 6.54 on epoch=9
05/29/2022 20:45:11 - INFO - __main__ - Step 150 Global step 150 Train loss 6.06 on epoch=10
05/29/2022 20:45:38 - INFO - __main__ - Global step 150 Train loss 6.32 Classification-F1 0.0 on epoch=10
05/29/2022 20:45:39 - INFO - __main__ - Step 160 Global step 160 Train loss 6.18 on epoch=11
05/29/2022 20:45:40 - INFO - __main__ - Step 170 Global step 170 Train loss 6.18 on epoch=12
05/29/2022 20:45:42 - INFO - __main__ - Step 180 Global step 180 Train loss 5.70 on epoch=12
05/29/2022 20:45:43 - INFO - __main__ - Step 190 Global step 190 Train loss 6.09 on epoch=13
05/29/2022 20:45:44 - INFO - __main__ - Step 200 Global step 200 Train loss 5.69 on epoch=14
05/29/2022 20:46:28 - INFO - __main__ - Global step 200 Train loss 5.97 Classification-F1 0.0 on epoch=14
05/29/2022 20:46:29 - INFO - __main__ - Step 210 Global step 210 Train loss 6.01 on epoch=14
05/29/2022 20:46:30 - INFO - __main__ - Step 220 Global step 220 Train loss 5.70 on epoch=15
05/29/2022 20:46:31 - INFO - __main__ - Step 230 Global step 230 Train loss 5.83 on epoch=16
05/29/2022 20:46:33 - INFO - __main__ - Step 240 Global step 240 Train loss 5.62 on epoch=17
05/29/2022 20:46:34 - INFO - __main__ - Step 250 Global step 250 Train loss 5.38 on epoch=17
05/29/2022 20:47:03 - INFO - __main__ - Global step 250 Train loss 5.71 Classification-F1 0.0 on epoch=17
05/29/2022 20:47:04 - INFO - __main__ - Step 260 Global step 260 Train loss 5.48 on epoch=18
05/29/2022 20:47:05 - INFO - __main__ - Step 270 Global step 270 Train loss 5.26 on epoch=19
05/29/2022 20:47:07 - INFO - __main__ - Step 280 Global step 280 Train loss 5.42 on epoch=19
05/29/2022 20:47:08 - INFO - __main__ - Step 290 Global step 290 Train loss 5.03 on epoch=20
05/29/2022 20:47:09 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/29/2022 20:47:24 - INFO - __main__ - Global step 300 Train loss 5.32 Classification-F1 0.0065832784726793945 on epoch=21
05/29/2022 20:47:24 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0065832784726793945 on epoch=21, global_step=300
05/29/2022 20:47:26 - INFO - __main__ - Step 310 Global step 310 Train loss 5.14 on epoch=22
05/29/2022 20:47:27 - INFO - __main__ - Step 320 Global step 320 Train loss 4.94 on epoch=22
05/29/2022 20:47:28 - INFO - __main__ - Step 330 Global step 330 Train loss 5.09 on epoch=23
05/29/2022 20:47:29 - INFO - __main__ - Step 340 Global step 340 Train loss 5.08 on epoch=24
05/29/2022 20:47:31 - INFO - __main__ - Step 350 Global step 350 Train loss 5.18 on epoch=24
05/29/2022 20:47:34 - INFO - __main__ - Global step 350 Train loss 5.09 Classification-F1 0.007231404958677684 on epoch=24
05/29/2022 20:47:34 - INFO - __main__ - Saving model with best Classification-F1: 0.0065832784726793945 -> 0.007231404958677684 on epoch=24, global_step=350
05/29/2022 20:47:35 - INFO - __main__ - Step 360 Global step 360 Train loss 4.86 on epoch=25
05/29/2022 20:47:37 - INFO - __main__ - Step 370 Global step 370 Train loss 5.03 on epoch=26
05/29/2022 20:47:38 - INFO - __main__ - Step 380 Global step 380 Train loss 4.98 on epoch=27
05/29/2022 20:47:39 - INFO - __main__ - Step 390 Global step 390 Train loss 4.62 on epoch=27
05/29/2022 20:47:40 - INFO - __main__ - Step 400 Global step 400 Train loss 4.77 on epoch=28
05/29/2022 20:47:43 - INFO - __main__ - Global step 400 Train loss 4.85 Classification-F1 0.0072028811524609835 on epoch=28
05/29/2022 20:47:44 - INFO - __main__ - Step 410 Global step 410 Train loss 4.67 on epoch=29
05/29/2022 20:47:46 - INFO - __main__ - Step 420 Global step 420 Train loss 4.82 on epoch=29
05/29/2022 20:47:47 - INFO - __main__ - Step 430 Global step 430 Train loss 4.47 on epoch=30
05/29/2022 20:47:48 - INFO - __main__ - Step 440 Global step 440 Train loss 4.63 on epoch=31
05/29/2022 20:47:49 - INFO - __main__ - Step 450 Global step 450 Train loss 4.56 on epoch=32
05/29/2022 20:47:52 - INFO - __main__ - Global step 450 Train loss 4.63 Classification-F1 0.008403361344537815 on epoch=32
05/29/2022 20:47:52 - INFO - __main__ - Saving model with best Classification-F1: 0.007231404958677684 -> 0.008403361344537815 on epoch=32, global_step=450
05/29/2022 20:47:53 - INFO - __main__ - Step 460 Global step 460 Train loss 4.42 on epoch=32
05/29/2022 20:47:54 - INFO - __main__ - Step 470 Global step 470 Train loss 4.47 on epoch=33
05/29/2022 20:47:56 - INFO - __main__ - Step 480 Global step 480 Train loss 4.34 on epoch=34
05/29/2022 20:47:57 - INFO - __main__ - Step 490 Global step 490 Train loss 4.36 on epoch=34
05/29/2022 20:47:58 - INFO - __main__ - Step 500 Global step 500 Train loss 4.24 on epoch=35
05/29/2022 20:48:00 - INFO - __main__ - Global step 500 Train loss 4.37 Classification-F1 0.009523809523809523 on epoch=35
05/29/2022 20:48:00 - INFO - __main__ - Saving model with best Classification-F1: 0.008403361344537815 -> 0.009523809523809523 on epoch=35, global_step=500
05/29/2022 20:48:01 - INFO - __main__ - Step 510 Global step 510 Train loss 4.31 on epoch=36
05/29/2022 20:48:03 - INFO - __main__ - Step 520 Global step 520 Train loss 4.16 on epoch=37
05/29/2022 20:48:04 - INFO - __main__ - Step 530 Global step 530 Train loss 4.08 on epoch=37
05/29/2022 20:48:05 - INFO - __main__ - Step 540 Global step 540 Train loss 4.08 on epoch=38
05/29/2022 20:48:06 - INFO - __main__ - Step 550 Global step 550 Train loss 4.08 on epoch=39
05/29/2022 20:48:08 - INFO - __main__ - Global step 550 Train loss 4.14 Classification-F1 0.009523809523809523 on epoch=39
05/29/2022 20:48:10 - INFO - __main__ - Step 560 Global step 560 Train loss 4.09 on epoch=39
05/29/2022 20:48:11 - INFO - __main__ - Step 570 Global step 570 Train loss 3.99 on epoch=40
05/29/2022 20:48:12 - INFO - __main__ - Step 580 Global step 580 Train loss 3.83 on epoch=41
05/29/2022 20:48:13 - INFO - __main__ - Step 590 Global step 590 Train loss 3.90 on epoch=42
05/29/2022 20:48:15 - INFO - __main__ - Step 600 Global step 600 Train loss 3.83 on epoch=42
05/29/2022 20:48:17 - INFO - __main__ - Global step 600 Train loss 3.93 Classification-F1 0.009523809523809523 on epoch=42
05/29/2022 20:48:18 - INFO - __main__ - Step 610 Global step 610 Train loss 3.84 on epoch=43
05/29/2022 20:48:19 - INFO - __main__ - Step 620 Global step 620 Train loss 3.72 on epoch=44
05/29/2022 20:48:20 - INFO - __main__ - Step 630 Global step 630 Train loss 3.88 on epoch=44
05/29/2022 20:48:22 - INFO - __main__ - Step 640 Global step 640 Train loss 3.58 on epoch=45
05/29/2022 20:48:23 - INFO - __main__ - Step 650 Global step 650 Train loss 3.71 on epoch=46
05/29/2022 20:48:25 - INFO - __main__ - Global step 650 Train loss 3.75 Classification-F1 0.009523809523809523 on epoch=46
05/29/2022 20:48:26 - INFO - __main__ - Step 660 Global step 660 Train loss 3.55 on epoch=47
05/29/2022 20:48:27 - INFO - __main__ - Step 670 Global step 670 Train loss 3.61 on epoch=47
05/29/2022 20:48:29 - INFO - __main__ - Step 680 Global step 680 Train loss 3.65 on epoch=48
05/29/2022 20:48:30 - INFO - __main__ - Step 690 Global step 690 Train loss 3.45 on epoch=49
05/29/2022 20:48:31 - INFO - __main__ - Step 700 Global step 700 Train loss 3.64 on epoch=49
05/29/2022 20:48:33 - INFO - __main__ - Global step 700 Train loss 3.58 Classification-F1 0.028485757121439276 on epoch=49
05/29/2022 20:48:33 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.028485757121439276 on epoch=49, global_step=700
05/29/2022 20:48:34 - INFO - __main__ - Step 710 Global step 710 Train loss 3.44 on epoch=50
05/29/2022 20:48:36 - INFO - __main__ - Step 720 Global step 720 Train loss 3.35 on epoch=51
05/29/2022 20:48:37 - INFO - __main__ - Step 730 Global step 730 Train loss 3.31 on epoch=52
05/29/2022 20:48:38 - INFO - __main__ - Step 740 Global step 740 Train loss 3.42 on epoch=52
05/29/2022 20:48:40 - INFO - __main__ - Step 750 Global step 750 Train loss 3.35 on epoch=53
05/29/2022 20:48:42 - INFO - __main__ - Global step 750 Train loss 3.37 Classification-F1 0.01800720288115246 on epoch=53
05/29/2022 20:48:43 - INFO - __main__ - Step 760 Global step 760 Train loss 3.24 on epoch=54
05/29/2022 20:48:44 - INFO - __main__ - Step 770 Global step 770 Train loss 3.32 on epoch=54
05/29/2022 20:48:45 - INFO - __main__ - Step 780 Global step 780 Train loss 3.18 on epoch=55
05/29/2022 20:48:47 - INFO - __main__ - Step 790 Global step 790 Train loss 3.26 on epoch=56
05/29/2022 20:48:48 - INFO - __main__ - Step 800 Global step 800 Train loss 3.18 on epoch=57
05/29/2022 20:48:50 - INFO - __main__ - Global step 800 Train loss 3.24 Classification-F1 0.025068946497517928 on epoch=57
05/29/2022 20:48:51 - INFO - __main__ - Step 810 Global step 810 Train loss 3.22 on epoch=57
05/29/2022 20:48:52 - INFO - __main__ - Step 820 Global step 820 Train loss 3.04 on epoch=58
05/29/2022 20:48:54 - INFO - __main__ - Step 830 Global step 830 Train loss 3.13 on epoch=59
05/29/2022 20:48:55 - INFO - __main__ - Step 840 Global step 840 Train loss 3.18 on epoch=59
05/29/2022 20:48:56 - INFO - __main__ - Step 850 Global step 850 Train loss 2.88 on epoch=60
05/29/2022 20:48:58 - INFO - __main__ - Global step 850 Train loss 3.09 Classification-F1 0.009563658099222952 on epoch=60
05/29/2022 20:48:59 - INFO - __main__ - Step 860 Global step 860 Train loss 2.98 on epoch=61
05/29/2022 20:49:01 - INFO - __main__ - Step 870 Global step 870 Train loss 2.89 on epoch=62
05/29/2022 20:49:02 - INFO - __main__ - Step 880 Global step 880 Train loss 3.02 on epoch=62
05/29/2022 20:49:03 - INFO - __main__ - Step 890 Global step 890 Train loss 3.03 on epoch=63
05/29/2022 20:49:04 - INFO - __main__ - Step 900 Global step 900 Train loss 2.96 on epoch=64
05/29/2022 20:49:06 - INFO - __main__ - Global step 900 Train loss 2.98 Classification-F1 0.024081089128564808 on epoch=64
05/29/2022 20:49:08 - INFO - __main__ - Step 910 Global step 910 Train loss 2.83 on epoch=64
05/29/2022 20:49:09 - INFO - __main__ - Step 920 Global step 920 Train loss 2.69 on epoch=65
05/29/2022 20:49:10 - INFO - __main__ - Step 930 Global step 930 Train loss 2.95 on epoch=66
05/29/2022 20:49:11 - INFO - __main__ - Step 940 Global step 940 Train loss 2.93 on epoch=67
05/29/2022 20:49:13 - INFO - __main__ - Step 950 Global step 950 Train loss 2.89 on epoch=67
05/29/2022 20:49:16 - INFO - __main__ - Global step 950 Train loss 2.86 Classification-F1 0.05508180344245918 on epoch=67
05/29/2022 20:49:16 - INFO - __main__ - Saving model with best Classification-F1: 0.028485757121439276 -> 0.05508180344245918 on epoch=67, global_step=950
05/29/2022 20:49:17 - INFO - __main__ - Step 960 Global step 960 Train loss 2.80 on epoch=68
05/29/2022 20:49:18 - INFO - __main__ - Step 970 Global step 970 Train loss 2.79 on epoch=69
05/29/2022 20:49:20 - INFO - __main__ - Step 980 Global step 980 Train loss 2.92 on epoch=69
05/29/2022 20:49:21 - INFO - __main__ - Step 990 Global step 990 Train loss 2.81 on epoch=70
05/29/2022 20:49:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.73 on epoch=71
05/29/2022 20:49:25 - INFO - __main__ - Global step 1000 Train loss 2.81 Classification-F1 0.07907107670654469 on epoch=71
05/29/2022 20:49:25 - INFO - __main__ - Saving model with best Classification-F1: 0.05508180344245918 -> 0.07907107670654469 on epoch=71, global_step=1000
05/29/2022 20:49:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.75 on epoch=72
05/29/2022 20:49:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.88 on epoch=72
05/29/2022 20:49:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.65 on epoch=73
05/29/2022 20:49:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.72 on epoch=74
05/29/2022 20:49:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.59 on epoch=74
05/29/2022 20:49:34 - INFO - __main__ - Global step 1050 Train loss 2.72 Classification-F1 0.046860500803379605 on epoch=74
05/29/2022 20:49:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.58 on epoch=75
05/29/2022 20:49:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.53 on epoch=76
05/29/2022 20:49:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.68 on epoch=77
05/29/2022 20:49:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.51 on epoch=77
05/29/2022 20:49:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.49 on epoch=78
05/29/2022 20:49:43 - INFO - __main__ - Global step 1100 Train loss 2.56 Classification-F1 0.048964630897404 on epoch=78
05/29/2022 20:49:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.55 on epoch=79
05/29/2022 20:49:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.61 on epoch=79
05/29/2022 20:49:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.54 on epoch=80
05/29/2022 20:49:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.54 on epoch=81
05/29/2022 20:49:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.49 on epoch=82
05/29/2022 20:49:51 - INFO - __main__ - Global step 1150 Train loss 2.55 Classification-F1 0.04747840147294873 on epoch=82
05/29/2022 20:49:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.63 on epoch=82
05/29/2022 20:49:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.50 on epoch=83
05/29/2022 20:49:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.60 on epoch=84
05/29/2022 20:49:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.60 on epoch=84
05/29/2022 20:49:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.45 on epoch=85
05/29/2022 20:50:01 - INFO - __main__ - Global step 1200 Train loss 2.56 Classification-F1 0.07546270653121834 on epoch=85
05/29/2022 20:50:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.32 on epoch=86
05/29/2022 20:50:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.45 on epoch=87
05/29/2022 20:50:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.37 on epoch=87
05/29/2022 20:50:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.36 on epoch=88
05/29/2022 20:50:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.23 on epoch=89
05/29/2022 20:50:10 - INFO - __main__ - Global step 1250 Train loss 2.35 Classification-F1 0.059761348708217775 on epoch=89
05/29/2022 20:50:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.39 on epoch=89
05/29/2022 20:50:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.28 on epoch=90
05/29/2022 20:50:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.23 on epoch=91
05/29/2022 20:50:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.31 on epoch=92
05/29/2022 20:50:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.19 on epoch=92
05/29/2022 20:50:19 - INFO - __main__ - Global step 1300 Train loss 2.28 Classification-F1 0.055208935643718246 on epoch=92
05/29/2022 20:50:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.28 on epoch=93
05/29/2022 20:50:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.27 on epoch=94
05/29/2022 20:50:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.37 on epoch=94
05/29/2022 20:50:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.36 on epoch=95
05/29/2022 20:50:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.31 on epoch=96
05/29/2022 20:50:27 - INFO - __main__ - Global step 1350 Train loss 2.32 Classification-F1 0.0776048367620732 on epoch=96
05/29/2022 20:50:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.41 on epoch=97
05/29/2022 20:50:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.24 on epoch=97
05/29/2022 20:50:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.20 on epoch=98
05/29/2022 20:50:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.13 on epoch=99
05/29/2022 20:50:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.09 on epoch=99
05/29/2022 20:50:36 - INFO - __main__ - Global step 1400 Train loss 2.21 Classification-F1 0.07363172150112762 on epoch=99
05/29/2022 20:50:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.12 on epoch=100
05/29/2022 20:50:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.27 on epoch=101
05/29/2022 20:50:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.30 on epoch=102
05/29/2022 20:50:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.27 on epoch=102
05/29/2022 20:50:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.20 on epoch=103
05/29/2022 20:50:45 - INFO - __main__ - Global step 1450 Train loss 2.23 Classification-F1 0.07114280934156711 on epoch=103
05/29/2022 20:50:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.99 on epoch=104
05/29/2022 20:50:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.38 on epoch=104
05/29/2022 20:50:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.18 on epoch=105
05/29/2022 20:50:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.25 on epoch=106
05/29/2022 20:50:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.11 on epoch=107
05/29/2022 20:50:53 - INFO - __main__ - Global step 1500 Train loss 2.18 Classification-F1 0.08958019633051473 on epoch=107
05/29/2022 20:50:53 - INFO - __main__ - Saving model with best Classification-F1: 0.07907107670654469 -> 0.08958019633051473 on epoch=107, global_step=1500
05/29/2022 20:50:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.19 on epoch=107
05/29/2022 20:50:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.05 on epoch=108
05/29/2022 20:50:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.97 on epoch=109
05/29/2022 20:50:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.14 on epoch=109
05/29/2022 20:51:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.06 on epoch=110
05/29/2022 20:51:02 - INFO - __main__ - Global step 1550 Train loss 2.08 Classification-F1 0.1096157581140896 on epoch=110
05/29/2022 20:51:02 - INFO - __main__ - Saving model with best Classification-F1: 0.08958019633051473 -> 0.1096157581140896 on epoch=110, global_step=1550
05/29/2022 20:51:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.93 on epoch=111
05/29/2022 20:51:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.05 on epoch=112
05/29/2022 20:51:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.07 on epoch=112
05/29/2022 20:51:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.05 on epoch=113
05/29/2022 20:51:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.00 on epoch=114
05/29/2022 20:51:12 - INFO - __main__ - Global step 1600 Train loss 2.02 Classification-F1 0.11571149159003588 on epoch=114
05/29/2022 20:51:12 - INFO - __main__ - Saving model with best Classification-F1: 0.1096157581140896 -> 0.11571149159003588 on epoch=114, global_step=1600
05/29/2022 20:51:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.16 on epoch=114
05/29/2022 20:51:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.89 on epoch=115
05/29/2022 20:51:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.08 on epoch=116
05/29/2022 20:51:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.09 on epoch=117
05/29/2022 20:51:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.25 on epoch=117
05/29/2022 20:51:21 - INFO - __main__ - Global step 1650 Train loss 2.10 Classification-F1 0.13002759632281005 on epoch=117
05/29/2022 20:51:21 - INFO - __main__ - Saving model with best Classification-F1: 0.11571149159003588 -> 0.13002759632281005 on epoch=117, global_step=1650
05/29/2022 20:51:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.83 on epoch=118
05/29/2022 20:51:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.87 on epoch=119
05/29/2022 20:51:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.07 on epoch=119
05/29/2022 20:51:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.00 on epoch=120
05/29/2022 20:51:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.03 on epoch=121
05/29/2022 20:51:29 - INFO - __main__ - Global step 1700 Train loss 1.96 Classification-F1 0.11659487521556487 on epoch=121
05/29/2022 20:51:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.99 on epoch=122
05/29/2022 20:51:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.97 on epoch=122
05/29/2022 20:51:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.09 on epoch=123
05/29/2022 20:51:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.96 on epoch=124
05/29/2022 20:51:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.12 on epoch=124
05/29/2022 20:51:38 - INFO - __main__ - Global step 1750 Train loss 2.03 Classification-F1 0.05395443823380785 on epoch=124
05/29/2022 20:51:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.93 on epoch=125
05/29/2022 20:51:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.01 on epoch=126
05/29/2022 20:51:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.24 on epoch=127
05/29/2022 20:51:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.27 on epoch=127
05/29/2022 20:51:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.21 on epoch=128
05/29/2022 20:51:46 - INFO - __main__ - Global step 1800 Train loss 2.13 Classification-F1 0.09902841519382874 on epoch=128
05/29/2022 20:51:48 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.03 on epoch=129
05/29/2022 20:51:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.03 on epoch=129
05/29/2022 20:51:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.90 on epoch=130
05/29/2022 20:51:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.97 on epoch=131
05/29/2022 20:51:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.11 on epoch=132
05/29/2022 20:51:55 - INFO - __main__ - Global step 1850 Train loss 2.01 Classification-F1 0.01821329390125149 on epoch=132
05/29/2022 20:51:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.92 on epoch=132
05/29/2022 20:51:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.80 on epoch=133
05/29/2022 20:51:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.98 on epoch=134
05/29/2022 20:52:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.90 on epoch=134
05/29/2022 20:52:01 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.87 on epoch=135
05/29/2022 20:52:04 - INFO - __main__ - Global step 1900 Train loss 1.89 Classification-F1 0.038769757374408534 on epoch=135
05/29/2022 20:52:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.00 on epoch=136
05/29/2022 20:52:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.91 on epoch=137
05/29/2022 20:52:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.98 on epoch=137
05/29/2022 20:52:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.96 on epoch=138
05/29/2022 20:52:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.88 on epoch=139
05/29/2022 20:52:12 - INFO - __main__ - Global step 1950 Train loss 1.95 Classification-F1 0.009726443768996961 on epoch=139
05/29/2022 20:52:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.29 on epoch=139
05/29/2022 20:52:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.97 on epoch=140
05/29/2022 20:52:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.97 on epoch=141
05/29/2022 20:52:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.95 on epoch=142
05/29/2022 20:52:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.97 on epoch=142
05/29/2022 20:52:21 - INFO - __main__ - Global step 2000 Train loss 2.03 Classification-F1 0.06975881261595547 on epoch=142
05/29/2022 20:52:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.00 on epoch=143
05/29/2022 20:52:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.79 on epoch=144
05/29/2022 20:52:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.94 on epoch=144
05/29/2022 20:52:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.72 on epoch=145
05/29/2022 20:52:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.90 on epoch=146
05/29/2022 20:52:31 - INFO - __main__ - Global step 2050 Train loss 1.87 Classification-F1 0.08109941452585301 on epoch=146
05/29/2022 20:52:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.89 on epoch=147
05/29/2022 20:52:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.82 on epoch=147
05/29/2022 20:52:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.79 on epoch=148
05/29/2022 20:52:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.73 on epoch=149
05/29/2022 20:52:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.87 on epoch=149
05/29/2022 20:52:40 - INFO - __main__ - Global step 2100 Train loss 1.82 Classification-F1 0.15528383316919533 on epoch=149
05/29/2022 20:52:40 - INFO - __main__ - Saving model with best Classification-F1: 0.13002759632281005 -> 0.15528383316919533 on epoch=149, global_step=2100
05/29/2022 20:52:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.69 on epoch=150
05/29/2022 20:52:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.89 on epoch=151
05/29/2022 20:52:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.75 on epoch=152
05/29/2022 20:52:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.74 on epoch=152
05/29/2022 20:52:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.99 on epoch=153
05/29/2022 20:52:49 - INFO - __main__ - Global step 2150 Train loss 1.81 Classification-F1 0.0957826363875423 on epoch=153
05/29/2022 20:52:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.73 on epoch=154
05/29/2022 20:52:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.33 on epoch=154
05/29/2022 20:52:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.00 on epoch=155
05/29/2022 20:52:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.03 on epoch=156
05/29/2022 20:52:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.14 on epoch=157
05/29/2022 20:52:57 - INFO - __main__ - Global step 2200 Train loss 2.05 Classification-F1 0.11688786827495667 on epoch=157
05/29/2022 20:52:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.09 on epoch=157
05/29/2022 20:53:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.95 on epoch=158
05/29/2022 20:53:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.92 on epoch=159
05/29/2022 20:53:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.98 on epoch=159
05/29/2022 20:53:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.88 on epoch=160
05/29/2022 20:53:07 - INFO - __main__ - Global step 2250 Train loss 1.97 Classification-F1 0.03043525102348632 on epoch=160
05/29/2022 20:53:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.07 on epoch=161
05/29/2022 20:53:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.91 on epoch=162
05/29/2022 20:53:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.87 on epoch=162
05/29/2022 20:53:12 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.75 on epoch=163
05/29/2022 20:53:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.83 on epoch=164
05/29/2022 20:53:15 - INFO - __main__ - Global step 2300 Train loss 1.88 Classification-F1 0.11716569533771395 on epoch=164
05/29/2022 20:53:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.83 on epoch=164
05/29/2022 20:53:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.61 on epoch=165
05/29/2022 20:53:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.75 on epoch=166
05/29/2022 20:53:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.82 on epoch=167
05/29/2022 20:53:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.61 on epoch=167
05/29/2022 20:53:24 - INFO - __main__ - Global step 2350 Train loss 1.72 Classification-F1 0.13881679049917098 on epoch=167
05/29/2022 20:53:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.70 on epoch=168
05/29/2022 20:53:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.68 on epoch=169
05/29/2022 20:53:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.73 on epoch=169
05/29/2022 20:53:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.62 on epoch=170
05/29/2022 20:53:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.72 on epoch=171
05/29/2022 20:53:33 - INFO - __main__ - Global step 2400 Train loss 1.69 Classification-F1 0.0956001046933549 on epoch=171
05/29/2022 20:53:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.69 on epoch=172
05/29/2022 20:53:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.67 on epoch=172
05/29/2022 20:53:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.66 on epoch=173
05/29/2022 20:53:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.54 on epoch=174
05/29/2022 20:53:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.74 on epoch=174
05/29/2022 20:53:42 - INFO - __main__ - Global step 2450 Train loss 1.66 Classification-F1 0.04853688056375626 on epoch=174
05/29/2022 20:53:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.68 on epoch=175
05/29/2022 20:53:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.72 on epoch=176
05/29/2022 20:53:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.79 on epoch=177
05/29/2022 20:53:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.79 on epoch=177
05/29/2022 20:53:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.76 on epoch=178
05/29/2022 20:53:52 - INFO - __main__ - Global step 2500 Train loss 1.75 Classification-F1 0.09196071249210445 on epoch=178
05/29/2022 20:53:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.69 on epoch=179
05/29/2022 20:53:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.72 on epoch=179
05/29/2022 20:53:55 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.63 on epoch=180
05/29/2022 20:53:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.70 on epoch=181
05/29/2022 20:53:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.56 on epoch=182
05/29/2022 20:54:00 - INFO - __main__ - Global step 2550 Train loss 1.66 Classification-F1 0.16868017576963074 on epoch=182
05/29/2022 20:54:00 - INFO - __main__ - Saving model with best Classification-F1: 0.15528383316919533 -> 0.16868017576963074 on epoch=182, global_step=2550
05/29/2022 20:54:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.62 on epoch=182
05/29/2022 20:54:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.62 on epoch=183
05/29/2022 20:54:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.52 on epoch=184
05/29/2022 20:54:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.64 on epoch=184
05/29/2022 20:54:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.59 on epoch=185
05/29/2022 20:54:09 - INFO - __main__ - Global step 2600 Train loss 1.60 Classification-F1 0.10489123348990428 on epoch=185
05/29/2022 20:54:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.75 on epoch=186
05/29/2022 20:54:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.64 on epoch=187
05/29/2022 20:54:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.56 on epoch=187
05/29/2022 20:54:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.57 on epoch=188
05/29/2022 20:54:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.51 on epoch=189
05/29/2022 20:54:18 - INFO - __main__ - Global step 2650 Train loss 1.60 Classification-F1 0.07845594378102116 on epoch=189
05/29/2022 20:54:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.70 on epoch=189
05/29/2022 20:54:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.58 on epoch=190
05/29/2022 20:54:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.57 on epoch=191
05/29/2022 20:54:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.59 on epoch=192
05/29/2022 20:54:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.47 on epoch=192
05/29/2022 20:54:26 - INFO - __main__ - Global step 2700 Train loss 1.58 Classification-F1 0.08701359744838008 on epoch=192
05/29/2022 20:54:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.58 on epoch=193
05/29/2022 20:54:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.67 on epoch=194
05/29/2022 20:54:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.85 on epoch=194
05/29/2022 20:54:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.55 on epoch=195
05/29/2022 20:54:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.58 on epoch=196
05/29/2022 20:54:35 - INFO - __main__ - Global step 2750 Train loss 1.64 Classification-F1 0.11014064944101198 on epoch=196
05/29/2022 20:54:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.66 on epoch=197
05/29/2022 20:54:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.61 on epoch=197
05/29/2022 20:54:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.58 on epoch=198
05/29/2022 20:54:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.63 on epoch=199
05/29/2022 20:54:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.59 on epoch=199
05/29/2022 20:54:44 - INFO - __main__ - Global step 2800 Train loss 1.61 Classification-F1 0.1179954810206911 on epoch=199
05/29/2022 20:54:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.51 on epoch=200
05/29/2022 20:54:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.65 on epoch=201
05/29/2022 20:54:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.58 on epoch=202
05/29/2022 20:54:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.50 on epoch=202
05/29/2022 20:54:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.66 on epoch=203
05/29/2022 20:54:53 - INFO - __main__ - Global step 2850 Train loss 1.58 Classification-F1 0.08898313871002947 on epoch=203
05/29/2022 20:54:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.53 on epoch=204
05/29/2022 20:54:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.56 on epoch=204
05/29/2022 20:54:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.47 on epoch=205
05/29/2022 20:54:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.53 on epoch=206
05/29/2022 20:54:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.49 on epoch=207
05/29/2022 20:55:01 - INFO - __main__ - Global step 2900 Train loss 1.51 Classification-F1 0.08250942605781315 on epoch=207
05/29/2022 20:55:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.54 on epoch=207
05/29/2022 20:55:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.66 on epoch=208
05/29/2022 20:55:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.47 on epoch=209
05/29/2022 20:55:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.68 on epoch=209
05/29/2022 20:55:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.48 on epoch=210
05/29/2022 20:55:10 - INFO - __main__ - Global step 2950 Train loss 1.56 Classification-F1 0.05943655657751823 on epoch=210
05/29/2022 20:55:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.59 on epoch=211
05/29/2022 20:55:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.48 on epoch=212
05/29/2022 20:55:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.63 on epoch=212
05/29/2022 20:55:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.57 on epoch=213
05/29/2022 20:55:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.68 on epoch=214
05/29/2022 20:55:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:55:17 - INFO - __main__ - Printing 3 examples
05/29/2022 20:55:17 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 20:55:17 - INFO - __main__ - ['Company']
05/29/2022 20:55:17 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 20:55:17 - INFO - __main__ - ['Company']
05/29/2022 20:55:17 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 20:55:17 - INFO - __main__ - ['Company']
05/29/2022 20:55:17 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:55:17 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:55:18 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:55:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:55:18 - INFO - __main__ - Printing 3 examples
05/29/2022 20:55:18 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 20:55:18 - INFO - __main__ - ['Company']
05/29/2022 20:55:18 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 20:55:18 - INFO - __main__ - ['Company']
05/29/2022 20:55:18 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 20:55:18 - INFO - __main__ - ['Company']
05/29/2022 20:55:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:55:18 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:55:18 - INFO - __main__ - Global step 3000 Train loss 1.59 Classification-F1 0.10468724074995853 on epoch=214
05/29/2022 20:55:18 - INFO - __main__ - save last model!
05/29/2022 20:55:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 20:55:18 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 20:55:18 - INFO - __main__ - Printing 3 examples
05/29/2022 20:55:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 20:55:18 - INFO - __main__ - ['Animal']
05/29/2022 20:55:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 20:55:18 - INFO - __main__ - ['Animal']
05/29/2022 20:55:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 20:55:18 - INFO - __main__ - ['Village']
05/29/2022 20:55:18 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:55:18 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:55:20 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:55:23 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 20:55:24 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:55:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:55:24 - INFO - __main__ - Starting training!
05/29/2022 20:55:55 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/29/2022 20:55:55 - INFO - __main__ - Classification-F1 on test data: 0.0784
05/29/2022 20:55:55 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.16868017576963074, test_performance=0.07841842630528417
05/29/2022 20:55:55 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/29/2022 20:55:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:55:56 - INFO - __main__ - Printing 3 examples
05/29/2022 20:55:56 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 20:55:56 - INFO - __main__ - ['Company']
05/29/2022 20:55:56 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 20:55:56 - INFO - __main__ - ['Company']
05/29/2022 20:55:56 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 20:55:56 - INFO - __main__ - ['Company']
05/29/2022 20:55:56 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:55:56 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:55:56 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 20:55:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 20:55:56 - INFO - __main__ - Printing 3 examples
05/29/2022 20:55:56 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 20:55:56 - INFO - __main__ - ['Company']
05/29/2022 20:55:56 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 20:55:56 - INFO - __main__ - ['Company']
05/29/2022 20:55:56 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 20:55:56 - INFO - __main__ - ['Company']
05/29/2022 20:55:56 - INFO - __main__ - Tokenizing Input ...
05/29/2022 20:55:57 - INFO - __main__ - Tokenizing Output ...
05/29/2022 20:55:57 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 20:56:03 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 20:56:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 20:56:03 - INFO - __main__ - Starting training!
05/29/2022 20:56:05 - INFO - __main__ - Step 10 Global step 10 Train loss 7.29 on epoch=0
05/29/2022 20:56:06 - INFO - __main__ - Step 20 Global step 20 Train loss 7.64 on epoch=1
05/29/2022 20:56:07 - INFO - __main__ - Step 30 Global step 30 Train loss 7.35 on epoch=2
05/29/2022 20:56:09 - INFO - __main__ - Step 40 Global step 40 Train loss 6.90 on epoch=2
05/29/2022 20:56:10 - INFO - __main__ - Step 50 Global step 50 Train loss 7.15 on epoch=3
05/29/2022 20:56:19 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/29/2022 20:56:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 20:56:20 - INFO - __main__ - Step 60 Global step 60 Train loss 6.90 on epoch=4
05/29/2022 20:56:22 - INFO - __main__ - Step 70 Global step 70 Train loss 7.04 on epoch=4
05/29/2022 20:56:23 - INFO - __main__ - Step 80 Global step 80 Train loss 6.57 on epoch=5
05/29/2022 20:56:24 - INFO - __main__ - Step 90 Global step 90 Train loss 6.85 on epoch=6
05/29/2022 20:56:25 - INFO - __main__ - Step 100 Global step 100 Train loss 6.84 on epoch=7
05/29/2022 20:57:21 - INFO - __main__ - Global step 100 Train loss 6.84 Classification-F1 0.0 on epoch=7
05/29/2022 20:57:23 - INFO - __main__ - Step 110 Global step 110 Train loss 6.28 on epoch=7
05/29/2022 20:57:24 - INFO - __main__ - Step 120 Global step 120 Train loss 6.59 on epoch=8
05/29/2022 20:57:25 - INFO - __main__ - Step 130 Global step 130 Train loss 6.31 on epoch=9
05/29/2022 20:57:26 - INFO - __main__ - Step 140 Global step 140 Train loss 6.49 on epoch=9
05/29/2022 20:57:27 - INFO - __main__ - Step 150 Global step 150 Train loss 6.06 on epoch=10
05/29/2022 20:58:38 - INFO - __main__ - Global step 150 Train loss 6.35 Classification-F1 0.0 on epoch=10
05/29/2022 20:58:39 - INFO - __main__ - Step 160 Global step 160 Train loss 6.45 on epoch=11
05/29/2022 20:58:40 - INFO - __main__ - Step 170 Global step 170 Train loss 6.22 on epoch=12
05/29/2022 20:58:42 - INFO - __main__ - Step 180 Global step 180 Train loss 5.85 on epoch=12
05/29/2022 20:58:43 - INFO - __main__ - Step 190 Global step 190 Train loss 6.10 on epoch=13
05/29/2022 20:58:44 - INFO - __main__ - Step 200 Global step 200 Train loss 5.99 on epoch=14
05/29/2022 20:59:25 - INFO - __main__ - Global step 200 Train loss 6.12 Classification-F1 0.0 on epoch=14
05/29/2022 20:59:26 - INFO - __main__ - Step 210 Global step 210 Train loss 6.13 on epoch=14
05/29/2022 20:59:28 - INFO - __main__ - Step 220 Global step 220 Train loss 5.73 on epoch=15
05/29/2022 20:59:29 - INFO - __main__ - Step 230 Global step 230 Train loss 6.13 on epoch=16
05/29/2022 20:59:30 - INFO - __main__ - Step 240 Global step 240 Train loss 6.02 on epoch=17
05/29/2022 20:59:32 - INFO - __main__ - Step 250 Global step 250 Train loss 5.66 on epoch=17
05/29/2022 21:00:33 - INFO - __main__ - Global step 250 Train loss 5.93 Classification-F1 0.0 on epoch=17
05/29/2022 21:00:35 - INFO - __main__ - Step 260 Global step 260 Train loss 5.88 on epoch=18
05/29/2022 21:00:36 - INFO - __main__ - Step 270 Global step 270 Train loss 5.65 on epoch=19
05/29/2022 21:00:37 - INFO - __main__ - Step 280 Global step 280 Train loss 5.84 on epoch=19
05/29/2022 21:00:39 - INFO - __main__ - Step 290 Global step 290 Train loss 5.53 on epoch=20
05/29/2022 21:00:40 - INFO - __main__ - Step 300 Global step 300 Train loss 5.82 on epoch=21
05/29/2022 21:01:05 - INFO - __main__ - Global step 300 Train loss 5.74 Classification-F1 0.0 on epoch=21
05/29/2022 21:01:06 - INFO - __main__ - Step 310 Global step 310 Train loss 5.72 on epoch=22
05/29/2022 21:01:07 - INFO - __main__ - Step 320 Global step 320 Train loss 5.49 on epoch=22
05/29/2022 21:01:09 - INFO - __main__ - Step 330 Global step 330 Train loss 5.70 on epoch=23
05/29/2022 21:01:10 - INFO - __main__ - Step 340 Global step 340 Train loss 5.55 on epoch=24
05/29/2022 21:01:11 - INFO - __main__ - Step 350 Global step 350 Train loss 5.62 on epoch=24
05/29/2022 21:01:25 - INFO - __main__ - Global step 350 Train loss 5.62 Classification-F1 0.0 on epoch=24
05/29/2022 21:01:27 - INFO - __main__ - Step 360 Global step 360 Train loss 5.40 on epoch=25
05/29/2022 21:01:28 - INFO - __main__ - Step 370 Global step 370 Train loss 5.43 on epoch=26
05/29/2022 21:01:29 - INFO - __main__ - Step 380 Global step 380 Train loss 5.48 on epoch=27
05/29/2022 21:01:30 - INFO - __main__ - Step 390 Global step 390 Train loss 5.19 on epoch=27
05/29/2022 21:01:32 - INFO - __main__ - Step 400 Global step 400 Train loss 5.44 on epoch=28
05/29/2022 21:01:36 - INFO - __main__ - Global step 400 Train loss 5.39 Classification-F1 0.0 on epoch=28
05/29/2022 21:01:37 - INFO - __main__ - Step 410 Global step 410 Train loss 5.10 on epoch=29
05/29/2022 21:01:38 - INFO - __main__ - Step 420 Global step 420 Train loss 5.43 on epoch=29
05/29/2022 21:01:40 - INFO - __main__ - Step 430 Global step 430 Train loss 5.11 on epoch=30
05/29/2022 21:01:41 - INFO - __main__ - Step 440 Global step 440 Train loss 5.28 on epoch=31
05/29/2022 21:01:42 - INFO - __main__ - Step 450 Global step 450 Train loss 5.17 on epoch=32
05/29/2022 21:01:45 - INFO - __main__ - Global step 450 Train loss 5.22 Classification-F1 0.005050505050505051 on epoch=32
05/29/2022 21:01:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005050505050505051 on epoch=32, global_step=450
05/29/2022 21:01:47 - INFO - __main__ - Step 460 Global step 460 Train loss 4.97 on epoch=32
05/29/2022 21:01:48 - INFO - __main__ - Step 470 Global step 470 Train loss 5.10 on epoch=33
05/29/2022 21:01:49 - INFO - __main__ - Step 480 Global step 480 Train loss 4.99 on epoch=34
05/29/2022 21:01:50 - INFO - __main__ - Step 490 Global step 490 Train loss 5.29 on epoch=34
05/29/2022 21:01:52 - INFO - __main__ - Step 500 Global step 500 Train loss 4.97 on epoch=35
05/29/2022 21:01:55 - INFO - __main__ - Global step 500 Train loss 5.06 Classification-F1 0.006521739130434782 on epoch=35
05/29/2022 21:01:55 - INFO - __main__ - Saving model with best Classification-F1: 0.005050505050505051 -> 0.006521739130434782 on epoch=35, global_step=500
05/29/2022 21:01:56 - INFO - __main__ - Step 510 Global step 510 Train loss 5.05 on epoch=36
05/29/2022 21:01:57 - INFO - __main__ - Step 520 Global step 520 Train loss 4.94 on epoch=37
05/29/2022 21:01:59 - INFO - __main__ - Step 530 Global step 530 Train loss 4.81 on epoch=37
05/29/2022 21:02:00 - INFO - __main__ - Step 540 Global step 540 Train loss 4.90 on epoch=38
05/29/2022 21:02:01 - INFO - __main__ - Step 550 Global step 550 Train loss 4.74 on epoch=39
05/29/2022 21:02:09 - INFO - __main__ - Global step 550 Train loss 4.89 Classification-F1 0.007183908045977012 on epoch=39
05/29/2022 21:02:09 - INFO - __main__ - Saving model with best Classification-F1: 0.006521739130434782 -> 0.007183908045977012 on epoch=39, global_step=550
05/29/2022 21:02:10 - INFO - __main__ - Step 560 Global step 560 Train loss 4.94 on epoch=39
05/29/2022 21:02:12 - INFO - __main__ - Step 570 Global step 570 Train loss 4.66 on epoch=40
05/29/2022 21:02:13 - INFO - __main__ - Step 580 Global step 580 Train loss 4.77 on epoch=41
05/29/2022 21:02:14 - INFO - __main__ - Step 590 Global step 590 Train loss 4.76 on epoch=42
05/29/2022 21:02:16 - INFO - __main__ - Step 600 Global step 600 Train loss 4.66 on epoch=42
05/29/2022 21:02:33 - INFO - __main__ - Global step 600 Train loss 4.76 Classification-F1 0.006410256410256411 on epoch=42
05/29/2022 21:02:34 - INFO - __main__ - Step 610 Global step 610 Train loss 4.65 on epoch=43
05/29/2022 21:02:36 - INFO - __main__ - Step 620 Global step 620 Train loss 4.39 on epoch=44
05/29/2022 21:02:37 - INFO - __main__ - Step 630 Global step 630 Train loss 4.76 on epoch=44
05/29/2022 21:02:38 - INFO - __main__ - Step 640 Global step 640 Train loss 4.42 on epoch=45
05/29/2022 21:02:39 - INFO - __main__ - Step 650 Global step 650 Train loss 5.00 on epoch=46
05/29/2022 21:02:52 - INFO - __main__ - Global step 650 Train loss 4.64 Classification-F1 0.00892608089260809 on epoch=46
05/29/2022 21:02:52 - INFO - __main__ - Saving model with best Classification-F1: 0.007183908045977012 -> 0.00892608089260809 on epoch=46, global_step=650
05/29/2022 21:02:53 - INFO - __main__ - Step 660 Global step 660 Train loss 4.49 on epoch=47
05/29/2022 21:02:54 - INFO - __main__ - Step 670 Global step 670 Train loss 4.38 on epoch=47
05/29/2022 21:02:56 - INFO - __main__ - Step 680 Global step 680 Train loss 4.43 on epoch=48
05/29/2022 21:02:57 - INFO - __main__ - Step 690 Global step 690 Train loss 4.30 on epoch=49
05/29/2022 21:02:58 - INFO - __main__ - Step 700 Global step 700 Train loss 4.70 on epoch=49
05/29/2022 21:03:00 - INFO - __main__ - Global step 700 Train loss 4.46 Classification-F1 0.009523809523809523 on epoch=49
05/29/2022 21:03:00 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=49, global_step=700
05/29/2022 21:03:02 - INFO - __main__ - Step 710 Global step 710 Train loss 4.27 on epoch=50
05/29/2022 21:03:03 - INFO - __main__ - Step 720 Global step 720 Train loss 4.39 on epoch=51
05/29/2022 21:03:04 - INFO - __main__ - Step 730 Global step 730 Train loss 4.46 on epoch=52
05/29/2022 21:03:06 - INFO - __main__ - Step 740 Global step 740 Train loss 4.26 on epoch=52
05/29/2022 21:03:07 - INFO - __main__ - Step 750 Global step 750 Train loss 4.29 on epoch=53
05/29/2022 21:03:09 - INFO - __main__ - Global step 750 Train loss 4.33 Classification-F1 0.01680672268907563 on epoch=53
05/29/2022 21:03:09 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01680672268907563 on epoch=53, global_step=750
05/29/2022 21:03:10 - INFO - __main__ - Step 760 Global step 760 Train loss 4.14 on epoch=54
05/29/2022 21:03:11 - INFO - __main__ - Step 770 Global step 770 Train loss 4.43 on epoch=54
05/29/2022 21:03:13 - INFO - __main__ - Step 780 Global step 780 Train loss 4.10 on epoch=55
05/29/2022 21:03:14 - INFO - __main__ - Step 790 Global step 790 Train loss 4.21 on epoch=56
05/29/2022 21:03:15 - INFO - __main__ - Step 800 Global step 800 Train loss 4.15 on epoch=57
05/29/2022 21:03:17 - INFO - __main__ - Global step 800 Train loss 4.21 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 21:03:18 - INFO - __main__ - Step 810 Global step 810 Train loss 4.08 on epoch=57
05/29/2022 21:03:20 - INFO - __main__ - Step 820 Global step 820 Train loss 4.19 on epoch=58
05/29/2022 21:03:21 - INFO - __main__ - Step 830 Global step 830 Train loss 4.15 on epoch=59
05/29/2022 21:03:22 - INFO - __main__ - Step 840 Global step 840 Train loss 4.08 on epoch=59
05/29/2022 21:03:24 - INFO - __main__ - Step 850 Global step 850 Train loss 4.00 on epoch=60
05/29/2022 21:03:26 - INFO - __main__ - Global step 850 Train loss 4.10 Classification-F1 0.02902852369017783 on epoch=60
05/29/2022 21:03:26 - INFO - __main__ - Saving model with best Classification-F1: 0.01680672268907563 -> 0.02902852369017783 on epoch=60, global_step=850
05/29/2022 21:03:27 - INFO - __main__ - Step 860 Global step 860 Train loss 4.07 on epoch=61
05/29/2022 21:03:28 - INFO - __main__ - Step 870 Global step 870 Train loss 3.97 on epoch=62
05/29/2022 21:03:29 - INFO - __main__ - Step 880 Global step 880 Train loss 4.09 on epoch=62
05/29/2022 21:03:31 - INFO - __main__ - Step 890 Global step 890 Train loss 4.04 on epoch=63
05/29/2022 21:03:32 - INFO - __main__ - Step 900 Global step 900 Train loss 4.01 on epoch=64
05/29/2022 21:03:34 - INFO - __main__ - Global step 900 Train loss 4.04 Classification-F1 0.01259538567150518 on epoch=64
05/29/2022 21:03:35 - INFO - __main__ - Step 910 Global step 910 Train loss 4.20 on epoch=64
05/29/2022 21:03:37 - INFO - __main__ - Step 920 Global step 920 Train loss 3.89 on epoch=65
05/29/2022 21:03:38 - INFO - __main__ - Step 930 Global step 930 Train loss 3.97 on epoch=66
05/29/2022 21:03:39 - INFO - __main__ - Step 940 Global step 940 Train loss 3.97 on epoch=67
05/29/2022 21:03:40 - INFO - __main__ - Step 950 Global step 950 Train loss 3.96 on epoch=67
05/29/2022 21:03:42 - INFO - __main__ - Global step 950 Train loss 4.00 Classification-F1 0.033948273948273947 on epoch=67
05/29/2022 21:03:42 - INFO - __main__ - Saving model with best Classification-F1: 0.02902852369017783 -> 0.033948273948273947 on epoch=67, global_step=950
05/29/2022 21:03:44 - INFO - __main__ - Step 960 Global step 960 Train loss 3.84 on epoch=68
05/29/2022 21:03:45 - INFO - __main__ - Step 970 Global step 970 Train loss 3.81 on epoch=69
05/29/2022 21:03:46 - INFO - __main__ - Step 980 Global step 980 Train loss 3.94 on epoch=69
05/29/2022 21:03:48 - INFO - __main__ - Step 990 Global step 990 Train loss 3.81 on epoch=70
05/29/2022 21:03:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.85 on epoch=71
05/29/2022 21:03:51 - INFO - __main__ - Global step 1000 Train loss 3.85 Classification-F1 0.027836117288370394 on epoch=71
05/29/2022 21:03:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.72 on epoch=72
05/29/2022 21:03:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.82 on epoch=72
05/29/2022 21:03:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.60 on epoch=73
05/29/2022 21:03:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.77 on epoch=74
05/29/2022 21:03:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.87 on epoch=74
05/29/2022 21:03:59 - INFO - __main__ - Global step 1050 Train loss 3.76 Classification-F1 0.03267599946156953 on epoch=74
05/29/2022 21:04:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.61 on epoch=75
05/29/2022 21:04:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.67 on epoch=76
05/29/2022 21:04:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.64 on epoch=77
05/29/2022 21:04:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.67 on epoch=77
05/29/2022 21:04:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.72 on epoch=78
05/29/2022 21:04:07 - INFO - __main__ - Global step 1100 Train loss 3.66 Classification-F1 0.02391395154553049 on epoch=78
05/29/2022 21:04:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.53 on epoch=79
05/29/2022 21:04:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.62 on epoch=79
05/29/2022 21:04:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.56 on epoch=80
05/29/2022 21:04:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.56 on epoch=81
05/29/2022 21:04:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.45 on epoch=82
05/29/2022 21:04:15 - INFO - __main__ - Global step 1150 Train loss 3.54 Classification-F1 0.030845335542797597 on epoch=82
05/29/2022 21:04:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.62 on epoch=82
05/29/2022 21:04:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.57 on epoch=83
05/29/2022 21:04:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.45 on epoch=84
05/29/2022 21:04:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.60 on epoch=84
05/29/2022 21:04:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.36 on epoch=85
05/29/2022 21:04:24 - INFO - __main__ - Global step 1200 Train loss 3.52 Classification-F1 0.037323322331073126 on epoch=85
05/29/2022 21:04:24 - INFO - __main__ - Saving model with best Classification-F1: 0.033948273948273947 -> 0.037323322331073126 on epoch=85, global_step=1200
05/29/2022 21:04:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.44 on epoch=86
05/29/2022 21:04:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.43 on epoch=87
05/29/2022 21:04:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.59 on epoch=87
05/29/2022 21:04:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.48 on epoch=88
05/29/2022 21:04:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.57 on epoch=89
05/29/2022 21:04:32 - INFO - __main__ - Global step 1250 Train loss 3.50 Classification-F1 0.022622375111545325 on epoch=89
05/29/2022 21:04:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.61 on epoch=89
05/29/2022 21:04:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.49 on epoch=90
05/29/2022 21:04:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.61 on epoch=91
05/29/2022 21:04:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.51 on epoch=92
05/29/2022 21:04:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.48 on epoch=92
05/29/2022 21:04:40 - INFO - __main__ - Global step 1300 Train loss 3.54 Classification-F1 0.012162759840778416 on epoch=92
05/29/2022 21:04:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.53 on epoch=93
05/29/2022 21:04:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.53 on epoch=94
05/29/2022 21:04:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.50 on epoch=94
05/29/2022 21:04:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.39 on epoch=95
05/29/2022 21:04:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.48 on epoch=96
05/29/2022 21:04:49 - INFO - __main__ - Global step 1350 Train loss 3.49 Classification-F1 0.02346962346962347 on epoch=96
05/29/2022 21:04:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.32 on epoch=97
05/29/2022 21:04:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.33 on epoch=97
05/29/2022 21:04:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.40 on epoch=98
05/29/2022 21:04:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.29 on epoch=99
05/29/2022 21:04:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.38 on epoch=99
05/29/2022 21:04:57 - INFO - __main__ - Global step 1400 Train loss 3.34 Classification-F1 0.03506898157814432 on epoch=99
05/29/2022 21:04:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.33 on epoch=100
05/29/2022 21:04:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.25 on epoch=101
05/29/2022 21:05:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.36 on epoch=102
05/29/2022 21:05:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.43 on epoch=102
05/29/2022 21:05:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.34 on epoch=103
05/29/2022 21:05:05 - INFO - __main__ - Global step 1450 Train loss 3.34 Classification-F1 0.04311540536381989 on epoch=103
05/29/2022 21:05:05 - INFO - __main__ - Saving model with best Classification-F1: 0.037323322331073126 -> 0.04311540536381989 on epoch=103, global_step=1450
05/29/2022 21:05:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.30 on epoch=104
05/29/2022 21:05:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.32 on epoch=104
05/29/2022 21:05:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.23 on epoch=105
05/29/2022 21:05:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.34 on epoch=106
05/29/2022 21:05:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.28 on epoch=107
05/29/2022 21:05:13 - INFO - __main__ - Global step 1500 Train loss 3.30 Classification-F1 0.045524454841225026 on epoch=107
05/29/2022 21:05:13 - INFO - __main__ - Saving model with best Classification-F1: 0.04311540536381989 -> 0.045524454841225026 on epoch=107, global_step=1500
05/29/2022 21:05:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.49 on epoch=107
05/29/2022 21:05:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.27 on epoch=108
05/29/2022 21:05:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.18 on epoch=109
05/29/2022 21:05:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.44 on epoch=109
05/29/2022 21:05:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.22 on epoch=110
05/29/2022 21:05:21 - INFO - __main__ - Global step 1550 Train loss 3.32 Classification-F1 0.02108428737348598 on epoch=110
05/29/2022 21:05:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.31 on epoch=111
05/29/2022 21:05:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.29 on epoch=112
05/29/2022 21:05:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.17 on epoch=112
05/29/2022 21:05:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.23 on epoch=113
05/29/2022 21:05:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.34 on epoch=114
05/29/2022 21:05:29 - INFO - __main__ - Global step 1600 Train loss 3.27 Classification-F1 0.04195208393000998 on epoch=114
05/29/2022 21:05:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.41 on epoch=114
05/29/2022 21:05:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.29 on epoch=115
05/29/2022 21:05:33 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.17 on epoch=116
05/29/2022 21:05:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.18 on epoch=117
05/29/2022 21:05:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.22 on epoch=117
05/29/2022 21:05:37 - INFO - __main__ - Global step 1650 Train loss 3.25 Classification-F1 0.04641714468542176 on epoch=117
05/29/2022 21:05:37 - INFO - __main__ - Saving model with best Classification-F1: 0.045524454841225026 -> 0.04641714468542176 on epoch=117, global_step=1650
05/29/2022 21:05:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.32 on epoch=118
05/29/2022 21:05:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.05 on epoch=119
05/29/2022 21:05:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.14 on epoch=119
05/29/2022 21:05:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.12 on epoch=120
05/29/2022 21:05:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.16 on epoch=121
05/29/2022 21:05:46 - INFO - __main__ - Global step 1700 Train loss 3.16 Classification-F1 0.046672016342300705 on epoch=121
05/29/2022 21:05:46 - INFO - __main__ - Saving model with best Classification-F1: 0.04641714468542176 -> 0.046672016342300705 on epoch=121, global_step=1700
05/29/2022 21:05:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.19 on epoch=122
05/29/2022 21:05:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.31 on epoch=122
05/29/2022 21:05:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.03 on epoch=123
05/29/2022 21:05:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.98 on epoch=124
05/29/2022 21:05:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.14 on epoch=124
05/29/2022 21:05:54 - INFO - __main__ - Global step 1750 Train loss 3.13 Classification-F1 0.03506934996676299 on epoch=124
05/29/2022 21:05:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.16 on epoch=125
05/29/2022 21:05:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.99 on epoch=126
05/29/2022 21:05:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.06 on epoch=127
05/29/2022 21:05:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.17 on epoch=127
05/29/2022 21:06:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.89 on epoch=128
05/29/2022 21:06:02 - INFO - __main__ - Global step 1800 Train loss 3.05 Classification-F1 0.027360160365086476 on epoch=128
05/29/2022 21:06:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.07 on epoch=129
05/29/2022 21:06:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.20 on epoch=129
05/29/2022 21:06:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.09 on epoch=130
05/29/2022 21:06:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.11 on epoch=131
05/29/2022 21:06:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.98 on epoch=132
05/29/2022 21:06:10 - INFO - __main__ - Global step 1850 Train loss 3.09 Classification-F1 0.04830607760239014 on epoch=132
05/29/2022 21:06:10 - INFO - __main__ - Saving model with best Classification-F1: 0.046672016342300705 -> 0.04830607760239014 on epoch=132, global_step=1850
05/29/2022 21:06:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.02 on epoch=132
05/29/2022 21:06:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.03 on epoch=133
05/29/2022 21:06:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.13 on epoch=134
05/29/2022 21:06:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.11 on epoch=134
05/29/2022 21:06:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.11 on epoch=135
05/29/2022 21:06:19 - INFO - __main__ - Global step 1900 Train loss 3.08 Classification-F1 0.021404899988164278 on epoch=135
05/29/2022 21:06:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.93 on epoch=136
05/29/2022 21:06:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.97 on epoch=137
05/29/2022 21:06:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.01 on epoch=137
05/29/2022 21:06:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.10 on epoch=138
05/29/2022 21:06:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.01 on epoch=139
05/29/2022 21:06:27 - INFO - __main__ - Global step 1950 Train loss 3.00 Classification-F1 0.00927643784786642 on epoch=139
05/29/2022 21:06:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.10 on epoch=139
05/29/2022 21:06:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.06 on epoch=140
05/29/2022 21:06:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.02 on epoch=141
05/29/2022 21:06:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.02 on epoch=142
05/29/2022 21:06:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.90 on epoch=142
05/29/2022 21:06:35 - INFO - __main__ - Global step 2000 Train loss 3.02 Classification-F1 0.013223249235222525 on epoch=142
05/29/2022 21:06:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.05 on epoch=143
05/29/2022 21:06:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.84 on epoch=144
05/29/2022 21:06:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.10 on epoch=144
05/29/2022 21:06:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.98 on epoch=145
05/29/2022 21:06:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.00 on epoch=146
05/29/2022 21:06:43 - INFO - __main__ - Global step 2050 Train loss 2.99 Classification-F1 0.018456213654292886 on epoch=146
05/29/2022 21:06:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.96 on epoch=147
05/29/2022 21:06:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.12 on epoch=147
05/29/2022 21:06:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.91 on epoch=148
05/29/2022 21:06:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.87 on epoch=149
05/29/2022 21:06:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.00 on epoch=149
05/29/2022 21:06:51 - INFO - __main__ - Global step 2100 Train loss 2.97 Classification-F1 0.013583638583638582 on epoch=149
05/29/2022 21:06:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.82 on epoch=150
05/29/2022 21:06:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.02 on epoch=151
05/29/2022 21:06:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.90 on epoch=152
05/29/2022 21:06:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.82 on epoch=152
05/29/2022 21:06:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.92 on epoch=153
05/29/2022 21:07:00 - INFO - __main__ - Global step 2150 Train loss 2.90 Classification-F1 0.03500566893424036 on epoch=153
05/29/2022 21:07:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.05 on epoch=154
05/29/2022 21:07:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.88 on epoch=154
05/29/2022 21:07:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.95 on epoch=155
05/29/2022 21:07:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.84 on epoch=156
05/29/2022 21:07:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.03 on epoch=157
05/29/2022 21:07:08 - INFO - __main__ - Global step 2200 Train loss 2.95 Classification-F1 0.04679183385534213 on epoch=157
05/29/2022 21:07:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.94 on epoch=157
05/29/2022 21:07:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.95 on epoch=158
05/29/2022 21:07:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.78 on epoch=159
05/29/2022 21:07:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.96 on epoch=159
05/29/2022 21:07:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.90 on epoch=160
05/29/2022 21:07:16 - INFO - __main__ - Global step 2250 Train loss 2.91 Classification-F1 0.024481792717086837 on epoch=160
05/29/2022 21:07:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.71 on epoch=161
05/29/2022 21:07:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.85 on epoch=162
05/29/2022 21:07:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.97 on epoch=162
05/29/2022 21:07:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.76 on epoch=163
05/29/2022 21:07:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.83 on epoch=164
05/29/2022 21:07:24 - INFO - __main__ - Global step 2300 Train loss 2.82 Classification-F1 0.046359587077960285 on epoch=164
05/29/2022 21:07:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.03 on epoch=164
05/29/2022 21:07:27 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.96 on epoch=165
05/29/2022 21:07:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.92 on epoch=166
05/29/2022 21:07:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.94 on epoch=167
05/29/2022 21:07:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.90 on epoch=167
05/29/2022 21:07:32 - INFO - __main__ - Global step 2350 Train loss 2.95 Classification-F1 0.05851316603196303 on epoch=167
05/29/2022 21:07:32 - INFO - __main__ - Saving model with best Classification-F1: 0.04830607760239014 -> 0.05851316603196303 on epoch=167, global_step=2350
05/29/2022 21:07:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.88 on epoch=168
05/29/2022 21:07:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.93 on epoch=169
05/29/2022 21:07:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.85 on epoch=169
05/29/2022 21:07:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.85 on epoch=170
05/29/2022 21:07:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.75 on epoch=171
05/29/2022 21:07:41 - INFO - __main__ - Global step 2400 Train loss 2.85 Classification-F1 0.02644981437551097 on epoch=171
05/29/2022 21:07:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.71 on epoch=172
05/29/2022 21:07:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.03 on epoch=172
05/29/2022 21:07:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.91 on epoch=173
05/29/2022 21:07:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.79 on epoch=174
05/29/2022 21:07:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.00 on epoch=174
05/29/2022 21:07:49 - INFO - __main__ - Global step 2450 Train loss 2.89 Classification-F1 0.016828087167070217 on epoch=174
05/29/2022 21:07:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.81 on epoch=175
05/29/2022 21:07:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.95 on epoch=176
05/29/2022 21:07:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.87 on epoch=177
05/29/2022 21:07:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.99 on epoch=177
05/29/2022 21:07:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.76 on epoch=178
05/29/2022 21:07:57 - INFO - __main__ - Global step 2500 Train loss 2.88 Classification-F1 0.009685230024213076 on epoch=178
05/29/2022 21:07:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.84 on epoch=179
05/29/2022 21:08:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.97 on epoch=179
05/29/2022 21:08:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.81 on epoch=180
05/29/2022 21:08:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.91 on epoch=181
05/29/2022 21:08:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.85 on epoch=182
05/29/2022 21:08:05 - INFO - __main__ - Global step 2550 Train loss 2.87 Classification-F1 0.009316770186335404 on epoch=182
05/29/2022 21:08:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.70 on epoch=182
05/29/2022 21:08:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.70 on epoch=183
05/29/2022 21:08:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.91 on epoch=184
05/29/2022 21:08:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.75 on epoch=184
05/29/2022 21:08:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.73 on epoch=185
05/29/2022 21:08:13 - INFO - __main__ - Global step 2600 Train loss 2.76 Classification-F1 0.015652173913043476 on epoch=185
05/29/2022 21:08:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.88 on epoch=186
05/29/2022 21:08:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.77 on epoch=187
05/29/2022 21:08:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.88 on epoch=187
05/29/2022 21:08:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.89 on epoch=188
05/29/2022 21:08:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.74 on epoch=189
05/29/2022 21:08:22 - INFO - __main__ - Global step 2650 Train loss 2.83 Classification-F1 0.009644364074743823 on epoch=189
05/29/2022 21:08:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.77 on epoch=189
05/29/2022 21:08:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.71 on epoch=190
05/29/2022 21:08:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.81 on epoch=191
05/29/2022 21:08:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.83 on epoch=192
05/29/2022 21:08:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.82 on epoch=192
05/29/2022 21:08:30 - INFO - __main__ - Global step 2700 Train loss 2.79 Classification-F1 0.025164835164835166 on epoch=192
05/29/2022 21:08:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.91 on epoch=193
05/29/2022 21:08:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.78 on epoch=194
05/29/2022 21:08:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.89 on epoch=194
05/29/2022 21:08:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.68 on epoch=195
05/29/2022 21:08:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/29/2022 21:08:38 - INFO - __main__ - Global step 2750 Train loss 2.84 Classification-F1 0.043001885338208326 on epoch=196
05/29/2022 21:08:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.79 on epoch=197
05/29/2022 21:08:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.79 on epoch=197
05/29/2022 21:08:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.72 on epoch=198
05/29/2022 21:08:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.68 on epoch=199
05/29/2022 21:08:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.78 on epoch=199
05/29/2022 21:08:46 - INFO - __main__ - Global step 2800 Train loss 2.75 Classification-F1 0.0189098998887653 on epoch=199
05/29/2022 21:08:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.80 on epoch=200
05/29/2022 21:08:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.73 on epoch=201
05/29/2022 21:08:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.84 on epoch=202
05/29/2022 21:08:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.78 on epoch=202
05/29/2022 21:08:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.68 on epoch=203
05/29/2022 21:08:55 - INFO - __main__ - Global step 2850 Train loss 2.76 Classification-F1 0.031145617667356802 on epoch=203
05/29/2022 21:08:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.63 on epoch=204
05/29/2022 21:08:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.76 on epoch=204
05/29/2022 21:08:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.68 on epoch=205
05/29/2022 21:09:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.65 on epoch=206
05/29/2022 21:09:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.76 on epoch=207
05/29/2022 21:09:03 - INFO - __main__ - Global step 2900 Train loss 2.69 Classification-F1 0.04006211180124224 on epoch=207
05/29/2022 21:09:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.78 on epoch=207
05/29/2022 21:09:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.57 on epoch=208
05/29/2022 21:09:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.65 on epoch=209
05/29/2022 21:09:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.71 on epoch=209
05/29/2022 21:09:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.60 on epoch=210
05/29/2022 21:09:12 - INFO - __main__ - Global step 2950 Train loss 2.66 Classification-F1 0.009523809523809523 on epoch=210
05/29/2022 21:09:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.68 on epoch=211
05/29/2022 21:09:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.93 on epoch=212
05/29/2022 21:09:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.74 on epoch=212
05/29/2022 21:09:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.68 on epoch=213
05/29/2022 21:09:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.69 on epoch=214
05/29/2022 21:09:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:09:19 - INFO - __main__ - Printing 3 examples
05/29/2022 21:09:19 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 21:09:19 - INFO - __main__ - ['Company']
05/29/2022 21:09:19 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 21:09:19 - INFO - __main__ - ['Company']
05/29/2022 21:09:19 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 21:09:19 - INFO - __main__ - ['Company']
05/29/2022 21:09:19 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:09:20 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:09:20 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:09:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:09:20 - INFO - __main__ - Printing 3 examples
05/29/2022 21:09:20 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 21:09:20 - INFO - __main__ - ['Company']
05/29/2022 21:09:20 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 21:09:20 - INFO - __main__ - ['Company']
05/29/2022 21:09:20 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 21:09:20 - INFO - __main__ - ['Company']
05/29/2022 21:09:20 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:09:20 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:09:20 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:09:20 - INFO - __main__ - Global step 3000 Train loss 2.74 Classification-F1 0.02791094586230164 on epoch=214
05/29/2022 21:09:20 - INFO - __main__ - save last model!
05/29/2022 21:09:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 21:09:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 21:09:20 - INFO - __main__ - Printing 3 examples
05/29/2022 21:09:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 21:09:20 - INFO - __main__ - ['Animal']
05/29/2022 21:09:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 21:09:20 - INFO - __main__ - ['Animal']
05/29/2022 21:09:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 21:09:20 - INFO - __main__ - ['Village']
05/29/2022 21:09:20 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:09:22 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:09:25 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:09:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:09:26 - INFO - __main__ - Starting training!
05/29/2022 21:09:26 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 21:09:58 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/29/2022 21:09:58 - INFO - __main__ - Classification-F1 on test data: 0.0245
05/29/2022 21:09:59 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.05851316603196303, test_performance=0.02453195594723706
05/29/2022 21:09:59 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/29/2022 21:10:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:10:00 - INFO - __main__ - Printing 3 examples
05/29/2022 21:10:00 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/29/2022 21:10:00 - INFO - __main__ - ['Company']
05/29/2022 21:10:00 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/29/2022 21:10:00 - INFO - __main__ - ['Company']
05/29/2022 21:10:00 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/29/2022 21:10:00 - INFO - __main__ - ['Company']
05/29/2022 21:10:00 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:10:00 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:10:00 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:10:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:10:00 - INFO - __main__ - Printing 3 examples
05/29/2022 21:10:00 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/29/2022 21:10:00 - INFO - __main__ - ['Company']
05/29/2022 21:10:00 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/29/2022 21:10:00 - INFO - __main__ - ['Company']
05/29/2022 21:10:00 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/29/2022 21:10:00 - INFO - __main__ - ['Company']
05/29/2022 21:10:00 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:10:00 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:10:00 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:10:06 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:10:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:10:06 - INFO - __main__ - Starting training!
05/29/2022 21:10:07 - INFO - __main__ - Step 10 Global step 10 Train loss 7.33 on epoch=0
05/29/2022 21:10:09 - INFO - __main__ - Step 20 Global step 20 Train loss 7.59 on epoch=1
05/29/2022 21:10:10 - INFO - __main__ - Step 30 Global step 30 Train loss 7.56 on epoch=2
05/29/2022 21:10:11 - INFO - __main__ - Step 40 Global step 40 Train loss 7.00 on epoch=2
05/29/2022 21:10:13 - INFO - __main__ - Step 50 Global step 50 Train loss 7.35 on epoch=3
05/29/2022 21:10:21 - INFO - __main__ - Global step 50 Train loss 7.37 Classification-F1 0.0 on epoch=3
05/29/2022 21:10:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 21:10:23 - INFO - __main__ - Step 60 Global step 60 Train loss 7.08 on epoch=4
05/29/2022 21:10:24 - INFO - __main__ - Step 70 Global step 70 Train loss 7.19 on epoch=4
05/29/2022 21:10:25 - INFO - __main__ - Step 80 Global step 80 Train loss 6.90 on epoch=5
05/29/2022 21:10:27 - INFO - __main__ - Step 90 Global step 90 Train loss 6.99 on epoch=6
05/29/2022 21:10:28 - INFO - __main__ - Step 100 Global step 100 Train loss 6.99 on epoch=7
05/29/2022 21:11:05 - INFO - __main__ - Global step 100 Train loss 7.03 Classification-F1 0.0 on epoch=7
05/29/2022 21:11:06 - INFO - __main__ - Step 110 Global step 110 Train loss 6.62 on epoch=7
05/29/2022 21:11:08 - INFO - __main__ - Step 120 Global step 120 Train loss 6.95 on epoch=8
05/29/2022 21:11:09 - INFO - __main__ - Step 130 Global step 130 Train loss 6.75 on epoch=9
05/29/2022 21:11:10 - INFO - __main__ - Step 140 Global step 140 Train loss 6.94 on epoch=9
05/29/2022 21:11:11 - INFO - __main__ - Step 150 Global step 150 Train loss 6.47 on epoch=10
05/29/2022 21:11:58 - INFO - __main__ - Global step 150 Train loss 6.74 Classification-F1 0.0 on epoch=10
05/29/2022 21:12:00 - INFO - __main__ - Step 160 Global step 160 Train loss 6.85 on epoch=11
05/29/2022 21:12:01 - INFO - __main__ - Step 170 Global step 170 Train loss 6.77 on epoch=12
05/29/2022 21:12:02 - INFO - __main__ - Step 180 Global step 180 Train loss 6.38 on epoch=12
05/29/2022 21:12:03 - INFO - __main__ - Step 190 Global step 190 Train loss 6.73 on epoch=13
05/29/2022 21:12:05 - INFO - __main__ - Step 200 Global step 200 Train loss 6.39 on epoch=14
05/29/2022 21:13:16 - INFO - __main__ - Global step 200 Train loss 6.62 Classification-F1 0.0 on epoch=14
05/29/2022 21:13:17 - INFO - __main__ - Step 210 Global step 210 Train loss 6.63 on epoch=14
05/29/2022 21:13:19 - INFO - __main__ - Step 220 Global step 220 Train loss 6.22 on epoch=15
05/29/2022 21:13:20 - INFO - __main__ - Step 230 Global step 230 Train loss 6.54 on epoch=16
05/29/2022 21:13:22 - INFO - __main__ - Step 240 Global step 240 Train loss 6.39 on epoch=17
05/29/2022 21:13:23 - INFO - __main__ - Step 250 Global step 250 Train loss 6.21 on epoch=17
05/29/2022 21:14:35 - INFO - __main__ - Global step 250 Train loss 6.40 Classification-F1 0.0 on epoch=17
05/29/2022 21:14:36 - INFO - __main__ - Step 260 Global step 260 Train loss 6.45 on epoch=18
05/29/2022 21:14:38 - INFO - __main__ - Step 270 Global step 270 Train loss 6.16 on epoch=19
05/29/2022 21:14:39 - INFO - __main__ - Step 280 Global step 280 Train loss 6.35 on epoch=19
05/29/2022 21:14:40 - INFO - __main__ - Step 290 Global step 290 Train loss 6.01 on epoch=20
05/29/2022 21:14:41 - INFO - __main__ - Step 300 Global step 300 Train loss 6.29 on epoch=21
05/29/2022 21:15:56 - INFO - __main__ - Global step 300 Train loss 6.25 Classification-F1 0.0 on epoch=21
05/29/2022 21:15:57 - INFO - __main__ - Step 310 Global step 310 Train loss 6.12 on epoch=22
05/29/2022 21:15:58 - INFO - __main__ - Step 320 Global step 320 Train loss 5.87 on epoch=22
05/29/2022 21:16:00 - INFO - __main__ - Step 330 Global step 330 Train loss 6.08 on epoch=23
05/29/2022 21:16:01 - INFO - __main__ - Step 340 Global step 340 Train loss 5.95 on epoch=24
05/29/2022 21:16:02 - INFO - __main__ - Step 350 Global step 350 Train loss 6.02 on epoch=24
05/29/2022 21:17:19 - INFO - __main__ - Global step 350 Train loss 6.01 Classification-F1 0.0 on epoch=24
05/29/2022 21:17:21 - INFO - __main__ - Step 360 Global step 360 Train loss 5.83 on epoch=25
05/29/2022 21:17:22 - INFO - __main__ - Step 370 Global step 370 Train loss 5.92 on epoch=26
05/29/2022 21:17:23 - INFO - __main__ - Step 380 Global step 380 Train loss 5.99 on epoch=27
05/29/2022 21:17:25 - INFO - __main__ - Step 390 Global step 390 Train loss 5.64 on epoch=27
05/29/2022 21:17:26 - INFO - __main__ - Step 400 Global step 400 Train loss 5.93 on epoch=28
05/29/2022 21:18:43 - INFO - __main__ - Global step 400 Train loss 5.86 Classification-F1 0.0 on epoch=28
05/29/2022 21:18:44 - INFO - __main__ - Step 410 Global step 410 Train loss 5.83 on epoch=29
05/29/2022 21:18:45 - INFO - __main__ - Step 420 Global step 420 Train loss 5.87 on epoch=29
05/29/2022 21:18:47 - INFO - __main__ - Step 430 Global step 430 Train loss 5.66 on epoch=30
05/29/2022 21:18:48 - INFO - __main__ - Step 440 Global step 440 Train loss 5.63 on epoch=31
05/29/2022 21:18:49 - INFO - __main__ - Step 450 Global step 450 Train loss 5.68 on epoch=32
05/29/2022 21:19:25 - INFO - __main__ - Global step 450 Train loss 5.73 Classification-F1 0.0 on epoch=32
05/29/2022 21:19:27 - INFO - __main__ - Step 460 Global step 460 Train loss 5.39 on epoch=32
05/29/2022 21:19:28 - INFO - __main__ - Step 470 Global step 470 Train loss 5.63 on epoch=33
05/29/2022 21:19:29 - INFO - __main__ - Step 480 Global step 480 Train loss 5.35 on epoch=34
05/29/2022 21:19:31 - INFO - __main__ - Step 490 Global step 490 Train loss 5.71 on epoch=34
05/29/2022 21:19:32 - INFO - __main__ - Step 500 Global step 500 Train loss 5.46 on epoch=35
05/29/2022 21:20:07 - INFO - __main__ - Global step 500 Train loss 5.51 Classification-F1 0.0 on epoch=35
05/29/2022 21:20:08 - INFO - __main__ - Step 510 Global step 510 Train loss 5.52 on epoch=36
05/29/2022 21:20:09 - INFO - __main__ - Step 520 Global step 520 Train loss 5.52 on epoch=37
05/29/2022 21:20:11 - INFO - __main__ - Step 530 Global step 530 Train loss 5.27 on epoch=37
05/29/2022 21:20:12 - INFO - __main__ - Step 540 Global step 540 Train loss 5.44 on epoch=38
05/29/2022 21:20:13 - INFO - __main__ - Step 550 Global step 550 Train loss 5.28 on epoch=39
05/29/2022 21:20:41 - INFO - __main__ - Global step 550 Train loss 5.41 Classification-F1 0.0009775171065493648 on epoch=39
05/29/2022 21:20:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0009775171065493648 on epoch=39, global_step=550
05/29/2022 21:20:43 - INFO - __main__ - Step 560 Global step 560 Train loss 5.44 on epoch=39
05/29/2022 21:20:44 - INFO - __main__ - Step 570 Global step 570 Train loss 5.22 on epoch=40
05/29/2022 21:20:45 - INFO - __main__ - Step 580 Global step 580 Train loss 5.32 on epoch=41
05/29/2022 21:20:47 - INFO - __main__ - Step 590 Global step 590 Train loss 5.28 on epoch=42
05/29/2022 21:20:48 - INFO - __main__ - Step 600 Global step 600 Train loss 5.19 on epoch=42
05/29/2022 21:21:01 - INFO - __main__ - Global step 600 Train loss 5.29 Classification-F1 0.002197802197802198 on epoch=42
05/29/2022 21:21:01 - INFO - __main__ - Saving model with best Classification-F1: 0.0009775171065493648 -> 0.002197802197802198 on epoch=42, global_step=600
05/29/2022 21:21:02 - INFO - __main__ - Step 610 Global step 610 Train loss 5.42 on epoch=43
05/29/2022 21:21:03 - INFO - __main__ - Step 620 Global step 620 Train loss 5.12 on epoch=44
05/29/2022 21:21:05 - INFO - __main__ - Step 630 Global step 630 Train loss 5.42 on epoch=44
05/29/2022 21:21:06 - INFO - __main__ - Step 640 Global step 640 Train loss 4.96 on epoch=45
05/29/2022 21:21:07 - INFO - __main__ - Step 650 Global step 650 Train loss 5.20 on epoch=46
05/29/2022 21:21:10 - INFO - __main__ - Global step 650 Train loss 5.22 Classification-F1 0.006284038542103057 on epoch=46
05/29/2022 21:21:10 - INFO - __main__ - Saving model with best Classification-F1: 0.002197802197802198 -> 0.006284038542103057 on epoch=46, global_step=650
05/29/2022 21:21:11 - INFO - __main__ - Step 660 Global step 660 Train loss 5.14 on epoch=47
05/29/2022 21:21:13 - INFO - __main__ - Step 670 Global step 670 Train loss 4.91 on epoch=47
05/29/2022 21:21:14 - INFO - __main__ - Step 680 Global step 680 Train loss 5.13 on epoch=48
05/29/2022 21:21:15 - INFO - __main__ - Step 690 Global step 690 Train loss 5.03 on epoch=49
05/29/2022 21:21:17 - INFO - __main__ - Step 700 Global step 700 Train loss 5.19 on epoch=49
05/29/2022 21:21:19 - INFO - __main__ - Global step 700 Train loss 5.08 Classification-F1 0.00640614990390775 on epoch=49
05/29/2022 21:21:19 - INFO - __main__ - Saving model with best Classification-F1: 0.006284038542103057 -> 0.00640614990390775 on epoch=49, global_step=700
05/29/2022 21:21:21 - INFO - __main__ - Step 710 Global step 710 Train loss 4.89 on epoch=50
05/29/2022 21:21:22 - INFO - __main__ - Step 720 Global step 720 Train loss 5.08 on epoch=51
05/29/2022 21:21:23 - INFO - __main__ - Step 730 Global step 730 Train loss 4.90 on epoch=52
05/29/2022 21:21:24 - INFO - __main__ - Step 740 Global step 740 Train loss 4.75 on epoch=52
05/29/2022 21:21:26 - INFO - __main__ - Step 750 Global step 750 Train loss 4.87 on epoch=53
05/29/2022 21:21:28 - INFO - __main__ - Global step 750 Train loss 4.90 Classification-F1 0.007942417473318442 on epoch=53
05/29/2022 21:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.00640614990390775 -> 0.007942417473318442 on epoch=53, global_step=750
05/29/2022 21:21:30 - INFO - __main__ - Step 760 Global step 760 Train loss 4.79 on epoch=54
05/29/2022 21:21:31 - INFO - __main__ - Step 770 Global step 770 Train loss 4.99 on epoch=54
05/29/2022 21:21:32 - INFO - __main__ - Step 780 Global step 780 Train loss 4.65 on epoch=55
05/29/2022 21:21:33 - INFO - __main__ - Step 790 Global step 790 Train loss 4.84 on epoch=56
05/29/2022 21:21:35 - INFO - __main__ - Step 800 Global step 800 Train loss 4.80 on epoch=57
05/29/2022 21:21:37 - INFO - __main__ - Global step 800 Train loss 4.81 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 21:21:37 - INFO - __main__ - Saving model with best Classification-F1: 0.007942417473318442 -> 0.009523809523809523 on epoch=57, global_step=800
05/29/2022 21:21:38 - INFO - __main__ - Step 810 Global step 810 Train loss 4.72 on epoch=57
05/29/2022 21:21:40 - INFO - __main__ - Step 820 Global step 820 Train loss 4.89 on epoch=58
05/29/2022 21:21:41 - INFO - __main__ - Step 830 Global step 830 Train loss 4.71 on epoch=59
05/29/2022 21:21:42 - INFO - __main__ - Step 840 Global step 840 Train loss 4.85 on epoch=59
05/29/2022 21:21:44 - INFO - __main__ - Step 850 Global step 850 Train loss 4.76 on epoch=60
05/29/2022 21:21:46 - INFO - __main__ - Global step 850 Train loss 4.79 Classification-F1 0.009523809523809523 on epoch=60
05/29/2022 21:21:47 - INFO - __main__ - Step 860 Global step 860 Train loss 4.79 on epoch=61
05/29/2022 21:21:49 - INFO - __main__ - Step 870 Global step 870 Train loss 4.70 on epoch=62
05/29/2022 21:21:50 - INFO - __main__ - Step 880 Global step 880 Train loss 4.53 on epoch=62
05/29/2022 21:21:51 - INFO - __main__ - Step 890 Global step 890 Train loss 4.64 on epoch=63
05/29/2022 21:21:52 - INFO - __main__ - Step 900 Global step 900 Train loss 4.61 on epoch=64
05/29/2022 21:21:55 - INFO - __main__ - Global step 900 Train loss 4.66 Classification-F1 0.009523809523809523 on epoch=64
05/29/2022 21:21:56 - INFO - __main__ - Step 910 Global step 910 Train loss 4.88 on epoch=64
05/29/2022 21:21:57 - INFO - __main__ - Step 920 Global step 920 Train loss 4.49 on epoch=65
05/29/2022 21:21:59 - INFO - __main__ - Step 930 Global step 930 Train loss 4.62 on epoch=66
05/29/2022 21:22:00 - INFO - __main__ - Step 940 Global step 940 Train loss 4.53 on epoch=67
05/29/2022 21:22:01 - INFO - __main__ - Step 950 Global step 950 Train loss 4.44 on epoch=67
05/29/2022 21:22:03 - INFO - __main__ - Global step 950 Train loss 4.59 Classification-F1 0.009523809523809523 on epoch=67
05/29/2022 21:22:04 - INFO - __main__ - Step 960 Global step 960 Train loss 4.53 on epoch=68
05/29/2022 21:22:06 - INFO - __main__ - Step 970 Global step 970 Train loss 4.39 on epoch=69
05/29/2022 21:22:07 - INFO - __main__ - Step 980 Global step 980 Train loss 4.67 on epoch=69
05/29/2022 21:22:08 - INFO - __main__ - Step 990 Global step 990 Train loss 4.48 on epoch=70
05/29/2022 21:22:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.59 on epoch=71
05/29/2022 21:22:11 - INFO - __main__ - Global step 1000 Train loss 4.53 Classification-F1 0.009523809523809523 on epoch=71
05/29/2022 21:22:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.29 on epoch=72
05/29/2022 21:22:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.26 on epoch=72
05/29/2022 21:22:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.47 on epoch=73
05/29/2022 21:22:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.23 on epoch=74
05/29/2022 21:22:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.45 on epoch=74
05/29/2022 21:22:20 - INFO - __main__ - Global step 1050 Train loss 4.34 Classification-F1 0.009523809523809523 on epoch=74
05/29/2022 21:22:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.29 on epoch=75
05/29/2022 21:22:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.27 on epoch=76
05/29/2022 21:22:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.28 on epoch=77
05/29/2022 21:22:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.14 on epoch=77
05/29/2022 21:22:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.25 on epoch=78
05/29/2022 21:22:28 - INFO - __main__ - Global step 1100 Train loss 4.24 Classification-F1 0.009523809523809523 on epoch=78
05/29/2022 21:22:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.27 on epoch=79
05/29/2022 21:22:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.28 on epoch=79
05/29/2022 21:22:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.00 on epoch=80
05/29/2022 21:22:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.22 on epoch=81
05/29/2022 21:22:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.17 on epoch=82
05/29/2022 21:22:36 - INFO - __main__ - Global step 1150 Train loss 4.19 Classification-F1 0.009523809523809523 on epoch=82
05/29/2022 21:22:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.26 on epoch=82
05/29/2022 21:22:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.04 on epoch=83
05/29/2022 21:22:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.11 on epoch=84
05/29/2022 21:22:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.11 on epoch=84
05/29/2022 21:22:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.01 on epoch=85
05/29/2022 21:22:44 - INFO - __main__ - Global step 1200 Train loss 4.11 Classification-F1 0.01796701944376077 on epoch=85
05/29/2022 21:22:44 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01796701944376077 on epoch=85, global_step=1200
05/29/2022 21:22:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.15 on epoch=86
05/29/2022 21:22:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.02 on epoch=87
05/29/2022 21:22:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.99 on epoch=87
05/29/2022 21:22:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.98 on epoch=88
05/29/2022 21:22:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.02 on epoch=89
05/29/2022 21:22:53 - INFO - __main__ - Global step 1250 Train loss 4.03 Classification-F1 0.029210814760686883 on epoch=89
05/29/2022 21:22:53 - INFO - __main__ - Saving model with best Classification-F1: 0.01796701944376077 -> 0.029210814760686883 on epoch=89, global_step=1250
05/29/2022 21:22:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.15 on epoch=89
05/29/2022 21:22:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.88 on epoch=90
05/29/2022 21:22:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 4.09 on epoch=91
05/29/2022 21:22:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.06 on epoch=92
05/29/2022 21:22:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.93 on epoch=92
05/29/2022 21:23:01 - INFO - __main__ - Global step 1300 Train loss 4.02 Classification-F1 0.016618075801749267 on epoch=92
05/29/2022 21:23:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.89 on epoch=93
05/29/2022 21:23:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 4.00 on epoch=94
05/29/2022 21:23:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.94 on epoch=94
05/29/2022 21:23:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.83 on epoch=95
05/29/2022 21:23:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.91 on epoch=96
05/29/2022 21:23:09 - INFO - __main__ - Global step 1350 Train loss 3.91 Classification-F1 0.01724307022940238 on epoch=96
05/29/2022 21:23:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.73 on epoch=97
05/29/2022 21:23:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.89 on epoch=97
05/29/2022 21:23:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.79 on epoch=98
05/29/2022 21:23:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.83 on epoch=99
05/29/2022 21:23:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.83 on epoch=99
05/29/2022 21:23:18 - INFO - __main__ - Global step 1400 Train loss 3.81 Classification-F1 0.013267418768749737 on epoch=99
05/29/2022 21:23:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.67 on epoch=100
05/29/2022 21:23:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.77 on epoch=101
05/29/2022 21:23:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.65 on epoch=102
05/29/2022 21:23:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.74 on epoch=102
05/29/2022 21:23:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.70 on epoch=103
05/29/2022 21:23:26 - INFO - __main__ - Global step 1450 Train loss 3.71 Classification-F1 0.009563658099222952 on epoch=103
05/29/2022 21:23:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.54 on epoch=104
05/29/2022 21:23:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.82 on epoch=104
05/29/2022 21:23:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.61 on epoch=105
05/29/2022 21:23:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.56 on epoch=106
05/29/2022 21:23:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.48 on epoch=107
05/29/2022 21:23:34 - INFO - __main__ - Global step 1500 Train loss 3.60 Classification-F1 0.009644364074743823 on epoch=107
05/29/2022 21:23:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.61 on epoch=107
05/29/2022 21:23:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.64 on epoch=108
05/29/2022 21:23:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.50 on epoch=109
05/29/2022 21:23:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.67 on epoch=109
05/29/2022 21:23:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.50 on epoch=110
05/29/2022 21:23:42 - INFO - __main__ - Global step 1550 Train loss 3.58 Classification-F1 0.009563658099222952 on epoch=110
05/29/2022 21:23:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.41 on epoch=111
05/29/2022 21:23:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.56 on epoch=112
05/29/2022 21:23:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.54 on epoch=112
05/29/2022 21:23:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.56 on epoch=113
05/29/2022 21:23:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.64 on epoch=114
05/29/2022 21:23:50 - INFO - __main__ - Global step 1600 Train loss 3.54 Classification-F1 0.017163161067225024 on epoch=114
05/29/2022 21:23:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.66 on epoch=114
05/29/2022 21:23:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.52 on epoch=115
05/29/2022 21:23:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.59 on epoch=116
05/29/2022 21:23:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.62 on epoch=117
05/29/2022 21:23:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.57 on epoch=117
05/29/2022 21:23:59 - INFO - __main__ - Global step 1650 Train loss 3.59 Classification-F1 0.024042555098455716 on epoch=117
05/29/2022 21:24:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.45 on epoch=118
05/29/2022 21:24:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.40 on epoch=119
05/29/2022 21:24:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.51 on epoch=119
05/29/2022 21:24:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.50 on epoch=120
05/29/2022 21:24:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.52 on epoch=121
05/29/2022 21:24:07 - INFO - __main__ - Global step 1700 Train loss 3.48 Classification-F1 0.024675324675324677 on epoch=121
05/29/2022 21:24:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.47 on epoch=122
05/29/2022 21:24:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.40 on epoch=122
05/29/2022 21:24:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.27 on epoch=123
05/29/2022 21:24:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.38 on epoch=124
05/29/2022 21:24:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.37 on epoch=124
05/29/2022 21:24:15 - INFO - __main__ - Global step 1750 Train loss 3.38 Classification-F1 0.03539319501264533 on epoch=124
05/29/2022 21:24:15 - INFO - __main__ - Saving model with best Classification-F1: 0.029210814760686883 -> 0.03539319501264533 on epoch=124, global_step=1750
05/29/2022 21:24:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.42 on epoch=125
05/29/2022 21:24:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.49 on epoch=126
05/29/2022 21:24:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.42 on epoch=127
05/29/2022 21:24:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.35 on epoch=127
05/29/2022 21:24:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.33 on epoch=128
05/29/2022 21:24:23 - INFO - __main__ - Global step 1800 Train loss 3.40 Classification-F1 0.020719040684715744 on epoch=128
05/29/2022 21:24:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.36 on epoch=129
05/29/2022 21:24:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.36 on epoch=129
05/29/2022 21:24:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.25 on epoch=130
05/29/2022 21:24:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.30 on epoch=131
05/29/2022 21:24:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.21 on epoch=132
05/29/2022 21:24:32 - INFO - __main__ - Global step 1850 Train loss 3.30 Classification-F1 0.04694632765972536 on epoch=132
05/29/2022 21:24:32 - INFO - __main__ - Saving model with best Classification-F1: 0.03539319501264533 -> 0.04694632765972536 on epoch=132, global_step=1850
05/29/2022 21:24:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.40 on epoch=132
05/29/2022 21:24:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.18 on epoch=133
05/29/2022 21:24:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.25 on epoch=134
05/29/2022 21:24:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.36 on epoch=134
05/29/2022 21:24:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.34 on epoch=135
05/29/2022 21:24:40 - INFO - __main__ - Global step 1900 Train loss 3.31 Classification-F1 0.027522268251751532 on epoch=135
05/29/2022 21:24:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.30 on epoch=136
05/29/2022 21:24:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.26 on epoch=137
05/29/2022 21:24:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.19 on epoch=137
05/29/2022 21:24:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.17 on epoch=138
05/29/2022 21:24:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.26 on epoch=139
05/29/2022 21:24:48 - INFO - __main__ - Global step 1950 Train loss 3.24 Classification-F1 0.00976800976800977 on epoch=139
05/29/2022 21:24:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.25 on epoch=139
05/29/2022 21:24:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.16 on epoch=140
05/29/2022 21:24:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.09 on epoch=141
05/29/2022 21:24:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.21 on epoch=142
05/29/2022 21:24:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.30 on epoch=142
05/29/2022 21:24:56 - INFO - __main__ - Global step 2000 Train loss 3.20 Classification-F1 0.010342598577892695 on epoch=142
05/29/2022 21:24:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.07 on epoch=143
05/29/2022 21:24:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.15 on epoch=144
05/29/2022 21:25:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.15 on epoch=144
05/29/2022 21:25:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.35 on epoch=145
05/29/2022 21:25:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.23 on epoch=146
05/29/2022 21:25:05 - INFO - __main__ - Global step 2050 Train loss 3.19 Classification-F1 0.04818032941072327 on epoch=146
05/29/2022 21:25:05 - INFO - __main__ - Saving model with best Classification-F1: 0.04694632765972536 -> 0.04818032941072327 on epoch=146, global_step=2050
05/29/2022 21:25:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.17 on epoch=147
05/29/2022 21:25:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.13 on epoch=147
05/29/2022 21:25:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.14 on epoch=148
05/29/2022 21:25:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.07 on epoch=149
05/29/2022 21:25:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.14 on epoch=149
05/29/2022 21:25:13 - INFO - __main__ - Global step 2100 Train loss 3.13 Classification-F1 0.0552718062260047 on epoch=149
05/29/2022 21:25:13 - INFO - __main__ - Saving model with best Classification-F1: 0.04818032941072327 -> 0.0552718062260047 on epoch=149, global_step=2100
05/29/2022 21:25:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.06 on epoch=150
05/29/2022 21:25:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.12 on epoch=151
05/29/2022 21:25:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.16 on epoch=152
05/29/2022 21:25:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.09 on epoch=152
05/29/2022 21:25:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.12 on epoch=153
05/29/2022 21:25:21 - INFO - __main__ - Global step 2150 Train loss 3.11 Classification-F1 0.03472338073035329 on epoch=153
05/29/2022 21:25:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.16 on epoch=154
05/29/2022 21:25:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.11 on epoch=154
05/29/2022 21:25:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.12 on epoch=155
05/29/2022 21:25:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.07 on epoch=156
05/29/2022 21:25:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.06 on epoch=157
05/29/2022 21:25:29 - INFO - __main__ - Global step 2200 Train loss 3.10 Classification-F1 0.022954485661667984 on epoch=157
05/29/2022 21:25:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.18 on epoch=157
05/29/2022 21:25:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.16 on epoch=158
05/29/2022 21:25:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.99 on epoch=159
05/29/2022 21:25:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.12 on epoch=159
05/29/2022 21:25:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.99 on epoch=160
05/29/2022 21:25:38 - INFO - __main__ - Global step 2250 Train loss 3.09 Classification-F1 0.02650290885585003 on epoch=160
05/29/2022 21:25:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.05 on epoch=161
05/29/2022 21:25:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.07 on epoch=162
05/29/2022 21:25:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.02 on epoch=162
05/29/2022 21:25:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.99 on epoch=163
05/29/2022 21:25:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.96 on epoch=164
05/29/2022 21:25:46 - INFO - __main__ - Global step 2300 Train loss 3.02 Classification-F1 0.020205600850762142 on epoch=164
05/29/2022 21:25:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.11 on epoch=164
05/29/2022 21:25:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.05 on epoch=165
05/29/2022 21:25:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.94 on epoch=166
05/29/2022 21:25:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.00 on epoch=167
05/29/2022 21:25:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.10 on epoch=167
05/29/2022 21:25:54 - INFO - __main__ - Global step 2350 Train loss 3.04 Classification-F1 0.019029314860184166 on epoch=167
05/29/2022 21:25:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.06 on epoch=168
05/29/2022 21:25:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.89 on epoch=169
05/29/2022 21:25:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.84 on epoch=169
05/29/2022 21:25:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.92 on epoch=170
05/29/2022 21:26:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 3.15 on epoch=171
05/29/2022 21:26:02 - INFO - __main__ - Global step 2400 Train loss 2.97 Classification-F1 0.022183117367887806 on epoch=171
05/29/2022 21:26:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.97 on epoch=172
05/29/2022 21:26:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.94 on epoch=172
05/29/2022 21:26:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.26 on epoch=173
05/29/2022 21:26:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.89 on epoch=174
05/29/2022 21:26:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.05 on epoch=174
05/29/2022 21:26:11 - INFO - __main__ - Global step 2450 Train loss 3.02 Classification-F1 0.014139581758629378 on epoch=174
05/29/2022 21:26:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.84 on epoch=175
05/29/2022 21:26:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.87 on epoch=176
05/29/2022 21:26:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.97 on epoch=177
05/29/2022 21:26:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.92 on epoch=177
05/29/2022 21:26:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.87 on epoch=178
05/29/2022 21:26:19 - INFO - __main__ - Global step 2500 Train loss 2.89 Classification-F1 0.01773445696686635 on epoch=178
05/29/2022 21:26:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.89 on epoch=179
05/29/2022 21:26:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.91 on epoch=179
05/29/2022 21:26:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.87 on epoch=180
05/29/2022 21:26:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.04 on epoch=181
05/29/2022 21:26:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.00 on epoch=182
05/29/2022 21:26:28 - INFO - __main__ - Global step 2550 Train loss 2.94 Classification-F1 0.025985125985125986 on epoch=182
05/29/2022 21:26:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.91 on epoch=182
05/29/2022 21:26:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.78 on epoch=183
05/29/2022 21:26:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.84 on epoch=184
05/29/2022 21:26:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.87 on epoch=184
05/29/2022 21:26:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.88 on epoch=185
05/29/2022 21:26:36 - INFO - __main__ - Global step 2600 Train loss 2.86 Classification-F1 0.0467401141743247 on epoch=185
05/29/2022 21:26:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.88 on epoch=186
05/29/2022 21:26:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.95 on epoch=187
05/29/2022 21:26:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 3.02 on epoch=187
05/29/2022 21:26:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.81 on epoch=188
05/29/2022 21:26:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.67 on epoch=189
05/29/2022 21:26:44 - INFO - __main__ - Global step 2650 Train loss 2.86 Classification-F1 0.02337600058231268 on epoch=189
05/29/2022 21:26:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.94 on epoch=189
05/29/2022 21:26:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.60 on epoch=190
05/29/2022 21:26:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.82 on epoch=191
05/29/2022 21:26:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.90 on epoch=192
05/29/2022 21:26:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.79 on epoch=192
05/29/2022 21:26:52 - INFO - __main__ - Global step 2700 Train loss 2.81 Classification-F1 0.03251112879292918 on epoch=192
05/29/2022 21:26:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.73 on epoch=193
05/29/2022 21:26:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.83 on epoch=194
05/29/2022 21:26:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.84 on epoch=194
05/29/2022 21:26:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.72 on epoch=195
05/29/2022 21:26:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.63 on epoch=196
05/29/2022 21:27:01 - INFO - __main__ - Global step 2750 Train loss 2.75 Classification-F1 0.019543650793650797 on epoch=196
05/29/2022 21:27:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.72 on epoch=197
05/29/2022 21:27:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.77 on epoch=197
05/29/2022 21:27:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.77 on epoch=198
05/29/2022 21:27:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.64 on epoch=199
05/29/2022 21:27:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.64 on epoch=199
05/29/2022 21:27:10 - INFO - __main__ - Global step 2800 Train loss 2.71 Classification-F1 0.016314435507505942 on epoch=199
05/29/2022 21:27:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.67 on epoch=200
05/29/2022 21:27:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.72 on epoch=201
05/29/2022 21:27:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.75 on epoch=202
05/29/2022 21:27:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.71 on epoch=202
05/29/2022 21:27:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.70 on epoch=203
05/29/2022 21:27:19 - INFO - __main__ - Global step 2850 Train loss 2.71 Classification-F1 0.04089140672991604 on epoch=203
05/29/2022 21:27:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.70 on epoch=204
05/29/2022 21:27:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.75 on epoch=204
05/29/2022 21:27:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.79 on epoch=205
05/29/2022 21:27:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.69 on epoch=206
05/29/2022 21:27:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.74 on epoch=207
05/29/2022 21:27:28 - INFO - __main__ - Global step 2900 Train loss 2.74 Classification-F1 0.01972558514931396 on epoch=207
05/29/2022 21:27:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.79 on epoch=207
05/29/2022 21:27:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.73 on epoch=208
05/29/2022 21:27:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.68 on epoch=209
05/29/2022 21:27:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.86 on epoch=209
05/29/2022 21:27:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.58 on epoch=210
05/29/2022 21:27:37 - INFO - __main__ - Global step 2950 Train loss 2.73 Classification-F1 0.040890652557319225 on epoch=210
05/29/2022 21:27:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.81 on epoch=211
05/29/2022 21:27:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.60 on epoch=212
05/29/2022 21:27:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.63 on epoch=212
05/29/2022 21:27:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.69 on epoch=213
05/29/2022 21:27:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.75 on epoch=214
05/29/2022 21:27:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:27:44 - INFO - __main__ - Printing 3 examples
05/29/2022 21:27:44 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 21:27:44 - INFO - __main__ - ['Film']
05/29/2022 21:27:44 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 21:27:44 - INFO - __main__ - ['Film']
05/29/2022 21:27:44 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 21:27:44 - INFO - __main__ - ['Film']
05/29/2022 21:27:44 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:27:44 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:27:45 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:27:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:27:45 - INFO - __main__ - Printing 3 examples
05/29/2022 21:27:45 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 21:27:45 - INFO - __main__ - ['Film']
05/29/2022 21:27:45 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 21:27:45 - INFO - __main__ - ['Film']
05/29/2022 21:27:45 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 21:27:45 - INFO - __main__ - ['Film']
05/29/2022 21:27:45 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:27:45 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:27:45 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:27:46 - INFO - __main__ - Global step 3000 Train loss 2.70 Classification-F1 0.01610070257611241 on epoch=214
05/29/2022 21:27:46 - INFO - __main__ - save last model!
05/29/2022 21:27:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 21:27:46 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 21:27:46 - INFO - __main__ - Printing 3 examples
05/29/2022 21:27:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 21:27:46 - INFO - __main__ - ['Animal']
05/29/2022 21:27:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 21:27:46 - INFO - __main__ - ['Animal']
05/29/2022 21:27:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 21:27:46 - INFO - __main__ - ['Village']
05/29/2022 21:27:46 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:27:48 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:27:51 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 21:27:51 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:27:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:27:51 - INFO - __main__ - Starting training!
05/29/2022 21:28:28 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/29/2022 21:28:28 - INFO - __main__ - Classification-F1 on test data: 0.0182
05/29/2022 21:28:28 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.0552718062260047, test_performance=0.018247439487849383
05/29/2022 21:28:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/29/2022 21:28:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:28:29 - INFO - __main__ - Printing 3 examples
05/29/2022 21:28:29 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 21:28:29 - INFO - __main__ - ['Film']
05/29/2022 21:28:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 21:28:29 - INFO - __main__ - ['Film']
05/29/2022 21:28:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 21:28:29 - INFO - __main__ - ['Film']
05/29/2022 21:28:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:28:29 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:28:29 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:28:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:28:29 - INFO - __main__ - Printing 3 examples
05/29/2022 21:28:29 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 21:28:29 - INFO - __main__ - ['Film']
05/29/2022 21:28:29 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 21:28:29 - INFO - __main__ - ['Film']
05/29/2022 21:28:29 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 21:28:29 - INFO - __main__ - ['Film']
05/29/2022 21:28:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:28:29 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:28:30 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:28:35 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:28:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:28:35 - INFO - __main__ - Starting training!
05/29/2022 21:28:37 - INFO - __main__ - Step 10 Global step 10 Train loss 7.39 on epoch=0
05/29/2022 21:28:38 - INFO - __main__ - Step 20 Global step 20 Train loss 7.49 on epoch=1
05/29/2022 21:28:39 - INFO - __main__ - Step 30 Global step 30 Train loss 6.92 on epoch=2
05/29/2022 21:28:41 - INFO - __main__ - Step 40 Global step 40 Train loss 7.17 on epoch=2
05/29/2022 21:28:42 - INFO - __main__ - Step 50 Global step 50 Train loss 6.78 on epoch=3
05/29/2022 21:29:39 - INFO - __main__ - Global step 50 Train loss 7.15 Classification-F1 0.0 on epoch=3
05/29/2022 21:29:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 21:29:40 - INFO - __main__ - Step 60 Global step 60 Train loss 6.74 on epoch=4
05/29/2022 21:29:42 - INFO - __main__ - Step 70 Global step 70 Train loss 6.64 on epoch=4
05/29/2022 21:29:43 - INFO - __main__ - Step 80 Global step 80 Train loss 6.55 on epoch=5
05/29/2022 21:29:44 - INFO - __main__ - Step 90 Global step 90 Train loss 6.30 on epoch=6
05/29/2022 21:29:45 - INFO - __main__ - Step 100 Global step 100 Train loss 6.15 on epoch=7
05/29/2022 21:30:47 - INFO - __main__ - Global step 100 Train loss 6.48 Classification-F1 0.0 on epoch=7
05/29/2022 21:30:48 - INFO - __main__ - Step 110 Global step 110 Train loss 6.19 on epoch=7
05/29/2022 21:30:49 - INFO - __main__ - Step 120 Global step 120 Train loss 5.97 on epoch=8
05/29/2022 21:30:51 - INFO - __main__ - Step 130 Global step 130 Train loss 5.77 on epoch=9
05/29/2022 21:30:52 - INFO - __main__ - Step 140 Global step 140 Train loss 5.93 on epoch=9
05/29/2022 21:30:53 - INFO - __main__ - Step 150 Global step 150 Train loss 5.76 on epoch=10
05/29/2022 21:31:21 - INFO - __main__ - Global step 150 Train loss 5.92 Classification-F1 0.0 on epoch=10
05/29/2022 21:31:23 - INFO - __main__ - Step 160 Global step 160 Train loss 5.74 on epoch=11
05/29/2022 21:31:24 - INFO - __main__ - Step 170 Global step 170 Train loss 5.66 on epoch=12
05/29/2022 21:31:25 - INFO - __main__ - Step 180 Global step 180 Train loss 5.62 on epoch=12
05/29/2022 21:31:26 - INFO - __main__ - Step 190 Global step 190 Train loss 5.42 on epoch=13
05/29/2022 21:31:28 - INFO - __main__ - Step 200 Global step 200 Train loss 5.39 on epoch=14
05/29/2022 21:31:38 - INFO - __main__ - Global step 200 Train loss 5.57 Classification-F1 0.0 on epoch=14
05/29/2022 21:31:39 - INFO - __main__ - Step 210 Global step 210 Train loss 5.44 on epoch=14
05/29/2022 21:31:40 - INFO - __main__ - Step 220 Global step 220 Train loss 5.49 on epoch=15
05/29/2022 21:31:41 - INFO - __main__ - Step 230 Global step 230 Train loss 5.27 on epoch=16
05/29/2022 21:31:43 - INFO - __main__ - Step 240 Global step 240 Train loss 5.17 on epoch=17
05/29/2022 21:31:44 - INFO - __main__ - Step 250 Global step 250 Train loss 5.17 on epoch=17
05/29/2022 21:31:52 - INFO - __main__ - Global step 250 Train loss 5.31 Classification-F1 0.005305039787798408 on epoch=17
05/29/2022 21:31:52 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005305039787798408 on epoch=17, global_step=250
05/29/2022 21:31:54 - INFO - __main__ - Step 260 Global step 260 Train loss 5.07 on epoch=18
05/29/2022 21:31:55 - INFO - __main__ - Step 270 Global step 270 Train loss 5.07 on epoch=19
05/29/2022 21:31:56 - INFO - __main__ - Step 280 Global step 280 Train loss 5.25 on epoch=19
05/29/2022 21:31:57 - INFO - __main__ - Step 290 Global step 290 Train loss 5.09 on epoch=20
05/29/2022 21:31:59 - INFO - __main__ - Step 300 Global step 300 Train loss 4.97 on epoch=21
05/29/2022 21:32:01 - INFO - __main__ - Global step 300 Train loss 5.09 Classification-F1 0.008771929824561405 on epoch=21
05/29/2022 21:32:01 - INFO - __main__ - Saving model with best Classification-F1: 0.005305039787798408 -> 0.008771929824561405 on epoch=21, global_step=300
05/29/2022 21:32:03 - INFO - __main__ - Step 310 Global step 310 Train loss 4.95 on epoch=22
05/29/2022 21:32:04 - INFO - __main__ - Step 320 Global step 320 Train loss 4.88 on epoch=22
05/29/2022 21:32:05 - INFO - __main__ - Step 330 Global step 330 Train loss 4.92 on epoch=23
05/29/2022 21:32:06 - INFO - __main__ - Step 340 Global step 340 Train loss 4.75 on epoch=24
05/29/2022 21:32:08 - INFO - __main__ - Step 350 Global step 350 Train loss 4.81 on epoch=24
05/29/2022 21:32:10 - INFO - __main__ - Global step 350 Train loss 4.86 Classification-F1 0.008963585434173669 on epoch=24
05/29/2022 21:32:10 - INFO - __main__ - Saving model with best Classification-F1: 0.008771929824561405 -> 0.008963585434173669 on epoch=24, global_step=350
05/29/2022 21:32:11 - INFO - __main__ - Step 360 Global step 360 Train loss 4.75 on epoch=25
05/29/2022 21:32:13 - INFO - __main__ - Step 370 Global step 370 Train loss 4.73 on epoch=26
05/29/2022 21:32:14 - INFO - __main__ - Step 380 Global step 380 Train loss 4.69 on epoch=27
05/29/2022 21:32:15 - INFO - __main__ - Step 390 Global step 390 Train loss 4.58 on epoch=27
05/29/2022 21:32:16 - INFO - __main__ - Step 400 Global step 400 Train loss 4.59 on epoch=28
05/29/2022 21:32:19 - INFO - __main__ - Global step 400 Train loss 4.67 Classification-F1 0.006508135168961201 on epoch=28
05/29/2022 21:32:21 - INFO - __main__ - Step 410 Global step 410 Train loss 4.56 on epoch=29
05/29/2022 21:32:22 - INFO - __main__ - Step 420 Global step 420 Train loss 4.61 on epoch=29
05/29/2022 21:32:23 - INFO - __main__ - Step 430 Global step 430 Train loss 4.52 on epoch=30
05/29/2022 21:32:24 - INFO - __main__ - Step 440 Global step 440 Train loss 4.35 on epoch=31
05/29/2022 21:32:26 - INFO - __main__ - Step 450 Global step 450 Train loss 4.37 on epoch=32
05/29/2022 21:32:28 - INFO - __main__ - Global step 450 Train loss 4.48 Classification-F1 0.009523809523809523 on epoch=32
05/29/2022 21:32:28 - INFO - __main__ - Saving model with best Classification-F1: 0.008963585434173669 -> 0.009523809523809523 on epoch=32, global_step=450
05/29/2022 21:32:29 - INFO - __main__ - Step 460 Global step 460 Train loss 4.33 on epoch=32
05/29/2022 21:32:31 - INFO - __main__ - Step 470 Global step 470 Train loss 4.27 on epoch=33
05/29/2022 21:32:32 - INFO - __main__ - Step 480 Global step 480 Train loss 4.20 on epoch=34
05/29/2022 21:32:33 - INFO - __main__ - Step 490 Global step 490 Train loss 4.34 on epoch=34
05/29/2022 21:32:35 - INFO - __main__ - Step 500 Global step 500 Train loss 4.23 on epoch=35
05/29/2022 21:32:37 - INFO - __main__ - Global step 500 Train loss 4.27 Classification-F1 0.009523809523809523 on epoch=35
05/29/2022 21:32:38 - INFO - __main__ - Step 510 Global step 510 Train loss 4.02 on epoch=36
05/29/2022 21:32:39 - INFO - __main__ - Step 520 Global step 520 Train loss 4.16 on epoch=37
05/29/2022 21:32:41 - INFO - __main__ - Step 530 Global step 530 Train loss 3.99 on epoch=37
05/29/2022 21:32:42 - INFO - __main__ - Step 540 Global step 540 Train loss 4.02 on epoch=38
05/29/2022 21:32:43 - INFO - __main__ - Step 550 Global step 550 Train loss 3.70 on epoch=39
05/29/2022 21:32:45 - INFO - __main__ - Global step 550 Train loss 3.98 Classification-F1 0.009523809523809523 on epoch=39
05/29/2022 21:32:46 - INFO - __main__ - Step 560 Global step 560 Train loss 3.90 on epoch=39
05/29/2022 21:32:48 - INFO - __main__ - Step 570 Global step 570 Train loss 3.85 on epoch=40
05/29/2022 21:32:49 - INFO - __main__ - Step 580 Global step 580 Train loss 3.55 on epoch=41
05/29/2022 21:32:50 - INFO - __main__ - Step 590 Global step 590 Train loss 3.77 on epoch=42
05/29/2022 21:32:51 - INFO - __main__ - Step 600 Global step 600 Train loss 3.60 on epoch=42
05/29/2022 21:32:53 - INFO - __main__ - Global step 600 Train loss 3.74 Classification-F1 0.024729891956782712 on epoch=42
05/29/2022 21:32:53 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024729891956782712 on epoch=42, global_step=600
05/29/2022 21:32:55 - INFO - __main__ - Step 610 Global step 610 Train loss 3.61 on epoch=43
05/29/2022 21:32:56 - INFO - __main__ - Step 620 Global step 620 Train loss 3.52 on epoch=44
05/29/2022 21:32:57 - INFO - __main__ - Step 630 Global step 630 Train loss 3.61 on epoch=44
05/29/2022 21:32:59 - INFO - __main__ - Step 640 Global step 640 Train loss 3.70 on epoch=45
05/29/2022 21:33:00 - INFO - __main__ - Step 650 Global step 650 Train loss 3.41 on epoch=46
05/29/2022 21:33:02 - INFO - __main__ - Global step 650 Train loss 3.57 Classification-F1 0.04756188189561539 on epoch=46
05/29/2022 21:33:02 - INFO - __main__ - Saving model with best Classification-F1: 0.024729891956782712 -> 0.04756188189561539 on epoch=46, global_step=650
05/29/2022 21:33:03 - INFO - __main__ - Step 660 Global step 660 Train loss 3.54 on epoch=47
05/29/2022 21:33:04 - INFO - __main__ - Step 670 Global step 670 Train loss 3.50 on epoch=47
05/29/2022 21:33:06 - INFO - __main__ - Step 680 Global step 680 Train loss 3.51 on epoch=48
05/29/2022 21:33:07 - INFO - __main__ - Step 690 Global step 690 Train loss 3.37 on epoch=49
05/29/2022 21:33:08 - INFO - __main__ - Step 700 Global step 700 Train loss 3.30 on epoch=49
05/29/2022 21:33:10 - INFO - __main__ - Global step 700 Train loss 3.44 Classification-F1 0.022575037920306462 on epoch=49
05/29/2022 21:33:11 - INFO - __main__ - Step 710 Global step 710 Train loss 3.44 on epoch=50
05/29/2022 21:33:13 - INFO - __main__ - Step 720 Global step 720 Train loss 3.18 on epoch=51
05/29/2022 21:33:14 - INFO - __main__ - Step 730 Global step 730 Train loss 3.42 on epoch=52
05/29/2022 21:33:15 - INFO - __main__ - Step 740 Global step 740 Train loss 3.30 on epoch=52
05/29/2022 21:33:16 - INFO - __main__ - Step 750 Global step 750 Train loss 3.18 on epoch=53
05/29/2022 21:33:18 - INFO - __main__ - Global step 750 Train loss 3.30 Classification-F1 0.01392136603404209 on epoch=53
05/29/2022 21:33:20 - INFO - __main__ - Step 760 Global step 760 Train loss 3.13 on epoch=54
05/29/2022 21:33:21 - INFO - __main__ - Step 770 Global step 770 Train loss 3.16 on epoch=54
05/29/2022 21:33:22 - INFO - __main__ - Step 780 Global step 780 Train loss 3.22 on epoch=55
05/29/2022 21:33:24 - INFO - __main__ - Step 790 Global step 790 Train loss 3.00 on epoch=56
05/29/2022 21:33:25 - INFO - __main__ - Step 800 Global step 800 Train loss 3.11 on epoch=57
05/29/2022 21:33:27 - INFO - __main__ - Global step 800 Train loss 3.12 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 21:33:28 - INFO - __main__ - Step 810 Global step 810 Train loss 3.14 on epoch=57
05/29/2022 21:33:29 - INFO - __main__ - Step 820 Global step 820 Train loss 3.12 on epoch=58
05/29/2022 21:33:30 - INFO - __main__ - Step 830 Global step 830 Train loss 3.00 on epoch=59
05/29/2022 21:33:32 - INFO - __main__ - Step 840 Global step 840 Train loss 3.10 on epoch=59
05/29/2022 21:33:33 - INFO - __main__ - Step 850 Global step 850 Train loss 3.22 on epoch=60
05/29/2022 21:33:35 - INFO - __main__ - Global step 850 Train loss 3.12 Classification-F1 0.04542263713996236 on epoch=60
05/29/2022 21:33:36 - INFO - __main__ - Step 860 Global step 860 Train loss 2.91 on epoch=61
05/29/2022 21:33:37 - INFO - __main__ - Step 870 Global step 870 Train loss 3.11 on epoch=62
05/29/2022 21:33:39 - INFO - __main__ - Step 880 Global step 880 Train loss 2.95 on epoch=62
05/29/2022 21:33:40 - INFO - __main__ - Step 890 Global step 890 Train loss 2.91 on epoch=63
05/29/2022 21:33:41 - INFO - __main__ - Step 900 Global step 900 Train loss 2.98 on epoch=64
05/29/2022 21:33:43 - INFO - __main__ - Global step 900 Train loss 2.97 Classification-F1 0.016965179052456817 on epoch=64
05/29/2022 21:33:44 - INFO - __main__ - Step 910 Global step 910 Train loss 2.89 on epoch=64
05/29/2022 21:33:46 - INFO - __main__ - Step 920 Global step 920 Train loss 3.02 on epoch=65
05/29/2022 21:33:47 - INFO - __main__ - Step 930 Global step 930 Train loss 2.87 on epoch=66
05/29/2022 21:33:48 - INFO - __main__ - Step 940 Global step 940 Train loss 2.94 on epoch=67
05/29/2022 21:33:50 - INFO - __main__ - Step 950 Global step 950 Train loss 2.86 on epoch=67
05/29/2022 21:33:52 - INFO - __main__ - Global step 950 Train loss 2.91 Classification-F1 0.026761069391260155 on epoch=67
05/29/2022 21:33:53 - INFO - __main__ - Step 960 Global step 960 Train loss 2.97 on epoch=68
05/29/2022 21:33:54 - INFO - __main__ - Step 970 Global step 970 Train loss 2.82 on epoch=69
05/29/2022 21:33:55 - INFO - __main__ - Step 980 Global step 980 Train loss 2.88 on epoch=69
05/29/2022 21:33:57 - INFO - __main__ - Step 990 Global step 990 Train loss 2.94 on epoch=70
05/29/2022 21:33:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 2.70 on epoch=71
05/29/2022 21:34:00 - INFO - __main__ - Global step 1000 Train loss 2.86 Classification-F1 0.014221829082510197 on epoch=71
05/29/2022 21:34:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 2.86 on epoch=72
05/29/2022 21:34:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 2.68 on epoch=72
05/29/2022 21:34:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 2.92 on epoch=73
05/29/2022 21:34:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 2.84 on epoch=74
05/29/2022 21:34:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 2.80 on epoch=74
05/29/2022 21:34:08 - INFO - __main__ - Global step 1050 Train loss 2.82 Classification-F1 0.02734234866563723 on epoch=74
05/29/2022 21:34:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 2.84 on epoch=75
05/29/2022 21:34:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 2.73 on epoch=76
05/29/2022 21:34:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 2.78 on epoch=77
05/29/2022 21:34:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.60 on epoch=77
05/29/2022 21:34:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.66 on epoch=78
05/29/2022 21:34:16 - INFO - __main__ - Global step 1100 Train loss 2.72 Classification-F1 0.024704618689581095 on epoch=78
05/29/2022 21:34:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 2.72 on epoch=79
05/29/2022 21:34:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.81 on epoch=79
05/29/2022 21:34:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 2.75 on epoch=80
05/29/2022 21:34:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.71 on epoch=81
05/29/2022 21:34:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 2.79 on epoch=82
05/29/2022 21:34:25 - INFO - __main__ - Global step 1150 Train loss 2.76 Classification-F1 0.0717237184952866 on epoch=82
05/29/2022 21:34:25 - INFO - __main__ - Saving model with best Classification-F1: 0.04756188189561539 -> 0.0717237184952866 on epoch=82, global_step=1150
05/29/2022 21:34:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 2.78 on epoch=82
05/29/2022 21:34:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.73 on epoch=83
05/29/2022 21:34:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 2.78 on epoch=84
05/29/2022 21:34:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.63 on epoch=84
05/29/2022 21:34:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 2.70 on epoch=85
05/29/2022 21:34:33 - INFO - __main__ - Global step 1200 Train loss 2.73 Classification-F1 0.07011087263188104 on epoch=85
05/29/2022 21:34:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.76 on epoch=86
05/29/2022 21:34:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 2.83 on epoch=87
05/29/2022 21:34:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.64 on epoch=87
05/29/2022 21:34:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.63 on epoch=88
05/29/2022 21:34:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.46 on epoch=89
05/29/2022 21:34:41 - INFO - __main__ - Global step 1250 Train loss 2.67 Classification-F1 0.04789395677949894 on epoch=89
05/29/2022 21:34:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.53 on epoch=89
05/29/2022 21:34:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 2.55 on epoch=90
05/29/2022 21:34:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.51 on epoch=91
05/29/2022 21:34:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.63 on epoch=92
05/29/2022 21:34:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.61 on epoch=92
05/29/2022 21:34:50 - INFO - __main__ - Global step 1300 Train loss 2.57 Classification-F1 0.009523809523809523 on epoch=92
05/29/2022 21:34:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.56 on epoch=93
05/29/2022 21:34:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.48 on epoch=94
05/29/2022 21:34:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.44 on epoch=94
05/29/2022 21:34:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.65 on epoch=95
05/29/2022 21:34:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.47 on epoch=96
05/29/2022 21:34:58 - INFO - __main__ - Global step 1350 Train loss 2.52 Classification-F1 0.039384214372349166 on epoch=96
05/29/2022 21:34:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.57 on epoch=97
05/29/2022 21:35:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.60 on epoch=97
05/29/2022 21:35:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.54 on epoch=98
05/29/2022 21:35:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.54 on epoch=99
05/29/2022 21:35:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.53 on epoch=99
05/29/2022 21:35:06 - INFO - __main__ - Global step 1400 Train loss 2.55 Classification-F1 0.04631297964631298 on epoch=99
05/29/2022 21:35:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.46 on epoch=100
05/29/2022 21:35:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.47 on epoch=101
05/29/2022 21:35:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.71 on epoch=102
05/29/2022 21:35:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.41 on epoch=102
05/29/2022 21:35:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.49 on epoch=103
05/29/2022 21:35:15 - INFO - __main__ - Global step 1450 Train loss 2.51 Classification-F1 0.04603658819275097 on epoch=103
05/29/2022 21:35:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.60 on epoch=104
05/29/2022 21:35:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.42 on epoch=104
05/29/2022 21:35:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.56 on epoch=105
05/29/2022 21:35:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.44 on epoch=106
05/29/2022 21:35:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.36 on epoch=107
05/29/2022 21:35:23 - INFO - __main__ - Global step 1500 Train loss 2.48 Classification-F1 0.04733882464028138 on epoch=107
05/29/2022 21:35:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.61 on epoch=107
05/29/2022 21:35:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.27 on epoch=108
05/29/2022 21:35:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.30 on epoch=109
05/29/2022 21:35:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.30 on epoch=109
05/29/2022 21:35:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.47 on epoch=110
05/29/2022 21:35:31 - INFO - __main__ - Global step 1550 Train loss 2.39 Classification-F1 0.04896407962842083 on epoch=110
05/29/2022 21:35:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.29 on epoch=111
05/29/2022 21:35:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.40 on epoch=112
05/29/2022 21:35:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.36 on epoch=112
05/29/2022 21:35:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.31 on epoch=113
05/29/2022 21:35:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.28 on epoch=114
05/29/2022 21:35:40 - INFO - __main__ - Global step 1600 Train loss 2.33 Classification-F1 0.03653731421499494 on epoch=114
05/29/2022 21:35:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.28 on epoch=114
05/29/2022 21:35:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.47 on epoch=115
05/29/2022 21:35:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.27 on epoch=116
05/29/2022 21:35:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.42 on epoch=117
05/29/2022 21:35:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.25 on epoch=117
05/29/2022 21:35:48 - INFO - __main__ - Global step 1650 Train loss 2.34 Classification-F1 0.025097956158000638 on epoch=117
05/29/2022 21:35:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.33 on epoch=118
05/29/2022 21:35:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.28 on epoch=119
05/29/2022 21:35:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.33 on epoch=119
05/29/2022 21:35:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.31 on epoch=120
05/29/2022 21:35:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.28 on epoch=121
05/29/2022 21:35:57 - INFO - __main__ - Global step 1700 Train loss 2.30 Classification-F1 0.018132626184802277 on epoch=121
05/29/2022 21:35:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.33 on epoch=122
05/29/2022 21:36:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.27 on epoch=122
05/29/2022 21:36:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.37 on epoch=123
05/29/2022 21:36:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.13 on epoch=124
05/29/2022 21:36:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.15 on epoch=124
05/29/2022 21:36:07 - INFO - __main__ - Global step 1750 Train loss 2.25 Classification-F1 0.05229575178641393 on epoch=124
05/29/2022 21:36:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.26 on epoch=125
05/29/2022 21:36:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.27 on epoch=126
05/29/2022 21:36:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.25 on epoch=127
05/29/2022 21:36:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.09 on epoch=127
05/29/2022 21:36:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.09 on epoch=128
05/29/2022 21:36:16 - INFO - __main__ - Global step 1800 Train loss 2.19 Classification-F1 0.017662951705504897 on epoch=128
05/29/2022 21:36:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.20 on epoch=129
05/29/2022 21:36:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.28 on epoch=129
05/29/2022 21:36:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.25 on epoch=130
05/29/2022 21:36:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.19 on epoch=131
05/29/2022 21:36:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.30 on epoch=132
05/29/2022 21:36:25 - INFO - __main__ - Global step 1850 Train loss 2.24 Classification-F1 0.07346803058325077 on epoch=132
05/29/2022 21:36:25 - INFO - __main__ - Saving model with best Classification-F1: 0.0717237184952866 -> 0.07346803058325077 on epoch=132, global_step=1850
05/29/2022 21:36:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.29 on epoch=132
05/29/2022 21:36:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.32 on epoch=133
05/29/2022 21:36:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.22 on epoch=134
05/29/2022 21:36:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.26 on epoch=134
05/29/2022 21:36:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.26 on epoch=135
05/29/2022 21:36:33 - INFO - __main__ - Global step 1900 Train loss 2.27 Classification-F1 0.04010450333979746 on epoch=135
05/29/2022 21:36:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.15 on epoch=136
05/29/2022 21:36:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.20 on epoch=137
05/29/2022 21:36:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.06 on epoch=137
05/29/2022 21:36:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.24 on epoch=138
05/29/2022 21:36:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.13 on epoch=139
05/29/2022 21:36:42 - INFO - __main__ - Global step 1950 Train loss 2.16 Classification-F1 0.03805075419622878 on epoch=139
05/29/2022 21:36:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.10 on epoch=139
05/29/2022 21:36:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.20 on epoch=140
05/29/2022 21:36:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.15 on epoch=141
05/29/2022 21:36:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.23 on epoch=142
05/29/2022 21:36:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.11 on epoch=142
05/29/2022 21:36:50 - INFO - __main__ - Global step 2000 Train loss 2.16 Classification-F1 0.03984319773793458 on epoch=142
05/29/2022 21:36:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.06 on epoch=143
05/29/2022 21:36:52 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.14 on epoch=144
05/29/2022 21:36:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.17 on epoch=144
05/29/2022 21:36:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.14 on epoch=145
05/29/2022 21:36:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.03 on epoch=146
05/29/2022 21:36:58 - INFO - __main__ - Global step 2050 Train loss 2.11 Classification-F1 0.03137844724172507 on epoch=146
05/29/2022 21:36:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.29 on epoch=147
05/29/2022 21:37:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.09 on epoch=147
05/29/2022 21:37:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.00 on epoch=148
05/29/2022 21:37:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.02 on epoch=149
05/29/2022 21:37:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.09 on epoch=149
05/29/2022 21:37:06 - INFO - __main__ - Global step 2100 Train loss 2.10 Classification-F1 0.05099846390168971 on epoch=149
05/29/2022 21:37:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.14 on epoch=150
05/29/2022 21:37:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.04 on epoch=151
05/29/2022 21:37:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.04 on epoch=152
05/29/2022 21:37:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.16 on epoch=152
05/29/2022 21:37:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.13 on epoch=153
05/29/2022 21:37:15 - INFO - __main__ - Global step 2150 Train loss 2.10 Classification-F1 0.009523809523809523 on epoch=153
05/29/2022 21:37:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.10 on epoch=154
05/29/2022 21:37:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.06 on epoch=154
05/29/2022 21:37:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.06 on epoch=155
05/29/2022 21:37:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.00 on epoch=156
05/29/2022 21:37:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.05 on epoch=157
05/29/2022 21:37:23 - INFO - __main__ - Global step 2200 Train loss 2.06 Classification-F1 0.022799860514724015 on epoch=157
05/29/2022 21:37:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.08 on epoch=157
05/29/2022 21:37:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.20 on epoch=158
05/29/2022 21:37:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.95 on epoch=159
05/29/2022 21:37:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.02 on epoch=159
05/29/2022 21:37:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.01 on epoch=160
05/29/2022 21:37:31 - INFO - __main__ - Global step 2250 Train loss 2.05 Classification-F1 0.015995994413260602 on epoch=160
05/29/2022 21:37:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.99 on epoch=161
05/29/2022 21:37:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.04 on epoch=162
05/29/2022 21:37:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.04 on epoch=162
05/29/2022 21:37:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.87 on epoch=163
05/29/2022 21:37:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.01 on epoch=164
05/29/2022 21:37:40 - INFO - __main__ - Global step 2300 Train loss 1.99 Classification-F1 0.014995334302641003 on epoch=164
05/29/2022 21:37:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.09 on epoch=164
05/29/2022 21:37:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.83 on epoch=165
05/29/2022 21:37:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.98 on epoch=166
05/29/2022 21:37:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.93 on epoch=167
05/29/2022 21:37:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.96 on epoch=167
05/29/2022 21:37:48 - INFO - __main__ - Global step 2350 Train loss 1.96 Classification-F1 0.028196969402999556 on epoch=167
05/29/2022 21:37:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.04 on epoch=168
05/29/2022 21:37:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.94 on epoch=169
05/29/2022 21:37:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.00 on epoch=169
05/29/2022 21:37:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.03 on epoch=170
05/29/2022 21:37:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.99 on epoch=171
05/29/2022 21:37:56 - INFO - __main__ - Global step 2400 Train loss 2.00 Classification-F1 0.027810728277003188 on epoch=171
05/29/2022 21:37:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.97 on epoch=172
05/29/2022 21:37:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.88 on epoch=172
05/29/2022 21:38:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.94 on epoch=173
05/29/2022 21:38:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 1.82 on epoch=174
05/29/2022 21:38:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.85 on epoch=174
05/29/2022 21:38:05 - INFO - __main__ - Global step 2450 Train loss 1.89 Classification-F1 0.009603841536614645 on epoch=174
05/29/2022 21:38:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.97 on epoch=175
05/29/2022 21:38:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.86 on epoch=176
05/29/2022 21:38:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.95 on epoch=177
05/29/2022 21:38:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.95 on epoch=177
05/29/2022 21:38:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 1.97 on epoch=178
05/29/2022 21:38:13 - INFO - __main__ - Global step 2500 Train loss 1.94 Classification-F1 0.05139314562064986 on epoch=178
05/29/2022 21:38:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.81 on epoch=179
05/29/2022 21:38:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.97 on epoch=179
05/29/2022 21:38:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 1.85 on epoch=180
05/29/2022 21:38:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.79 on epoch=181
05/29/2022 21:38:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.75 on epoch=182
05/29/2022 21:38:21 - INFO - __main__ - Global step 2550 Train loss 1.83 Classification-F1 0.02613400037812132 on epoch=182
05/29/2022 21:38:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.78 on epoch=182
05/29/2022 21:38:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.88 on epoch=183
05/29/2022 21:38:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.94 on epoch=184
05/29/2022 21:38:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.87 on epoch=184
05/29/2022 21:38:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.88 on epoch=185
05/29/2022 21:38:29 - INFO - __main__ - Global step 2600 Train loss 1.87 Classification-F1 0.021771609428138945 on epoch=185
05/29/2022 21:38:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.88 on epoch=186
05/29/2022 21:38:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.85 on epoch=187
05/29/2022 21:38:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.83 on epoch=187
05/29/2022 21:38:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 1.74 on epoch=188
05/29/2022 21:38:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.86 on epoch=189
05/29/2022 21:38:37 - INFO - __main__ - Global step 2650 Train loss 1.83 Classification-F1 0.02977867203219316 on epoch=189
05/29/2022 21:38:38 - INFO - __main__ - Step 2660 Global step 2660 Train loss 1.96 on epoch=189
05/29/2022 21:38:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 1.73 on epoch=190
05/29/2022 21:38:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 1.89 on epoch=191
05/29/2022 21:38:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.84 on epoch=192
05/29/2022 21:38:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.77 on epoch=192
05/29/2022 21:38:45 - INFO - __main__ - Global step 2700 Train loss 1.84 Classification-F1 0.03324269682217117 on epoch=192
05/29/2022 21:38:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 1.71 on epoch=193
05/29/2022 21:38:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.75 on epoch=194
05/29/2022 21:38:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.00 on epoch=194
05/29/2022 21:38:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.74 on epoch=195
05/29/2022 21:38:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.77 on epoch=196
05/29/2022 21:38:54 - INFO - __main__ - Global step 2750 Train loss 1.79 Classification-F1 0.05477356600952106 on epoch=196
05/29/2022 21:38:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.69 on epoch=197
05/29/2022 21:38:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 1.90 on epoch=197
05/29/2022 21:38:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 1.64 on epoch=198
05/29/2022 21:38:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 1.87 on epoch=199
05/29/2022 21:39:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.73 on epoch=199
05/29/2022 21:39:02 - INFO - __main__ - Global step 2800 Train loss 1.77 Classification-F1 0.0630140518787636 on epoch=199
05/29/2022 21:39:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 1.70 on epoch=200
05/29/2022 21:39:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.80 on epoch=201
05/29/2022 21:39:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 1.73 on epoch=202
05/29/2022 21:39:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 1.73 on epoch=202
05/29/2022 21:39:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.71 on epoch=203
05/29/2022 21:39:10 - INFO - __main__ - Global step 2850 Train loss 1.74 Classification-F1 0.04603778535817371 on epoch=203
05/29/2022 21:39:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 1.63 on epoch=204
05/29/2022 21:39:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 1.70 on epoch=204
05/29/2022 21:39:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.75 on epoch=205
05/29/2022 21:39:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.80 on epoch=206
05/29/2022 21:39:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 1.82 on epoch=207
05/29/2022 21:39:19 - INFO - __main__ - Global step 2900 Train loss 1.74 Classification-F1 0.03289108058393018 on epoch=207
05/29/2022 21:39:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.73 on epoch=207
05/29/2022 21:39:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 1.65 on epoch=208
05/29/2022 21:39:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 1.84 on epoch=209
05/29/2022 21:39:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 1.69 on epoch=209
05/29/2022 21:39:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.68 on epoch=210
05/29/2022 21:39:27 - INFO - __main__ - Global step 2950 Train loss 1.72 Classification-F1 0.049508387226489745 on epoch=210
05/29/2022 21:39:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 1.75 on epoch=211
05/29/2022 21:39:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.73 on epoch=212
05/29/2022 21:39:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.62 on epoch=212
05/29/2022 21:39:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.86 on epoch=213
05/29/2022 21:39:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.71 on epoch=214
05/29/2022 21:39:35 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:39:35 - INFO - __main__ - Printing 3 examples
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 21:39:35 - INFO - __main__ - ['Film']
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 21:39:35 - INFO - __main__ - ['Film']
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 21:39:35 - INFO - __main__ - ['Film']
05/29/2022 21:39:35 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:39:35 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:39:35 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:39:35 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:39:35 - INFO - __main__ - Printing 3 examples
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 21:39:35 - INFO - __main__ - ['Film']
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 21:39:35 - INFO - __main__ - ['Film']
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 21:39:35 - INFO - __main__ - ['Film']
05/29/2022 21:39:35 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:39:35 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:39:35 - INFO - __main__ - Global step 3000 Train loss 1.73 Classification-F1 0.013777818819835624 on epoch=214
05/29/2022 21:39:35 - INFO - __main__ - save last model!
05/29/2022 21:39:35 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:39:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 21:39:35 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 21:39:35 - INFO - __main__ - Printing 3 examples
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 21:39:35 - INFO - __main__ - ['Animal']
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 21:39:35 - INFO - __main__ - ['Animal']
05/29/2022 21:39:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 21:39:35 - INFO - __main__ - ['Village']
05/29/2022 21:39:35 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:39:37 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:39:41 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 21:39:41 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:39:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:39:42 - INFO - __main__ - Starting training!
05/29/2022 21:40:12 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/29/2022 21:40:12 - INFO - __main__ - Classification-F1 on test data: 0.0174
05/29/2022 21:40:12 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.07346803058325077, test_performance=0.017445121297461487
05/29/2022 21:40:12 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/29/2022 21:40:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:40:13 - INFO - __main__ - Printing 3 examples
05/29/2022 21:40:13 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 21:40:13 - INFO - __main__ - ['Film']
05/29/2022 21:40:13 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 21:40:13 - INFO - __main__ - ['Film']
05/29/2022 21:40:13 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 21:40:13 - INFO - __main__ - ['Film']
05/29/2022 21:40:13 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:40:13 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:40:13 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:40:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:40:13 - INFO - __main__ - Printing 3 examples
05/29/2022 21:40:13 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 21:40:13 - INFO - __main__ - ['Film']
05/29/2022 21:40:13 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 21:40:13 - INFO - __main__ - ['Film']
05/29/2022 21:40:13 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 21:40:13 - INFO - __main__ - ['Film']
05/29/2022 21:40:13 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:40:13 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:40:13 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:40:19 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:40:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:40:19 - INFO - __main__ - Starting training!
05/29/2022 21:40:21 - INFO - __main__ - Step 10 Global step 10 Train loss 7.36 on epoch=0
05/29/2022 21:40:22 - INFO - __main__ - Step 20 Global step 20 Train loss 7.47 on epoch=1
05/29/2022 21:40:24 - INFO - __main__ - Step 30 Global step 30 Train loss 7.10 on epoch=2
05/29/2022 21:40:25 - INFO - __main__ - Step 40 Global step 40 Train loss 7.12 on epoch=2
05/29/2022 21:40:26 - INFO - __main__ - Step 50 Global step 50 Train loss 6.78 on epoch=3
05/29/2022 21:40:49 - INFO - __main__ - Global step 50 Train loss 7.17 Classification-F1 0.0 on epoch=3
05/29/2022 21:40:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 21:40:50 - INFO - __main__ - Step 60 Global step 60 Train loss 6.60 on epoch=4
05/29/2022 21:40:51 - INFO - __main__ - Step 70 Global step 70 Train loss 6.66 on epoch=4
05/29/2022 21:40:53 - INFO - __main__ - Step 80 Global step 80 Train loss 6.56 on epoch=5
05/29/2022 21:40:54 - INFO - __main__ - Step 90 Global step 90 Train loss 6.54 on epoch=6
05/29/2022 21:40:55 - INFO - __main__ - Step 100 Global step 100 Train loss 6.28 on epoch=7
05/29/2022 21:41:59 - INFO - __main__ - Global step 100 Train loss 6.53 Classification-F1 0.0 on epoch=7
05/29/2022 21:42:01 - INFO - __main__ - Step 110 Global step 110 Train loss 6.34 on epoch=7
05/29/2022 21:42:02 - INFO - __main__ - Step 120 Global step 120 Train loss 6.14 on epoch=8
05/29/2022 21:42:03 - INFO - __main__ - Step 130 Global step 130 Train loss 5.97 on epoch=9
05/29/2022 21:42:04 - INFO - __main__ - Step 140 Global step 140 Train loss 6.18 on epoch=9
05/29/2022 21:42:06 - INFO - __main__ - Step 150 Global step 150 Train loss 6.09 on epoch=10
05/29/2022 21:43:11 - INFO - __main__ - Global step 150 Train loss 6.14 Classification-F1 0.0 on epoch=10
05/29/2022 21:43:12 - INFO - __main__ - Step 160 Global step 160 Train loss 6.10 on epoch=11
05/29/2022 21:43:13 - INFO - __main__ - Step 170 Global step 170 Train loss 5.93 on epoch=12
05/29/2022 21:43:15 - INFO - __main__ - Step 180 Global step 180 Train loss 5.97 on epoch=12
05/29/2022 21:43:16 - INFO - __main__ - Step 190 Global step 190 Train loss 5.72 on epoch=13
05/29/2022 21:43:17 - INFO - __main__ - Step 200 Global step 200 Train loss 5.78 on epoch=14
05/29/2022 21:44:29 - INFO - __main__ - Global step 200 Train loss 5.90 Classification-F1 0.0 on epoch=14
05/29/2022 21:44:30 - INFO - __main__ - Step 210 Global step 210 Train loss 5.86 on epoch=14
05/29/2022 21:44:31 - INFO - __main__ - Step 220 Global step 220 Train loss 5.79 on epoch=15
05/29/2022 21:44:32 - INFO - __main__ - Step 230 Global step 230 Train loss 5.92 on epoch=16
05/29/2022 21:44:34 - INFO - __main__ - Step 240 Global step 240 Train loss 5.60 on epoch=17
05/29/2022 21:44:35 - INFO - __main__ - Step 250 Global step 250 Train loss 5.54 on epoch=17
05/29/2022 21:45:19 - INFO - __main__ - Global step 250 Train loss 5.74 Classification-F1 0.0 on epoch=17
05/29/2022 21:45:20 - INFO - __main__ - Step 260 Global step 260 Train loss 5.58 on epoch=18
05/29/2022 21:45:22 - INFO - __main__ - Step 270 Global step 270 Train loss 5.52 on epoch=19
05/29/2022 21:45:23 - INFO - __main__ - Step 280 Global step 280 Train loss 5.63 on epoch=19
05/29/2022 21:45:25 - INFO - __main__ - Step 290 Global step 290 Train loss 5.53 on epoch=20
05/29/2022 21:45:26 - INFO - __main__ - Step 300 Global step 300 Train loss 5.43 on epoch=21
05/29/2022 21:45:42 - INFO - __main__ - Global step 300 Train loss 5.54 Classification-F1 0.0 on epoch=21
05/29/2022 21:45:44 - INFO - __main__ - Step 310 Global step 310 Train loss 5.36 on epoch=22
05/29/2022 21:45:45 - INFO - __main__ - Step 320 Global step 320 Train loss 5.50 on epoch=22
05/29/2022 21:45:47 - INFO - __main__ - Step 330 Global step 330 Train loss 5.31 on epoch=23
05/29/2022 21:45:48 - INFO - __main__ - Step 340 Global step 340 Train loss 5.23 on epoch=24
05/29/2022 21:45:49 - INFO - __main__ - Step 350 Global step 350 Train loss 5.29 on epoch=24
05/29/2022 21:45:53 - INFO - __main__ - Global step 350 Train loss 5.34 Classification-F1 0.00538116591928251 on epoch=24
05/29/2022 21:45:53 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.00538116591928251 on epoch=24, global_step=350
05/29/2022 21:45:54 - INFO - __main__ - Step 360 Global step 360 Train loss 5.16 on epoch=25
05/29/2022 21:45:55 - INFO - __main__ - Step 370 Global step 370 Train loss 5.23 on epoch=26
05/29/2022 21:45:57 - INFO - __main__ - Step 380 Global step 380 Train loss 5.34 on epoch=27
05/29/2022 21:45:58 - INFO - __main__ - Step 390 Global step 390 Train loss 4.94 on epoch=27
05/29/2022 21:45:59 - INFO - __main__ - Step 400 Global step 400 Train loss 4.95 on epoch=28
05/29/2022 21:46:03 - INFO - __main__ - Global step 400 Train loss 5.12 Classification-F1 0.008438818565400845 on epoch=28
05/29/2022 21:46:03 - INFO - __main__ - Saving model with best Classification-F1: 0.00538116591928251 -> 0.008438818565400845 on epoch=28, global_step=400
05/29/2022 21:46:04 - INFO - __main__ - Step 410 Global step 410 Train loss 4.91 on epoch=29
05/29/2022 21:46:06 - INFO - __main__ - Step 420 Global step 420 Train loss 5.04 on epoch=29
05/29/2022 21:46:07 - INFO - __main__ - Step 430 Global step 430 Train loss 4.92 on epoch=30
05/29/2022 21:46:08 - INFO - __main__ - Step 440 Global step 440 Train loss 4.79 on epoch=31
05/29/2022 21:46:10 - INFO - __main__ - Step 450 Global step 450 Train loss 4.89 on epoch=32
05/29/2022 21:46:12 - INFO - __main__ - Global step 450 Train loss 4.91 Classification-F1 0.009523809523809523 on epoch=32
05/29/2022 21:46:12 - INFO - __main__ - Saving model with best Classification-F1: 0.008438818565400845 -> 0.009523809523809523 on epoch=32, global_step=450
05/29/2022 21:46:14 - INFO - __main__ - Step 460 Global step 460 Train loss 4.80 on epoch=32
05/29/2022 21:46:15 - INFO - __main__ - Step 470 Global step 470 Train loss 4.70 on epoch=33
05/29/2022 21:46:16 - INFO - __main__ - Step 480 Global step 480 Train loss 4.73 on epoch=34
05/29/2022 21:46:18 - INFO - __main__ - Step 490 Global step 490 Train loss 4.66 on epoch=34
05/29/2022 21:46:19 - INFO - __main__ - Step 500 Global step 500 Train loss 4.65 on epoch=35
05/29/2022 21:46:21 - INFO - __main__ - Global step 500 Train loss 4.71 Classification-F1 0.009523809523809523 on epoch=35
05/29/2022 21:46:23 - INFO - __main__ - Step 510 Global step 510 Train loss 4.50 on epoch=36
05/29/2022 21:46:24 - INFO - __main__ - Step 520 Global step 520 Train loss 4.69 on epoch=37
05/29/2022 21:46:25 - INFO - __main__ - Step 530 Global step 530 Train loss 4.44 on epoch=37
05/29/2022 21:46:27 - INFO - __main__ - Step 540 Global step 540 Train loss 4.41 on epoch=38
05/29/2022 21:46:28 - INFO - __main__ - Step 550 Global step 550 Train loss 4.46 on epoch=39
05/29/2022 21:46:30 - INFO - __main__ - Global step 550 Train loss 4.50 Classification-F1 0.009523809523809523 on epoch=39
05/29/2022 21:46:31 - INFO - __main__ - Step 560 Global step 560 Train loss 4.40 on epoch=39
05/29/2022 21:46:32 - INFO - __main__ - Step 570 Global step 570 Train loss 4.49 on epoch=40
05/29/2022 21:46:34 - INFO - __main__ - Step 580 Global step 580 Train loss 4.28 on epoch=41
05/29/2022 21:46:35 - INFO - __main__ - Step 590 Global step 590 Train loss 4.11 on epoch=42
05/29/2022 21:46:37 - INFO - __main__ - Step 600 Global step 600 Train loss 4.18 on epoch=42
05/29/2022 21:46:39 - INFO - __main__ - Global step 600 Train loss 4.29 Classification-F1 0.014082268421387245 on epoch=42
05/29/2022 21:46:39 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.014082268421387245 on epoch=42, global_step=600
05/29/2022 21:46:40 - INFO - __main__ - Step 610 Global step 610 Train loss 4.20 on epoch=43
05/29/2022 21:46:41 - INFO - __main__ - Step 620 Global step 620 Train loss 4.15 on epoch=44
05/29/2022 21:46:43 - INFO - __main__ - Step 630 Global step 630 Train loss 4.11 on epoch=44
05/29/2022 21:46:44 - INFO - __main__ - Step 640 Global step 640 Train loss 4.33 on epoch=45
05/29/2022 21:46:46 - INFO - __main__ - Step 650 Global step 650 Train loss 3.93 on epoch=46
05/29/2022 21:46:48 - INFO - __main__ - Global step 650 Train loss 4.14 Classification-F1 0.009696186166774399 on epoch=46
05/29/2022 21:46:49 - INFO - __main__ - Step 660 Global step 660 Train loss 4.14 on epoch=47
05/29/2022 21:46:50 - INFO - __main__ - Step 670 Global step 670 Train loss 4.04 on epoch=47
05/29/2022 21:46:52 - INFO - __main__ - Step 680 Global step 680 Train loss 3.97 on epoch=48
05/29/2022 21:46:53 - INFO - __main__ - Step 690 Global step 690 Train loss 3.96 on epoch=49
05/29/2022 21:46:54 - INFO - __main__ - Step 700 Global step 700 Train loss 3.91 on epoch=49
05/29/2022 21:46:56 - INFO - __main__ - Global step 700 Train loss 4.00 Classification-F1 0.016021112680937276 on epoch=49
05/29/2022 21:46:56 - INFO - __main__ - Saving model with best Classification-F1: 0.014082268421387245 -> 0.016021112680937276 on epoch=49, global_step=700
05/29/2022 21:46:58 - INFO - __main__ - Step 710 Global step 710 Train loss 3.92 on epoch=50
05/29/2022 21:46:59 - INFO - __main__ - Step 720 Global step 720 Train loss 3.76 on epoch=51
05/29/2022 21:47:01 - INFO - __main__ - Step 730 Global step 730 Train loss 3.83 on epoch=52
05/29/2022 21:47:02 - INFO - __main__ - Step 740 Global step 740 Train loss 3.84 on epoch=52
05/29/2022 21:47:04 - INFO - __main__ - Step 750 Global step 750 Train loss 3.83 on epoch=53
05/29/2022 21:47:06 - INFO - __main__ - Global step 750 Train loss 3.83 Classification-F1 0.022077595196145407 on epoch=53
05/29/2022 21:47:06 - INFO - __main__ - Saving model with best Classification-F1: 0.016021112680937276 -> 0.022077595196145407 on epoch=53, global_step=750
05/29/2022 21:47:07 - INFO - __main__ - Step 760 Global step 760 Train loss 3.67 on epoch=54
05/29/2022 21:47:08 - INFO - __main__ - Step 770 Global step 770 Train loss 3.57 on epoch=54
05/29/2022 21:47:10 - INFO - __main__ - Step 780 Global step 780 Train loss 3.81 on epoch=55
05/29/2022 21:47:11 - INFO - __main__ - Step 790 Global step 790 Train loss 3.66 on epoch=56
05/29/2022 21:47:12 - INFO - __main__ - Step 800 Global step 800 Train loss 3.46 on epoch=57
05/29/2022 21:47:14 - INFO - __main__ - Global step 800 Train loss 3.63 Classification-F1 0.009563658099222952 on epoch=57
05/29/2022 21:47:16 - INFO - __main__ - Step 810 Global step 810 Train loss 3.71 on epoch=57
05/29/2022 21:47:17 - INFO - __main__ - Step 820 Global step 820 Train loss 3.70 on epoch=58
05/29/2022 21:47:18 - INFO - __main__ - Step 830 Global step 830 Train loss 3.46 on epoch=59
05/29/2022 21:47:19 - INFO - __main__ - Step 840 Global step 840 Train loss 3.45 on epoch=59
05/29/2022 21:47:21 - INFO - __main__ - Step 850 Global step 850 Train loss 3.67 on epoch=60
05/29/2022 21:47:23 - INFO - __main__ - Global step 850 Train loss 3.60 Classification-F1 0.015243052328283296 on epoch=60
05/29/2022 21:47:24 - INFO - __main__ - Step 860 Global step 860 Train loss 3.34 on epoch=61
05/29/2022 21:47:25 - INFO - __main__ - Step 870 Global step 870 Train loss 3.45 on epoch=62
05/29/2022 21:47:27 - INFO - __main__ - Step 880 Global step 880 Train loss 3.44 on epoch=62
05/29/2022 21:47:28 - INFO - __main__ - Step 890 Global step 890 Train loss 3.37 on epoch=63
05/29/2022 21:47:29 - INFO - __main__ - Step 900 Global step 900 Train loss 3.28 on epoch=64
05/29/2022 21:47:31 - INFO - __main__ - Global step 900 Train loss 3.38 Classification-F1 0.008965929468021518 on epoch=64
05/29/2022 21:47:32 - INFO - __main__ - Step 910 Global step 910 Train loss 3.21 on epoch=64
05/29/2022 21:47:34 - INFO - __main__ - Step 920 Global step 920 Train loss 3.44 on epoch=65
05/29/2022 21:47:35 - INFO - __main__ - Step 930 Global step 930 Train loss 3.24 on epoch=66
05/29/2022 21:47:36 - INFO - __main__ - Step 940 Global step 940 Train loss 3.29 on epoch=67
05/29/2022 21:47:37 - INFO - __main__ - Step 950 Global step 950 Train loss 3.31 on epoch=67
05/29/2022 21:47:39 - INFO - __main__ - Global step 950 Train loss 3.30 Classification-F1 0.017540349473122583 on epoch=67
05/29/2022 21:47:41 - INFO - __main__ - Step 960 Global step 960 Train loss 3.22 on epoch=68
05/29/2022 21:47:42 - INFO - __main__ - Step 970 Global step 970 Train loss 3.28 on epoch=69
05/29/2022 21:47:43 - INFO - __main__ - Step 980 Global step 980 Train loss 2.96 on epoch=69
05/29/2022 21:47:45 - INFO - __main__ - Step 990 Global step 990 Train loss 3.24 on epoch=70
05/29/2022 21:47:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.15 on epoch=71
05/29/2022 21:47:48 - INFO - __main__ - Global step 1000 Train loss 3.17 Classification-F1 0.01216579655117861 on epoch=71
05/29/2022 21:47:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.22 on epoch=72
05/29/2022 21:47:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.15 on epoch=72
05/29/2022 21:47:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.14 on epoch=73
05/29/2022 21:47:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.25 on epoch=74
05/29/2022 21:47:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.03 on epoch=74
05/29/2022 21:47:56 - INFO - __main__ - Global step 1050 Train loss 3.16 Classification-F1 0.029260582241872675 on epoch=74
05/29/2022 21:47:56 - INFO - __main__ - Saving model with best Classification-F1: 0.022077595196145407 -> 0.029260582241872675 on epoch=74, global_step=1050
05/29/2022 21:47:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.15 on epoch=75
05/29/2022 21:47:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.14 on epoch=76
05/29/2022 21:48:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.01 on epoch=77
05/29/2022 21:48:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 2.96 on epoch=77
05/29/2022 21:48:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 2.94 on epoch=78
05/29/2022 21:48:05 - INFO - __main__ - Global step 1100 Train loss 3.04 Classification-F1 0.016664141796697472 on epoch=78
05/29/2022 21:48:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.00 on epoch=79
05/29/2022 21:48:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 2.92 on epoch=79
05/29/2022 21:48:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.11 on epoch=80
05/29/2022 21:48:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 2.85 on epoch=81
05/29/2022 21:48:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.03 on epoch=82
05/29/2022 21:48:13 - INFO - __main__ - Global step 1150 Train loss 2.98 Classification-F1 0.0228843736908253 on epoch=82
05/29/2022 21:48:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.03 on epoch=82
05/29/2022 21:48:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 2.95 on epoch=83
05/29/2022 21:48:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.01 on epoch=84
05/29/2022 21:48:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 2.84 on epoch=84
05/29/2022 21:48:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.00 on epoch=85
05/29/2022 21:48:22 - INFO - __main__ - Global step 1200 Train loss 2.97 Classification-F1 0.025842115775498452 on epoch=85
05/29/2022 21:48:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 2.95 on epoch=86
05/29/2022 21:48:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.05 on epoch=87
05/29/2022 21:48:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 2.88 on epoch=87
05/29/2022 21:48:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 2.94 on epoch=88
05/29/2022 21:48:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 2.75 on epoch=89
05/29/2022 21:48:30 - INFO - __main__ - Global step 1250 Train loss 2.92 Classification-F1 0.041557699594084174 on epoch=89
05/29/2022 21:48:30 - INFO - __main__ - Saving model with best Classification-F1: 0.029260582241872675 -> 0.041557699594084174 on epoch=89, global_step=1250
05/29/2022 21:48:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 2.86 on epoch=89
05/29/2022 21:48:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.00 on epoch=90
05/29/2022 21:48:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 2.83 on epoch=91
05/29/2022 21:48:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 2.91 on epoch=92
05/29/2022 21:48:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 2.89 on epoch=92
05/29/2022 21:48:39 - INFO - __main__ - Global step 1300 Train loss 2.90 Classification-F1 0.04131000578368999 on epoch=92
05/29/2022 21:48:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 2.96 on epoch=93
05/29/2022 21:48:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 2.66 on epoch=94
05/29/2022 21:48:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 2.82 on epoch=94
05/29/2022 21:48:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 2.96 on epoch=95
05/29/2022 21:48:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 2.81 on epoch=96
05/29/2022 21:48:47 - INFO - __main__ - Global step 1350 Train loss 2.84 Classification-F1 0.034306198438578926 on epoch=96
05/29/2022 21:48:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 2.87 on epoch=97
05/29/2022 21:48:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 2.82 on epoch=97
05/29/2022 21:48:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.86 on epoch=98
05/29/2022 21:48:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 2.82 on epoch=99
05/29/2022 21:48:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 2.63 on epoch=99
05/29/2022 21:48:56 - INFO - __main__ - Global step 1400 Train loss 2.80 Classification-F1 0.009937888198757764 on epoch=99
05/29/2022 21:48:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 2.93 on epoch=100
05/29/2022 21:48:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.73 on epoch=101
05/29/2022 21:48:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.82 on epoch=102
05/29/2022 21:49:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 2.81 on epoch=102
05/29/2022 21:49:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 2.71 on epoch=103
05/29/2022 21:49:04 - INFO - __main__ - Global step 1450 Train loss 2.80 Classification-F1 0.015154185022026432 on epoch=103
05/29/2022 21:49:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 2.77 on epoch=104
05/29/2022 21:49:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.83 on epoch=104
05/29/2022 21:49:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 2.87 on epoch=105
05/29/2022 21:49:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.73 on epoch=106
05/29/2022 21:49:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.73 on epoch=107
05/29/2022 21:49:13 - INFO - __main__ - Global step 1500 Train loss 2.78 Classification-F1 0.02032227032227032 on epoch=107
05/29/2022 21:49:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 2.67 on epoch=107
05/29/2022 21:49:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 2.82 on epoch=108
05/29/2022 21:49:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.64 on epoch=109
05/29/2022 21:49:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.69 on epoch=109
05/29/2022 21:49:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 2.76 on epoch=110
05/29/2022 21:49:21 - INFO - __main__ - Global step 1550 Train loss 2.72 Classification-F1 0.022980987266701555 on epoch=110
05/29/2022 21:49:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.52 on epoch=111
05/29/2022 21:49:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.66 on epoch=112
05/29/2022 21:49:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.53 on epoch=112
05/29/2022 21:49:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.69 on epoch=113
05/29/2022 21:49:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.55 on epoch=114
05/29/2022 21:49:30 - INFO - __main__ - Global step 1600 Train loss 2.59 Classification-F1 0.03183846228959011 on epoch=114
05/29/2022 21:49:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.53 on epoch=114
05/29/2022 21:49:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 2.72 on epoch=115
05/29/2022 21:49:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.43 on epoch=116
05/29/2022 21:49:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.65 on epoch=117
05/29/2022 21:49:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.61 on epoch=117
05/29/2022 21:49:38 - INFO - __main__ - Global step 1650 Train loss 2.59 Classification-F1 0.01767752715121136 on epoch=117
05/29/2022 21:49:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.76 on epoch=118
05/29/2022 21:49:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.53 on epoch=119
05/29/2022 21:49:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.49 on epoch=119
05/29/2022 21:49:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.74 on epoch=120
05/29/2022 21:49:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.44 on epoch=121
05/29/2022 21:49:47 - INFO - __main__ - Global step 1700 Train loss 2.59 Classification-F1 0.009937888198757764 on epoch=121
05/29/2022 21:49:48 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.70 on epoch=122
05/29/2022 21:49:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.41 on epoch=122
05/29/2022 21:49:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.67 on epoch=123
05/29/2022 21:49:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.57 on epoch=124
05/29/2022 21:49:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.52 on epoch=124
05/29/2022 21:49:55 - INFO - __main__ - Global step 1750 Train loss 2.57 Classification-F1 0.04742028246128682 on epoch=124
05/29/2022 21:49:55 - INFO - __main__ - Saving model with best Classification-F1: 0.041557699594084174 -> 0.04742028246128682 on epoch=124, global_step=1750
05/29/2022 21:49:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 2.67 on epoch=125
05/29/2022 21:49:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.59 on epoch=126
05/29/2022 21:49:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.67 on epoch=127
05/29/2022 21:50:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.52 on epoch=127
05/29/2022 21:50:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.70 on epoch=128
05/29/2022 21:50:04 - INFO - __main__ - Global step 1800 Train loss 2.63 Classification-F1 0.0653606488170099 on epoch=128
05/29/2022 21:50:04 - INFO - __main__ - Saving model with best Classification-F1: 0.04742028246128682 -> 0.0653606488170099 on epoch=128, global_step=1800
05/29/2022 21:50:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.45 on epoch=129
05/29/2022 21:50:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.48 on epoch=129
05/29/2022 21:50:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.62 on epoch=130
05/29/2022 21:50:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.46 on epoch=131
05/29/2022 21:50:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.68 on epoch=132
05/29/2022 21:50:12 - INFO - __main__ - Global step 1850 Train loss 2.54 Classification-F1 0.027562111801242233 on epoch=132
05/29/2022 21:50:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.52 on epoch=132
05/29/2022 21:50:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.45 on epoch=133
05/29/2022 21:50:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.59 on epoch=134
05/29/2022 21:50:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.36 on epoch=134
05/29/2022 21:50:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.58 on epoch=135
05/29/2022 21:50:21 - INFO - __main__ - Global step 1900 Train loss 2.50 Classification-F1 0.01728680676049097 on epoch=135
05/29/2022 21:50:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.46 on epoch=136
05/29/2022 21:50:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.57 on epoch=137
05/29/2022 21:50:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.57 on epoch=137
05/29/2022 21:50:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.49 on epoch=138
05/29/2022 21:50:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.42 on epoch=139
05/29/2022 21:50:30 - INFO - __main__ - Global step 1950 Train loss 2.51 Classification-F1 0.030137743170662756 on epoch=139
05/29/2022 21:50:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.29 on epoch=139
05/29/2022 21:50:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.73 on epoch=140
05/29/2022 21:50:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.46 on epoch=141
05/29/2022 21:50:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.47 on epoch=142
05/29/2022 21:50:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.49 on epoch=142
05/29/2022 21:50:39 - INFO - __main__ - Global step 2000 Train loss 2.49 Classification-F1 0.016910866910866913 on epoch=142
05/29/2022 21:50:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.32 on epoch=143
05/29/2022 21:50:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.28 on epoch=144
05/29/2022 21:50:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.47 on epoch=144
05/29/2022 21:50:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.64 on epoch=145
05/29/2022 21:50:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.35 on epoch=146
05/29/2022 21:50:48 - INFO - __main__ - Global step 2050 Train loss 2.41 Classification-F1 0.017052560934687776 on epoch=146
05/29/2022 21:50:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.51 on epoch=147
05/29/2022 21:50:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.30 on epoch=147
05/29/2022 21:50:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.39 on epoch=148
05/29/2022 21:50:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.32 on epoch=149
05/29/2022 21:50:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.33 on epoch=149
05/29/2022 21:50:56 - INFO - __main__ - Global step 2100 Train loss 2.37 Classification-F1 0.017704517704517704 on epoch=149
05/29/2022 21:50:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.67 on epoch=150
05/29/2022 21:50:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.39 on epoch=151
05/29/2022 21:51:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.46 on epoch=152
05/29/2022 21:51:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.37 on epoch=152
05/29/2022 21:51:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.42 on epoch=153
05/29/2022 21:51:05 - INFO - __main__ - Global step 2150 Train loss 2.46 Classification-F1 0.026077097505668938 on epoch=153
05/29/2022 21:51:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.33 on epoch=154
05/29/2022 21:51:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.23 on epoch=154
05/29/2022 21:51:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.26 on epoch=155
05/29/2022 21:51:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.26 on epoch=156
05/29/2022 21:51:11 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.41 on epoch=157
05/29/2022 21:51:13 - INFO - __main__ - Global step 2200 Train loss 2.30 Classification-F1 0.041230826194922146 on epoch=157
05/29/2022 21:51:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.10 on epoch=157
05/29/2022 21:51:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.23 on epoch=158
05/29/2022 21:51:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.45 on epoch=159
05/29/2022 21:51:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.29 on epoch=159
05/29/2022 21:51:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.35 on epoch=160
05/29/2022 21:51:21 - INFO - __main__ - Global step 2250 Train loss 2.28 Classification-F1 0.03471051365788208 on epoch=160
05/29/2022 21:51:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.28 on epoch=161
05/29/2022 21:51:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.28 on epoch=162
05/29/2022 21:51:25 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.25 on epoch=162
05/29/2022 21:51:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.26 on epoch=163
05/29/2022 21:51:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.39 on epoch=164
05/29/2022 21:51:30 - INFO - __main__ - Global step 2300 Train loss 2.29 Classification-F1 0.037531925050722045 on epoch=164
05/29/2022 21:51:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.38 on epoch=164
05/29/2022 21:51:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.29 on epoch=165
05/29/2022 21:51:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.11 on epoch=166
05/29/2022 21:51:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.37 on epoch=167
05/29/2022 21:51:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.20 on epoch=167
05/29/2022 21:51:38 - INFO - __main__ - Global step 2350 Train loss 2.27 Classification-F1 0.047017333369690696 on epoch=167
05/29/2022 21:51:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.24 on epoch=168
05/29/2022 21:51:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.23 on epoch=169
05/29/2022 21:51:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.14 on epoch=169
05/29/2022 21:51:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.25 on epoch=170
05/29/2022 21:51:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.30 on epoch=171
05/29/2022 21:51:47 - INFO - __main__ - Global step 2400 Train loss 2.23 Classification-F1 0.04487647559936717 on epoch=171
05/29/2022 21:51:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.30 on epoch=172
05/29/2022 21:51:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.13 on epoch=172
05/29/2022 21:51:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.22 on epoch=173
05/29/2022 21:51:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.23 on epoch=174
05/29/2022 21:51:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.22 on epoch=174
05/29/2022 21:51:55 - INFO - __main__ - Global step 2450 Train loss 2.22 Classification-F1 0.048135084421991006 on epoch=174
05/29/2022 21:51:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.22 on epoch=175
05/29/2022 21:51:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.96 on epoch=176
05/29/2022 21:51:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.15 on epoch=177
05/29/2022 21:52:00 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.07 on epoch=177
05/29/2022 21:52:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.23 on epoch=178
05/29/2022 21:52:04 - INFO - __main__ - Global step 2500 Train loss 2.12 Classification-F1 0.034098404378087 on epoch=178
05/29/2022 21:52:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.14 on epoch=179
05/29/2022 21:52:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.21 on epoch=179
05/29/2022 21:52:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.26 on epoch=180
05/29/2022 21:52:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.12 on epoch=181
05/29/2022 21:52:10 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.35 on epoch=182
05/29/2022 21:52:12 - INFO - __main__ - Global step 2550 Train loss 2.21 Classification-F1 0.02442466348241424 on epoch=182
05/29/2022 21:52:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.12 on epoch=182
05/29/2022 21:52:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.30 on epoch=183
05/29/2022 21:52:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.18 on epoch=184
05/29/2022 21:52:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.15 on epoch=184
05/29/2022 21:52:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.27 on epoch=185
05/29/2022 21:52:21 - INFO - __main__ - Global step 2600 Train loss 2.21 Classification-F1 0.04423105922929991 on epoch=185
05/29/2022 21:52:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.22 on epoch=186
05/29/2022 21:52:24 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.21 on epoch=187
05/29/2022 21:52:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.07 on epoch=187
05/29/2022 21:52:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.03 on epoch=188
05/29/2022 21:52:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 1.95 on epoch=189
05/29/2022 21:52:30 - INFO - __main__ - Global step 2650 Train loss 2.10 Classification-F1 0.07818484200616001 on epoch=189
05/29/2022 21:52:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0653606488170099 -> 0.07818484200616001 on epoch=189, global_step=2650
05/29/2022 21:52:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.13 on epoch=189
05/29/2022 21:52:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.16 on epoch=190
05/29/2022 21:52:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.01 on epoch=191
05/29/2022 21:52:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.13 on epoch=192
05/29/2022 21:52:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 1.99 on epoch=192
05/29/2022 21:52:38 - INFO - __main__ - Global step 2700 Train loss 2.09 Classification-F1 0.061139459343052156 on epoch=192
05/29/2022 21:52:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.06 on epoch=193
05/29/2022 21:52:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.06 on epoch=194
05/29/2022 21:52:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.08 on epoch=194
05/29/2022 21:52:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 1.97 on epoch=195
05/29/2022 21:52:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.06 on epoch=196
05/29/2022 21:52:47 - INFO - __main__ - Global step 2750 Train loss 2.05 Classification-F1 0.06845545235638115 on epoch=196
05/29/2022 21:52:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.08 on epoch=197
05/29/2022 21:52:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.01 on epoch=197
05/29/2022 21:52:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.06 on epoch=198
05/29/2022 21:52:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.05 on epoch=199
05/29/2022 21:52:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.03 on epoch=199
05/29/2022 21:52:55 - INFO - __main__ - Global step 2800 Train loss 2.05 Classification-F1 0.0901874136374937 on epoch=199
05/29/2022 21:52:55 - INFO - __main__ - Saving model with best Classification-F1: 0.07818484200616001 -> 0.0901874136374937 on epoch=199, global_step=2800
05/29/2022 21:52:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.08 on epoch=200
05/29/2022 21:52:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.06 on epoch=201
05/29/2022 21:52:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.15 on epoch=202
05/29/2022 21:53:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.06 on epoch=202
05/29/2022 21:53:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.11 on epoch=203
05/29/2022 21:53:04 - INFO - __main__ - Global step 2850 Train loss 2.09 Classification-F1 0.08084187475288178 on epoch=203
05/29/2022 21:53:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.06 on epoch=204
05/29/2022 21:53:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.14 on epoch=204
05/29/2022 21:53:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.01 on epoch=205
05/29/2022 21:53:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.06 on epoch=206
05/29/2022 21:53:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.00 on epoch=207
05/29/2022 21:53:13 - INFO - __main__ - Global step 2900 Train loss 2.06 Classification-F1 0.0707468127342237 on epoch=207
05/29/2022 21:53:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.02 on epoch=207
05/29/2022 21:53:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.10 on epoch=208
05/29/2022 21:53:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.03 on epoch=209
05/29/2022 21:53:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.11 on epoch=209
05/29/2022 21:53:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 1.91 on epoch=210
05/29/2022 21:53:21 - INFO - __main__ - Global step 2950 Train loss 2.03 Classification-F1 0.08941591453169584 on epoch=210
05/29/2022 21:53:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.09 on epoch=211
05/29/2022 21:53:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.94 on epoch=212
05/29/2022 21:53:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.86 on epoch=212
05/29/2022 21:53:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 1.93 on epoch=213
05/29/2022 21:53:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 1.99 on epoch=214
05/29/2022 21:53:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:53:29 - INFO - __main__ - Printing 3 examples
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 21:53:29 - INFO - __main__ - ['Film']
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 21:53:29 - INFO - __main__ - ['Film']
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 21:53:29 - INFO - __main__ - ['Film']
05/29/2022 21:53:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:53:29 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:53:29 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:53:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:53:29 - INFO - __main__ - Printing 3 examples
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 21:53:29 - INFO - __main__ - ['Film']
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 21:53:29 - INFO - __main__ - ['Film']
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 21:53:29 - INFO - __main__ - ['Film']
05/29/2022 21:53:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:53:29 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:53:29 - INFO - __main__ - Global step 3000 Train loss 1.96 Classification-F1 0.06239911021037329 on epoch=214
05/29/2022 21:53:29 - INFO - __main__ - save last model!
05/29/2022 21:53:29 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:53:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 21:53:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 21:53:29 - INFO - __main__ - Printing 3 examples
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 21:53:29 - INFO - __main__ - ['Animal']
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 21:53:29 - INFO - __main__ - ['Animal']
05/29/2022 21:53:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 21:53:29 - INFO - __main__ - ['Village']
05/29/2022 21:53:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:53:31 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:53:35 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:53:35 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 21:53:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:53:35 - INFO - __main__ - Starting training!
05/29/2022 21:54:06 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/29/2022 21:54:06 - INFO - __main__ - Classification-F1 on test data: 0.0605
05/29/2022 21:54:06 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.0901874136374937, test_performance=0.06054021125330055
05/29/2022 21:54:06 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/29/2022 21:54:07 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:54:07 - INFO - __main__ - Printing 3 examples
05/29/2022 21:54:07 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 21:54:07 - INFO - __main__ - ['Film']
05/29/2022 21:54:07 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 21:54:07 - INFO - __main__ - ['Film']
05/29/2022 21:54:07 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 21:54:07 - INFO - __main__ - ['Film']
05/29/2022 21:54:07 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:54:07 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:54:08 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 21:54:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 21:54:08 - INFO - __main__ - Printing 3 examples
05/29/2022 21:54:08 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 21:54:08 - INFO - __main__ - ['Film']
05/29/2022 21:54:08 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 21:54:08 - INFO - __main__ - ['Film']
05/29/2022 21:54:08 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 21:54:08 - INFO - __main__ - ['Film']
05/29/2022 21:54:08 - INFO - __main__ - Tokenizing Input ...
05/29/2022 21:54:08 - INFO - __main__ - Tokenizing Output ...
05/29/2022 21:54:08 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 21:54:13 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 21:54:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 21:54:13 - INFO - __main__ - Starting training!
05/29/2022 21:54:15 - INFO - __main__ - Step 10 Global step 10 Train loss 7.43 on epoch=0
05/29/2022 21:54:16 - INFO - __main__ - Step 20 Global step 20 Train loss 7.35 on epoch=1
05/29/2022 21:54:18 - INFO - __main__ - Step 30 Global step 30 Train loss 7.04 on epoch=2
05/29/2022 21:54:19 - INFO - __main__ - Step 40 Global step 40 Train loss 7.27 on epoch=2
05/29/2022 21:54:20 - INFO - __main__ - Step 50 Global step 50 Train loss 6.91 on epoch=3
05/29/2022 21:54:31 - INFO - __main__ - Global step 50 Train loss 7.20 Classification-F1 0.0 on epoch=3
05/29/2022 21:54:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 21:54:32 - INFO - __main__ - Step 60 Global step 60 Train loss 6.77 on epoch=4
05/29/2022 21:54:34 - INFO - __main__ - Step 70 Global step 70 Train loss 6.97 on epoch=4
05/29/2022 21:54:35 - INFO - __main__ - Step 80 Global step 80 Train loss 6.76 on epoch=5
05/29/2022 21:54:36 - INFO - __main__ - Step 90 Global step 90 Train loss 6.68 on epoch=6
05/29/2022 21:54:37 - INFO - __main__ - Step 100 Global step 100 Train loss 6.56 on epoch=7
05/29/2022 21:55:01 - INFO - __main__ - Global step 100 Train loss 6.75 Classification-F1 0.0 on epoch=7
05/29/2022 21:55:02 - INFO - __main__ - Step 110 Global step 110 Train loss 6.59 on epoch=7
05/29/2022 21:55:03 - INFO - __main__ - Step 120 Global step 120 Train loss 6.38 on epoch=8
05/29/2022 21:55:05 - INFO - __main__ - Step 130 Global step 130 Train loss 6.35 on epoch=9
05/29/2022 21:55:06 - INFO - __main__ - Step 140 Global step 140 Train loss 6.43 on epoch=9
05/29/2022 21:55:07 - INFO - __main__ - Step 150 Global step 150 Train loss 6.29 on epoch=10
05/29/2022 21:56:11 - INFO - __main__ - Global step 150 Train loss 6.41 Classification-F1 0.0 on epoch=10
05/29/2022 21:56:12 - INFO - __main__ - Step 160 Global step 160 Train loss 6.36 on epoch=11
05/29/2022 21:56:13 - INFO - __main__ - Step 170 Global step 170 Train loss 6.17 on epoch=12
05/29/2022 21:56:14 - INFO - __main__ - Step 180 Global step 180 Train loss 6.12 on epoch=12
05/29/2022 21:56:16 - INFO - __main__ - Step 190 Global step 190 Train loss 6.13 on epoch=13
05/29/2022 21:56:17 - INFO - __main__ - Step 200 Global step 200 Train loss 5.88 on epoch=14
05/29/2022 21:57:21 - INFO - __main__ - Global step 200 Train loss 6.13 Classification-F1 0.0 on epoch=14
05/29/2022 21:57:22 - INFO - __main__ - Step 210 Global step 210 Train loss 6.18 on epoch=14
05/29/2022 21:57:23 - INFO - __main__ - Step 220 Global step 220 Train loss 5.99 on epoch=15
05/29/2022 21:57:24 - INFO - __main__ - Step 230 Global step 230 Train loss 5.79 on epoch=16
05/29/2022 21:57:26 - INFO - __main__ - Step 240 Global step 240 Train loss 5.82 on epoch=17
05/29/2022 21:57:27 - INFO - __main__ - Step 250 Global step 250 Train loss 5.95 on epoch=17
05/29/2022 21:58:30 - INFO - __main__ - Global step 250 Train loss 5.95 Classification-F1 0.0 on epoch=17
05/29/2022 21:58:32 - INFO - __main__ - Step 260 Global step 260 Train loss 5.65 on epoch=18
05/29/2022 21:58:33 - INFO - __main__ - Step 270 Global step 270 Train loss 5.61 on epoch=19
05/29/2022 21:58:34 - INFO - __main__ - Step 280 Global step 280 Train loss 5.76 on epoch=19
05/29/2022 21:58:36 - INFO - __main__ - Step 290 Global step 290 Train loss 5.62 on epoch=20
05/29/2022 21:58:37 - INFO - __main__ - Step 300 Global step 300 Train loss 5.62 on epoch=21
05/29/2022 21:59:28 - INFO - __main__ - Global step 300 Train loss 5.65 Classification-F1 0.0 on epoch=21
05/29/2022 21:59:30 - INFO - __main__ - Step 310 Global step 310 Train loss 5.68 on epoch=22
05/29/2022 21:59:31 - INFO - __main__ - Step 320 Global step 320 Train loss 5.59 on epoch=22
05/29/2022 21:59:32 - INFO - __main__ - Step 330 Global step 330 Train loss 5.46 on epoch=23
05/29/2022 21:59:34 - INFO - __main__ - Step 340 Global step 340 Train loss 5.33 on epoch=24
05/29/2022 21:59:35 - INFO - __main__ - Step 350 Global step 350 Train loss 5.45 on epoch=24
05/29/2022 22:00:25 - INFO - __main__ - Global step 350 Train loss 5.50 Classification-F1 0.0 on epoch=24
05/29/2022 22:00:27 - INFO - __main__ - Step 360 Global step 360 Train loss 5.41 on epoch=25
05/29/2022 22:00:28 - INFO - __main__ - Step 370 Global step 370 Train loss 5.35 on epoch=26
05/29/2022 22:00:29 - INFO - __main__ - Step 380 Global step 380 Train loss 5.19 on epoch=27
05/29/2022 22:00:30 - INFO - __main__ - Step 390 Global step 390 Train loss 5.38 on epoch=27
05/29/2022 22:00:32 - INFO - __main__ - Step 400 Global step 400 Train loss 5.19 on epoch=28
05/29/2022 22:00:36 - INFO - __main__ - Global step 400 Train loss 5.30 Classification-F1 0.0 on epoch=28
05/29/2022 22:00:37 - INFO - __main__ - Step 410 Global step 410 Train loss 4.96 on epoch=29
05/29/2022 22:00:38 - INFO - __main__ - Step 420 Global step 420 Train loss 5.19 on epoch=29
05/29/2022 22:00:40 - INFO - __main__ - Step 430 Global step 430 Train loss 5.30 on epoch=30
05/29/2022 22:00:41 - INFO - __main__ - Step 440 Global step 440 Train loss 5.04 on epoch=31
05/29/2022 22:00:42 - INFO - __main__ - Step 450 Global step 450 Train loss 4.98 on epoch=32
05/29/2022 22:00:50 - INFO - __main__ - Global step 450 Train loss 5.09 Classification-F1 0.0038940809968847356 on epoch=32
05/29/2022 22:00:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0038940809968847356 on epoch=32, global_step=450
05/29/2022 22:00:52 - INFO - __main__ - Step 460 Global step 460 Train loss 5.17 on epoch=32
05/29/2022 22:00:53 - INFO - __main__ - Step 470 Global step 470 Train loss 5.17 on epoch=33
05/29/2022 22:00:55 - INFO - __main__ - Step 480 Global step 480 Train loss 4.96 on epoch=34
05/29/2022 22:00:56 - INFO - __main__ - Step 490 Global step 490 Train loss 5.08 on epoch=34
05/29/2022 22:00:57 - INFO - __main__ - Step 500 Global step 500 Train loss 5.04 on epoch=35
05/29/2022 22:01:00 - INFO - __main__ - Global step 500 Train loss 5.08 Classification-F1 0.00847457627118644 on epoch=35
05/29/2022 22:01:00 - INFO - __main__ - Saving model with best Classification-F1: 0.0038940809968847356 -> 0.00847457627118644 on epoch=35, global_step=500
05/29/2022 22:01:01 - INFO - __main__ - Step 510 Global step 510 Train loss 4.84 on epoch=36
05/29/2022 22:01:02 - INFO - __main__ - Step 520 Global step 520 Train loss 4.78 on epoch=37
05/29/2022 22:01:04 - INFO - __main__ - Step 530 Global step 530 Train loss 4.79 on epoch=37
05/29/2022 22:01:05 - INFO - __main__ - Step 540 Global step 540 Train loss 4.70 on epoch=38
05/29/2022 22:01:07 - INFO - __main__ - Step 550 Global step 550 Train loss 4.67 on epoch=39
05/29/2022 22:01:20 - INFO - __main__ - Global step 550 Train loss 4.76 Classification-F1 0.00597524541186513 on epoch=39
05/29/2022 22:01:21 - INFO - __main__ - Step 560 Global step 560 Train loss 4.81 on epoch=39
05/29/2022 22:01:22 - INFO - __main__ - Step 570 Global step 570 Train loss 4.65 on epoch=40
05/29/2022 22:01:24 - INFO - __main__ - Step 580 Global step 580 Train loss 4.70 on epoch=41
05/29/2022 22:01:25 - INFO - __main__ - Step 590 Global step 590 Train loss 4.58 on epoch=42
05/29/2022 22:01:26 - INFO - __main__ - Step 600 Global step 600 Train loss 4.68 on epoch=42
05/29/2022 22:01:29 - INFO - __main__ - Global step 600 Train loss 4.68 Classification-F1 0.00892608089260809 on epoch=42
05/29/2022 22:01:29 - INFO - __main__ - Saving model with best Classification-F1: 0.00847457627118644 -> 0.00892608089260809 on epoch=42, global_step=600
05/29/2022 22:01:30 - INFO - __main__ - Step 610 Global step 610 Train loss 4.59 on epoch=43
05/29/2022 22:01:32 - INFO - __main__ - Step 620 Global step 620 Train loss 4.43 on epoch=44
05/29/2022 22:01:33 - INFO - __main__ - Step 630 Global step 630 Train loss 4.57 on epoch=44
05/29/2022 22:01:35 - INFO - __main__ - Step 640 Global step 640 Train loss 4.62 on epoch=45
05/29/2022 22:01:36 - INFO - __main__ - Step 650 Global step 650 Train loss 4.50 on epoch=46
05/29/2022 22:01:38 - INFO - __main__ - Global step 650 Train loss 4.54 Classification-F1 0.009523809523809523 on epoch=46
05/29/2022 22:01:38 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=46, global_step=650
05/29/2022 22:01:39 - INFO - __main__ - Step 660 Global step 660 Train loss 4.59 on epoch=47
05/29/2022 22:01:41 - INFO - __main__ - Step 670 Global step 670 Train loss 4.40 on epoch=47
05/29/2022 22:01:42 - INFO - __main__ - Step 680 Global step 680 Train loss 4.49 on epoch=48
05/29/2022 22:01:43 - INFO - __main__ - Step 690 Global step 690 Train loss 4.30 on epoch=49
05/29/2022 22:01:45 - INFO - __main__ - Step 700 Global step 700 Train loss 4.44 on epoch=49
05/29/2022 22:01:46 - INFO - __main__ - Global step 700 Train loss 4.45 Classification-F1 0.009523809523809523 on epoch=49
05/29/2022 22:01:48 - INFO - __main__ - Step 710 Global step 710 Train loss 4.39 on epoch=50
05/29/2022 22:01:49 - INFO - __main__ - Step 720 Global step 720 Train loss 4.30 on epoch=51
05/29/2022 22:01:51 - INFO - __main__ - Step 730 Global step 730 Train loss 4.30 on epoch=52
05/29/2022 22:01:52 - INFO - __main__ - Step 740 Global step 740 Train loss 4.28 on epoch=52
05/29/2022 22:01:54 - INFO - __main__ - Step 750 Global step 750 Train loss 4.31 on epoch=53
05/29/2022 22:01:56 - INFO - __main__ - Global step 750 Train loss 4.31 Classification-F1 0.009523809523809523 on epoch=53
05/29/2022 22:01:57 - INFO - __main__ - Step 760 Global step 760 Train loss 4.17 on epoch=54
05/29/2022 22:01:58 - INFO - __main__ - Step 770 Global step 770 Train loss 4.21 on epoch=54
05/29/2022 22:02:00 - INFO - __main__ - Step 780 Global step 780 Train loss 4.35 on epoch=55
05/29/2022 22:02:01 - INFO - __main__ - Step 790 Global step 790 Train loss 4.16 on epoch=56
05/29/2022 22:02:03 - INFO - __main__ - Step 800 Global step 800 Train loss 4.04 on epoch=57
05/29/2022 22:02:04 - INFO - __main__ - Global step 800 Train loss 4.19 Classification-F1 0.009563658099222952 on epoch=57
05/29/2022 22:02:04 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009563658099222952 on epoch=57, global_step=800
05/29/2022 22:02:06 - INFO - __main__ - Step 810 Global step 810 Train loss 4.17 on epoch=57
05/29/2022 22:02:07 - INFO - __main__ - Step 820 Global step 820 Train loss 4.23 on epoch=58
05/29/2022 22:02:08 - INFO - __main__ - Step 830 Global step 830 Train loss 4.04 on epoch=59
05/29/2022 22:02:10 - INFO - __main__ - Step 840 Global step 840 Train loss 4.04 on epoch=59
05/29/2022 22:02:11 - INFO - __main__ - Step 850 Global step 850 Train loss 4.16 on epoch=60
05/29/2022 22:02:13 - INFO - __main__ - Global step 850 Train loss 4.13 Classification-F1 0.01540799189614267 on epoch=60
05/29/2022 22:02:13 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.01540799189614267 on epoch=60, global_step=850
05/29/2022 22:02:14 - INFO - __main__ - Step 860 Global step 860 Train loss 3.96 on epoch=61
05/29/2022 22:02:15 - INFO - __main__ - Step 870 Global step 870 Train loss 3.95 on epoch=62
05/29/2022 22:02:17 - INFO - __main__ - Step 880 Global step 880 Train loss 3.88 on epoch=62
05/29/2022 22:02:18 - INFO - __main__ - Step 890 Global step 890 Train loss 4.08 on epoch=63
05/29/2022 22:02:19 - INFO - __main__ - Step 900 Global step 900 Train loss 3.90 on epoch=64
05/29/2022 22:02:21 - INFO - __main__ - Global step 900 Train loss 3.96 Classification-F1 0.025388637400428116 on epoch=64
05/29/2022 22:02:21 - INFO - __main__ - Saving model with best Classification-F1: 0.01540799189614267 -> 0.025388637400428116 on epoch=64, global_step=900
05/29/2022 22:02:22 - INFO - __main__ - Step 910 Global step 910 Train loss 3.79 on epoch=64
05/29/2022 22:02:24 - INFO - __main__ - Step 920 Global step 920 Train loss 4.00 on epoch=65
05/29/2022 22:02:25 - INFO - __main__ - Step 930 Global step 930 Train loss 3.85 on epoch=66
05/29/2022 22:02:26 - INFO - __main__ - Step 940 Global step 940 Train loss 3.82 on epoch=67
05/29/2022 22:02:28 - INFO - __main__ - Step 950 Global step 950 Train loss 3.91 on epoch=67
05/29/2022 22:02:30 - INFO - __main__ - Global step 950 Train loss 3.87 Classification-F1 0.032004429678848284 on epoch=67
05/29/2022 22:02:30 - INFO - __main__ - Saving model with best Classification-F1: 0.025388637400428116 -> 0.032004429678848284 on epoch=67, global_step=950
05/29/2022 22:02:31 - INFO - __main__ - Step 960 Global step 960 Train loss 3.80 on epoch=68
05/29/2022 22:02:32 - INFO - __main__ - Step 970 Global step 970 Train loss 3.60 on epoch=69
05/29/2022 22:02:33 - INFO - __main__ - Step 980 Global step 980 Train loss 3.83 on epoch=69
05/29/2022 22:02:35 - INFO - __main__ - Step 990 Global step 990 Train loss 3.90 on epoch=70
05/29/2022 22:02:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 3.46 on epoch=71
05/29/2022 22:02:38 - INFO - __main__ - Global step 1000 Train loss 3.72 Classification-F1 0.016692785828740474 on epoch=71
05/29/2022 22:02:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 3.71 on epoch=72
05/29/2022 22:02:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 3.72 on epoch=72
05/29/2022 22:02:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 3.69 on epoch=73
05/29/2022 22:02:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 3.60 on epoch=74
05/29/2022 22:02:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 3.62 on epoch=74
05/29/2022 22:02:46 - INFO - __main__ - Global step 1050 Train loss 3.67 Classification-F1 0.03493897559023609 on epoch=74
05/29/2022 22:02:46 - INFO - __main__ - Saving model with best Classification-F1: 0.032004429678848284 -> 0.03493897559023609 on epoch=74, global_step=1050
05/29/2022 22:02:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 3.70 on epoch=75
05/29/2022 22:02:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 3.43 on epoch=76
05/29/2022 22:02:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 3.79 on epoch=77
05/29/2022 22:02:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 3.58 on epoch=77
05/29/2022 22:02:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 3.66 on epoch=78
05/29/2022 22:02:55 - INFO - __main__ - Global step 1100 Train loss 3.63 Classification-F1 0.017377860235003092 on epoch=78
05/29/2022 22:02:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 3.37 on epoch=79
05/29/2022 22:02:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 3.46 on epoch=79
05/29/2022 22:02:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 3.49 on epoch=80
05/29/2022 22:03:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 3.34 on epoch=81
05/29/2022 22:03:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 3.29 on epoch=82
05/29/2022 22:03:03 - INFO - __main__ - Global step 1150 Train loss 3.39 Classification-F1 0.021957671957671957 on epoch=82
05/29/2022 22:03:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 3.54 on epoch=82
05/29/2022 22:03:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 3.48 on epoch=83
05/29/2022 22:03:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 3.32 on epoch=84
05/29/2022 22:03:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 3.27 on epoch=84
05/29/2022 22:03:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 3.48 on epoch=85
05/29/2022 22:03:12 - INFO - __main__ - Global step 1200 Train loss 3.42 Classification-F1 0.012877180575200375 on epoch=85
05/29/2022 22:03:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 3.51 on epoch=86
05/29/2022 22:03:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 3.41 on epoch=87
05/29/2022 22:03:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 3.40 on epoch=87
05/29/2022 22:03:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 3.31 on epoch=88
05/29/2022 22:03:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 3.21 on epoch=89
05/29/2022 22:03:20 - INFO - __main__ - Global step 1250 Train loss 3.37 Classification-F1 0.031569494335451774 on epoch=89
05/29/2022 22:03:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 3.17 on epoch=89
05/29/2022 22:03:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 3.32 on epoch=90
05/29/2022 22:03:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.20 on epoch=91
05/29/2022 22:03:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 3.25 on epoch=92
05/29/2022 22:03:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.27 on epoch=92
05/29/2022 22:03:28 - INFO - __main__ - Global step 1300 Train loss 3.24 Classification-F1 0.04141254202830558 on epoch=92
05/29/2022 22:03:28 - INFO - __main__ - Saving model with best Classification-F1: 0.03493897559023609 -> 0.04141254202830558 on epoch=92, global_step=1300
05/29/2022 22:03:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 3.15 on epoch=93
05/29/2022 22:03:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.26 on epoch=94
05/29/2022 22:03:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.15 on epoch=94
05/29/2022 22:03:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 3.34 on epoch=95
05/29/2022 22:03:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.05 on epoch=96
05/29/2022 22:03:37 - INFO - __main__ - Global step 1350 Train loss 3.19 Classification-F1 0.017552515511699188 on epoch=96
05/29/2022 22:03:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.03 on epoch=97
05/29/2022 22:03:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.10 on epoch=97
05/29/2022 22:03:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 2.97 on epoch=98
05/29/2022 22:03:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.11 on epoch=99
05/29/2022 22:03:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.11 on epoch=99
05/29/2022 22:03:45 - INFO - __main__ - Global step 1400 Train loss 3.06 Classification-F1 0.047930038156995085 on epoch=99
05/29/2022 22:03:45 - INFO - __main__ - Saving model with best Classification-F1: 0.04141254202830558 -> 0.047930038156995085 on epoch=99, global_step=1400
05/29/2022 22:03:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.19 on epoch=100
05/29/2022 22:03:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 2.91 on epoch=101
05/29/2022 22:03:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 2.99 on epoch=102
05/29/2022 22:03:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.02 on epoch=102
05/29/2022 22:03:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.01 on epoch=103
05/29/2022 22:03:53 - INFO - __main__ - Global step 1450 Train loss 3.02 Classification-F1 0.02766318411794775 on epoch=103
05/29/2022 22:03:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.03 on epoch=104
05/29/2022 22:03:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 2.88 on epoch=104
05/29/2022 22:03:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.11 on epoch=105
05/29/2022 22:03:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 2.88 on epoch=106
05/29/2022 22:04:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 2.99 on epoch=107
05/29/2022 22:04:02 - INFO - __main__ - Global step 1500 Train loss 2.98 Classification-F1 0.05494765281999324 on epoch=107
05/29/2022 22:04:02 - INFO - __main__ - Saving model with best Classification-F1: 0.047930038156995085 -> 0.05494765281999324 on epoch=107, global_step=1500
05/29/2022 22:04:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.06 on epoch=107
05/29/2022 22:04:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.04 on epoch=108
05/29/2022 22:04:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 2.83 on epoch=109
05/29/2022 22:04:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 2.93 on epoch=109
05/29/2022 22:04:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.07 on epoch=110
05/29/2022 22:04:10 - INFO - __main__ - Global step 1550 Train loss 2.99 Classification-F1 0.03438228438228438 on epoch=110
05/29/2022 22:04:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 2.99 on epoch=111
05/29/2022 22:04:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 2.98 on epoch=112
05/29/2022 22:04:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 2.86 on epoch=112
05/29/2022 22:04:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 2.87 on epoch=113
05/29/2022 22:04:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 2.89 on epoch=114
05/29/2022 22:04:19 - INFO - __main__ - Global step 1600 Train loss 2.92 Classification-F1 0.04339544513457557 on epoch=114
05/29/2022 22:04:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 2.88 on epoch=114
05/29/2022 22:04:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.05 on epoch=115
05/29/2022 22:04:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 2.87 on epoch=116
05/29/2022 22:04:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 2.99 on epoch=117
05/29/2022 22:04:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 2.90 on epoch=117
05/29/2022 22:04:27 - INFO - __main__ - Global step 1650 Train loss 2.94 Classification-F1 0.033651672694394216 on epoch=117
05/29/2022 22:04:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 2.93 on epoch=118
05/29/2022 22:04:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 2.91 on epoch=119
05/29/2022 22:04:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 2.81 on epoch=119
05/29/2022 22:04:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 2.91 on epoch=120
05/29/2022 22:04:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 2.74 on epoch=121
05/29/2022 22:04:36 - INFO - __main__ - Global step 1700 Train loss 2.86 Classification-F1 0.048099280382744955 on epoch=121
05/29/2022 22:04:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 2.85 on epoch=122
05/29/2022 22:04:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 2.76 on epoch=122
05/29/2022 22:04:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 2.77 on epoch=123
05/29/2022 22:04:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 2.79 on epoch=124
05/29/2022 22:04:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 2.84 on epoch=124
05/29/2022 22:04:44 - INFO - __main__ - Global step 1750 Train loss 2.80 Classification-F1 0.04834505634566592 on epoch=124
05/29/2022 22:04:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.04 on epoch=125
05/29/2022 22:04:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 2.79 on epoch=126
05/29/2022 22:04:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 2.82 on epoch=127
05/29/2022 22:04:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 2.78 on epoch=127
05/29/2022 22:04:51 - INFO - __main__ - Step 1800 Global step 1800 Train loss 2.89 on epoch=128
05/29/2022 22:04:53 - INFO - __main__ - Global step 1800 Train loss 2.86 Classification-F1 0.04475408520150356 on epoch=128
05/29/2022 22:04:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 2.71 on epoch=129
05/29/2022 22:04:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 2.77 on epoch=129
05/29/2022 22:04:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 2.76 on epoch=130
05/29/2022 22:04:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 2.82 on epoch=131
05/29/2022 22:04:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 2.82 on epoch=132
05/29/2022 22:05:01 - INFO - __main__ - Global step 1850 Train loss 2.78 Classification-F1 0.02227791701475912 on epoch=132
05/29/2022 22:05:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 2.73 on epoch=132
05/29/2022 22:05:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 2.84 on epoch=133
05/29/2022 22:05:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 2.68 on epoch=134
05/29/2022 22:05:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 2.64 on epoch=134
05/29/2022 22:05:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 2.83 on epoch=135
05/29/2022 22:05:12 - INFO - __main__ - Global step 1900 Train loss 2.75 Classification-F1 0.009644364074743823 on epoch=135
05/29/2022 22:05:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 2.65 on epoch=136
05/29/2022 22:05:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 2.81 on epoch=137
05/29/2022 22:05:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 2.74 on epoch=137
05/29/2022 22:05:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 2.75 on epoch=138
05/29/2022 22:05:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 2.66 on epoch=139
05/29/2022 22:05:21 - INFO - __main__ - Global step 1950 Train loss 2.72 Classification-F1 0.03380307635626784 on epoch=139
05/29/2022 22:05:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 2.73 on epoch=139
05/29/2022 22:05:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 2.69 on epoch=140
05/29/2022 22:05:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 2.51 on epoch=141
05/29/2022 22:05:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 2.60 on epoch=142
05/29/2022 22:05:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 2.53 on epoch=142
05/29/2022 22:05:30 - INFO - __main__ - Global step 2000 Train loss 2.61 Classification-F1 0.009523809523809523 on epoch=142
05/29/2022 22:05:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 2.70 on epoch=143
05/29/2022 22:05:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 2.73 on epoch=144
05/29/2022 22:05:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 2.64 on epoch=144
05/29/2022 22:05:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 2.71 on epoch=145
05/29/2022 22:05:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 2.61 on epoch=146
05/29/2022 22:05:39 - INFO - __main__ - Global step 2050 Train loss 2.68 Classification-F1 0.009235209235209235 on epoch=146
05/29/2022 22:05:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 2.52 on epoch=147
05/29/2022 22:05:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 2.70 on epoch=147
05/29/2022 22:05:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 2.49 on epoch=148
05/29/2022 22:05:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 2.66 on epoch=149
05/29/2022 22:05:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 2.56 on epoch=149
05/29/2022 22:05:48 - INFO - __main__ - Global step 2100 Train loss 2.59 Classification-F1 0.009563658099222952 on epoch=149
05/29/2022 22:05:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 2.53 on epoch=150
05/29/2022 22:05:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 2.46 on epoch=151
05/29/2022 22:05:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 2.65 on epoch=152
05/29/2022 22:05:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 2.59 on epoch=152
05/29/2022 22:05:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 2.78 on epoch=153
05/29/2022 22:05:57 - INFO - __main__ - Global step 2150 Train loss 2.60 Classification-F1 0.009001406469760902 on epoch=153
05/29/2022 22:05:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 2.53 on epoch=154
05/29/2022 22:06:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 2.52 on epoch=154
05/29/2022 22:06:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 2.60 on epoch=155
05/29/2022 22:06:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 2.43 on epoch=156
05/29/2022 22:06:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 2.61 on epoch=157
05/29/2022 22:06:06 - INFO - __main__ - Global step 2200 Train loss 2.54 Classification-F1 0.009563658099222952 on epoch=157
05/29/2022 22:06:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 2.53 on epoch=157
05/29/2022 22:06:08 - INFO - __main__ - Step 2220 Global step 2220 Train loss 2.58 on epoch=158
05/29/2022 22:06:10 - INFO - __main__ - Step 2230 Global step 2230 Train loss 2.55 on epoch=159
05/29/2022 22:06:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 2.47 on epoch=159
05/29/2022 22:06:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 2.49 on epoch=160
05/29/2022 22:06:15 - INFO - __main__ - Global step 2250 Train loss 2.52 Classification-F1 0.0435077890805445 on epoch=160
05/29/2022 22:06:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 2.40 on epoch=161
05/29/2022 22:06:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 2.54 on epoch=162
05/29/2022 22:06:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 2.35 on epoch=162
05/29/2022 22:06:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 2.62 on epoch=163
05/29/2022 22:06:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 2.44 on epoch=164
05/29/2022 22:06:23 - INFO - __main__ - Global step 2300 Train loss 2.47 Classification-F1 0.01762173796072101 on epoch=164
05/29/2022 22:06:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 2.52 on epoch=164
05/29/2022 22:06:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 2.54 on epoch=165
05/29/2022 22:06:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 2.55 on epoch=166
05/29/2022 22:06:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 2.72 on epoch=167
05/29/2022 22:06:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 2.46 on epoch=167
05/29/2022 22:06:32 - INFO - __main__ - Global step 2350 Train loss 2.56 Classification-F1 0.009523809523809523 on epoch=167
05/29/2022 22:06:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 2.50 on epoch=168
05/29/2022 22:06:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.50 on epoch=169
05/29/2022 22:06:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 2.41 on epoch=169
05/29/2022 22:06:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 2.55 on epoch=170
05/29/2022 22:06:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.40 on epoch=171
05/29/2022 22:06:41 - INFO - __main__ - Global step 2400 Train loss 2.47 Classification-F1 0.04017250333039807 on epoch=171
05/29/2022 22:06:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 2.39 on epoch=172
05/29/2022 22:06:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 2.44 on epoch=172
05/29/2022 22:06:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 2.47 on epoch=173
05/29/2022 22:06:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.42 on epoch=174
05/29/2022 22:06:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 2.48 on epoch=174
05/29/2022 22:06:49 - INFO - __main__ - Global step 2450 Train loss 2.44 Classification-F1 0.061464262142871484 on epoch=174
05/29/2022 22:06:49 - INFO - __main__ - Saving model with best Classification-F1: 0.05494765281999324 -> 0.061464262142871484 on epoch=174, global_step=2450
05/29/2022 22:06:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 2.49 on epoch=175
05/29/2022 22:06:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.40 on epoch=176
05/29/2022 22:06:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.44 on epoch=177
05/29/2022 22:06:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 2.29 on epoch=177
05/29/2022 22:06:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 2.47 on epoch=178
05/29/2022 22:06:58 - INFO - __main__ - Global step 2500 Train loss 2.42 Classification-F1 0.04415255463887683 on epoch=178
05/29/2022 22:06:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 2.52 on epoch=179
05/29/2022 22:07:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 2.44 on epoch=179
05/29/2022 22:07:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 2.42 on epoch=180
05/29/2022 22:07:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 2.32 on epoch=181
05/29/2022 22:07:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 2.35 on epoch=182
05/29/2022 22:07:06 - INFO - __main__ - Global step 2550 Train loss 2.41 Classification-F1 0.009563658099222952 on epoch=182
05/29/2022 22:07:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 2.28 on epoch=182
05/29/2022 22:07:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 2.30 on epoch=183
05/29/2022 22:07:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.32 on epoch=184
05/29/2022 22:07:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.39 on epoch=184
05/29/2022 22:07:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 2.38 on epoch=185
05/29/2022 22:07:16 - INFO - __main__ - Global step 2600 Train loss 2.34 Classification-F1 0.02801300538217087 on epoch=185
05/29/2022 22:07:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.36 on epoch=186
05/29/2022 22:07:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 2.34 on epoch=187
05/29/2022 22:07:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.44 on epoch=187
05/29/2022 22:07:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 2.59 on epoch=188
05/29/2022 22:07:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.37 on epoch=189
05/29/2022 22:07:26 - INFO - __main__ - Global step 2650 Train loss 2.42 Classification-F1 0.03751951344398237 on epoch=189
05/29/2022 22:07:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.31 on epoch=189
05/29/2022 22:07:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 2.29 on epoch=190
05/29/2022 22:07:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.28 on epoch=191
05/29/2022 22:07:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.45 on epoch=192
05/29/2022 22:07:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 2.28 on epoch=192
05/29/2022 22:07:35 - INFO - __main__ - Global step 2700 Train loss 2.32 Classification-F1 0.018255578093306284 on epoch=192
05/29/2022 22:07:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 2.34 on epoch=193
05/29/2022 22:07:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.30 on epoch=194
05/29/2022 22:07:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.46 on epoch=194
05/29/2022 22:07:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 2.39 on epoch=195
05/29/2022 22:07:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.15 on epoch=196
05/29/2022 22:07:44 - INFO - __main__ - Global step 2750 Train loss 2.33 Classification-F1 0.04852607709750567 on epoch=196
05/29/2022 22:07:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 2.31 on epoch=197
05/29/2022 22:07:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.27 on epoch=197
05/29/2022 22:07:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 2.37 on epoch=198
05/29/2022 22:07:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.26 on epoch=199
05/29/2022 22:07:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.25 on epoch=199
05/29/2022 22:07:54 - INFO - __main__ - Global step 2800 Train loss 2.29 Classification-F1 0.026835822210475306 on epoch=199
05/29/2022 22:07:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 2.37 on epoch=200
05/29/2022 22:07:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.21 on epoch=201
05/29/2022 22:07:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.33 on epoch=202
05/29/2022 22:07:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 2.21 on epoch=202
05/29/2022 22:08:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 2.24 on epoch=203
05/29/2022 22:08:03 - INFO - __main__ - Global step 2850 Train loss 2.27 Classification-F1 0.028522039757994815 on epoch=203
05/29/2022 22:08:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.11 on epoch=204
05/29/2022 22:08:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.29 on epoch=204
05/29/2022 22:08:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 2.26 on epoch=205
05/29/2022 22:08:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.09 on epoch=206
05/29/2022 22:08:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.22 on epoch=207
05/29/2022 22:08:12 - INFO - __main__ - Global step 2900 Train loss 2.19 Classification-F1 0.030750761843198814 on epoch=207
05/29/2022 22:08:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.22 on epoch=207
05/29/2022 22:08:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 2.33 on epoch=208
05/29/2022 22:08:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.04 on epoch=209
05/29/2022 22:08:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.24 on epoch=209
05/29/2022 22:08:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 2.19 on epoch=210
05/29/2022 22:08:21 - INFO - __main__ - Global step 2950 Train loss 2.20 Classification-F1 0.03557417736382803 on epoch=210
05/29/2022 22:08:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.16 on epoch=211
05/29/2022 22:08:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.23 on epoch=212
05/29/2022 22:08:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.29 on epoch=212
05/29/2022 22:08:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.25 on epoch=213
05/29/2022 22:08:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.17 on epoch=214
05/29/2022 22:08:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 22:08:28 - INFO - __main__ - Printing 3 examples
05/29/2022 22:08:28 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 22:08:28 - INFO - __main__ - ['Film']
05/29/2022 22:08:28 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 22:08:28 - INFO - __main__ - ['Film']
05/29/2022 22:08:28 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 22:08:28 - INFO - __main__ - ['Film']
05/29/2022 22:08:28 - INFO - __main__ - Tokenizing Input ...
05/29/2022 22:08:28 - INFO - __main__ - Tokenizing Output ...
05/29/2022 22:08:28 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 22:08:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 22:08:28 - INFO - __main__ - Printing 3 examples
05/29/2022 22:08:28 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 22:08:28 - INFO - __main__ - ['Film']
05/29/2022 22:08:28 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 22:08:28 - INFO - __main__ - ['Film']
05/29/2022 22:08:28 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 22:08:28 - INFO - __main__ - ['Film']
05/29/2022 22:08:28 - INFO - __main__ - Tokenizing Input ...
05/29/2022 22:08:29 - INFO - __main__ - Tokenizing Output ...
05/29/2022 22:08:29 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 22:08:29 - INFO - __main__ - Global step 3000 Train loss 2.22 Classification-F1 0.032851719521665414 on epoch=214
05/29/2022 22:08:29 - INFO - __main__ - save last model!
05/29/2022 22:08:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 22:08:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 22:08:29 - INFO - __main__ - Printing 3 examples
05/29/2022 22:08:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 22:08:29 - INFO - __main__ - ['Animal']
05/29/2022 22:08:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 22:08:29 - INFO - __main__ - ['Animal']
05/29/2022 22:08:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 22:08:29 - INFO - __main__ - ['Village']
05/29/2022 22:08:29 - INFO - __main__ - Tokenizing Input ...
05/29/2022 22:08:31 - INFO - __main__ - Tokenizing Output ...
05/29/2022 22:08:34 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 22:08:34 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 22:08:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 22:08:35 - INFO - __main__ - Starting training!
05/29/2022 22:09:04 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/29/2022 22:09:04 - INFO - __main__ - Classification-F1 on test data: 0.0347
05/29/2022 22:09:05 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.061464262142871484, test_performance=0.0346654571503911
05/29/2022 22:09:05 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/29/2022 22:09:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 22:09:06 - INFO - __main__ - Printing 3 examples
05/29/2022 22:09:06 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/29/2022 22:09:06 - INFO - __main__ - ['Film']
05/29/2022 22:09:06 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/29/2022 22:09:06 - INFO - __main__ - ['Film']
05/29/2022 22:09:06 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/29/2022 22:09:06 - INFO - __main__ - ['Film']
05/29/2022 22:09:06 - INFO - __main__ - Tokenizing Input ...
05/29/2022 22:09:06 - INFO - __main__ - Tokenizing Output ...
05/29/2022 22:09:06 - INFO - __main__ - Loaded 224 examples from train data
05/29/2022 22:09:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/29/2022 22:09:06 - INFO - __main__ - Printing 3 examples
05/29/2022 22:09:06 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/29/2022 22:09:06 - INFO - __main__ - ['Film']
05/29/2022 22:09:06 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/29/2022 22:09:06 - INFO - __main__ - ['Film']
05/29/2022 22:09:06 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/29/2022 22:09:06 - INFO - __main__ - ['Film']
05/29/2022 22:09:06 - INFO - __main__ - Tokenizing Input ...
05/29/2022 22:09:06 - INFO - __main__ - Tokenizing Output ...
05/29/2022 22:09:06 - INFO - __main__ - Loaded 224 examples from dev data
05/29/2022 22:09:12 - INFO - __main__ - load prompt embedding from ckpt
05/29/2022 22:09:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/29/2022 22:09:13 - INFO - __main__ - Starting training!
05/29/2022 22:09:15 - INFO - __main__ - Step 10 Global step 10 Train loss 7.40 on epoch=0
05/29/2022 22:09:16 - INFO - __main__ - Step 20 Global step 20 Train loss 7.44 on epoch=1
05/29/2022 22:09:17 - INFO - __main__ - Step 30 Global step 30 Train loss 7.14 on epoch=2
05/29/2022 22:09:19 - INFO - __main__ - Step 40 Global step 40 Train loss 7.24 on epoch=2
05/29/2022 22:09:20 - INFO - __main__ - Step 50 Global step 50 Train loss 7.14 on epoch=3
05/29/2022 22:09:31 - INFO - __main__ - Global step 50 Train loss 7.27 Classification-F1 0.0 on epoch=3
05/29/2022 22:09:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/29/2022 22:09:32 - INFO - __main__ - Step 60 Global step 60 Train loss 6.87 on epoch=4
05/29/2022 22:09:34 - INFO - __main__ - Step 70 Global step 70 Train loss 7.23 on epoch=4
05/29/2022 22:09:35 - INFO - __main__ - Step 80 Global step 80 Train loss 6.86 on epoch=5
05/29/2022 22:09:36 - INFO - __main__ - Step 90 Global step 90 Train loss 6.93 on epoch=6
05/29/2022 22:09:37 - INFO - __main__ - Step 100 Global step 100 Train loss 6.70 on epoch=7
05/29/2022 22:10:18 - INFO - __main__ - Global step 100 Train loss 6.92 Classification-F1 0.0 on epoch=7
05/29/2022 22:10:19 - INFO - __main__ - Step 110 Global step 110 Train loss 6.77 on epoch=7
05/29/2022 22:10:21 - INFO - __main__ - Step 120 Global step 120 Train loss 6.57 on epoch=8
05/29/2022 22:10:22 - INFO - __main__ - Step 130 Global step 130 Train loss 6.61 on epoch=9
05/29/2022 22:10:23 - INFO - __main__ - Step 140 Global step 140 Train loss 6.74 on epoch=9
05/29/2022 22:10:25 - INFO - __main__ - Step 150 Global step 150 Train loss 6.56 on epoch=10
05/29/2022 22:11:25 - INFO - __main__ - Global step 150 Train loss 6.65 Classification-F1 0.0 on epoch=10
05/29/2022 22:11:26 - INFO - __main__ - Step 160 Global step 160 Train loss 6.67 on epoch=11
05/29/2022 22:11:28 - INFO - __main__ - Step 170 Global step 170 Train loss 6.57 on epoch=12
05/29/2022 22:11:29 - INFO - __main__ - Step 180 Global step 180 Train loss 6.67 on epoch=12
05/29/2022 22:11:30 - INFO - __main__ - Step 190 Global step 190 Train loss 6.40 on epoch=13
05/29/2022 22:11:31 - INFO - __main__ - Step 200 Global step 200 Train loss 6.33 on epoch=14
05/29/2022 22:12:38 - INFO - __main__ - Global step 200 Train loss 6.53 Classification-F1 0.0 on epoch=14
05/29/2022 22:12:39 - INFO - __main__ - Step 210 Global step 210 Train loss 6.54 on epoch=14
05/29/2022 22:12:40 - INFO - __main__ - Step 220 Global step 220 Train loss 6.45 on epoch=15
05/29/2022 22:12:42 - INFO - __main__ - Step 230 Global step 230 Train loss 6.30 on epoch=16
05/29/2022 22:12:43 - INFO - __main__ - Step 240 Global step 240 Train loss 6.22 on epoch=17
05/29/2022 22:12:44 - INFO - __main__ - Step 250 Global step 250 Train loss 6.47 on epoch=17
05/29/2022 22:13:42 - INFO - __main__ - Global step 250 Train loss 6.39 Classification-F1 0.0 on epoch=17
05/29/2022 22:13:44 - INFO - __main__ - Step 260 Global step 260 Train loss 6.30 on epoch=18
05/29/2022 22:13:45 - INFO - __main__ - Step 270 Global step 270 Train loss 6.17 on epoch=19
05/29/2022 22:13:46 - INFO - __main__ - Step 280 Global step 280 Train loss 6.35 on epoch=19
05/29/2022 22:13:48 - INFO - __main__ - Step 290 Global step 290 Train loss 6.19 on epoch=20
05/29/2022 22:13:49 - INFO - __main__ - Step 300 Global step 300 Train loss 6.28 on epoch=21
05/29/2022 22:15:01 - INFO - __main__ - Global step 300 Train loss 6.26 Classification-F1 0.0 on epoch=21
05/29/2022 22:15:02 - INFO - __main__ - Step 310 Global step 310 Train loss 6.17 on epoch=22
05/29/2022 22:15:03 - INFO - __main__ - Step 320 Global step 320 Train loss 6.27 on epoch=22
05/29/2022 22:15:05 - INFO - __main__ - Step 330 Global step 330 Train loss 6.14 on epoch=23
05/29/2022 22:15:06 - INFO - __main__ - Step 340 Global step 340 Train loss 5.99 on epoch=24
05/29/2022 22:15:07 - INFO - __main__ - Step 350 Global step 350 Train loss 6.21 on epoch=24
05/29/2022 22:16:16 - INFO - __main__ - Global step 350 Train loss 6.16 Classification-F1 0.0 on epoch=24
05/29/2022 22:16:17 - INFO - __main__ - Step 360 Global step 360 Train loss 6.03 on epoch=25
05/29/2022 22:16:18 - INFO - __main__ - Step 370 Global step 370 Train loss 6.07 on epoch=26
05/29/2022 22:16:20 - INFO - __main__ - Step 380 Global step 380 Train loss 5.89 on epoch=27
05/29/2022 22:16:21 - INFO - __main__ - Step 390 Global step 390 Train loss 5.97 on epoch=27
05/29/2022 22:16:22 - INFO - __main__ - Step 400 Global step 400 Train loss 5.79 on epoch=28
05/29/2022 22:17:33 - INFO - __main__ - Global step 400 Train loss 5.95 Classification-F1 0.0 on epoch=28
05/29/2022 22:17:35 - INFO - __main__ - Step 410 Global step 410 Train loss 5.85 on epoch=29
05/29/2022 22:17:36 - INFO - __main__ - Step 420 Global step 420 Train loss 6.00 on epoch=29
05/29/2022 22:17:37 - INFO - __main__ - Step 430 Global step 430 Train loss 5.83 on epoch=30
05/29/2022 22:17:38 - INFO - __main__ - Step 440 Global step 440 Train loss 5.80 on epoch=31
05/29/2022 22:17:40 - INFO - __main__ - Step 450 Global step 450 Train loss 5.67 on epoch=32
05/29/2022 22:18:35 - INFO - __main__ - Global step 450 Train loss 5.83 Classification-F1 0.0 on epoch=32
05/29/2022 22:18:36 - INFO - __main__ - Step 460 Global step 460 Train loss 5.74 on epoch=32
05/29/2022 22:18:38 - INFO - __main__ - Step 470 Global step 470 Train loss 5.61 on epoch=33
05/29/2022 22:18:39 - INFO - __main__ - Step 480 Global step 480 Train loss 5.54 on epoch=34
05/29/2022 22:18:40 - INFO - __main__ - Step 490 Global step 490 Train loss 5.72 on epoch=34
05/29/2022 22:18:42 - INFO - __main__ - Step 500 Global step 500 Train loss 5.58 on epoch=35
05/29/2022 22:19:15 - INFO - __main__ - Global step 500 Train loss 5.64 Classification-F1 0.0019230769230769232 on epoch=35
05/29/2022 22:19:15 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0019230769230769232 on epoch=35, global_step=500
05/29/2022 22:19:17 - INFO - __main__ - Step 510 Global step 510 Train loss 5.59 on epoch=36
05/29/2022 22:19:18 - INFO - __main__ - Step 520 Global step 520 Train loss 5.54 on epoch=37
05/29/2022 22:19:19 - INFO - __main__ - Step 530 Global step 530 Train loss 5.57 on epoch=37
05/29/2022 22:19:20 - INFO - __main__ - Step 540 Global step 540 Train loss 5.40 on epoch=38
05/29/2022 22:19:22 - INFO - __main__ - Step 550 Global step 550 Train loss 5.38 on epoch=39
05/29/2022 22:19:47 - INFO - __main__ - Global step 550 Train loss 5.50 Classification-F1 0.003961516694963214 on epoch=39
05/29/2022 22:19:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0019230769230769232 -> 0.003961516694963214 on epoch=39, global_step=550
05/29/2022 22:19:49 - INFO - __main__ - Step 560 Global step 560 Train loss 5.50 on epoch=39
05/29/2022 22:19:50 - INFO - __main__ - Step 570 Global step 570 Train loss 5.49 on epoch=40
05/29/2022 22:19:51 - INFO - __main__ - Step 580 Global step 580 Train loss 5.35 on epoch=41
05/29/2022 22:19:53 - INFO - __main__ - Step 590 Global step 590 Train loss 5.28 on epoch=42
05/29/2022 22:19:54 - INFO - __main__ - Step 600 Global step 600 Train loss 5.47 on epoch=42
05/29/2022 22:20:20 - INFO - __main__ - Global step 600 Train loss 5.42 Classification-F1 0.0026262036766851473 on epoch=42
05/29/2022 22:20:21 - INFO - __main__ - Step 610 Global step 610 Train loss 5.28 on epoch=43
05/29/2022 22:20:23 - INFO - __main__ - Step 620 Global step 620 Train loss 5.16 on epoch=44
05/29/2022 22:20:24 - INFO - __main__ - Step 630 Global step 630 Train loss 5.38 on epoch=44
05/29/2022 22:20:25 - INFO - __main__ - Step 640 Global step 640 Train loss 5.25 on epoch=45
05/29/2022 22:20:27 - INFO - __main__ - Step 650 Global step 650 Train loss 5.30 on epoch=46
05/29/2022 22:20:54 - INFO - __main__ - Global step 650 Train loss 5.27 Classification-F1 0.004222972972972973 on epoch=46
05/29/2022 22:20:54 - INFO - __main__ - Saving model with best Classification-F1: 0.003961516694963214 -> 0.004222972972972973 on epoch=46, global_step=650
05/29/2022 22:20:55 - INFO - __main__ - Step 660 Global step 660 Train loss 5.30 on epoch=47
05/29/2022 22:20:56 - INFO - __main__ - Step 670 Global step 670 Train loss 5.32 on epoch=47
05/29/2022 22:20:58 - INFO - __main__ - Step 680 Global step 680 Train loss 5.22 on epoch=48
05/29/2022 22:20:59 - INFO - __main__ - Step 690 Global step 690 Train loss 5.12 on epoch=49
05/29/2022 22:21:00 - INFO - __main__ - Step 700 Global step 700 Train loss 5.16 on epoch=49
05/29/2022 22:21:04 - INFO - __main__ - Global step 700 Train loss 5.22 Classification-F1 0.0071225071225071235 on epoch=49
05/29/2022 22:21:04 - INFO - __main__ - Saving model with best Classification-F1: 0.004222972972972973 -> 0.0071225071225071235 on epoch=49, global_step=700
05/29/2022 22:21:06 - INFO - __main__ - Step 710 Global step 710 Train loss 5.11 on epoch=50
05/29/2022 22:21:07 - INFO - __main__ - Step 720 Global step 720 Train loss 5.11 on epoch=51
05/29/2022 22:21:08 - INFO - __main__ - Step 730 Global step 730 Train loss 5.13 on epoch=52
05/29/2022 22:21:09 - INFO - __main__ - Step 740 Global step 740 Train loss 5.12 on epoch=52
05/29/2022 22:21:11 - INFO - __main__ - Step 750 Global step 750 Train loss 5.01 on epoch=53
05/29/2022 22:21:13 - INFO - __main__ - Global step 750 Train loss 5.10 Classification-F1 0.009523809523809523 on epoch=53
05/29/2022 22:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0071225071225071235 -> 0.009523809523809523 on epoch=53, global_step=750
05/29/2022 22:21:15 - INFO - __main__ - Step 760 Global step 760 Train loss 4.95 on epoch=54
05/29/2022 22:21:16 - INFO - __main__ - Step 770 Global step 770 Train loss 5.02 on epoch=54
05/29/2022 22:21:17 - INFO - __main__ - Step 780 Global step 780 Train loss 5.04 on epoch=55
05/29/2022 22:21:18 - INFO - __main__ - Step 790 Global step 790 Train loss 4.93 on epoch=56
05/29/2022 22:21:20 - INFO - __main__ - Step 800 Global step 800 Train loss 4.91 on epoch=57
05/29/2022 22:21:22 - INFO - __main__ - Global step 800 Train loss 4.97 Classification-F1 0.009523809523809523 on epoch=57
05/29/2022 22:21:24 - INFO - __main__ - Step 810 Global step 810 Train loss 4.95 on epoch=57
05/29/2022 22:21:25 - INFO - __main__ - Step 820 Global step 820 Train loss 4.89 on epoch=58
05/29/2022 22:21:26 - INFO - __main__ - Step 830 Global step 830 Train loss 4.81 on epoch=59
05/29/2022 22:21:27 - INFO - __main__ - Step 840 Global step 840 Train loss 4.93 on epoch=59
05/29/2022 22:21:29 - INFO - __main__ - Step 850 Global step 850 Train loss 4.95 on epoch=60
05/29/2022 22:21:32 - INFO - __main__ - Global step 850 Train loss 4.91 Classification-F1 0.009523809523809523 on epoch=60
05/29/2022 22:21:33 - INFO - __main__ - Step 860 Global step 860 Train loss 4.73 on epoch=61
05/29/2022 22:21:34 - INFO - __main__ - Step 870 Global step 870 Train loss 4.80 on epoch=62
05/29/2022 22:21:36 - INFO - __main__ - Step 880 Global step 880 Train loss 4.68 on epoch=62
05/29/2022 22:21:37 - INFO - __main__ - Step 890 Global step 890 Train loss 4.71 on epoch=63
05/29/2022 22:21:38 - INFO - __main__ - Step 900 Global step 900 Train loss 4.70 on epoch=64
05/29/2022 22:21:40 - INFO - __main__ - Global step 900 Train loss 4.73 Classification-F1 0.009523809523809523 on epoch=64
05/29/2022 22:21:41 - INFO - __main__ - Step 910 Global step 910 Train loss 4.82 on epoch=64
05/29/2022 22:21:43 - INFO - __main__ - Step 920 Global step 920 Train loss 4.75 on epoch=65
05/29/2022 22:21:44 - INFO - __main__ - Step 930 Global step 930 Train loss 4.59 on epoch=66
05/29/2022 22:21:45 - INFO - __main__ - Step 940 Global step 940 Train loss 4.64 on epoch=67
05/29/2022 22:21:47 - INFO - __main__ - Step 950 Global step 950 Train loss 4.70 on epoch=67
05/29/2022 22:21:49 - INFO - __main__ - Global step 950 Train loss 4.70 Classification-F1 0.009523809523809523 on epoch=67
05/29/2022 22:21:50 - INFO - __main__ - Step 960 Global step 960 Train loss 4.49 on epoch=68
05/29/2022 22:21:51 - INFO - __main__ - Step 970 Global step 970 Train loss 4.50 on epoch=69
05/29/2022 22:21:52 - INFO - __main__ - Step 980 Global step 980 Train loss 4.53 on epoch=69
05/29/2022 22:21:54 - INFO - __main__ - Step 990 Global step 990 Train loss 4.63 on epoch=70
05/29/2022 22:21:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 4.39 on epoch=71
05/29/2022 22:21:57 - INFO - __main__ - Global step 1000 Train loss 4.51 Classification-F1 0.009523809523809523 on epoch=71
05/29/2022 22:21:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 4.47 on epoch=72
05/29/2022 22:22:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 4.39 on epoch=72
05/29/2022 22:22:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 4.49 on epoch=73
05/29/2022 22:22:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 4.25 on epoch=74
05/29/2022 22:22:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 4.42 on epoch=74
05/29/2022 22:22:05 - INFO - __main__ - Global step 1050 Train loss 4.41 Classification-F1 0.009523809523809523 on epoch=74
05/29/2022 22:22:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 4.47 on epoch=75
05/29/2022 22:22:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 4.40 on epoch=76
05/29/2022 22:22:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 4.47 on epoch=77
05/29/2022 22:22:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 4.31 on epoch=77
05/29/2022 22:22:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 4.38 on epoch=78
05/29/2022 22:22:14 - INFO - __main__ - Global step 1100 Train loss 4.41 Classification-F1 0.009523809523809523 on epoch=78
05/29/2022 22:22:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 4.23 on epoch=79
05/29/2022 22:22:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 4.23 on epoch=79
05/29/2022 22:22:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 4.46 on epoch=80
05/29/2022 22:22:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 4.27 on epoch=81
05/29/2022 22:22:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 4.21 on epoch=82
05/29/2022 22:22:22 - INFO - __main__ - Global step 1150 Train loss 4.28 Classification-F1 0.009563658099222952 on epoch=82
05/29/2022 22:22:22 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009563658099222952 on epoch=82, global_step=1150
05/29/2022 22:22:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 4.20 on epoch=82
05/29/2022 22:22:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 4.28 on epoch=83
05/29/2022 22:22:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 4.06 on epoch=84
05/29/2022 22:22:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 4.17 on epoch=84
05/29/2022 22:22:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 4.38 on epoch=85
05/29/2022 22:22:31 - INFO - __main__ - Global step 1200 Train loss 4.22 Classification-F1 0.017104407565519775 on epoch=85
05/29/2022 22:22:31 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.017104407565519775 on epoch=85, global_step=1200
05/29/2022 22:22:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 4.06 on epoch=86
05/29/2022 22:22:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 4.06 on epoch=87
05/29/2022 22:22:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 4.09 on epoch=87
05/29/2022 22:22:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 4.10 on epoch=88
05/29/2022 22:22:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 4.02 on epoch=89
05/29/2022 22:22:39 - INFO - __main__ - Global step 1250 Train loss 4.07 Classification-F1 0.01761922888683452 on epoch=89
05/29/2022 22:22:39 - INFO - __main__ - Saving model with best Classification-F1: 0.017104407565519775 -> 0.01761922888683452 on epoch=89, global_step=1250
05/29/2022 22:22:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 4.02 on epoch=89
05/29/2022 22:22:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 4.31 on epoch=90
05/29/2022 22:22:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 3.87 on epoch=91
05/29/2022 22:22:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 4.10 on epoch=92
05/29/2022 22:22:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 3.99 on epoch=92
05/29/2022 22:22:48 - INFO - __main__ - Global step 1300 Train loss 4.06 Classification-F1 0.021873187930223786 on epoch=92
05/29/2022 22:22:48 - INFO - __main__ - Saving model with best Classification-F1: 0.01761922888683452 -> 0.021873187930223786 on epoch=92, global_step=1300
05/29/2022 22:22:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 4.04 on epoch=93
05/29/2022 22:22:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 3.82 on epoch=94
05/29/2022 22:22:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 3.95 on epoch=94
05/29/2022 22:22:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 4.03 on epoch=95
05/29/2022 22:22:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 3.83 on epoch=96
05/29/2022 22:22:56 - INFO - __main__ - Global step 1350 Train loss 3.93 Classification-F1 0.018614718614718615 on epoch=96
05/29/2022 22:22:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 3.93 on epoch=97
05/29/2022 22:22:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 3.96 on epoch=97
05/29/2022 22:23:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 3.91 on epoch=98
05/29/2022 22:23:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 3.80 on epoch=99
05/29/2022 22:23:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 3.74 on epoch=99
05/29/2022 22:23:04 - INFO - __main__ - Global step 1400 Train loss 3.87 Classification-F1 0.014901337247227659 on epoch=99
05/29/2022 22:23:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 3.93 on epoch=100
05/29/2022 22:23:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 3.64 on epoch=101
05/29/2022 22:23:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 3.73 on epoch=102
05/29/2022 22:23:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 3.72 on epoch=102
05/29/2022 22:23:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 3.80 on epoch=103
05/29/2022 22:23:13 - INFO - __main__ - Global step 1450 Train loss 3.76 Classification-F1 0.019930875576036868 on epoch=103
05/29/2022 22:23:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 3.65 on epoch=104
05/29/2022 22:23:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 3.72 on epoch=104
05/29/2022 22:23:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 3.83 on epoch=105
05/29/2022 22:23:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 3.65 on epoch=106
05/29/2022 22:23:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 3.65 on epoch=107
05/29/2022 22:23:21 - INFO - __main__ - Global step 1500 Train loss 3.70 Classification-F1 0.024521114427606305 on epoch=107
05/29/2022 22:23:21 - INFO - __main__ - Saving model with best Classification-F1: 0.021873187930223786 -> 0.024521114427606305 on epoch=107, global_step=1500
05/29/2022 22:23:23 - INFO - __main__ - Step 1510 Global step 1510 Train loss 3.77 on epoch=107
05/29/2022 22:23:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 3.71 on epoch=108
05/29/2022 22:23:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 3.65 on epoch=109
05/29/2022 22:23:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 3.56 on epoch=109
05/29/2022 22:23:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 3.68 on epoch=110
05/29/2022 22:23:30 - INFO - __main__ - Global step 1550 Train loss 3.67 Classification-F1 0.03806269982740571 on epoch=110
05/29/2022 22:23:30 - INFO - __main__ - Saving model with best Classification-F1: 0.024521114427606305 -> 0.03806269982740571 on epoch=110, global_step=1550
05/29/2022 22:23:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 3.58 on epoch=111
05/29/2022 22:23:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 3.69 on epoch=112
05/29/2022 22:23:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 3.68 on epoch=112
05/29/2022 22:23:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 3.53 on epoch=113
05/29/2022 22:23:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 3.67 on epoch=114
05/29/2022 22:23:38 - INFO - __main__ - Global step 1600 Train loss 3.63 Classification-F1 0.02168909092660188 on epoch=114
05/29/2022 22:23:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 3.52 on epoch=114
05/29/2022 22:23:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 3.71 on epoch=115
05/29/2022 22:23:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 3.55 on epoch=116
05/29/2022 22:23:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 3.61 on epoch=117
05/29/2022 22:23:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 3.45 on epoch=117
05/29/2022 22:23:47 - INFO - __main__ - Global step 1650 Train loss 3.57 Classification-F1 0.009563658099222952 on epoch=117
05/29/2022 22:23:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 3.67 on epoch=118
05/29/2022 22:23:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 3.47 on epoch=119
05/29/2022 22:23:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 3.43 on epoch=119
05/29/2022 22:23:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 3.70 on epoch=120
05/29/2022 22:23:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 3.55 on epoch=121
05/29/2022 22:23:55 - INFO - __main__ - Global step 1700 Train loss 3.56 Classification-F1 0.017704517704517704 on epoch=121
05/29/2022 22:23:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 3.62 on epoch=122
05/29/2022 22:23:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 3.47 on epoch=122
05/29/2022 22:23:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 3.70 on epoch=123
05/29/2022 22:24:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 3.44 on epoch=124
05/29/2022 22:24:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 3.44 on epoch=124
05/29/2022 22:24:04 - INFO - __main__ - Global step 1750 Train loss 3.53 Classification-F1 0.027118440539566906 on epoch=124
05/29/2022 22:24:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 3.65 on epoch=125
05/29/2022 22:24:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 3.43 on epoch=126
05/29/2022 22:24:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 3.45 on epoch=127
05/29/2022 22:24:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 3.29 on epoch=127
05/29/2022 22:24:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 3.54 on epoch=128
05/29/2022 22:24:12 - INFO - __main__ - Global step 1800 Train loss 3.47 Classification-F1 0.024031853828118684 on epoch=128
05/29/2022 22:24:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 3.37 on epoch=129
05/29/2022 22:24:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 3.50 on epoch=129
05/29/2022 22:24:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 3.61 on epoch=130
05/29/2022 22:24:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 3.37 on epoch=131
05/29/2022 22:24:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 3.53 on epoch=132
05/29/2022 22:24:20 - INFO - __main__ - Global step 1850 Train loss 3.48 Classification-F1 0.012161468360929278 on epoch=132
05/29/2022 22:24:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 3.48 on epoch=132
05/29/2022 22:24:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 3.55 on epoch=133
05/29/2022 22:24:24 - INFO - __main__ - Step 1880 Global step 1880 Train loss 3.42 on epoch=134
05/29/2022 22:24:26 - INFO - __main__ - Step 1890 Global step 1890 Train loss 3.36 on epoch=134
05/29/2022 22:24:27 - INFO - __main__ - Step 1900 Global step 1900 Train loss 3.47 on epoch=135
05/29/2022 22:24:29 - INFO - __main__ - Global step 1900 Train loss 3.46 Classification-F1 0.010249839846252402 on epoch=135
05/29/2022 22:24:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 3.31 on epoch=136
05/29/2022 22:24:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 3.41 on epoch=137
05/29/2022 22:24:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 3.34 on epoch=137
05/29/2022 22:24:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 3.39 on epoch=138
05/29/2022 22:24:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 3.45 on epoch=139
05/29/2022 22:24:37 - INFO - __main__ - Global step 1950 Train loss 3.38 Classification-F1 0.0206747275712793 on epoch=139
05/29/2022 22:24:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 3.39 on epoch=139
05/29/2022 22:24:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 3.58 on epoch=140
05/29/2022 22:24:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 3.33 on epoch=141
05/29/2022 22:24:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 3.32 on epoch=142
05/29/2022 22:24:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 3.40 on epoch=142
05/29/2022 22:24:46 - INFO - __main__ - Global step 2000 Train loss 3.40 Classification-F1 0.02703772418058133 on epoch=142
05/29/2022 22:24:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 3.35 on epoch=143
05/29/2022 22:24:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 3.27 on epoch=144
05/29/2022 22:24:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 3.24 on epoch=144
05/29/2022 22:24:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 3.38 on epoch=145
05/29/2022 22:24:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 3.23 on epoch=146
05/29/2022 22:24:54 - INFO - __main__ - Global step 2050 Train loss 3.30 Classification-F1 0.021442651969264186 on epoch=146
05/29/2022 22:24:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 3.40 on epoch=147
05/29/2022 22:24:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 3.14 on epoch=147
05/29/2022 22:24:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 3.46 on epoch=148
05/29/2022 22:25:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 3.26 on epoch=149
05/29/2022 22:25:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 3.35 on epoch=149
05/29/2022 22:25:03 - INFO - __main__ - Global step 2100 Train loss 3.32 Classification-F1 0.009563658099222952 on epoch=149
05/29/2022 22:25:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 3.43 on epoch=150
05/29/2022 22:25:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 3.20 on epoch=151
05/29/2022 22:25:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 3.21 on epoch=152
05/29/2022 22:25:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 3.22 on epoch=152
05/29/2022 22:25:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 3.36 on epoch=153
05/29/2022 22:25:13 - INFO - __main__ - Global step 2150 Train loss 3.28 Classification-F1 0.01544973544973545 on epoch=153
05/29/2022 22:25:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 3.24 on epoch=154
05/29/2022 22:25:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 3.17 on epoch=154
05/29/2022 22:25:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 3.35 on epoch=155
05/29/2022 22:25:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 3.03 on epoch=156
05/29/2022 22:25:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 3.18 on epoch=157
05/29/2022 22:25:23 - INFO - __main__ - Global step 2200 Train loss 3.19 Classification-F1 0.009563658099222952 on epoch=157
05/29/2022 22:25:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 3.17 on epoch=157
05/29/2022 22:25:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 3.18 on epoch=158
05/29/2022 22:25:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 3.17 on epoch=159
05/29/2022 22:25:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 3.13 on epoch=159
05/29/2022 22:25:30 - INFO - __main__ - Step 2250 Global step 2250 Train loss 3.21 on epoch=160
05/29/2022 22:25:32 - INFO - __main__ - Global step 2250 Train loss 3.17 Classification-F1 0.009523809523809523 on epoch=160
05/29/2022 22:25:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 3.12 on epoch=161
05/29/2022 22:25:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 3.33 on epoch=162
05/29/2022 22:25:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 3.04 on epoch=162
05/29/2022 22:25:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 3.16 on epoch=163
05/29/2022 22:25:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 3.12 on epoch=164
05/29/2022 22:25:40 - INFO - __main__ - Global step 2300 Train loss 3.15 Classification-F1 0.009563658099222952 on epoch=164
05/29/2022 22:25:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 3.08 on epoch=164
05/29/2022 22:25:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 3.26 on epoch=165
05/29/2022 22:25:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 3.22 on epoch=166
05/29/2022 22:25:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 3.09 on epoch=167
05/29/2022 22:25:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 3.13 on epoch=167
05/29/2022 22:25:49 - INFO - __main__ - Global step 2350 Train loss 3.16 Classification-F1 0.01796701944376077 on epoch=167
05/29/2022 22:25:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 3.15 on epoch=168
05/29/2022 22:25:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 2.98 on epoch=169
05/29/2022 22:25:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 3.08 on epoch=169
05/29/2022 22:25:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 3.23 on epoch=170
05/29/2022 22:25:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 2.92 on epoch=171
05/29/2022 22:25:57 - INFO - __main__ - Global step 2400 Train loss 3.07 Classification-F1 0.015272290381460687 on epoch=171
05/29/2022 22:25:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 3.19 on epoch=172
05/29/2022 22:26:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 3.00 on epoch=172
05/29/2022 22:26:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 3.14 on epoch=173
05/29/2022 22:26:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 2.99 on epoch=174
05/29/2022 22:26:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 3.07 on epoch=174
05/29/2022 22:26:06 - INFO - __main__ - Global step 2450 Train loss 3.08 Classification-F1 0.009523809523809523 on epoch=174
05/29/2022 22:26:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 3.14 on epoch=175
05/29/2022 22:26:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 2.92 on epoch=176
05/29/2022 22:26:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 2.99 on epoch=177
05/29/2022 22:26:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 3.21 on epoch=177
05/29/2022 22:26:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 3.11 on epoch=178
05/29/2022 22:26:14 - INFO - __main__ - Global step 2500 Train loss 3.07 Classification-F1 0.022317227286171384 on epoch=178
05/29/2022 22:26:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 3.07 on epoch=179
05/29/2022 22:26:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 3.04 on epoch=179
05/29/2022 22:26:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 3.12 on epoch=180
05/29/2022 22:26:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 3.11 on epoch=181
05/29/2022 22:26:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 3.08 on epoch=182
05/29/2022 22:26:23 - INFO - __main__ - Global step 2550 Train loss 3.08 Classification-F1 0.017580872011251757 on epoch=182
05/29/2022 22:26:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 3.01 on epoch=182
05/29/2022 22:26:25 - INFO - __main__ - Step 2570 Global step 2570 Train loss 3.11 on epoch=183
05/29/2022 22:26:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 2.79 on epoch=184
05/29/2022 22:26:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 2.93 on epoch=184
05/29/2022 22:26:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 3.12 on epoch=185
05/29/2022 22:26:31 - INFO - __main__ - Global step 2600 Train loss 2.99 Classification-F1 0.009644364074743823 on epoch=185
05/29/2022 22:26:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 2.86 on epoch=186
05/29/2022 22:26:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 3.07 on epoch=187
05/29/2022 22:26:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 2.84 on epoch=187
05/29/2022 22:26:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 3.02 on epoch=188
05/29/2022 22:26:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 2.95 on epoch=189
05/29/2022 22:26:40 - INFO - __main__ - Global step 2650 Train loss 2.95 Classification-F1 0.009041591320072331 on epoch=189
05/29/2022 22:26:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 2.95 on epoch=189
05/29/2022 22:26:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 3.11 on epoch=190
05/29/2022 22:26:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 2.99 on epoch=191
05/29/2022 22:26:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 2.98 on epoch=192
05/29/2022 22:26:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 3.03 on epoch=192
05/29/2022 22:26:48 - INFO - __main__ - Global step 2700 Train loss 3.01 Classification-F1 0.009523809523809523 on epoch=192
05/29/2022 22:26:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 3.06 on epoch=193
05/29/2022 22:26:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 2.96 on epoch=194
05/29/2022 22:26:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 2.93 on epoch=194
05/29/2022 22:26:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 3.11 on epoch=195
05/29/2022 22:26:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 2.95 on epoch=196
05/29/2022 22:26:57 - INFO - __main__ - Global step 2750 Train loss 3.00 Classification-F1 0.009523809523809523 on epoch=196
05/29/2022 22:26:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 3.21 on epoch=197
05/29/2022 22:26:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 2.98 on epoch=197
05/29/2022 22:27:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 3.19 on epoch=198
05/29/2022 22:27:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 2.94 on epoch=199
05/29/2022 22:27:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 2.94 on epoch=199
05/29/2022 22:27:05 - INFO - __main__ - Global step 2800 Train loss 3.05 Classification-F1 0.0394118460156196 on epoch=199
05/29/2022 22:27:05 - INFO - __main__ - Saving model with best Classification-F1: 0.03806269982740571 -> 0.0394118460156196 on epoch=199, global_step=2800
05/29/2022 22:27:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 3.06 on epoch=200
05/29/2022 22:27:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 2.84 on epoch=201
05/29/2022 22:27:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 2.90 on epoch=202
05/29/2022 22:27:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 3.04 on epoch=202
05/29/2022 22:27:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 3.08 on epoch=203
05/29/2022 22:27:14 - INFO - __main__ - Global step 2850 Train loss 2.98 Classification-F1 0.04125036111791079 on epoch=203
05/29/2022 22:27:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0394118460156196 -> 0.04125036111791079 on epoch=203, global_step=2850
05/29/2022 22:27:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 2.90 on epoch=204
05/29/2022 22:27:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 2.88 on epoch=204
05/29/2022 22:27:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 3.10 on epoch=205
05/29/2022 22:27:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 2.96 on epoch=206
05/29/2022 22:27:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 2.95 on epoch=207
05/29/2022 22:27:22 - INFO - __main__ - Global step 2900 Train loss 2.96 Classification-F1 0.0442352965116097 on epoch=207
05/29/2022 22:27:22 - INFO - __main__ - Saving model with best Classification-F1: 0.04125036111791079 -> 0.0442352965116097 on epoch=207, global_step=2900
05/29/2022 22:27:23 - INFO - __main__ - Step 2910 Global step 2910 Train loss 2.82 on epoch=207
05/29/2022 22:27:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 3.07 on epoch=208
05/29/2022 22:27:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 2.94 on epoch=209
05/29/2022 22:27:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 2.86 on epoch=209
05/29/2022 22:27:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 3.08 on epoch=210
05/29/2022 22:27:31 - INFO - __main__ - Global step 2950 Train loss 2.95 Classification-F1 0.05457669787448294 on epoch=210
05/29/2022 22:27:31 - INFO - __main__ - Saving model with best Classification-F1: 0.0442352965116097 -> 0.05457669787448294 on epoch=210, global_step=2950
05/29/2022 22:27:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 2.69 on epoch=211
05/29/2022 22:27:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 2.90 on epoch=212
05/29/2022 22:27:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 2.86 on epoch=212
05/29/2022 22:27:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 2.98 on epoch=213
05/29/2022 22:27:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 2.88 on epoch=214
05/29/2022 22:27:39 - INFO - __main__ - Global step 3000 Train loss 2.86 Classification-F1 0.020305480682839168 on epoch=214
05/29/2022 22:27:39 - INFO - __main__ - save last model!
05/29/2022 22:27:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/29/2022 22:27:39 - INFO - __main__ - Start tokenizing ... 3500 instances
05/29/2022 22:27:39 - INFO - __main__ - Printing 3 examples
05/29/2022 22:27:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/29/2022 22:27:39 - INFO - __main__ - ['Animal']
05/29/2022 22:27:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/29/2022 22:27:39 - INFO - __main__ - ['Animal']
05/29/2022 22:27:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/29/2022 22:27:39 - INFO - __main__ - ['Village']
05/29/2022 22:27:39 - INFO - __main__ - Tokenizing Input ...
05/29/2022 22:27:41 - INFO - __main__ - Tokenizing Output ...
05/29/2022 22:27:44 - INFO - __main__ - Loaded 3500 examples from test data
05/29/2022 22:28:14 - INFO - __main__ - Saved prediction in models/T5-base-fomaml-cls2cls-3e-5-2-5000-5e-1/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/29/2022 22:28:14 - INFO - __main__ - Classification-F1 on test data: 0.0272
05/29/2022 22:28:14 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.05457669787448294, test_performance=0.027175661431532258
