05/21/2022 21:28:31 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/21/2022 21:28:31 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-emo
05/21/2022 21:28:31 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/21/2022 21:28:31 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-emo
05/21/2022 21:28:31 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:28:31 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:28:31 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:28:31 - INFO - __main__ - Using 2 gpus
05/21/2022 21:28:31 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:28:31 - INFO - __main__ - Using 2 gpus
05/21/2022 21:28:31 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
05/21/2022 21:28:31 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
05/21/2022 21:28:37 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.5, bsz=8 ...
06/04/2022 05:00:34 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
06/04/2022 05:00:34 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-emo
06/04/2022 05:00:34 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
06/04/2022 05:00:34 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-emo
06/04/2022 05:00:35 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/04/2022 05:00:35 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/04/2022 05:00:35 - INFO - __main__ - args.device: cuda:0
06/04/2022 05:00:35 - INFO - __main__ - Using 2 gpus
06/04/2022 05:00:35 - INFO - __main__ - args.device: cuda:1
06/04/2022 05:00:35 - INFO - __main__ - Using 2 gpus
06/04/2022 05:00:35 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
06/04/2022 05:00:35 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
06/04/2022 05:00:40 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.5, bsz=8 ...
06/04/2022 05:00:40 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:00:40 - INFO - __main__ - Printing 3 examples
06/04/2022 05:00:40 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:00:40 - INFO - __main__ - ['others']
06/04/2022 05:00:40 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:00:40 - INFO - __main__ - ['others']
06/04/2022 05:00:40 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:00:40 - INFO - __main__ - ['others']
06/04/2022 05:00:40 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:00:40 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:00:40 - INFO - __main__ - Printing 3 examples
06/04/2022 05:00:40 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:00:40 - INFO - __main__ - ['others']
06/04/2022 05:00:40 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:00:40 - INFO - __main__ - ['others']
06/04/2022 05:00:40 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:00:40 - INFO - __main__ - ['others']
06/04/2022 05:00:40 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:00:41 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:00:41 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:00:41 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:00:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:00:41 - INFO - __main__ - Printing 3 examples
06/04/2022 05:00:41 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:00:41 - INFO - __main__ - ['others']
06/04/2022 05:00:41 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:00:41 - INFO - __main__ - ['others']
06/04/2022 05:00:41 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:00:41 - INFO - __main__ - ['others']
06/04/2022 05:00:41 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:00:41 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:00:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:00:41 - INFO - __main__ - Printing 3 examples
06/04/2022 05:00:41 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:00:41 - INFO - __main__ - ['others']
06/04/2022 05:00:41 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:00:41 - INFO - __main__ - ['others']
06/04/2022 05:00:41 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:00:41 - INFO - __main__ - ['others']
06/04/2022 05:00:41 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:00:41 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:00:41 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:00:41 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:00:41 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:00:59 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:00:59 - INFO - __main__ - task name: emo
06/04/2022 05:00:59 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:00:59 - INFO - __main__ - task name: emo
06/04/2022 05:00:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:00:59 - INFO - __main__ - Starting training!
06/04/2022 05:01:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:01:00 - INFO - __main__ - Starting training!
06/04/2022 05:01:03 - INFO - __main__ - Step 10 Global step 10 Train loss 6.44 on epoch=1
06/04/2022 05:01:06 - INFO - __main__ - Step 20 Global step 20 Train loss 2.31 on epoch=2
06/04/2022 05:01:08 - INFO - __main__ - Step 30 Global step 30 Train loss 1.24 on epoch=3
06/04/2022 05:01:11 - INFO - __main__ - Step 40 Global step 40 Train loss 1.17 on epoch=4
06/04/2022 05:01:13 - INFO - __main__ - Step 50 Global step 50 Train loss 1.00 on epoch=6
06/04/2022 05:01:15 - INFO - __main__ - Global step 50 Train loss 2.43 Classification-F1 0.1 on epoch=6
06/04/2022 05:01:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/04/2022 05:01:18 - INFO - __main__ - Step 60 Global step 60 Train loss 1.02 on epoch=7
06/04/2022 05:01:20 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=8
06/04/2022 05:01:23 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=9
06/04/2022 05:01:25 - INFO - __main__ - Step 90 Global step 90 Train loss 1.00 on epoch=11
06/04/2022 05:01:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=12
06/04/2022 05:01:30 - INFO - __main__ - Global step 100 Train loss 0.97 Classification-F1 0.21362229102167182 on epoch=12
06/04/2022 05:01:30 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.21362229102167182 on epoch=12, global_step=100
06/04/2022 05:01:32 - INFO - __main__ - Step 110 Global step 110 Train loss 0.99 on epoch=13
06/04/2022 05:01:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=14
06/04/2022 05:01:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.92 on epoch=16
06/04/2022 05:01:40 - INFO - __main__ - Step 140 Global step 140 Train loss 0.86 on epoch=17
06/04/2022 05:01:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=18
06/04/2022 05:01:44 - INFO - __main__ - Global step 150 Train loss 0.90 Classification-F1 0.23683784658539217 on epoch=18
06/04/2022 05:01:44 - INFO - __main__ - Saving model with best Classification-F1: 0.21362229102167182 -> 0.23683784658539217 on epoch=18, global_step=150
06/04/2022 05:01:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=19
06/04/2022 05:01:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.88 on epoch=21
06/04/2022 05:01:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.88 on epoch=22
06/04/2022 05:01:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.81 on epoch=23
06/04/2022 05:01:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.85 on epoch=24
06/04/2022 05:01:59 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.2572390572390572 on epoch=24
06/04/2022 05:01:59 - INFO - __main__ - Saving model with best Classification-F1: 0.23683784658539217 -> 0.2572390572390572 on epoch=24, global_step=200
06/04/2022 05:02:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.91 on epoch=26
06/04/2022 05:02:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.80 on epoch=27
06/04/2022 05:02:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=28
06/04/2022 05:02:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.88 on epoch=29
06/04/2022 05:02:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.83 on epoch=31
06/04/2022 05:02:13 - INFO - __main__ - Global step 250 Train loss 0.84 Classification-F1 0.1304822565969063 on epoch=31
06/04/2022 05:02:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.76 on epoch=32
06/04/2022 05:02:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.86 on epoch=33
06/04/2022 05:02:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.77 on epoch=34
06/04/2022 05:02:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.83 on epoch=36
06/04/2022 05:02:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.67 on epoch=37
06/04/2022 05:02:27 - INFO - __main__ - Global step 300 Train loss 0.78 Classification-F1 0.4547637817055293 on epoch=37
06/04/2022 05:02:27 - INFO - __main__ - Saving model with best Classification-F1: 0.2572390572390572 -> 0.4547637817055293 on epoch=37, global_step=300
06/04/2022 05:02:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=38
06/04/2022 05:02:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.72 on epoch=39
06/04/2022 05:02:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.77 on epoch=41
06/04/2022 05:02:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.73 on epoch=42
06/04/2022 05:02:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=43
06/04/2022 05:02:41 - INFO - __main__ - Global step 350 Train loss 0.73 Classification-F1 0.3236401279879541 on epoch=43
06/04/2022 05:02:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.75 on epoch=44
06/04/2022 05:02:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.66 on epoch=46
06/04/2022 05:02:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.67 on epoch=47
06/04/2022 05:02:51 - INFO - __main__ - Step 390 Global step 390 Train loss 0.77 on epoch=48
06/04/2022 05:02:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.70 on epoch=49
06/04/2022 05:02:56 - INFO - __main__ - Global step 400 Train loss 0.71 Classification-F1 0.6558441110638231 on epoch=49
06/04/2022 05:02:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4547637817055293 -> 0.6558441110638231 on epoch=49, global_step=400
06/04/2022 05:02:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.68 on epoch=51
06/04/2022 05:03:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=52
06/04/2022 05:03:03 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=53
06/04/2022 05:03:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.59 on epoch=54
06/04/2022 05:03:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.57 on epoch=56
06/04/2022 05:03:10 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.5362792073351079 on epoch=56
06/04/2022 05:03:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.54 on epoch=57
06/04/2022 05:03:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.56 on epoch=58
06/04/2022 05:03:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.48 on epoch=59
06/04/2022 05:03:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.62 on epoch=61
06/04/2022 05:03:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=62
06/04/2022 05:03:24 - INFO - __main__ - Global step 500 Train loss 0.55 Classification-F1 0.6568773603657325 on epoch=62
06/04/2022 05:03:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6558441110638231 -> 0.6568773603657325 on epoch=62, global_step=500
06/04/2022 05:03:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.54 on epoch=63
06/04/2022 05:03:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=64
06/04/2022 05:03:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.48 on epoch=66
06/04/2022 05:03:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=67
06/04/2022 05:03:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=68
06/04/2022 05:03:39 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.7218424767720542 on epoch=68
06/04/2022 05:03:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6568773603657325 -> 0.7218424767720542 on epoch=68, global_step=550
06/04/2022 05:03:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.38 on epoch=69
06/04/2022 05:03:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.51 on epoch=71
06/04/2022 05:03:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=72
06/04/2022 05:03:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=73
06/04/2022 05:03:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=74
06/04/2022 05:03:53 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.6752319963187361 on epoch=74
06/04/2022 05:03:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=76
06/04/2022 05:03:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=77
06/04/2022 05:04:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=78
06/04/2022 05:04:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=79
06/04/2022 05:04:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=81
06/04/2022 05:04:08 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.755659558210614 on epoch=81
06/04/2022 05:04:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7218424767720542 -> 0.755659558210614 on epoch=81, global_step=650
06/04/2022 05:04:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=82
06/04/2022 05:04:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=83
06/04/2022 05:04:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=84
06/04/2022 05:04:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=86
06/04/2022 05:04:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=87
06/04/2022 05:04:23 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.7662816605098813 on epoch=87
06/04/2022 05:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.755659558210614 -> 0.7662816605098813 on epoch=87, global_step=700
06/04/2022 05:04:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=88
06/04/2022 05:04:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=89
06/04/2022 05:04:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=91
06/04/2022 05:04:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=92
06/04/2022 05:04:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=93
06/04/2022 05:04:37 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.7649482870071106 on epoch=93
06/04/2022 05:04:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=94
06/04/2022 05:04:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=96
06/04/2022 05:04:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=97
06/04/2022 05:04:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=98
06/04/2022 05:04:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=99
06/04/2022 05:04:51 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.7229686769518467 on epoch=99
06/04/2022 05:04:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=101
06/04/2022 05:04:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=102
06/04/2022 05:04:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=103
06/04/2022 05:05:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=104
06/04/2022 05:05:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=106
06/04/2022 05:05:06 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7472243442831679 on epoch=106
06/04/2022 05:05:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=107
06/04/2022 05:05:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=108
06/04/2022 05:05:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=109
06/04/2022 05:05:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=111
06/04/2022 05:05:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=112
06/04/2022 05:05:21 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.7257276714513556 on epoch=112
06/04/2022 05:05:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=113
06/04/2022 05:05:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=114
06/04/2022 05:05:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=116
06/04/2022 05:05:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=117
06/04/2022 05:05:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=118
06/04/2022 05:05:35 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6763009708889117 on epoch=118
06/04/2022 05:05:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=119
06/04/2022 05:05:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=121
06/04/2022 05:05:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=122
06/04/2022 05:05:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=123
06/04/2022 05:05:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=124
06/04/2022 05:05:50 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7502294806642633 on epoch=124
06/04/2022 05:05:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=126
06/04/2022 05:05:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=127
06/04/2022 05:05:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=128
06/04/2022 05:05:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=129
06/04/2022 05:06:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=131
06/04/2022 05:06:04 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.7355688227968648 on epoch=131
06/04/2022 05:06:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=132
06/04/2022 05:06:09 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=133
06/04/2022 05:06:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=134
06/04/2022 05:06:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=136
06/04/2022 05:06:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=137
06/04/2022 05:06:18 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.7326749468115693 on epoch=137
06/04/2022 05:06:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=138
06/04/2022 05:06:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=139
06/04/2022 05:06:26 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=141
06/04/2022 05:06:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=142
06/04/2022 05:06:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=143
06/04/2022 05:06:32 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7299899193548387 on epoch=143
06/04/2022 05:06:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=144
06/04/2022 05:06:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=146
06/04/2022 05:06:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=147
06/04/2022 05:06:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=148
06/04/2022 05:06:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=149
06/04/2022 05:06:47 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.740110683256628 on epoch=149
06/04/2022 05:06:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=151
06/04/2022 05:06:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=152
06/04/2022 05:06:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=153
06/04/2022 05:06:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=154
06/04/2022 05:06:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=156
06/04/2022 05:07:01 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7092797612823005 on epoch=156
06/04/2022 05:07:04 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=157
06/04/2022 05:07:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=158
06/04/2022 05:07:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=159
06/04/2022 05:07:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=161
06/04/2022 05:07:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=162
06/04/2022 05:07:16 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6895647371432994 on epoch=162
06/04/2022 05:07:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=163
06/04/2022 05:07:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=164
06/04/2022 05:07:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=166
06/04/2022 05:07:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=167
06/04/2022 05:07:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=168
06/04/2022 05:07:30 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7495528891490262 on epoch=168
06/04/2022 05:07:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=169
06/04/2022 05:07:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=171
06/04/2022 05:07:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=172
06/04/2022 05:07:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=173
06/04/2022 05:07:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=174
06/04/2022 05:07:45 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7430635105606715 on epoch=174
06/04/2022 05:07:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=176
06/04/2022 05:07:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=177
06/04/2022 05:07:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=178
06/04/2022 05:07:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=179
06/04/2022 05:07:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=181
06/04/2022 05:07:59 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7038339382940109 on epoch=181
06/04/2022 05:08:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=182
06/04/2022 05:08:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=183
06/04/2022 05:08:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=184
06/04/2022 05:08:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=186
06/04/2022 05:08:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=187
06/04/2022 05:08:13 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7655347626443867 on epoch=187
06/04/2022 05:08:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=188
06/04/2022 05:08:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=189
06/04/2022 05:08:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=191
06/04/2022 05:08:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=192
06/04/2022 05:08:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=193
06/04/2022 05:08:28 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7693882042253521 on epoch=193
06/04/2022 05:08:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7662816605098813 -> 0.7693882042253521 on epoch=193, global_step=1550
06/04/2022 05:08:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=194
06/04/2022 05:08:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=196
06/04/2022 05:08:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=197
06/04/2022 05:08:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=198
06/04/2022 05:08:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=199
06/04/2022 05:08:42 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7441747782825006 on epoch=199
06/04/2022 05:08:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=201
06/04/2022 05:08:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=202
06/04/2022 05:08:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
06/04/2022 05:08:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=204
06/04/2022 05:08:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
06/04/2022 05:08:56 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7334385318956197 on epoch=206
06/04/2022 05:08:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
06/04/2022 05:09:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
06/04/2022 05:09:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=209
06/04/2022 05:09:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=211
06/04/2022 05:09:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
06/04/2022 05:09:10 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7690905598283473 on epoch=212
06/04/2022 05:09:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=213
06/04/2022 05:09:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=214
06/04/2022 05:09:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=216
06/04/2022 05:09:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=217
06/04/2022 05:09:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=218
06/04/2022 05:09:24 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7397289216128193 on epoch=218
06/04/2022 05:09:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=219
06/04/2022 05:09:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=221
06/04/2022 05:09:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
06/04/2022 05:09:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=223
06/04/2022 05:09:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 05:09:39 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.755869399386865 on epoch=224
06/04/2022 05:09:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=226
06/04/2022 05:09:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=227
06/04/2022 05:09:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=228
06/04/2022 05:09:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=229
06/04/2022 05:09:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
06/04/2022 05:09:53 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7375202621207815 on epoch=231
06/04/2022 05:09:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=232
06/04/2022 05:09:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=233
06/04/2022 05:10:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
06/04/2022 05:10:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=236
06/04/2022 05:10:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/04/2022 05:10:07 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7387619749447311 on epoch=237
06/04/2022 05:10:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=238
06/04/2022 05:10:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
06/04/2022 05:10:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=241
06/04/2022 05:10:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=242
06/04/2022 05:10:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.15 on epoch=243
06/04/2022 05:10:22 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7763021626561072 on epoch=243
06/04/2022 05:10:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7693882042253521 -> 0.7763021626561072 on epoch=243, global_step=1950
06/04/2022 05:10:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
06/04/2022 05:10:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=246
06/04/2022 05:10:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
06/04/2022 05:10:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=248
06/04/2022 05:10:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=249
06/04/2022 05:10:36 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7324559206571828 on epoch=249
06/04/2022 05:10:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=251
06/04/2022 05:10:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
06/04/2022 05:10:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=253
06/04/2022 05:10:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=254
06/04/2022 05:10:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=256
06/04/2022 05:10:51 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7806961400181738 on epoch=256
06/04/2022 05:10:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7763021626561072 -> 0.7806961400181738 on epoch=256, global_step=2050
06/04/2022 05:10:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=257
06/04/2022 05:10:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
06/04/2022 05:10:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=259
06/04/2022 05:11:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=261
06/04/2022 05:11:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=262
06/04/2022 05:11:06 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7607752489331436 on epoch=262
06/04/2022 05:11:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=263
06/04/2022 05:11:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=264
06/04/2022 05:11:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=266
06/04/2022 05:11:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=267
06/04/2022 05:11:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/04/2022 05:11:21 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7581375244379277 on epoch=268
06/04/2022 05:11:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=269
06/04/2022 05:11:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 05:11:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=272
06/04/2022 05:11:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=273
06/04/2022 05:11:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
06/04/2022 05:11:36 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7733771873391663 on epoch=274
06/04/2022 05:11:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 05:11:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=277
06/04/2022 05:11:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/04/2022 05:11:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=279
06/04/2022 05:11:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=281
06/04/2022 05:11:50 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7632444238604013 on epoch=281
06/04/2022 05:11:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/04/2022 05:11:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=283
06/04/2022 05:11:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=284
06/04/2022 05:12:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=286
06/04/2022 05:12:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
06/04/2022 05:12:05 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7722557773109244 on epoch=287
06/04/2022 05:12:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=288
06/04/2022 05:12:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=289
06/04/2022 05:12:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=291
06/04/2022 05:12:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=292
06/04/2022 05:12:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
06/04/2022 05:12:20 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7614234945275369 on epoch=293
06/04/2022 05:12:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
06/04/2022 05:12:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=296
06/04/2022 05:12:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=297
06/04/2022 05:12:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
06/04/2022 05:12:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=299
06/04/2022 05:12:34 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.747074554459465 on epoch=299
06/04/2022 05:12:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/04/2022 05:12:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=302
06/04/2022 05:12:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=303
06/04/2022 05:12:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
06/04/2022 05:12:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
06/04/2022 05:12:49 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7666380399589354 on epoch=306
06/04/2022 05:12:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
06/04/2022 05:12:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/04/2022 05:12:57 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/04/2022 05:12:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
06/04/2022 05:13:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 05:13:04 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7593669911455756 on epoch=312
06/04/2022 05:13:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=313
06/04/2022 05:13:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=314
06/04/2022 05:13:11 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/04/2022 05:13:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=317
06/04/2022 05:13:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
06/04/2022 05:13:19 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7702859981548505 on epoch=318
06/04/2022 05:13:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
06/04/2022 05:13:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 05:13:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 05:13:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/04/2022 05:13:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
06/04/2022 05:13:34 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7713157809932003 on epoch=324
06/04/2022 05:13:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=326
06/04/2022 05:13:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
06/04/2022 05:13:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
06/04/2022 05:13:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=329
06/04/2022 05:13:47 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=331
06/04/2022 05:13:49 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7572857309838988 on epoch=331
06/04/2022 05:13:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/04/2022 05:13:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/04/2022 05:13:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/04/2022 05:13:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=336
06/04/2022 05:14:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=337
06/04/2022 05:14:04 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.770537992155108 on epoch=337
06/04/2022 05:14:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
06/04/2022 05:14:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
06/04/2022 05:14:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.17 on epoch=341
06/04/2022 05:14:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/04/2022 05:14:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/04/2022 05:14:19 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7299634524603033 on epoch=343
06/04/2022 05:14:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
06/04/2022 05:14:24 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
06/04/2022 05:14:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 05:14:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 05:14:32 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=349
06/04/2022 05:14:34 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7561007701103041 on epoch=349
06/04/2022 05:14:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
06/04/2022 05:14:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
06/04/2022 05:14:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 05:14:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 05:14:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/04/2022 05:14:49 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7704912911036476 on epoch=356
06/04/2022 05:14:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 05:14:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
06/04/2022 05:14:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
06/04/2022 05:14:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/04/2022 05:15:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/04/2022 05:15:04 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7812717787580317 on epoch=362
06/04/2022 05:15:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7806961400181738 -> 0.7812717787580317 on epoch=362, global_step=2900
06/04/2022 05:15:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.12 on epoch=363
06/04/2022 05:15:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
06/04/2022 05:15:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
06/04/2022 05:15:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=367
06/04/2022 05:15:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
06/04/2022 05:15:19 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8030330863852628 on epoch=368
06/04/2022 05:15:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7812717787580317 -> 0.8030330863852628 on epoch=368, global_step=2950
06/04/2022 05:15:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 05:15:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=371
06/04/2022 05:15:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 05:15:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/04/2022 05:15:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
06/04/2022 05:15:33 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:15:33 - INFO - __main__ - Printing 3 examples
06/04/2022 05:15:33 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:15:33 - INFO - __main__ - ['others']
06/04/2022 05:15:33 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:15:33 - INFO - __main__ - ['others']
06/04/2022 05:15:33 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:15:33 - INFO - __main__ - ['others']
06/04/2022 05:15:33 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:15:33 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:15:33 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:15:33 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:15:33 - INFO - __main__ - Printing 3 examples
06/04/2022 05:15:33 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:15:33 - INFO - __main__ - ['others']
06/04/2022 05:15:33 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:15:33 - INFO - __main__ - ['others']
06/04/2022 05:15:33 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:15:33 - INFO - __main__ - ['others']
06/04/2022 05:15:33 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:15:33 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:15:33 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:15:34 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8025728383458647 on epoch=374
06/04/2022 05:15:34 - INFO - __main__ - save last model!
06/04/2022 05:15:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 05:15:34 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 05:15:34 - INFO - __main__ - Printing 3 examples
06/04/2022 05:15:34 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 05:15:34 - INFO - __main__ - ['others']
06/04/2022 05:15:34 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 05:15:34 - INFO - __main__ - ['others']
06/04/2022 05:15:34 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 05:15:34 - INFO - __main__ - ['others']
06/04/2022 05:15:34 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:15:37 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:15:42 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 05:15:48 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:15:48 - INFO - __main__ - task name: emo
06/04/2022 05:15:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:15:49 - INFO - __main__ - Starting training!
06/04/2022 05:17:14 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_100_0.5_8_predictions.txt
06/04/2022 05:17:14 - INFO - __main__ - Classification-F1 on test data: 0.4212
06/04/2022 05:17:14 - INFO - __main__ - prefix=emo_32_100, lr=0.5, bsz=8, dev_performance=0.8030330863852628, test_performance=0.42120794359233055
06/04/2022 05:17:14 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.4, bsz=8 ...
06/04/2022 05:17:15 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:17:15 - INFO - __main__ - Printing 3 examples
06/04/2022 05:17:15 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:17:15 - INFO - __main__ - ['others']
06/04/2022 05:17:15 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:17:15 - INFO - __main__ - ['others']
06/04/2022 05:17:15 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:17:15 - INFO - __main__ - ['others']
06/04/2022 05:17:15 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:17:15 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:17:15 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:17:15 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:17:15 - INFO - __main__ - Printing 3 examples
06/04/2022 05:17:15 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:17:15 - INFO - __main__ - ['others']
06/04/2022 05:17:15 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:17:15 - INFO - __main__ - ['others']
06/04/2022 05:17:15 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:17:15 - INFO - __main__ - ['others']
06/04/2022 05:17:15 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:17:15 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:17:15 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:17:35 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:17:35 - INFO - __main__ - task name: emo
06/04/2022 05:17:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:17:35 - INFO - __main__ - Starting training!
06/04/2022 05:17:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.87 on epoch=1
06/04/2022 05:17:41 - INFO - __main__ - Step 20 Global step 20 Train loss 2.67 on epoch=2
06/04/2022 05:17:44 - INFO - __main__ - Step 30 Global step 30 Train loss 1.39 on epoch=3
06/04/2022 05:17:46 - INFO - __main__ - Step 40 Global step 40 Train loss 1.14 on epoch=4
06/04/2022 05:17:49 - INFO - __main__ - Step 50 Global step 50 Train loss 1.10 on epoch=6
06/04/2022 05:17:51 - INFO - __main__ - Global step 50 Train loss 2.63 Classification-F1 0.1 on epoch=6
06/04/2022 05:17:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/04/2022 05:17:53 - INFO - __main__ - Step 60 Global step 60 Train loss 0.96 on epoch=7
06/04/2022 05:17:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.97 on epoch=8
06/04/2022 05:17:59 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=9
06/04/2022 05:18:01 - INFO - __main__ - Step 90 Global step 90 Train loss 1.11 on epoch=11
06/04/2022 05:18:04 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=12
06/04/2022 05:18:06 - INFO - __main__ - Global step 100 Train loss 1.00 Classification-F1 0.1802536231884058 on epoch=12
06/04/2022 05:18:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1802536231884058 on epoch=12, global_step=100
06/04/2022 05:18:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=13
06/04/2022 05:18:11 - INFO - __main__ - Step 120 Global step 120 Train loss 1.01 on epoch=14
06/04/2022 05:18:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=16
06/04/2022 05:18:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=17
06/04/2022 05:18:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.93 on epoch=18
06/04/2022 05:18:21 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.14473684210526316 on epoch=18
06/04/2022 05:18:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=19
06/04/2022 05:18:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.84 on epoch=21
06/04/2022 05:18:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.84 on epoch=22
06/04/2022 05:18:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=23
06/04/2022 05:18:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.90 on epoch=24
06/04/2022 05:18:36 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.13026315789473686 on epoch=24
06/04/2022 05:18:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.84 on epoch=26
06/04/2022 05:18:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=27
06/04/2022 05:18:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=28
06/04/2022 05:18:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=29
06/04/2022 05:18:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.83 on epoch=31
06/04/2022 05:18:51 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.1 on epoch=31
06/04/2022 05:18:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.80 on epoch=32
06/04/2022 05:18:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.81 on epoch=33
06/04/2022 05:18:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.83 on epoch=34
06/04/2022 05:19:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.78 on epoch=36
06/04/2022 05:19:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.79 on epoch=37
06/04/2022 05:19:06 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.18835114564286043 on epoch=37
06/04/2022 05:19:06 - INFO - __main__ - Saving model with best Classification-F1: 0.1802536231884058 -> 0.18835114564286043 on epoch=37, global_step=300
06/04/2022 05:19:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.85 on epoch=38
06/04/2022 05:19:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.89 on epoch=39
06/04/2022 05:19:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.75 on epoch=41
06/04/2022 05:19:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.78 on epoch=42
06/04/2022 05:19:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.87 on epoch=43
06/04/2022 05:19:22 - INFO - __main__ - Global step 350 Train loss 0.83 Classification-F1 0.22490391785693803 on epoch=43
06/04/2022 05:19:22 - INFO - __main__ - Saving model with best Classification-F1: 0.18835114564286043 -> 0.22490391785693803 on epoch=43, global_step=350
06/04/2022 05:19:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.83 on epoch=44
06/04/2022 05:19:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.79 on epoch=46
06/04/2022 05:19:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.78 on epoch=47
06/04/2022 05:19:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.87 on epoch=48
06/04/2022 05:19:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.82 on epoch=49
06/04/2022 05:19:38 - INFO - __main__ - Global step 400 Train loss 0.82 Classification-F1 0.10062893081761007 on epoch=49
06/04/2022 05:19:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.80 on epoch=51
06/04/2022 05:19:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.78 on epoch=52
06/04/2022 05:19:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.76 on epoch=53
06/04/2022 05:19:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.70 on epoch=54
06/04/2022 05:19:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.74 on epoch=56
06/04/2022 05:19:53 - INFO - __main__ - Global step 450 Train loss 0.76 Classification-F1 0.1464741078828752 on epoch=56
06/04/2022 05:19:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.72 on epoch=57
06/04/2022 05:19:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.83 on epoch=58
06/04/2022 05:20:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.77 on epoch=59
06/04/2022 05:20:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.78 on epoch=61
06/04/2022 05:20:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.70 on epoch=62
06/04/2022 05:20:08 - INFO - __main__ - Global step 500 Train loss 0.76 Classification-F1 0.5379754453538758 on epoch=62
06/04/2022 05:20:08 - INFO - __main__ - Saving model with best Classification-F1: 0.22490391785693803 -> 0.5379754453538758 on epoch=62, global_step=500
06/04/2022 05:20:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.68 on epoch=63
06/04/2022 05:20:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.65 on epoch=64
06/04/2022 05:20:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.68 on epoch=66
06/04/2022 05:20:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.61 on epoch=67
06/04/2022 05:20:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.58 on epoch=68
06/04/2022 05:20:24 - INFO - __main__ - Global step 550 Train loss 0.64 Classification-F1 0.4516623340214594 on epoch=68
06/04/2022 05:20:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.60 on epoch=69
06/04/2022 05:20:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.57 on epoch=71
06/04/2022 05:20:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.60 on epoch=72
06/04/2022 05:20:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.71 on epoch=73
06/04/2022 05:20:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.56 on epoch=74
06/04/2022 05:20:39 - INFO - __main__ - Global step 600 Train loss 0.61 Classification-F1 0.7328022445553435 on epoch=74
06/04/2022 05:20:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5379754453538758 -> 0.7328022445553435 on epoch=74, global_step=600
06/04/2022 05:20:41 - INFO - __main__ - Step 610 Global step 610 Train loss 0.54 on epoch=76
06/04/2022 05:20:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.47 on epoch=77
06/04/2022 05:20:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=78
06/04/2022 05:20:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.55 on epoch=79
06/04/2022 05:20:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.53 on epoch=81
06/04/2022 05:20:54 - INFO - __main__ - Global step 650 Train loss 0.52 Classification-F1 0.7113157894736842 on epoch=81
06/04/2022 05:20:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=82
06/04/2022 05:20:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.57 on epoch=83
06/04/2022 05:21:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.42 on epoch=84
06/04/2022 05:21:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.49 on epoch=86
06/04/2022 05:21:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.44 on epoch=87
06/04/2022 05:21:09 - INFO - __main__ - Global step 700 Train loss 0.47 Classification-F1 0.6764363679493139 on epoch=87
06/04/2022 05:21:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.39 on epoch=88
06/04/2022 05:21:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=89
06/04/2022 05:21:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.50 on epoch=91
06/04/2022 05:21:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=92
06/04/2022 05:21:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=93
06/04/2022 05:21:24 - INFO - __main__ - Global step 750 Train loss 0.43 Classification-F1 0.7563218390804598 on epoch=93
06/04/2022 05:21:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7328022445553435 -> 0.7563218390804598 on epoch=93, global_step=750
06/04/2022 05:21:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=94
06/04/2022 05:21:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.39 on epoch=96
06/04/2022 05:21:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.32 on epoch=97
06/04/2022 05:21:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=98
06/04/2022 05:21:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.44 on epoch=99
06/04/2022 05:21:39 - INFO - __main__ - Global step 800 Train loss 0.38 Classification-F1 0.7954415683288922 on epoch=99
06/04/2022 05:21:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7563218390804598 -> 0.7954415683288922 on epoch=99, global_step=800
06/04/2022 05:21:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=101
06/04/2022 05:21:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.47 on epoch=102
06/04/2022 05:21:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.33 on epoch=103
06/04/2022 05:21:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.32 on epoch=104
06/04/2022 05:21:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.36 on epoch=106
06/04/2022 05:21:55 - INFO - __main__ - Global step 850 Train loss 0.37 Classification-F1 0.7254834770963804 on epoch=106
06/04/2022 05:21:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.34 on epoch=107
06/04/2022 05:22:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.38 on epoch=108
06/04/2022 05:22:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.37 on epoch=109
06/04/2022 05:22:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.30 on epoch=111
06/04/2022 05:22:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.34 on epoch=112
06/04/2022 05:22:09 - INFO - __main__ - Global step 900 Train loss 0.34 Classification-F1 0.6673747456415333 on epoch=112
06/04/2022 05:22:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.34 on epoch=113
06/04/2022 05:22:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=114
06/04/2022 05:22:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.31 on epoch=116
06/04/2022 05:22:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=117
06/04/2022 05:22:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=118
06/04/2022 05:22:24 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.8362211101860202 on epoch=118
06/04/2022 05:22:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7954415683288922 -> 0.8362211101860202 on epoch=118, global_step=950
06/04/2022 05:22:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.39 on epoch=119
06/04/2022 05:22:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.32 on epoch=121
06/04/2022 05:22:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=122
06/04/2022 05:22:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=123
06/04/2022 05:22:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=124
06/04/2022 05:22:40 - INFO - __main__ - Global step 1000 Train loss 0.28 Classification-F1 0.6726229738712481 on epoch=124
06/04/2022 05:22:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.31 on epoch=126
06/04/2022 05:22:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=127
06/04/2022 05:22:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=128
06/04/2022 05:22:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.31 on epoch=129
06/04/2022 05:22:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.30 on epoch=131
06/04/2022 05:22:55 - INFO - __main__ - Global step 1050 Train loss 0.28 Classification-F1 0.7382595541166159 on epoch=131
06/04/2022 05:22:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=132
06/04/2022 05:23:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.29 on epoch=133
06/04/2022 05:23:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=134
06/04/2022 05:23:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=136
06/04/2022 05:23:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=137
06/04/2022 05:23:10 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.7898433383482228 on epoch=137
06/04/2022 05:23:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=138
06/04/2022 05:23:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=139
06/04/2022 05:23:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=141
06/04/2022 05:23:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=142
06/04/2022 05:23:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=143
06/04/2022 05:23:25 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.7902293914198677 on epoch=143
06/04/2022 05:23:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=144
06/04/2022 05:23:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=146
06/04/2022 05:23:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=147
06/04/2022 05:23:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=148
06/04/2022 05:23:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=149
06/04/2022 05:23:40 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.8185676849765042 on epoch=149
06/04/2022 05:23:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=151
06/04/2022 05:23:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=152
06/04/2022 05:23:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=153
06/04/2022 05:23:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=154
06/04/2022 05:23:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=156
06/04/2022 05:23:56 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.7561371143439455 on epoch=156
06/04/2022 05:23:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=157
06/04/2022 05:24:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.23 on epoch=158
06/04/2022 05:24:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.33 on epoch=159
06/04/2022 05:24:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=161
06/04/2022 05:24:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=162
06/04/2022 05:24:11 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.7693156463804717 on epoch=162
06/04/2022 05:24:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=163
06/04/2022 05:24:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=164
06/04/2022 05:24:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=166
06/04/2022 05:24:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=167
06/04/2022 05:24:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.23 on epoch=168
06/04/2022 05:24:26 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.8337933806699364 on epoch=168
06/04/2022 05:24:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=169
06/04/2022 05:24:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=171
06/04/2022 05:24:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=172
06/04/2022 05:24:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=173
06/04/2022 05:24:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=174
06/04/2022 05:24:41 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.7148161779740727 on epoch=174
06/04/2022 05:24:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=176
06/04/2022 05:24:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=177
06/04/2022 05:24:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=178
06/04/2022 05:24:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=179
06/04/2022 05:24:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=181
06/04/2022 05:24:56 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.791417495402033 on epoch=181
06/04/2022 05:24:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=182
06/04/2022 05:25:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=183
06/04/2022 05:25:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=184
06/04/2022 05:25:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=186
06/04/2022 05:25:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=187
06/04/2022 05:25:11 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7890373143500005 on epoch=187
06/04/2022 05:25:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=188
06/04/2022 05:25:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=189
06/04/2022 05:25:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=191
06/04/2022 05:25:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=192
06/04/2022 05:25:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=193
06/04/2022 05:25:27 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.8434340659340659 on epoch=193
06/04/2022 05:25:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8362211101860202 -> 0.8434340659340659 on epoch=193, global_step=1550
06/04/2022 05:25:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=194
06/04/2022 05:25:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=196
06/04/2022 05:25:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=197
06/04/2022 05:25:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/04/2022 05:25:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=199
06/04/2022 05:25:42 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.8101553618794999 on epoch=199
06/04/2022 05:25:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=201
06/04/2022 05:25:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=202
06/04/2022 05:25:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=203
06/04/2022 05:25:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=204
06/04/2022 05:25:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
06/04/2022 05:25:58 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7932227255503117 on epoch=206
06/04/2022 05:26:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=207
06/04/2022 05:26:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=208
06/04/2022 05:26:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=209
06/04/2022 05:26:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=211
06/04/2022 05:26:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=212
06/04/2022 05:26:13 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8116109946998645 on epoch=212
06/04/2022 05:26:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=213
06/04/2022 05:26:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=214
06/04/2022 05:26:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=216
06/04/2022 05:26:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=217
06/04/2022 05:26:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=218
06/04/2022 05:26:29 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7803021957160816 on epoch=218
06/04/2022 05:26:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=219
06/04/2022 05:26:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=221
06/04/2022 05:26:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
06/04/2022 05:26:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=223
06/04/2022 05:26:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=224
06/04/2022 05:26:43 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7839244122864729 on epoch=224
06/04/2022 05:26:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=226
06/04/2022 05:26:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=227
06/04/2022 05:26:52 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=228
06/04/2022 05:26:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=229
06/04/2022 05:26:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=231
06/04/2022 05:26:59 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7999382969971205 on epoch=231
06/04/2022 05:27:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=232
06/04/2022 05:27:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=233
06/04/2022 05:27:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
06/04/2022 05:27:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=236
06/04/2022 05:27:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/04/2022 05:27:14 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7980431285872045 on epoch=237
06/04/2022 05:27:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=238
06/04/2022 05:27:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
06/04/2022 05:27:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=241
06/04/2022 05:27:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=242
06/04/2022 05:27:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=243
06/04/2022 05:27:29 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.793513431013431 on epoch=243
06/04/2022 05:27:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=244
06/04/2022 05:27:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=246
06/04/2022 05:27:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=247
06/04/2022 05:27:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=248
06/04/2022 05:27:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=249
06/04/2022 05:27:44 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7423469387755102 on epoch=249
06/04/2022 05:27:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=251
06/04/2022 05:27:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=252
06/04/2022 05:27:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
06/04/2022 05:27:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/04/2022 05:27:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=256
06/04/2022 05:27:59 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7882214183584046 on epoch=256
06/04/2022 05:28:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=257
06/04/2022 05:28:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
06/04/2022 05:28:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/04/2022 05:28:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=261
06/04/2022 05:28:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=262
06/04/2022 05:28:14 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7742385799174234 on epoch=262
06/04/2022 05:28:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
06/04/2022 05:28:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=264
06/04/2022 05:28:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
06/04/2022 05:28:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=267
06/04/2022 05:28:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/04/2022 05:28:30 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7864752386430558 on epoch=268
06/04/2022 05:28:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
06/04/2022 05:28:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
06/04/2022 05:28:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=272
06/04/2022 05:28:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=273
06/04/2022 05:28:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=274
06/04/2022 05:28:45 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7518007231865658 on epoch=274
06/04/2022 05:28:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 05:28:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=277
06/04/2022 05:28:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/04/2022 05:28:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
06/04/2022 05:28:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=281
06/04/2022 05:29:00 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7645685741797923 on epoch=281
06/04/2022 05:29:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/04/2022 05:29:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/04/2022 05:29:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/04/2022 05:29:11 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 05:29:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
06/04/2022 05:29:15 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7405630521439345 on epoch=287
06/04/2022 05:29:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=288
06/04/2022 05:29:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
06/04/2022 05:29:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
06/04/2022 05:29:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
06/04/2022 05:29:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
06/04/2022 05:29:30 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7860360360360361 on epoch=293
06/04/2022 05:29:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.09 on epoch=294
06/04/2022 05:29:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/04/2022 05:29:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
06/04/2022 05:29:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=298
06/04/2022 05:29:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.11 on epoch=299
06/04/2022 05:29:46 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7753967156289643 on epoch=299
06/04/2022 05:29:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=301
06/04/2022 05:29:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=302
06/04/2022 05:29:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=303
06/04/2022 05:29:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
06/04/2022 05:29:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=306
06/04/2022 05:30:01 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7736703149001536 on epoch=306
06/04/2022 05:30:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
06/04/2022 05:30:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
06/04/2022 05:30:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=309
06/04/2022 05:30:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=311
06/04/2022 05:30:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/04/2022 05:30:16 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.802063041125541 on epoch=312
06/04/2022 05:30:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/04/2022 05:30:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 05:30:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/04/2022 05:30:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=317
06/04/2022 05:30:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
06/04/2022 05:30:31 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7860496933696339 on epoch=318
06/04/2022 05:30:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=319
06/04/2022 05:30:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=321
06/04/2022 05:30:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=322
06/04/2022 05:30:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
06/04/2022 05:30:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/04/2022 05:30:46 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7864857138001194 on epoch=324
06/04/2022 05:30:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/04/2022 05:30:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
06/04/2022 05:30:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=328
06/04/2022 05:30:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
06/04/2022 05:31:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=331
06/04/2022 05:31:02 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7756147540983607 on epoch=331
06/04/2022 05:31:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
06/04/2022 05:31:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=333
06/04/2022 05:31:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/04/2022 05:31:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=336
06/04/2022 05:31:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/04/2022 05:31:17 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7661870329324273 on epoch=337
06/04/2022 05:31:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
06/04/2022 05:31:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
06/04/2022 05:31:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=341
06/04/2022 05:31:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
06/04/2022 05:31:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/04/2022 05:31:32 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7648015904834554 on epoch=343
06/04/2022 05:31:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=344
06/04/2022 05:31:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/04/2022 05:31:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 05:31:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/04/2022 05:31:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=349
06/04/2022 05:31:47 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7890053485162181 on epoch=349
06/04/2022 05:31:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
06/04/2022 05:31:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
06/04/2022 05:31:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/04/2022 05:31:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 05:32:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=356
06/04/2022 05:32:02 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7876546273320467 on epoch=356
06/04/2022 05:32:05 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 05:32:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/04/2022 05:32:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=359
06/04/2022 05:32:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/04/2022 05:32:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=362
06/04/2022 05:32:17 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7148617511520738 on epoch=362
06/04/2022 05:32:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
06/04/2022 05:32:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
06/04/2022 05:32:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/04/2022 05:32:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 05:32:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
06/04/2022 05:32:33 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7949569412427002 on epoch=368
06/04/2022 05:32:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
06/04/2022 05:32:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
06/04/2022 05:32:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 05:32:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
06/04/2022 05:32:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 05:32:47 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:32:47 - INFO - __main__ - Printing 3 examples
06/04/2022 05:32:47 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:32:47 - INFO - __main__ - ['others']
06/04/2022 05:32:47 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:32:47 - INFO - __main__ - ['others']
06/04/2022 05:32:47 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:32:47 - INFO - __main__ - ['others']
06/04/2022 05:32:47 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:32:47 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:32:47 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:32:47 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:32:47 - INFO - __main__ - Printing 3 examples
06/04/2022 05:32:47 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:32:47 - INFO - __main__ - ['others']
06/04/2022 05:32:47 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:32:47 - INFO - __main__ - ['others']
06/04/2022 05:32:47 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:32:47 - INFO - __main__ - ['others']
06/04/2022 05:32:47 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:32:47 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:32:47 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:32:48 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.771711388642741 on epoch=374
06/04/2022 05:32:48 - INFO - __main__ - save last model!
06/04/2022 05:32:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 05:32:48 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 05:32:48 - INFO - __main__ - Printing 3 examples
06/04/2022 05:32:48 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 05:32:48 - INFO - __main__ - ['others']
06/04/2022 05:32:48 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 05:32:48 - INFO - __main__ - ['others']
06/04/2022 05:32:48 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 05:32:48 - INFO - __main__ - ['others']
06/04/2022 05:32:48 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:32:50 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:32:56 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 05:33:06 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:33:06 - INFO - __main__ - task name: emo
06/04/2022 05:33:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:33:07 - INFO - __main__ - Starting training!
06/04/2022 05:34:17 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_100_0.4_8_predictions.txt
06/04/2022 05:34:17 - INFO - __main__ - Classification-F1 on test data: 0.4329
06/04/2022 05:34:17 - INFO - __main__ - prefix=emo_32_100, lr=0.4, bsz=8, dev_performance=0.8434340659340659, test_performance=0.4328723157012915
06/04/2022 05:34:17 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.3, bsz=8 ...
06/04/2022 05:34:18 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:34:18 - INFO - __main__ - Printing 3 examples
06/04/2022 05:34:18 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:34:18 - INFO - __main__ - ['others']
06/04/2022 05:34:18 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:34:18 - INFO - __main__ - ['others']
06/04/2022 05:34:18 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:34:18 - INFO - __main__ - ['others']
06/04/2022 05:34:18 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:34:18 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:34:18 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:34:18 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:34:18 - INFO - __main__ - Printing 3 examples
06/04/2022 05:34:18 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:34:18 - INFO - __main__ - ['others']
06/04/2022 05:34:18 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:34:18 - INFO - __main__ - ['others']
06/04/2022 05:34:18 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:34:18 - INFO - __main__ - ['others']
06/04/2022 05:34:18 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:34:18 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:34:18 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:34:33 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:34:33 - INFO - __main__ - task name: emo
06/04/2022 05:34:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:34:34 - INFO - __main__ - Starting training!
06/04/2022 05:34:37 - INFO - __main__ - Step 10 Global step 10 Train loss 7.54 on epoch=1
06/04/2022 05:34:39 - INFO - __main__ - Step 20 Global step 20 Train loss 4.39 on epoch=2
06/04/2022 05:34:42 - INFO - __main__ - Step 30 Global step 30 Train loss 2.23 on epoch=3
06/04/2022 05:34:45 - INFO - __main__ - Step 40 Global step 40 Train loss 1.48 on epoch=4
06/04/2022 05:34:48 - INFO - __main__ - Step 50 Global step 50 Train loss 1.26 on epoch=6
06/04/2022 05:34:49 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.10062893081761007 on epoch=6
06/04/2022 05:34:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10062893081761007 on epoch=6, global_step=50
06/04/2022 05:34:52 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=7
06/04/2022 05:34:55 - INFO - __main__ - Step 70 Global step 70 Train loss 1.13 on epoch=8
06/04/2022 05:34:57 - INFO - __main__ - Step 80 Global step 80 Train loss 1.00 on epoch=9
06/04/2022 05:35:00 - INFO - __main__ - Step 90 Global step 90 Train loss 1.04 on epoch=11
06/04/2022 05:35:02 - INFO - __main__ - Step 100 Global step 100 Train loss 1.01 on epoch=12
06/04/2022 05:35:04 - INFO - __main__ - Global step 100 Train loss 1.05 Classification-F1 0.1784997900825675 on epoch=12
06/04/2022 05:35:04 - INFO - __main__ - Saving model with best Classification-F1: 0.10062893081761007 -> 0.1784997900825675 on epoch=12, global_step=100
06/04/2022 05:35:07 - INFO - __main__ - Step 110 Global step 110 Train loss 1.03 on epoch=13
06/04/2022 05:35:09 - INFO - __main__ - Step 120 Global step 120 Train loss 1.00 on epoch=14
06/04/2022 05:35:12 - INFO - __main__ - Step 130 Global step 130 Train loss 1.04 on epoch=16
06/04/2022 05:35:15 - INFO - __main__ - Step 140 Global step 140 Train loss 1.00 on epoch=17
06/04/2022 05:35:17 - INFO - __main__ - Step 150 Global step 150 Train loss 0.93 on epoch=18
06/04/2022 05:35:19 - INFO - __main__ - Global step 150 Train loss 1.00 Classification-F1 0.203125 on epoch=18
06/04/2022 05:35:19 - INFO - __main__ - Saving model with best Classification-F1: 0.1784997900825675 -> 0.203125 on epoch=18, global_step=150
06/04/2022 05:35:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.98 on epoch=19
06/04/2022 05:35:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.96 on epoch=21
06/04/2022 05:35:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=22
06/04/2022 05:35:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.88 on epoch=23
06/04/2022 05:35:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.98 on epoch=24
06/04/2022 05:35:34 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.11726998491704374 on epoch=24
06/04/2022 05:35:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=26
06/04/2022 05:35:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=27
06/04/2022 05:35:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.86 on epoch=28
06/04/2022 05:35:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.91 on epoch=29
06/04/2022 05:35:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.90 on epoch=31
06/04/2022 05:35:49 - INFO - __main__ - Global step 250 Train loss 0.91 Classification-F1 0.11641733793632528 on epoch=31
06/04/2022 05:35:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.82 on epoch=32
06/04/2022 05:35:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.90 on epoch=33
06/04/2022 05:35:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.87 on epoch=34
06/04/2022 05:35:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.84 on epoch=36
06/04/2022 05:36:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.83 on epoch=37
06/04/2022 05:36:03 - INFO - __main__ - Global step 300 Train loss 0.85 Classification-F1 0.2421202697658465 on epoch=37
06/04/2022 05:36:03 - INFO - __main__ - Saving model with best Classification-F1: 0.203125 -> 0.2421202697658465 on epoch=37, global_step=300
06/04/2022 05:36:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.89 on epoch=38
06/04/2022 05:36:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.85 on epoch=39
06/04/2022 05:36:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.80 on epoch=41
06/04/2022 05:36:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.76 on epoch=42
06/04/2022 05:36:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.83 on epoch=43
06/04/2022 05:36:18 - INFO - __main__ - Global step 350 Train loss 0.83 Classification-F1 0.2637997456200328 on epoch=43
06/04/2022 05:36:18 - INFO - __main__ - Saving model with best Classification-F1: 0.2421202697658465 -> 0.2637997456200328 on epoch=43, global_step=350
06/04/2022 05:36:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.82 on epoch=44
06/04/2022 05:36:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.93 on epoch=46
06/04/2022 05:36:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.80 on epoch=47
06/04/2022 05:36:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.82 on epoch=48
06/04/2022 05:36:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.79 on epoch=49
06/04/2022 05:36:33 - INFO - __main__ - Global step 400 Train loss 0.83 Classification-F1 0.1973377499693289 on epoch=49
06/04/2022 05:36:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.73 on epoch=51
06/04/2022 05:36:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.72 on epoch=52
06/04/2022 05:36:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.77 on epoch=53
06/04/2022 05:36:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.71 on epoch=54
06/04/2022 05:36:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.74 on epoch=56
06/04/2022 05:36:48 - INFO - __main__ - Global step 450 Train loss 0.73 Classification-F1 0.2716822675181524 on epoch=56
06/04/2022 05:36:48 - INFO - __main__ - Saving model with best Classification-F1: 0.2637997456200328 -> 0.2716822675181524 on epoch=56, global_step=450
06/04/2022 05:36:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.76 on epoch=57
06/04/2022 05:36:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.78 on epoch=58
06/04/2022 05:36:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.82 on epoch=59
06/04/2022 05:36:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.78 on epoch=61
06/04/2022 05:37:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.64 on epoch=62
06/04/2022 05:37:03 - INFO - __main__ - Global step 500 Train loss 0.75 Classification-F1 0.4558055040197897 on epoch=62
06/04/2022 05:37:04 - INFO - __main__ - Saving model with best Classification-F1: 0.2716822675181524 -> 0.4558055040197897 on epoch=62, global_step=500
06/04/2022 05:37:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.75 on epoch=63
06/04/2022 05:37:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.61 on epoch=64
06/04/2022 05:37:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.69 on epoch=66
06/04/2022 05:37:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.74 on epoch=67
06/04/2022 05:37:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.64 on epoch=68
06/04/2022 05:37:18 - INFO - __main__ - Global step 550 Train loss 0.69 Classification-F1 0.5486760964548422 on epoch=68
06/04/2022 05:37:18 - INFO - __main__ - Saving model with best Classification-F1: 0.4558055040197897 -> 0.5486760964548422 on epoch=68, global_step=550
06/04/2022 05:37:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.65 on epoch=69
06/04/2022 05:37:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.58 on epoch=71
06/04/2022 05:37:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.52 on epoch=72
06/04/2022 05:37:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.59 on epoch=73
06/04/2022 05:37:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.69 on epoch=74
06/04/2022 05:37:34 - INFO - __main__ - Global step 600 Train loss 0.61 Classification-F1 0.5011227647773435 on epoch=74
06/04/2022 05:37:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.69 on epoch=76
06/04/2022 05:37:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.57 on epoch=77
06/04/2022 05:37:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=78
06/04/2022 05:37:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.55 on epoch=79
06/04/2022 05:37:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.65 on epoch=81
06/04/2022 05:37:48 - INFO - __main__ - Global step 650 Train loss 0.59 Classification-F1 0.684322932873186 on epoch=81
06/04/2022 05:37:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5486760964548422 -> 0.684322932873186 on epoch=81, global_step=650
06/04/2022 05:37:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=82
06/04/2022 05:37:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.48 on epoch=83
06/04/2022 05:37:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.51 on epoch=84
06/04/2022 05:37:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.56 on epoch=86
06/04/2022 05:38:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.48 on epoch=87
06/04/2022 05:38:03 - INFO - __main__ - Global step 700 Train loss 0.50 Classification-F1 0.6315720555316638 on epoch=87
06/04/2022 05:38:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.45 on epoch=88
06/04/2022 05:38:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=89
06/04/2022 05:38:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.53 on epoch=91
06/04/2022 05:38:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.41 on epoch=92
06/04/2022 05:38:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=93
06/04/2022 05:38:18 - INFO - __main__ - Global step 750 Train loss 0.46 Classification-F1 0.7510843634786382 on epoch=93
06/04/2022 05:38:18 - INFO - __main__ - Saving model with best Classification-F1: 0.684322932873186 -> 0.7510843634786382 on epoch=93, global_step=750
06/04/2022 05:38:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.47 on epoch=94
06/04/2022 05:38:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.49 on epoch=96
06/04/2022 05:38:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.25 on epoch=97
06/04/2022 05:38:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.40 on epoch=98
06/04/2022 05:38:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.41 on epoch=99
06/04/2022 05:38:33 - INFO - __main__ - Global step 800 Train loss 0.40 Classification-F1 0.7058433716042412 on epoch=99
06/04/2022 05:38:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=101
06/04/2022 05:38:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.27 on epoch=102
06/04/2022 05:38:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.38 on epoch=103
06/04/2022 05:38:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.41 on epoch=104
06/04/2022 05:38:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=106
06/04/2022 05:38:48 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.7398737946356995 on epoch=106
06/04/2022 05:38:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.38 on epoch=107
06/04/2022 05:38:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.34 on epoch=108
06/04/2022 05:38:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.30 on epoch=109
06/04/2022 05:38:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.35 on epoch=111
06/04/2022 05:39:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.28 on epoch=112
06/04/2022 05:39:03 - INFO - __main__ - Global step 900 Train loss 0.33 Classification-F1 0.7516673599004774 on epoch=112
06/04/2022 05:39:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7510843634786382 -> 0.7516673599004774 on epoch=112, global_step=900
06/04/2022 05:39:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.33 on epoch=113
06/04/2022 05:39:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=114
06/04/2022 05:39:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.36 on epoch=116
06/04/2022 05:39:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=117
06/04/2022 05:39:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=118
06/04/2022 05:39:18 - INFO - __main__ - Global step 950 Train loss 0.31 Classification-F1 0.7264531243404483 on epoch=118
06/04/2022 05:39:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.38 on epoch=119
06/04/2022 05:39:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.29 on epoch=121
06/04/2022 05:39:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=122
06/04/2022 05:39:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=123
06/04/2022 05:39:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=124
06/04/2022 05:39:33 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.7577949777518156 on epoch=124
06/04/2022 05:39:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7516673599004774 -> 0.7577949777518156 on epoch=124, global_step=1000
06/04/2022 05:39:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=126
06/04/2022 05:39:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=127
06/04/2022 05:39:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=128
06/04/2022 05:39:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=129
06/04/2022 05:39:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=131
06/04/2022 05:39:49 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.7085284897658122 on epoch=131
06/04/2022 05:39:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=132
06/04/2022 05:39:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=133
06/04/2022 05:39:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=134
06/04/2022 05:39:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=136
06/04/2022 05:40:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=137
06/04/2022 05:40:04 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.7456242596541104 on epoch=137
06/04/2022 05:40:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=138
06/04/2022 05:40:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=139
06/04/2022 05:40:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=141
06/04/2022 05:40:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=142
06/04/2022 05:40:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=143
06/04/2022 05:40:19 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.8115330747683689 on epoch=143
06/04/2022 05:40:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7577949777518156 -> 0.8115330747683689 on epoch=143, global_step=1150
06/04/2022 05:40:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.21 on epoch=144
06/04/2022 05:40:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.28 on epoch=146
06/04/2022 05:40:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=147
06/04/2022 05:40:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.25 on epoch=148
06/04/2022 05:40:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=149
06/04/2022 05:40:34 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.7835309617918313 on epoch=149
06/04/2022 05:40:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=151
06/04/2022 05:40:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=152
06/04/2022 05:40:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=153
06/04/2022 05:40:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=154
06/04/2022 05:40:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=156
06/04/2022 05:40:49 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.7443369614304695 on epoch=156
06/04/2022 05:40:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=157
06/04/2022 05:40:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.25 on epoch=158
06/04/2022 05:40:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=159
06/04/2022 05:40:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=161
06/04/2022 05:41:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=162
06/04/2022 05:41:04 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.6614418712265666 on epoch=162
06/04/2022 05:41:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=163
06/04/2022 05:41:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=164
06/04/2022 05:41:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=166
06/04/2022 05:41:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=167
06/04/2022 05:41:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=168
06/04/2022 05:41:19 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.7566028225806452 on epoch=168
06/04/2022 05:41:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=169
06/04/2022 05:41:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=171
06/04/2022 05:41:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=172
06/04/2022 05:41:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=173
06/04/2022 05:41:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=174
06/04/2022 05:41:34 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.7280202223851417 on epoch=174
06/04/2022 05:41:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=176
06/04/2022 05:41:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=177
06/04/2022 05:41:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=178
06/04/2022 05:41:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=179
06/04/2022 05:41:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=181
06/04/2022 05:41:49 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.7378211810199047 on epoch=181
06/04/2022 05:41:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=182
06/04/2022 05:41:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=183
06/04/2022 05:41:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=184
06/04/2022 05:41:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=186
06/04/2022 05:42:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=187
06/04/2022 05:42:04 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.7192221651543687 on epoch=187
06/04/2022 05:42:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=188
06/04/2022 05:42:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=189
06/04/2022 05:42:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=191
06/04/2022 05:42:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=192
06/04/2022 05:42:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=193
06/04/2022 05:42:19 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.7518052983905426 on epoch=193
06/04/2022 05:42:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=194
06/04/2022 05:42:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=196
06/04/2022 05:42:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
06/04/2022 05:42:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=198
06/04/2022 05:42:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=199
06/04/2022 05:42:34 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7550213605259319 on epoch=199
06/04/2022 05:42:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=201
06/04/2022 05:42:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=202
06/04/2022 05:42:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=203
06/04/2022 05:42:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=204
06/04/2022 05:42:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=206
06/04/2022 05:42:49 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7405643272644858 on epoch=206
06/04/2022 05:42:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=207
06/04/2022 05:42:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=208
06/04/2022 05:42:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
06/04/2022 05:43:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=211
06/04/2022 05:43:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=212
06/04/2022 05:43:04 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7278823006555313 on epoch=212
06/04/2022 05:43:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
06/04/2022 05:43:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=214
06/04/2022 05:43:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=216
06/04/2022 05:43:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=217
06/04/2022 05:43:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=218
06/04/2022 05:43:19 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7484098752021433 on epoch=218
06/04/2022 05:43:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
06/04/2022 05:43:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=221
06/04/2022 05:43:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=222
06/04/2022 05:43:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=223
06/04/2022 05:43:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 05:43:35 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7667283604298033 on epoch=224
06/04/2022 05:43:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
06/04/2022 05:43:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
06/04/2022 05:43:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=228
06/04/2022 05:43:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.15 on epoch=229
06/04/2022 05:43:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
06/04/2022 05:43:50 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.768388825105243 on epoch=231
06/04/2022 05:43:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=232
06/04/2022 05:43:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=233
06/04/2022 05:43:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=234
06/04/2022 05:44:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/04/2022 05:44:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=237
06/04/2022 05:44:05 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7322550034506556 on epoch=237
06/04/2022 05:44:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
06/04/2022 05:44:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=239
06/04/2022 05:44:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=241
06/04/2022 05:44:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=242
06/04/2022 05:44:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=243
06/04/2022 05:44:21 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7563596887841544 on epoch=243
06/04/2022 05:44:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=244
06/04/2022 05:44:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=246
06/04/2022 05:44:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=247
06/04/2022 05:44:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=248
06/04/2022 05:44:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=249
06/04/2022 05:44:36 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7627955502768096 on epoch=249
06/04/2022 05:44:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
06/04/2022 05:44:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
06/04/2022 05:44:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=253
06/04/2022 05:44:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=254
06/04/2022 05:44:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=256
06/04/2022 05:44:51 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7245717028503914 on epoch=256
06/04/2022 05:44:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=257
06/04/2022 05:44:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/04/2022 05:44:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=259
06/04/2022 05:45:02 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=261
06/04/2022 05:45:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=262
06/04/2022 05:45:06 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7385838002258438 on epoch=262
06/04/2022 05:45:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
06/04/2022 05:45:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
06/04/2022 05:45:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
06/04/2022 05:45:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/04/2022 05:45:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=268
06/04/2022 05:45:22 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7125926045918918 on epoch=268
06/04/2022 05:45:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=269
06/04/2022 05:45:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
06/04/2022 05:45:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/04/2022 05:45:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
06/04/2022 05:45:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
06/04/2022 05:45:37 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6808061561579006 on epoch=274
06/04/2022 05:45:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 05:45:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
06/04/2022 05:45:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=278
06/04/2022 05:45:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=279
06/04/2022 05:45:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=281
06/04/2022 05:45:52 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7501092097866291 on epoch=281
06/04/2022 05:45:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=282
06/04/2022 05:45:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/04/2022 05:45:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
06/04/2022 05:46:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
06/04/2022 05:46:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
06/04/2022 05:46:06 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7546265328874024 on epoch=287
06/04/2022 05:46:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=288
06/04/2022 05:46:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=289
06/04/2022 05:46:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/04/2022 05:46:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/04/2022 05:46:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=293
06/04/2022 05:46:22 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7597272316581779 on epoch=293
06/04/2022 05:46:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
06/04/2022 05:46:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=296
06/04/2022 05:46:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/04/2022 05:46:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=298
06/04/2022 05:46:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
06/04/2022 05:46:37 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.778226509832236 on epoch=299
06/04/2022 05:46:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/04/2022 05:46:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=302
06/04/2022 05:46:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/04/2022 05:46:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
06/04/2022 05:46:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=306
06/04/2022 05:46:52 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.708543352433662 on epoch=306
06/04/2022 05:46:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/04/2022 05:46:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
06/04/2022 05:47:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=309
06/04/2022 05:47:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=311
06/04/2022 05:47:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 05:47:07 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7614149678240987 on epoch=312
06/04/2022 05:47:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=313
06/04/2022 05:47:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 05:47:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
06/04/2022 05:47:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/04/2022 05:47:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=318
06/04/2022 05:47:23 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7798517710349292 on epoch=318
06/04/2022 05:47:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/04/2022 05:47:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 05:47:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=322
06/04/2022 05:47:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
06/04/2022 05:47:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
06/04/2022 05:47:38 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7708512931034482 on epoch=324
06/04/2022 05:47:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/04/2022 05:47:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 05:47:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
06/04/2022 05:47:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/04/2022 05:47:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/04/2022 05:47:54 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7280552487793537 on epoch=331
06/04/2022 05:47:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=332
06/04/2022 05:47:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/04/2022 05:48:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/04/2022 05:48:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/04/2022 05:48:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/04/2022 05:48:09 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7529178150567504 on epoch=337
06/04/2022 05:48:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
06/04/2022 05:48:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=339
06/04/2022 05:48:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/04/2022 05:48:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=342
06/04/2022 05:48:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=343
06/04/2022 05:48:25 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.794510395937693 on epoch=343
06/04/2022 05:48:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
06/04/2022 05:48:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=346
06/04/2022 05:48:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 05:48:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
06/04/2022 05:48:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 05:48:40 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7712269237405107 on epoch=349
06/04/2022 05:48:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/04/2022 05:48:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/04/2022 05:48:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
06/04/2022 05:48:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 05:48:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 05:48:55 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7433356823630034 on epoch=356
06/04/2022 05:48:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.10 on epoch=357
06/04/2022 05:49:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/04/2022 05:49:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
06/04/2022 05:49:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/04/2022 05:49:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/04/2022 05:49:10 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7577258190425826 on epoch=362
06/04/2022 05:49:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
06/04/2022 05:49:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
06/04/2022 05:49:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/04/2022 05:49:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 05:49:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
06/04/2022 05:49:24 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7716690389924085 on epoch=368
06/04/2022 05:49:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.11 on epoch=369
06/04/2022 05:49:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
06/04/2022 05:49:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=372
06/04/2022 05:49:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/04/2022 05:49:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/04/2022 05:49:38 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:49:38 - INFO - __main__ - Printing 3 examples
06/04/2022 05:49:38 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:49:38 - INFO - __main__ - ['others']
06/04/2022 05:49:38 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:49:38 - INFO - __main__ - ['others']
06/04/2022 05:49:38 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:49:38 - INFO - __main__ - ['others']
06/04/2022 05:49:38 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:49:38 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:49:39 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:49:39 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:49:39 - INFO - __main__ - Printing 3 examples
06/04/2022 05:49:39 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:49:39 - INFO - __main__ - ['others']
06/04/2022 05:49:39 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:49:39 - INFO - __main__ - ['others']
06/04/2022 05:49:39 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:49:39 - INFO - __main__ - ['others']
06/04/2022 05:49:39 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:49:39 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:49:39 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:49:39 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7846675712347355 on epoch=374
06/04/2022 05:49:39 - INFO - __main__ - save last model!
06/04/2022 05:49:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 05:49:39 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 05:49:39 - INFO - __main__ - Printing 3 examples
06/04/2022 05:49:39 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 05:49:39 - INFO - __main__ - ['others']
06/04/2022 05:49:39 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 05:49:39 - INFO - __main__ - ['others']
06/04/2022 05:49:39 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 05:49:39 - INFO - __main__ - ['others']
06/04/2022 05:49:39 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:49:41 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:49:47 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 05:49:54 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:49:54 - INFO - __main__ - task name: emo
06/04/2022 05:49:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:49:55 - INFO - __main__ - Starting training!
06/04/2022 05:51:13 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_100_0.3_8_predictions.txt
06/04/2022 05:51:13 - INFO - __main__ - Classification-F1 on test data: 0.3884
06/04/2022 05:51:13 - INFO - __main__ - prefix=emo_32_100, lr=0.3, bsz=8, dev_performance=0.8115330747683689, test_performance=0.3884066118538148
06/04/2022 05:51:13 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.2, bsz=8 ...
06/04/2022 05:51:14 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:51:14 - INFO - __main__ - Printing 3 examples
06/04/2022 05:51:14 - INFO - __main__ -  [emo] how cause yes am listening
06/04/2022 05:51:14 - INFO - __main__ - ['others']
06/04/2022 05:51:14 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/04/2022 05:51:14 - INFO - __main__ - ['others']
06/04/2022 05:51:14 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/04/2022 05:51:14 - INFO - __main__ - ['others']
06/04/2022 05:51:14 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:51:14 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:51:14 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 05:51:14 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 05:51:14 - INFO - __main__ - Printing 3 examples
06/04/2022 05:51:14 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
06/04/2022 05:51:14 - INFO - __main__ - ['others']
06/04/2022 05:51:14 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
06/04/2022 05:51:14 - INFO - __main__ - ['others']
06/04/2022 05:51:14 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
06/04/2022 05:51:14 - INFO - __main__ - ['others']
06/04/2022 05:51:14 - INFO - __main__ - Tokenizing Input ...
06/04/2022 05:51:14 - INFO - __main__ - Tokenizing Output ...
06/04/2022 05:51:14 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 05:51:29 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 05:51:29 - INFO - __main__ - task name: emo
06/04/2022 05:51:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 05:51:30 - INFO - __main__ - Starting training!
06/04/2022 05:51:33 - INFO - __main__ - Step 10 Global step 10 Train loss 7.64 on epoch=1
06/04/2022 05:51:35 - INFO - __main__ - Step 20 Global step 20 Train loss 5.25 on epoch=2
06/04/2022 05:51:38 - INFO - __main__ - Step 30 Global step 30 Train loss 3.35 on epoch=3
06/04/2022 05:51:40 - INFO - __main__ - Step 40 Global step 40 Train loss 2.16 on epoch=4
06/04/2022 05:51:43 - INFO - __main__ - Step 50 Global step 50 Train loss 1.63 on epoch=6
06/04/2022 05:51:44 - INFO - __main__ - Global step 50 Train loss 4.00 Classification-F1 0.10126582278481013 on epoch=6
06/04/2022 05:51:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10126582278481013 on epoch=6, global_step=50
06/04/2022 05:51:47 - INFO - __main__ - Step 60 Global step 60 Train loss 1.22 on epoch=7
06/04/2022 05:51:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.23 on epoch=8
06/04/2022 05:51:52 - INFO - __main__ - Step 80 Global step 80 Train loss 0.98 on epoch=9
06/04/2022 05:51:54 - INFO - __main__ - Step 90 Global step 90 Train loss 1.12 on epoch=11
06/04/2022 05:51:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=12
06/04/2022 05:51:58 - INFO - __main__ - Global step 100 Train loss 1.11 Classification-F1 0.1269482151835093 on epoch=12
06/04/2022 05:51:58 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.1269482151835093 on epoch=12, global_step=100
06/04/2022 05:52:01 - INFO - __main__ - Step 110 Global step 110 Train loss 1.04 on epoch=13
06/04/2022 05:52:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.98 on epoch=14
06/04/2022 05:52:06 - INFO - __main__ - Step 130 Global step 130 Train loss 1.02 on epoch=16
06/04/2022 05:52:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.96 on epoch=17
06/04/2022 05:52:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.91 on epoch=18
06/04/2022 05:52:12 - INFO - __main__ - Global step 150 Train loss 0.98 Classification-F1 0.17395824726651796 on epoch=18
06/04/2022 05:52:12 - INFO - __main__ - Saving model with best Classification-F1: 0.1269482151835093 -> 0.17395824726651796 on epoch=18, global_step=150
06/04/2022 05:52:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.94 on epoch=19
06/04/2022 05:52:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=21
06/04/2022 05:52:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=22
06/04/2022 05:52:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.91 on epoch=23
06/04/2022 05:52:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.88 on epoch=24
06/04/2022 05:52:27 - INFO - __main__ - Global step 200 Train loss 0.89 Classification-F1 0.20391545391545393 on epoch=24
06/04/2022 05:52:27 - INFO - __main__ - Saving model with best Classification-F1: 0.17395824726651796 -> 0.20391545391545393 on epoch=24, global_step=200
06/04/2022 05:52:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=26
06/04/2022 05:52:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.91 on epoch=27
06/04/2022 05:52:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.91 on epoch=28
06/04/2022 05:52:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=29
06/04/2022 05:52:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=31
06/04/2022 05:52:41 - INFO - __main__ - Global step 250 Train loss 0.88 Classification-F1 0.13025283347863992 on epoch=31
06/04/2022 05:52:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.79 on epoch=32
06/04/2022 05:52:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=33
06/04/2022 05:52:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.90 on epoch=34
06/04/2022 05:52:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.84 on epoch=36
06/04/2022 05:52:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.77 on epoch=37
06/04/2022 05:52:55 - INFO - __main__ - Global step 300 Train loss 0.83 Classification-F1 0.2021649505068812 on epoch=37
06/04/2022 05:52:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.83 on epoch=38
06/04/2022 05:53:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.82 on epoch=39
06/04/2022 05:53:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.88 on epoch=41
06/04/2022 05:53:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.84 on epoch=42
06/04/2022 05:53:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.78 on epoch=43
06/04/2022 05:53:09 - INFO - __main__ - Global step 350 Train loss 0.83 Classification-F1 0.23311546840958602 on epoch=43
06/04/2022 05:53:09 - INFO - __main__ - Saving model with best Classification-F1: 0.20391545391545393 -> 0.23311546840958602 on epoch=43, global_step=350
06/04/2022 05:53:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.85 on epoch=44
06/04/2022 05:53:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.90 on epoch=46
06/04/2022 05:53:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.80 on epoch=47
06/04/2022 05:53:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.89 on epoch=48
06/04/2022 05:53:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.77 on epoch=49
06/04/2022 05:53:23 - INFO - __main__ - Global step 400 Train loss 0.84 Classification-F1 0.19346026490066226 on epoch=49
06/04/2022 05:53:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.89 on epoch=51
06/04/2022 05:53:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.77 on epoch=52
06/04/2022 05:53:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.78 on epoch=53
06/04/2022 05:53:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.78 on epoch=54
06/04/2022 05:53:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.80 on epoch=56
06/04/2022 05:53:38 - INFO - __main__ - Global step 450 Train loss 0.80 Classification-F1 0.23252303252303252 on epoch=56
06/04/2022 05:53:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.76 on epoch=57
06/04/2022 05:53:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.74 on epoch=58
06/04/2022 05:53:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.74 on epoch=59
06/04/2022 05:53:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.63 on epoch=61
06/04/2022 05:53:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.74 on epoch=62
06/04/2022 05:53:52 - INFO - __main__ - Global step 500 Train loss 0.72 Classification-F1 0.5951512858898207 on epoch=62
06/04/2022 05:53:52 - INFO - __main__ - Saving model with best Classification-F1: 0.23311546840958602 -> 0.5951512858898207 on epoch=62, global_step=500
06/04/2022 05:53:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.68 on epoch=63
06/04/2022 05:53:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.73 on epoch=64
06/04/2022 05:54:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.68 on epoch=66
06/04/2022 05:54:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=67
06/04/2022 05:54:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.69 on epoch=68
06/04/2022 05:54:06 - INFO - __main__ - Global step 550 Train loss 0.68 Classification-F1 0.44087204445221573 on epoch=68
06/04/2022 05:54:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.63 on epoch=69
06/04/2022 05:54:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.71 on epoch=71
06/04/2022 05:54:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.66 on epoch=72
06/04/2022 05:54:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.64 on epoch=73
06/04/2022 05:54:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.65 on epoch=74
06/04/2022 05:54:21 - INFO - __main__ - Global step 600 Train loss 0.66 Classification-F1 0.5468843843843844 on epoch=74
06/04/2022 05:54:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.59 on epoch=76
06/04/2022 05:54:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.62 on epoch=77
06/04/2022 05:54:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.60 on epoch=78
06/04/2022 05:54:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.58 on epoch=79
06/04/2022 05:54:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.66 on epoch=81
06/04/2022 05:54:35 - INFO - __main__ - Global step 650 Train loss 0.61 Classification-F1 0.6178175618073316 on epoch=81
06/04/2022 05:54:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5951512858898207 -> 0.6178175618073316 on epoch=81, global_step=650
06/04/2022 05:54:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.55 on epoch=82
06/04/2022 05:54:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.58 on epoch=83
06/04/2022 05:54:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.55 on epoch=84
06/04/2022 05:54:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.56 on epoch=86
06/04/2022 05:54:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=87
06/04/2022 05:54:49 - INFO - __main__ - Global step 700 Train loss 0.54 Classification-F1 0.4435588972431078 on epoch=87
06/04/2022 05:54:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.48 on epoch=88
06/04/2022 05:54:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=89
06/04/2022 05:54:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.58 on epoch=91
06/04/2022 05:54:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.54 on epoch=92
06/04/2022 05:55:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.46 on epoch=93
06/04/2022 05:55:04 - INFO - __main__ - Global step 750 Train loss 0.50 Classification-F1 0.6123799899336093 on epoch=93
06/04/2022 05:55:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.51 on epoch=94
06/04/2022 05:55:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.48 on epoch=96
06/04/2022 05:55:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.52 on epoch=97
06/04/2022 05:55:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.46 on epoch=98
06/04/2022 05:55:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.40 on epoch=99
06/04/2022 05:55:18 - INFO - __main__ - Global step 800 Train loss 0.47 Classification-F1 0.6677993452187 on epoch=99
06/04/2022 05:55:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6178175618073316 -> 0.6677993452187 on epoch=99, global_step=800
06/04/2022 05:55:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.42 on epoch=101
06/04/2022 05:55:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.41 on epoch=102
06/04/2022 05:55:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.45 on epoch=103
06/04/2022 05:55:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.46 on epoch=104
06/04/2022 05:55:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.40 on epoch=106
06/04/2022 05:55:33 - INFO - __main__ - Global step 850 Train loss 0.43 Classification-F1 0.616965609176192 on epoch=106
06/04/2022 05:55:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.43 on epoch=107
06/04/2022 05:55:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.42 on epoch=108
06/04/2022 05:55:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.35 on epoch=109
06/04/2022 05:55:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.33 on epoch=111
06/04/2022 05:55:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.36 on epoch=112
06/04/2022 05:55:48 - INFO - __main__ - Global step 900 Train loss 0.38 Classification-F1 0.6670859716568672 on epoch=112
06/04/2022 05:55:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.31 on epoch=113
06/04/2022 05:55:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.44 on epoch=114
06/04/2022 05:55:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.44 on epoch=116
06/04/2022 05:55:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.33 on epoch=117
06/04/2022 05:56:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=118
06/04/2022 05:56:03 - INFO - __main__ - Global step 950 Train loss 0.36 Classification-F1 0.629851903658841 on epoch=118
06/04/2022 05:56:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.36 on epoch=119
06/04/2022 05:56:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.45 on epoch=121
06/04/2022 05:56:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.32 on epoch=122
06/04/2022 05:56:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.34 on epoch=123
06/04/2022 05:56:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.28 on epoch=124
06/04/2022 05:56:18 - INFO - __main__ - Global step 1000 Train loss 0.35 Classification-F1 0.7214355436449194 on epoch=124
06/04/2022 05:56:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6677993452187 -> 0.7214355436449194 on epoch=124, global_step=1000
06/04/2022 05:56:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.31 on epoch=126
06/04/2022 05:56:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=127
06/04/2022 05:56:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=128
06/04/2022 05:56:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=129
06/04/2022 05:56:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=131
06/04/2022 05:56:34 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.6764152727068327 on epoch=131
06/04/2022 05:56:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.29 on epoch=132
06/04/2022 05:56:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.28 on epoch=133
06/04/2022 05:56:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.26 on epoch=134
06/04/2022 05:56:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.31 on epoch=136
06/04/2022 05:56:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=137
06/04/2022 05:56:49 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.7098111491389794 on epoch=137
06/04/2022 05:56:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=138
06/04/2022 05:56:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.26 on epoch=139
06/04/2022 05:56:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=141
06/04/2022 05:56:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.31 on epoch=142
06/04/2022 05:57:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=143
06/04/2022 05:57:04 - INFO - __main__ - Global step 1150 Train loss 0.27 Classification-F1 0.6880276782158502 on epoch=143
06/04/2022 05:57:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=144
06/04/2022 05:57:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=146
06/04/2022 05:57:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=147
06/04/2022 05:57:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=148
06/04/2022 05:57:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=149
06/04/2022 05:57:19 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.6716897233201581 on epoch=149
06/04/2022 05:57:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.27 on epoch=151
06/04/2022 05:57:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=152
06/04/2022 05:57:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=153
06/04/2022 05:57:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=154
06/04/2022 05:57:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.22 on epoch=156
06/04/2022 05:57:35 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.6563978160204575 on epoch=156
06/04/2022 05:57:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=157
06/04/2022 05:57:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=158
06/04/2022 05:57:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.21 on epoch=159
06/04/2022 05:57:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=161
06/04/2022 05:57:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.23 on epoch=162
06/04/2022 05:57:50 - INFO - __main__ - Global step 1300 Train loss 0.21 Classification-F1 0.6858920187793428 on epoch=162
06/04/2022 05:57:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=163
06/04/2022 05:57:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.26 on epoch=164
06/04/2022 05:57:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=166
06/04/2022 05:58:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=167
06/04/2022 05:58:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=168
06/04/2022 05:58:05 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.6802521422239732 on epoch=168
06/04/2022 05:58:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=169
06/04/2022 05:58:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=171
06/04/2022 05:58:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=172
06/04/2022 05:58:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=173
06/04/2022 05:58:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=174
06/04/2022 05:58:20 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.6380688348932497 on epoch=174
06/04/2022 05:58:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=176
06/04/2022 05:58:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.25 on epoch=177
06/04/2022 05:58:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=178
06/04/2022 05:58:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=179
06/04/2022 05:58:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=181
06/04/2022 05:58:36 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.6821548277003795 on epoch=181
06/04/2022 05:58:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.18 on epoch=182
06/04/2022 05:58:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=183
06/04/2022 05:58:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=184
06/04/2022 05:58:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=186
06/04/2022 05:58:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.15 on epoch=187
06/04/2022 05:58:51 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.6645871870760883 on epoch=187
06/04/2022 05:58:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=188
06/04/2022 05:58:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=189
06/04/2022 05:58:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=191
06/04/2022 05:59:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=192
06/04/2022 05:59:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=193
06/04/2022 05:59:06 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.6543485901741779 on epoch=193
06/04/2022 05:59:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=194
06/04/2022 05:59:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.16 on epoch=196
06/04/2022 05:59:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.22 on epoch=197
06/04/2022 05:59:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=198
06/04/2022 05:59:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=199
06/04/2022 05:59:22 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.6458485786659162 on epoch=199
06/04/2022 05:59:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=201
06/04/2022 05:59:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=202
06/04/2022 05:59:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.21 on epoch=203
06/04/2022 05:59:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=204
06/04/2022 05:59:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=206
06/04/2022 05:59:37 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6886485280999108 on epoch=206
06/04/2022 05:59:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=207
06/04/2022 05:59:42 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=208
06/04/2022 05:59:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=209
06/04/2022 05:59:47 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=211
06/04/2022 05:59:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=212
06/04/2022 05:59:52 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.6767857142857143 on epoch=212
06/04/2022 05:59:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.13 on epoch=213
06/04/2022 05:59:57 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
06/04/2022 06:00:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=216
06/04/2022 06:00:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=217
06/04/2022 06:00:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=218
06/04/2022 06:00:07 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.6919369753876796 on epoch=218
06/04/2022 06:00:10 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=219
06/04/2022 06:00:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=221
06/04/2022 06:00:15 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=222
06/04/2022 06:00:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.15 on epoch=223
06/04/2022 06:00:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=224
06/04/2022 06:00:22 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.6342031834959714 on epoch=224
06/04/2022 06:00:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=226
06/04/2022 06:00:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=227
06/04/2022 06:00:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=228
06/04/2022 06:00:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=229
06/04/2022 06:00:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
06/04/2022 06:00:37 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.6753622138510577 on epoch=231
06/04/2022 06:00:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=232
06/04/2022 06:00:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=233
06/04/2022 06:00:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=234
06/04/2022 06:00:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=236
06/04/2022 06:00:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=237
06/04/2022 06:00:52 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7003588516746411 on epoch=237
06/04/2022 06:00:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
06/04/2022 06:00:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=239
06/04/2022 06:01:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.16 on epoch=241
06/04/2022 06:01:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=242
06/04/2022 06:01:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=243
06/04/2022 06:01:07 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7171445658733795 on epoch=243
06/04/2022 06:01:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=244
06/04/2022 06:01:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=246
06/04/2022 06:01:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=247
06/04/2022 06:01:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.16 on epoch=248
06/04/2022 06:01:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
06/04/2022 06:01:22 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.663472393267652 on epoch=249
06/04/2022 06:01:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=251
06/04/2022 06:01:27 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=252
06/04/2022 06:01:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=253
06/04/2022 06:01:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
06/04/2022 06:01:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
06/04/2022 06:01:37 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6470642740084414 on epoch=256
06/04/2022 06:01:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=257
06/04/2022 06:01:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=258
06/04/2022 06:01:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=259
06/04/2022 06:01:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=261
06/04/2022 06:01:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=262
06/04/2022 06:01:52 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6932114355765864 on epoch=262
06/04/2022 06:01:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=263
06/04/2022 06:01:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=264
06/04/2022 06:02:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=266
06/04/2022 06:02:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=267
06/04/2022 06:02:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=268
06/04/2022 06:02:07 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7331876041956098 on epoch=268
06/04/2022 06:02:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7214355436449194 -> 0.7331876041956098 on epoch=268, global_step=2150
06/04/2022 06:02:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=269
06/04/2022 06:02:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
06/04/2022 06:02:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/04/2022 06:02:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=273
06/04/2022 06:02:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=274
06/04/2022 06:02:22 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.681421082969281 on epoch=274
06/04/2022 06:02:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 06:02:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
06/04/2022 06:02:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
06/04/2022 06:02:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=279
06/04/2022 06:02:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=281
06/04/2022 06:02:37 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6887505152211035 on epoch=281
06/04/2022 06:02:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=282
06/04/2022 06:02:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
06/04/2022 06:02:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=284
06/04/2022 06:02:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 06:02:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=287
06/04/2022 06:02:52 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7064827201783723 on epoch=287
06/04/2022 06:02:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
06/04/2022 06:02:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
06/04/2022 06:02:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=291
06/04/2022 06:03:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
06/04/2022 06:03:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=293
06/04/2022 06:03:07 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7152688113214428 on epoch=293
06/04/2022 06:03:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=294
06/04/2022 06:03:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=296
06/04/2022 06:03:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/04/2022 06:03:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=298
06/04/2022 06:03:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.14 on epoch=299
06/04/2022 06:03:22 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7008239773433322 on epoch=299
06/04/2022 06:03:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=301
06/04/2022 06:03:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=302
06/04/2022 06:03:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.10 on epoch=303
06/04/2022 06:03:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
06/04/2022 06:03:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=306
06/04/2022 06:03:38 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.6985588563978394 on epoch=306
06/04/2022 06:03:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=307
06/04/2022 06:03:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=308
06/04/2022 06:03:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
06/04/2022 06:03:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=311
06/04/2022 06:03:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=312
06/04/2022 06:03:53 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.703393901345864 on epoch=312
06/04/2022 06:03:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=313
06/04/2022 06:03:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=314
06/04/2022 06:04:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
06/04/2022 06:04:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/04/2022 06:04:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=318
06/04/2022 06:04:08 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6870060475149098 on epoch=318
06/04/2022 06:04:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
06/04/2022 06:04:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=321
06/04/2022 06:04:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 06:04:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=323
06/04/2022 06:04:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=324
06/04/2022 06:04:23 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6796360744355148 on epoch=324
06/04/2022 06:04:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=326
06/04/2022 06:04:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=327
06/04/2022 06:04:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/04/2022 06:04:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=329
06/04/2022 06:04:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=331
06/04/2022 06:04:38 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.6708239894543275 on epoch=331
06/04/2022 06:04:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=332
06/04/2022 06:04:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
06/04/2022 06:04:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=334
06/04/2022 06:04:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/04/2022 06:04:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=337
06/04/2022 06:04:53 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6852843437250832 on epoch=337
06/04/2022 06:04:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=338
06/04/2022 06:04:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
06/04/2022 06:05:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/04/2022 06:05:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=342
06/04/2022 06:05:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/04/2022 06:05:08 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7233354802110799 on epoch=343
06/04/2022 06:05:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
06/04/2022 06:05:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/04/2022 06:05:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=347
06/04/2022 06:05:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.19 on epoch=348
06/04/2022 06:05:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/04/2022 06:05:23 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.7224905303030303 on epoch=349
06/04/2022 06:05:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/04/2022 06:05:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/04/2022 06:05:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
06/04/2022 06:05:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 06:05:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/04/2022 06:05:38 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.692602657429962 on epoch=356
06/04/2022 06:05:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=357
06/04/2022 06:05:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=358
06/04/2022 06:05:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=359
06/04/2022 06:05:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/04/2022 06:05:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/04/2022 06:05:53 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7184877245274139 on epoch=362
06/04/2022 06:05:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/04/2022 06:05:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
06/04/2022 06:06:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=366
06/04/2022 06:06:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.09 on epoch=367
06/04/2022 06:06:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=368
06/04/2022 06:06:07 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6933238636363637 on epoch=368
06/04/2022 06:06:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=369
06/04/2022 06:06:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/04/2022 06:06:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=372
06/04/2022 06:06:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
06/04/2022 06:06:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/04/2022 06:06:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:06:21 - INFO - __main__ - Printing 3 examples
06/04/2022 06:06:21 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:06:21 - INFO - __main__ - ['others']
06/04/2022 06:06:21 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:06:21 - INFO - __main__ - ['others']
06/04/2022 06:06:21 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:06:21 - INFO - __main__ - ['others']
06/04/2022 06:06:21 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:06:21 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:06:21 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:06:21 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:06:21 - INFO - __main__ - Printing 3 examples
06/04/2022 06:06:21 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:06:21 - INFO - __main__ - ['others']
06/04/2022 06:06:21 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:06:21 - INFO - __main__ - ['others']
06/04/2022 06:06:21 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:06:21 - INFO - __main__ - ['others']
06/04/2022 06:06:21 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:06:21 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:06:21 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:06:22 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.711879652605459 on epoch=374
06/04/2022 06:06:22 - INFO - __main__ - save last model!
06/04/2022 06:06:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 06:06:22 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 06:06:22 - INFO - __main__ - Printing 3 examples
06/04/2022 06:06:22 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 06:06:22 - INFO - __main__ - ['others']
06/04/2022 06:06:22 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 06:06:22 - INFO - __main__ - ['others']
06/04/2022 06:06:22 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 06:06:22 - INFO - __main__ - ['others']
06/04/2022 06:06:22 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:06:24 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:06:30 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 06:06:37 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:06:37 - INFO - __main__ - task name: emo
06/04/2022 06:06:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:06:37 - INFO - __main__ - Starting training!
06/04/2022 06:08:06 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_100_0.2_8_predictions.txt
06/04/2022 06:08:06 - INFO - __main__ - Classification-F1 on test data: 0.4350
06/04/2022 06:08:06 - INFO - __main__ - prefix=emo_32_100, lr=0.2, bsz=8, dev_performance=0.7331876041956098, test_performance=0.43502037624557616
06/04/2022 06:08:06 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.5, bsz=8 ...
06/04/2022 06:08:07 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:08:07 - INFO - __main__ - Printing 3 examples
06/04/2022 06:08:07 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:08:07 - INFO - __main__ - ['others']
06/04/2022 06:08:07 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:08:07 - INFO - __main__ - ['others']
06/04/2022 06:08:07 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:08:07 - INFO - __main__ - ['others']
06/04/2022 06:08:07 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:08:07 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:08:08 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:08:08 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:08:08 - INFO - __main__ - Printing 3 examples
06/04/2022 06:08:08 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:08:08 - INFO - __main__ - ['others']
06/04/2022 06:08:08 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:08:08 - INFO - __main__ - ['others']
06/04/2022 06:08:08 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:08:08 - INFO - __main__ - ['others']
06/04/2022 06:08:08 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:08:08 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:08:08 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:08:27 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:08:27 - INFO - __main__ - task name: emo
06/04/2022 06:08:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:08:28 - INFO - __main__ - Starting training!
06/04/2022 06:08:31 - INFO - __main__ - Step 10 Global step 10 Train loss 6.71 on epoch=1
06/04/2022 06:08:34 - INFO - __main__ - Step 20 Global step 20 Train loss 2.60 on epoch=2
06/04/2022 06:08:36 - INFO - __main__ - Step 30 Global step 30 Train loss 1.39 on epoch=3
06/04/2022 06:08:39 - INFO - __main__ - Step 40 Global step 40 Train loss 1.20 on epoch=4
06/04/2022 06:08:42 - INFO - __main__ - Step 50 Global step 50 Train loss 1.06 on epoch=6
06/04/2022 06:08:44 - INFO - __main__ - Global step 50 Train loss 2.59 Classification-F1 0.1304822565969063 on epoch=6
06/04/2022 06:08:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1304822565969063 on epoch=6, global_step=50
06/04/2022 06:08:46 - INFO - __main__ - Step 60 Global step 60 Train loss 0.99 on epoch=7
06/04/2022 06:08:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.07 on epoch=8
06/04/2022 06:08:51 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=9
06/04/2022 06:08:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.95 on epoch=11
06/04/2022 06:08:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=12
06/04/2022 06:08:59 - INFO - __main__ - Global step 100 Train loss 0.98 Classification-F1 0.10062893081761007 on epoch=12
06/04/2022 06:09:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=13
06/04/2022 06:09:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=14
06/04/2022 06:09:07 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=16
06/04/2022 06:09:10 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=17
06/04/2022 06:09:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.91 on epoch=18
06/04/2022 06:09:14 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.2367617783676178 on epoch=18
06/04/2022 06:09:14 - INFO - __main__ - Saving model with best Classification-F1: 0.1304822565969063 -> 0.2367617783676178 on epoch=18, global_step=150
06/04/2022 06:09:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=19
06/04/2022 06:09:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=21
06/04/2022 06:09:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=22
06/04/2022 06:09:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.90 on epoch=23
06/04/2022 06:09:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=24
06/04/2022 06:09:29 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.2821664946949111 on epoch=24
06/04/2022 06:09:29 - INFO - __main__ - Saving model with best Classification-F1: 0.2367617783676178 -> 0.2821664946949111 on epoch=24, global_step=200
06/04/2022 06:09:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=26
06/04/2022 06:09:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.80 on epoch=27
06/04/2022 06:09:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.75 on epoch=28
06/04/2022 06:09:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.77 on epoch=29
06/04/2022 06:09:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=31
06/04/2022 06:09:45 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.27271997803506653 on epoch=31
06/04/2022 06:09:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.72 on epoch=32
06/04/2022 06:09:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=33
06/04/2022 06:09:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.81 on epoch=34
06/04/2022 06:09:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=36
06/04/2022 06:09:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.71 on epoch=37
06/04/2022 06:10:01 - INFO - __main__ - Global step 300 Train loss 0.73 Classification-F1 0.16026865291571174 on epoch=37
06/04/2022 06:10:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.67 on epoch=38
06/04/2022 06:10:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.70 on epoch=39
06/04/2022 06:10:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.58 on epoch=41
06/04/2022 06:10:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=42
06/04/2022 06:10:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.61 on epoch=43
06/04/2022 06:10:16 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.5104685906789224 on epoch=43
06/04/2022 06:10:16 - INFO - __main__ - Saving model with best Classification-F1: 0.2821664946949111 -> 0.5104685906789224 on epoch=43, global_step=350
06/04/2022 06:10:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=44
06/04/2022 06:10:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=46
06/04/2022 06:10:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=47
06/04/2022 06:10:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=48
06/04/2022 06:10:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=49
06/04/2022 06:10:32 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.6793192532347149 on epoch=49
06/04/2022 06:10:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5104685906789224 -> 0.6793192532347149 on epoch=49, global_step=400
06/04/2022 06:10:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=51
06/04/2022 06:10:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=52
06/04/2022 06:10:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=53
06/04/2022 06:10:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=54
06/04/2022 06:10:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=56
06/04/2022 06:10:47 - INFO - __main__ - Global step 450 Train loss 0.41 Classification-F1 0.6373827392120075 on epoch=56
06/04/2022 06:10:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=57
06/04/2022 06:10:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=58
06/04/2022 06:10:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=59
06/04/2022 06:10:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=61
06/04/2022 06:11:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=62
06/04/2022 06:11:02 - INFO - __main__ - Global step 500 Train loss 0.34 Classification-F1 0.597783781746046 on epoch=62
06/04/2022 06:11:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=63
06/04/2022 06:11:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=64
06/04/2022 06:11:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=66
06/04/2022 06:11:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=67
06/04/2022 06:11:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=68
06/04/2022 06:11:17 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.6563839850409723 on epoch=68
06/04/2022 06:11:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=69
06/04/2022 06:11:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=71
06/04/2022 06:11:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=72
06/04/2022 06:11:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=73
06/04/2022 06:11:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=74
06/04/2022 06:11:32 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.6959889042668638 on epoch=74
06/04/2022 06:11:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6793192532347149 -> 0.6959889042668638 on epoch=74, global_step=600
06/04/2022 06:11:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=76
06/04/2022 06:11:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=77
06/04/2022 06:11:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=78
06/04/2022 06:11:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=79
06/04/2022 06:11:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=81
06/04/2022 06:11:48 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.6895856673051208 on epoch=81
06/04/2022 06:11:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=82
06/04/2022 06:11:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=83
06/04/2022 06:11:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=84
06/04/2022 06:11:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=86
06/04/2022 06:12:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=87
06/04/2022 06:12:03 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.6520233435840089 on epoch=87
06/04/2022 06:12:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=88
06/04/2022 06:12:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=89
06/04/2022 06:12:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=91
06/04/2022 06:12:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=92
06/04/2022 06:12:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=93
06/04/2022 06:12:19 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.6692185502669373 on epoch=93
06/04/2022 06:12:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=94
06/04/2022 06:12:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=96
06/04/2022 06:12:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=97
06/04/2022 06:12:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=98
06/04/2022 06:12:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=99
06/04/2022 06:12:34 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.7331496885358014 on epoch=99
06/04/2022 06:12:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6959889042668638 -> 0.7331496885358014 on epoch=99, global_step=800
06/04/2022 06:12:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=101
06/04/2022 06:12:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=102
06/04/2022 06:12:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=103
06/04/2022 06:12:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=104
06/04/2022 06:12:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=106
06/04/2022 06:12:50 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7431985294117647 on epoch=106
06/04/2022 06:12:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7331496885358014 -> 0.7431985294117647 on epoch=106, global_step=850
06/04/2022 06:12:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=107
06/04/2022 06:12:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=108
06/04/2022 06:12:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=109
06/04/2022 06:13:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=111
06/04/2022 06:13:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=112
06/04/2022 06:13:05 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7289043252755394 on epoch=112
06/04/2022 06:13:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=113
06/04/2022 06:13:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=114
06/04/2022 06:13:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=116
06/04/2022 06:13:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=117
06/04/2022 06:13:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=118
06/04/2022 06:13:21 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7075109302876998 on epoch=118
06/04/2022 06:13:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=119
06/04/2022 06:13:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=121
06/04/2022 06:13:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=122
06/04/2022 06:13:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=123
06/04/2022 06:13:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=124
06/04/2022 06:13:36 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7195828375537174 on epoch=124
06/04/2022 06:13:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=126
06/04/2022 06:13:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=127
06/04/2022 06:13:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=128
06/04/2022 06:13:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=129
06/04/2022 06:13:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=131
06/04/2022 06:13:52 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7350475881462254 on epoch=131
06/04/2022 06:13:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=132
06/04/2022 06:13:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=133
06/04/2022 06:13:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=134
06/04/2022 06:14:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=136
06/04/2022 06:14:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=137
06/04/2022 06:14:07 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7486921258354051 on epoch=137
06/04/2022 06:14:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7431985294117647 -> 0.7486921258354051 on epoch=137, global_step=1100
06/04/2022 06:14:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=138
06/04/2022 06:14:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=139
06/04/2022 06:14:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=141
06/04/2022 06:14:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=142
06/04/2022 06:14:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=143
06/04/2022 06:14:22 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7432862407419427 on epoch=143
06/04/2022 06:14:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=144
06/04/2022 06:14:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=146
06/04/2022 06:14:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=147
06/04/2022 06:14:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=148
06/04/2022 06:14:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=149
06/04/2022 06:14:38 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7628844839371155 on epoch=149
06/04/2022 06:14:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7486921258354051 -> 0.7628844839371155 on epoch=149, global_step=1200
06/04/2022 06:14:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=151
06/04/2022 06:14:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=152
06/04/2022 06:14:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=153
06/04/2022 06:14:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=154
06/04/2022 06:14:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=156
06/04/2022 06:14:54 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7257569875776397 on epoch=156
06/04/2022 06:14:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=157
06/04/2022 06:14:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=158
06/04/2022 06:15:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=159
06/04/2022 06:15:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=161
06/04/2022 06:15:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=162
06/04/2022 06:15:09 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7717867737764569 on epoch=162
06/04/2022 06:15:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7628844839371155 -> 0.7717867737764569 on epoch=162, global_step=1300
06/04/2022 06:15:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=163
06/04/2022 06:15:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=164
06/04/2022 06:15:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=166
06/04/2022 06:15:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=167
06/04/2022 06:15:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=168
06/04/2022 06:15:25 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7538794538794538 on epoch=168
06/04/2022 06:15:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=169
06/04/2022 06:15:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=171
06/04/2022 06:15:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=172
06/04/2022 06:15:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=173
06/04/2022 06:15:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=174
06/04/2022 06:15:40 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7461262941637606 on epoch=174
06/04/2022 06:15:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=176
06/04/2022 06:15:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=177
06/04/2022 06:15:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=178
06/04/2022 06:15:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=179
06/04/2022 06:15:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=181
06/04/2022 06:15:56 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7434368776194287 on epoch=181
06/04/2022 06:15:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=182
06/04/2022 06:16:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=183
06/04/2022 06:16:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=184
06/04/2022 06:16:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=186
06/04/2022 06:16:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=187
06/04/2022 06:16:11 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7570207642238791 on epoch=187
06/04/2022 06:16:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=188
06/04/2022 06:16:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=189
06/04/2022 06:16:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=191
06/04/2022 06:16:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=192
06/04/2022 06:16:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=193
06/04/2022 06:16:27 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7591321865586012 on epoch=193
06/04/2022 06:16:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=194
06/04/2022 06:16:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=196
06/04/2022 06:16:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=197
06/04/2022 06:16:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=198
06/04/2022 06:16:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=199
06/04/2022 06:16:42 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.6730321414345681 on epoch=199
06/04/2022 06:16:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=201
06/04/2022 06:16:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=202
06/04/2022 06:16:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=203
06/04/2022 06:16:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=204
06/04/2022 06:16:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=206
06/04/2022 06:16:57 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7579687139228815 on epoch=206
06/04/2022 06:17:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=207
06/04/2022 06:17:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=208
06/04/2022 06:17:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=209
06/04/2022 06:17:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=211
06/04/2022 06:17:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
06/04/2022 06:17:12 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7699544464250347 on epoch=212
06/04/2022 06:17:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=213
06/04/2022 06:17:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=214
06/04/2022 06:17:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=216
06/04/2022 06:17:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=217
06/04/2022 06:17:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=218
06/04/2022 06:17:28 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7625066009505368 on epoch=218
06/04/2022 06:17:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=219
06/04/2022 06:17:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=221
06/04/2022 06:17:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=222
06/04/2022 06:17:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=223
06/04/2022 06:17:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 06:17:43 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.709072211044042 on epoch=224
06/04/2022 06:17:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=226
06/04/2022 06:17:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=227
06/04/2022 06:17:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=228
06/04/2022 06:17:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=229
06/04/2022 06:17:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=231
06/04/2022 06:17:59 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7589532923054686 on epoch=231
06/04/2022 06:18:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=232
06/04/2022 06:18:04 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=233
06/04/2022 06:18:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
06/04/2022 06:18:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=236
06/04/2022 06:18:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=237
06/04/2022 06:18:14 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7548999654135738 on epoch=237
06/04/2022 06:18:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=238
06/04/2022 06:18:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=239
06/04/2022 06:18:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=241
06/04/2022 06:18:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=242
06/04/2022 06:18:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
06/04/2022 06:18:30 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7240304472136174 on epoch=243
06/04/2022 06:18:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
06/04/2022 06:18:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=246
06/04/2022 06:18:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
06/04/2022 06:18:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=248
06/04/2022 06:18:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
06/04/2022 06:18:45 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7526314685791275 on epoch=249
06/04/2022 06:18:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=251
06/04/2022 06:18:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=252
06/04/2022 06:18:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
06/04/2022 06:18:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/04/2022 06:18:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=256
06/04/2022 06:19:01 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7569746880405238 on epoch=256
06/04/2022 06:19:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=257
06/04/2022 06:19:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=258
06/04/2022 06:19:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=259
06/04/2022 06:19:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=261
06/04/2022 06:19:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=262
06/04/2022 06:19:16 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7573453423592806 on epoch=262
06/04/2022 06:19:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=263
06/04/2022 06:19:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=264
06/04/2022 06:19:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=266
06/04/2022 06:19:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=267
06/04/2022 06:19:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=268
06/04/2022 06:19:31 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7404412488919531 on epoch=268
06/04/2022 06:19:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
06/04/2022 06:19:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=271
06/04/2022 06:19:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=272
06/04/2022 06:19:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=273
06/04/2022 06:19:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=274
06/04/2022 06:19:47 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7493399577572964 on epoch=274
06/04/2022 06:19:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=276
06/04/2022 06:19:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=277
06/04/2022 06:19:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=278
06/04/2022 06:19:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
06/04/2022 06:20:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=281
06/04/2022 06:20:03 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7815166591285994 on epoch=281
06/04/2022 06:20:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7717867737764569 -> 0.7815166591285994 on epoch=281, global_step=2250
06/04/2022 06:20:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=282
06/04/2022 06:20:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=283
06/04/2022 06:20:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=284
06/04/2022 06:20:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 06:20:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
06/04/2022 06:20:18 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7752624280893272 on epoch=287
06/04/2022 06:20:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=288
06/04/2022 06:20:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
06/04/2022 06:20:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/04/2022 06:20:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=292
06/04/2022 06:20:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=293
06/04/2022 06:20:35 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7798911095746106 on epoch=293
06/04/2022 06:20:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
06/04/2022 06:20:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=296
06/04/2022 06:20:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
06/04/2022 06:20:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=298
06/04/2022 06:20:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/04/2022 06:20:50 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7367434165421782 on epoch=299
06/04/2022 06:20:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=301
06/04/2022 06:20:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=302
06/04/2022 06:20:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=303
06/04/2022 06:21:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
06/04/2022 06:21:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=306
06/04/2022 06:21:06 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7567365584606964 on epoch=306
06/04/2022 06:21:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
06/04/2022 06:21:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=308
06/04/2022 06:21:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=309
06/04/2022 06:21:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
06/04/2022 06:21:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/04/2022 06:21:21 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7570750427346711 on epoch=312
06/04/2022 06:21:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/04/2022 06:21:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 06:21:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
06/04/2022 06:21:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
06/04/2022 06:21:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
06/04/2022 06:21:38 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7803814976839939 on epoch=318
06/04/2022 06:21:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
06/04/2022 06:21:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 06:21:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=322
06/04/2022 06:21:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
06/04/2022 06:21:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
06/04/2022 06:21:54 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7746791138192176 on epoch=324
06/04/2022 06:21:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=326
06/04/2022 06:21:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
06/04/2022 06:22:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=328
06/04/2022 06:22:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
06/04/2022 06:22:07 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
06/04/2022 06:22:09 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7663167175093573 on epoch=331
06/04/2022 06:22:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
06/04/2022 06:22:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
06/04/2022 06:22:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=334
06/04/2022 06:22:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=336
06/04/2022 06:22:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/04/2022 06:22:25 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7121025530659908 on epoch=337
06/04/2022 06:22:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
06/04/2022 06:22:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
06/04/2022 06:22:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=341
06/04/2022 06:22:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
06/04/2022 06:22:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=343
06/04/2022 06:22:41 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7273082006252936 on epoch=343
06/04/2022 06:22:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
06/04/2022 06:22:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=346
06/04/2022 06:22:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
06/04/2022 06:22:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/04/2022 06:22:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 06:22:57 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7546768299189075 on epoch=349
06/04/2022 06:23:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
06/04/2022 06:23:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
06/04/2022 06:23:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 06:23:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
06/04/2022 06:23:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/04/2022 06:23:13 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7258861478256512 on epoch=356
06/04/2022 06:23:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/04/2022 06:23:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
06/04/2022 06:23:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 06:23:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/04/2022 06:23:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
06/04/2022 06:23:29 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7491978609625668 on epoch=362
06/04/2022 06:23:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/04/2022 06:23:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
06/04/2022 06:23:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=366
06/04/2022 06:23:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
06/04/2022 06:23:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=368
06/04/2022 06:23:44 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.712115619590673 on epoch=368
06/04/2022 06:23:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/04/2022 06:23:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/04/2022 06:23:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 06:23:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/04/2022 06:23:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 06:23:59 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:23:59 - INFO - __main__ - Printing 3 examples
06/04/2022 06:23:59 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:23:59 - INFO - __main__ - ['others']
06/04/2022 06:23:59 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:23:59 - INFO - __main__ - ['others']
06/04/2022 06:23:59 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:23:59 - INFO - __main__ - ['others']
06/04/2022 06:23:59 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:23:59 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:23:59 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:23:59 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:23:59 - INFO - __main__ - Printing 3 examples
06/04/2022 06:23:59 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:23:59 - INFO - __main__ - ['others']
06/04/2022 06:23:59 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:23:59 - INFO - __main__ - ['others']
06/04/2022 06:23:59 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:23:59 - INFO - __main__ - ['others']
06/04/2022 06:23:59 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:23:59 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:23:59 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:24:00 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.72467004819946 on epoch=374
06/04/2022 06:24:00 - INFO - __main__ - save last model!
06/04/2022 06:24:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 06:24:00 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 06:24:00 - INFO - __main__ - Printing 3 examples
06/04/2022 06:24:00 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 06:24:00 - INFO - __main__ - ['others']
06/04/2022 06:24:00 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 06:24:00 - INFO - __main__ - ['others']
06/04/2022 06:24:00 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 06:24:00 - INFO - __main__ - ['others']
06/04/2022 06:24:00 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:24:02 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:24:07 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 06:24:19 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:24:19 - INFO - __main__ - task name: emo
06/04/2022 06:24:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:24:20 - INFO - __main__ - Starting training!
06/04/2022 06:25:40 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_13_0.5_8_predictions.txt
06/04/2022 06:25:40 - INFO - __main__ - Classification-F1 on test data: 0.1219
06/04/2022 06:25:40 - INFO - __main__ - prefix=emo_32_13, lr=0.5, bsz=8, dev_performance=0.7815166591285994, test_performance=0.12185331850217189
06/04/2022 06:25:40 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.4, bsz=8 ...
06/04/2022 06:25:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:25:41 - INFO - __main__ - Printing 3 examples
06/04/2022 06:25:41 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:25:41 - INFO - __main__ - ['others']
06/04/2022 06:25:41 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:25:41 - INFO - __main__ - ['others']
06/04/2022 06:25:41 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:25:41 - INFO - __main__ - ['others']
06/04/2022 06:25:41 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:25:42 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:25:42 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:25:42 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:25:42 - INFO - __main__ - Printing 3 examples
06/04/2022 06:25:42 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:25:42 - INFO - __main__ - ['others']
06/04/2022 06:25:42 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:25:42 - INFO - __main__ - ['others']
06/04/2022 06:25:42 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:25:42 - INFO - __main__ - ['others']
06/04/2022 06:25:42 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:25:42 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:25:42 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:25:57 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:25:57 - INFO - __main__ - task name: emo
06/04/2022 06:25:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:25:58 - INFO - __main__ - Starting training!
06/04/2022 06:26:01 - INFO - __main__ - Step 10 Global step 10 Train loss 7.14 on epoch=1
06/04/2022 06:26:04 - INFO - __main__ - Step 20 Global step 20 Train loss 3.19 on epoch=2
06/04/2022 06:26:06 - INFO - __main__ - Step 30 Global step 30 Train loss 1.52 on epoch=3
06/04/2022 06:26:09 - INFO - __main__ - Step 40 Global step 40 Train loss 1.06 on epoch=4
06/04/2022 06:26:11 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=6
06/04/2022 06:26:13 - INFO - __main__ - Global step 50 Train loss 2.78 Classification-F1 0.11947174447174447 on epoch=6
06/04/2022 06:26:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11947174447174447 on epoch=6, global_step=50
06/04/2022 06:26:15 - INFO - __main__ - Step 60 Global step 60 Train loss 0.94 on epoch=7
06/04/2022 06:26:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=8
06/04/2022 06:26:20 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=9
06/04/2022 06:26:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.97 on epoch=11
06/04/2022 06:26:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=12
06/04/2022 06:26:27 - INFO - __main__ - Global step 100 Train loss 0.96 Classification-F1 0.20557979914116736 on epoch=12
06/04/2022 06:26:27 - INFO - __main__ - Saving model with best Classification-F1: 0.11947174447174447 -> 0.20557979914116736 on epoch=12, global_step=100
06/04/2022 06:26:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=13
06/04/2022 06:26:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=14
06/04/2022 06:26:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=16
06/04/2022 06:26:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=17
06/04/2022 06:26:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.85 on epoch=18
06/04/2022 06:26:41 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.21184873949579835 on epoch=18
06/04/2022 06:26:41 - INFO - __main__ - Saving model with best Classification-F1: 0.20557979914116736 -> 0.21184873949579835 on epoch=18, global_step=150
06/04/2022 06:26:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.86 on epoch=19
06/04/2022 06:26:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=21
06/04/2022 06:26:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=22
06/04/2022 06:26:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.89 on epoch=23
06/04/2022 06:26:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.81 on epoch=24
06/04/2022 06:26:56 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.21413698387382596 on epoch=24
06/04/2022 06:26:56 - INFO - __main__ - Saving model with best Classification-F1: 0.21184873949579835 -> 0.21413698387382596 on epoch=24, global_step=200
06/04/2022 06:26:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=26
06/04/2022 06:27:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.78 on epoch=27
06/04/2022 06:27:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=28
06/04/2022 06:27:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=29
06/04/2022 06:27:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.79 on epoch=31
06/04/2022 06:27:10 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.13263757115749525 on epoch=31
06/04/2022 06:27:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=32
06/04/2022 06:27:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.79 on epoch=33
06/04/2022 06:27:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.79 on epoch=34
06/04/2022 06:27:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.78 on epoch=36
06/04/2022 06:27:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.80 on epoch=37
06/04/2022 06:27:25 - INFO - __main__ - Global step 300 Train loss 0.77 Classification-F1 0.18961060363499388 on epoch=37
06/04/2022 06:27:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.80 on epoch=38
06/04/2022 06:27:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.77 on epoch=39
06/04/2022 06:27:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.70 on epoch=41
06/04/2022 06:27:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.70 on epoch=42
06/04/2022 06:27:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.70 on epoch=43
06/04/2022 06:27:39 - INFO - __main__ - Global step 350 Train loss 0.73 Classification-F1 0.40221776156405475 on epoch=43
06/04/2022 06:27:39 - INFO - __main__ - Saving model with best Classification-F1: 0.21413698387382596 -> 0.40221776156405475 on epoch=43, global_step=350
06/04/2022 06:27:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.52 on epoch=44
06/04/2022 06:27:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.67 on epoch=46
06/04/2022 06:27:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.58 on epoch=47
06/04/2022 06:27:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=48
06/04/2022 06:27:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=49
06/04/2022 06:27:53 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.5703412578675044 on epoch=49
06/04/2022 06:27:53 - INFO - __main__ - Saving model with best Classification-F1: 0.40221776156405475 -> 0.5703412578675044 on epoch=49, global_step=400
06/04/2022 06:27:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=51
06/04/2022 06:27:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.50 on epoch=52
06/04/2022 06:28:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.57 on epoch=53
06/04/2022 06:28:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=54
06/04/2022 06:28:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=56
06/04/2022 06:28:08 - INFO - __main__ - Global step 450 Train loss 0.51 Classification-F1 0.6297410192147035 on epoch=56
06/04/2022 06:28:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5703412578675044 -> 0.6297410192147035 on epoch=56, global_step=450
06/04/2022 06:28:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=57
06/04/2022 06:28:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.59 on epoch=58
06/04/2022 06:28:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=59
06/04/2022 06:28:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=61
06/04/2022 06:28:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.49 on epoch=62
06/04/2022 06:28:22 - INFO - __main__ - Global step 500 Train loss 0.48 Classification-F1 0.45971083172147004 on epoch=62
06/04/2022 06:28:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=63
06/04/2022 06:28:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.42 on epoch=64
06/04/2022 06:28:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.45 on epoch=66
06/04/2022 06:28:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=67
06/04/2022 06:28:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.36 on epoch=68
06/04/2022 06:28:37 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.5627653548002385 on epoch=68
06/04/2022 06:28:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=69
06/04/2022 06:28:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=71
06/04/2022 06:28:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=72
06/04/2022 06:28:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=73
06/04/2022 06:28:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.32 on epoch=74
06/04/2022 06:28:53 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.6259597320918076 on epoch=74
06/04/2022 06:28:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=76
06/04/2022 06:28:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=77
06/04/2022 06:29:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=78
06/04/2022 06:29:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=79
06/04/2022 06:29:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=81
06/04/2022 06:29:08 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.6429803205518361 on epoch=81
06/04/2022 06:29:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6297410192147035 -> 0.6429803205518361 on epoch=81, global_step=650
06/04/2022 06:29:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=82
06/04/2022 06:29:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=83
06/04/2022 06:29:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=84
06/04/2022 06:29:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=86
06/04/2022 06:29:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=87
06/04/2022 06:29:23 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.591508587613975 on epoch=87
06/04/2022 06:29:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=88
06/04/2022 06:29:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=89
06/04/2022 06:29:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=91
06/04/2022 06:29:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=92
06/04/2022 06:29:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=93
06/04/2022 06:29:37 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.6268821603927986 on epoch=93
06/04/2022 06:29:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=94
06/04/2022 06:29:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=96
06/04/2022 06:29:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=97
06/04/2022 06:29:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=98
06/04/2022 06:29:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=99
06/04/2022 06:29:52 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6448054551137543 on epoch=99
06/04/2022 06:29:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6429803205518361 -> 0.6448054551137543 on epoch=99, global_step=800
06/04/2022 06:29:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=101
06/04/2022 06:29:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=102
06/04/2022 06:30:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=103
06/04/2022 06:30:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=104
06/04/2022 06:30:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=106
06/04/2022 06:30:07 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.6593664648459169 on epoch=106
06/04/2022 06:30:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6448054551137543 -> 0.6593664648459169 on epoch=106, global_step=850
06/04/2022 06:30:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=107
06/04/2022 06:30:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=108
06/04/2022 06:30:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=109
06/04/2022 06:30:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=111
06/04/2022 06:30:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=112
06/04/2022 06:30:23 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.6392172085765797 on epoch=112
06/04/2022 06:30:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=113
06/04/2022 06:30:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=114
06/04/2022 06:30:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=116
06/04/2022 06:30:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=117
06/04/2022 06:30:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=118
06/04/2022 06:30:38 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6232998885172798 on epoch=118
06/04/2022 06:30:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=119
06/04/2022 06:30:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=121
06/04/2022 06:30:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=122
06/04/2022 06:30:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=123
06/04/2022 06:30:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=124
06/04/2022 06:30:53 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6833333333333333 on epoch=124
06/04/2022 06:30:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6593664648459169 -> 0.6833333333333333 on epoch=124, global_step=1000
06/04/2022 06:30:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=126
06/04/2022 06:30:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=127
06/04/2022 06:31:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=128
06/04/2022 06:31:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=129
06/04/2022 06:31:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=131
06/04/2022 06:31:07 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6890169927142966 on epoch=131
06/04/2022 06:31:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6833333333333333 -> 0.6890169927142966 on epoch=131, global_step=1050
06/04/2022 06:31:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=132
06/04/2022 06:31:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=133
06/04/2022 06:31:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=134
06/04/2022 06:31:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=136
06/04/2022 06:31:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=137
06/04/2022 06:31:22 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.6524650233177881 on epoch=137
06/04/2022 06:31:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=138
06/04/2022 06:31:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=139
06/04/2022 06:31:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=141
06/04/2022 06:31:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=142
06/04/2022 06:31:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=143
06/04/2022 06:31:37 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.6756156077558944 on epoch=143
06/04/2022 06:31:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=144
06/04/2022 06:31:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=146
06/04/2022 06:31:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=147
06/04/2022 06:31:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=148
06/04/2022 06:31:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=149
06/04/2022 06:31:52 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.6767231638418079 on epoch=149
06/04/2022 06:31:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=151
06/04/2022 06:31:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=152
06/04/2022 06:32:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=153
06/04/2022 06:32:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=154
06/04/2022 06:32:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=156
06/04/2022 06:32:07 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7021003028404345 on epoch=156
06/04/2022 06:32:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6890169927142966 -> 0.7021003028404345 on epoch=156, global_step=1250
06/04/2022 06:32:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=157
06/04/2022 06:32:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=158
06/04/2022 06:32:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=159
06/04/2022 06:32:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=161
06/04/2022 06:32:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=162
06/04/2022 06:32:22 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.7114624505928854 on epoch=162
06/04/2022 06:32:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7021003028404345 -> 0.7114624505928854 on epoch=162, global_step=1300
06/04/2022 06:32:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=163
06/04/2022 06:32:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=164
06/04/2022 06:32:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=166
06/04/2022 06:32:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=167
06/04/2022 06:32:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=168
06/04/2022 06:32:37 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7261605271039233 on epoch=168
06/04/2022 06:32:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7114624505928854 -> 0.7261605271039233 on epoch=168, global_step=1350
06/04/2022 06:32:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=169
06/04/2022 06:32:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=171
06/04/2022 06:32:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=172
06/04/2022 06:32:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=173
06/04/2022 06:32:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=174
06/04/2022 06:32:52 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6957152285101469 on epoch=174
06/04/2022 06:32:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=176
06/04/2022 06:32:57 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=177
06/04/2022 06:33:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=178
06/04/2022 06:33:02 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=179
06/04/2022 06:33:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=181
06/04/2022 06:33:07 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.681001212358747 on epoch=181
06/04/2022 06:33:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=182
06/04/2022 06:33:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=183
06/04/2022 06:33:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=184
06/04/2022 06:33:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=186
06/04/2022 06:33:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=187
06/04/2022 06:33:22 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6818097496451155 on epoch=187
06/04/2022 06:33:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=188
06/04/2022 06:33:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=189
06/04/2022 06:33:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=191
06/04/2022 06:33:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=192
06/04/2022 06:33:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=193
06/04/2022 06:33:38 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7155486545644644 on epoch=193
06/04/2022 06:33:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=194
06/04/2022 06:33:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=196
06/04/2022 06:33:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=197
06/04/2022 06:33:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/04/2022 06:33:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=199
06/04/2022 06:33:53 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.71941073598857 on epoch=199
06/04/2022 06:33:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=201
06/04/2022 06:33:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=202
06/04/2022 06:34:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=203
06/04/2022 06:34:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=204
06/04/2022 06:34:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=206
06/04/2022 06:34:07 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6860825845100557 on epoch=206
06/04/2022 06:34:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=207
06/04/2022 06:34:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=208
06/04/2022 06:34:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=209
06/04/2022 06:34:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=211
06/04/2022 06:34:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=212
06/04/2022 06:34:21 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6901223776223777 on epoch=212
06/04/2022 06:34:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=213
06/04/2022 06:34:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=214
06/04/2022 06:34:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=216
06/04/2022 06:34:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
06/04/2022 06:34:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=218
06/04/2022 06:34:37 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6487311899605752 on epoch=218
06/04/2022 06:34:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
06/04/2022 06:34:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=221
06/04/2022 06:34:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=222
06/04/2022 06:34:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=223
06/04/2022 06:34:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 06:34:51 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6715361262902246 on epoch=224
06/04/2022 06:34:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
06/04/2022 06:34:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=227
06/04/2022 06:34:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=228
06/04/2022 06:35:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=229
06/04/2022 06:35:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=231
06/04/2022 06:35:06 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7023344039473072 on epoch=231
06/04/2022 06:35:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=232
06/04/2022 06:35:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=233
06/04/2022 06:35:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
06/04/2022 06:35:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=236
06/04/2022 06:35:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/04/2022 06:35:21 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7083466224091224 on epoch=237
06/04/2022 06:35:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
06/04/2022 06:35:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
06/04/2022 06:35:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=241
06/04/2022 06:35:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
06/04/2022 06:35:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
06/04/2022 06:35:36 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.602619596225587 on epoch=243
06/04/2022 06:35:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
06/04/2022 06:35:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=246
06/04/2022 06:35:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=247
06/04/2022 06:35:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=248
06/04/2022 06:35:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=249
06/04/2022 06:35:52 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7061175666438826 on epoch=249
06/04/2022 06:35:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
06/04/2022 06:35:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
06/04/2022 06:36:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=253
06/04/2022 06:36:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=254
06/04/2022 06:36:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=256
06/04/2022 06:36:07 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7190818473251853 on epoch=256
06/04/2022 06:36:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=257
06/04/2022 06:36:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/04/2022 06:36:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
06/04/2022 06:36:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=261
06/04/2022 06:36:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
06/04/2022 06:36:23 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6867343304843305 on epoch=262
06/04/2022 06:36:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=263
06/04/2022 06:36:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=264
06/04/2022 06:36:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/04/2022 06:36:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=267
06/04/2022 06:36:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
06/04/2022 06:36:38 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6833357771260997 on epoch=268
06/04/2022 06:36:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
06/04/2022 06:36:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 06:36:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
06/04/2022 06:36:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=273
06/04/2022 06:36:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=274
06/04/2022 06:36:54 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7254473104579038 on epoch=274
06/04/2022 06:36:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=276
06/04/2022 06:37:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
06/04/2022 06:37:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=278
06/04/2022 06:37:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
06/04/2022 06:37:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/04/2022 06:37:11 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6657272498040312 on epoch=281
06/04/2022 06:37:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=282
06/04/2022 06:37:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/04/2022 06:37:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/04/2022 06:37:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 06:37:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/04/2022 06:37:27 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6585135061292143 on epoch=287
06/04/2022 06:37:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
06/04/2022 06:37:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
06/04/2022 06:37:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=291
06/04/2022 06:37:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=292
06/04/2022 06:37:40 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=293
06/04/2022 06:37:42 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6679372219139138 on epoch=293
06/04/2022 06:37:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
06/04/2022 06:37:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/04/2022 06:37:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
06/04/2022 06:37:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
06/04/2022 06:37:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/04/2022 06:37:57 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6930001285264442 on epoch=299
06/04/2022 06:38:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=301
06/04/2022 06:38:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=302
06/04/2022 06:38:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/04/2022 06:38:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
06/04/2022 06:38:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=306
06/04/2022 06:38:13 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6973182847766058 on epoch=306
06/04/2022 06:38:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=307
06/04/2022 06:38:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=308
06/04/2022 06:38:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=309
06/04/2022 06:38:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
06/04/2022 06:38:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=312
06/04/2022 06:38:28 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6610864274948961 on epoch=312
06/04/2022 06:38:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=313
06/04/2022 06:38:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 06:38:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
06/04/2022 06:38:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/04/2022 06:38:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
06/04/2022 06:38:43 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6894157678479712 on epoch=318
06/04/2022 06:38:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/04/2022 06:38:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 06:38:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 06:38:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
06/04/2022 06:38:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/04/2022 06:38:58 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6870193076431084 on epoch=324
06/04/2022 06:39:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/04/2022 06:39:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
06/04/2022 06:39:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
06/04/2022 06:39:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
06/04/2022 06:39:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/04/2022 06:39:14 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7102179208637829 on epoch=331
06/04/2022 06:39:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
06/04/2022 06:39:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=333
06/04/2022 06:39:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=334
06/04/2022 06:39:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=336
06/04/2022 06:39:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=337
06/04/2022 06:39:29 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6970819304152637 on epoch=337
06/04/2022 06:39:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
06/04/2022 06:39:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=339
06/04/2022 06:39:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=341
06/04/2022 06:39:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=342
06/04/2022 06:39:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=343
06/04/2022 06:39:45 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6539788713701757 on epoch=343
06/04/2022 06:39:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
06/04/2022 06:39:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
06/04/2022 06:39:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
06/04/2022 06:39:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/04/2022 06:39:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 06:40:00 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.707370292388368 on epoch=349
06/04/2022 06:40:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/04/2022 06:40:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
06/04/2022 06:40:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/04/2022 06:40:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=354
06/04/2022 06:40:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 06:40:15 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7052238001169782 on epoch=356
06/04/2022 06:40:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/04/2022 06:40:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
06/04/2022 06:40:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
06/04/2022 06:40:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/04/2022 06:40:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/04/2022 06:40:30 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7031998831092928 on epoch=362
06/04/2022 06:40:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/04/2022 06:40:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 06:40:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
06/04/2022 06:40:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 06:40:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=368
06/04/2022 06:40:46 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6755847953216374 on epoch=368
06/04/2022 06:40:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/04/2022 06:40:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=371
06/04/2022 06:40:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 06:40:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=373
06/04/2022 06:40:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 06:41:00 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:41:00 - INFO - __main__ - Printing 3 examples
06/04/2022 06:41:00 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:41:00 - INFO - __main__ - ['others']
06/04/2022 06:41:00 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:41:00 - INFO - __main__ - ['others']
06/04/2022 06:41:00 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:41:00 - INFO - __main__ - ['others']
06/04/2022 06:41:00 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:41:00 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:41:00 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:41:00 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:41:00 - INFO - __main__ - Printing 3 examples
06/04/2022 06:41:00 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:41:00 - INFO - __main__ - ['others']
06/04/2022 06:41:00 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:41:00 - INFO - __main__ - ['others']
06/04/2022 06:41:00 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:41:00 - INFO - __main__ - ['others']
06/04/2022 06:41:00 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:41:00 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:41:00 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:41:01 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7432549801301802 on epoch=374
06/04/2022 06:41:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7261605271039233 -> 0.7432549801301802 on epoch=374, global_step=3000
06/04/2022 06:41:01 - INFO - __main__ - save last model!
06/04/2022 06:41:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 06:41:01 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 06:41:01 - INFO - __main__ - Printing 3 examples
06/04/2022 06:41:01 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 06:41:01 - INFO - __main__ - ['others']
06/04/2022 06:41:01 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 06:41:01 - INFO - __main__ - ['others']
06/04/2022 06:41:01 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 06:41:01 - INFO - __main__ - ['others']
06/04/2022 06:41:01 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:41:03 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:41:08 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 06:41:16 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:41:16 - INFO - __main__ - task name: emo
06/04/2022 06:41:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:41:17 - INFO - __main__ - Starting training!
06/04/2022 06:42:48 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_13_0.4_8_predictions.txt
06/04/2022 06:42:48 - INFO - __main__ - Classification-F1 on test data: 0.4390
06/04/2022 06:42:48 - INFO - __main__ - prefix=emo_32_13, lr=0.4, bsz=8, dev_performance=0.7432549801301802, test_performance=0.4389594693948657
06/04/2022 06:42:48 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.3, bsz=8 ...
06/04/2022 06:42:49 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:42:49 - INFO - __main__ - Printing 3 examples
06/04/2022 06:42:49 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:42:49 - INFO - __main__ - ['others']
06/04/2022 06:42:49 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:42:49 - INFO - __main__ - ['others']
06/04/2022 06:42:49 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:42:49 - INFO - __main__ - ['others']
06/04/2022 06:42:49 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:42:49 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:42:49 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:42:49 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:42:49 - INFO - __main__ - Printing 3 examples
06/04/2022 06:42:49 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:42:49 - INFO - __main__ - ['others']
06/04/2022 06:42:49 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:42:49 - INFO - __main__ - ['others']
06/04/2022 06:42:49 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:42:49 - INFO - __main__ - ['others']
06/04/2022 06:42:49 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:42:49 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:42:49 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:43:04 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:43:04 - INFO - __main__ - task name: emo
06/04/2022 06:43:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:43:05 - INFO - __main__ - Starting training!
06/04/2022 06:43:08 - INFO - __main__ - Step 10 Global step 10 Train loss 7.10 on epoch=1
06/04/2022 06:43:10 - INFO - __main__ - Step 20 Global step 20 Train loss 3.68 on epoch=2
06/04/2022 06:43:13 - INFO - __main__ - Step 30 Global step 30 Train loss 1.98 on epoch=3
06/04/2022 06:43:15 - INFO - __main__ - Step 40 Global step 40 Train loss 1.37 on epoch=4
06/04/2022 06:43:18 - INFO - __main__ - Step 50 Global step 50 Train loss 1.21 on epoch=6
06/04/2022 06:43:20 - INFO - __main__ - Global step 50 Train loss 3.07 Classification-F1 0.19092970521541952 on epoch=6
06/04/2022 06:43:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19092970521541952 on epoch=6, global_step=50
06/04/2022 06:43:22 - INFO - __main__ - Step 60 Global step 60 Train loss 1.21 on epoch=7
06/04/2022 06:43:25 - INFO - __main__ - Step 70 Global step 70 Train loss 1.04 on epoch=8
06/04/2022 06:43:27 - INFO - __main__ - Step 80 Global step 80 Train loss 1.04 on epoch=9
06/04/2022 06:43:30 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=11
06/04/2022 06:43:33 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=12
06/04/2022 06:43:34 - INFO - __main__ - Global step 100 Train loss 1.03 Classification-F1 0.20228170250109698 on epoch=12
06/04/2022 06:43:34 - INFO - __main__ - Saving model with best Classification-F1: 0.19092970521541952 -> 0.20228170250109698 on epoch=12, global_step=100
06/04/2022 06:43:37 - INFO - __main__ - Step 110 Global step 110 Train loss 0.93 on epoch=13
06/04/2022 06:43:39 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=14
06/04/2022 06:43:42 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=16
06/04/2022 06:43:44 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=17
06/04/2022 06:43:47 - INFO - __main__ - Step 150 Global step 150 Train loss 0.95 on epoch=18
06/04/2022 06:43:49 - INFO - __main__ - Global step 150 Train loss 0.90 Classification-F1 0.10982711555959963 on epoch=18
06/04/2022 06:43:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.88 on epoch=19
06/04/2022 06:43:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=21
06/04/2022 06:43:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=22
06/04/2022 06:43:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.97 on epoch=23
06/04/2022 06:44:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=24
06/04/2022 06:44:03 - INFO - __main__ - Global step 200 Train loss 0.90 Classification-F1 0.2557497972677937 on epoch=24
06/04/2022 06:44:03 - INFO - __main__ - Saving model with best Classification-F1: 0.20228170250109698 -> 0.2557497972677937 on epoch=24, global_step=200
06/04/2022 06:44:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=26
06/04/2022 06:44:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.86 on epoch=27
06/04/2022 06:44:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.86 on epoch=28
06/04/2022 06:44:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.86 on epoch=29
06/04/2022 06:44:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.90 on epoch=31
06/04/2022 06:44:18 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.26060756522524153 on epoch=31
06/04/2022 06:44:18 - INFO - __main__ - Saving model with best Classification-F1: 0.2557497972677937 -> 0.26060756522524153 on epoch=31, global_step=250
06/04/2022 06:44:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.80 on epoch=32
06/04/2022 06:44:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.84 on epoch=33
06/04/2022 06:44:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.78 on epoch=34
06/04/2022 06:44:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.79 on epoch=36
06/04/2022 06:44:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.78 on epoch=37
06/04/2022 06:44:32 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.24470551378446118 on epoch=37
06/04/2022 06:44:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=38
06/04/2022 06:44:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.75 on epoch=39
06/04/2022 06:44:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.84 on epoch=41
06/04/2022 06:44:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.81 on epoch=42
06/04/2022 06:44:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.85 on epoch=43
06/04/2022 06:44:47 - INFO - __main__ - Global step 350 Train loss 0.81 Classification-F1 0.4309707464822855 on epoch=43
06/04/2022 06:44:47 - INFO - __main__ - Saving model with best Classification-F1: 0.26060756522524153 -> 0.4309707464822855 on epoch=43, global_step=350
06/04/2022 06:44:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.80 on epoch=44
06/04/2022 06:44:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.68 on epoch=46
06/04/2022 06:44:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.76 on epoch=47
06/04/2022 06:44:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.73 on epoch=48
06/04/2022 06:44:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.72 on epoch=49
06/04/2022 06:45:01 - INFO - __main__ - Global step 400 Train loss 0.74 Classification-F1 0.48473646236804135 on epoch=49
06/04/2022 06:45:01 - INFO - __main__ - Saving model with best Classification-F1: 0.4309707464822855 -> 0.48473646236804135 on epoch=49, global_step=400
06/04/2022 06:45:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.65 on epoch=51
06/04/2022 06:45:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.65 on epoch=52
06/04/2022 06:45:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.61 on epoch=53
06/04/2022 06:45:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.59 on epoch=54
06/04/2022 06:45:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.58 on epoch=56
06/04/2022 06:45:16 - INFO - __main__ - Global step 450 Train loss 0.62 Classification-F1 0.4080709586466166 on epoch=56
06/04/2022 06:45:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.58 on epoch=57
06/04/2022 06:45:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.58 on epoch=58
06/04/2022 06:45:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.50 on epoch=59
06/04/2022 06:45:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=61
06/04/2022 06:45:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.57 on epoch=62
06/04/2022 06:45:30 - INFO - __main__ - Global step 500 Train loss 0.54 Classification-F1 0.5809303187546331 on epoch=62
06/04/2022 06:45:30 - INFO - __main__ - Saving model with best Classification-F1: 0.48473646236804135 -> 0.5809303187546331 on epoch=62, global_step=500
06/04/2022 06:45:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=63
06/04/2022 06:45:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=64
06/04/2022 06:45:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=66
06/04/2022 06:45:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=67
06/04/2022 06:45:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.58 on epoch=68
06/04/2022 06:45:45 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.48267084208153915 on epoch=68
06/04/2022 06:45:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.44 on epoch=69
06/04/2022 06:45:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=71
06/04/2022 06:45:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=72
06/04/2022 06:45:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.40 on epoch=73
06/04/2022 06:45:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=74
06/04/2022 06:45:59 - INFO - __main__ - Global step 600 Train loss 0.40 Classification-F1 0.6046454865556978 on epoch=74
06/04/2022 06:45:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5809303187546331 -> 0.6046454865556978 on epoch=74, global_step=600
06/04/2022 06:46:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=76
06/04/2022 06:46:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=77
06/04/2022 06:46:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.38 on epoch=78
06/04/2022 06:46:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=79
06/04/2022 06:46:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.38 on epoch=81
06/04/2022 06:46:14 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.5731970754403456 on epoch=81
06/04/2022 06:46:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.37 on epoch=82
06/04/2022 06:46:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.38 on epoch=83
06/04/2022 06:46:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=84
06/04/2022 06:46:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=86
06/04/2022 06:46:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=87
06/04/2022 06:46:29 - INFO - __main__ - Global step 700 Train loss 0.32 Classification-F1 0.5973103589067126 on epoch=87
06/04/2022 06:46:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=88
06/04/2022 06:46:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=89
06/04/2022 06:46:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=91
06/04/2022 06:46:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=92
06/04/2022 06:46:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.25 on epoch=93
06/04/2022 06:46:44 - INFO - __main__ - Global step 750 Train loss 0.31 Classification-F1 0.6242989590447218 on epoch=93
06/04/2022 06:46:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6046454865556978 -> 0.6242989590447218 on epoch=93, global_step=750
06/04/2022 06:46:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=94
06/04/2022 06:46:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=96
06/04/2022 06:46:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=97
06/04/2022 06:46:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.37 on epoch=98
06/04/2022 06:46:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=99
06/04/2022 06:46:58 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.7057406030385209 on epoch=99
06/04/2022 06:46:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6242989590447218 -> 0.7057406030385209 on epoch=99, global_step=800
06/04/2022 06:47:01 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=101
06/04/2022 06:47:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=102
06/04/2022 06:47:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=103
06/04/2022 06:47:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=104
06/04/2022 06:47:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=106
06/04/2022 06:47:13 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.6799676018426019 on epoch=106
06/04/2022 06:47:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.26 on epoch=107
06/04/2022 06:47:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=108
06/04/2022 06:47:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=109
06/04/2022 06:47:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=111
06/04/2022 06:47:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.28 on epoch=112
06/04/2022 06:47:27 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.7053691168292188 on epoch=112
06/04/2022 06:47:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=113
06/04/2022 06:47:32 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=114
06/04/2022 06:47:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=116
06/04/2022 06:47:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=117
06/04/2022 06:47:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=118
06/04/2022 06:47:42 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6342592592592593 on epoch=118
06/04/2022 06:47:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=119
06/04/2022 06:47:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=121
06/04/2022 06:47:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=122
06/04/2022 06:47:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=123
06/04/2022 06:47:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=124
06/04/2022 06:47:56 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.6771075329114262 on epoch=124
06/04/2022 06:47:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=126
06/04/2022 06:48:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=127
06/04/2022 06:48:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=128
06/04/2022 06:48:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=129
06/04/2022 06:48:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=131
06/04/2022 06:48:11 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.733310588114121 on epoch=131
06/04/2022 06:48:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7057406030385209 -> 0.733310588114121 on epoch=131, global_step=1050
06/04/2022 06:48:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=132
06/04/2022 06:48:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=133
06/04/2022 06:48:18 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=134
06/04/2022 06:48:21 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=136
06/04/2022 06:48:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=137
06/04/2022 06:48:25 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.7437693087006588 on epoch=137
06/04/2022 06:48:25 - INFO - __main__ - Saving model with best Classification-F1: 0.733310588114121 -> 0.7437693087006588 on epoch=137, global_step=1100
06/04/2022 06:48:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=138
06/04/2022 06:48:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=139
06/04/2022 06:48:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=141
06/04/2022 06:48:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=142
06/04/2022 06:48:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=143
06/04/2022 06:48:40 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6922500347933276 on epoch=143
06/04/2022 06:48:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.20 on epoch=144
06/04/2022 06:48:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=146
06/04/2022 06:48:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=147
06/04/2022 06:48:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=148
06/04/2022 06:48:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=149
06/04/2022 06:48:54 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.6327193798177586 on epoch=149
06/04/2022 06:48:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=151
06/04/2022 06:48:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=152
06/04/2022 06:49:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=153
06/04/2022 06:49:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=154
06/04/2022 06:49:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=156
06/04/2022 06:49:08 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7244237018430567 on epoch=156
06/04/2022 06:49:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=157
06/04/2022 06:49:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=158
06/04/2022 06:49:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=159
06/04/2022 06:49:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=161
06/04/2022 06:49:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=162
06/04/2022 06:49:23 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6813736263736263 on epoch=162
06/04/2022 06:49:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=163
06/04/2022 06:49:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=164
06/04/2022 06:49:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=166
06/04/2022 06:49:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=167
06/04/2022 06:49:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=168
06/04/2022 06:49:37 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7036169659120479 on epoch=168
06/04/2022 06:49:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=169
06/04/2022 06:49:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=171
06/04/2022 06:49:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=172
06/04/2022 06:49:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=173
06/04/2022 06:49:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=174
06/04/2022 06:49:53 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7015588851937536 on epoch=174
06/04/2022 06:49:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=176
06/04/2022 06:49:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=177
06/04/2022 06:50:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=178
06/04/2022 06:50:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=179
06/04/2022 06:50:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=181
06/04/2022 06:50:07 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7080936594915886 on epoch=181
06/04/2022 06:50:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=182
06/04/2022 06:50:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=183
06/04/2022 06:50:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=184
06/04/2022 06:50:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=186
06/04/2022 06:50:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=187
06/04/2022 06:50:22 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.6978389077156586 on epoch=187
06/04/2022 06:50:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=188
06/04/2022 06:50:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=189
06/04/2022 06:50:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=191
06/04/2022 06:50:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=192
06/04/2022 06:50:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=193
06/04/2022 06:50:36 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.6714313081554462 on epoch=193
06/04/2022 06:50:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=194
06/04/2022 06:50:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.16 on epoch=196
06/04/2022 06:50:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=197
06/04/2022 06:50:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/04/2022 06:50:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=199
06/04/2022 06:50:50 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7018880138094725 on epoch=199
06/04/2022 06:50:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=201
06/04/2022 06:50:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=202
06/04/2022 06:50:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=203
06/04/2022 06:51:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=204
06/04/2022 06:51:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
06/04/2022 06:51:04 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7182118956312503 on epoch=206
06/04/2022 06:51:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=207
06/04/2022 06:51:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
06/04/2022 06:51:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=209
06/04/2022 06:51:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
06/04/2022 06:51:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
06/04/2022 06:51:19 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7090997986770203 on epoch=212
06/04/2022 06:51:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
06/04/2022 06:51:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
06/04/2022 06:51:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=216
06/04/2022 06:51:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=217
06/04/2022 06:51:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
06/04/2022 06:51:34 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7058667846019289 on epoch=218
06/04/2022 06:51:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=219
06/04/2022 06:51:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
06/04/2022 06:51:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=222
06/04/2022 06:51:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=223
06/04/2022 06:51:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=224
06/04/2022 06:51:49 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7069092885816236 on epoch=224
06/04/2022 06:51:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=226
06/04/2022 06:51:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=227
06/04/2022 06:51:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=228
06/04/2022 06:51:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=229
06/04/2022 06:52:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
06/04/2022 06:52:03 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6997461602724762 on epoch=231
06/04/2022 06:52:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=232
06/04/2022 06:52:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=233
06/04/2022 06:52:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
06/04/2022 06:52:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=236
06/04/2022 06:52:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=237
06/04/2022 06:52:18 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7010969454396178 on epoch=237
06/04/2022 06:52:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=238
06/04/2022 06:52:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=239
06/04/2022 06:52:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=241
06/04/2022 06:52:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=242
06/04/2022 06:52:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
06/04/2022 06:52:33 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7364483342744212 on epoch=243
06/04/2022 06:52:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
06/04/2022 06:52:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=246
06/04/2022 06:52:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
06/04/2022 06:52:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=248
06/04/2022 06:52:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
06/04/2022 06:52:47 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7085616438356164 on epoch=249
06/04/2022 06:52:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
06/04/2022 06:52:52 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
06/04/2022 06:52:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=253
06/04/2022 06:52:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
06/04/2022 06:52:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=256
06/04/2022 06:53:01 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7321951575723128 on epoch=256
06/04/2022 06:53:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
06/04/2022 06:53:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=258
06/04/2022 06:53:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
06/04/2022 06:53:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
06/04/2022 06:53:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 06:53:16 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7245821128638165 on epoch=262
06/04/2022 06:53:18 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
06/04/2022 06:53:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
06/04/2022 06:53:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=266
06/04/2022 06:53:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=267
06/04/2022 06:53:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=268
06/04/2022 06:53:30 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7234651237544197 on epoch=268
06/04/2022 06:53:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=269
06/04/2022 06:53:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 06:53:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/04/2022 06:53:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=273
06/04/2022 06:53:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
06/04/2022 06:53:45 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7073650034176351 on epoch=274
06/04/2022 06:53:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=276
06/04/2022 06:53:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=277
06/04/2022 06:53:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/04/2022 06:53:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
06/04/2022 06:53:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=281
06/04/2022 06:53:59 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7312331471494607 on epoch=281
06/04/2022 06:54:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=282
06/04/2022 06:54:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=283
06/04/2022 06:54:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
06/04/2022 06:54:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=286
06/04/2022 06:54:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/04/2022 06:54:13 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7246342886535087 on epoch=287
06/04/2022 06:54:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=288
06/04/2022 06:54:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
06/04/2022 06:54:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/04/2022 06:54:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
06/04/2022 06:54:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
06/04/2022 06:54:28 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7246725642563355 on epoch=293
06/04/2022 06:54:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
06/04/2022 06:54:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/04/2022 06:54:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/04/2022 06:54:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/04/2022 06:54:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/04/2022 06:54:43 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7098576861734758 on epoch=299
06/04/2022 06:54:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=301
06/04/2022 06:54:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=302
06/04/2022 06:54:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/04/2022 06:54:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
06/04/2022 06:54:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
06/04/2022 06:54:58 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7171219585012689 on epoch=306
06/04/2022 06:55:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
06/04/2022 06:55:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/04/2022 06:55:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
06/04/2022 06:55:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=311
06/04/2022 06:55:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
06/04/2022 06:55:12 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7120082815734989 on epoch=312
06/04/2022 06:55:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/04/2022 06:55:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 06:55:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=316
06/04/2022 06:55:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
06/04/2022 06:55:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
06/04/2022 06:55:27 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7082064993829701 on epoch=318
06/04/2022 06:55:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
06/04/2022 06:55:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=321
06/04/2022 06:55:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 06:55:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
06/04/2022 06:55:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
06/04/2022 06:55:42 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.715998451652102 on epoch=324
06/04/2022 06:55:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=326
06/04/2022 06:55:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 06:55:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=328
06/04/2022 06:55:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
06/04/2022 06:55:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=331
06/04/2022 06:55:57 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6928648233486943 on epoch=331
06/04/2022 06:56:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=332
06/04/2022 06:56:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/04/2022 06:56:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/04/2022 06:56:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=336
06/04/2022 06:56:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/04/2022 06:56:12 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7114136622390891 on epoch=337
06/04/2022 06:56:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 06:56:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=339
06/04/2022 06:56:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/04/2022 06:56:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
06/04/2022 06:56:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/04/2022 06:56:28 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7230083405234398 on epoch=343
06/04/2022 06:56:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
06/04/2022 06:56:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
06/04/2022 06:56:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
06/04/2022 06:56:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/04/2022 06:56:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=349
06/04/2022 06:56:43 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7266582752766231 on epoch=349
06/04/2022 06:56:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
06/04/2022 06:56:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/04/2022 06:56:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=353
06/04/2022 06:56:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 06:56:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 06:56:58 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7319932184750733 on epoch=356
06/04/2022 06:57:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=357
06/04/2022 06:57:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
06/04/2022 06:57:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 06:57:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=361
06/04/2022 06:57:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=362
06/04/2022 06:57:13 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7325777582159624 on epoch=362
06/04/2022 06:57:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
06/04/2022 06:57:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 06:57:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
06/04/2022 06:57:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 06:57:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 06:57:28 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7654723748473748 on epoch=368
06/04/2022 06:57:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7437693087006588 -> 0.7654723748473748 on epoch=368, global_step=2950
06/04/2022 06:57:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 06:57:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
06/04/2022 06:57:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 06:57:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
06/04/2022 06:57:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 06:57:43 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:57:43 - INFO - __main__ - Printing 3 examples
06/04/2022 06:57:43 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:57:43 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:57:43 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:57:43 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:57:43 - INFO - __main__ - Printing 3 examples
06/04/2022 06:57:43 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:57:43 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:57:43 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:57:43 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7494523450405803 on epoch=374
06/04/2022 06:57:43 - INFO - __main__ - save last model!
06/04/2022 06:57:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 06:57:43 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 06:57:43 - INFO - __main__ - Printing 3 examples
06/04/2022 06:57:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 06:57:43 - INFO - __main__ - ['others']
06/04/2022 06:57:43 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:57:45 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:57:51 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 06:57:59 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:57:59 - INFO - __main__ - task name: emo
06/04/2022 06:57:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:57:59 - INFO - __main__ - Starting training!
06/04/2022 06:59:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_13_0.3_8_predictions.txt
06/04/2022 06:59:15 - INFO - __main__ - Classification-F1 on test data: 0.5054
06/04/2022 06:59:15 - INFO - __main__ - prefix=emo_32_13, lr=0.3, bsz=8, dev_performance=0.7654723748473748, test_performance=0.505407379531743
06/04/2022 06:59:15 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.2, bsz=8 ...
06/04/2022 06:59:16 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:59:16 - INFO - __main__ - Printing 3 examples
06/04/2022 06:59:16 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/04/2022 06:59:16 - INFO - __main__ - ['others']
06/04/2022 06:59:16 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/04/2022 06:59:16 - INFO - __main__ - ['others']
06/04/2022 06:59:16 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/04/2022 06:59:16 - INFO - __main__ - ['others']
06/04/2022 06:59:16 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:59:16 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:59:16 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 06:59:16 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 06:59:16 - INFO - __main__ - Printing 3 examples
06/04/2022 06:59:16 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
06/04/2022 06:59:16 - INFO - __main__ - ['others']
06/04/2022 06:59:16 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
06/04/2022 06:59:16 - INFO - __main__ - ['others']
06/04/2022 06:59:16 - INFO - __main__ -  [emo] u oly first  no you no u
06/04/2022 06:59:16 - INFO - __main__ - ['others']
06/04/2022 06:59:16 - INFO - __main__ - Tokenizing Input ...
06/04/2022 06:59:16 - INFO - __main__ - Tokenizing Output ...
06/04/2022 06:59:17 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 06:59:31 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 06:59:31 - INFO - __main__ - task name: emo
06/04/2022 06:59:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 06:59:32 - INFO - __main__ - Starting training!
06/04/2022 06:59:35 - INFO - __main__ - Step 10 Global step 10 Train loss 7.71 on epoch=1
06/04/2022 06:59:37 - INFO - __main__ - Step 20 Global step 20 Train loss 6.02 on epoch=2
06/04/2022 06:59:40 - INFO - __main__ - Step 30 Global step 30 Train loss 3.58 on epoch=3
06/04/2022 06:59:42 - INFO - __main__ - Step 40 Global step 40 Train loss 2.32 on epoch=4
06/04/2022 06:59:45 - INFO - __main__ - Step 50 Global step 50 Train loss 1.66 on epoch=6
06/04/2022 06:59:47 - INFO - __main__ - Global step 50 Train loss 4.26 Classification-F1 0.12039473684210528 on epoch=6
06/04/2022 06:59:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12039473684210528 on epoch=6, global_step=50
06/04/2022 06:59:50 - INFO - __main__ - Step 60 Global step 60 Train loss 1.38 on epoch=7
06/04/2022 06:59:52 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=8
06/04/2022 06:59:55 - INFO - __main__ - Step 80 Global step 80 Train loss 1.07 on epoch=9
06/04/2022 06:59:57 - INFO - __main__ - Step 90 Global step 90 Train loss 1.12 on epoch=11
06/04/2022 07:00:00 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=12
06/04/2022 07:00:01 - INFO - __main__ - Global step 100 Train loss 1.16 Classification-F1 0.11578044596912522 on epoch=12
06/04/2022 07:00:04 - INFO - __main__ - Step 110 Global step 110 Train loss 1.02 on epoch=13
06/04/2022 07:00:06 - INFO - __main__ - Step 120 Global step 120 Train loss 1.07 on epoch=14
06/04/2022 07:00:09 - INFO - __main__ - Step 130 Global step 130 Train loss 1.14 on epoch=16
06/04/2022 07:00:11 - INFO - __main__ - Step 140 Global step 140 Train loss 0.95 on epoch=17
06/04/2022 07:00:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.95 on epoch=18
06/04/2022 07:00:16 - INFO - __main__ - Global step 150 Train loss 1.03 Classification-F1 0.17491705374917055 on epoch=18
06/04/2022 07:00:16 - INFO - __main__ - Saving model with best Classification-F1: 0.12039473684210528 -> 0.17491705374917055 on epoch=18, global_step=150
06/04/2022 07:00:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.95 on epoch=19
06/04/2022 07:00:21 - INFO - __main__ - Step 170 Global step 170 Train loss 1.09 on epoch=21
06/04/2022 07:00:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.92 on epoch=22
06/04/2022 07:00:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.98 on epoch=23
06/04/2022 07:00:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=24
06/04/2022 07:00:30 - INFO - __main__ - Global step 200 Train loss 0.98 Classification-F1 0.1897412468880767 on epoch=24
06/04/2022 07:00:30 - INFO - __main__ - Saving model with best Classification-F1: 0.17491705374917055 -> 0.1897412468880767 on epoch=24, global_step=200
06/04/2022 07:00:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.95 on epoch=26
06/04/2022 07:00:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.88 on epoch=27
06/04/2022 07:00:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.86 on epoch=28
06/04/2022 07:00:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=29
06/04/2022 07:00:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.91 on epoch=31
06/04/2022 07:00:45 - INFO - __main__ - Global step 250 Train loss 0.89 Classification-F1 0.1411898911898912 on epoch=31
06/04/2022 07:00:47 - INFO - __main__ - Step 260 Global step 260 Train loss 0.80 on epoch=32
06/04/2022 07:00:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.94 on epoch=33
06/04/2022 07:00:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.88 on epoch=34
06/04/2022 07:00:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.85 on epoch=36
06/04/2022 07:00:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.86 on epoch=37
06/04/2022 07:00:59 - INFO - __main__ - Global step 300 Train loss 0.87 Classification-F1 0.16277641277641278 on epoch=37
06/04/2022 07:01:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.84 on epoch=38
06/04/2022 07:01:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.92 on epoch=39
06/04/2022 07:01:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.88 on epoch=41
06/04/2022 07:01:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.86 on epoch=42
06/04/2022 07:01:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.88 on epoch=43
06/04/2022 07:01:14 - INFO - __main__ - Global step 350 Train loss 0.87 Classification-F1 0.1 on epoch=43
06/04/2022 07:01:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.86 on epoch=44
06/04/2022 07:01:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.81 on epoch=46
06/04/2022 07:01:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.81 on epoch=47
06/04/2022 07:01:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.90 on epoch=48
06/04/2022 07:01:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.83 on epoch=49
06/04/2022 07:01:28 - INFO - __main__ - Global step 400 Train loss 0.84 Classification-F1 0.24544846050870145 on epoch=49
06/04/2022 07:01:28 - INFO - __main__ - Saving model with best Classification-F1: 0.1897412468880767 -> 0.24544846050870145 on epoch=49, global_step=400
06/04/2022 07:01:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.79 on epoch=51
06/04/2022 07:01:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.78 on epoch=52
06/04/2022 07:01:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.89 on epoch=53
06/04/2022 07:01:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.93 on epoch=54
06/04/2022 07:01:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.80 on epoch=56
06/04/2022 07:01:43 - INFO - __main__ - Global step 450 Train loss 0.84 Classification-F1 0.1 on epoch=56
06/04/2022 07:01:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.86 on epoch=57
06/04/2022 07:01:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.82 on epoch=58
06/04/2022 07:01:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.71 on epoch=59
06/04/2022 07:01:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.72 on epoch=61
06/04/2022 07:01:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.85 on epoch=62
06/04/2022 07:01:57 - INFO - __main__ - Global step 500 Train loss 0.79 Classification-F1 0.1581196581196581 on epoch=62
06/04/2022 07:02:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.83 on epoch=63
06/04/2022 07:02:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.85 on epoch=64
06/04/2022 07:02:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.86 on epoch=66
06/04/2022 07:02:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.85 on epoch=67
06/04/2022 07:02:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.88 on epoch=68
06/04/2022 07:02:12 - INFO - __main__ - Global step 550 Train loss 0.86 Classification-F1 0.21493394229782767 on epoch=68
06/04/2022 07:02:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.82 on epoch=69
06/04/2022 07:02:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.76 on epoch=71
06/04/2022 07:02:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.90 on epoch=72
06/04/2022 07:02:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.81 on epoch=73
06/04/2022 07:02:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.84 on epoch=74
06/04/2022 07:02:26 - INFO - __main__ - Global step 600 Train loss 0.82 Classification-F1 0.2832080200501253 on epoch=74
06/04/2022 07:02:26 - INFO - __main__ - Saving model with best Classification-F1: 0.24544846050870145 -> 0.2832080200501253 on epoch=74, global_step=600
06/04/2022 07:02:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.79 on epoch=76
06/04/2022 07:02:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.76 on epoch=77
06/04/2022 07:02:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.84 on epoch=78
06/04/2022 07:02:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.81 on epoch=79
06/04/2022 07:02:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.77 on epoch=81
06/04/2022 07:02:41 - INFO - __main__ - Global step 650 Train loss 0.79 Classification-F1 0.13226621049201695 on epoch=81
06/04/2022 07:02:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.75 on epoch=82
06/04/2022 07:02:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.78 on epoch=83
06/04/2022 07:02:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.73 on epoch=84
06/04/2022 07:02:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.77 on epoch=86
06/04/2022 07:02:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.80 on epoch=87
06/04/2022 07:02:55 - INFO - __main__ - Global step 700 Train loss 0.77 Classification-F1 0.1304822565969063 on epoch=87
06/04/2022 07:02:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.80 on epoch=88
06/04/2022 07:03:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.79 on epoch=89
06/04/2022 07:03:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.77 on epoch=91
06/04/2022 07:03:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.70 on epoch=92
06/04/2022 07:03:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.71 on epoch=93
06/04/2022 07:03:10 - INFO - __main__ - Global step 750 Train loss 0.75 Classification-F1 0.37011596788581624 on epoch=93
06/04/2022 07:03:10 - INFO - __main__ - Saving model with best Classification-F1: 0.2832080200501253 -> 0.37011596788581624 on epoch=93, global_step=750
06/04/2022 07:03:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.71 on epoch=94
06/04/2022 07:03:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.69 on epoch=96
06/04/2022 07:03:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.67 on epoch=97
06/04/2022 07:03:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.64 on epoch=98
06/04/2022 07:03:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.57 on epoch=99
06/04/2022 07:03:24 - INFO - __main__ - Global step 800 Train loss 0.65 Classification-F1 0.47942932343277467 on epoch=99
06/04/2022 07:03:24 - INFO - __main__ - Saving model with best Classification-F1: 0.37011596788581624 -> 0.47942932343277467 on epoch=99, global_step=800
06/04/2022 07:03:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.67 on epoch=101
06/04/2022 07:03:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.65 on epoch=102
06/04/2022 07:03:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.65 on epoch=103
06/04/2022 07:03:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.61 on epoch=104
06/04/2022 07:03:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.64 on epoch=106
06/04/2022 07:03:39 - INFO - __main__ - Global step 850 Train loss 0.64 Classification-F1 0.4160453557005281 on epoch=106
06/04/2022 07:03:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.57 on epoch=107
06/04/2022 07:03:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.57 on epoch=108
06/04/2022 07:03:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.59 on epoch=109
06/04/2022 07:03:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.52 on epoch=111
06/04/2022 07:03:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.57 on epoch=112
06/04/2022 07:03:54 - INFO - __main__ - Global step 900 Train loss 0.56 Classification-F1 0.38922149621136615 on epoch=112
06/04/2022 07:03:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.49 on epoch=113
06/04/2022 07:03:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.51 on epoch=114
06/04/2022 07:04:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.59 on epoch=116
06/04/2022 07:04:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.43 on epoch=117
06/04/2022 07:04:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.53 on epoch=118
06/04/2022 07:04:09 - INFO - __main__ - Global step 950 Train loss 0.51 Classification-F1 0.5655514024432586 on epoch=118
06/04/2022 07:04:09 - INFO - __main__ - Saving model with best Classification-F1: 0.47942932343277467 -> 0.5655514024432586 on epoch=118, global_step=950
06/04/2022 07:04:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.40 on epoch=119
06/04/2022 07:04:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.44 on epoch=121
06/04/2022 07:04:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.39 on epoch=122
06/04/2022 07:04:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.47 on epoch=123
06/04/2022 07:04:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.41 on epoch=124
06/04/2022 07:04:23 - INFO - __main__ - Global step 1000 Train loss 0.42 Classification-F1 0.6047762240204344 on epoch=124
06/04/2022 07:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5655514024432586 -> 0.6047762240204344 on epoch=124, global_step=1000
06/04/2022 07:04:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.38 on epoch=126
06/04/2022 07:04:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.34 on epoch=127
06/04/2022 07:04:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.44 on epoch=128
06/04/2022 07:04:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.43 on epoch=129
06/04/2022 07:04:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.38 on epoch=131
06/04/2022 07:04:38 - INFO - __main__ - Global step 1050 Train loss 0.39 Classification-F1 0.6087912333883325 on epoch=131
06/04/2022 07:04:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6047762240204344 -> 0.6087912333883325 on epoch=131, global_step=1050
06/04/2022 07:04:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.35 on epoch=132
06/04/2022 07:04:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.44 on epoch=133
06/04/2022 07:04:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.38 on epoch=134
06/04/2022 07:04:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.45 on epoch=136
06/04/2022 07:04:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.43 on epoch=137
06/04/2022 07:04:52 - INFO - __main__ - Global step 1100 Train loss 0.41 Classification-F1 0.6228991596638656 on epoch=137
06/04/2022 07:04:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6087912333883325 -> 0.6228991596638656 on epoch=137, global_step=1100
06/04/2022 07:04:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.41 on epoch=138
06/04/2022 07:04:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.31 on epoch=139
06/04/2022 07:05:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.34 on epoch=141
06/04/2022 07:05:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.41 on epoch=142
06/04/2022 07:05:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=143
06/04/2022 07:05:07 - INFO - __main__ - Global step 1150 Train loss 0.36 Classification-F1 0.5406737142031259 on epoch=143
06/04/2022 07:05:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.38 on epoch=144
06/04/2022 07:05:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.36 on epoch=146
06/04/2022 07:05:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.30 on epoch=147
06/04/2022 07:05:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.30 on epoch=148
06/04/2022 07:05:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.29 on epoch=149
06/04/2022 07:05:21 - INFO - __main__ - Global step 1200 Train loss 0.32 Classification-F1 0.6261155511155512 on epoch=149
06/04/2022 07:05:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6228991596638656 -> 0.6261155511155512 on epoch=149, global_step=1200
06/04/2022 07:05:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.32 on epoch=151
06/04/2022 07:05:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.24 on epoch=152
06/04/2022 07:05:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.30 on epoch=153
06/04/2022 07:05:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.28 on epoch=154
06/04/2022 07:05:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=156
06/04/2022 07:05:36 - INFO - __main__ - Global step 1250 Train loss 0.28 Classification-F1 0.6861433835990856 on epoch=156
06/04/2022 07:05:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6261155511155512 -> 0.6861433835990856 on epoch=156, global_step=1250
06/04/2022 07:05:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.23 on epoch=157
06/04/2022 07:05:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.35 on epoch=158
06/04/2022 07:05:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.25 on epoch=159
06/04/2022 07:05:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=161
06/04/2022 07:05:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=162
06/04/2022 07:05:51 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.6236893413082085 on epoch=162
06/04/2022 07:05:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.30 on epoch=163
06/04/2022 07:05:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=164
06/04/2022 07:05:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.25 on epoch=166
06/04/2022 07:06:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.29 on epoch=167
06/04/2022 07:06:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.27 on epoch=168
06/04/2022 07:06:05 - INFO - __main__ - Global step 1350 Train loss 0.26 Classification-F1 0.6541305550433338 on epoch=168
06/04/2022 07:06:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.19 on epoch=169
06/04/2022 07:06:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.27 on epoch=171
06/04/2022 07:06:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=172
06/04/2022 07:06:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.33 on epoch=173
06/04/2022 07:06:18 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.25 on epoch=174
06/04/2022 07:06:20 - INFO - __main__ - Global step 1400 Train loss 0.25 Classification-F1 0.6728387699600419 on epoch=174
06/04/2022 07:06:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.22 on epoch=176
06/04/2022 07:06:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=177
06/04/2022 07:06:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.23 on epoch=178
06/04/2022 07:06:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.19 on epoch=179
06/04/2022 07:06:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=181
06/04/2022 07:06:35 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.6765929307765823 on epoch=181
06/04/2022 07:06:37 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.19 on epoch=182
06/04/2022 07:06:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.24 on epoch=183
06/04/2022 07:06:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=184
06/04/2022 07:06:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=186
06/04/2022 07:06:47 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=187
06/04/2022 07:06:49 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.6611929753426662 on epoch=187
06/04/2022 07:06:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.24 on epoch=188
06/04/2022 07:06:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=189
06/04/2022 07:06:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=191
06/04/2022 07:06:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.22 on epoch=192
06/04/2022 07:07:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.24 on epoch=193
06/04/2022 07:07:04 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.6685163405234974 on epoch=193
06/04/2022 07:07:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.23 on epoch=194
06/04/2022 07:07:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=196
06/04/2022 07:07:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.20 on epoch=197
06/04/2022 07:07:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=198
06/04/2022 07:07:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.18 on epoch=199
06/04/2022 07:07:18 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.684695540381427 on epoch=199
06/04/2022 07:07:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.19 on epoch=201
06/04/2022 07:07:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=202
06/04/2022 07:07:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=203
06/04/2022 07:07:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=204
06/04/2022 07:07:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=206
06/04/2022 07:07:32 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.7020301701552766 on epoch=206
06/04/2022 07:07:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6861433835990856 -> 0.7020301701552766 on epoch=206, global_step=1650
06/04/2022 07:07:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=207
06/04/2022 07:07:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=208
06/04/2022 07:07:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=209
06/04/2022 07:07:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=211
06/04/2022 07:07:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=212
06/04/2022 07:07:47 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.6692159340756652 on epoch=212
06/04/2022 07:07:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=213
06/04/2022 07:07:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=214
06/04/2022 07:07:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=216
06/04/2022 07:07:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=217
06/04/2022 07:08:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=218
06/04/2022 07:08:02 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.6749775717703349 on epoch=218
06/04/2022 07:08:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=219
06/04/2022 07:08:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=221
06/04/2022 07:08:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=222
06/04/2022 07:08:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=223
06/04/2022 07:08:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=224
06/04/2022 07:08:16 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.6685231702725439 on epoch=224
06/04/2022 07:08:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=226
06/04/2022 07:08:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=227
06/04/2022 07:08:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=228
06/04/2022 07:08:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=229
06/04/2022 07:08:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=231
06/04/2022 07:08:31 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.7126262545033453 on epoch=231
06/04/2022 07:08:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7020301701552766 -> 0.7126262545033453 on epoch=231, global_step=1850
06/04/2022 07:08:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=232
06/04/2022 07:08:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.14 on epoch=233
06/04/2022 07:08:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=234
06/04/2022 07:08:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/04/2022 07:08:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.14 on epoch=237
06/04/2022 07:08:46 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.6956295374367135 on epoch=237
06/04/2022 07:08:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=238
06/04/2022 07:08:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=239
06/04/2022 07:08:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=241
06/04/2022 07:08:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=242
06/04/2022 07:08:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/04/2022 07:09:01 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.696470271724509 on epoch=243
06/04/2022 07:09:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=244
06/04/2022 07:09:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=246
06/04/2022 07:09:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=247
06/04/2022 07:09:11 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=248
06/04/2022 07:09:14 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=249
06/04/2022 07:09:16 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7047800154806599 on epoch=249
06/04/2022 07:09:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
06/04/2022 07:09:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=252
06/04/2022 07:09:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.16 on epoch=253
06/04/2022 07:09:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=254
06/04/2022 07:09:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
06/04/2022 07:09:30 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6938650659987621 on epoch=256
06/04/2022 07:09:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
06/04/2022 07:09:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
06/04/2022 07:09:38 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
06/04/2022 07:09:41 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=261
06/04/2022 07:09:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=262
06/04/2022 07:09:45 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6832298136645962 on epoch=262
06/04/2022 07:09:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=263
06/04/2022 07:09:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=264
06/04/2022 07:09:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=266
06/04/2022 07:09:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=267
06/04/2022 07:09:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=268
06/04/2022 07:10:00 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6815117050008168 on epoch=268
06/04/2022 07:10:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
06/04/2022 07:10:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/04/2022 07:10:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/04/2022 07:10:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=273
06/04/2022 07:10:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
06/04/2022 07:10:15 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6866129032258066 on epoch=274
06/04/2022 07:10:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=276
06/04/2022 07:10:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=277
06/04/2022 07:10:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
06/04/2022 07:10:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/04/2022 07:10:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=281
06/04/2022 07:10:30 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.696417470501818 on epoch=281
06/04/2022 07:10:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=282
06/04/2022 07:10:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=283
06/04/2022 07:10:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/04/2022 07:10:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=286
06/04/2022 07:10:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=287
06/04/2022 07:10:45 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.6800545133878467 on epoch=287
06/04/2022 07:10:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=288
06/04/2022 07:10:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=289
06/04/2022 07:10:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
06/04/2022 07:10:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
06/04/2022 07:10:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=293
06/04/2022 07:10:59 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6827073552425664 on epoch=293
06/04/2022 07:11:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=294
06/04/2022 07:11:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=296
06/04/2022 07:11:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=297
06/04/2022 07:11:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
06/04/2022 07:11:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=299
06/04/2022 07:11:14 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6921546546546546 on epoch=299
06/04/2022 07:11:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=301
06/04/2022 07:11:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/04/2022 07:11:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=303
06/04/2022 07:11:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
06/04/2022 07:11:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/04/2022 07:11:29 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6880537823758163 on epoch=306
06/04/2022 07:11:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
06/04/2022 07:11:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/04/2022 07:11:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
06/04/2022 07:11:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=311
06/04/2022 07:11:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/04/2022 07:11:43 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6887300311708553 on epoch=312
06/04/2022 07:11:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/04/2022 07:11:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 07:11:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=316
06/04/2022 07:11:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/04/2022 07:11:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
06/04/2022 07:11:57 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6664031463530907 on epoch=318
06/04/2022 07:12:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/04/2022 07:12:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=321
06/04/2022 07:12:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 07:12:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=323
06/04/2022 07:12:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/04/2022 07:12:13 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.705663081338729 on epoch=324
06/04/2022 07:12:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
06/04/2022 07:12:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.11 on epoch=327
06/04/2022 07:12:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=328
06/04/2022 07:12:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/04/2022 07:12:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=331
06/04/2022 07:12:27 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6647907647907647 on epoch=331
06/04/2022 07:12:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=332
06/04/2022 07:12:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/04/2022 07:12:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/04/2022 07:12:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/04/2022 07:12:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=337
06/04/2022 07:12:42 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6769712682720284 on epoch=337
06/04/2022 07:12:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
06/04/2022 07:12:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/04/2022 07:12:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/04/2022 07:12:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/04/2022 07:12:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/04/2022 07:12:57 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6882357554166387 on epoch=343
06/04/2022 07:13:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=344
06/04/2022 07:13:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
06/04/2022 07:13:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 07:13:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=348
06/04/2022 07:13:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/04/2022 07:13:12 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6745815772717625 on epoch=349
06/04/2022 07:13:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.10 on epoch=351
06/04/2022 07:13:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/04/2022 07:13:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 07:13:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=354
06/04/2022 07:13:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/04/2022 07:13:27 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6706287122196398 on epoch=356
06/04/2022 07:13:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/04/2022 07:13:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=358
06/04/2022 07:13:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 07:13:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=361
06/04/2022 07:13:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/04/2022 07:13:41 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6603156434888672 on epoch=362
06/04/2022 07:13:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=363
06/04/2022 07:13:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=364
06/04/2022 07:13:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/04/2022 07:13:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
06/04/2022 07:13:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=368
06/04/2022 07:13:56 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.659344355566174 on epoch=368
06/04/2022 07:13:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
06/04/2022 07:14:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/04/2022 07:14:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
06/04/2022 07:14:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/04/2022 07:14:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/04/2022 07:14:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:14:11 - INFO - __main__ - Printing 3 examples
06/04/2022 07:14:11 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 07:14:11 - INFO - __main__ - ['sad']
06/04/2022 07:14:11 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 07:14:11 - INFO - __main__ - ['sad']
06/04/2022 07:14:11 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 07:14:11 - INFO - __main__ - ['sad']
06/04/2022 07:14:11 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:14:11 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:14:11 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 07:14:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:14:11 - INFO - __main__ - Printing 3 examples
06/04/2022 07:14:11 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 07:14:11 - INFO - __main__ - ['sad']
06/04/2022 07:14:11 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 07:14:11 - INFO - __main__ - ['sad']
06/04/2022 07:14:11 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 07:14:11 - INFO - __main__ - ['sad']
06/04/2022 07:14:11 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:14:11 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:14:11 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 07:14:11 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6257481952415681 on epoch=374
06/04/2022 07:14:11 - INFO - __main__ - save last model!
06/04/2022 07:14:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 07:14:12 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 07:14:12 - INFO - __main__ - Printing 3 examples
06/04/2022 07:14:12 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 07:14:12 - INFO - __main__ - ['others']
06/04/2022 07:14:12 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 07:14:12 - INFO - __main__ - ['others']
06/04/2022 07:14:12 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 07:14:12 - INFO - __main__ - ['others']
06/04/2022 07:14:12 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:14:14 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:14:19 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 07:14:26 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 07:14:26 - INFO - __main__ - task name: emo
06/04/2022 07:14:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 07:14:26 - INFO - __main__ - Starting training!
06/04/2022 07:15:51 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_13_0.2_8_predictions.txt
06/04/2022 07:15:51 - INFO - __main__ - Classification-F1 on test data: 0.3493
06/04/2022 07:15:52 - INFO - __main__ - prefix=emo_32_13, lr=0.2, bsz=8, dev_performance=0.7126262545033453, test_performance=0.34928537480930927
06/04/2022 07:15:52 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.5, bsz=8 ...
06/04/2022 07:15:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:15:53 - INFO - __main__ - Printing 3 examples
06/04/2022 07:15:53 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 07:15:53 - INFO - __main__ - ['sad']
06/04/2022 07:15:53 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 07:15:53 - INFO - __main__ - ['sad']
06/04/2022 07:15:53 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 07:15:53 - INFO - __main__ - ['sad']
06/04/2022 07:15:53 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:15:53 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:15:53 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 07:15:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:15:53 - INFO - __main__ - Printing 3 examples
06/04/2022 07:15:53 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 07:15:53 - INFO - __main__ - ['sad']
06/04/2022 07:15:53 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 07:15:53 - INFO - __main__ - ['sad']
06/04/2022 07:15:53 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 07:15:53 - INFO - __main__ - ['sad']
06/04/2022 07:15:53 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:15:53 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:15:53 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 07:16:12 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 07:16:12 - INFO - __main__ - task name: emo
06/04/2022 07:16:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 07:16:13 - INFO - __main__ - Starting training!
06/04/2022 07:16:15 - INFO - __main__ - Step 10 Global step 10 Train loss 6.19 on epoch=1
06/04/2022 07:16:18 - INFO - __main__ - Step 20 Global step 20 Train loss 2.25 on epoch=2
06/04/2022 07:16:21 - INFO - __main__ - Step 30 Global step 30 Train loss 1.25 on epoch=3
06/04/2022 07:16:24 - INFO - __main__ - Step 40 Global step 40 Train loss 1.07 on epoch=4
06/04/2022 07:16:26 - INFO - __main__ - Step 50 Global step 50 Train loss 1.05 on epoch=6
06/04/2022 07:16:28 - INFO - __main__ - Global step 50 Train loss 2.36 Classification-F1 0.18265107212475634 on epoch=6
06/04/2022 07:16:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18265107212475634 on epoch=6, global_step=50
06/04/2022 07:16:31 - INFO - __main__ - Step 60 Global step 60 Train loss 0.91 on epoch=7
06/04/2022 07:16:33 - INFO - __main__ - Step 70 Global step 70 Train loss 0.99 on epoch=8
06/04/2022 07:16:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=9
06/04/2022 07:16:38 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=11
06/04/2022 07:16:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=12
06/04/2022 07:16:43 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.1 on epoch=12
06/04/2022 07:16:46 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=13
06/04/2022 07:16:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.87 on epoch=14
06/04/2022 07:16:51 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=16
06/04/2022 07:16:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=17
06/04/2022 07:16:56 - INFO - __main__ - Step 150 Global step 150 Train loss 0.86 on epoch=18
06/04/2022 07:16:58 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.14579221281429502 on epoch=18
06/04/2022 07:17:01 - INFO - __main__ - Step 160 Global step 160 Train loss 0.89 on epoch=19
06/04/2022 07:17:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=21
06/04/2022 07:17:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=22
06/04/2022 07:17:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.80 on epoch=23
06/04/2022 07:17:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=24
06/04/2022 07:17:13 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.15031118830510928 on epoch=24
06/04/2022 07:17:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.81 on epoch=26
06/04/2022 07:17:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.83 on epoch=27
06/04/2022 07:17:21 - INFO - __main__ - Step 230 Global step 230 Train loss 0.88 on epoch=28
06/04/2022 07:17:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.83 on epoch=29
06/04/2022 07:17:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.82 on epoch=31
06/04/2022 07:17:28 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.3406446063549889 on epoch=31
06/04/2022 07:17:28 - INFO - __main__ - Saving model with best Classification-F1: 0.18265107212475634 -> 0.3406446063549889 on epoch=31, global_step=250
06/04/2022 07:17:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.78 on epoch=32
06/04/2022 07:17:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=33
06/04/2022 07:17:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.74 on epoch=34
06/04/2022 07:17:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.73 on epoch=36
06/04/2022 07:17:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.83 on epoch=37
06/04/2022 07:17:44 - INFO - __main__ - Global step 300 Train loss 0.77 Classification-F1 0.207986832986833 on epoch=37
06/04/2022 07:17:47 - INFO - __main__ - Step 310 Global step 310 Train loss 0.70 on epoch=38
06/04/2022 07:17:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=39
06/04/2022 07:17:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.70 on epoch=41
06/04/2022 07:17:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.72 on epoch=42
06/04/2022 07:17:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=43
06/04/2022 07:17:59 - INFO - __main__ - Global step 350 Train loss 0.67 Classification-F1 0.5450200284006095 on epoch=43
06/04/2022 07:17:59 - INFO - __main__ - Saving model with best Classification-F1: 0.3406446063549889 -> 0.5450200284006095 on epoch=43, global_step=350
06/04/2022 07:18:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=44
06/04/2022 07:18:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=46
06/04/2022 07:18:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=47
06/04/2022 07:18:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.57 on epoch=48
06/04/2022 07:18:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.47 on epoch=49
06/04/2022 07:18:14 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.5984268707482994 on epoch=49
06/04/2022 07:18:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5450200284006095 -> 0.5984268707482994 on epoch=49, global_step=400
06/04/2022 07:18:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=51
06/04/2022 07:18:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=52
06/04/2022 07:18:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=53
06/04/2022 07:18:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=54
06/04/2022 07:18:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=56
06/04/2022 07:18:29 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.5084036786309047 on epoch=56
06/04/2022 07:18:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=57
06/04/2022 07:18:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=58
06/04/2022 07:18:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=59
06/04/2022 07:18:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=61
06/04/2022 07:18:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=62
06/04/2022 07:18:44 - INFO - __main__ - Global step 500 Train loss 0.31 Classification-F1 0.5878926459719143 on epoch=62
06/04/2022 07:18:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=63
06/04/2022 07:18:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=64
06/04/2022 07:18:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=66
06/04/2022 07:18:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=67
06/04/2022 07:18:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=68
06/04/2022 07:18:59 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.6194440256409695 on epoch=68
06/04/2022 07:18:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5984268707482994 -> 0.6194440256409695 on epoch=68, global_step=550
06/04/2022 07:19:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=69
06/04/2022 07:19:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=71
06/04/2022 07:19:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=72
06/04/2022 07:19:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=73
06/04/2022 07:19:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=74
06/04/2022 07:19:14 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.6689998407389711 on epoch=74
06/04/2022 07:19:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6194440256409695 -> 0.6689998407389711 on epoch=74, global_step=600
06/04/2022 07:19:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=76
06/04/2022 07:19:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=77
06/04/2022 07:19:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=78
06/04/2022 07:19:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=79
06/04/2022 07:19:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=81
06/04/2022 07:19:29 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6417410714285714 on epoch=81
06/04/2022 07:19:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=82
06/04/2022 07:19:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=83
06/04/2022 07:19:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=84
06/04/2022 07:19:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=86
06/04/2022 07:19:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=87
06/04/2022 07:19:44 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.6801638176638176 on epoch=87
06/04/2022 07:19:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6689998407389711 -> 0.6801638176638176 on epoch=87, global_step=700
06/04/2022 07:19:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=88
06/04/2022 07:19:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=89
06/04/2022 07:19:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=91
06/04/2022 07:19:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=92
06/04/2022 07:19:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=93
06/04/2022 07:19:59 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6850748926619828 on epoch=93
06/04/2022 07:19:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6801638176638176 -> 0.6850748926619828 on epoch=93, global_step=750
06/04/2022 07:20:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=94
06/04/2022 07:20:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=96
06/04/2022 07:20:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=97
06/04/2022 07:20:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=98
06/04/2022 07:20:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=99
06/04/2022 07:20:14 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7110646093855049 on epoch=99
06/04/2022 07:20:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6850748926619828 -> 0.7110646093855049 on epoch=99, global_step=800
06/04/2022 07:20:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=101
06/04/2022 07:20:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=102
06/04/2022 07:20:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=103
06/04/2022 07:20:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=104
06/04/2022 07:20:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=106
06/04/2022 07:20:29 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.6848191718703538 on epoch=106
06/04/2022 07:20:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=107
06/04/2022 07:20:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=108
06/04/2022 07:20:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=109
06/04/2022 07:20:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=111
06/04/2022 07:20:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=112
06/04/2022 07:20:44 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.7102849422746254 on epoch=112
06/04/2022 07:20:47 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=113
06/04/2022 07:20:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=114
06/04/2022 07:20:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=116
06/04/2022 07:20:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=117
06/04/2022 07:20:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=118
06/04/2022 07:21:00 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.6937927663734116 on epoch=118
06/04/2022 07:21:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=119
06/04/2022 07:21:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=121
06/04/2022 07:21:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=122
06/04/2022 07:21:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=123
06/04/2022 07:21:13 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=124
06/04/2022 07:21:15 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7106035632155034 on epoch=124
06/04/2022 07:21:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=126
06/04/2022 07:21:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=127
06/04/2022 07:21:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=128
06/04/2022 07:21:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=129
06/04/2022 07:21:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=131
06/04/2022 07:21:30 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7347106459046758 on epoch=131
06/04/2022 07:21:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7110646093855049 -> 0.7347106459046758 on epoch=131, global_step=1050
06/04/2022 07:21:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=132
06/04/2022 07:21:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=133
06/04/2022 07:21:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=134
06/04/2022 07:21:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=136
06/04/2022 07:21:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=137
06/04/2022 07:21:45 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6952807646356033 on epoch=137
06/04/2022 07:21:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=138
06/04/2022 07:21:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=139
06/04/2022 07:21:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=141
06/04/2022 07:21:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=142
06/04/2022 07:21:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=143
06/04/2022 07:22:00 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7229838709677419 on epoch=143
06/04/2022 07:22:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=144
06/04/2022 07:22:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=146
06/04/2022 07:22:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=147
06/04/2022 07:22:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=148
06/04/2022 07:22:14 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=149
06/04/2022 07:22:16 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7518847875384378 on epoch=149
06/04/2022 07:22:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7347106459046758 -> 0.7518847875384378 on epoch=149, global_step=1200
06/04/2022 07:22:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=151
06/04/2022 07:22:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=152
06/04/2022 07:22:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=153
06/04/2022 07:22:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=154
06/04/2022 07:22:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=156
06/04/2022 07:22:32 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7473895137859765 on epoch=156
06/04/2022 07:22:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=157
06/04/2022 07:22:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=158
06/04/2022 07:22:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=159
06/04/2022 07:22:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=161
06/04/2022 07:22:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=162
06/04/2022 07:22:47 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7575564971751412 on epoch=162
06/04/2022 07:22:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7518847875384378 -> 0.7575564971751412 on epoch=162, global_step=1300
06/04/2022 07:22:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=163
06/04/2022 07:22:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=164
06/04/2022 07:22:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=166
06/04/2022 07:22:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=167
06/04/2022 07:23:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=168
06/04/2022 07:23:03 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7080363903853226 on epoch=168
06/04/2022 07:23:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=169
06/04/2022 07:23:09 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=171
06/04/2022 07:23:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=172
06/04/2022 07:23:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=173
06/04/2022 07:23:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=174
06/04/2022 07:23:19 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7132091572504707 on epoch=174
06/04/2022 07:23:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=176
06/04/2022 07:23:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=177
06/04/2022 07:23:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=178
06/04/2022 07:23:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=179
06/04/2022 07:23:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=181
06/04/2022 07:23:35 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.722161267850923 on epoch=181
06/04/2022 07:23:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=182
06/04/2022 07:23:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=183
06/04/2022 07:23:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=184
06/04/2022 07:23:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=186
06/04/2022 07:23:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=187
06/04/2022 07:23:50 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7347485768500949 on epoch=187
06/04/2022 07:23:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=188
06/04/2022 07:23:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=189
06/04/2022 07:23:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=191
06/04/2022 07:24:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=192
06/04/2022 07:24:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=193
06/04/2022 07:24:06 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7243911294961269 on epoch=193
06/04/2022 07:24:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=194
06/04/2022 07:24:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=196
06/04/2022 07:24:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=197
06/04/2022 07:24:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=198
06/04/2022 07:24:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=199
06/04/2022 07:24:22 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7661638240326765 on epoch=199
06/04/2022 07:24:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7575564971751412 -> 0.7661638240326765 on epoch=199, global_step=1600
06/04/2022 07:24:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=201
06/04/2022 07:24:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=202
06/04/2022 07:24:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=203
06/04/2022 07:24:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=204
06/04/2022 07:24:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=206
06/04/2022 07:24:38 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7416116984428179 on epoch=206
06/04/2022 07:24:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=207
06/04/2022 07:24:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
06/04/2022 07:24:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=209
06/04/2022 07:24:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
06/04/2022 07:24:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=212
06/04/2022 07:24:54 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7285680836279043 on epoch=212
06/04/2022 07:24:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=213
06/04/2022 07:25:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=214
06/04/2022 07:25:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=216
06/04/2022 07:25:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=217
06/04/2022 07:25:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=218
06/04/2022 07:25:10 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7516364368433162 on epoch=218
06/04/2022 07:25:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=219
06/04/2022 07:25:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=221
06/04/2022 07:25:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=222
06/04/2022 07:25:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=223
06/04/2022 07:25:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 07:25:26 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7491905153270457 on epoch=224
06/04/2022 07:25:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=226
06/04/2022 07:25:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=227
06/04/2022 07:25:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=228
06/04/2022 07:25:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=229
06/04/2022 07:25:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=231
06/04/2022 07:25:42 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6806307291381919 on epoch=231
06/04/2022 07:25:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=232
06/04/2022 07:25:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=233
06/04/2022 07:25:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=234
06/04/2022 07:25:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=236
06/04/2022 07:25:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=237
06/04/2022 07:25:57 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7485616566716642 on epoch=237
06/04/2022 07:26:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=238
06/04/2022 07:26:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=239
06/04/2022 07:26:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=241
06/04/2022 07:26:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=242
06/04/2022 07:26:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=243
06/04/2022 07:26:13 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7819543201896143 on epoch=243
06/04/2022 07:26:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7661638240326765 -> 0.7819543201896143 on epoch=243, global_step=1950
06/04/2022 07:26:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=244
06/04/2022 07:26:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=246
06/04/2022 07:26:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=247
06/04/2022 07:26:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=248
06/04/2022 07:26:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=249
06/04/2022 07:26:29 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7304529404514177 on epoch=249
06/04/2022 07:26:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=251
06/04/2022 07:26:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
06/04/2022 07:26:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
06/04/2022 07:26:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=254
06/04/2022 07:26:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
06/04/2022 07:26:44 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7739134756545143 on epoch=256
06/04/2022 07:26:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
06/04/2022 07:26:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=258
06/04/2022 07:26:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=259
06/04/2022 07:26:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
06/04/2022 07:26:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
06/04/2022 07:26:59 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7585597352838733 on epoch=262
06/04/2022 07:27:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=263
06/04/2022 07:27:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=264
06/04/2022 07:27:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=266
06/04/2022 07:27:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/04/2022 07:27:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=268
06/04/2022 07:27:14 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7513159851657815 on epoch=268
06/04/2022 07:27:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
06/04/2022 07:27:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=271
06/04/2022 07:27:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=272
06/04/2022 07:27:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
06/04/2022 07:27:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=274
06/04/2022 07:27:29 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7227873605582584 on epoch=274
06/04/2022 07:27:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=276
06/04/2022 07:27:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
06/04/2022 07:27:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/04/2022 07:27:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
06/04/2022 07:27:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/04/2022 07:27:45 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7288350181325902 on epoch=281
06/04/2022 07:27:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=282
06/04/2022 07:27:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=283
06/04/2022 07:27:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=284
06/04/2022 07:27:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 07:27:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
06/04/2022 07:27:59 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7658733295630776 on epoch=287
06/04/2022 07:28:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=288
06/04/2022 07:28:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=289
06/04/2022 07:28:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/04/2022 07:28:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=292
06/04/2022 07:28:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=293
06/04/2022 07:28:14 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7575757575757576 on epoch=293
06/04/2022 07:28:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
06/04/2022 07:28:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/04/2022 07:28:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/04/2022 07:28:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=298
06/04/2022 07:28:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/04/2022 07:28:29 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7460586238064336 on epoch=299
06/04/2022 07:28:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/04/2022 07:28:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=302
06/04/2022 07:28:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/04/2022 07:28:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
06/04/2022 07:28:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
06/04/2022 07:28:44 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.708276525590803 on epoch=306
06/04/2022 07:28:47 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/04/2022 07:28:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
06/04/2022 07:28:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/04/2022 07:28:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
06/04/2022 07:28:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 07:28:59 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7329202296955288 on epoch=312
06/04/2022 07:29:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=313
06/04/2022 07:29:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=314
06/04/2022 07:29:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
06/04/2022 07:29:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=317
06/04/2022 07:29:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
06/04/2022 07:29:13 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7491200175448215 on epoch=318
06/04/2022 07:29:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/04/2022 07:29:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 07:29:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
06/04/2022 07:29:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
06/04/2022 07:29:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=324
06/04/2022 07:29:28 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7039720751083293 on epoch=324
06/04/2022 07:29:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=326
06/04/2022 07:29:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 07:29:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
06/04/2022 07:29:38 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
06/04/2022 07:29:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
06/04/2022 07:29:43 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7244237877799522 on epoch=331
06/04/2022 07:29:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
06/04/2022 07:29:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=333
06/04/2022 07:29:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=334
06/04/2022 07:29:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=336
06/04/2022 07:29:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
06/04/2022 07:29:58 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7506726551956815 on epoch=337
06/04/2022 07:30:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
06/04/2022 07:30:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
06/04/2022 07:30:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.12 on epoch=341
06/04/2022 07:30:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
06/04/2022 07:30:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/04/2022 07:30:13 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7727271362517265 on epoch=343
06/04/2022 07:30:16 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
06/04/2022 07:30:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=346
06/04/2022 07:30:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 07:30:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 07:30:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=349
06/04/2022 07:30:28 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7979166666666667 on epoch=349
06/04/2022 07:30:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7819543201896143 -> 0.7979166666666667 on epoch=349, global_step=2800
06/04/2022 07:30:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
06/04/2022 07:30:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
06/04/2022 07:30:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/04/2022 07:30:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
06/04/2022 07:30:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 07:30:44 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.758058833003564 on epoch=356
06/04/2022 07:30:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/04/2022 07:30:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
06/04/2022 07:30:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 07:30:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/04/2022 07:30:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
06/04/2022 07:30:59 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7816028361408349 on epoch=362
06/04/2022 07:31:02 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/04/2022 07:31:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
06/04/2022 07:31:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
06/04/2022 07:31:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=367
06/04/2022 07:31:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 07:31:14 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7907582559860102 on epoch=368
06/04/2022 07:31:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 07:31:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
06/04/2022 07:31:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 07:31:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
06/04/2022 07:31:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 07:31:28 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:31:28 - INFO - __main__ - Printing 3 examples
06/04/2022 07:31:28 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 07:31:28 - INFO - __main__ - ['sad']
06/04/2022 07:31:28 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 07:31:28 - INFO - __main__ - ['sad']
06/04/2022 07:31:28 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 07:31:28 - INFO - __main__ - ['sad']
06/04/2022 07:31:28 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:31:29 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:31:29 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 07:31:29 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:31:29 - INFO - __main__ - Printing 3 examples
06/04/2022 07:31:29 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 07:31:29 - INFO - __main__ - ['sad']
06/04/2022 07:31:29 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 07:31:29 - INFO - __main__ - ['sad']
06/04/2022 07:31:29 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 07:31:29 - INFO - __main__ - ['sad']
06/04/2022 07:31:29 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:31:29 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:31:29 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 07:31:30 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7123566608710051 on epoch=374
06/04/2022 07:31:30 - INFO - __main__ - save last model!
06/04/2022 07:31:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 07:31:30 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 07:31:30 - INFO - __main__ - Printing 3 examples
06/04/2022 07:31:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 07:31:30 - INFO - __main__ - ['others']
06/04/2022 07:31:30 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 07:31:30 - INFO - __main__ - ['others']
06/04/2022 07:31:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 07:31:30 - INFO - __main__ - ['others']
06/04/2022 07:31:30 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:31:32 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:31:38 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 07:31:48 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 07:31:48 - INFO - __main__ - task name: emo
06/04/2022 07:31:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 07:31:49 - INFO - __main__ - Starting training!
06/04/2022 07:33:20 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_21_0.5_8_predictions.txt
06/04/2022 07:33:20 - INFO - __main__ - Classification-F1 on test data: 0.3985
06/04/2022 07:33:21 - INFO - __main__ - prefix=emo_32_21, lr=0.5, bsz=8, dev_performance=0.7979166666666667, test_performance=0.3984836528242834
06/04/2022 07:33:21 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.4, bsz=8 ...
06/04/2022 07:33:22 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:33:22 - INFO - __main__ - Printing 3 examples
06/04/2022 07:33:22 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 07:33:22 - INFO - __main__ - ['sad']
06/04/2022 07:33:22 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 07:33:22 - INFO - __main__ - ['sad']
06/04/2022 07:33:22 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 07:33:22 - INFO - __main__ - ['sad']
06/04/2022 07:33:22 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:33:22 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:33:22 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 07:33:22 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:33:22 - INFO - __main__ - Printing 3 examples
06/04/2022 07:33:22 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 07:33:22 - INFO - __main__ - ['sad']
06/04/2022 07:33:22 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 07:33:22 - INFO - __main__ - ['sad']
06/04/2022 07:33:22 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 07:33:22 - INFO - __main__ - ['sad']
06/04/2022 07:33:22 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:33:22 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:33:22 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 07:33:41 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 07:33:41 - INFO - __main__ - task name: emo
06/04/2022 07:33:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 07:33:42 - INFO - __main__ - Starting training!
06/04/2022 07:33:45 - INFO - __main__ - Step 10 Global step 10 Train loss 6.50 on epoch=1
06/04/2022 07:33:48 - INFO - __main__ - Step 20 Global step 20 Train loss 2.96 on epoch=2
06/04/2022 07:33:50 - INFO - __main__ - Step 30 Global step 30 Train loss 1.81 on epoch=3
06/04/2022 07:33:53 - INFO - __main__ - Step 40 Global step 40 Train loss 1.36 on epoch=4
06/04/2022 07:33:56 - INFO - __main__ - Step 50 Global step 50 Train loss 1.20 on epoch=6
06/04/2022 07:33:58 - INFO - __main__ - Global step 50 Train loss 2.76 Classification-F1 0.1 on epoch=6
06/04/2022 07:33:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/04/2022 07:34:00 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=7
06/04/2022 07:34:03 - INFO - __main__ - Step 70 Global step 70 Train loss 1.11 on epoch=8
06/04/2022 07:34:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=9
06/04/2022 07:34:08 - INFO - __main__ - Step 90 Global step 90 Train loss 1.01 on epoch=11
06/04/2022 07:34:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=12
06/04/2022 07:34:13 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.1821157371039539 on epoch=12
06/04/2022 07:34:13 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1821157371039539 on epoch=12, global_step=100
06/04/2022 07:34:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=13
06/04/2022 07:34:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=14
06/04/2022 07:34:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=16
06/04/2022 07:34:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=17
06/04/2022 07:34:26 - INFO - __main__ - Step 150 Global step 150 Train loss 0.97 on epoch=18
06/04/2022 07:34:28 - INFO - __main__ - Global step 150 Train loss 0.92 Classification-F1 0.15859154929577468 on epoch=18
06/04/2022 07:34:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=19
06/04/2022 07:34:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.90 on epoch=21
06/04/2022 07:34:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.91 on epoch=22
06/04/2022 07:34:39 - INFO - __main__ - Step 190 Global step 190 Train loss 1.02 on epoch=23
06/04/2022 07:34:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=24
06/04/2022 07:34:43 - INFO - __main__ - Global step 200 Train loss 0.94 Classification-F1 0.1121977240398293 on epoch=24
06/04/2022 07:34:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.82 on epoch=26
06/04/2022 07:34:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.90 on epoch=27
06/04/2022 07:34:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=28
06/04/2022 07:34:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=29
06/04/2022 07:34:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.84 on epoch=31
06/04/2022 07:34:58 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.20303654143077715 on epoch=31
06/04/2022 07:34:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1821157371039539 -> 0.20303654143077715 on epoch=31, global_step=250
06/04/2022 07:35:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.78 on epoch=32
06/04/2022 07:35:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.84 on epoch=33
06/04/2022 07:35:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=34
06/04/2022 07:35:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.86 on epoch=36
06/04/2022 07:35:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.83 on epoch=37
06/04/2022 07:35:13 - INFO - __main__ - Global step 300 Train loss 0.83 Classification-F1 0.2772774919001334 on epoch=37
06/04/2022 07:35:13 - INFO - __main__ - Saving model with best Classification-F1: 0.20303654143077715 -> 0.2772774919001334 on epoch=37, global_step=300
06/04/2022 07:35:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.82 on epoch=38
06/04/2022 07:35:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.73 on epoch=39
06/04/2022 07:35:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.79 on epoch=41
06/04/2022 07:35:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.76 on epoch=42
06/04/2022 07:35:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.76 on epoch=43
06/04/2022 07:35:29 - INFO - __main__ - Global step 350 Train loss 0.77 Classification-F1 0.32378838048906644 on epoch=43
06/04/2022 07:35:29 - INFO - __main__ - Saving model with best Classification-F1: 0.2772774919001334 -> 0.32378838048906644 on epoch=43, global_step=350
06/04/2022 07:35:31 - INFO - __main__ - Step 360 Global step 360 Train loss 0.82 on epoch=44
06/04/2022 07:35:34 - INFO - __main__ - Step 370 Global step 370 Train loss 0.76 on epoch=46
06/04/2022 07:35:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.79 on epoch=47
06/04/2022 07:35:39 - INFO - __main__ - Step 390 Global step 390 Train loss 0.79 on epoch=48
06/04/2022 07:35:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.72 on epoch=49
06/04/2022 07:35:44 - INFO - __main__ - Global step 400 Train loss 0.77 Classification-F1 0.32178142574859403 on epoch=49
06/04/2022 07:35:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.70 on epoch=51
06/04/2022 07:35:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.73 on epoch=52
06/04/2022 07:35:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.75 on epoch=53
06/04/2022 07:35:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.62 on epoch=54
06/04/2022 07:35:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.74 on epoch=56
06/04/2022 07:35:59 - INFO - __main__ - Global step 450 Train loss 0.71 Classification-F1 0.3539775476096231 on epoch=56
06/04/2022 07:35:59 - INFO - __main__ - Saving model with best Classification-F1: 0.32378838048906644 -> 0.3539775476096231 on epoch=56, global_step=450
06/04/2022 07:36:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.62 on epoch=57
06/04/2022 07:36:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.65 on epoch=58
06/04/2022 07:36:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.59 on epoch=59
06/04/2022 07:36:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.64 on epoch=61
06/04/2022 07:36:12 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=62
06/04/2022 07:36:14 - INFO - __main__ - Global step 500 Train loss 0.62 Classification-F1 0.5511173903615764 on epoch=62
06/04/2022 07:36:14 - INFO - __main__ - Saving model with best Classification-F1: 0.3539775476096231 -> 0.5511173903615764 on epoch=62, global_step=500
06/04/2022 07:36:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.56 on epoch=63
06/04/2022 07:36:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=64
06/04/2022 07:36:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.59 on epoch=66
06/04/2022 07:36:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.56 on epoch=67
06/04/2022 07:36:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.65 on epoch=68
06/04/2022 07:36:29 - INFO - __main__ - Global step 550 Train loss 0.57 Classification-F1 0.5027807362485415 on epoch=68
06/04/2022 07:36:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.46 on epoch=69
06/04/2022 07:36:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=71
06/04/2022 07:36:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.52 on epoch=72
06/04/2022 07:36:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.55 on epoch=73
06/04/2022 07:36:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.53 on epoch=74
06/04/2022 07:36:44 - INFO - __main__ - Global step 600 Train loss 0.52 Classification-F1 0.32595302873940646 on epoch=74
06/04/2022 07:36:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.54 on epoch=76
06/04/2022 07:36:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.42 on epoch=77
06/04/2022 07:36:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.58 on epoch=78
06/04/2022 07:36:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.54 on epoch=79
06/04/2022 07:36:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.51 on epoch=81
06/04/2022 07:36:59 - INFO - __main__ - Global step 650 Train loss 0.52 Classification-F1 0.5880396504499805 on epoch=81
06/04/2022 07:36:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5511173903615764 -> 0.5880396504499805 on epoch=81, global_step=650
06/04/2022 07:37:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.45 on epoch=82
06/04/2022 07:37:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.55 on epoch=83
06/04/2022 07:37:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=84
06/04/2022 07:37:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.51 on epoch=86
06/04/2022 07:37:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=87
06/04/2022 07:37:13 - INFO - __main__ - Global step 700 Train loss 0.45 Classification-F1 0.5752472817879795 on epoch=87
06/04/2022 07:37:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.48 on epoch=88
06/04/2022 07:37:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=89
06/04/2022 07:37:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.40 on epoch=91
06/04/2022 07:37:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=92
06/04/2022 07:37:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.44 on epoch=93
06/04/2022 07:37:28 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.6129290352504638 on epoch=93
06/04/2022 07:37:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5880396504499805 -> 0.6129290352504638 on epoch=93, global_step=750
06/04/2022 07:37:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=94
06/04/2022 07:37:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.40 on epoch=96
06/04/2022 07:37:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.36 on epoch=97
06/04/2022 07:37:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=98
06/04/2022 07:37:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=99
06/04/2022 07:37:43 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.4999084249084249 on epoch=99
06/04/2022 07:37:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.34 on epoch=101
06/04/2022 07:37:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=102
06/04/2022 07:37:51 - INFO - __main__ - Step 830 Global step 830 Train loss 0.30 on epoch=103
06/04/2022 07:37:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.33 on epoch=104
06/04/2022 07:37:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.40 on epoch=106
06/04/2022 07:37:58 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.5481571560190984 on epoch=106
06/04/2022 07:38:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.35 on epoch=107
06/04/2022 07:38:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.39 on epoch=108
06/04/2022 07:38:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.27 on epoch=109
06/04/2022 07:38:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=111
06/04/2022 07:38:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=112
06/04/2022 07:38:13 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.7010249657826294 on epoch=112
06/04/2022 07:38:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6129290352504638 -> 0.7010249657826294 on epoch=112, global_step=900
06/04/2022 07:38:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=113
06/04/2022 07:38:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=114
06/04/2022 07:38:21 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=116
06/04/2022 07:38:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.39 on epoch=117
06/04/2022 07:38:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=118
06/04/2022 07:38:28 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.6221361822545551 on epoch=118
06/04/2022 07:38:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=119
06/04/2022 07:38:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=121
06/04/2022 07:38:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=122
06/04/2022 07:38:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=123
06/04/2022 07:38:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=124
06/04/2022 07:38:44 - INFO - __main__ - Global step 1000 Train loss 0.21 Classification-F1 0.5920215552362693 on epoch=124
06/04/2022 07:38:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=126
06/04/2022 07:38:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=127
06/04/2022 07:38:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.31 on epoch=128
06/04/2022 07:38:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=129
06/04/2022 07:38:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=131
06/04/2022 07:38:59 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.5868749421418633 on epoch=131
06/04/2022 07:39:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.23 on epoch=132
06/04/2022 07:39:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=133
06/04/2022 07:39:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=134
06/04/2022 07:39:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=136
06/04/2022 07:39:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=137
06/04/2022 07:39:14 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.6768501995392753 on epoch=137
06/04/2022 07:39:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=138
06/04/2022 07:39:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=139
06/04/2022 07:39:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=141
06/04/2022 07:39:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=142
06/04/2022 07:39:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=143
06/04/2022 07:39:29 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.71023859211715 on epoch=143
06/04/2022 07:39:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7010249657826294 -> 0.71023859211715 on epoch=143, global_step=1150
06/04/2022 07:39:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=144
06/04/2022 07:39:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.20 on epoch=146
06/04/2022 07:39:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=147
06/04/2022 07:39:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=148
06/04/2022 07:39:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=149
06/04/2022 07:39:44 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.7168289326694729 on epoch=149
06/04/2022 07:39:44 - INFO - __main__ - Saving model with best Classification-F1: 0.71023859211715 -> 0.7168289326694729 on epoch=149, global_step=1200
06/04/2022 07:39:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=151
06/04/2022 07:39:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=152
06/04/2022 07:39:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=153
06/04/2022 07:39:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=154
06/04/2022 07:39:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=156
06/04/2022 07:39:59 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.6486108336528886 on epoch=156
06/04/2022 07:40:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=157
06/04/2022 07:40:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=158
06/04/2022 07:40:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=159
06/04/2022 07:40:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=161
06/04/2022 07:40:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=162
06/04/2022 07:40:14 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.7180350672877847 on epoch=162
06/04/2022 07:40:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7168289326694729 -> 0.7180350672877847 on epoch=162, global_step=1300
06/04/2022 07:40:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=163
06/04/2022 07:40:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=164
06/04/2022 07:40:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=166
06/04/2022 07:40:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=167
06/04/2022 07:40:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=168
06/04/2022 07:40:29 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7270585317460317 on epoch=168
06/04/2022 07:40:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7180350672877847 -> 0.7270585317460317 on epoch=168, global_step=1350
06/04/2022 07:40:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=169
06/04/2022 07:40:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=171
06/04/2022 07:40:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=172
06/04/2022 07:40:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=173
06/04/2022 07:40:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=174
06/04/2022 07:40:45 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.6658924291329775 on epoch=174
06/04/2022 07:40:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=176
06/04/2022 07:40:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=177
06/04/2022 07:40:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=178
06/04/2022 07:40:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=179
06/04/2022 07:40:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=181
06/04/2022 07:41:00 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6791460664411484 on epoch=181
06/04/2022 07:41:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=182
06/04/2022 07:41:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=183
06/04/2022 07:41:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=184
06/04/2022 07:41:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=186
06/04/2022 07:41:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=187
06/04/2022 07:41:16 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6981554019457245 on epoch=187
06/04/2022 07:41:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=188
06/04/2022 07:41:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=189
06/04/2022 07:41:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=191
06/04/2022 07:41:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=192
06/04/2022 07:41:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=193
06/04/2022 07:41:31 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.627734514858575 on epoch=193
06/04/2022 07:41:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=194
06/04/2022 07:41:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=196
06/04/2022 07:41:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
06/04/2022 07:41:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=198
06/04/2022 07:41:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=199
06/04/2022 07:41:47 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6307471264367817 on epoch=199
06/04/2022 07:41:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=201
06/04/2022 07:41:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=202
06/04/2022 07:41:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=203
06/04/2022 07:41:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=204
06/04/2022 07:42:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=206
06/04/2022 07:42:02 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7027601838052658 on epoch=206
06/04/2022 07:42:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
06/04/2022 07:42:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=208
06/04/2022 07:42:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=209
06/04/2022 07:42:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=211
06/04/2022 07:42:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=212
06/04/2022 07:42:18 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6976330913490623 on epoch=212
06/04/2022 07:42:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=213
06/04/2022 07:42:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
06/04/2022 07:42:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=216
06/04/2022 07:42:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=217
06/04/2022 07:42:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=218
06/04/2022 07:42:34 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7335126301403925 on epoch=218
06/04/2022 07:42:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7270585317460317 -> 0.7335126301403925 on epoch=218, global_step=1750
06/04/2022 07:42:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=219
06/04/2022 07:42:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=221
06/04/2022 07:42:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=222
06/04/2022 07:42:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=223
06/04/2022 07:42:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=224
06/04/2022 07:42:49 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.682334658805247 on epoch=224
06/04/2022 07:42:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=226
06/04/2022 07:42:54 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
06/04/2022 07:42:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=228
06/04/2022 07:43:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=229
06/04/2022 07:43:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=231
06/04/2022 07:43:05 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6383246259029928 on epoch=231
06/04/2022 07:43:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
06/04/2022 07:43:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=233
06/04/2022 07:43:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
06/04/2022 07:43:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=236
06/04/2022 07:43:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=237
06/04/2022 07:43:20 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6819263699674354 on epoch=237
06/04/2022 07:43:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
06/04/2022 07:43:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=239
06/04/2022 07:43:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=241
06/04/2022 07:43:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=242
06/04/2022 07:43:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
06/04/2022 07:43:36 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6923940030557677 on epoch=243
06/04/2022 07:43:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
06/04/2022 07:43:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=246
06/04/2022 07:43:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
06/04/2022 07:43:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=248
06/04/2022 07:43:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
06/04/2022 07:43:51 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6575042681288854 on epoch=249
06/04/2022 07:43:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=251
06/04/2022 07:43:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=252
06/04/2022 07:43:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
06/04/2022 07:44:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/04/2022 07:44:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=256
06/04/2022 07:44:07 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7593723238316613 on epoch=256
06/04/2022 07:44:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7335126301403925 -> 0.7593723238316613 on epoch=256, global_step=2050
06/04/2022 07:44:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=257
06/04/2022 07:44:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
06/04/2022 07:44:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/04/2022 07:44:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
06/04/2022 07:44:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=262
06/04/2022 07:44:23 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6783885197421334 on epoch=262
06/04/2022 07:44:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=263
06/04/2022 07:44:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=264
06/04/2022 07:44:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=266
06/04/2022 07:44:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/04/2022 07:44:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/04/2022 07:44:38 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.668219606744197 on epoch=268
06/04/2022 07:44:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=269
06/04/2022 07:44:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 07:44:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
06/04/2022 07:44:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=273
06/04/2022 07:44:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=274
06/04/2022 07:44:54 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6816973644803834 on epoch=274
06/04/2022 07:44:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=276
06/04/2022 07:44:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
06/04/2022 07:45:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=278
06/04/2022 07:45:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=279
06/04/2022 07:45:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=281
06/04/2022 07:45:10 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6893302089052736 on epoch=281
06/04/2022 07:45:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
06/04/2022 07:45:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=283
06/04/2022 07:45:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/04/2022 07:45:21 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 07:45:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=287
06/04/2022 07:45:26 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6299230944240587 on epoch=287
06/04/2022 07:45:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=288
06/04/2022 07:45:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
06/04/2022 07:45:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
06/04/2022 07:45:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/04/2022 07:45:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/04/2022 07:45:42 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.644652393732379 on epoch=293
06/04/2022 07:45:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
06/04/2022 07:45:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/04/2022 07:45:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
06/04/2022 07:45:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/04/2022 07:45:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=299
06/04/2022 07:45:57 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6703882119687957 on epoch=299
06/04/2022 07:46:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/04/2022 07:46:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/04/2022 07:46:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/04/2022 07:46:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
06/04/2022 07:46:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/04/2022 07:46:13 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6936091083632068 on epoch=306
06/04/2022 07:46:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
06/04/2022 07:46:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=308
06/04/2022 07:46:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
06/04/2022 07:46:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=311
06/04/2022 07:46:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 07:46:29 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6773028474648037 on epoch=312
06/04/2022 07:46:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/04/2022 07:46:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=314
06/04/2022 07:46:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=316
06/04/2022 07:46:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
06/04/2022 07:46:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
06/04/2022 07:46:45 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.710928258318356 on epoch=318
06/04/2022 07:46:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
06/04/2022 07:46:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 07:46:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=322
06/04/2022 07:46:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
06/04/2022 07:46:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
06/04/2022 07:47:00 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6745718575963202 on epoch=324
06/04/2022 07:47:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=326
06/04/2022 07:47:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=327
06/04/2022 07:47:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/04/2022 07:47:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/04/2022 07:47:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/04/2022 07:47:16 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7175461582482455 on epoch=331
06/04/2022 07:47:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
06/04/2022 07:47:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/04/2022 07:47:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=334
06/04/2022 07:47:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/04/2022 07:47:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
06/04/2022 07:47:31 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7049752840339832 on epoch=337
06/04/2022 07:47:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 07:47:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/04/2022 07:47:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/04/2022 07:47:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
06/04/2022 07:47:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=343
06/04/2022 07:47:46 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6517426076748111 on epoch=343
06/04/2022 07:47:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
06/04/2022 07:47:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=346
06/04/2022 07:47:54 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
06/04/2022 07:47:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
06/04/2022 07:48:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 07:48:02 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7056992221582786 on epoch=349
06/04/2022 07:48:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=351
06/04/2022 07:48:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/04/2022 07:48:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 07:48:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
06/04/2022 07:48:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 07:48:18 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7098139126111116 on epoch=356
06/04/2022 07:48:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 07:48:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/04/2022 07:48:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 07:48:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/04/2022 07:48:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
06/04/2022 07:48:33 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.68924767156995 on epoch=362
06/04/2022 07:48:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
06/04/2022 07:48:39 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
06/04/2022 07:48:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/04/2022 07:48:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 07:48:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 07:48:49 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7094075079149706 on epoch=368
06/04/2022 07:48:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 07:48:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/04/2022 07:48:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.08 on epoch=372
06/04/2022 07:48:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/04/2022 07:49:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=374
06/04/2022 07:49:03 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:49:03 - INFO - __main__ - Printing 3 examples
06/04/2022 07:49:03 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 07:49:03 - INFO - __main__ - ['sad']
06/04/2022 07:49:03 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 07:49:03 - INFO - __main__ - ['sad']
06/04/2022 07:49:03 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 07:49:03 - INFO - __main__ - ['sad']
06/04/2022 07:49:03 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:49:03 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:49:03 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 07:49:03 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:49:03 - INFO - __main__ - Printing 3 examples
06/04/2022 07:49:03 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 07:49:03 - INFO - __main__ - ['sad']
06/04/2022 07:49:03 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 07:49:03 - INFO - __main__ - ['sad']
06/04/2022 07:49:03 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 07:49:03 - INFO - __main__ - ['sad']
06/04/2022 07:49:03 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:49:03 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:49:03 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 07:49:04 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6596862567130939 on epoch=374
06/04/2022 07:49:04 - INFO - __main__ - save last model!
06/04/2022 07:49:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 07:49:04 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 07:49:04 - INFO - __main__ - Printing 3 examples
06/04/2022 07:49:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 07:49:04 - INFO - __main__ - ['others']
06/04/2022 07:49:04 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 07:49:04 - INFO - __main__ - ['others']
06/04/2022 07:49:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 07:49:04 - INFO - __main__ - ['others']
06/04/2022 07:49:04 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:49:06 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:49:11 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 07:49:19 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 07:49:19 - INFO - __main__ - task name: emo
06/04/2022 07:49:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 07:49:20 - INFO - __main__ - Starting training!
06/04/2022 07:50:51 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_21_0.4_8_predictions.txt
06/04/2022 07:50:51 - INFO - __main__ - Classification-F1 on test data: 0.3997
06/04/2022 07:50:52 - INFO - __main__ - prefix=emo_32_21, lr=0.4, bsz=8, dev_performance=0.7593723238316613, test_performance=0.39973634371030453
06/04/2022 07:50:52 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.3, bsz=8 ...
06/04/2022 07:50:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:50:53 - INFO - __main__ - Printing 3 examples
06/04/2022 07:50:53 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 07:50:53 - INFO - __main__ - ['sad']
06/04/2022 07:50:53 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 07:50:53 - INFO - __main__ - ['sad']
06/04/2022 07:50:53 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 07:50:53 - INFO - __main__ - ['sad']
06/04/2022 07:50:53 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:50:53 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:50:53 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 07:50:53 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 07:50:53 - INFO - __main__ - Printing 3 examples
06/04/2022 07:50:53 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 07:50:53 - INFO - __main__ - ['sad']
06/04/2022 07:50:53 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 07:50:53 - INFO - __main__ - ['sad']
06/04/2022 07:50:53 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 07:50:53 - INFO - __main__ - ['sad']
06/04/2022 07:50:53 - INFO - __main__ - Tokenizing Input ...
06/04/2022 07:50:53 - INFO - __main__ - Tokenizing Output ...
06/04/2022 07:50:53 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 07:51:08 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 07:51:08 - INFO - __main__ - task name: emo
06/04/2022 07:51:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 07:51:09 - INFO - __main__ - Starting training!
06/04/2022 07:51:12 - INFO - __main__ - Step 10 Global step 10 Train loss 7.47 on epoch=1
06/04/2022 07:51:14 - INFO - __main__ - Step 20 Global step 20 Train loss 4.14 on epoch=2
06/04/2022 07:51:17 - INFO - __main__ - Step 30 Global step 30 Train loss 1.94 on epoch=3
06/04/2022 07:51:20 - INFO - __main__ - Step 40 Global step 40 Train loss 1.33 on epoch=4
06/04/2022 07:51:22 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=6
06/04/2022 07:51:24 - INFO - __main__ - Global step 50 Train loss 3.20 Classification-F1 0.14621798689696247 on epoch=6
06/04/2022 07:51:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.14621798689696247 on epoch=6, global_step=50
06/04/2022 07:51:26 - INFO - __main__ - Step 60 Global step 60 Train loss 1.12 on epoch=7
06/04/2022 07:51:29 - INFO - __main__ - Step 70 Global step 70 Train loss 0.92 on epoch=8
06/04/2022 07:51:31 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=9
06/04/2022 07:51:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=11
06/04/2022 07:51:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=12
06/04/2022 07:51:38 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.2186600164541341 on epoch=12
06/04/2022 07:51:38 - INFO - __main__ - Saving model with best Classification-F1: 0.14621798689696247 -> 0.2186600164541341 on epoch=12, global_step=100
06/04/2022 07:51:41 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=13
06/04/2022 07:51:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=14
06/04/2022 07:51:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.94 on epoch=16
06/04/2022 07:51:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=17
06/04/2022 07:51:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.97 on epoch=18
06/04/2022 07:51:52 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.1 on epoch=18
06/04/2022 07:51:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.83 on epoch=19
06/04/2022 07:51:58 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=21
06/04/2022 07:52:00 - INFO - __main__ - Step 180 Global step 180 Train loss 0.91 on epoch=22
06/04/2022 07:52:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=23
06/04/2022 07:52:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=24
06/04/2022 07:52:07 - INFO - __main__ - Global step 200 Train loss 0.86 Classification-F1 0.09554140127388534 on epoch=24
06/04/2022 07:52:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=26
06/04/2022 07:52:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.92 on epoch=27
06/04/2022 07:52:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=28
06/04/2022 07:52:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.86 on epoch=29
06/04/2022 07:52:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.88 on epoch=31
06/04/2022 07:52:22 - INFO - __main__ - Global step 250 Train loss 0.85 Classification-F1 0.14342751842751844 on epoch=31
06/04/2022 07:52:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.81 on epoch=32
06/04/2022 07:52:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=33
06/04/2022 07:52:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.92 on epoch=34
06/04/2022 07:52:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.82 on epoch=36
06/04/2022 07:52:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.79 on epoch=37
06/04/2022 07:52:36 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.2465034965034965 on epoch=37
06/04/2022 07:52:36 - INFO - __main__ - Saving model with best Classification-F1: 0.2186600164541341 -> 0.2465034965034965 on epoch=37, global_step=300
06/04/2022 07:52:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.78 on epoch=38
06/04/2022 07:52:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.81 on epoch=39
06/04/2022 07:52:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.81 on epoch=41
06/04/2022 07:52:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.86 on epoch=42
06/04/2022 07:52:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.86 on epoch=43
06/04/2022 07:52:51 - INFO - __main__ - Global step 350 Train loss 0.83 Classification-F1 0.2334100057504313 on epoch=43
06/04/2022 07:52:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.72 on epoch=44
06/04/2022 07:52:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.72 on epoch=46
06/04/2022 07:52:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.77 on epoch=47
06/04/2022 07:53:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.68 on epoch=48
06/04/2022 07:53:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.72 on epoch=49
06/04/2022 07:53:06 - INFO - __main__ - Global step 400 Train loss 0.72 Classification-F1 0.48427672955974843 on epoch=49
06/04/2022 07:53:06 - INFO - __main__ - Saving model with best Classification-F1: 0.2465034965034965 -> 0.48427672955974843 on epoch=49, global_step=400
06/04/2022 07:53:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.76 on epoch=51
06/04/2022 07:53:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.75 on epoch=52
06/04/2022 07:53:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.67 on epoch=53
06/04/2022 07:53:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.60 on epoch=54
06/04/2022 07:53:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.55 on epoch=56
06/04/2022 07:53:20 - INFO - __main__ - Global step 450 Train loss 0.66 Classification-F1 0.6310518934081346 on epoch=56
06/04/2022 07:53:20 - INFO - __main__ - Saving model with best Classification-F1: 0.48427672955974843 -> 0.6310518934081346 on epoch=56, global_step=450
06/04/2022 07:53:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.57 on epoch=57
06/04/2022 07:53:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.58 on epoch=58
06/04/2022 07:53:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.51 on epoch=59
06/04/2022 07:53:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=61
06/04/2022 07:53:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.64 on epoch=62
06/04/2022 07:53:35 - INFO - __main__ - Global step 500 Train loss 0.57 Classification-F1 0.5346103145837243 on epoch=62
06/04/2022 07:53:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=63
06/04/2022 07:53:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.55 on epoch=64
06/04/2022 07:53:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=66
06/04/2022 07:53:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.55 on epoch=67
06/04/2022 07:53:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=68
06/04/2022 07:53:49 - INFO - __main__ - Global step 550 Train loss 0.54 Classification-F1 0.526456500310321 on epoch=68
06/04/2022 07:53:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.50 on epoch=69
06/04/2022 07:53:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.45 on epoch=71
06/04/2022 07:53:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.55 on epoch=72
06/04/2022 07:54:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.47 on epoch=73
06/04/2022 07:54:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.50 on epoch=74
06/04/2022 07:54:04 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.5535875888817064 on epoch=74
06/04/2022 07:54:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.39 on epoch=76
06/04/2022 07:54:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.50 on epoch=77
06/04/2022 07:54:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.33 on epoch=78
06/04/2022 07:54:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=79
06/04/2022 07:54:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.39 on epoch=81
06/04/2022 07:54:18 - INFO - __main__ - Global step 650 Train loss 0.40 Classification-F1 0.6497824095281722 on epoch=81
06/04/2022 07:54:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6310518934081346 -> 0.6497824095281722 on epoch=81, global_step=650
06/04/2022 07:54:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.33 on epoch=82
06/04/2022 07:54:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.42 on epoch=83
06/04/2022 07:54:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=84
06/04/2022 07:54:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=86
06/04/2022 07:54:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.44 on epoch=87
06/04/2022 07:54:33 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.6310394670688788 on epoch=87
06/04/2022 07:54:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.40 on epoch=88
06/04/2022 07:54:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.34 on epoch=89
06/04/2022 07:54:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=91
06/04/2022 07:54:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=92
06/04/2022 07:54:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.38 on epoch=93
06/04/2022 07:54:47 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.5790472980563981 on epoch=93
06/04/2022 07:54:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=94
06/04/2022 07:54:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=96
06/04/2022 07:54:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=97
06/04/2022 07:54:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=98
06/04/2022 07:55:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=99
06/04/2022 07:55:02 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.5787550287550287 on epoch=99
06/04/2022 07:55:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=101
06/04/2022 07:55:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.32 on epoch=102
06/04/2022 07:55:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.30 on epoch=103
06/04/2022 07:55:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.33 on epoch=104
06/04/2022 07:55:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=106
06/04/2022 07:55:17 - INFO - __main__ - Global step 850 Train loss 0.30 Classification-F1 0.6535818685699101 on epoch=106
06/04/2022 07:55:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6497824095281722 -> 0.6535818685699101 on epoch=106, global_step=850
06/04/2022 07:55:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=107
06/04/2022 07:55:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=108
06/04/2022 07:55:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=109
06/04/2022 07:55:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=111
06/04/2022 07:55:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=112
06/04/2022 07:55:32 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.6569929369901409 on epoch=112
06/04/2022 07:55:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6535818685699101 -> 0.6569929369901409 on epoch=112, global_step=900
06/04/2022 07:55:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=113
06/04/2022 07:55:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=114
06/04/2022 07:55:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=116
06/04/2022 07:55:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=117
06/04/2022 07:55:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=118
06/04/2022 07:55:46 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.652995027490457 on epoch=118
06/04/2022 07:55:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=119
06/04/2022 07:55:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=121
06/04/2022 07:55:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=122
06/04/2022 07:55:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=123
06/04/2022 07:55:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=124
06/04/2022 07:56:01 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.6843441067724738 on epoch=124
06/04/2022 07:56:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6569929369901409 -> 0.6843441067724738 on epoch=124, global_step=1000
06/04/2022 07:56:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=126
06/04/2022 07:56:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=127
06/04/2022 07:56:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=128
06/04/2022 07:56:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=129
06/04/2022 07:56:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=131
06/04/2022 07:56:15 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.7098687498356084 on epoch=131
06/04/2022 07:56:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6843441067724738 -> 0.7098687498356084 on epoch=131, global_step=1050
06/04/2022 07:56:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=132
06/04/2022 07:56:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=133
06/04/2022 07:56:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=134
06/04/2022 07:56:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=136
06/04/2022 07:56:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=137
06/04/2022 07:56:29 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.6430482951709366 on epoch=137
06/04/2022 07:56:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=138
06/04/2022 07:56:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=139
06/04/2022 07:56:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=141
06/04/2022 07:56:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=142
06/04/2022 07:56:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=143
06/04/2022 07:56:44 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.6275361021601623 on epoch=143
06/04/2022 07:56:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=144
06/04/2022 07:56:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=146
06/04/2022 07:56:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.23 on epoch=147
06/04/2022 07:56:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=148
06/04/2022 07:56:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=149
06/04/2022 07:56:59 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7272809666946927 on epoch=149
06/04/2022 07:56:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7098687498356084 -> 0.7272809666946927 on epoch=149, global_step=1200
06/04/2022 07:57:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=151
06/04/2022 07:57:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=152
06/04/2022 07:57:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=153
06/04/2022 07:57:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=154
06/04/2022 07:57:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=156
06/04/2022 07:57:14 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.6653191878543991 on epoch=156
06/04/2022 07:57:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=157
06/04/2022 07:57:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=158
06/04/2022 07:57:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=159
06/04/2022 07:57:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=161
06/04/2022 07:57:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=162
06/04/2022 07:57:30 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.681019381868584 on epoch=162
06/04/2022 07:57:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=163
06/04/2022 07:57:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=164
06/04/2022 07:57:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=166
06/04/2022 07:57:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=167
06/04/2022 07:57:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=168
06/04/2022 07:57:45 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.6703943745165305 on epoch=168
06/04/2022 07:57:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=169
06/04/2022 07:57:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=171
06/04/2022 07:57:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=172
06/04/2022 07:57:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=173
06/04/2022 07:57:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=174
06/04/2022 07:58:00 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.695925951653237 on epoch=174
06/04/2022 07:58:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=176
06/04/2022 07:58:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=177
06/04/2022 07:58:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=178
06/04/2022 07:58:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=179
06/04/2022 07:58:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=181
06/04/2022 07:58:16 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.6955909299129639 on epoch=181
06/04/2022 07:58:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=182
06/04/2022 07:58:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=183
06/04/2022 07:58:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
06/04/2022 07:58:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=186
06/04/2022 07:58:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=187
06/04/2022 07:58:31 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7130501116178425 on epoch=187
06/04/2022 07:58:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=188
06/04/2022 07:58:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=189
06/04/2022 07:58:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=191
06/04/2022 07:58:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
06/04/2022 07:58:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=193
06/04/2022 07:58:46 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7524441169245886 on epoch=193
06/04/2022 07:58:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7272809666946927 -> 0.7524441169245886 on epoch=193, global_step=1550
06/04/2022 07:58:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=194
06/04/2022 07:58:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=196
06/04/2022 07:58:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=197
06/04/2022 07:58:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=198
06/04/2022 07:59:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=199
06/04/2022 07:59:01 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6790855493840569 on epoch=199
06/04/2022 07:59:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=201
06/04/2022 07:59:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=202
06/04/2022 07:59:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=203
06/04/2022 07:59:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=204
06/04/2022 07:59:15 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=206
06/04/2022 07:59:16 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7202526481063374 on epoch=206
06/04/2022 07:59:19 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=207
06/04/2022 07:59:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
06/04/2022 07:59:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=209
06/04/2022 07:59:27 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=211
06/04/2022 07:59:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=212
06/04/2022 07:59:32 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6581446980877721 on epoch=212
06/04/2022 07:59:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=213
06/04/2022 07:59:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
06/04/2022 07:59:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=216
06/04/2022 07:59:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=217
06/04/2022 07:59:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=218
06/04/2022 07:59:47 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7281736781736782 on epoch=218
06/04/2022 07:59:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=219
06/04/2022 07:59:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=221
06/04/2022 07:59:55 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=222
06/04/2022 07:59:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=223
06/04/2022 08:00:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=224
06/04/2022 08:00:02 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7295946736903717 on epoch=224
06/04/2022 08:00:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=226
06/04/2022 08:00:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=227
06/04/2022 08:00:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=228
06/04/2022 08:00:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=229
06/04/2022 08:00:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
06/04/2022 08:00:17 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6441310741803352 on epoch=231
06/04/2022 08:00:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=232
06/04/2022 08:00:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
06/04/2022 08:00:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
06/04/2022 08:00:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=236
06/04/2022 08:00:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=237
06/04/2022 08:00:33 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7412137435619408 on epoch=237
06/04/2022 08:00:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=238
06/04/2022 08:00:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=239
06/04/2022 08:00:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=241
06/04/2022 08:00:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
06/04/2022 08:00:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/04/2022 08:00:48 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7355272580160137 on epoch=243
06/04/2022 08:00:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=244
06/04/2022 08:00:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=246
06/04/2022 08:00:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=247
06/04/2022 08:00:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
06/04/2022 08:01:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=249
06/04/2022 08:01:04 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7184616062892055 on epoch=249
06/04/2022 08:01:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.15 on epoch=251
06/04/2022 08:01:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
06/04/2022 08:01:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
06/04/2022 08:01:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/04/2022 08:01:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=256
06/04/2022 08:01:19 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6405059382684737 on epoch=256
06/04/2022 08:01:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
06/04/2022 08:01:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=258
06/04/2022 08:01:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=259
06/04/2022 08:01:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
06/04/2022 08:01:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 08:01:34 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7026471245649327 on epoch=262
06/04/2022 08:01:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
06/04/2022 08:01:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
06/04/2022 08:01:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
06/04/2022 08:01:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=267
06/04/2022 08:01:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=268
06/04/2022 08:01:49 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6805598612158248 on epoch=268
06/04/2022 08:01:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
06/04/2022 08:01:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 08:01:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=272
06/04/2022 08:02:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=273
06/04/2022 08:02:02 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
06/04/2022 08:02:05 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7028746615703136 on epoch=274
06/04/2022 08:02:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=276
06/04/2022 08:02:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
06/04/2022 08:02:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/04/2022 08:02:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=279
06/04/2022 08:02:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
06/04/2022 08:02:20 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7408693489793565 on epoch=281
06/04/2022 08:02:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=282
06/04/2022 08:02:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/04/2022 08:02:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
06/04/2022 08:02:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
06/04/2022 08:02:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/04/2022 08:02:36 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7102462852462852 on epoch=287
06/04/2022 08:02:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=288
06/04/2022 08:02:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=289
06/04/2022 08:02:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=291
06/04/2022 08:02:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/04/2022 08:02:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/04/2022 08:02:51 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.72621261247196 on epoch=293
06/04/2022 08:02:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
06/04/2022 08:02:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=296
06/04/2022 08:02:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/04/2022 08:03:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/04/2022 08:03:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/04/2022 08:03:06 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7171567481109158 on epoch=299
06/04/2022 08:03:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=301
06/04/2022 08:03:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/04/2022 08:03:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/04/2022 08:03:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
06/04/2022 08:03:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=306
06/04/2022 08:03:22 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7005636943175216 on epoch=306
06/04/2022 08:03:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
06/04/2022 08:03:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=308
06/04/2022 08:03:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
06/04/2022 08:03:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=311
06/04/2022 08:03:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 08:03:37 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7040416696689966 on epoch=312
06/04/2022 08:03:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
06/04/2022 08:03:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 08:03:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/04/2022 08:03:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=317
06/04/2022 08:03:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
06/04/2022 08:03:52 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7352786453460758 on epoch=318
06/04/2022 08:03:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=319
06/04/2022 08:03:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=321
06/04/2022 08:04:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 08:04:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=323
06/04/2022 08:04:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
06/04/2022 08:04:07 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7392407149659366 on epoch=324
06/04/2022 08:04:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=326
06/04/2022 08:04:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 08:04:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/04/2022 08:04:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/04/2022 08:04:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=331
06/04/2022 08:04:22 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7396267461325329 on epoch=331
06/04/2022 08:04:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=332
06/04/2022 08:04:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/04/2022 08:04:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/04/2022 08:04:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=336
06/04/2022 08:04:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=337
06/04/2022 08:04:37 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7427482288632359 on epoch=337
06/04/2022 08:04:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
06/04/2022 08:04:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
06/04/2022 08:04:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/04/2022 08:04:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=342
06/04/2022 08:04:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/04/2022 08:04:53 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7109035675729959 on epoch=343
06/04/2022 08:04:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=344
06/04/2022 08:04:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=346
06/04/2022 08:05:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 08:05:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 08:05:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=349
06/04/2022 08:05:09 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7073440397596616 on epoch=349
06/04/2022 08:05:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=351
06/04/2022 08:05:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=352
06/04/2022 08:05:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 08:05:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 08:05:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/04/2022 08:05:25 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7184678897511007 on epoch=356
06/04/2022 08:05:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 08:05:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=358
06/04/2022 08:05:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 08:05:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.14 on epoch=361
06/04/2022 08:05:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
06/04/2022 08:05:40 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7337463261376305 on epoch=362
06/04/2022 08:05:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=363
06/04/2022 08:05:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 08:05:48 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/04/2022 08:05:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 08:05:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=368
06/04/2022 08:05:56 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6372305994162988 on epoch=368
06/04/2022 08:05:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=369
06/04/2022 08:06:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/04/2022 08:06:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 08:06:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/04/2022 08:06:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 08:06:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:06:11 - INFO - __main__ - Printing 3 examples
06/04/2022 08:06:11 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 08:06:11 - INFO - __main__ - ['sad']
06/04/2022 08:06:11 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 08:06:11 - INFO - __main__ - ['sad']
06/04/2022 08:06:11 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 08:06:11 - INFO - __main__ - ['sad']
06/04/2022 08:06:11 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:06:11 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:06:11 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 08:06:11 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:06:11 - INFO - __main__ - Printing 3 examples
06/04/2022 08:06:11 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 08:06:11 - INFO - __main__ - ['sad']
06/04/2022 08:06:11 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 08:06:11 - INFO - __main__ - ['sad']
06/04/2022 08:06:11 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 08:06:11 - INFO - __main__ - ['sad']
06/04/2022 08:06:11 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:06:11 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:06:11 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 08:06:11 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7174137931034482 on epoch=374
06/04/2022 08:06:11 - INFO - __main__ - save last model!
06/04/2022 08:06:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 08:06:12 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 08:06:12 - INFO - __main__ - Printing 3 examples
06/04/2022 08:06:12 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 08:06:12 - INFO - __main__ - ['others']
06/04/2022 08:06:12 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 08:06:12 - INFO - __main__ - ['others']
06/04/2022 08:06:12 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 08:06:12 - INFO - __main__ - ['others']
06/04/2022 08:06:12 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:06:14 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:06:19 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 08:06:26 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 08:06:26 - INFO - __main__ - task name: emo
06/04/2022 08:06:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 08:06:27 - INFO - __main__ - Starting training!
06/04/2022 08:07:53 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_21_0.3_8_predictions.txt
06/04/2022 08:07:53 - INFO - __main__ - Classification-F1 on test data: 0.4444
06/04/2022 08:07:53 - INFO - __main__ - prefix=emo_32_21, lr=0.3, bsz=8, dev_performance=0.7524441169245886, test_performance=0.4444226403595258
06/04/2022 08:07:53 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.2, bsz=8 ...
06/04/2022 08:07:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:07:54 - INFO - __main__ - Printing 3 examples
06/04/2022 08:07:54 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/04/2022 08:07:54 - INFO - __main__ - ['sad']
06/04/2022 08:07:54 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/04/2022 08:07:54 - INFO - __main__ - ['sad']
06/04/2022 08:07:54 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/04/2022 08:07:54 - INFO - __main__ - ['sad']
06/04/2022 08:07:54 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:07:54 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:07:54 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 08:07:54 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:07:54 - INFO - __main__ - Printing 3 examples
06/04/2022 08:07:54 - INFO - __main__ -  [emo] i am not ok why  down with fever
06/04/2022 08:07:54 - INFO - __main__ - ['sad']
06/04/2022 08:07:54 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
06/04/2022 08:07:54 - INFO - __main__ - ['sad']
06/04/2022 08:07:54 - INFO - __main__ -  [emo] o go to hell how are u  miserable
06/04/2022 08:07:54 - INFO - __main__ - ['sad']
06/04/2022 08:07:54 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:07:54 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:07:55 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 08:08:14 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 08:08:14 - INFO - __main__ - task name: emo
06/04/2022 08:08:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 08:08:15 - INFO - __main__ - Starting training!
06/04/2022 08:08:19 - INFO - __main__ - Step 10 Global step 10 Train loss 7.63 on epoch=1
06/04/2022 08:08:21 - INFO - __main__ - Step 20 Global step 20 Train loss 5.29 on epoch=2
06/04/2022 08:08:24 - INFO - __main__ - Step 30 Global step 30 Train loss 3.05 on epoch=3
06/04/2022 08:08:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.94 on epoch=4
06/04/2022 08:08:29 - INFO - __main__ - Step 50 Global step 50 Train loss 1.51 on epoch=6
06/04/2022 08:08:31 - INFO - __main__ - Global step 50 Train loss 3.88 Classification-F1 0.1 on epoch=6
06/04/2022 08:08:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/04/2022 08:08:34 - INFO - __main__ - Step 60 Global step 60 Train loss 1.22 on epoch=7
06/04/2022 08:08:36 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=8
06/04/2022 08:08:39 - INFO - __main__ - Step 80 Global step 80 Train loss 1.10 on epoch=9
06/04/2022 08:08:42 - INFO - __main__ - Step 90 Global step 90 Train loss 1.03 on epoch=11
06/04/2022 08:08:44 - INFO - __main__ - Step 100 Global step 100 Train loss 1.06 on epoch=12
06/04/2022 08:08:46 - INFO - __main__ - Global step 100 Train loss 1.12 Classification-F1 0.1 on epoch=12
06/04/2022 08:08:49 - INFO - __main__ - Step 110 Global step 110 Train loss 1.04 on epoch=13
06/04/2022 08:08:51 - INFO - __main__ - Step 120 Global step 120 Train loss 1.07 on epoch=14
06/04/2022 08:08:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.96 on epoch=16
06/04/2022 08:08:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.95 on epoch=17
06/04/2022 08:08:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.98 on epoch=18
06/04/2022 08:09:01 - INFO - __main__ - Global step 150 Train loss 1.00 Classification-F1 0.1392343724761751 on epoch=18
06/04/2022 08:09:01 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1392343724761751 on epoch=18, global_step=150
06/04/2022 08:09:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.87 on epoch=19
06/04/2022 08:09:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=21
06/04/2022 08:09:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=22
06/04/2022 08:09:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=23
06/04/2022 08:09:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=24
06/04/2022 08:09:16 - INFO - __main__ - Global step 200 Train loss 0.90 Classification-F1 0.24888940846387653 on epoch=24
06/04/2022 08:09:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1392343724761751 -> 0.24888940846387653 on epoch=24, global_step=200
06/04/2022 08:09:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.86 on epoch=26
06/04/2022 08:09:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.86 on epoch=27
06/04/2022 08:09:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.93 on epoch=28
06/04/2022 08:09:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.88 on epoch=29
06/04/2022 08:09:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.90 on epoch=31
06/04/2022 08:09:31 - INFO - __main__ - Global step 250 Train loss 0.89 Classification-F1 0.11578044596912522 on epoch=31
06/04/2022 08:09:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=32
06/04/2022 08:09:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.89 on epoch=33
06/04/2022 08:09:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.78 on epoch=34
06/04/2022 08:09:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.87 on epoch=36
06/04/2022 08:09:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.89 on epoch=37
06/04/2022 08:09:46 - INFO - __main__ - Global step 300 Train loss 0.85 Classification-F1 0.1 on epoch=37
06/04/2022 08:09:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.83 on epoch=38
06/04/2022 08:09:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.89 on epoch=39
06/04/2022 08:09:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.77 on epoch=41
06/04/2022 08:09:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.87 on epoch=42
06/04/2022 08:10:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.84 on epoch=43
06/04/2022 08:10:01 - INFO - __main__ - Global step 350 Train loss 0.84 Classification-F1 0.38167344865198705 on epoch=43
06/04/2022 08:10:01 - INFO - __main__ - Saving model with best Classification-F1: 0.24888940846387653 -> 0.38167344865198705 on epoch=43, global_step=350
06/04/2022 08:10:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.86 on epoch=44
06/04/2022 08:10:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.74 on epoch=46
06/04/2022 08:10:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.89 on epoch=47
06/04/2022 08:10:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.78 on epoch=48
06/04/2022 08:10:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.83 on epoch=49
06/04/2022 08:10:16 - INFO - __main__ - Global step 400 Train loss 0.82 Classification-F1 0.44420132610006025 on epoch=49
06/04/2022 08:10:16 - INFO - __main__ - Saving model with best Classification-F1: 0.38167344865198705 -> 0.44420132610006025 on epoch=49, global_step=400
06/04/2022 08:10:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.78 on epoch=51
06/04/2022 08:10:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.76 on epoch=52
06/04/2022 08:10:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.80 on epoch=53
06/04/2022 08:10:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.68 on epoch=54
06/04/2022 08:10:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.74 on epoch=56
06/04/2022 08:10:31 - INFO - __main__ - Global step 450 Train loss 0.75 Classification-F1 0.31288230552936436 on epoch=56
06/04/2022 08:10:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.79 on epoch=57
06/04/2022 08:10:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.70 on epoch=58
06/04/2022 08:10:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.72 on epoch=59
06/04/2022 08:10:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.75 on epoch=61
06/04/2022 08:10:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.75 on epoch=62
06/04/2022 08:10:46 - INFO - __main__ - Global step 500 Train loss 0.74 Classification-F1 0.5024596431605778 on epoch=62
06/04/2022 08:10:46 - INFO - __main__ - Saving model with best Classification-F1: 0.44420132610006025 -> 0.5024596431605778 on epoch=62, global_step=500
06/04/2022 08:10:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.67 on epoch=63
06/04/2022 08:10:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.61 on epoch=64
06/04/2022 08:10:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.63 on epoch=66
06/04/2022 08:10:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.67 on epoch=67
06/04/2022 08:10:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.70 on epoch=68
06/04/2022 08:11:00 - INFO - __main__ - Global step 550 Train loss 0.66 Classification-F1 0.6357700270743748 on epoch=68
06/04/2022 08:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5024596431605778 -> 0.6357700270743748 on epoch=68, global_step=550
06/04/2022 08:11:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.68 on epoch=69
06/04/2022 08:11:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.58 on epoch=71
06/04/2022 08:11:08 - INFO - __main__ - Step 580 Global step 580 Train loss 0.62 on epoch=72
06/04/2022 08:11:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.64 on epoch=73
06/04/2022 08:11:13 - INFO - __main__ - Step 600 Global step 600 Train loss 0.52 on epoch=74
06/04/2022 08:11:15 - INFO - __main__ - Global step 600 Train loss 0.61 Classification-F1 0.5278951148525353 on epoch=74
06/04/2022 08:11:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.56 on epoch=76
06/04/2022 08:11:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.54 on epoch=77
06/04/2022 08:11:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.68 on epoch=78
06/04/2022 08:11:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.49 on epoch=79
06/04/2022 08:11:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.50 on epoch=81
06/04/2022 08:11:30 - INFO - __main__ - Global step 650 Train loss 0.55 Classification-F1 0.5714719984656694 on epoch=81
06/04/2022 08:11:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.49 on epoch=82
06/04/2022 08:11:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.46 on epoch=83
06/04/2022 08:11:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.43 on epoch=84
06/04/2022 08:11:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.44 on epoch=86
06/04/2022 08:11:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.48 on epoch=87
06/04/2022 08:11:45 - INFO - __main__ - Global step 700 Train loss 0.46 Classification-F1 0.5909412972935653 on epoch=87
06/04/2022 08:11:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.41 on epoch=88
06/04/2022 08:11:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=89
06/04/2022 08:11:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.36 on epoch=91
06/04/2022 08:11:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.43 on epoch=92
06/04/2022 08:11:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.51 on epoch=93
06/04/2022 08:11:59 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.6349941011780036 on epoch=93
06/04/2022 08:12:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=94
06/04/2022 08:12:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.45 on epoch=96
06/04/2022 08:12:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.48 on epoch=97
06/04/2022 08:12:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.37 on epoch=98
06/04/2022 08:12:12 - INFO - __main__ - Step 800 Global step 800 Train loss 0.40 on epoch=99
06/04/2022 08:12:14 - INFO - __main__ - Global step 800 Train loss 0.41 Classification-F1 0.5964596696877748 on epoch=99
06/04/2022 08:12:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.34 on epoch=101
06/04/2022 08:12:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.46 on epoch=102
06/04/2022 08:12:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.39 on epoch=103
06/04/2022 08:12:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.30 on epoch=104
06/04/2022 08:12:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.32 on epoch=106
06/04/2022 08:12:28 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.6299002435024748 on epoch=106
06/04/2022 08:12:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.37 on epoch=107
06/04/2022 08:12:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.43 on epoch=108
06/04/2022 08:12:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.43 on epoch=109
06/04/2022 08:12:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.35 on epoch=111
06/04/2022 08:12:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.37 on epoch=112
06/04/2022 08:12:43 - INFO - __main__ - Global step 900 Train loss 0.39 Classification-F1 0.6363562091503268 on epoch=112
06/04/2022 08:12:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6357700270743748 -> 0.6363562091503268 on epoch=112, global_step=900
06/04/2022 08:12:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.33 on epoch=113
06/04/2022 08:12:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=114
06/04/2022 08:12:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.37 on epoch=116
06/04/2022 08:12:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.34 on epoch=117
06/04/2022 08:12:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=118
06/04/2022 08:12:57 - INFO - __main__ - Global step 950 Train loss 0.33 Classification-F1 0.6435056782514409 on epoch=118
06/04/2022 08:12:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6363562091503268 -> 0.6435056782514409 on epoch=118, global_step=950
06/04/2022 08:13:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.33 on epoch=119
06/04/2022 08:13:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.30 on epoch=121
06/04/2022 08:13:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.34 on epoch=122
06/04/2022 08:13:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=123
06/04/2022 08:13:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=124
06/04/2022 08:13:12 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.6645047178701109 on epoch=124
06/04/2022 08:13:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6435056782514409 -> 0.6645047178701109 on epoch=124, global_step=1000
06/04/2022 08:13:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=126
06/04/2022 08:13:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.31 on epoch=127
06/04/2022 08:13:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.24 on epoch=128
06/04/2022 08:13:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.24 on epoch=129
06/04/2022 08:13:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.30 on epoch=131
06/04/2022 08:13:26 - INFO - __main__ - Global step 1050 Train loss 0.26 Classification-F1 0.6664619969217671 on epoch=131
06/04/2022 08:13:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6645047178701109 -> 0.6664619969217671 on epoch=131, global_step=1050
06/04/2022 08:13:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.41 on epoch=132
06/04/2022 08:13:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=133
06/04/2022 08:13:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=134
06/04/2022 08:13:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.29 on epoch=136
06/04/2022 08:13:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=137
06/04/2022 08:13:41 - INFO - __main__ - Global step 1100 Train loss 0.29 Classification-F1 0.6669408265212863 on epoch=137
06/04/2022 08:13:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6664619969217671 -> 0.6669408265212863 on epoch=137, global_step=1100
06/04/2022 08:13:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=138
06/04/2022 08:13:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=139
06/04/2022 08:13:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=141
06/04/2022 08:13:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.27 on epoch=142
06/04/2022 08:13:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=143
06/04/2022 08:13:56 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.6661543715846994 on epoch=143
06/04/2022 08:13:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=144
06/04/2022 08:14:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=146
06/04/2022 08:14:03 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=147
06/04/2022 08:14:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=148
06/04/2022 08:14:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=149
06/04/2022 08:14:11 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.6283838447932613 on epoch=149
06/04/2022 08:14:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.27 on epoch=151
06/04/2022 08:14:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.21 on epoch=152
06/04/2022 08:14:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=153
06/04/2022 08:14:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.26 on epoch=154
06/04/2022 08:14:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.24 on epoch=156
06/04/2022 08:14:25 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.6448744082572367 on epoch=156
06/04/2022 08:14:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=157
06/04/2022 08:14:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.26 on epoch=158
06/04/2022 08:14:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=159
06/04/2022 08:14:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.19 on epoch=161
06/04/2022 08:14:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=162
06/04/2022 08:14:40 - INFO - __main__ - Global step 1300 Train loss 0.19 Classification-F1 0.6642534697494817 on epoch=162
06/04/2022 08:14:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=163
06/04/2022 08:14:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=164
06/04/2022 08:14:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=166
06/04/2022 08:14:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.20 on epoch=167
06/04/2022 08:14:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=168
06/04/2022 08:14:55 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6798194701609457 on epoch=168
06/04/2022 08:14:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6669408265212863 -> 0.6798194701609457 on epoch=168, global_step=1350
06/04/2022 08:14:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=169
06/04/2022 08:15:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=171
06/04/2022 08:15:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=172
06/04/2022 08:15:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=173
06/04/2022 08:15:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.22 on epoch=174
06/04/2022 08:15:09 - INFO - __main__ - Global step 1400 Train loss 0.17 Classification-F1 0.669752302763419 on epoch=174
06/04/2022 08:15:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=176
06/04/2022 08:15:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=177
06/04/2022 08:15:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=178
06/04/2022 08:15:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=179
06/04/2022 08:15:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=181
06/04/2022 08:15:24 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.7027290448343081 on epoch=181
06/04/2022 08:15:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6798194701609457 -> 0.7027290448343081 on epoch=181, global_step=1450
06/04/2022 08:15:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=182
06/04/2022 08:15:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.18 on epoch=183
06/04/2022 08:15:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=184
06/04/2022 08:15:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=186
06/04/2022 08:15:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=187
06/04/2022 08:15:38 - INFO - __main__ - Global step 1500 Train loss 0.16 Classification-F1 0.6740904106858054 on epoch=187
06/04/2022 08:15:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=188
06/04/2022 08:15:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.17 on epoch=189
06/04/2022 08:15:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=191
06/04/2022 08:15:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=192
06/04/2022 08:15:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.22 on epoch=193
06/04/2022 08:15:53 - INFO - __main__ - Global step 1550 Train loss 0.15 Classification-F1 0.6628540305010893 on epoch=193
06/04/2022 08:15:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=194
06/04/2022 08:15:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=196
06/04/2022 08:16:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=197
06/04/2022 08:16:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=198
06/04/2022 08:16:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=199
06/04/2022 08:16:07 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.6873083523000328 on epoch=199
06/04/2022 08:16:10 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=201
06/04/2022 08:16:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=202
06/04/2022 08:16:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=203
06/04/2022 08:16:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=204
06/04/2022 08:16:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=206
06/04/2022 08:16:22 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.7041317867393687 on epoch=206
06/04/2022 08:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7027290448343081 -> 0.7041317867393687 on epoch=206, global_step=1650
06/04/2022 08:16:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=207
06/04/2022 08:16:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=208
06/04/2022 08:16:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
06/04/2022 08:16:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=211
06/04/2022 08:16:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=212
06/04/2022 08:16:37 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6954834240527275 on epoch=212
06/04/2022 08:16:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=213
06/04/2022 08:16:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=214
06/04/2022 08:16:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=216
06/04/2022 08:16:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=217
06/04/2022 08:16:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=218
06/04/2022 08:16:52 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6978854183466838 on epoch=218
06/04/2022 08:16:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=219
06/04/2022 08:16:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=221
06/04/2022 08:17:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=222
06/04/2022 08:17:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=223
06/04/2022 08:17:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=224
06/04/2022 08:17:07 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.6512429971988796 on epoch=224
06/04/2022 08:17:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=226
06/04/2022 08:17:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=227
06/04/2022 08:17:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=228
06/04/2022 08:17:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=229
06/04/2022 08:17:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
06/04/2022 08:17:22 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.718907397241474 on epoch=231
06/04/2022 08:17:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7041317867393687 -> 0.718907397241474 on epoch=231, global_step=1850
06/04/2022 08:17:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=232
06/04/2022 08:17:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=233
06/04/2022 08:17:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=234
06/04/2022 08:17:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=236
06/04/2022 08:17:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=237
06/04/2022 08:17:37 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6909707139754463 on epoch=237
06/04/2022 08:17:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=238
06/04/2022 08:17:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=239
06/04/2022 08:17:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=241
06/04/2022 08:17:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=242
06/04/2022 08:17:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.16 on epoch=243
06/04/2022 08:17:52 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.6570485589775515 on epoch=243
06/04/2022 08:17:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=244
06/04/2022 08:17:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=246
06/04/2022 08:18:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
06/04/2022 08:18:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.14 on epoch=248
06/04/2022 08:18:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=249
06/04/2022 08:18:07 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.6808555757087972 on epoch=249
06/04/2022 08:18:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=251
06/04/2022 08:18:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=252
06/04/2022 08:18:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=253
06/04/2022 08:18:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
06/04/2022 08:18:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=256
06/04/2022 08:18:23 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6956210192064238 on epoch=256
06/04/2022 08:18:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=257
06/04/2022 08:18:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=258
06/04/2022 08:18:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=259
06/04/2022 08:18:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=261
06/04/2022 08:18:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 08:18:38 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7255130308000729 on epoch=262
06/04/2022 08:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.718907397241474 -> 0.7255130308000729 on epoch=262, global_step=2100
06/04/2022 08:18:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=263
06/04/2022 08:18:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
06/04/2022 08:18:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=266
06/04/2022 08:18:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=267
06/04/2022 08:18:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
06/04/2022 08:18:54 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6880133001351283 on epoch=268
06/04/2022 08:18:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
06/04/2022 08:18:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=271
06/04/2022 08:19:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=272
06/04/2022 08:19:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
06/04/2022 08:19:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=274
06/04/2022 08:19:10 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6800265625847021 on epoch=274
06/04/2022 08:19:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=276
06/04/2022 08:19:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=277
06/04/2022 08:19:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/04/2022 08:19:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=279
06/04/2022 08:19:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=281
06/04/2022 08:19:26 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7721026562636977 on epoch=281
06/04/2022 08:19:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7255130308000729 -> 0.7721026562636977 on epoch=281, global_step=2250
06/04/2022 08:19:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=282
06/04/2022 08:19:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=283
06/04/2022 08:19:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=284
06/04/2022 08:19:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
06/04/2022 08:19:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=287
06/04/2022 08:19:41 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7107583774250441 on epoch=287
06/04/2022 08:19:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=288
06/04/2022 08:19:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=289
06/04/2022 08:19:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=291
06/04/2022 08:19:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
06/04/2022 08:19:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
06/04/2022 08:19:57 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6950622037020261 on epoch=293
06/04/2022 08:19:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=294
06/04/2022 08:20:02 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/04/2022 08:20:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/04/2022 08:20:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=298
06/04/2022 08:20:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=299
06/04/2022 08:20:12 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7028414234897502 on epoch=299
06/04/2022 08:20:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
06/04/2022 08:20:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=302
06/04/2022 08:20:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.11 on epoch=303
06/04/2022 08:20:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=304
06/04/2022 08:20:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=306
06/04/2022 08:20:28 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7409482577183879 on epoch=306
06/04/2022 08:20:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/04/2022 08:20:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=308
06/04/2022 08:20:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=309
06/04/2022 08:20:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=311
06/04/2022 08:20:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=312
06/04/2022 08:20:44 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7081925352037153 on epoch=312
06/04/2022 08:20:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/04/2022 08:20:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=314
06/04/2022 08:20:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=316
06/04/2022 08:20:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=317
06/04/2022 08:20:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=318
06/04/2022 08:21:00 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6763277957133889 on epoch=318
06/04/2022 08:21:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
06/04/2022 08:21:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
06/04/2022 08:21:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.11 on epoch=322
06/04/2022 08:21:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
06/04/2022 08:21:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=324
06/04/2022 08:21:16 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6788653523589591 on epoch=324
06/04/2022 08:21:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
06/04/2022 08:21:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=327
06/04/2022 08:21:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=328
06/04/2022 08:21:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=329
06/04/2022 08:21:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=331
06/04/2022 08:21:31 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7242345697195859 on epoch=331
06/04/2022 08:21:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
06/04/2022 08:21:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/04/2022 08:21:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/04/2022 08:21:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=336
06/04/2022 08:21:45 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=337
06/04/2022 08:21:47 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7215510060586461 on epoch=337
06/04/2022 08:21:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 08:21:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
06/04/2022 08:21:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
06/04/2022 08:21:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/04/2022 08:22:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/04/2022 08:22:03 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6941280566280567 on epoch=343
06/04/2022 08:22:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/04/2022 08:22:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
06/04/2022 08:22:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
06/04/2022 08:22:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=348
06/04/2022 08:22:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=349
06/04/2022 08:22:19 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.6971677559912854 on epoch=349
06/04/2022 08:22:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/04/2022 08:22:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/04/2022 08:22:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 08:22:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
06/04/2022 08:22:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/04/2022 08:22:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6708256565402788 on epoch=356
06/04/2022 08:22:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/04/2022 08:22:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/04/2022 08:22:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=359
06/04/2022 08:22:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/04/2022 08:22:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/04/2022 08:22:50 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6339401276689411 on epoch=362
06/04/2022 08:22:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/04/2022 08:22:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 08:22:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=366
06/04/2022 08:23:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 08:23:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=368
06/04/2022 08:23:05 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6625425245178451 on epoch=368
06/04/2022 08:23:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=369
06/04/2022 08:23:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/04/2022 08:23:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.09 on epoch=372
06/04/2022 08:23:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/04/2022 08:23:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 08:23:20 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:23:20 - INFO - __main__ - Printing 3 examples
06/04/2022 08:23:20 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 08:23:20 - INFO - __main__ - ['happy']
06/04/2022 08:23:20 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 08:23:20 - INFO - __main__ - ['happy']
06/04/2022 08:23:20 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 08:23:20 - INFO - __main__ - ['happy']
06/04/2022 08:23:20 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:23:20 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:23:20 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 08:23:20 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:23:20 - INFO - __main__ - Printing 3 examples
06/04/2022 08:23:20 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 08:23:20 - INFO - __main__ - ['happy']
06/04/2022 08:23:20 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 08:23:20 - INFO - __main__ - ['happy']
06/04/2022 08:23:20 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 08:23:20 - INFO - __main__ - ['happy']
06/04/2022 08:23:20 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:23:20 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:23:20 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 08:23:21 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7040491984521835 on epoch=374
06/04/2022 08:23:21 - INFO - __main__ - save last model!
06/04/2022 08:23:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 08:23:21 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 08:23:21 - INFO - __main__ - Printing 3 examples
06/04/2022 08:23:21 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 08:23:21 - INFO - __main__ - ['others']
06/04/2022 08:23:21 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 08:23:21 - INFO - __main__ - ['others']
06/04/2022 08:23:21 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 08:23:21 - INFO - __main__ - ['others']
06/04/2022 08:23:21 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:23:23 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:23:28 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 08:23:39 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 08:23:39 - INFO - __main__ - task name: emo
06/04/2022 08:23:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 08:23:40 - INFO - __main__ - Starting training!
06/04/2022 08:25:02 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_21_0.2_8_predictions.txt
06/04/2022 08:25:02 - INFO - __main__ - Classification-F1 on test data: 0.4279
06/04/2022 08:25:03 - INFO - __main__ - prefix=emo_32_21, lr=0.2, bsz=8, dev_performance=0.7721026562636977, test_performance=0.4278552879254194
06/04/2022 08:25:03 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.5, bsz=8 ...
06/04/2022 08:25:04 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:25:04 - INFO - __main__ - Printing 3 examples
06/04/2022 08:25:04 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 08:25:04 - INFO - __main__ - ['happy']
06/04/2022 08:25:04 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 08:25:04 - INFO - __main__ - ['happy']
06/04/2022 08:25:04 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 08:25:04 - INFO - __main__ - ['happy']
06/04/2022 08:25:04 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:25:04 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:25:04 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 08:25:04 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:25:04 - INFO - __main__ - Printing 3 examples
06/04/2022 08:25:04 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 08:25:04 - INFO - __main__ - ['happy']
06/04/2022 08:25:04 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 08:25:04 - INFO - __main__ - ['happy']
06/04/2022 08:25:04 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 08:25:04 - INFO - __main__ - ['happy']
06/04/2022 08:25:04 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:25:04 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:25:04 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 08:25:23 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 08:25:23 - INFO - __main__ - task name: emo
06/04/2022 08:25:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 08:25:24 - INFO - __main__ - Starting training!
06/04/2022 08:25:26 - INFO - __main__ - Step 10 Global step 10 Train loss 6.06 on epoch=1
06/04/2022 08:25:29 - INFO - __main__ - Step 20 Global step 20 Train loss 2.17 on epoch=2
06/04/2022 08:25:32 - INFO - __main__ - Step 30 Global step 30 Train loss 1.16 on epoch=3
06/04/2022 08:25:35 - INFO - __main__ - Step 40 Global step 40 Train loss 1.09 on epoch=4
06/04/2022 08:25:37 - INFO - __main__ - Step 50 Global step 50 Train loss 1.15 on epoch=6
06/04/2022 08:25:39 - INFO - __main__ - Global step 50 Train loss 2.33 Classification-F1 0.1 on epoch=6
06/04/2022 08:25:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/04/2022 08:25:42 - INFO - __main__ - Step 60 Global step 60 Train loss 0.93 on epoch=7
06/04/2022 08:25:44 - INFO - __main__ - Step 70 Global step 70 Train loss 0.97 on epoch=8
06/04/2022 08:25:47 - INFO - __main__ - Step 80 Global step 80 Train loss 1.02 on epoch=9
06/04/2022 08:25:50 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=11
06/04/2022 08:25:52 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=12
06/04/2022 08:25:54 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.1 on epoch=12
06/04/2022 08:25:57 - INFO - __main__ - Step 110 Global step 110 Train loss 0.87 on epoch=13
06/04/2022 08:25:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=14
06/04/2022 08:26:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=16
06/04/2022 08:26:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=17
06/04/2022 08:26:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=18
06/04/2022 08:26:09 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.18131185372564684 on epoch=18
06/04/2022 08:26:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.18131185372564684 on epoch=18, global_step=150
06/04/2022 08:26:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=19
06/04/2022 08:26:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=21
06/04/2022 08:26:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.81 on epoch=22
06/04/2022 08:26:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.81 on epoch=23
06/04/2022 08:26:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=24
06/04/2022 08:26:24 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.20399047051816557 on epoch=24
06/04/2022 08:26:24 - INFO - __main__ - Saving model with best Classification-F1: 0.18131185372564684 -> 0.20399047051816557 on epoch=24, global_step=200
06/04/2022 08:26:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.78 on epoch=26
06/04/2022 08:26:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=27
06/04/2022 08:26:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.82 on epoch=28
06/04/2022 08:26:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=29
06/04/2022 08:26:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=31
06/04/2022 08:26:38 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.37771189396581795 on epoch=31
06/04/2022 08:26:38 - INFO - __main__ - Saving model with best Classification-F1: 0.20399047051816557 -> 0.37771189396581795 on epoch=31, global_step=250
06/04/2022 08:26:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=32
06/04/2022 08:26:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=33
06/04/2022 08:26:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.73 on epoch=34
06/04/2022 08:26:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.74 on epoch=36
06/04/2022 08:26:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=37
06/04/2022 08:26:53 - INFO - __main__ - Global step 300 Train loss 0.70 Classification-F1 0.3182765511990864 on epoch=37
06/04/2022 08:26:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.58 on epoch=38
06/04/2022 08:26:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.58 on epoch=39
06/04/2022 08:27:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=41
06/04/2022 08:27:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=42
06/04/2022 08:27:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=43
06/04/2022 08:27:08 - INFO - __main__ - Global step 350 Train loss 0.60 Classification-F1 0.4162240289069557 on epoch=43
06/04/2022 08:27:08 - INFO - __main__ - Saving model with best Classification-F1: 0.37771189396581795 -> 0.4162240289069557 on epoch=43, global_step=350
06/04/2022 08:27:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=44
06/04/2022 08:27:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.58 on epoch=46
06/04/2022 08:27:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=47
06/04/2022 08:27:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.55 on epoch=48
06/04/2022 08:27:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=49
06/04/2022 08:27:23 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.4572456914670029 on epoch=49
06/04/2022 08:27:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4162240289069557 -> 0.4572456914670029 on epoch=49, global_step=400
06/04/2022 08:27:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=51
06/04/2022 08:27:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.48 on epoch=52
06/04/2022 08:27:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=53
06/04/2022 08:27:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=54
06/04/2022 08:27:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=56
06/04/2022 08:27:38 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.5617201146729638 on epoch=56
06/04/2022 08:27:38 - INFO - __main__ - Saving model with best Classification-F1: 0.4572456914670029 -> 0.5617201146729638 on epoch=56, global_step=450
06/04/2022 08:27:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=57
06/04/2022 08:27:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=58
06/04/2022 08:27:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=59
06/04/2022 08:27:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=61
06/04/2022 08:27:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=62
06/04/2022 08:27:53 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.5395392224158262 on epoch=62
06/04/2022 08:27:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=63
06/04/2022 08:27:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=64
06/04/2022 08:28:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=66
06/04/2022 08:28:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=67
06/04/2022 08:28:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=68
06/04/2022 08:28:08 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.6517767102248034 on epoch=68
06/04/2022 08:28:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5617201146729638 -> 0.6517767102248034 on epoch=68, global_step=550
06/04/2022 08:28:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=69
06/04/2022 08:28:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=71
06/04/2022 08:28:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=72
06/04/2022 08:28:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=73
06/04/2022 08:28:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=74
06/04/2022 08:28:22 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.5961067548803398 on epoch=74
06/04/2022 08:28:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=76
06/04/2022 08:28:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=77
06/04/2022 08:28:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=78
06/04/2022 08:28:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=79
06/04/2022 08:28:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=81
06/04/2022 08:28:37 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.6587308869392305 on epoch=81
06/04/2022 08:28:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6517767102248034 -> 0.6587308869392305 on epoch=81, global_step=650
06/04/2022 08:28:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=82
06/04/2022 08:28:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=83
06/04/2022 08:28:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=84
06/04/2022 08:28:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=86
06/04/2022 08:28:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=87
06/04/2022 08:28:53 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.6187542061751454 on epoch=87
06/04/2022 08:28:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=88
06/04/2022 08:28:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=89
06/04/2022 08:29:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=91
06/04/2022 08:29:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=92
06/04/2022 08:29:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=93
06/04/2022 08:29:08 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6997431140288284 on epoch=93
06/04/2022 08:29:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6587308869392305 -> 0.6997431140288284 on epoch=93, global_step=750
06/04/2022 08:29:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=94
06/04/2022 08:29:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=96
06/04/2022 08:29:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=97
06/04/2022 08:29:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=98
06/04/2022 08:29:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=99
06/04/2022 08:29:23 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.7123697670572671 on epoch=99
06/04/2022 08:29:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6997431140288284 -> 0.7123697670572671 on epoch=99, global_step=800
06/04/2022 08:29:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=101
06/04/2022 08:29:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=102
06/04/2022 08:29:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=103
06/04/2022 08:29:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=104
06/04/2022 08:29:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=106
06/04/2022 08:29:38 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6632122831705207 on epoch=106
06/04/2022 08:29:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=107
06/04/2022 08:29:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=108
06/04/2022 08:29:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=109
06/04/2022 08:29:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=111
06/04/2022 08:29:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=112
06/04/2022 08:29:53 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.688798036270934 on epoch=112
06/04/2022 08:29:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=113
06/04/2022 08:29:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=114
06/04/2022 08:30:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=116
06/04/2022 08:30:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=117
06/04/2022 08:30:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=118
06/04/2022 08:30:09 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6986700502490502 on epoch=118
06/04/2022 08:30:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=119
06/04/2022 08:30:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=121
06/04/2022 08:30:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=122
06/04/2022 08:30:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=123
06/04/2022 08:30:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=124
06/04/2022 08:30:24 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7034846328781581 on epoch=124
06/04/2022 08:30:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=126
06/04/2022 08:30:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=127
06/04/2022 08:30:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=128
06/04/2022 08:30:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=129
06/04/2022 08:30:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=131
06/04/2022 08:30:40 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6546806086981921 on epoch=131
06/04/2022 08:30:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=132
06/04/2022 08:30:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=133
06/04/2022 08:30:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=134
06/04/2022 08:30:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=136
06/04/2022 08:30:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=137
06/04/2022 08:30:55 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7283467572622819 on epoch=137
06/04/2022 08:30:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7123697670572671 -> 0.7283467572622819 on epoch=137, global_step=1100
06/04/2022 08:30:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=138
06/04/2022 08:31:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=139
06/04/2022 08:31:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=141
06/04/2022 08:31:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=142
06/04/2022 08:31:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=143
06/04/2022 08:31:10 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6837931781480169 on epoch=143
06/04/2022 08:31:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=144
06/04/2022 08:31:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=146
06/04/2022 08:31:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=147
06/04/2022 08:31:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=148
06/04/2022 08:31:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=149
06/04/2022 08:31:26 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.7096006810091317 on epoch=149
06/04/2022 08:31:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=151
06/04/2022 08:31:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=152
06/04/2022 08:31:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=153
06/04/2022 08:31:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=154
06/04/2022 08:31:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=156
06/04/2022 08:31:41 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7094641749379652 on epoch=156
06/04/2022 08:31:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=157
06/04/2022 08:31:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=158
06/04/2022 08:31:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=159
06/04/2022 08:31:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
06/04/2022 08:31:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=162
06/04/2022 08:31:57 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7024733169129721 on epoch=162
06/04/2022 08:31:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=163
06/04/2022 08:32:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=164
06/04/2022 08:32:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=166
06/04/2022 08:32:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=167
06/04/2022 08:32:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=168
06/04/2022 08:32:12 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7032783975659229 on epoch=168
06/04/2022 08:32:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=169
06/04/2022 08:32:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=171
06/04/2022 08:32:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=172
06/04/2022 08:32:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=173
06/04/2022 08:32:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=174
06/04/2022 08:32:28 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7259021165272597 on epoch=174
06/04/2022 08:32:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=176
06/04/2022 08:32:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=177
06/04/2022 08:32:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=178
06/04/2022 08:32:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=179
06/04/2022 08:32:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=181
06/04/2022 08:32:44 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6699724072018745 on epoch=181
06/04/2022 08:32:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=182
06/04/2022 08:32:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=183
06/04/2022 08:32:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=184
06/04/2022 08:32:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=186
06/04/2022 08:32:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=187
06/04/2022 08:32:59 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6838383621721711 on epoch=187
06/04/2022 08:33:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=188
06/04/2022 08:33:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=189
06/04/2022 08:33:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=191
06/04/2022 08:33:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=192
06/04/2022 08:33:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=193
06/04/2022 08:33:16 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.6696888948974896 on epoch=193
06/04/2022 08:33:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=194
06/04/2022 08:33:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=196
06/04/2022 08:33:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=197
06/04/2022 08:33:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=198
06/04/2022 08:33:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=199
06/04/2022 08:33:31 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7102647782365024 on epoch=199
06/04/2022 08:33:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=201
06/04/2022 08:33:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=202
06/04/2022 08:33:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=203
06/04/2022 08:33:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=204
06/04/2022 08:33:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=206
06/04/2022 08:33:47 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6967252596434275 on epoch=206
06/04/2022 08:33:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=207
06/04/2022 08:33:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
06/04/2022 08:33:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=209
06/04/2022 08:33:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=211
06/04/2022 08:34:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
06/04/2022 08:34:02 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7008523592085236 on epoch=212
06/04/2022 08:34:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=213
06/04/2022 08:34:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
06/04/2022 08:34:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=216
06/04/2022 08:34:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=217
06/04/2022 08:34:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=218
06/04/2022 08:34:18 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7096009389671362 on epoch=218
06/04/2022 08:34:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
06/04/2022 08:34:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=221
06/04/2022 08:34:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
06/04/2022 08:34:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=223
06/04/2022 08:34:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
06/04/2022 08:34:34 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7138541666666667 on epoch=224
06/04/2022 08:34:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=226
06/04/2022 08:34:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=227
06/04/2022 08:34:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=228
06/04/2022 08:34:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=229
06/04/2022 08:34:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=231
06/04/2022 08:34:49 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7071400614773661 on epoch=231
06/04/2022 08:34:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=232
06/04/2022 08:34:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
06/04/2022 08:34:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
06/04/2022 08:34:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=236
06/04/2022 08:35:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/04/2022 08:35:04 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7164206442467311 on epoch=237
06/04/2022 08:35:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
06/04/2022 08:35:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
06/04/2022 08:35:11 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=241
06/04/2022 08:35:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
06/04/2022 08:35:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=243
06/04/2022 08:35:19 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7212880721909017 on epoch=243
06/04/2022 08:35:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
06/04/2022 08:35:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=246
06/04/2022 08:35:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=247
06/04/2022 08:35:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=248
06/04/2022 08:35:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=249
06/04/2022 08:35:35 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7401901736089761 on epoch=249
06/04/2022 08:35:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7283467572622819 -> 0.7401901736089761 on epoch=249, global_step=2000
06/04/2022 08:35:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=251
06/04/2022 08:35:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=252
06/04/2022 08:35:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=253
06/04/2022 08:35:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
06/04/2022 08:35:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=256
06/04/2022 08:35:50 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7308718586537528 on epoch=256
06/04/2022 08:35:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
06/04/2022 08:35:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
06/04/2022 08:35:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=259
06/04/2022 08:36:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=261
06/04/2022 08:36:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 08:36:06 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6866996958161053 on epoch=262
06/04/2022 08:36:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=263
06/04/2022 08:36:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=264
06/04/2022 08:36:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=266
06/04/2022 08:36:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=267
06/04/2022 08:36:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/04/2022 08:36:22 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7209022371758221 on epoch=268
06/04/2022 08:36:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
06/04/2022 08:36:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
06/04/2022 08:36:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=272
06/04/2022 08:36:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=273
06/04/2022 08:36:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
06/04/2022 08:36:37 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.676881050096566 on epoch=274
06/04/2022 08:36:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=276
06/04/2022 08:36:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
06/04/2022 08:36:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/04/2022 08:36:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/04/2022 08:36:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/04/2022 08:36:53 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6866875054957353 on epoch=281
06/04/2022 08:36:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=282
06/04/2022 08:36:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/04/2022 08:37:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
06/04/2022 08:37:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=286
06/04/2022 08:37:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=287
06/04/2022 08:37:09 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6931171060269421 on epoch=287
06/04/2022 08:37:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=288
06/04/2022 08:37:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=289
06/04/2022 08:37:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=291
06/04/2022 08:37:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=292
06/04/2022 08:37:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/04/2022 08:37:25 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7171908740644011 on epoch=293
06/04/2022 08:37:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
06/04/2022 08:37:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/04/2022 08:37:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/04/2022 08:37:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/04/2022 08:37:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
06/04/2022 08:37:40 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6816408229451708 on epoch=299
06/04/2022 08:37:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=301
06/04/2022 08:37:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/04/2022 08:37:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/04/2022 08:37:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
06/04/2022 08:37:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
06/04/2022 08:37:55 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.733342758058876 on epoch=306
06/04/2022 08:37:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
06/04/2022 08:38:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
06/04/2022 08:38:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=309
06/04/2022 08:38:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=311
06/04/2022 08:38:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 08:38:11 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7098387723387724 on epoch=312
06/04/2022 08:38:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=313
06/04/2022 08:38:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 08:38:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/04/2022 08:38:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
06/04/2022 08:38:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/04/2022 08:38:26 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7017277286222118 on epoch=318
06/04/2022 08:38:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
06/04/2022 08:38:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
06/04/2022 08:38:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=322
06/04/2022 08:38:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
06/04/2022 08:38:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
06/04/2022 08:38:41 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7016260805397427 on epoch=324
06/04/2022 08:38:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=326
06/04/2022 08:38:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 08:38:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
06/04/2022 08:38:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
06/04/2022 08:38:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
06/04/2022 08:38:57 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6881988869818485 on epoch=331
06/04/2022 08:39:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/04/2022 08:39:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=333
06/04/2022 08:39:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=334
06/04/2022 08:39:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=336
06/04/2022 08:39:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/04/2022 08:39:13 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7024414481307477 on epoch=337
06/04/2022 08:39:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 08:39:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/04/2022 08:39:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=341
06/04/2022 08:39:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=342
06/04/2022 08:39:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=343
06/04/2022 08:39:28 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6769564239561869 on epoch=343
06/04/2022 08:39:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/04/2022 08:39:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=346
06/04/2022 08:39:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
06/04/2022 08:39:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 08:39:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 08:39:43 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.664968320241085 on epoch=349
06/04/2022 08:39:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=351
06/04/2022 08:39:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=352
06/04/2022 08:39:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=353
06/04/2022 08:39:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=354
06/04/2022 08:39:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 08:39:58 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6559643534221489 on epoch=356
06/04/2022 08:40:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 08:40:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/04/2022 08:40:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
06/04/2022 08:40:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/04/2022 08:40:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
06/04/2022 08:40:13 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6798283710530972 on epoch=362
06/04/2022 08:40:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/04/2022 08:40:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 08:40:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/04/2022 08:40:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
06/04/2022 08:40:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 08:40:29 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6803944061730199 on epoch=368
06/04/2022 08:40:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 08:40:34 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/04/2022 08:40:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 08:40:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/04/2022 08:40:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
06/04/2022 08:40:43 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:40:43 - INFO - __main__ - Printing 3 examples
06/04/2022 08:40:43 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 08:40:43 - INFO - __main__ - ['happy']
06/04/2022 08:40:43 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 08:40:43 - INFO - __main__ - ['happy']
06/04/2022 08:40:43 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 08:40:43 - INFO - __main__ - ['happy']
06/04/2022 08:40:43 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:40:43 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:40:43 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 08:40:43 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:40:43 - INFO - __main__ - Printing 3 examples
06/04/2022 08:40:43 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 08:40:43 - INFO - __main__ - ['happy']
06/04/2022 08:40:43 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 08:40:43 - INFO - __main__ - ['happy']
06/04/2022 08:40:43 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 08:40:43 - INFO - __main__ - ['happy']
06/04/2022 08:40:43 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:40:43 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:40:43 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 08:40:44 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6770065876889939 on epoch=374
06/04/2022 08:40:44 - INFO - __main__ - save last model!
06/04/2022 08:40:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 08:40:44 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 08:40:44 - INFO - __main__ - Printing 3 examples
06/04/2022 08:40:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 08:40:44 - INFO - __main__ - ['others']
06/04/2022 08:40:44 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 08:40:44 - INFO - __main__ - ['others']
06/04/2022 08:40:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 08:40:44 - INFO - __main__ - ['others']
06/04/2022 08:40:44 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:40:46 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:40:52 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 08:40:59 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 08:40:59 - INFO - __main__ - task name: emo
06/04/2022 08:41:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 08:41:00 - INFO - __main__ - Starting training!
06/04/2022 08:42:28 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_42_0.5_8_predictions.txt
06/04/2022 08:42:28 - INFO - __main__ - Classification-F1 on test data: 0.4316
06/04/2022 08:42:29 - INFO - __main__ - prefix=emo_32_42, lr=0.5, bsz=8, dev_performance=0.7401901736089761, test_performance=0.43157605344089633
06/04/2022 08:42:29 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.4, bsz=8 ...
06/04/2022 08:42:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:42:30 - INFO - __main__ - Printing 3 examples
06/04/2022 08:42:30 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 08:42:30 - INFO - __main__ - ['happy']
06/04/2022 08:42:30 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 08:42:30 - INFO - __main__ - ['happy']
06/04/2022 08:42:30 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 08:42:30 - INFO - __main__ - ['happy']
06/04/2022 08:42:30 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:42:30 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:42:30 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 08:42:30 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:42:30 - INFO - __main__ - Printing 3 examples
06/04/2022 08:42:30 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 08:42:30 - INFO - __main__ - ['happy']
06/04/2022 08:42:30 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 08:42:30 - INFO - __main__ - ['happy']
06/04/2022 08:42:30 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 08:42:30 - INFO - __main__ - ['happy']
06/04/2022 08:42:30 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:42:30 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:42:30 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 08:42:45 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 08:42:45 - INFO - __main__ - task name: emo
06/04/2022 08:42:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 08:42:46 - INFO - __main__ - Starting training!
06/04/2022 08:42:49 - INFO - __main__ - Step 10 Global step 10 Train loss 6.17 on epoch=1
06/04/2022 08:42:51 - INFO - __main__ - Step 20 Global step 20 Train loss 2.52 on epoch=2
06/04/2022 08:42:54 - INFO - __main__ - Step 30 Global step 30 Train loss 1.44 on epoch=3
06/04/2022 08:42:57 - INFO - __main__ - Step 40 Global step 40 Train loss 1.20 on epoch=4
06/04/2022 08:42:59 - INFO - __main__ - Step 50 Global step 50 Train loss 1.16 on epoch=6
06/04/2022 08:43:01 - INFO - __main__ - Global step 50 Train loss 2.50 Classification-F1 0.1 on epoch=6
06/04/2022 08:43:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=6, global_step=50
06/04/2022 08:43:04 - INFO - __main__ - Step 60 Global step 60 Train loss 1.05 on epoch=7
06/04/2022 08:43:06 - INFO - __main__ - Step 70 Global step 70 Train loss 1.02 on epoch=8
06/04/2022 08:43:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=9
06/04/2022 08:43:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=11
06/04/2022 08:43:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=12
06/04/2022 08:43:16 - INFO - __main__ - Global step 100 Train loss 0.98 Classification-F1 0.23281723018565123 on epoch=12
06/04/2022 08:43:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.23281723018565123 on epoch=12, global_step=100
06/04/2022 08:43:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=13
06/04/2022 08:43:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=14
06/04/2022 08:43:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=16
06/04/2022 08:43:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.89 on epoch=17
06/04/2022 08:43:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=18
06/04/2022 08:43:30 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.13486312399355876 on epoch=18
06/04/2022 08:43:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=19
06/04/2022 08:43:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.84 on epoch=21
06/04/2022 08:43:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=22
06/04/2022 08:43:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=23
06/04/2022 08:43:43 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=24
06/04/2022 08:43:45 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.1 on epoch=24
06/04/2022 08:43:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=26
06/04/2022 08:43:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=27
06/04/2022 08:43:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=28
06/04/2022 08:43:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=29
06/04/2022 08:43:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.79 on epoch=31
06/04/2022 08:44:00 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.1866151866151866 on epoch=31
06/04/2022 08:44:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.76 on epoch=32
06/04/2022 08:44:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.81 on epoch=33
06/04/2022 08:44:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.77 on epoch=34
06/04/2022 08:44:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.86 on epoch=36
06/04/2022 08:44:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.70 on epoch=37
06/04/2022 08:44:15 - INFO - __main__ - Global step 300 Train loss 0.78 Classification-F1 0.3048913043478261 on epoch=37
06/04/2022 08:44:15 - INFO - __main__ - Saving model with best Classification-F1: 0.23281723018565123 -> 0.3048913043478261 on epoch=37, global_step=300
06/04/2022 08:44:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.80 on epoch=38
06/04/2022 08:44:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.70 on epoch=39
06/04/2022 08:44:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.70 on epoch=41
06/04/2022 08:44:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.70 on epoch=42
06/04/2022 08:44:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.71 on epoch=43
06/04/2022 08:44:30 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.5113160420178455 on epoch=43
06/04/2022 08:44:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3048913043478261 -> 0.5113160420178455 on epoch=43, global_step=350
06/04/2022 08:44:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=44
06/04/2022 08:44:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.71 on epoch=46
06/04/2022 08:44:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.71 on epoch=47
06/04/2022 08:44:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.63 on epoch=48
06/04/2022 08:44:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.61 on epoch=49
06/04/2022 08:44:45 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.43631455647149997 on epoch=49
06/04/2022 08:44:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=51
06/04/2022 08:44:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=52
06/04/2022 08:44:53 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=53
06/04/2022 08:44:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.65 on epoch=54
06/04/2022 08:44:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=56
06/04/2022 08:45:00 - INFO - __main__ - Global step 450 Train loss 0.56 Classification-F1 0.602491932171566 on epoch=56
06/04/2022 08:45:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5113160420178455 -> 0.602491932171566 on epoch=56, global_step=450
06/04/2022 08:45:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.48 on epoch=57
06/04/2022 08:45:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=58
06/04/2022 08:45:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.54 on epoch=59
06/04/2022 08:45:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=61
06/04/2022 08:45:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=62
06/04/2022 08:45:15 - INFO - __main__ - Global step 500 Train loss 0.47 Classification-F1 0.48199830833712065 on epoch=62
06/04/2022 08:45:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.46 on epoch=63
06/04/2022 08:45:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=64
06/04/2022 08:45:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.50 on epoch=66
06/04/2022 08:45:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.34 on epoch=67
06/04/2022 08:45:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.51 on epoch=68
06/04/2022 08:45:30 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.6334627128720005 on epoch=68
06/04/2022 08:45:30 - INFO - __main__ - Saving model with best Classification-F1: 0.602491932171566 -> 0.6334627128720005 on epoch=68, global_step=550
06/04/2022 08:45:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=69
06/04/2022 08:45:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=71
06/04/2022 08:45:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=72
06/04/2022 08:45:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=73
06/04/2022 08:45:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=74
06/04/2022 08:45:45 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.5915817496959935 on epoch=74
06/04/2022 08:45:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=76
06/04/2022 08:45:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=77
06/04/2022 08:45:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=78
06/04/2022 08:45:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.40 on epoch=79
06/04/2022 08:45:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=81
06/04/2022 08:46:00 - INFO - __main__ - Global step 650 Train loss 0.29 Classification-F1 0.6516383782959023 on epoch=81
06/04/2022 08:46:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6334627128720005 -> 0.6516383782959023 on epoch=81, global_step=650
06/04/2022 08:46:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.28 on epoch=82
06/04/2022 08:46:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=83
06/04/2022 08:46:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=84
06/04/2022 08:46:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=86
06/04/2022 08:46:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=87
06/04/2022 08:46:15 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.6933274434211466 on epoch=87
06/04/2022 08:46:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6516383782959023 -> 0.6933274434211466 on epoch=87, global_step=700
06/04/2022 08:46:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=88
06/04/2022 08:46:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=89
06/04/2022 08:46:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=91
06/04/2022 08:46:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=92
06/04/2022 08:46:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=93
06/04/2022 08:46:29 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.6889861253228957 on epoch=93
06/04/2022 08:46:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=94
06/04/2022 08:46:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=96
06/04/2022 08:46:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=97
06/04/2022 08:46:40 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=98
06/04/2022 08:46:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=99
06/04/2022 08:46:44 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.6717228512538058 on epoch=99
06/04/2022 08:46:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=101
06/04/2022 08:46:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=102
06/04/2022 08:46:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=103
06/04/2022 08:46:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=104
06/04/2022 08:46:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=106
06/04/2022 08:46:59 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.7207486062324772 on epoch=106
06/04/2022 08:46:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6933274434211466 -> 0.7207486062324772 on epoch=106, global_step=850
06/04/2022 08:47:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=107
06/04/2022 08:47:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=108
06/04/2022 08:47:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=109
06/04/2022 08:47:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=111
06/04/2022 08:47:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=112
06/04/2022 08:47:14 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6745065818782601 on epoch=112
06/04/2022 08:47:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=113
06/04/2022 08:47:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=114
06/04/2022 08:47:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=116
06/04/2022 08:47:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=117
06/04/2022 08:47:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=118
06/04/2022 08:47:29 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6807258938244853 on epoch=118
06/04/2022 08:47:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=119
06/04/2022 08:47:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=121
06/04/2022 08:47:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=122
06/04/2022 08:47:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=123
06/04/2022 08:47:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=124
06/04/2022 08:47:44 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6845488741109713 on epoch=124
06/04/2022 08:47:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=126
06/04/2022 08:47:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=127
06/04/2022 08:47:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=128
06/04/2022 08:47:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=129
06/04/2022 08:47:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=131
06/04/2022 08:48:00 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.6805909776498013 on epoch=131
06/04/2022 08:48:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=132
06/04/2022 08:48:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=133
06/04/2022 08:48:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=134
06/04/2022 08:48:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=136
06/04/2022 08:48:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=137
06/04/2022 08:48:15 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6797938269475272 on epoch=137
06/04/2022 08:48:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=138
06/04/2022 08:48:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=139
06/04/2022 08:48:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=141
06/04/2022 08:48:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=142
06/04/2022 08:48:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=143
06/04/2022 08:48:30 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6813373026460524 on epoch=143
06/04/2022 08:48:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=144
06/04/2022 08:48:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=146
06/04/2022 08:48:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=147
06/04/2022 08:48:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=148
06/04/2022 08:48:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=149
06/04/2022 08:48:45 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6794489324272442 on epoch=149
06/04/2022 08:48:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=151
06/04/2022 08:48:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=152
06/04/2022 08:48:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=153
06/04/2022 08:48:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=154
06/04/2022 08:48:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=156
06/04/2022 08:49:01 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6833261328725039 on epoch=156
06/04/2022 08:49:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=157
06/04/2022 08:49:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=158
06/04/2022 08:49:09 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=159
06/04/2022 08:49:11 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=161
06/04/2022 08:49:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=162
06/04/2022 08:49:16 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6626609078590786 on epoch=162
06/04/2022 08:49:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=163
06/04/2022 08:49:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=164
06/04/2022 08:49:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=166
06/04/2022 08:49:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=167
06/04/2022 08:49:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=168
06/04/2022 08:49:31 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6864512597405386 on epoch=168
06/04/2022 08:49:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=169
06/04/2022 08:49:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=171
06/04/2022 08:49:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=172
06/04/2022 08:49:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=173
06/04/2022 08:49:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=174
06/04/2022 08:49:46 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6669354588204408 on epoch=174
06/04/2022 08:49:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=176
06/04/2022 08:49:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=177
06/04/2022 08:49:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=178
06/04/2022 08:49:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=179
06/04/2022 08:49:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=181
06/04/2022 08:50:01 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7049533785614488 on epoch=181
06/04/2022 08:50:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=182
06/04/2022 08:50:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=183
06/04/2022 08:50:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=184
06/04/2022 08:50:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=186
06/04/2022 08:50:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=187
06/04/2022 08:50:16 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6977271537051584 on epoch=187
06/04/2022 08:50:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=188
06/04/2022 08:50:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=189
06/04/2022 08:50:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=191
06/04/2022 08:50:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=192
06/04/2022 08:50:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=193
06/04/2022 08:50:31 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7020785901003457 on epoch=193
06/04/2022 08:50:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=194
06/04/2022 08:50:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=196
06/04/2022 08:50:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=197
06/04/2022 08:50:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=198
06/04/2022 08:50:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=199
06/04/2022 08:50:46 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6632236842105264 on epoch=199
06/04/2022 08:50:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=201
06/04/2022 08:50:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=202
06/04/2022 08:50:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=203
06/04/2022 08:50:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=204
06/04/2022 08:50:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=206
06/04/2022 08:51:01 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.706264286362804 on epoch=206
06/04/2022 08:51:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=207
06/04/2022 08:51:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=208
06/04/2022 08:51:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=209
06/04/2022 08:51:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=211
06/04/2022 08:51:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=212
06/04/2022 08:51:16 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6870359981299673 on epoch=212
06/04/2022 08:51:19 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=213
06/04/2022 08:51:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=214
06/04/2022 08:51:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=216
06/04/2022 08:51:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
06/04/2022 08:51:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=218
06/04/2022 08:51:32 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.700774738032865 on epoch=218
06/04/2022 08:51:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=219
06/04/2022 08:51:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=221
06/04/2022 08:51:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=222
06/04/2022 08:51:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=223
06/04/2022 08:51:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 08:51:47 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7071671644868758 on epoch=224
06/04/2022 08:51:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=226
06/04/2022 08:51:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=227
06/04/2022 08:51:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=228
06/04/2022 08:51:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=229
06/04/2022 08:52:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=231
06/04/2022 08:52:02 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6961625762519507 on epoch=231
06/04/2022 08:52:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=232
06/04/2022 08:52:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=233
06/04/2022 08:52:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
06/04/2022 08:52:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=236
06/04/2022 08:52:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=237
06/04/2022 08:52:18 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6917833780138929 on epoch=237
06/04/2022 08:52:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
06/04/2022 08:52:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
06/04/2022 08:52:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=241
06/04/2022 08:52:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
06/04/2022 08:52:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/04/2022 08:52:32 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7305583842266625 on epoch=243
06/04/2022 08:52:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7207486062324772 -> 0.7305583842266625 on epoch=243, global_step=1950
06/04/2022 08:52:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=244
06/04/2022 08:52:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=246
06/04/2022 08:52:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
06/04/2022 08:52:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
06/04/2022 08:52:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=249
06/04/2022 08:52:48 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6881592039800994 on epoch=249
06/04/2022 08:52:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=251
06/04/2022 08:52:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=252
06/04/2022 08:52:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=253
06/04/2022 08:52:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=254
06/04/2022 08:53:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=256
06/04/2022 08:53:03 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6591945773524721 on epoch=256
06/04/2022 08:53:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=257
06/04/2022 08:53:09 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
06/04/2022 08:53:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=259
06/04/2022 08:53:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
06/04/2022 08:53:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=262
06/04/2022 08:53:19 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6885157159217891 on epoch=262
06/04/2022 08:53:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=263
06/04/2022 08:53:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=264
06/04/2022 08:53:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=266
06/04/2022 08:53:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=267
06/04/2022 08:53:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=268
06/04/2022 08:53:34 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6872153989801049 on epoch=268
06/04/2022 08:53:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
06/04/2022 08:53:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/04/2022 08:53:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
06/04/2022 08:53:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=273
06/04/2022 08:53:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
06/04/2022 08:53:50 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6507450527714399 on epoch=274
06/04/2022 08:53:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 08:53:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=277
06/04/2022 08:53:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=278
06/04/2022 08:54:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=279
06/04/2022 08:54:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=281
06/04/2022 08:54:05 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6996497962265482 on epoch=281
06/04/2022 08:54:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
06/04/2022 08:54:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
06/04/2022 08:54:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/04/2022 08:54:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 08:54:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=287
06/04/2022 08:54:21 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6681103389432292 on epoch=287
06/04/2022 08:54:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=288
06/04/2022 08:54:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=289
06/04/2022 08:54:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=291
06/04/2022 08:54:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
06/04/2022 08:54:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=293
06/04/2022 08:54:35 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6896504561142645 on epoch=293
06/04/2022 08:54:38 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
06/04/2022 08:54:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=296
06/04/2022 08:54:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/04/2022 08:54:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/04/2022 08:54:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=299
06/04/2022 08:54:51 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6713869685324791 on epoch=299
06/04/2022 08:54:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=301
06/04/2022 08:54:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=302
06/04/2022 08:54:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/04/2022 08:55:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
06/04/2022 08:55:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=306
06/04/2022 08:55:06 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6988331318165812 on epoch=306
06/04/2022 08:55:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
06/04/2022 08:55:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=308
06/04/2022 08:55:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=309
06/04/2022 08:55:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
06/04/2022 08:55:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 08:55:22 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6872510822510822 on epoch=312
06/04/2022 08:55:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=313
06/04/2022 08:55:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=314
06/04/2022 08:55:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/04/2022 08:55:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/04/2022 08:55:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/04/2022 08:55:37 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.681001866196283 on epoch=318
06/04/2022 08:55:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
06/04/2022 08:55:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 08:55:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=322
06/04/2022 08:55:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
06/04/2022 08:55:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=324
06/04/2022 08:55:53 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6734394341290894 on epoch=324
06/04/2022 08:55:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=326
06/04/2022 08:55:59 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
06/04/2022 08:56:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
06/04/2022 08:56:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=329
06/04/2022 08:56:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=331
06/04/2022 08:56:09 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6876764637103225 on epoch=331
06/04/2022 08:56:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/04/2022 08:56:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=333
06/04/2022 08:56:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/04/2022 08:56:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/04/2022 08:56:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
06/04/2022 08:56:24 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6969341325493278 on epoch=337
06/04/2022 08:56:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 08:56:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
06/04/2022 08:56:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
06/04/2022 08:56:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/04/2022 08:56:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=343
06/04/2022 08:56:40 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6837454212454213 on epoch=343
06/04/2022 08:56:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
06/04/2022 08:56:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
06/04/2022 08:56:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
06/04/2022 08:56:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 08:56:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/04/2022 08:56:55 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6888279801201691 on epoch=349
06/04/2022 08:56:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
06/04/2022 08:57:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
06/04/2022 08:57:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/04/2022 08:57:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
06/04/2022 08:57:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/04/2022 08:57:11 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6801287810721772 on epoch=356
06/04/2022 08:57:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 08:57:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/04/2022 08:57:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
06/04/2022 08:57:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
06/04/2022 08:57:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/04/2022 08:57:27 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7061871079112458 on epoch=362
06/04/2022 08:57:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/04/2022 08:57:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 08:57:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/04/2022 08:57:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
06/04/2022 08:57:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 08:57:43 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6340073529411765 on epoch=368
06/04/2022 08:57:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 08:57:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
06/04/2022 08:57:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 08:57:53 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=373
06/04/2022 08:57:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=374
06/04/2022 08:57:57 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:57:57 - INFO - __main__ - Printing 3 examples
06/04/2022 08:57:57 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 08:57:57 - INFO - __main__ - ['happy']
06/04/2022 08:57:57 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 08:57:57 - INFO - __main__ - ['happy']
06/04/2022 08:57:57 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 08:57:57 - INFO - __main__ - ['happy']
06/04/2022 08:57:57 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:57:57 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:57:57 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 08:57:57 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 08:57:57 - INFO - __main__ - Printing 3 examples
06/04/2022 08:57:57 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 08:57:57 - INFO - __main__ - ['happy']
06/04/2022 08:57:57 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 08:57:57 - INFO - __main__ - ['happy']
06/04/2022 08:57:57 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 08:57:57 - INFO - __main__ - ['happy']
06/04/2022 08:57:57 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:57:57 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:57:57 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 08:57:59 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6843506493506494 on epoch=374
06/04/2022 08:57:59 - INFO - __main__ - save last model!
06/04/2022 08:57:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 08:57:59 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 08:57:59 - INFO - __main__ - Printing 3 examples
06/04/2022 08:57:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 08:57:59 - INFO - __main__ - ['others']
06/04/2022 08:57:59 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 08:57:59 - INFO - __main__ - ['others']
06/04/2022 08:57:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 08:57:59 - INFO - __main__ - ['others']
06/04/2022 08:57:59 - INFO - __main__ - Tokenizing Input ...
06/04/2022 08:58:01 - INFO - __main__ - Tokenizing Output ...
06/04/2022 08:58:06 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 08:58:12 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 08:58:12 - INFO - __main__ - task name: emo
06/04/2022 08:58:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 08:58:12 - INFO - __main__ - Starting training!
06/04/2022 09:00:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_42_0.4_8_predictions.txt
06/04/2022 09:00:15 - INFO - __main__ - Classification-F1 on test data: 0.4153
06/04/2022 09:00:15 - INFO - __main__ - prefix=emo_32_42, lr=0.4, bsz=8, dev_performance=0.7305583842266625, test_performance=0.41527015952378205
06/04/2022 09:00:15 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.3, bsz=8 ...
06/04/2022 09:00:16 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:00:16 - INFO - __main__ - Printing 3 examples
06/04/2022 09:00:16 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 09:00:16 - INFO - __main__ - ['happy']
06/04/2022 09:00:16 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 09:00:16 - INFO - __main__ - ['happy']
06/04/2022 09:00:16 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 09:00:16 - INFO - __main__ - ['happy']
06/04/2022 09:00:16 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:00:16 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:00:16 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 09:00:16 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:00:16 - INFO - __main__ - Printing 3 examples
06/04/2022 09:00:16 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 09:00:16 - INFO - __main__ - ['happy']
06/04/2022 09:00:16 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 09:00:16 - INFO - __main__ - ['happy']
06/04/2022 09:00:16 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 09:00:16 - INFO - __main__ - ['happy']
06/04/2022 09:00:16 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:00:16 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:00:16 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 09:00:34 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 09:00:34 - INFO - __main__ - task name: emo
06/04/2022 09:00:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 09:00:35 - INFO - __main__ - Starting training!
06/04/2022 09:00:38 - INFO - __main__ - Step 10 Global step 10 Train loss 7.10 on epoch=1
06/04/2022 09:00:41 - INFO - __main__ - Step 20 Global step 20 Train loss 3.93 on epoch=2
06/04/2022 09:00:44 - INFO - __main__ - Step 30 Global step 30 Train loss 1.88 on epoch=3
06/04/2022 09:00:46 - INFO - __main__ - Step 40 Global step 40 Train loss 1.25 on epoch=4
06/04/2022 09:00:49 - INFO - __main__ - Step 50 Global step 50 Train loss 1.22 on epoch=6
06/04/2022 09:00:51 - INFO - __main__ - Global step 50 Train loss 3.08 Classification-F1 0.10062893081761007 on epoch=6
06/04/2022 09:00:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10062893081761007 on epoch=6, global_step=50
06/04/2022 09:00:54 - INFO - __main__ - Step 60 Global step 60 Train loss 1.13 on epoch=7
06/04/2022 09:00:56 - INFO - __main__ - Step 70 Global step 70 Train loss 1.07 on epoch=8
06/04/2022 09:00:59 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=9
06/04/2022 09:01:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=11
06/04/2022 09:01:04 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=12
06/04/2022 09:01:06 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.10062893081761007 on epoch=12
06/04/2022 09:01:08 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=13
06/04/2022 09:01:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=14
06/04/2022 09:01:14 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=16
06/04/2022 09:01:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=17
06/04/2022 09:01:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.86 on epoch=18
06/04/2022 09:01:21 - INFO - __main__ - Global step 150 Train loss 0.92 Classification-F1 0.1760382474668189 on epoch=18
06/04/2022 09:01:21 - INFO - __main__ - Saving model with best Classification-F1: 0.10062893081761007 -> 0.1760382474668189 on epoch=18, global_step=150
06/04/2022 09:01:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.86 on epoch=19
06/04/2022 09:01:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=21
06/04/2022 09:01:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=22
06/04/2022 09:01:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=23
06/04/2022 09:01:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.94 on epoch=24
06/04/2022 09:01:35 - INFO - __main__ - Global step 200 Train loss 0.89 Classification-F1 0.24654136729170317 on epoch=24
06/04/2022 09:01:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1760382474668189 -> 0.24654136729170317 on epoch=24, global_step=200
06/04/2022 09:01:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.86 on epoch=26
06/04/2022 09:01:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=27
06/04/2022 09:01:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.87 on epoch=28
06/04/2022 09:01:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=29
06/04/2022 09:01:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=31
06/04/2022 09:01:50 - INFO - __main__ - Global step 250 Train loss 0.85 Classification-F1 0.18470360200290745 on epoch=31
06/04/2022 09:01:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.78 on epoch=32
06/04/2022 09:01:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.84 on epoch=33
06/04/2022 09:01:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.75 on epoch=34
06/04/2022 09:02:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.90 on epoch=36
06/04/2022 09:02:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.78 on epoch=37
06/04/2022 09:02:05 - INFO - __main__ - Global step 300 Train loss 0.81 Classification-F1 0.22480739599383667 on epoch=37
06/04/2022 09:02:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.80 on epoch=38
06/04/2022 09:02:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.79 on epoch=39
06/04/2022 09:02:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.78 on epoch=41
06/04/2022 09:02:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.78 on epoch=42
06/04/2022 09:02:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.78 on epoch=43
06/04/2022 09:02:20 - INFO - __main__ - Global step 350 Train loss 0.78 Classification-F1 0.20089430894308943 on epoch=43
06/04/2022 09:02:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.70 on epoch=44
06/04/2022 09:02:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.73 on epoch=46
06/04/2022 09:02:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.83 on epoch=47
06/04/2022 09:02:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.75 on epoch=48
06/04/2022 09:02:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.83 on epoch=49
06/04/2022 09:02:34 - INFO - __main__ - Global step 400 Train loss 0.77 Classification-F1 0.1798076923076923 on epoch=49
06/04/2022 09:02:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.79 on epoch=51
06/04/2022 09:02:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.69 on epoch=52
06/04/2022 09:02:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.70 on epoch=53
06/04/2022 09:02:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.75 on epoch=54
06/04/2022 09:02:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.76 on epoch=56
06/04/2022 09:02:49 - INFO - __main__ - Global step 450 Train loss 0.74 Classification-F1 0.2992547425474255 on epoch=56
06/04/2022 09:02:49 - INFO - __main__ - Saving model with best Classification-F1: 0.24654136729170317 -> 0.2992547425474255 on epoch=56, global_step=450
06/04/2022 09:02:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.71 on epoch=57
06/04/2022 09:02:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.69 on epoch=58
06/04/2022 09:02:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.69 on epoch=59
06/04/2022 09:03:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.67 on epoch=61
06/04/2022 09:03:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.75 on epoch=62
06/04/2022 09:03:04 - INFO - __main__ - Global step 500 Train loss 0.70 Classification-F1 0.28747355912061795 on epoch=62
06/04/2022 09:03:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.66 on epoch=63
06/04/2022 09:03:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.67 on epoch=64
06/04/2022 09:03:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.62 on epoch=66
06/04/2022 09:03:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=67
06/04/2022 09:03:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.61 on epoch=68
06/04/2022 09:03:19 - INFO - __main__ - Global step 550 Train loss 0.63 Classification-F1 0.46280324250912486 on epoch=68
06/04/2022 09:03:19 - INFO - __main__ - Saving model with best Classification-F1: 0.2992547425474255 -> 0.46280324250912486 on epoch=68, global_step=550
06/04/2022 09:03:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.55 on epoch=69
06/04/2022 09:03:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.62 on epoch=71
06/04/2022 09:03:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.58 on epoch=72
06/04/2022 09:03:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.56 on epoch=73
06/04/2022 09:03:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.65 on epoch=74
06/04/2022 09:03:33 - INFO - __main__ - Global step 600 Train loss 0.59 Classification-F1 0.40465054326939864 on epoch=74
06/04/2022 09:03:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.52 on epoch=76
06/04/2022 09:03:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.48 on epoch=77
06/04/2022 09:03:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.57 on epoch=78
06/04/2022 09:03:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.51 on epoch=79
06/04/2022 09:03:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=81
06/04/2022 09:03:48 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.4954235845040443 on epoch=81
06/04/2022 09:03:48 - INFO - __main__ - Saving model with best Classification-F1: 0.46280324250912486 -> 0.4954235845040443 on epoch=81, global_step=650
06/04/2022 09:03:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.59 on epoch=82
06/04/2022 09:03:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.50 on epoch=83
06/04/2022 09:03:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.63 on epoch=84
06/04/2022 09:03:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.52 on epoch=86
06/04/2022 09:04:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.50 on epoch=87
06/04/2022 09:04:03 - INFO - __main__ - Global step 700 Train loss 0.55 Classification-F1 0.5338510852100832 on epoch=87
06/04/2022 09:04:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4954235845040443 -> 0.5338510852100832 on epoch=87, global_step=700
06/04/2022 09:04:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.53 on epoch=88
06/04/2022 09:04:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.57 on epoch=89
06/04/2022 09:04:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=91
06/04/2022 09:04:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.39 on epoch=92
06/04/2022 09:04:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.46 on epoch=93
06/04/2022 09:04:18 - INFO - __main__ - Global step 750 Train loss 0.46 Classification-F1 0.6055944250441123 on epoch=93
06/04/2022 09:04:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5338510852100832 -> 0.6055944250441123 on epoch=93, global_step=750
06/04/2022 09:04:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=94
06/04/2022 09:04:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.32 on epoch=96
06/04/2022 09:04:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=97
06/04/2022 09:04:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=98
06/04/2022 09:04:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=99
06/04/2022 09:04:33 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.5562271062271062 on epoch=99
06/04/2022 09:04:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.46 on epoch=101
06/04/2022 09:04:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=102
06/04/2022 09:04:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=103
06/04/2022 09:04:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=104
06/04/2022 09:04:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=106
06/04/2022 09:04:48 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.6066525175644027 on epoch=106
06/04/2022 09:04:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6055944250441123 -> 0.6066525175644027 on epoch=106, global_step=850
06/04/2022 09:04:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.33 on epoch=107
06/04/2022 09:04:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.32 on epoch=108
06/04/2022 09:04:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=109
06/04/2022 09:04:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=111
06/04/2022 09:05:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=112
06/04/2022 09:05:03 - INFO - __main__ - Global step 900 Train loss 0.28 Classification-F1 0.5939116692194668 on epoch=112
06/04/2022 09:05:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=113
06/04/2022 09:05:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=114
06/04/2022 09:05:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=116
06/04/2022 09:05:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=117
06/04/2022 09:05:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=118
06/04/2022 09:05:17 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.6566585047858301 on epoch=118
06/04/2022 09:05:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6066525175644027 -> 0.6566585047858301 on epoch=118, global_step=950
06/04/2022 09:05:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=119
06/04/2022 09:05:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=121
06/04/2022 09:05:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.23 on epoch=122
06/04/2022 09:05:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=123
06/04/2022 09:05:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.24 on epoch=124
06/04/2022 09:05:33 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.597801143674717 on epoch=124
06/04/2022 09:05:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=126
06/04/2022 09:05:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=127
06/04/2022 09:05:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=128
06/04/2022 09:05:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=129
06/04/2022 09:05:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=131
06/04/2022 09:05:48 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.6276664322550398 on epoch=131
06/04/2022 09:05:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=132
06/04/2022 09:05:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=133
06/04/2022 09:05:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=134
06/04/2022 09:05:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=136
06/04/2022 09:06:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=137
06/04/2022 09:06:03 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.6188133785501249 on epoch=137
06/04/2022 09:06:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=138
06/04/2022 09:06:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=139
06/04/2022 09:06:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=141
06/04/2022 09:06:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=142
06/04/2022 09:06:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=143
06/04/2022 09:06:18 - INFO - __main__ - Global step 1150 Train loss 0.18 Classification-F1 0.662913691703379 on epoch=143
06/04/2022 09:06:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6566585047858301 -> 0.662913691703379 on epoch=143, global_step=1150
06/04/2022 09:06:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=144
06/04/2022 09:06:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=146
06/04/2022 09:06:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=147
06/04/2022 09:06:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=148
06/04/2022 09:06:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=149
06/04/2022 09:06:33 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.5161952861952862 on epoch=149
06/04/2022 09:06:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=151
06/04/2022 09:06:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=152
06/04/2022 09:06:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=153
06/04/2022 09:06:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=154
06/04/2022 09:06:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=156
06/04/2022 09:06:48 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.6715005099439061 on epoch=156
06/04/2022 09:06:48 - INFO - __main__ - Saving model with best Classification-F1: 0.662913691703379 -> 0.6715005099439061 on epoch=156, global_step=1250
06/04/2022 09:06:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=157
06/04/2022 09:06:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=158
06/04/2022 09:06:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=159
06/04/2022 09:06:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=161
06/04/2022 09:07:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=162
06/04/2022 09:07:03 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.7064620203756955 on epoch=162
06/04/2022 09:07:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6715005099439061 -> 0.7064620203756955 on epoch=162, global_step=1300
06/04/2022 09:07:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=163
06/04/2022 09:07:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=164
06/04/2022 09:07:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=166
06/04/2022 09:07:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=167
06/04/2022 09:07:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=168
06/04/2022 09:07:18 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.6762225612340029 on epoch=168
06/04/2022 09:07:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=169
06/04/2022 09:07:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=171
06/04/2022 09:07:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=172
06/04/2022 09:07:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=173
06/04/2022 09:07:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=174
06/04/2022 09:07:33 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6841235632183909 on epoch=174
06/04/2022 09:07:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=176
06/04/2022 09:07:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=177
06/04/2022 09:07:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=178
06/04/2022 09:07:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=179
06/04/2022 09:07:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=181
06/04/2022 09:07:48 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6785782556750299 on epoch=181
06/04/2022 09:07:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=182
06/04/2022 09:07:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=183
06/04/2022 09:07:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=184
06/04/2022 09:07:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=186
06/04/2022 09:08:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=187
06/04/2022 09:08:03 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.6575932599631816 on epoch=187
06/04/2022 09:08:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=188
06/04/2022 09:08:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=189
06/04/2022 09:08:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=191
06/04/2022 09:08:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
06/04/2022 09:08:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=193
06/04/2022 09:08:18 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6907895631287955 on epoch=193
06/04/2022 09:08:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=194
06/04/2022 09:08:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=196
06/04/2022 09:08:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=197
06/04/2022 09:08:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=198
06/04/2022 09:08:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=199
06/04/2022 09:08:33 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7172205228031145 on epoch=199
06/04/2022 09:08:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7064620203756955 -> 0.7172205228031145 on epoch=199, global_step=1600
06/04/2022 09:08:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=201
06/04/2022 09:08:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=202
06/04/2022 09:08:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=203
06/04/2022 09:08:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=204
06/04/2022 09:08:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=206
06/04/2022 09:08:48 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7254010695187166 on epoch=206
06/04/2022 09:08:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7172205228031145 -> 0.7254010695187166 on epoch=206, global_step=1650
06/04/2022 09:08:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=207
06/04/2022 09:08:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=208
06/04/2022 09:08:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=209
06/04/2022 09:08:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=211
06/04/2022 09:09:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=212
06/04/2022 09:09:03 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6949440421425781 on epoch=212
06/04/2022 09:09:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
06/04/2022 09:09:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=214
06/04/2022 09:09:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=216
06/04/2022 09:09:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
06/04/2022 09:09:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=218
06/04/2022 09:09:18 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6619446774449281 on epoch=218
06/04/2022 09:09:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
06/04/2022 09:09:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=221
06/04/2022 09:09:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
06/04/2022 09:09:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=223
06/04/2022 09:09:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
06/04/2022 09:09:33 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7265873015873017 on epoch=224
06/04/2022 09:09:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7254010695187166 -> 0.7265873015873017 on epoch=224, global_step=1800
06/04/2022 09:09:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=226
06/04/2022 09:09:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=227
06/04/2022 09:09:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=228
06/04/2022 09:09:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=229
06/04/2022 09:09:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
06/04/2022 09:09:49 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6481385281385281 on epoch=231
06/04/2022 09:09:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=232
06/04/2022 09:09:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=233
06/04/2022 09:09:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=234
06/04/2022 09:09:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/04/2022 09:10:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/04/2022 09:10:04 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6499735204554482 on epoch=237
06/04/2022 09:10:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
06/04/2022 09:10:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
06/04/2022 09:10:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=241
06/04/2022 09:10:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
06/04/2022 09:10:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
06/04/2022 09:10:19 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7145090512619505 on epoch=243
06/04/2022 09:10:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
06/04/2022 09:10:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=246
06/04/2022 09:10:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
06/04/2022 09:10:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=248
06/04/2022 09:10:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
06/04/2022 09:10:34 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6460230575877999 on epoch=249
06/04/2022 09:10:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=251
06/04/2022 09:10:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=252
06/04/2022 09:10:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
06/04/2022 09:10:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
06/04/2022 09:10:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
06/04/2022 09:10:50 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6250182773136967 on epoch=256
06/04/2022 09:10:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=257
06/04/2022 09:10:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/04/2022 09:10:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/04/2022 09:11:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
06/04/2022 09:11:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 09:11:05 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7164006172346822 on epoch=262
06/04/2022 09:11:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=263
06/04/2022 09:11:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
06/04/2022 09:11:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=266
06/04/2022 09:11:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/04/2022 09:11:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/04/2022 09:11:21 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7194922194922194 on epoch=268
06/04/2022 09:11:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
06/04/2022 09:11:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 09:11:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=272
06/04/2022 09:11:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.15 on epoch=273
06/04/2022 09:11:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
06/04/2022 09:11:36 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6707546679149112 on epoch=274
06/04/2022 09:11:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 09:11:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=277
06/04/2022 09:11:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=278
06/04/2022 09:11:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/04/2022 09:11:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
06/04/2022 09:11:52 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7093910158503886 on epoch=281
06/04/2022 09:11:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
06/04/2022 09:11:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=283
06/04/2022 09:12:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/04/2022 09:12:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=286
06/04/2022 09:12:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
06/04/2022 09:12:07 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7313176079896466 on epoch=287
06/04/2022 09:12:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7265873015873017 -> 0.7313176079896466 on epoch=287, global_step=2300
06/04/2022 09:12:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=288
06/04/2022 09:12:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=289
06/04/2022 09:12:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=291
06/04/2022 09:12:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=292
06/04/2022 09:12:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=293
06/04/2022 09:12:22 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7270585317460316 on epoch=293
06/04/2022 09:12:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.09 on epoch=294
06/04/2022 09:12:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/04/2022 09:12:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
06/04/2022 09:12:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
06/04/2022 09:12:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/04/2022 09:12:38 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6812699362041468 on epoch=299
06/04/2022 09:12:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=301
06/04/2022 09:12:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=302
06/04/2022 09:12:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/04/2022 09:12:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=304
06/04/2022 09:12:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/04/2022 09:12:53 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6654325640872542 on epoch=306
06/04/2022 09:12:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
06/04/2022 09:12:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
06/04/2022 09:13:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
06/04/2022 09:13:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=311
06/04/2022 09:13:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/04/2022 09:13:08 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6274949077179124 on epoch=312
06/04/2022 09:13:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/04/2022 09:13:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 09:13:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
06/04/2022 09:13:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
06/04/2022 09:13:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/04/2022 09:13:24 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6939716566203706 on epoch=318
06/04/2022 09:13:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/04/2022 09:13:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=321
06/04/2022 09:13:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 09:13:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
06/04/2022 09:13:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
06/04/2022 09:13:39 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6883385385596145 on epoch=324
06/04/2022 09:13:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=326
06/04/2022 09:13:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 09:13:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
06/04/2022 09:13:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/04/2022 09:13:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=331
06/04/2022 09:13:54 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6860697214878902 on epoch=331
06/04/2022 09:13:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
06/04/2022 09:14:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
06/04/2022 09:14:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=334
06/04/2022 09:14:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/04/2022 09:14:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/04/2022 09:14:10 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6942492096319104 on epoch=337
06/04/2022 09:14:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=338
06/04/2022 09:14:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/04/2022 09:14:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/04/2022 09:14:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
06/04/2022 09:14:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/04/2022 09:14:25 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7617636950695439 on epoch=343
06/04/2022 09:14:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7313176079896466 -> 0.7617636950695439 on epoch=343, global_step=2750
06/04/2022 09:14:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/04/2022 09:14:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=346
06/04/2022 09:14:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 09:14:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=348
06/04/2022 09:14:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/04/2022 09:14:40 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7363217768147345 on epoch=349
06/04/2022 09:14:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/04/2022 09:14:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/04/2022 09:14:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 09:14:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 09:14:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 09:14:55 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7231884354788114 on epoch=356
06/04/2022 09:14:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 09:15:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/04/2022 09:15:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=359
06/04/2022 09:15:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/04/2022 09:15:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/04/2022 09:15:11 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7169967628023839 on epoch=362
06/04/2022 09:15:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=363
06/04/2022 09:15:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
06/04/2022 09:15:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
06/04/2022 09:15:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 09:15:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 09:15:26 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7053218201331003 on epoch=368
06/04/2022 09:15:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 09:15:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/04/2022 09:15:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 09:15:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
06/04/2022 09:15:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=374
06/04/2022 09:15:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:15:41 - INFO - __main__ - Printing 3 examples
06/04/2022 09:15:41 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 09:15:41 - INFO - __main__ - ['happy']
06/04/2022 09:15:41 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 09:15:41 - INFO - __main__ - ['happy']
06/04/2022 09:15:41 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 09:15:41 - INFO - __main__ - ['happy']
06/04/2022 09:15:41 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:15:41 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:15:41 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 09:15:41 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:15:41 - INFO - __main__ - Printing 3 examples
06/04/2022 09:15:41 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 09:15:41 - INFO - __main__ - ['happy']
06/04/2022 09:15:41 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 09:15:41 - INFO - __main__ - ['happy']
06/04/2022 09:15:41 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 09:15:41 - INFO - __main__ - ['happy']
06/04/2022 09:15:41 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:15:41 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:15:41 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 09:15:42 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7200593914363373 on epoch=374
06/04/2022 09:15:42 - INFO - __main__ - save last model!
06/04/2022 09:15:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 09:15:42 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 09:15:42 - INFO - __main__ - Printing 3 examples
06/04/2022 09:15:42 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 09:15:42 - INFO - __main__ - ['others']
06/04/2022 09:15:42 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 09:15:42 - INFO - __main__ - ['others']
06/04/2022 09:15:42 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 09:15:42 - INFO - __main__ - ['others']
06/04/2022 09:15:42 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:15:44 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:15:50 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 09:16:00 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 09:16:00 - INFO - __main__ - task name: emo
06/04/2022 09:16:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 09:16:01 - INFO - __main__ - Starting training!
06/04/2022 09:17:08 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_42_0.3_8_predictions.txt
06/04/2022 09:17:08 - INFO - __main__ - Classification-F1 on test data: 0.3664
06/04/2022 09:17:09 - INFO - __main__ - prefix=emo_32_42, lr=0.3, bsz=8, dev_performance=0.7617636950695439, test_performance=0.3664247507565871
06/04/2022 09:17:09 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.2, bsz=8 ...
06/04/2022 09:17:10 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:17:10 - INFO - __main__ - Printing 3 examples
06/04/2022 09:17:10 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/04/2022 09:17:10 - INFO - __main__ - ['happy']
06/04/2022 09:17:10 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/04/2022 09:17:10 - INFO - __main__ - ['happy']
06/04/2022 09:17:10 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/04/2022 09:17:10 - INFO - __main__ - ['happy']
06/04/2022 09:17:10 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:17:10 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:17:10 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 09:17:10 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:17:10 - INFO - __main__ - Printing 3 examples
06/04/2022 09:17:10 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
06/04/2022 09:17:10 - INFO - __main__ - ['happy']
06/04/2022 09:17:10 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
06/04/2022 09:17:10 - INFO - __main__ - ['happy']
06/04/2022 09:17:10 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
06/04/2022 09:17:10 - INFO - __main__ - ['happy']
06/04/2022 09:17:10 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:17:10 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:17:10 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 09:17:25 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 09:17:25 - INFO - __main__ - task name: emo
06/04/2022 09:17:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 09:17:26 - INFO - __main__ - Starting training!
06/04/2022 09:17:29 - INFO - __main__ - Step 10 Global step 10 Train loss 7.06 on epoch=1
06/04/2022 09:17:32 - INFO - __main__ - Step 20 Global step 20 Train loss 4.63 on epoch=2
06/04/2022 09:17:35 - INFO - __main__ - Step 30 Global step 30 Train loss 2.83 on epoch=3
06/04/2022 09:17:37 - INFO - __main__ - Step 40 Global step 40 Train loss 1.88 on epoch=4
06/04/2022 09:17:40 - INFO - __main__ - Step 50 Global step 50 Train loss 1.26 on epoch=6
06/04/2022 09:17:42 - INFO - __main__ - Global step 50 Train loss 3.53 Classification-F1 0.09872611464968152 on epoch=6
06/04/2022 09:17:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09872611464968152 on epoch=6, global_step=50
06/04/2022 09:17:44 - INFO - __main__ - Step 60 Global step 60 Train loss 1.15 on epoch=7
06/04/2022 09:17:47 - INFO - __main__ - Step 70 Global step 70 Train loss 1.15 on epoch=8
06/04/2022 09:17:50 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=9
06/04/2022 09:17:52 - INFO - __main__ - Step 90 Global step 90 Train loss 1.14 on epoch=11
06/04/2022 09:17:55 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=12
06/04/2022 09:17:57 - INFO - __main__ - Global step 100 Train loss 1.09 Classification-F1 0.1 on epoch=12
06/04/2022 09:17:57 - INFO - __main__ - Saving model with best Classification-F1: 0.09872611464968152 -> 0.1 on epoch=12, global_step=100
06/04/2022 09:17:59 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=13
06/04/2022 09:18:02 - INFO - __main__ - Step 120 Global step 120 Train loss 0.98 on epoch=14
06/04/2022 09:18:05 - INFO - __main__ - Step 130 Global step 130 Train loss 1.01 on epoch=16
06/04/2022 09:18:07 - INFO - __main__ - Step 140 Global step 140 Train loss 0.88 on epoch=17
06/04/2022 09:18:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.85 on epoch=18
06/04/2022 09:18:12 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.16867772750125692 on epoch=18
06/04/2022 09:18:12 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.16867772750125692 on epoch=18, global_step=150
06/04/2022 09:18:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.97 on epoch=19
06/04/2022 09:18:17 - INFO - __main__ - Step 170 Global step 170 Train loss 1.07 on epoch=21
06/04/2022 09:18:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.90 on epoch=22
06/04/2022 09:18:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.96 on epoch=23
06/04/2022 09:18:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.92 on epoch=24
06/04/2022 09:18:27 - INFO - __main__ - Global step 200 Train loss 0.97 Classification-F1 0.11280714817572599 on epoch=24
06/04/2022 09:18:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.88 on epoch=26
06/04/2022 09:18:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.83 on epoch=27
06/04/2022 09:18:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=28
06/04/2022 09:18:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=29
06/04/2022 09:18:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.85 on epoch=31
06/04/2022 09:18:42 - INFO - __main__ - Global step 250 Train loss 0.86 Classification-F1 0.2497414622414622 on epoch=31
06/04/2022 09:18:42 - INFO - __main__ - Saving model with best Classification-F1: 0.16867772750125692 -> 0.2497414622414622 on epoch=31, global_step=250
06/04/2022 09:18:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.81 on epoch=32
06/04/2022 09:18:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.84 on epoch=33
06/04/2022 09:18:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.87 on epoch=34
06/04/2022 09:18:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.83 on epoch=36
06/04/2022 09:18:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=37
06/04/2022 09:18:57 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.13132259273136007 on epoch=37
06/04/2022 09:19:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.83 on epoch=38
06/04/2022 09:19:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.90 on epoch=39
06/04/2022 09:19:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.85 on epoch=41
06/04/2022 09:19:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.81 on epoch=42
06/04/2022 09:19:11 - INFO - __main__ - Step 350 Global step 350 Train loss 0.83 on epoch=43
06/04/2022 09:19:13 - INFO - __main__ - Global step 350 Train loss 0.84 Classification-F1 0.2275761368377138 on epoch=43
06/04/2022 09:19:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.74 on epoch=44
06/04/2022 09:19:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.84 on epoch=46
06/04/2022 09:19:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.80 on epoch=47
06/04/2022 09:19:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.83 on epoch=48
06/04/2022 09:19:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.75 on epoch=49
06/04/2022 09:19:28 - INFO - __main__ - Global step 400 Train loss 0.79 Classification-F1 0.2440610484406105 on epoch=49
06/04/2022 09:19:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.75 on epoch=51
06/04/2022 09:19:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.79 on epoch=52
06/04/2022 09:19:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.75 on epoch=53
06/04/2022 09:19:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.71 on epoch=54
06/04/2022 09:19:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.77 on epoch=56
06/04/2022 09:19:43 - INFO - __main__ - Global step 450 Train loss 0.75 Classification-F1 0.25576923076923075 on epoch=56
06/04/2022 09:19:43 - INFO - __main__ - Saving model with best Classification-F1: 0.2497414622414622 -> 0.25576923076923075 on epoch=56, global_step=450
06/04/2022 09:19:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.76 on epoch=57
06/04/2022 09:19:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.78 on epoch=58
06/04/2022 09:19:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.72 on epoch=59
06/04/2022 09:19:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.72 on epoch=61
06/04/2022 09:19:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.75 on epoch=62
06/04/2022 09:19:59 - INFO - __main__ - Global step 500 Train loss 0.75 Classification-F1 0.3489646854301289 on epoch=62
06/04/2022 09:19:59 - INFO - __main__ - Saving model with best Classification-F1: 0.25576923076923075 -> 0.3489646854301289 on epoch=62, global_step=500
06/04/2022 09:20:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.75 on epoch=63
06/04/2022 09:20:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.79 on epoch=64
06/04/2022 09:20:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.72 on epoch=66
06/04/2022 09:20:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.69 on epoch=67
06/04/2022 09:20:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.67 on epoch=68
06/04/2022 09:20:14 - INFO - __main__ - Global step 550 Train loss 0.72 Classification-F1 0.3951298701298701 on epoch=68
06/04/2022 09:20:14 - INFO - __main__ - Saving model with best Classification-F1: 0.3489646854301289 -> 0.3951298701298701 on epoch=68, global_step=550
06/04/2022 09:20:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.57 on epoch=69
06/04/2022 09:20:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.65 on epoch=71
06/04/2022 09:20:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.68 on epoch=72
06/04/2022 09:20:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.64 on epoch=73
06/04/2022 09:20:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.60 on epoch=74
06/04/2022 09:20:30 - INFO - __main__ - Global step 600 Train loss 0.63 Classification-F1 0.5763325396858505 on epoch=74
06/04/2022 09:20:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3951298701298701 -> 0.5763325396858505 on epoch=74, global_step=600
06/04/2022 09:20:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.60 on epoch=76
06/04/2022 09:20:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.63 on epoch=77
06/04/2022 09:20:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.54 on epoch=78
06/04/2022 09:20:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.57 on epoch=79
06/04/2022 09:20:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.57 on epoch=81
06/04/2022 09:20:45 - INFO - __main__ - Global step 650 Train loss 0.58 Classification-F1 0.44497012139594044 on epoch=81
06/04/2022 09:20:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.50 on epoch=82
06/04/2022 09:20:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.51 on epoch=83
06/04/2022 09:20:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.56 on epoch=84
06/04/2022 09:20:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.57 on epoch=86
06/04/2022 09:20:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.49 on epoch=87
06/04/2022 09:21:00 - INFO - __main__ - Global step 700 Train loss 0.53 Classification-F1 0.4989302967563837 on epoch=87
06/04/2022 09:21:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.57 on epoch=88
06/04/2022 09:21:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.56 on epoch=89
06/04/2022 09:21:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.47 on epoch=91
06/04/2022 09:21:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.43 on epoch=92
06/04/2022 09:21:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=93
06/04/2022 09:21:15 - INFO - __main__ - Global step 750 Train loss 0.49 Classification-F1 0.5657247223845705 on epoch=93
06/04/2022 09:21:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.45 on epoch=94
06/04/2022 09:21:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.44 on epoch=96
06/04/2022 09:21:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.47 on epoch=97
06/04/2022 09:21:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.45 on epoch=98
06/04/2022 09:21:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.49 on epoch=99
06/04/2022 09:21:30 - INFO - __main__ - Global step 800 Train loss 0.46 Classification-F1 0.590050933786078 on epoch=99
06/04/2022 09:21:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5763325396858505 -> 0.590050933786078 on epoch=99, global_step=800
06/04/2022 09:21:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.40 on epoch=101
06/04/2022 09:21:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.45 on epoch=102
06/04/2022 09:21:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=103
06/04/2022 09:21:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.42 on epoch=104
06/04/2022 09:21:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.39 on epoch=106
06/04/2022 09:21:46 - INFO - __main__ - Global step 850 Train loss 0.41 Classification-F1 0.6507622776925159 on epoch=106
06/04/2022 09:21:46 - INFO - __main__ - Saving model with best Classification-F1: 0.590050933786078 -> 0.6507622776925159 on epoch=106, global_step=850
06/04/2022 09:21:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.44 on epoch=107
06/04/2022 09:21:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.42 on epoch=108
06/04/2022 09:21:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.34 on epoch=109
06/04/2022 09:21:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.33 on epoch=111
06/04/2022 09:21:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.45 on epoch=112
06/04/2022 09:22:01 - INFO - __main__ - Global step 900 Train loss 0.40 Classification-F1 0.6243091703618019 on epoch=112
06/04/2022 09:22:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.30 on epoch=113
06/04/2022 09:22:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.39 on epoch=114
06/04/2022 09:22:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.35 on epoch=116
06/04/2022 09:22:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.34 on epoch=117
06/04/2022 09:22:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.31 on epoch=118
06/04/2022 09:22:16 - INFO - __main__ - Global step 950 Train loss 0.34 Classification-F1 0.6385872684975376 on epoch=118
06/04/2022 09:22:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.29 on epoch=119
06/04/2022 09:22:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.32 on epoch=121
06/04/2022 09:22:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.32 on epoch=122
06/04/2022 09:22:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.31 on epoch=123
06/04/2022 09:22:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=124
06/04/2022 09:22:31 - INFO - __main__ - Global step 1000 Train loss 0.31 Classification-F1 0.6271482585131538 on epoch=124
06/04/2022 09:22:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.26 on epoch=126
06/04/2022 09:22:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.31 on epoch=127
06/04/2022 09:22:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=128
06/04/2022 09:22:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.24 on epoch=129
06/04/2022 09:22:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.30 on epoch=131
06/04/2022 09:22:45 - INFO - __main__ - Global step 1050 Train loss 0.29 Classification-F1 0.6532196969696971 on epoch=131
06/04/2022 09:22:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6507622776925159 -> 0.6532196969696971 on epoch=131, global_step=1050
06/04/2022 09:22:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=132
06/04/2022 09:22:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.40 on epoch=133
06/04/2022 09:22:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.22 on epoch=134
06/04/2022 09:22:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=136
06/04/2022 09:22:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=137
06/04/2022 09:23:00 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.6492226097064807 on epoch=137
06/04/2022 09:23:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=138
06/04/2022 09:23:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.28 on epoch=139
06/04/2022 09:23:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=141
06/04/2022 09:23:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=142
06/04/2022 09:23:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.24 on epoch=143
06/04/2022 09:23:15 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.6011607372912777 on epoch=143
06/04/2022 09:23:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=144
06/04/2022 09:23:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=146
06/04/2022 09:23:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=147
06/04/2022 09:23:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=148
06/04/2022 09:23:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=149
06/04/2022 09:23:29 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.5690642690642691 on epoch=149
06/04/2022 09:23:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=151
06/04/2022 09:23:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.21 on epoch=152
06/04/2022 09:23:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=153
06/04/2022 09:23:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.24 on epoch=154
06/04/2022 09:23:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=156
06/04/2022 09:23:44 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.6136442072846979 on epoch=156
06/04/2022 09:23:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=157
06/04/2022 09:23:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=158
06/04/2022 09:23:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.26 on epoch=159
06/04/2022 09:23:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=161
06/04/2022 09:23:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=162
06/04/2022 09:23:59 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.624916339298705 on epoch=162
06/04/2022 09:24:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=163
06/04/2022 09:24:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=164
06/04/2022 09:24:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=166
06/04/2022 09:24:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=167
06/04/2022 09:24:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.23 on epoch=168
06/04/2022 09:24:13 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.6395244440023191 on epoch=168
06/04/2022 09:24:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=169
06/04/2022 09:24:18 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=171
06/04/2022 09:24:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=172
06/04/2022 09:24:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=173
06/04/2022 09:24:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.19 on epoch=174
06/04/2022 09:24:28 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.5986858230134159 on epoch=174
06/04/2022 09:24:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=176
06/04/2022 09:24:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=177
06/04/2022 09:24:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=178
06/04/2022 09:24:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=179
06/04/2022 09:24:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.16 on epoch=181
06/04/2022 09:24:42 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.6460222496083152 on epoch=181
06/04/2022 09:24:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.18 on epoch=182
06/04/2022 09:24:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.16 on epoch=183
06/04/2022 09:24:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
06/04/2022 09:24:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=186
06/04/2022 09:24:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.21 on epoch=187
06/04/2022 09:24:56 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.690747675881947 on epoch=187
06/04/2022 09:24:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6532196969696971 -> 0.690747675881947 on epoch=187, global_step=1500
06/04/2022 09:24:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=188
06/04/2022 09:25:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=189
06/04/2022 09:25:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=191
06/04/2022 09:25:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=192
06/04/2022 09:25:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=193
06/04/2022 09:25:11 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.6555892937471884 on epoch=193
06/04/2022 09:25:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=194
06/04/2022 09:25:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=196
06/04/2022 09:25:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
06/04/2022 09:25:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/04/2022 09:25:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=199
06/04/2022 09:25:26 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.6764433683077751 on epoch=199
06/04/2022 09:25:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=201
06/04/2022 09:25:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=202
06/04/2022 09:25:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
06/04/2022 09:25:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=204
06/04/2022 09:25:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
06/04/2022 09:25:41 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7047556255670613 on epoch=206
06/04/2022 09:25:41 - INFO - __main__ - Saving model with best Classification-F1: 0.690747675881947 -> 0.7047556255670613 on epoch=206, global_step=1650
06/04/2022 09:25:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=207
06/04/2022 09:25:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=208
06/04/2022 09:25:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=209
06/04/2022 09:25:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=211
06/04/2022 09:25:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=212
06/04/2022 09:25:55 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.6980173918882622 on epoch=212
06/04/2022 09:25:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=213
06/04/2022 09:26:00 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
06/04/2022 09:26:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=216
06/04/2022 09:26:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
06/04/2022 09:26:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=218
06/04/2022 09:26:10 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.685277957336781 on epoch=218
06/04/2022 09:26:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=219
06/04/2022 09:26:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=221
06/04/2022 09:26:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=222
06/04/2022 09:26:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
06/04/2022 09:26:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=224
06/04/2022 09:26:25 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.6802897496352109 on epoch=224
06/04/2022 09:26:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
06/04/2022 09:26:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
06/04/2022 09:26:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=228
06/04/2022 09:26:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=229
06/04/2022 09:26:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=231
06/04/2022 09:26:40 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7133780165729793 on epoch=231
06/04/2022 09:26:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7047556255670613 -> 0.7133780165729793 on epoch=231, global_step=1850
06/04/2022 09:26:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=232
06/04/2022 09:26:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=233
06/04/2022 09:26:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=234
06/04/2022 09:26:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=236
06/04/2022 09:26:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=237
06/04/2022 09:26:56 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.6847911211455269 on epoch=237
06/04/2022 09:26:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=238
06/04/2022 09:27:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
06/04/2022 09:27:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=241
06/04/2022 09:27:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
06/04/2022 09:27:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=243
06/04/2022 09:27:10 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.702679789803005 on epoch=243
06/04/2022 09:27:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=244
06/04/2022 09:27:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=246
06/04/2022 09:27:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=247
06/04/2022 09:27:20 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=248
06/04/2022 09:27:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=249
06/04/2022 09:27:25 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.5522619988706945 on epoch=249
06/04/2022 09:27:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
06/04/2022 09:27:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.14 on epoch=252
06/04/2022 09:27:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=253
06/04/2022 09:27:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=254
06/04/2022 09:27:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
06/04/2022 09:27:39 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.6616014008628609 on epoch=256
06/04/2022 09:27:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=257
06/04/2022 09:27:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=258
06/04/2022 09:27:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=259
06/04/2022 09:27:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=261
06/04/2022 09:27:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 09:27:54 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6687510339123242 on epoch=262
06/04/2022 09:27:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
06/04/2022 09:27:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
06/04/2022 09:28:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=266
06/04/2022 09:28:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=267
06/04/2022 09:28:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=268
06/04/2022 09:28:09 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6734608087302143 on epoch=268
06/04/2022 09:28:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=269
06/04/2022 09:28:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/04/2022 09:28:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/04/2022 09:28:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
06/04/2022 09:28:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=274
06/04/2022 09:28:24 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6445945225916454 on epoch=274
06/04/2022 09:28:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=276
06/04/2022 09:28:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
06/04/2022 09:28:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
06/04/2022 09:28:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.12 on epoch=279
06/04/2022 09:28:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=281
06/04/2022 09:28:38 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.6452419550084487 on epoch=281
06/04/2022 09:28:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/04/2022 09:28:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=283
06/04/2022 09:28:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
06/04/2022 09:28:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=286
06/04/2022 09:28:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=287
06/04/2022 09:28:54 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.6536467651341793 on epoch=287
06/04/2022 09:28:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=288
06/04/2022 09:28:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
06/04/2022 09:29:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
06/04/2022 09:29:04 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/04/2022 09:29:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=293
06/04/2022 09:29:09 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7097367113760557 on epoch=293
06/04/2022 09:29:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=294
06/04/2022 09:29:14 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=296
06/04/2022 09:29:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=297
06/04/2022 09:29:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.15 on epoch=298
06/04/2022 09:29:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/04/2022 09:29:23 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.6521212121212121 on epoch=299
06/04/2022 09:29:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=301
06/04/2022 09:29:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/04/2022 09:29:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
06/04/2022 09:29:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=304
06/04/2022 09:29:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/04/2022 09:29:38 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.689468194466706 on epoch=306
06/04/2022 09:29:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=307
06/04/2022 09:29:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/04/2022 09:29:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/04/2022 09:29:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
06/04/2022 09:29:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=312
06/04/2022 09:29:53 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7234243346033157 on epoch=312
06/04/2022 09:29:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7133780165729793 -> 0.7234243346033157 on epoch=312, global_step=2500
06/04/2022 09:29:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/04/2022 09:29:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=314
06/04/2022 09:30:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=316
06/04/2022 09:30:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=317
06/04/2022 09:30:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=318
06/04/2022 09:30:09 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6916417910447761 on epoch=318
06/04/2022 09:30:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=319
06/04/2022 09:30:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
06/04/2022 09:30:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=322
06/04/2022 09:30:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/04/2022 09:30:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
06/04/2022 09:30:24 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.66856212397196 on epoch=324
06/04/2022 09:30:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=326
06/04/2022 09:30:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=327
06/04/2022 09:30:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=328
06/04/2022 09:30:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
06/04/2022 09:30:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=331
06/04/2022 09:30:39 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7049255952380953 on epoch=331
06/04/2022 09:30:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
06/04/2022 09:30:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/04/2022 09:30:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/04/2022 09:30:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
06/04/2022 09:30:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
06/04/2022 09:30:54 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7306681215547868 on epoch=337
06/04/2022 09:30:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7234243346033157 -> 0.7306681215547868 on epoch=337, global_step=2700
06/04/2022 09:30:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 09:30:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/04/2022 09:31:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
06/04/2022 09:31:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
06/04/2022 09:31:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/04/2022 09:31:10 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.681880013368984 on epoch=343
06/04/2022 09:31:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=344
06/04/2022 09:31:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/04/2022 09:31:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 09:31:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
06/04/2022 09:31:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 09:31:25 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7053524978053279 on epoch=349
06/04/2022 09:31:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
06/04/2022 09:31:30 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=352
06/04/2022 09:31:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=353
06/04/2022 09:31:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
06/04/2022 09:31:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
06/04/2022 09:31:40 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6803947994292056 on epoch=356
06/04/2022 09:31:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=357
06/04/2022 09:31:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=358
06/04/2022 09:31:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 09:31:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/04/2022 09:31:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/04/2022 09:31:55 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6627788502788503 on epoch=362
06/04/2022 09:31:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=363
06/04/2022 09:32:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 09:32:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=366
06/04/2022 09:32:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 09:32:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=368
06/04/2022 09:32:10 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.6880231309496169 on epoch=368
06/04/2022 09:32:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
06/04/2022 09:32:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
06/04/2022 09:32:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=372
06/04/2022 09:32:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
06/04/2022 09:32:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
06/04/2022 09:32:24 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:32:24 - INFO - __main__ - Printing 3 examples
06/04/2022 09:32:24 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 09:32:24 - INFO - __main__ - ['others']
06/04/2022 09:32:24 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 09:32:24 - INFO - __main__ - ['others']
06/04/2022 09:32:24 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 09:32:24 - INFO - __main__ - ['others']
06/04/2022 09:32:24 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:32:25 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:32:25 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 09:32:25 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:32:25 - INFO - __main__ - Printing 3 examples
06/04/2022 09:32:25 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 09:32:25 - INFO - __main__ - ['others']
06/04/2022 09:32:25 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 09:32:25 - INFO - __main__ - ['others']
06/04/2022 09:32:25 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 09:32:25 - INFO - __main__ - ['others']
06/04/2022 09:32:25 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:32:25 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:32:25 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 09:32:25 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.612214398504721 on epoch=374
06/04/2022 09:32:25 - INFO - __main__ - save last model!
06/04/2022 09:32:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 09:32:26 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 09:32:26 - INFO - __main__ - Printing 3 examples
06/04/2022 09:32:26 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 09:32:26 - INFO - __main__ - ['others']
06/04/2022 09:32:26 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 09:32:26 - INFO - __main__ - ['others']
06/04/2022 09:32:26 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 09:32:26 - INFO - __main__ - ['others']
06/04/2022 09:32:26 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:32:28 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:32:33 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 09:32:40 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 09:32:40 - INFO - __main__ - task name: emo
06/04/2022 09:32:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 09:32:41 - INFO - __main__ - Starting training!
06/04/2022 09:34:07 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_42_0.2_8_predictions.txt
06/04/2022 09:34:07 - INFO - __main__ - Classification-F1 on test data: 0.3760
06/04/2022 09:34:07 - INFO - __main__ - prefix=emo_32_42, lr=0.2, bsz=8, dev_performance=0.7306681215547868, test_performance=0.37596338236951266
06/04/2022 09:34:07 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.5, bsz=8 ...
06/04/2022 09:34:09 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:34:09 - INFO - __main__ - Printing 3 examples
06/04/2022 09:34:09 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 09:34:09 - INFO - __main__ - ['others']
06/04/2022 09:34:09 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 09:34:09 - INFO - __main__ - ['others']
06/04/2022 09:34:09 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 09:34:09 - INFO - __main__ - ['others']
06/04/2022 09:34:09 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:34:09 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:34:09 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 09:34:09 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:34:09 - INFO - __main__ - Printing 3 examples
06/04/2022 09:34:09 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 09:34:09 - INFO - __main__ - ['others']
06/04/2022 09:34:09 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 09:34:09 - INFO - __main__ - ['others']
06/04/2022 09:34:09 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 09:34:09 - INFO - __main__ - ['others']
06/04/2022 09:34:09 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:34:09 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:34:09 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 09:34:25 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 09:34:25 - INFO - __main__ - task name: emo
06/04/2022 09:34:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 09:34:26 - INFO - __main__ - Starting training!
06/04/2022 09:34:29 - INFO - __main__ - Step 10 Global step 10 Train loss 6.93 on epoch=1
06/04/2022 09:34:31 - INFO - __main__ - Step 20 Global step 20 Train loss 2.61 on epoch=2
06/04/2022 09:34:34 - INFO - __main__ - Step 30 Global step 30 Train loss 1.36 on epoch=3
06/04/2022 09:34:36 - INFO - __main__ - Step 40 Global step 40 Train loss 1.07 on epoch=4
06/04/2022 09:34:39 - INFO - __main__ - Step 50 Global step 50 Train loss 1.04 on epoch=6
06/04/2022 09:34:41 - INFO - __main__ - Global step 50 Train loss 2.60 Classification-F1 0.19944739168877101 on epoch=6
06/04/2022 09:34:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.19944739168877101 on epoch=6, global_step=50
06/04/2022 09:34:43 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=7
06/04/2022 09:34:46 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=8
06/04/2022 09:34:48 - INFO - __main__ - Step 80 Global step 80 Train loss 0.98 on epoch=9
06/04/2022 09:34:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=11
06/04/2022 09:34:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.81 on epoch=12
06/04/2022 09:34:55 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.11578044596912522 on epoch=12
06/04/2022 09:34:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=13
06/04/2022 09:35:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.94 on epoch=14
06/04/2022 09:35:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=16
06/04/2022 09:35:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=17
06/04/2022 09:35:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=18
06/04/2022 09:35:10 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.10126582278481013 on epoch=18
06/04/2022 09:35:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.83 on epoch=19
06/04/2022 09:35:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.89 on epoch=21
06/04/2022 09:35:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.76 on epoch=22
06/04/2022 09:35:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=23
06/04/2022 09:35:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.81 on epoch=24
06/04/2022 09:35:24 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.16776315789473684 on epoch=24
06/04/2022 09:35:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.80 on epoch=26
06/04/2022 09:35:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=27
06/04/2022 09:35:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=28
06/04/2022 09:35:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=29
06/04/2022 09:35:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.74 on epoch=31
06/04/2022 09:35:39 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.42912666135591804 on epoch=31
06/04/2022 09:35:39 - INFO - __main__ - Saving model with best Classification-F1: 0.19944739168877101 -> 0.42912666135591804 on epoch=31, global_step=250
06/04/2022 09:35:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.70 on epoch=32
06/04/2022 09:35:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=33
06/04/2022 09:35:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.70 on epoch=34
06/04/2022 09:35:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.69 on epoch=36
06/04/2022 09:35:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.68 on epoch=37
06/04/2022 09:35:53 - INFO - __main__ - Global step 300 Train loss 0.70 Classification-F1 0.6134057015256826 on epoch=37
06/04/2022 09:35:53 - INFO - __main__ - Saving model with best Classification-F1: 0.42912666135591804 -> 0.6134057015256826 on epoch=37, global_step=300
06/04/2022 09:35:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.74 on epoch=38
06/04/2022 09:35:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=39
06/04/2022 09:36:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=41
06/04/2022 09:36:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=42
06/04/2022 09:36:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=43
06/04/2022 09:36:08 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.22305143429713736 on epoch=43
06/04/2022 09:36:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=44
06/04/2022 09:36:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=46
06/04/2022 09:36:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=47
06/04/2022 09:36:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.54 on epoch=48
06/04/2022 09:36:20 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=49
06/04/2022 09:36:22 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.5656951871657754 on epoch=49
06/04/2022 09:36:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.46 on epoch=51
06/04/2022 09:36:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.51 on epoch=52
06/04/2022 09:36:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=53
06/04/2022 09:36:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=54
06/04/2022 09:36:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=56
06/04/2022 09:36:37 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6549223610777324 on epoch=56
06/04/2022 09:36:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6134057015256826 -> 0.6549223610777324 on epoch=56, global_step=450
06/04/2022 09:36:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=57
06/04/2022 09:36:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=58
06/04/2022 09:36:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=59
06/04/2022 09:36:47 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=61
06/04/2022 09:36:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=62
06/04/2022 09:36:51 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.5379361559702117 on epoch=62
06/04/2022 09:36:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=63
06/04/2022 09:36:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=64
06/04/2022 09:36:59 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=66
06/04/2022 09:37:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=67
06/04/2022 09:37:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=68
06/04/2022 09:37:06 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.6066596552866576 on epoch=68
06/04/2022 09:37:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=69
06/04/2022 09:37:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=71
06/04/2022 09:37:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=72
06/04/2022 09:37:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=73
06/04/2022 09:37:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=74
06/04/2022 09:37:20 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.7402349592494062 on epoch=74
06/04/2022 09:37:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6549223610777324 -> 0.7402349592494062 on epoch=74, global_step=600
06/04/2022 09:37:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=76
06/04/2022 09:37:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=77
06/04/2022 09:37:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=78
06/04/2022 09:37:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=79
06/04/2022 09:37:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=81
06/04/2022 09:37:35 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.7821543338872837 on epoch=81
06/04/2022 09:37:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7402349592494062 -> 0.7821543338872837 on epoch=81, global_step=650
06/04/2022 09:37:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=82
06/04/2022 09:37:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.36 on epoch=83
06/04/2022 09:37:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=84
06/04/2022 09:37:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=86
06/04/2022 09:37:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=87
06/04/2022 09:37:51 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6657307935361559 on epoch=87
06/04/2022 09:37:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=88
06/04/2022 09:37:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=89
06/04/2022 09:37:59 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=91
06/04/2022 09:38:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=92
06/04/2022 09:38:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=93
06/04/2022 09:38:06 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.7900825847580412 on epoch=93
06/04/2022 09:38:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7821543338872837 -> 0.7900825847580412 on epoch=93, global_step=750
06/04/2022 09:38:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=94
06/04/2022 09:38:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=96
06/04/2022 09:38:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=97
06/04/2022 09:38:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=98
06/04/2022 09:38:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=99
06/04/2022 09:38:22 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.7780522889919805 on epoch=99
06/04/2022 09:38:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=101
06/04/2022 09:38:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=102
06/04/2022 09:38:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=103
06/04/2022 09:38:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=104
06/04/2022 09:38:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=106
06/04/2022 09:38:37 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7874011733361105 on epoch=106
06/04/2022 09:38:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=107
06/04/2022 09:38:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=108
06/04/2022 09:38:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=109
06/04/2022 09:38:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=111
06/04/2022 09:38:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=112
06/04/2022 09:38:52 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.7633718703842156 on epoch=112
06/04/2022 09:38:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=113
06/04/2022 09:38:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=114
06/04/2022 09:39:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=116
06/04/2022 09:39:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=117
06/04/2022 09:39:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=118
06/04/2022 09:39:07 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7241127038796049 on epoch=118
06/04/2022 09:39:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=119
06/04/2022 09:39:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=121
06/04/2022 09:39:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=122
06/04/2022 09:39:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=123
06/04/2022 09:39:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=124
06/04/2022 09:39:22 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7504284447946419 on epoch=124
06/04/2022 09:39:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=126
06/04/2022 09:39:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=127
06/04/2022 09:39:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=128
06/04/2022 09:39:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=129
06/04/2022 09:39:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=131
06/04/2022 09:39:38 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7860310216460501 on epoch=131
06/04/2022 09:39:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=132
06/04/2022 09:39:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=133
06/04/2022 09:39:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=134
06/04/2022 09:39:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=136
06/04/2022 09:39:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=137
06/04/2022 09:39:53 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7490623397553293 on epoch=137
06/04/2022 09:39:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=138
06/04/2022 09:39:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=139
06/04/2022 09:40:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=141
06/04/2022 09:40:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=142
06/04/2022 09:40:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=143
06/04/2022 09:40:08 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7476623376623377 on epoch=143
06/04/2022 09:40:11 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=144
06/04/2022 09:40:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=146
06/04/2022 09:40:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=147
06/04/2022 09:40:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=148
06/04/2022 09:40:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=149
06/04/2022 09:40:23 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.703745392538496 on epoch=149
06/04/2022 09:40:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=151
06/04/2022 09:40:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=152
06/04/2022 09:40:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=153
06/04/2022 09:40:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=154
06/04/2022 09:40:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=156
06/04/2022 09:40:39 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7416559691912709 on epoch=156
06/04/2022 09:40:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=157
06/04/2022 09:40:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=158
06/04/2022 09:40:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=159
06/04/2022 09:40:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=161
06/04/2022 09:40:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=162
06/04/2022 09:40:54 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7560666999230945 on epoch=162
06/04/2022 09:40:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=163
06/04/2022 09:41:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=164
06/04/2022 09:41:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=166
06/04/2022 09:41:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=167
06/04/2022 09:41:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=168
06/04/2022 09:41:10 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7175673858976945 on epoch=168
06/04/2022 09:41:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=169
06/04/2022 09:41:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=171
06/04/2022 09:41:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=172
06/04/2022 09:41:20 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=173
06/04/2022 09:41:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=174
06/04/2022 09:41:25 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7514696992195402 on epoch=174
06/04/2022 09:41:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=176
06/04/2022 09:41:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=177
06/04/2022 09:41:32 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=178
06/04/2022 09:41:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=179
06/04/2022 09:41:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=181
06/04/2022 09:41:40 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.738868532089718 on epoch=181
06/04/2022 09:41:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=182
06/04/2022 09:41:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=183
06/04/2022 09:41:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=184
06/04/2022 09:41:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=186
06/04/2022 09:41:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=187
06/04/2022 09:41:55 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7558434912537106 on epoch=187
06/04/2022 09:41:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=188
06/04/2022 09:42:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=189
06/04/2022 09:42:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=191
06/04/2022 09:42:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
06/04/2022 09:42:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=193
06/04/2022 09:42:10 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8051256376819901 on epoch=193
06/04/2022 09:42:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7900825847580412 -> 0.8051256376819901 on epoch=193, global_step=1550
06/04/2022 09:42:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=194
06/04/2022 09:42:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=196
06/04/2022 09:42:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=197
06/04/2022 09:42:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=198
06/04/2022 09:42:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=199
06/04/2022 09:42:26 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7889319653299915 on epoch=199
06/04/2022 09:42:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=201
06/04/2022 09:42:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=202
06/04/2022 09:42:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=203
06/04/2022 09:42:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=204
06/04/2022 09:42:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=206
06/04/2022 09:42:41 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7968578296703297 on epoch=206
06/04/2022 09:42:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
06/04/2022 09:42:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
06/04/2022 09:42:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=209
06/04/2022 09:42:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=211
06/04/2022 09:42:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
06/04/2022 09:42:56 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7492004253990555 on epoch=212
06/04/2022 09:42:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=213
06/04/2022 09:43:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=214
06/04/2022 09:43:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=216
06/04/2022 09:43:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=217
06/04/2022 09:43:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=218
06/04/2022 09:43:11 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7598368831778443 on epoch=218
06/04/2022 09:43:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=219
06/04/2022 09:43:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=221
06/04/2022 09:43:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=222
06/04/2022 09:43:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=223
06/04/2022 09:43:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 09:43:26 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7598395362503515 on epoch=224
06/04/2022 09:43:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=226
06/04/2022 09:43:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=227
06/04/2022 09:43:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=228
06/04/2022 09:43:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=229
06/04/2022 09:43:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=231
06/04/2022 09:43:42 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.812465299085357 on epoch=231
06/04/2022 09:43:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8051256376819901 -> 0.812465299085357 on epoch=231, global_step=1850
06/04/2022 09:43:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=232
06/04/2022 09:43:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=233
06/04/2022 09:43:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
06/04/2022 09:43:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=236
06/04/2022 09:43:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/04/2022 09:43:58 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8029695450748083 on epoch=237
06/04/2022 09:44:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
06/04/2022 09:44:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=239
06/04/2022 09:44:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=241
06/04/2022 09:44:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=242
06/04/2022 09:44:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=243
06/04/2022 09:44:13 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8255935316874948 on epoch=243
06/04/2022 09:44:14 - INFO - __main__ - Saving model with best Classification-F1: 0.812465299085357 -> 0.8255935316874948 on epoch=243, global_step=1950
06/04/2022 09:44:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=244
06/04/2022 09:44:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=246
06/04/2022 09:44:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
06/04/2022 09:44:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
06/04/2022 09:44:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=249
06/04/2022 09:44:30 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7516509634156692 on epoch=249
06/04/2022 09:44:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=251
06/04/2022 09:44:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=252
06/04/2022 09:44:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=253
06/04/2022 09:44:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=254
06/04/2022 09:44:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=256
06/04/2022 09:44:45 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7843253968253968 on epoch=256
06/04/2022 09:44:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=257
06/04/2022 09:44:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
06/04/2022 09:44:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
06/04/2022 09:44:56 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=261
06/04/2022 09:44:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 09:45:01 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.845817779795534 on epoch=262
06/04/2022 09:45:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8255935316874948 -> 0.845817779795534 on epoch=262, global_step=2100
06/04/2022 09:45:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=263
06/04/2022 09:45:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
06/04/2022 09:45:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=266
06/04/2022 09:45:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=267
06/04/2022 09:45:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/04/2022 09:45:16 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7999542124542124 on epoch=268
06/04/2022 09:45:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=269
06/04/2022 09:45:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 09:45:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=272
06/04/2022 09:45:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=273
06/04/2022 09:45:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
06/04/2022 09:45:32 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.8517360775425291 on epoch=274
06/04/2022 09:45:32 - INFO - __main__ - Saving model with best Classification-F1: 0.845817779795534 -> 0.8517360775425291 on epoch=274, global_step=2200
06/04/2022 09:45:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 09:45:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=277
06/04/2022 09:45:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=278
06/04/2022 09:45:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/04/2022 09:45:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/04/2022 09:45:48 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8358203062374525 on epoch=281
06/04/2022 09:45:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=282
06/04/2022 09:45:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/04/2022 09:45:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=284
06/04/2022 09:45:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=286
06/04/2022 09:46:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/04/2022 09:46:04 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7696962751591967 on epoch=287
06/04/2022 09:46:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
06/04/2022 09:46:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=289
06/04/2022 09:46:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
06/04/2022 09:46:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/04/2022 09:46:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
06/04/2022 09:46:19 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6753802938634398 on epoch=293
06/04/2022 09:46:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
06/04/2022 09:46:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/04/2022 09:46:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
06/04/2022 09:46:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=298
06/04/2022 09:46:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
06/04/2022 09:46:35 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.771729176620481 on epoch=299
06/04/2022 09:46:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
06/04/2022 09:46:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
06/04/2022 09:46:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=303
06/04/2022 09:46:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
06/04/2022 09:46:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=306
06/04/2022 09:46:51 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7973942892806991 on epoch=306
06/04/2022 09:46:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=307
06/04/2022 09:46:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=308
06/04/2022 09:46:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/04/2022 09:47:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
06/04/2022 09:47:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
06/04/2022 09:47:07 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8054191775965969 on epoch=312
06/04/2022 09:47:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
06/04/2022 09:47:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 09:47:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
06/04/2022 09:47:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
06/04/2022 09:47:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/04/2022 09:47:23 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8077998974676064 on epoch=318
06/04/2022 09:47:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
06/04/2022 09:47:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=321
06/04/2022 09:47:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 09:47:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
06/04/2022 09:47:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
06/04/2022 09:47:39 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8016454101716265 on epoch=324
06/04/2022 09:47:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=326
06/04/2022 09:47:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 09:47:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
06/04/2022 09:47:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
06/04/2022 09:47:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
06/04/2022 09:47:55 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8117216117216117 on epoch=331
06/04/2022 09:47:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
06/04/2022 09:48:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=333
06/04/2022 09:48:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/04/2022 09:48:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=336
06/04/2022 09:48:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=337
06/04/2022 09:48:10 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7546977717066508 on epoch=337
06/04/2022 09:48:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 09:48:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=339
06/04/2022 09:48:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=341
06/04/2022 09:48:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/04/2022 09:48:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=343
06/04/2022 09:48:26 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8118146929824561 on epoch=343
06/04/2022 09:48:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/04/2022 09:48:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=346
06/04/2022 09:48:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
06/04/2022 09:48:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 09:48:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
06/04/2022 09:48:42 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8066722837425775 on epoch=349
06/04/2022 09:48:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
06/04/2022 09:48:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
06/04/2022 09:48:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
06/04/2022 09:48:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
06/04/2022 09:48:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/04/2022 09:48:58 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8008695305910419 on epoch=356
06/04/2022 09:49:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/04/2022 09:49:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
06/04/2022 09:49:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
06/04/2022 09:49:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
06/04/2022 09:49:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
06/04/2022 09:49:14 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7624484139674419 on epoch=362
06/04/2022 09:49:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/04/2022 09:49:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=364
06/04/2022 09:49:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=366
06/04/2022 09:49:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
06/04/2022 09:49:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 09:49:30 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8198657257239707 on epoch=368
06/04/2022 09:49:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.08 on epoch=369
06/04/2022 09:49:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=371
06/04/2022 09:49:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 09:49:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/04/2022 09:49:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 09:49:44 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:49:44 - INFO - __main__ - Printing 3 examples
06/04/2022 09:49:44 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 09:49:44 - INFO - __main__ - ['others']
06/04/2022 09:49:44 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 09:49:44 - INFO - __main__ - ['others']
06/04/2022 09:49:44 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 09:49:44 - INFO - __main__ - ['others']
06/04/2022 09:49:44 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:49:44 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:49:44 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 09:49:44 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:49:44 - INFO - __main__ - Printing 3 examples
06/04/2022 09:49:44 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 09:49:44 - INFO - __main__ - ['others']
06/04/2022 09:49:44 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 09:49:44 - INFO - __main__ - ['others']
06/04/2022 09:49:44 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 09:49:44 - INFO - __main__ - ['others']
06/04/2022 09:49:44 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:49:44 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:49:45 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 09:49:45 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7472911120452104 on epoch=374
06/04/2022 09:49:45 - INFO - __main__ - save last model!
06/04/2022 09:49:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 09:49:45 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 09:49:45 - INFO - __main__ - Printing 3 examples
06/04/2022 09:49:45 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 09:49:45 - INFO - __main__ - ['others']
06/04/2022 09:49:45 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 09:49:45 - INFO - __main__ - ['others']
06/04/2022 09:49:45 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 09:49:45 - INFO - __main__ - ['others']
06/04/2022 09:49:45 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:49:48 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:49:54 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 09:50:03 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 09:50:03 - INFO - __main__ - task name: emo
06/04/2022 09:50:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 09:50:04 - INFO - __main__ - Starting training!
06/04/2022 09:51:21 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_87_0.5_8_predictions.txt
06/04/2022 09:51:21 - INFO - __main__ - Classification-F1 on test data: 0.3631
06/04/2022 09:51:22 - INFO - __main__ - prefix=emo_32_87, lr=0.5, bsz=8, dev_performance=0.8517360775425291, test_performance=0.3631337125349152
06/04/2022 09:51:22 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.4, bsz=8 ...
06/04/2022 09:51:23 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:51:23 - INFO - __main__ - Printing 3 examples
06/04/2022 09:51:23 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 09:51:23 - INFO - __main__ - ['others']
06/04/2022 09:51:23 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 09:51:23 - INFO - __main__ - ['others']
06/04/2022 09:51:23 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 09:51:23 - INFO - __main__ - ['others']
06/04/2022 09:51:23 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:51:23 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:51:23 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 09:51:23 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 09:51:23 - INFO - __main__ - Printing 3 examples
06/04/2022 09:51:23 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 09:51:23 - INFO - __main__ - ['others']
06/04/2022 09:51:23 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 09:51:23 - INFO - __main__ - ['others']
06/04/2022 09:51:23 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 09:51:23 - INFO - __main__ - ['others']
06/04/2022 09:51:23 - INFO - __main__ - Tokenizing Input ...
06/04/2022 09:51:23 - INFO - __main__ - Tokenizing Output ...
06/04/2022 09:51:23 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 09:51:38 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 09:51:38 - INFO - __main__ - task name: emo
06/04/2022 09:51:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 09:51:39 - INFO - __main__ - Starting training!
06/04/2022 09:51:42 - INFO - __main__ - Step 10 Global step 10 Train loss 7.10 on epoch=1
06/04/2022 09:51:44 - INFO - __main__ - Step 20 Global step 20 Train loss 3.59 on epoch=2
06/04/2022 09:51:47 - INFO - __main__ - Step 30 Global step 30 Train loss 1.97 on epoch=3
06/04/2022 09:51:50 - INFO - __main__ - Step 40 Global step 40 Train loss 1.37 on epoch=4
06/04/2022 09:51:52 - INFO - __main__ - Step 50 Global step 50 Train loss 1.21 on epoch=6
06/04/2022 09:51:54 - INFO - __main__ - Global step 50 Train loss 3.04 Classification-F1 0.16252355225216786 on epoch=6
06/04/2022 09:51:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16252355225216786 on epoch=6, global_step=50
06/04/2022 09:51:57 - INFO - __main__ - Step 60 Global step 60 Train loss 1.12 on epoch=7
06/04/2022 09:51:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.14 on epoch=8
06/04/2022 09:52:02 - INFO - __main__ - Step 80 Global step 80 Train loss 1.05 on epoch=9
06/04/2022 09:52:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.06 on epoch=11
06/04/2022 09:52:07 - INFO - __main__ - Step 100 Global step 100 Train loss 1.03 on epoch=12
06/04/2022 09:52:09 - INFO - __main__ - Global step 100 Train loss 1.08 Classification-F1 0.11578044596912522 on epoch=12
06/04/2022 09:52:12 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=13
06/04/2022 09:52:14 - INFO - __main__ - Step 120 Global step 120 Train loss 1.01 on epoch=14
06/04/2022 09:52:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=16
06/04/2022 09:52:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.89 on epoch=17
06/04/2022 09:52:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.85 on epoch=18
06/04/2022 09:52:24 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.1454212454212454 on epoch=18
06/04/2022 09:52:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.85 on epoch=19
06/04/2022 09:52:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=21
06/04/2022 09:52:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.84 on epoch=22
06/04/2022 09:52:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.78 on epoch=23
06/04/2022 09:52:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.85 on epoch=24
06/04/2022 09:52:38 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.14476797088262056 on epoch=24
06/04/2022 09:52:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=26
06/04/2022 09:52:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.93 on epoch=27
06/04/2022 09:52:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=28
06/04/2022 09:52:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.81 on epoch=29
06/04/2022 09:52:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=31
06/04/2022 09:52:53 - INFO - __main__ - Global step 250 Train loss 0.86 Classification-F1 0.18518518518518517 on epoch=31
06/04/2022 09:52:53 - INFO - __main__ - Saving model with best Classification-F1: 0.16252355225216786 -> 0.18518518518518517 on epoch=31, global_step=250
06/04/2022 09:52:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.75 on epoch=32
06/04/2022 09:52:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.80 on epoch=33
06/04/2022 09:53:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.83 on epoch=34
06/04/2022 09:53:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.81 on epoch=36
06/04/2022 09:53:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.72 on epoch=37
06/04/2022 09:53:08 - INFO - __main__ - Global step 300 Train loss 0.78 Classification-F1 0.1600439882697947 on epoch=37
06/04/2022 09:53:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.73 on epoch=38
06/04/2022 09:53:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.87 on epoch=39
06/04/2022 09:53:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=41
06/04/2022 09:53:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.73 on epoch=42
06/04/2022 09:53:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.69 on epoch=43
06/04/2022 09:53:22 - INFO - __main__ - Global step 350 Train loss 0.74 Classification-F1 0.1 on epoch=43
06/04/2022 09:53:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.70 on epoch=44
06/04/2022 09:53:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.67 on epoch=46
06/04/2022 09:53:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.66 on epoch=47
06/04/2022 09:53:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.67 on epoch=48
06/04/2022 09:53:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=49
06/04/2022 09:53:37 - INFO - __main__ - Global step 400 Train loss 0.65 Classification-F1 0.39388062917474687 on epoch=49
06/04/2022 09:53:37 - INFO - __main__ - Saving model with best Classification-F1: 0.18518518518518517 -> 0.39388062917474687 on epoch=49, global_step=400
06/04/2022 09:53:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.63 on epoch=51
06/04/2022 09:53:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=52
06/04/2022 09:53:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=53
06/04/2022 09:53:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.61 on epoch=54
06/04/2022 09:53:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.50 on epoch=56
06/04/2022 09:53:51 - INFO - __main__ - Global step 450 Train loss 0.57 Classification-F1 0.38170192978377127 on epoch=56
06/04/2022 09:53:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=57
06/04/2022 09:53:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=58
06/04/2022 09:53:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.56 on epoch=59
06/04/2022 09:54:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=61
06/04/2022 09:54:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=62
06/04/2022 09:54:06 - INFO - __main__ - Global step 500 Train loss 0.48 Classification-F1 0.6615530303030303 on epoch=62
06/04/2022 09:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.39388062917474687 -> 0.6615530303030303 on epoch=62, global_step=500
06/04/2022 09:54:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=63
06/04/2022 09:54:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.51 on epoch=64
06/04/2022 09:54:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.45 on epoch=66
06/04/2022 09:54:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=67
06/04/2022 09:54:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=68
06/04/2022 09:54:21 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.5008500856152841 on epoch=68
06/04/2022 09:54:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=69
06/04/2022 09:54:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.43 on epoch=71
06/04/2022 09:54:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.46 on epoch=72
06/04/2022 09:54:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=73
06/04/2022 09:54:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=74
06/04/2022 09:54:35 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.5903386911595867 on epoch=74
06/04/2022 09:54:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=76
06/04/2022 09:54:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=77
06/04/2022 09:54:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.33 on epoch=78
06/04/2022 09:54:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=79
06/04/2022 09:54:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=81
06/04/2022 09:54:50 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.664739608217869 on epoch=81
06/04/2022 09:54:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6615530303030303 -> 0.664739608217869 on epoch=81, global_step=650
06/04/2022 09:54:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.37 on epoch=82
06/04/2022 09:54:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.31 on epoch=83
06/04/2022 09:54:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=84
06/04/2022 09:55:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=86
06/04/2022 09:55:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=87
06/04/2022 09:55:04 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.638720150816925 on epoch=87
06/04/2022 09:55:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=88
06/04/2022 09:55:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=89
06/04/2022 09:55:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=91
06/04/2022 09:55:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=92
06/04/2022 09:55:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=93
06/04/2022 09:55:19 - INFO - __main__ - Global step 750 Train loss 0.29 Classification-F1 0.6337486573576799 on epoch=93
06/04/2022 09:55:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=94
06/04/2022 09:55:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=96
06/04/2022 09:55:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=97
06/04/2022 09:55:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=98
06/04/2022 09:55:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=99
06/04/2022 09:55:34 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.6370747724474275 on epoch=99
06/04/2022 09:55:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.28 on epoch=101
06/04/2022 09:55:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=102
06/04/2022 09:55:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=103
06/04/2022 09:55:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=104
06/04/2022 09:55:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=106
06/04/2022 09:55:48 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.6881492402477538 on epoch=106
06/04/2022 09:55:48 - INFO - __main__ - Saving model with best Classification-F1: 0.664739608217869 -> 0.6881492402477538 on epoch=106, global_step=850
06/04/2022 09:55:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=107
06/04/2022 09:55:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=108
06/04/2022 09:55:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=109
06/04/2022 09:55:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=111
06/04/2022 09:56:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=112
06/04/2022 09:56:03 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.6731748595152064 on epoch=112
06/04/2022 09:56:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=113
06/04/2022 09:56:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=114
06/04/2022 09:56:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=116
06/04/2022 09:56:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=117
06/04/2022 09:56:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=118
06/04/2022 09:56:18 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.683813499119964 on epoch=118
06/04/2022 09:56:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=119
06/04/2022 09:56:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=121
06/04/2022 09:56:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=122
06/04/2022 09:56:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=123
06/04/2022 09:56:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=124
06/04/2022 09:56:33 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6094558332930426 on epoch=124
06/04/2022 09:56:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=126
06/04/2022 09:56:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=127
06/04/2022 09:56:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=128
06/04/2022 09:56:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=129
06/04/2022 09:56:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=131
06/04/2022 09:56:47 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6195567274626904 on epoch=131
06/04/2022 09:56:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=132
06/04/2022 09:56:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=133
06/04/2022 09:56:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=134
06/04/2022 09:56:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=136
06/04/2022 09:57:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=137
06/04/2022 09:57:02 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6960127591706539 on epoch=137
06/04/2022 09:57:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6881492402477538 -> 0.6960127591706539 on epoch=137, global_step=1100
06/04/2022 09:57:04 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=138
06/04/2022 09:57:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=139
06/04/2022 09:57:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=141
06/04/2022 09:57:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=142
06/04/2022 09:57:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=143
06/04/2022 09:57:17 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7339981969799414 on epoch=143
06/04/2022 09:57:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6960127591706539 -> 0.7339981969799414 on epoch=143, global_step=1150
06/04/2022 09:57:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=144
06/04/2022 09:57:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=146
06/04/2022 09:57:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=147
06/04/2022 09:57:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=148
06/04/2022 09:57:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=149
06/04/2022 09:57:32 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6854262427647259 on epoch=149
06/04/2022 09:57:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=151
06/04/2022 09:57:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=152
06/04/2022 09:57:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=153
06/04/2022 09:57:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=154
06/04/2022 09:57:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=156
06/04/2022 09:57:46 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.6615147865649672 on epoch=156
06/04/2022 09:57:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=157
06/04/2022 09:57:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=158
06/04/2022 09:57:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=159
06/04/2022 09:57:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=161
06/04/2022 09:57:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=162
06/04/2022 09:58:01 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7833031242867309 on epoch=162
06/04/2022 09:58:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7339981969799414 -> 0.7833031242867309 on epoch=162, global_step=1300
06/04/2022 09:58:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=163
06/04/2022 09:58:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=164
06/04/2022 09:58:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=166
06/04/2022 09:58:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=167
06/04/2022 09:58:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=168
06/04/2022 09:58:16 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7790912976391413 on epoch=168
06/04/2022 09:58:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=169
06/04/2022 09:58:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=171
06/04/2022 09:58:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=172
06/04/2022 09:58:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=173
06/04/2022 09:58:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=174
06/04/2022 09:58:31 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7244549411873669 on epoch=174
06/04/2022 09:58:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=176
06/04/2022 09:58:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=177
06/04/2022 09:58:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=178
06/04/2022 09:58:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=179
06/04/2022 09:58:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=181
06/04/2022 09:58:46 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6654029372458291 on epoch=181
06/04/2022 09:58:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=182
06/04/2022 09:58:51 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=183
06/04/2022 09:58:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
06/04/2022 09:58:56 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=186
06/04/2022 09:58:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=187
06/04/2022 09:59:01 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7102623456790124 on epoch=187
06/04/2022 09:59:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=188
06/04/2022 09:59:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=189
06/04/2022 09:59:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=191
06/04/2022 09:59:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=192
06/04/2022 09:59:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=193
06/04/2022 09:59:16 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.742739898989899 on epoch=193
06/04/2022 09:59:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=194
06/04/2022 09:59:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=196
06/04/2022 09:59:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=197
06/04/2022 09:59:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=198
06/04/2022 09:59:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=199
06/04/2022 09:59:30 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7338024911619917 on epoch=199
06/04/2022 09:59:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=201
06/04/2022 09:59:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=202
06/04/2022 09:59:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=203
06/04/2022 09:59:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=204
06/04/2022 09:59:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=206
06/04/2022 09:59:45 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7561862695113342 on epoch=206
06/04/2022 09:59:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=207
06/04/2022 09:59:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
06/04/2022 09:59:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=209
06/04/2022 09:59:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=211
06/04/2022 09:59:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
06/04/2022 09:59:59 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6538672018973446 on epoch=212
06/04/2022 10:00:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=213
06/04/2022 10:00:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=214
06/04/2022 10:00:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=216
06/04/2022 10:00:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=217
06/04/2022 10:00:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=218
06/04/2022 10:00:14 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7485640720934837 on epoch=218
06/04/2022 10:00:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
06/04/2022 10:00:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=221
06/04/2022 10:00:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=222
06/04/2022 10:00:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=223
06/04/2022 10:00:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
06/04/2022 10:00:28 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7609421670614893 on epoch=224
06/04/2022 10:00:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=226
06/04/2022 10:00:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=227
06/04/2022 10:00:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=228
06/04/2022 10:00:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=229
06/04/2022 10:00:41 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=231
06/04/2022 10:00:43 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7350974762117157 on epoch=231
06/04/2022 10:00:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=232
06/04/2022 10:00:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
06/04/2022 10:00:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=234
06/04/2022 10:00:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=236
06/04/2022 10:00:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
06/04/2022 10:00:58 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7150252525252526 on epoch=237
06/04/2022 10:01:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
06/04/2022 10:01:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
06/04/2022 10:01:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=241
06/04/2022 10:01:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
06/04/2022 10:01:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=243
06/04/2022 10:01:12 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7443218795485548 on epoch=243
06/04/2022 10:01:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
06/04/2022 10:01:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=246
06/04/2022 10:01:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
06/04/2022 10:01:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
06/04/2022 10:01:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=249
06/04/2022 10:01:27 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7965298142717498 on epoch=249
06/04/2022 10:01:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7833031242867309 -> 0.7965298142717498 on epoch=249, global_step=2000
06/04/2022 10:01:29 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=251
06/04/2022 10:01:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
06/04/2022 10:01:34 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=253
06/04/2022 10:01:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
06/04/2022 10:01:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=256
06/04/2022 10:01:42 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7705689933323489 on epoch=256
06/04/2022 10:01:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=257
06/04/2022 10:01:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
06/04/2022 10:01:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
06/04/2022 10:01:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
06/04/2022 10:01:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=262
06/04/2022 10:01:56 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7806678255830798 on epoch=262
06/04/2022 10:01:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
06/04/2022 10:02:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
06/04/2022 10:02:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/04/2022 10:02:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=267
06/04/2022 10:02:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=268
06/04/2022 10:02:11 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8064878273713857 on epoch=268
06/04/2022 10:02:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7965298142717498 -> 0.8064878273713857 on epoch=268, global_step=2150
06/04/2022 10:02:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
06/04/2022 10:02:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
06/04/2022 10:02:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=272
06/04/2022 10:02:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
06/04/2022 10:02:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
06/04/2022 10:02:26 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7715477710703506 on epoch=274
06/04/2022 10:02:29 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
06/04/2022 10:02:31 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=277
06/04/2022 10:02:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/04/2022 10:02:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
06/04/2022 10:02:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
06/04/2022 10:02:41 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7295290975705385 on epoch=281
06/04/2022 10:02:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=282
06/04/2022 10:02:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
06/04/2022 10:02:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=284
06/04/2022 10:02:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
06/04/2022 10:02:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
06/04/2022 10:02:56 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6373670268649052 on epoch=287
06/04/2022 10:02:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=288
06/04/2022 10:03:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=289
06/04/2022 10:03:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=291
06/04/2022 10:03:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/04/2022 10:03:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
06/04/2022 10:03:11 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7267086050930345 on epoch=293
06/04/2022 10:03:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
06/04/2022 10:03:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
06/04/2022 10:03:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
06/04/2022 10:03:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
06/04/2022 10:03:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
06/04/2022 10:03:27 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7838687628161313 on epoch=299
06/04/2022 10:03:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=301
06/04/2022 10:03:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=302
06/04/2022 10:03:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=303
06/04/2022 10:03:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=304
06/04/2022 10:03:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
06/04/2022 10:03:42 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7218648412103026 on epoch=306
06/04/2022 10:03:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
06/04/2022 10:03:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/04/2022 10:03:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
06/04/2022 10:03:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=311
06/04/2022 10:03:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/04/2022 10:03:57 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6607696397170082 on epoch=312
06/04/2022 10:04:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
06/04/2022 10:04:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=314
06/04/2022 10:04:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=316
06/04/2022 10:04:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/04/2022 10:04:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/04/2022 10:04:13 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7893457682562421 on epoch=318
06/04/2022 10:04:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
06/04/2022 10:04:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
06/04/2022 10:04:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=322
06/04/2022 10:04:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=323
06/04/2022 10:04:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
06/04/2022 10:04:28 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7620707414750851 on epoch=324
06/04/2022 10:04:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=326
06/04/2022 10:04:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.19 on epoch=327
06/04/2022 10:04:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
06/04/2022 10:04:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/04/2022 10:04:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
06/04/2022 10:04:44 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7747702589807852 on epoch=331
06/04/2022 10:04:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
06/04/2022 10:04:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
06/04/2022 10:04:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/04/2022 10:04:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=336
06/04/2022 10:04:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=337
06/04/2022 10:04:59 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7784016448045734 on epoch=337
06/04/2022 10:05:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
06/04/2022 10:05:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/04/2022 10:05:07 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=341
06/04/2022 10:05:10 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
06/04/2022 10:05:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
06/04/2022 10:05:15 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.8015114529599607 on epoch=343
06/04/2022 10:05:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=344
06/04/2022 10:05:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
06/04/2022 10:05:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
06/04/2022 10:05:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 10:05:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 10:05:31 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7944508902041625 on epoch=349
06/04/2022 10:05:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
06/04/2022 10:05:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/04/2022 10:05:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
06/04/2022 10:05:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
06/04/2022 10:05:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
06/04/2022 10:05:46 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7567633459436738 on epoch=356
06/04/2022 10:05:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
06/04/2022 10:05:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
06/04/2022 10:05:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 10:05:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/04/2022 10:05:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
06/04/2022 10:06:02 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7569555035483324 on epoch=362
06/04/2022 10:06:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=363
06/04/2022 10:06:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
06/04/2022 10:06:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
06/04/2022 10:06:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
06/04/2022 10:06:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
06/04/2022 10:06:18 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7876162658802177 on epoch=368
06/04/2022 10:06:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
06/04/2022 10:06:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.14 on epoch=371
06/04/2022 10:06:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
06/04/2022 10:06:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
06/04/2022 10:06:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
06/04/2022 10:06:33 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:06:33 - INFO - __main__ - Printing 3 examples
06/04/2022 10:06:33 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 10:06:33 - INFO - __main__ - ['others']
06/04/2022 10:06:33 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 10:06:33 - INFO - __main__ - ['others']
06/04/2022 10:06:33 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 10:06:33 - INFO - __main__ - ['others']
06/04/2022 10:06:33 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:06:33 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:06:33 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 10:06:33 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:06:33 - INFO - __main__ - Printing 3 examples
06/04/2022 10:06:33 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 10:06:33 - INFO - __main__ - ['others']
06/04/2022 10:06:33 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 10:06:33 - INFO - __main__ - ['others']
06/04/2022 10:06:33 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 10:06:33 - INFO - __main__ - ['others']
06/04/2022 10:06:33 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:06:33 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:06:33 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 10:06:34 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.804374426044221 on epoch=374
06/04/2022 10:06:34 - INFO - __main__ - save last model!
06/04/2022 10:06:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 10:06:34 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 10:06:34 - INFO - __main__ - Printing 3 examples
06/04/2022 10:06:34 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 10:06:34 - INFO - __main__ - ['others']
06/04/2022 10:06:34 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 10:06:34 - INFO - __main__ - ['others']
06/04/2022 10:06:34 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 10:06:34 - INFO - __main__ - ['others']
06/04/2022 10:06:34 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:06:36 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:06:42 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 10:06:48 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 10:06:48 - INFO - __main__ - task name: emo
06/04/2022 10:06:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 10:06:49 - INFO - __main__ - Starting training!
06/04/2022 10:08:20 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_87_0.4_8_predictions.txt
06/04/2022 10:08:20 - INFO - __main__ - Classification-F1 on test data: 0.4601
06/04/2022 10:08:21 - INFO - __main__ - prefix=emo_32_87, lr=0.4, bsz=8, dev_performance=0.8064878273713857, test_performance=0.4601159797692467
06/04/2022 10:08:21 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.3, bsz=8 ...
06/04/2022 10:08:22 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:08:22 - INFO - __main__ - Printing 3 examples
06/04/2022 10:08:22 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 10:08:22 - INFO - __main__ - ['others']
06/04/2022 10:08:22 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 10:08:22 - INFO - __main__ - ['others']
06/04/2022 10:08:22 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 10:08:22 - INFO - __main__ - ['others']
06/04/2022 10:08:22 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:08:22 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:08:22 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 10:08:22 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:08:22 - INFO - __main__ - Printing 3 examples
06/04/2022 10:08:22 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 10:08:22 - INFO - __main__ - ['others']
06/04/2022 10:08:22 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 10:08:22 - INFO - __main__ - ['others']
06/04/2022 10:08:22 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 10:08:22 - INFO - __main__ - ['others']
06/04/2022 10:08:22 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:08:22 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:08:22 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 10:08:37 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 10:08:37 - INFO - __main__ - task name: emo
06/04/2022 10:08:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 10:08:38 - INFO - __main__ - Starting training!
06/04/2022 10:08:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.65 on epoch=1
06/04/2022 10:08:44 - INFO - __main__ - Step 20 Global step 20 Train loss 4.37 on epoch=2
06/04/2022 10:08:47 - INFO - __main__ - Step 30 Global step 30 Train loss 2.25 on epoch=3
06/04/2022 10:08:49 - INFO - __main__ - Step 40 Global step 40 Train loss 1.43 on epoch=4
06/04/2022 10:08:52 - INFO - __main__ - Step 50 Global step 50 Train loss 1.18 on epoch=6
06/04/2022 10:08:54 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.13034188034188032 on epoch=6
06/04/2022 10:08:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13034188034188032 on epoch=6, global_step=50
06/04/2022 10:08:56 - INFO - __main__ - Step 60 Global step 60 Train loss 1.13 on epoch=7
06/04/2022 10:08:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.01 on epoch=8
06/04/2022 10:09:01 - INFO - __main__ - Step 80 Global step 80 Train loss 1.02 on epoch=9
06/04/2022 10:09:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=11
06/04/2022 10:09:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=12
06/04/2022 10:09:08 - INFO - __main__ - Global step 100 Train loss 1.00 Classification-F1 0.1558572146807441 on epoch=12
06/04/2022 10:09:08 - INFO - __main__ - Saving model with best Classification-F1: 0.13034188034188032 -> 0.1558572146807441 on epoch=12, global_step=100
06/04/2022 10:09:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=13
06/04/2022 10:09:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=14
06/04/2022 10:09:16 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=16
06/04/2022 10:09:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=17
06/04/2022 10:09:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.96 on epoch=18
06/04/2022 10:09:23 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.1844626388104649 on epoch=18
06/04/2022 10:09:23 - INFO - __main__ - Saving model with best Classification-F1: 0.1558572146807441 -> 0.1844626388104649 on epoch=18, global_step=150
06/04/2022 10:09:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.89 on epoch=19
06/04/2022 10:09:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=21
06/04/2022 10:09:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.90 on epoch=22
06/04/2022 10:09:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=23
06/04/2022 10:09:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=24
06/04/2022 10:09:38 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.24373270649723305 on epoch=24
06/04/2022 10:09:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1844626388104649 -> 0.24373270649723305 on epoch=24, global_step=200
06/04/2022 10:09:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=26
06/04/2022 10:09:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.83 on epoch=27
06/04/2022 10:09:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.82 on epoch=28
06/04/2022 10:09:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=29
06/04/2022 10:09:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.79 on epoch=31
06/04/2022 10:09:53 - INFO - __main__ - Global step 250 Train loss 0.82 Classification-F1 0.3668335241723834 on epoch=31
06/04/2022 10:09:53 - INFO - __main__ - Saving model with best Classification-F1: 0.24373270649723305 -> 0.3668335241723834 on epoch=31, global_step=250
06/04/2022 10:09:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.85 on epoch=32
06/04/2022 10:09:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=33
06/04/2022 10:10:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=34
06/04/2022 10:10:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=36
06/04/2022 10:10:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.71 on epoch=37
06/04/2022 10:10:08 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.3289105758582503 on epoch=37
06/04/2022 10:10:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=38
06/04/2022 10:10:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.76 on epoch=39
06/04/2022 10:10:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.73 on epoch=41
06/04/2022 10:10:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.69 on epoch=42
06/04/2022 10:10:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.69 on epoch=43
06/04/2022 10:10:23 - INFO - __main__ - Global step 350 Train loss 0.73 Classification-F1 0.2172738622176824 on epoch=43
06/04/2022 10:10:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.80 on epoch=44
06/04/2022 10:10:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.78 on epoch=46
06/04/2022 10:10:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.74 on epoch=47
06/04/2022 10:10:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.72 on epoch=48
06/04/2022 10:10:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.63 on epoch=49
06/04/2022 10:10:37 - INFO - __main__ - Global step 400 Train loss 0.73 Classification-F1 0.31267224838653407 on epoch=49
06/04/2022 10:10:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.71 on epoch=51
06/04/2022 10:10:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.67 on epoch=52
06/04/2022 10:10:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.68 on epoch=53
06/04/2022 10:10:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.64 on epoch=54
06/04/2022 10:10:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.62 on epoch=56
06/04/2022 10:10:52 - INFO - __main__ - Global step 450 Train loss 0.66 Classification-F1 0.39232048728094454 on epoch=56
06/04/2022 10:10:52 - INFO - __main__ - Saving model with best Classification-F1: 0.3668335241723834 -> 0.39232048728094454 on epoch=56, global_step=450
06/04/2022 10:10:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.68 on epoch=57
06/04/2022 10:10:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.77 on epoch=58
06/04/2022 10:11:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.65 on epoch=59
06/04/2022 10:11:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.64 on epoch=61
06/04/2022 10:11:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.65 on epoch=62
06/04/2022 10:11:07 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.5056947208024203 on epoch=62
06/04/2022 10:11:07 - INFO - __main__ - Saving model with best Classification-F1: 0.39232048728094454 -> 0.5056947208024203 on epoch=62, global_step=500
06/04/2022 10:11:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=63
06/04/2022 10:11:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.55 on epoch=64
06/04/2022 10:11:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.68 on epoch=66
06/04/2022 10:11:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.61 on epoch=67
06/04/2022 10:11:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.55 on epoch=68
06/04/2022 10:11:21 - INFO - __main__ - Global step 550 Train loss 0.59 Classification-F1 0.48225108225108226 on epoch=68
06/04/2022 10:11:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.54 on epoch=69
06/04/2022 10:11:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=71
06/04/2022 10:11:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.60 on epoch=72
06/04/2022 10:11:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.56 on epoch=73
06/04/2022 10:11:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.46 on epoch=74
06/04/2022 10:11:37 - INFO - __main__ - Global step 600 Train loss 0.53 Classification-F1 0.6325950408936258 on epoch=74
06/04/2022 10:11:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5056947208024203 -> 0.6325950408936258 on epoch=74, global_step=600
06/04/2022 10:11:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.61 on epoch=76
06/04/2022 10:11:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=77
06/04/2022 10:11:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=78
06/04/2022 10:11:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.49 on epoch=79
06/04/2022 10:11:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.50 on epoch=81
06/04/2022 10:11:52 - INFO - __main__ - Global step 650 Train loss 0.53 Classification-F1 0.5915437406052537 on epoch=81
06/04/2022 10:11:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=82
06/04/2022 10:11:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.46 on epoch=83
06/04/2022 10:11:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.40 on epoch=84
06/04/2022 10:12:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.46 on epoch=86
06/04/2022 10:12:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.40 on epoch=87
06/04/2022 10:12:06 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.7578919714165615 on epoch=87
06/04/2022 10:12:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6325950408936258 -> 0.7578919714165615 on epoch=87, global_step=700
06/04/2022 10:12:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.48 on epoch=88
06/04/2022 10:12:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.36 on epoch=89
06/04/2022 10:12:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.52 on epoch=91
06/04/2022 10:12:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=92
06/04/2022 10:12:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.38 on epoch=93
06/04/2022 10:12:22 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.6712556727877564 on epoch=93
06/04/2022 10:12:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.35 on epoch=94
06/04/2022 10:12:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=96
06/04/2022 10:12:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=97
06/04/2022 10:12:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.36 on epoch=98
06/04/2022 10:12:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=99
06/04/2022 10:12:37 - INFO - __main__ - Global step 800 Train loss 0.35 Classification-F1 0.702052732924561 on epoch=99
06/04/2022 10:12:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=101
06/04/2022 10:12:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.36 on epoch=102
06/04/2022 10:12:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.38 on epoch=103
06/04/2022 10:12:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.32 on epoch=104
06/04/2022 10:12:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.32 on epoch=106
06/04/2022 10:12:52 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.7046111040312646 on epoch=106
06/04/2022 10:12:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.42 on epoch=107
06/04/2022 10:12:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=108
06/04/2022 10:12:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.31 on epoch=109
06/04/2022 10:13:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=111
06/04/2022 10:13:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=112
06/04/2022 10:13:07 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.70345920561506 on epoch=112
06/04/2022 10:13:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=113
06/04/2022 10:13:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=114
06/04/2022 10:13:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.25 on epoch=116
06/04/2022 10:13:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=117
06/04/2022 10:13:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.32 on epoch=118
06/04/2022 10:13:22 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.6414696393095459 on epoch=118
06/04/2022 10:13:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=119
06/04/2022 10:13:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.30 on epoch=121
06/04/2022 10:13:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=122
06/04/2022 10:13:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=123
06/04/2022 10:13:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.28 on epoch=124
06/04/2022 10:13:37 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.718628988153519 on epoch=124
06/04/2022 10:13:39 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=126
06/04/2022 10:13:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=127
06/04/2022 10:13:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.23 on epoch=128
06/04/2022 10:13:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=129
06/04/2022 10:13:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=131
06/04/2022 10:13:52 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.7218263718263718 on epoch=131
06/04/2022 10:13:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.24 on epoch=132
06/04/2022 10:13:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.25 on epoch=133
06/04/2022 10:14:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=134
06/04/2022 10:14:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=136
06/04/2022 10:14:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=137
06/04/2022 10:14:07 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.8028824545217988 on epoch=137
06/04/2022 10:14:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7578919714165615 -> 0.8028824545217988 on epoch=137, global_step=1100
06/04/2022 10:14:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=138
06/04/2022 10:14:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=139
06/04/2022 10:14:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=141
06/04/2022 10:14:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=142
06/04/2022 10:14:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=143
06/04/2022 10:14:22 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.7246551684421214 on epoch=143
06/04/2022 10:14:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=144
06/04/2022 10:14:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=146
06/04/2022 10:14:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=147
06/04/2022 10:14:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=148
06/04/2022 10:14:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=149
06/04/2022 10:14:37 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.7012636977294644 on epoch=149
06/04/2022 10:14:39 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=151
06/04/2022 10:14:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=152
06/04/2022 10:14:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=153
06/04/2022 10:14:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=154
06/04/2022 10:14:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=156
06/04/2022 10:14:51 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.7667330381880393 on epoch=156
06/04/2022 10:14:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=157
06/04/2022 10:14:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=158
06/04/2022 10:14:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=159
06/04/2022 10:15:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=161
06/04/2022 10:15:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=162
06/04/2022 10:15:06 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7592426253930056 on epoch=162
06/04/2022 10:15:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.24 on epoch=163
06/04/2022 10:15:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=164
06/04/2022 10:15:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=166
06/04/2022 10:15:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=167
06/04/2022 10:15:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.26 on epoch=168
06/04/2022 10:15:22 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.7024080470331748 on epoch=168
06/04/2022 10:15:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=169
06/04/2022 10:15:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=171
06/04/2022 10:15:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=172
06/04/2022 10:15:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=173
06/04/2022 10:15:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=174
06/04/2022 10:15:37 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.7753238816116297 on epoch=174
06/04/2022 10:15:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=176
06/04/2022 10:15:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=177
06/04/2022 10:15:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=178
06/04/2022 10:15:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=179
06/04/2022 10:15:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=181
06/04/2022 10:15:53 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6969401217431168 on epoch=181
06/04/2022 10:15:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=182
06/04/2022 10:15:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=183
06/04/2022 10:16:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=184
06/04/2022 10:16:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=186
06/04/2022 10:16:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=187
06/04/2022 10:16:09 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7611814880035218 on epoch=187
06/04/2022 10:16:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=188
06/04/2022 10:16:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=189
06/04/2022 10:16:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=191
06/04/2022 10:16:20 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=192
06/04/2022 10:16:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=193
06/04/2022 10:16:24 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7580919966165868 on epoch=193
06/04/2022 10:16:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=194
06/04/2022 10:16:30 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.16 on epoch=196
06/04/2022 10:16:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=197
06/04/2022 10:16:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
06/04/2022 10:16:38 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=199
06/04/2022 10:16:40 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.8034017286907393 on epoch=199
06/04/2022 10:16:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8028824545217988 -> 0.8034017286907393 on epoch=199, global_step=1600
06/04/2022 10:16:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=201
06/04/2022 10:16:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=202
06/04/2022 10:16:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=203
06/04/2022 10:16:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=204
06/04/2022 10:16:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=206
06/04/2022 10:16:56 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7612112504353883 on epoch=206
06/04/2022 10:16:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=207
06/04/2022 10:17:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=208
06/04/2022 10:17:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=209
06/04/2022 10:17:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
06/04/2022 10:17:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=212
06/04/2022 10:17:11 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.743629969136752 on epoch=212
06/04/2022 10:17:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=213
06/04/2022 10:17:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=214
06/04/2022 10:17:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=216
06/04/2022 10:17:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=217
06/04/2022 10:17:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=218
06/04/2022 10:17:27 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7415223825379209 on epoch=218
06/04/2022 10:17:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
06/04/2022 10:17:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=221
06/04/2022 10:17:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=222
06/04/2022 10:17:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=223
06/04/2022 10:17:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=224
06/04/2022 10:17:43 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.771045628610372 on epoch=224
06/04/2022 10:17:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=226
06/04/2022 10:17:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=227
06/04/2022 10:17:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=228
06/04/2022 10:17:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=229
06/04/2022 10:17:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=231
06/04/2022 10:17:58 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7527176074770706 on epoch=231
06/04/2022 10:18:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=232
06/04/2022 10:18:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=233
06/04/2022 10:18:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
06/04/2022 10:18:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
06/04/2022 10:18:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=237
06/04/2022 10:18:14 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7574225865209472 on epoch=237
06/04/2022 10:18:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
06/04/2022 10:18:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
06/04/2022 10:18:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=241
06/04/2022 10:18:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=242
06/04/2022 10:18:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=243
06/04/2022 10:18:29 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7265924214926031 on epoch=243
06/04/2022 10:18:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
06/04/2022 10:18:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=246
06/04/2022 10:18:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=247
06/04/2022 10:18:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=248
06/04/2022 10:18:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=249
06/04/2022 10:18:45 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7578431372549019 on epoch=249
06/04/2022 10:18:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=251
06/04/2022 10:18:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
06/04/2022 10:18:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
06/04/2022 10:18:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
06/04/2022 10:18:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
06/04/2022 10:19:00 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7574324892386333 on epoch=256
06/04/2022 10:19:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=257
06/04/2022 10:19:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
06/04/2022 10:19:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=259
06/04/2022 10:19:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
06/04/2022 10:19:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
06/04/2022 10:19:16 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7203102453102453 on epoch=262
06/04/2022 10:19:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=263
06/04/2022 10:19:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=264
06/04/2022 10:19:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
06/04/2022 10:19:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=267
06/04/2022 10:19:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=268
06/04/2022 10:19:32 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7587599735367496 on epoch=268
06/04/2022 10:19:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=269
06/04/2022 10:19:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
06/04/2022 10:19:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
06/04/2022 10:19:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=273
06/04/2022 10:19:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=274
06/04/2022 10:19:47 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7549098735539412 on epoch=274
06/04/2022 10:19:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=276
06/04/2022 10:19:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=277
06/04/2022 10:19:55 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
06/04/2022 10:19:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/04/2022 10:20:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=281
06/04/2022 10:20:03 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7033472346939839 on epoch=281
06/04/2022 10:20:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
06/04/2022 10:20:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=283
06/04/2022 10:20:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
06/04/2022 10:20:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
06/04/2022 10:20:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
06/04/2022 10:20:19 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7524031735446131 on epoch=287
06/04/2022 10:20:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=288
06/04/2022 10:20:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=289
06/04/2022 10:20:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
06/04/2022 10:20:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
06/04/2022 10:20:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/04/2022 10:20:34 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6979200754389989 on epoch=293
06/04/2022 10:20:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
06/04/2022 10:20:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/04/2022 10:20:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/04/2022 10:20:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=298
06/04/2022 10:20:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
06/04/2022 10:20:50 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7573967739107565 on epoch=299
06/04/2022 10:20:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=301
06/04/2022 10:20:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
06/04/2022 10:20:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
06/04/2022 10:21:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
06/04/2022 10:21:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
06/04/2022 10:21:05 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.728920390035397 on epoch=306
06/04/2022 10:21:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
06/04/2022 10:21:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
06/04/2022 10:21:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=309
06/04/2022 10:21:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=311
06/04/2022 10:21:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=312
06/04/2022 10:21:21 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7369131417481217 on epoch=312
06/04/2022 10:21:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
06/04/2022 10:21:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 10:21:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=316
06/04/2022 10:21:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
06/04/2022 10:21:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=318
06/04/2022 10:21:37 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7956043956043956 on epoch=318
06/04/2022 10:21:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
06/04/2022 10:21:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=321
06/04/2022 10:21:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
06/04/2022 10:21:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
06/04/2022 10:21:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=324
06/04/2022 10:21:52 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7719502418453721 on epoch=324
06/04/2022 10:21:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=326
06/04/2022 10:21:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
06/04/2022 10:22:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
06/04/2022 10:22:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=329
06/04/2022 10:22:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
06/04/2022 10:22:08 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7359402888595162 on epoch=331
06/04/2022 10:22:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=332
06/04/2022 10:22:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
06/04/2022 10:22:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
06/04/2022 10:22:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/04/2022 10:22:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=337
06/04/2022 10:22:24 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7386792452830189 on epoch=337
06/04/2022 10:22:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
06/04/2022 10:22:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
06/04/2022 10:22:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
06/04/2022 10:22:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
06/04/2022 10:22:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
06/04/2022 10:22:40 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7449135899450118 on epoch=343
06/04/2022 10:22:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
06/04/2022 10:22:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
06/04/2022 10:22:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 10:22:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
06/04/2022 10:22:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
06/04/2022 10:22:56 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7429267147802616 on epoch=349
06/04/2022 10:22:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=351
06/04/2022 10:23:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
06/04/2022 10:23:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=353
06/04/2022 10:23:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
06/04/2022 10:23:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/04/2022 10:23:12 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7195806296563326 on epoch=356
06/04/2022 10:23:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
06/04/2022 10:23:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
06/04/2022 10:23:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
06/04/2022 10:23:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/04/2022 10:23:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=362
06/04/2022 10:23:27 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7452287337313529 on epoch=362
06/04/2022 10:23:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
06/04/2022 10:23:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=364
06/04/2022 10:23:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
06/04/2022 10:23:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
06/04/2022 10:23:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=368
06/04/2022 10:23:43 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.713185724305072 on epoch=368
06/04/2022 10:23:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=369
06/04/2022 10:23:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
06/04/2022 10:23:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
06/04/2022 10:23:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
06/04/2022 10:23:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=374
06/04/2022 10:23:58 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:23:58 - INFO - __main__ - Printing 3 examples
06/04/2022 10:23:58 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 10:23:58 - INFO - __main__ - ['others']
06/04/2022 10:23:58 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 10:23:58 - INFO - __main__ - ['others']
06/04/2022 10:23:58 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 10:23:58 - INFO - __main__ - ['others']
06/04/2022 10:23:58 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:23:58 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:23:58 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 10:23:58 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:23:58 - INFO - __main__ - Printing 3 examples
06/04/2022 10:23:58 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 10:23:58 - INFO - __main__ - ['others']
06/04/2022 10:23:58 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 10:23:58 - INFO - __main__ - ['others']
06/04/2022 10:23:58 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 10:23:58 - INFO - __main__ - ['others']
06/04/2022 10:23:58 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:23:58 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:23:58 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 10:23:59 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7497765559062779 on epoch=374
06/04/2022 10:23:59 - INFO - __main__ - save last model!
06/04/2022 10:23:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 10:23:59 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 10:23:59 - INFO - __main__ - Printing 3 examples
06/04/2022 10:23:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 10:23:59 - INFO - __main__ - ['others']
06/04/2022 10:23:59 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 10:23:59 - INFO - __main__ - ['others']
06/04/2022 10:23:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 10:23:59 - INFO - __main__ - ['others']
06/04/2022 10:23:59 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:24:02 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:24:07 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 10:24:17 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 10:24:17 - INFO - __main__ - task name: emo
06/04/2022 10:24:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 10:24:18 - INFO - __main__ - Starting training!
06/04/2022 10:25:45 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_87_0.3_8_predictions.txt
06/04/2022 10:25:45 - INFO - __main__ - Classification-F1 on test data: 0.3794
06/04/2022 10:25:45 - INFO - __main__ - prefix=emo_32_87, lr=0.3, bsz=8, dev_performance=0.8034017286907393, test_performance=0.379392362817886
06/04/2022 10:25:45 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.2, bsz=8 ...
06/04/2022 10:25:46 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:25:46 - INFO - __main__ - Printing 3 examples
06/04/2022 10:25:46 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/04/2022 10:25:46 - INFO - __main__ - ['others']
06/04/2022 10:25:46 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/04/2022 10:25:46 - INFO - __main__ - ['others']
06/04/2022 10:25:46 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/04/2022 10:25:46 - INFO - __main__ - ['others']
06/04/2022 10:25:46 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:25:46 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:25:46 - INFO - __main__ - Loaded 128 examples from train data
06/04/2022 10:25:46 - INFO - __main__ - Start tokenizing ... 128 instances
06/04/2022 10:25:46 - INFO - __main__ - Printing 3 examples
06/04/2022 10:25:46 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
06/04/2022 10:25:46 - INFO - __main__ - ['others']
06/04/2022 10:25:46 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
06/04/2022 10:25:46 - INFO - __main__ - ['others']
06/04/2022 10:25:46 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
06/04/2022 10:25:46 - INFO - __main__ - ['others']
06/04/2022 10:25:46 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:25:46 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:25:47 - INFO - __main__ - Loaded 128 examples from dev data
06/04/2022 10:26:05 - INFO - __main__ - try to initialize prompt embeddings
06/04/2022 10:26:05 - INFO - __main__ - task name: emo
06/04/2022 10:26:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/04/2022 10:26:06 - INFO - __main__ - Starting training!
06/04/2022 10:26:09 - INFO - __main__ - Step 10 Global step 10 Train loss 7.63 on epoch=1
06/04/2022 10:26:12 - INFO - __main__ - Step 20 Global step 20 Train loss 5.22 on epoch=2
06/04/2022 10:26:14 - INFO - __main__ - Step 30 Global step 30 Train loss 3.08 on epoch=3
06/04/2022 10:26:17 - INFO - __main__ - Step 40 Global step 40 Train loss 2.04 on epoch=4
06/04/2022 10:26:20 - INFO - __main__ - Step 50 Global step 50 Train loss 1.51 on epoch=6
06/04/2022 10:26:21 - INFO - __main__ - Global step 50 Train loss 3.90 Classification-F1 0.13975868045635487 on epoch=6
06/04/2022 10:26:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13975868045635487 on epoch=6, global_step=50
06/04/2022 10:26:24 - INFO - __main__ - Step 60 Global step 60 Train loss 1.25 on epoch=7
06/04/2022 10:26:27 - INFO - __main__ - Step 70 Global step 70 Train loss 1.20 on epoch=8
06/04/2022 10:26:29 - INFO - __main__ - Step 80 Global step 80 Train loss 1.10 on epoch=9
06/04/2022 10:26:32 - INFO - __main__ - Step 90 Global step 90 Train loss 1.11 on epoch=11
06/04/2022 10:26:35 - INFO - __main__ - Step 100 Global step 100 Train loss 1.16 on epoch=12
06/04/2022 10:26:37 - INFO - __main__ - Global step 100 Train loss 1.16 Classification-F1 0.21468570528335937 on epoch=12
06/04/2022 10:26:37 - INFO - __main__ - Saving model with best Classification-F1: 0.13975868045635487 -> 0.21468570528335937 on epoch=12, global_step=100
06/04/2022 10:26:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.03 on epoch=13
06/04/2022 10:26:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=14
06/04/2022 10:26:44 - INFO - __main__ - Step 130 Global step 130 Train loss 1.05 on epoch=16
06/04/2022 10:26:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.98 on epoch=17
06/04/2022 10:26:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.93 on epoch=18
06/04/2022 10:26:52 - INFO - __main__ - Global step 150 Train loss 0.98 Classification-F1 0.1521825396825397 on epoch=18
06/04/2022 10:26:54 - INFO - __main__ - Step 160 Global step 160 Train loss 0.96 on epoch=19
06/04/2022 10:26:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=21
06/04/2022 10:26:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.93 on epoch=22
06/04/2022 10:27:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=23
06/04/2022 10:27:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.93 on epoch=24
06/04/2022 10:27:06 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.31164385622803215 on epoch=24
06/04/2022 10:27:07 - INFO - __main__ - Saving model with best Classification-F1: 0.21468570528335937 -> 0.31164385622803215 on epoch=24, global_step=200
06/04/2022 10:27:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=26
06/04/2022 10:27:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.86 on epoch=27
06/04/2022 10:27:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.92 on epoch=28
06/04/2022 10:27:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.94 on epoch=29
06/04/2022 10:27:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.85 on epoch=31
06/04/2022 10:27:22 - INFO - __main__ - Global step 250 Train loss 0.89 Classification-F1 0.37426688446015627 on epoch=31
06/04/2022 10:27:22 - INFO - __main__ - Saving model with best Classification-F1: 0.31164385622803215 -> 0.37426688446015627 on epoch=31, global_step=250
06/04/2022 10:27:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=32
06/04/2022 10:27:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.89 on epoch=33
06/04/2022 10:27:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=34
06/04/2022 10:27:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.93 on epoch=36
06/04/2022 10:27:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.91 on epoch=37
06/04/2022 10:27:37 - INFO - __main__ - Global step 300 Train loss 0.88 Classification-F1 0.11837732160312806 on epoch=37
06/04/2022 10:27:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.90 on epoch=38
06/04/2022 10:27:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.82 on epoch=39
06/04/2022 10:27:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.85 on epoch=41
06/04/2022 10:27:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.84 on epoch=42
06/04/2022 10:27:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.79 on epoch=43
06/04/2022 10:27:53 - INFO - __main__ - Global step 350 Train loss 0.84 Classification-F1 0.1739032078436052 on epoch=43
06/04/2022 10:27:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.79 on epoch=44
06/04/2022 10:27:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.80 on epoch=46
06/04/2022 10:28:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.79 on epoch=47
06/04/2022 10:28:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.87 on epoch=48
06/04/2022 10:28:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.82 on epoch=49
06/04/2022 10:28:08 - INFO - __main__ - Global step 400 Train loss 0.82 Classification-F1 0.23411199297588925 on epoch=49
06/04/2022 10:28:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.80 on epoch=51
06/04/2022 10:28:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.79 on epoch=52
06/04/2022 10:28:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.78 on epoch=53
06/04/2022 10:28:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.75 on epoch=54
06/04/2022 10:28:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.75 on epoch=56
06/04/2022 10:28:23 - INFO - __main__ - Global step 450 Train loss 0.77 Classification-F1 0.278517316017316 on epoch=56
06/04/2022 10:28:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.78 on epoch=57
06/04/2022 10:28:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.82 on epoch=58
06/04/2022 10:28:31 - INFO - __main__ - Step 480 Global step 480 Train loss 0.82 on epoch=59
06/04/2022 10:28:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.80 on epoch=61
06/04/2022 10:28:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.69 on epoch=62
06/04/2022 10:28:38 - INFO - __main__ - Global step 500 Train loss 0.78 Classification-F1 0.24090894508473487 on epoch=62
06/04/2022 10:28:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.71 on epoch=63
06/04/2022 10:28:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.73 on epoch=64
06/04/2022 10:28:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.72 on epoch=66
06/04/2022 10:28:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.70 on epoch=67
06/04/2022 10:28:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.71 on epoch=68
06/04/2022 10:28:53 - INFO - __main__ - Global step 550 Train loss 0.72 Classification-F1 0.2882120344429796 on epoch=68
06/04/2022 10:28:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.76 on epoch=69
06/04/2022 10:28:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.73 on epoch=71
06/04/2022 10:29:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.72 on epoch=72
06/04/2022 10:29:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.75 on epoch=73
06/04/2022 10:29:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.67 on epoch=74
06/04/2022 10:29:08 - INFO - __main__ - Global step 600 Train loss 0.73 Classification-F1 0.3171091051525834 on epoch=74
06/04/2022 10:29:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.66 on epoch=76
06/04/2022 10:29:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.75 on epoch=77
06/04/2022 10:29:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.61 on epoch=78
06/04/2022 10:29:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.66 on epoch=79
06/04/2022 10:29:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.55 on epoch=81
06/04/2022 10:29:23 - INFO - __main__ - Global step 650 Train loss 0.65 Classification-F1 0.5495253069781372 on epoch=81
06/04/2022 10:29:23 - INFO - __main__ - Saving model with best Classification-F1: 0.37426688446015627 -> 0.5495253069781372 on epoch=81, global_step=650
06/04/2022 10:29:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.60 on epoch=82
06/04/2022 10:29:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.56 on epoch=83
06/04/2022 10:29:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.54 on epoch=84
06/04/2022 10:29:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.53 on epoch=86
06/04/2022 10:29:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.55 on epoch=87
06/04/2022 10:29:39 - INFO - __main__ - Global step 700 Train loss 0.56 Classification-F1 0.5621217550565376 on epoch=87
06/04/2022 10:29:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5495253069781372 -> 0.5621217550565376 on epoch=87, global_step=700
06/04/2022 10:29:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.50 on epoch=88
06/04/2022 10:29:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.47 on epoch=89
06/04/2022 10:29:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.50 on epoch=91
06/04/2022 10:29:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.47 on epoch=92
06/04/2022 10:29:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.54 on epoch=93
06/04/2022 10:29:54 - INFO - __main__ - Global step 750 Train loss 0.50 Classification-F1 0.48665608288770046 on epoch=93
06/04/2022 10:29:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.44 on epoch=94
06/04/2022 10:29:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.50 on epoch=96
06/04/2022 10:30:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.44 on epoch=97
06/04/2022 10:30:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.47 on epoch=98
06/04/2022 10:30:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.37 on epoch=99
06/04/2022 10:30:09 - INFO - __main__ - Global step 800 Train loss 0.44 Classification-F1 0.4869003081244334 on epoch=99
06/04/2022 10:30:12 - INFO - __main__ - Step 810 Global step 810 Train loss 0.40 on epoch=101
06/04/2022 10:30:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.49 on epoch=102
06/04/2022 10:30:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.46 on epoch=103
06/04/2022 10:30:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.40 on epoch=104
06/04/2022 10:30:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.48 on epoch=106
06/04/2022 10:30:25 - INFO - __main__ - Global step 850 Train loss 0.45 Classification-F1 0.654232673969516 on epoch=106
06/04/2022 10:30:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5621217550565376 -> 0.654232673969516 on epoch=106, global_step=850
06/04/2022 10:30:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.55 on epoch=107
06/04/2022 10:30:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.40 on epoch=108
06/04/2022 10:30:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.34 on epoch=109
06/04/2022 10:30:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.43 on epoch=111
06/04/2022 10:30:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.44 on epoch=112
06/04/2022 10:30:40 - INFO - __main__ - Global step 900 Train loss 0.43 Classification-F1 0.6563833117023226 on epoch=112
06/04/2022 10:30:40 - INFO - __main__ - Saving model with best Classification-F1: 0.654232673969516 -> 0.6563833117023226 on epoch=112, global_step=900
06/04/2022 10:30:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.39 on epoch=113
06/04/2022 10:30:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=114
06/04/2022 10:30:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.46 on epoch=116
06/04/2022 10:30:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=117
06/04/2022 10:30:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.34 on epoch=118
06/04/2022 10:30:55 - INFO - __main__ - Global step 950 Train loss 0.37 Classification-F1 0.6283520461476126 on epoch=118
06/04/2022 10:30:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=119
06/04/2022 10:31:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.32 on epoch=121
06/04/2022 10:31:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.36 on epoch=122
06/04/2022 10:31:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=123
06/04/2022 10:31:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=124
06/04/2022 10:31:10 - INFO - __main__ - Global step 1000 Train loss 0.32 Classification-F1 0.5413440443928249 on epoch=124
06/04/2022 10:31:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.36 on epoch=126
06/04/2022 10:31:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.42 on epoch=127
06/04/2022 10:31:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.25 on epoch=128
06/04/2022 10:31:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.30 on epoch=129
06/04/2022 10:31:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=131
06/04/2022 10:31:26 - INFO - __main__ - Global step 1050 Train loss 0.32 Classification-F1 0.6622453448226013 on epoch=131
06/04/2022 10:31:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6563833117023226 -> 0.6622453448226013 on epoch=131, global_step=1050
06/04/2022 10:31:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.30 on epoch=132
06/04/2022 10:31:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.38 on epoch=133
06/04/2022 10:31:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.32 on epoch=134
06/04/2022 10:31:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=136
06/04/2022 10:31:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=137
06/04/2022 10:31:41 - INFO - __main__ - Global step 1100 Train loss 0.30 Classification-F1 0.6553764338736886 on epoch=137
06/04/2022 10:31:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=138
06/04/2022 10:31:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.31 on epoch=139
06/04/2022 10:31:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.32 on epoch=141
06/04/2022 10:31:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=142
06/04/2022 10:31:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=143
06/04/2022 10:31:57 - INFO - __main__ - Global step 1150 Train loss 0.29 Classification-F1 0.6862502251846515 on epoch=143
06/04/2022 10:31:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6622453448226013 -> 0.6862502251846515 on epoch=143, global_step=1150
06/04/2022 10:31:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=144
06/04/2022 10:32:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=146
06/04/2022 10:32:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.27 on epoch=147
06/04/2022 10:32:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=148
06/04/2022 10:32:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=149
06/04/2022 10:32:12 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.6644466820099731 on epoch=149
06/04/2022 10:32:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.23 on epoch=151
06/04/2022 10:32:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.26 on epoch=152
06/04/2022 10:32:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.28 on epoch=153
06/04/2022 10:32:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=154
06/04/2022 10:32:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=156
06/04/2022 10:32:27 - INFO - __main__ - Global step 1250 Train loss 0.24 Classification-F1 0.6748630776702655 on epoch=156
06/04/2022 10:32:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=157
06/04/2022 10:32:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.24 on epoch=158
06/04/2022 10:32:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=159
06/04/2022 10:32:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.25 on epoch=161
06/04/2022 10:32:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.27 on epoch=162
06/04/2022 10:32:43 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.6797727926373309 on epoch=162
06/04/2022 10:32:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=163
06/04/2022 10:32:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=164
06/04/2022 10:32:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=166
06/04/2022 10:32:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.20 on epoch=167
06/04/2022 10:32:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=168
06/04/2022 10:32:58 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.6814885675541414 on epoch=168
06/04/2022 10:33:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.29 on epoch=169
06/04/2022 10:33:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=171
06/04/2022 10:33:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=172
06/04/2022 10:33:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=173
06/04/2022 10:33:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=174
06/04/2022 10:33:14 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.603648240101442 on epoch=174
06/04/2022 10:33:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=176
06/04/2022 10:33:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=177
06/04/2022 10:33:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.26 on epoch=178
06/04/2022 10:33:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=179
06/04/2022 10:33:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=181
06/04/2022 10:33:30 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.6632081913440798 on epoch=181
06/04/2022 10:33:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=182
06/04/2022 10:33:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=183
06/04/2022 10:33:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=184
06/04/2022 10:33:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=186
06/04/2022 10:33:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.21 on epoch=187
06/04/2022 10:33:45 - INFO - __main__ - Global step 1500 Train loss 0.16 Classification-F1 0.6197147153416586 on epoch=187
06/04/2022 10:33:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=188
06/04/2022 10:33:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=189
06/04/2022 10:33:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=191
06/04/2022 10:33:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=192
06/04/2022 10:33:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=193
06/04/2022 10:34:01 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.6934362480114464 on epoch=193
06/04/2022 10:34:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6862502251846515 -> 0.6934362480114464 on epoch=193, global_step=1550
06/04/2022 10:34:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=194
06/04/2022 10:34:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=196
06/04/2022 10:34:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=197
06/04/2022 10:34:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=198
06/04/2022 10:34:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=199
06/04/2022 10:34:16 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.600115074798619 on epoch=199
06/04/2022 10:34:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=201
06/04/2022 10:34:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=202
06/04/2022 10:34:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=203
06/04/2022 10:34:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=204
06/04/2022 10:34:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=206
06/04/2022 10:34:32 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6819516194566984 on epoch=206
06/04/2022 10:34:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=207
06/04/2022 10:34:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=208
06/04/2022 10:34:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.19 on epoch=209
06/04/2022 10:34:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=211
06/04/2022 10:34:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=212
06/04/2022 10:34:48 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.7033037138300298 on epoch=212
06/04/2022 10:34:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6934362480114464 -> 0.7033037138300298 on epoch=212, global_step=1700
06/04/2022 10:34:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=213
06/04/2022 10:34:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=214
06/04/2022 10:34:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=216
06/04/2022 10:34:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=217
06/04/2022 10:35:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=218
06/04/2022 10:35:03 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.6862680096901695 on epoch=218
06/04/2022 10:35:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=219
06/04/2022 10:35:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=221
06/04/2022 10:35:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.14 on epoch=222
06/04/2022 10:35:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=223
06/04/2022 10:35:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=224
06/04/2022 10:35:19 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.6179847080466995 on epoch=224
06/04/2022 10:35:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=226
06/04/2022 10:35:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=227
06/04/2022 10:35:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=228
06/04/2022 10:35:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=229
06/04/2022 10:35:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
06/04/2022 10:35:34 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.6938738275636129 on epoch=231
06/04/2022 10:35:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=232
06/04/2022 10:35:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=233
06/04/2022 10:35:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
06/04/2022 10:35:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=236
06/04/2022 10:35:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=237
06/04/2022 10:35:50 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6500624358291269 on epoch=237
06/04/2022 10:35:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=238
06/04/2022 10:35:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=239
06/04/2022 10:35:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=241
06/04/2022 10:36:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=242
06/04/2022 10:36:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=243
06/04/2022 10:36:06 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.6515545496017124 on epoch=243
06/04/2022 10:36:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=244
06/04/2022 10:36:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=246
06/04/2022 10:36:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=247
06/04/2022 10:36:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=248
06/04/2022 10:36:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=249
06/04/2022 10:36:21 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7021923982894769 on epoch=249
06/04/2022 10:36:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=251
06/04/2022 10:36:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=252
06/04/2022 10:36:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=253
06/04/2022 10:36:32 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=254
06/04/2022 10:36:35 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
06/04/2022 10:36:37 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6562328954570336 on epoch=256
06/04/2022 10:36:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=257
06/04/2022 10:36:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=258
06/04/2022 10:36:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=259
06/04/2022 10:36:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=261
06/04/2022 10:36:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=262
06/04/2022 10:36:52 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6417670066722908 on epoch=262
06/04/2022 10:36:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=263
06/04/2022 10:36:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=264
06/04/2022 10:37:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
06/04/2022 10:37:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
06/04/2022 10:37:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
06/04/2022 10:37:08 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6598216501790589 on epoch=268
06/04/2022 10:37:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=269
06/04/2022 10:37:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=271
06/04/2022 10:37:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
06/04/2022 10:37:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=273
06/04/2022 10:37:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
06/04/2022 10:37:24 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.6456291887015603 on epoch=274
06/04/2022 10:37:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=276
06/04/2022 10:37:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
06/04/2022 10:37:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=278
06/04/2022 10:37:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
06/04/2022 10:37:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
06/04/2022 10:37:39 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7013334225915464 on epoch=281
06/04/2022 10:37:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=282
06/04/2022 10:37:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=283
06/04/2022 10:37:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=284
06/04/2022 10:37:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
06/04/2022 10:37:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=287
06/04/2022 10:37:54 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6588170163170163 on epoch=287
06/04/2022 10:37:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
06/04/2022 10:38:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=289
06/04/2022 10:38:03 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
06/04/2022 10:38:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
06/04/2022 10:38:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
06/04/2022 10:38:10 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6850214206214615 on epoch=293
06/04/2022 10:38:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=294
06/04/2022 10:38:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
06/04/2022 10:38:18 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
06/04/2022 10:38:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
06/04/2022 10:38:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=299
06/04/2022 10:38:26 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7021047251249433 on epoch=299
06/04/2022 10:38:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
06/04/2022 10:38:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=302
06/04/2022 10:38:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.11 on epoch=303
06/04/2022 10:38:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=304
06/04/2022 10:38:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=306
06/04/2022 10:38:41 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.6535907466434849 on epoch=306
06/04/2022 10:38:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
06/04/2022 10:38:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=308
06/04/2022 10:38:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
06/04/2022 10:38:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
06/04/2022 10:38:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
06/04/2022 10:38:57 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6244410761652142 on epoch=312
06/04/2022 10:39:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
06/04/2022 10:39:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
06/04/2022 10:39:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
06/04/2022 10:39:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=317
06/04/2022 10:39:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
06/04/2022 10:39:13 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6805983530130649 on epoch=318
06/04/2022 10:39:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=319
06/04/2022 10:39:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=321
06/04/2022 10:39:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
06/04/2022 10:39:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
06/04/2022 10:39:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
06/04/2022 10:39:29 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7009570686354937 on epoch=324
06/04/2022 10:39:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=326
06/04/2022 10:39:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=327
06/04/2022 10:39:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=328
06/04/2022 10:39:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
06/04/2022 10:39:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=331
06/04/2022 10:39:45 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6683030139496358 on epoch=331
06/04/2022 10:39:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=332
06/04/2022 10:39:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=333
06/04/2022 10:39:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
06/04/2022 10:39:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
06/04/2022 10:39:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=337
06/04/2022 10:40:01 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7084948867557563 on epoch=337
06/04/2022 10:40:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7033037138300298 -> 0.7084948867557563 on epoch=337, global_step=2700
06/04/2022 10:40:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=338
06/04/2022 10:40:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
06/04/2022 10:40:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=341
06/04/2022 10:40:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
06/04/2022 10:40:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=343
06/04/2022 10:40:17 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6447870893492362 on epoch=343
06/04/2022 10:40:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=344
06/04/2022 10:40:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=346
06/04/2022 10:40:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
06/04/2022 10:40:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
06/04/2022 10:40:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=349
06/04/2022 10:40:33 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6219898164952611 on epoch=349
06/04/2022 10:40:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=351
06/04/2022 10:40:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=352
06/04/2022 10:40:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=353
06/04/2022 10:40:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=354
06/04/2022 10:40:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
06/04/2022 10:40:49 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6689126927490158 on epoch=356
06/04/2022 10:40:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=357
06/04/2022 10:40:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
06/04/2022 10:40:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
06/04/2022 10:41:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
06/04/2022 10:41:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
06/04/2022 10:41:05 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6921616887132614 on epoch=362
06/04/2022 10:41:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
06/04/2022 10:41:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
06/04/2022 10:41:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=366
06/04/2022 10:41:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
06/04/2022 10:41:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=368
06/04/2022 10:41:21 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7430357552214022 on epoch=368
06/04/2022 10:41:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7084948867557563 -> 0.7430357552214022 on epoch=368, global_step=2950
06/04/2022 10:41:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
06/04/2022 10:41:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=371
06/04/2022 10:41:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
06/04/2022 10:41:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
06/04/2022 10:41:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
06/04/2022 10:41:36 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.662205014404005 on epoch=374
06/04/2022 10:41:36 - INFO - __main__ - save last model!
06/04/2022 10:41:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/04/2022 10:41:37 - INFO - __main__ - Start tokenizing ... 5509 instances
06/04/2022 10:41:37 - INFO - __main__ - Printing 3 examples
06/04/2022 10:41:37 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/04/2022 10:41:37 - INFO - __main__ - ['others']
06/04/2022 10:41:37 - INFO - __main__ -  [emo] what you like very little things ok
06/04/2022 10:41:37 - INFO - __main__ - ['others']
06/04/2022 10:41:37 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/04/2022 10:41:37 - INFO - __main__ - ['others']
06/04/2022 10:41:37 - INFO - __main__ - Tokenizing Input ...
06/04/2022 10:41:39 - INFO - __main__ - Tokenizing Output ...
06/04/2022 10:41:44 - INFO - __main__ - Loaded 5509 examples from test data
06/04/2022 10:43:18 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-emo/emo_32_87_0.2_8_predictions.txt
06/04/2022 10:43:18 - INFO - __main__ - Classification-F1 on test data: 0.4673
06/04/2022 10:43:18 - INFO - __main__ - prefix=emo_32_87, lr=0.2, bsz=8, dev_performance=0.7430357552214022, test_performance=0.4673344796030313
