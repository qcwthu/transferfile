05/21/2022 21:30:36 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/21/2022 21:30:36 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-tab_fact
05/21/2022 21:30:36 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/21/2022 21:30:36 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-tab_fact
05/21/2022 21:30:36 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:30:36 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:30:36 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:30:36 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:30:36 - INFO - __main__ - Using 2 gpus
05/21/2022 21:30:36 - INFO - __main__ - Using 2 gpus
05/21/2022 21:30:36 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
05/21/2022 21:30:36 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
05/21/2022 21:30:42 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.5, bsz=8 ...
06/05/2022 15:55:29 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
06/05/2022 15:55:29 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-tab_fact
06/05/2022 15:55:29 - INFO - __main__ - Namespace(task_dir='data_32/tab_fact/', task_name='tab_fact', identifier='T5-large-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down32shot/singletask-tab_fact', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
06/05/2022 15:55:29 - INFO - __main__ - models/T5-large-cls2cls-down32shot/singletask-tab_fact
06/05/2022 15:55:30 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/05/2022 15:55:30 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/05/2022 15:55:30 - INFO - __main__ - args.device: cuda:0
06/05/2022 15:55:30 - INFO - __main__ - Using 2 gpus
06/05/2022 15:55:30 - INFO - __main__ - args.device: cuda:1
06/05/2022 15:55:30 - INFO - __main__ - Using 2 gpus
06/05/2022 15:55:30 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
06/05/2022 15:55:30 - INFO - __main__ - Fine-tuning the following samples: ['tab_fact_32_100', 'tab_fact_32_13', 'tab_fact_32_21', 'tab_fact_32_42', 'tab_fact_32_87']
06/05/2022 15:55:34 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.5, bsz=8 ...
06/05/2022 15:55:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 15:55:35 - INFO - __main__ - Printing 3 examples
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ - Tokenizing Input ...
06/05/2022 15:55:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 15:55:35 - INFO - __main__ - Printing 3 examples
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ - Tokenizing Input ...
06/05/2022 15:55:35 - INFO - __main__ - Tokenizing Output ...
06/05/2022 15:55:35 - INFO - __main__ - Tokenizing Output ...
06/05/2022 15:55:35 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 15:55:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 15:55:35 - INFO - __main__ - Printing 3 examples
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ - Tokenizing Input ...
06/05/2022 15:55:35 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 15:55:35 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 15:55:35 - INFO - __main__ - Printing 3 examples
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 15:55:35 - INFO - __main__ - ['refuted']
06/05/2022 15:55:35 - INFO - __main__ - Tokenizing Input ...
06/05/2022 15:55:36 - INFO - __main__ - Tokenizing Output ...
06/05/2022 15:55:36 - INFO - __main__ - Tokenizing Output ...
06/05/2022 15:55:36 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 15:55:36 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 15:55:53 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 15:55:53 - INFO - __main__ - task name: tab_fact
06/05/2022 15:55:53 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 15:55:53 - INFO - __main__ - task name: tab_fact
06/05/2022 15:55:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 15:55:54 - INFO - __main__ - Starting training!
06/05/2022 15:55:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 15:55:54 - INFO - __main__ - Starting training!
06/05/2022 15:55:59 - INFO - __main__ - Step 10 Global step 10 Train loss 4.62 on epoch=2
06/05/2022 15:56:04 - INFO - __main__ - Step 20 Global step 20 Train loss 1.67 on epoch=4
06/05/2022 15:56:08 - INFO - __main__ - Step 30 Global step 30 Train loss 0.71 on epoch=7
06/05/2022 15:56:12 - INFO - __main__ - Step 40 Global step 40 Train loss 0.44 on epoch=9
06/05/2022 15:56:17 - INFO - __main__ - Step 50 Global step 50 Train loss 0.39 on epoch=12
06/05/2022 15:56:20 - INFO - __main__ - Global step 50 Train loss 1.57 Classification-F1 0.429800307219662 on epoch=12
06/05/2022 15:56:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.429800307219662 on epoch=12, global_step=50
06/05/2022 15:56:24 - INFO - __main__ - Step 60 Global step 60 Train loss 0.37 on epoch=14
06/05/2022 15:56:28 - INFO - __main__ - Step 70 Global step 70 Train loss 0.31 on epoch=17
06/05/2022 15:56:33 - INFO - __main__ - Step 80 Global step 80 Train loss 0.27 on epoch=19
06/05/2022 15:56:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.34 on epoch=22
06/05/2022 15:56:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=24
06/05/2022 15:56:44 - INFO - __main__ - Global step 100 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 15:56:48 - INFO - __main__ - Step 110 Global step 110 Train loss 0.24 on epoch=27
06/05/2022 15:56:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.31 on epoch=29
06/05/2022 15:56:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.26 on epoch=32
06/05/2022 15:57:01 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/05/2022 15:57:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=37
06/05/2022 15:57:08 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.39047619047619053 on epoch=37
06/05/2022 15:57:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=39
06/05/2022 15:57:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.25 on epoch=42
06/05/2022 15:57:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/05/2022 15:57:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.24 on epoch=47
06/05/2022 15:57:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=49
06/05/2022 15:57:33 - INFO - __main__ - Global step 200 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 15:57:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.21 on epoch=52
06/05/2022 15:57:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.20 on epoch=54
06/05/2022 15:57:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=57
06/05/2022 15:57:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=59
06/05/2022 15:57:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
06/05/2022 15:57:57 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 15:58:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.21 on epoch=64
06/05/2022 15:58:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/05/2022 15:58:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/05/2022 15:58:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/05/2022 15:58:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/05/2022 15:58:22 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.2008032128514056 on epoch=74
06/05/2022 15:58:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/05/2022 15:58:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/05/2022 15:58:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/05/2022 15:58:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/05/2022 15:58:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=87
06/05/2022 15:58:46 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.21985815602836878 on epoch=87
06/05/2022 15:58:50 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/05/2022 15:58:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/05/2022 15:58:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=94
06/05/2022 15:59:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/05/2022 15:59:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/05/2022 15:59:11 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.13580246913580246 on epoch=99
06/05/2022 15:59:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/05/2022 15:59:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=104
06/05/2022 15:59:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=107
06/05/2022 15:59:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=109
06/05/2022 15:59:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/05/2022 15:59:35 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.2175438596491228 on epoch=112
06/05/2022 15:59:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/05/2022 15:59:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/05/2022 15:59:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/05/2022 15:59:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/05/2022 15:59:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/05/2022 15:59:59 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=124
06/05/2022 16:00:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/05/2022 16:00:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/05/2022 16:00:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=132
06/05/2022 16:00:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/05/2022 16:00:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/05/2022 16:00:24 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.21985815602836878 on epoch=137
06/05/2022 16:00:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/05/2022 16:00:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/05/2022 16:00:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/05/2022 16:00:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/05/2022 16:00:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/05/2022 16:00:48 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/05/2022 16:00:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/05/2022 16:00:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/05/2022 16:01:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/05/2022 16:01:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/05/2022 16:01:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/05/2022 16:01:12 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=162
06/05/2022 16:01:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/05/2022 16:01:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/05/2022 16:01:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=169
06/05/2022 16:01:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=172
06/05/2022 16:01:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=174
06/05/2022 16:01:37 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.5390377412849323 on epoch=174
06/05/2022 16:01:37 - INFO - __main__ - Saving model with best Classification-F1: 0.429800307219662 -> 0.5390377412849323 on epoch=174, global_step=700
06/05/2022 16:01:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/05/2022 16:01:46 - INFO - __main__ - Step 720 Global step 720 Train loss 0.60 on epoch=179
06/05/2022 16:01:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.54 on epoch=182
06/05/2022 16:01:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.96 on epoch=184
06/05/2022 16:01:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.57 on epoch=187
06/05/2022 16:02:01 - INFO - __main__ - Global step 750 Train loss 0.57 Classification-F1 0.3591989987484355 on epoch=187
06/05/2022 16:02:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.92 on epoch=189
06/05/2022 16:02:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/05/2022 16:02:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=194
06/05/2022 16:02:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=197
06/05/2022 16:02:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=199
06/05/2022 16:02:26 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.3333333333333333 on epoch=199
06/05/2022 16:02:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/05/2022 16:02:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=204
06/05/2022 16:02:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/05/2022 16:02:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=209
06/05/2022 16:02:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=212
06/05/2022 16:02:50 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=212
06/05/2022 16:02:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/05/2022 16:02:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=217
06/05/2022 16:03:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=219
06/05/2022 16:03:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=222
06/05/2022 16:03:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/05/2022 16:03:14 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=224
06/05/2022 16:03:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=227
06/05/2022 16:03:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/05/2022 16:03:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=232
06/05/2022 16:03:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/05/2022 16:03:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=237
06/05/2022 16:03:39 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=237
06/05/2022 16:03:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=239
06/05/2022 16:03:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=242
06/05/2022 16:03:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/05/2022 16:03:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=247
06/05/2022 16:04:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/05/2022 16:04:04 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=249
06/05/2022 16:04:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=252
06/05/2022 16:04:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
06/05/2022 16:04:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=257
06/05/2022 16:04:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=259
06/05/2022 16:04:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=262
06/05/2022 16:04:28 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=262
06/05/2022 16:04:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=264
06/05/2022 16:04:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=267
06/05/2022 16:04:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=269
06/05/2022 16:04:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=272
06/05/2022 16:04:50 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=274
06/05/2022 16:04:53 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=274
06/05/2022 16:04:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=277
06/05/2022 16:05:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=279
06/05/2022 16:05:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=282
06/05/2022 16:05:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=284
06/05/2022 16:05:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=287
06/05/2022 16:05:17 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.24006017623038897 on epoch=287
06/05/2022 16:05:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.19 on epoch=289
06/05/2022 16:05:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=292
06/05/2022 16:05:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=294
06/05/2022 16:05:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/05/2022 16:05:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=299
06/05/2022 16:05:42 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.236999147485081 on epoch=299
06/05/2022 16:05:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=302
06/05/2022 16:05:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=304
06/05/2022 16:05:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=307
06/05/2022 16:05:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=309
06/05/2022 16:06:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=312
06/05/2022 16:06:07 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.24006017623038897 on epoch=312
06/05/2022 16:06:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=314
06/05/2022 16:06:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=317
06/05/2022 16:06:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=319
06/05/2022 16:06:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=322
06/05/2022 16:06:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=324
06/05/2022 16:06:31 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=324
06/05/2022 16:06:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=327
06/05/2022 16:06:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=329
06/05/2022 16:06:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.21 on epoch=332
06/05/2022 16:06:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=334
06/05/2022 16:06:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.21 on epoch=337
06/05/2022 16:06:56 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.2346616065781151 on epoch=337
06/05/2022 16:07:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.20 on epoch=339
06/05/2022 16:07:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=342
06/05/2022 16:07:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.21 on epoch=344
06/05/2022 16:07:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=347
06/05/2022 16:07:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=349
06/05/2022 16:07:20 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.2346616065781151 on epoch=349
06/05/2022 16:07:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=352
06/05/2022 16:07:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=354
06/05/2022 16:07:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=357
06/05/2022 16:07:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.19 on epoch=359
06/05/2022 16:07:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=362
06/05/2022 16:07:45 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.22701525054466232 on epoch=362
06/05/2022 16:07:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.20 on epoch=364
06/05/2022 16:07:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.19 on epoch=367
06/05/2022 16:07:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.18 on epoch=369
06/05/2022 16:08:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.20 on epoch=372
06/05/2022 16:08:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.19 on epoch=374
06/05/2022 16:08:09 - INFO - __main__ - Global step 1500 Train loss 0.19 Classification-F1 0.265054528212423 on epoch=374
06/05/2022 16:08:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=377
06/05/2022 16:08:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=379
06/05/2022 16:08:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.17 on epoch=382
06/05/2022 16:08:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.21 on epoch=384
06/05/2022 16:08:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=387
06/05/2022 16:08:34 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.2074074074074074 on epoch=387
06/05/2022 16:08:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.21 on epoch=389
06/05/2022 16:08:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=392
06/05/2022 16:08:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.18 on epoch=394
06/05/2022 16:08:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.22 on epoch=397
06/05/2022 16:08:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=399
06/05/2022 16:08:59 - INFO - __main__ - Global step 1600 Train loss 0.20 Classification-F1 0.2097378277153558 on epoch=399
06/05/2022 16:09:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.18 on epoch=402
06/05/2022 16:09:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.19 on epoch=404
06/05/2022 16:09:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.16 on epoch=407
06/05/2022 16:09:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=409
06/05/2022 16:09:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.19 on epoch=412
06/05/2022 16:09:23 - INFO - __main__ - Global step 1650 Train loss 0.17 Classification-F1 0.21985815602836878 on epoch=412
06/05/2022 16:09:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=414
06/05/2022 16:09:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=417
06/05/2022 16:09:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.15 on epoch=419
06/05/2022 16:09:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=422
06/05/2022 16:09:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.18 on epoch=424
06/05/2022 16:09:47 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.2247191011235955 on epoch=424
06/05/2022 16:09:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.19 on epoch=427
06/05/2022 16:09:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=429
06/05/2022 16:10:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=432
06/05/2022 16:10:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.18 on epoch=434
06/05/2022 16:10:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.15 on epoch=437
06/05/2022 16:10:12 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.5652830188679245 on epoch=437
06/05/2022 16:10:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5390377412849323 -> 0.5652830188679245 on epoch=437, global_step=1750
06/05/2022 16:10:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.17 on epoch=439
06/05/2022 16:10:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.19 on epoch=442
06/05/2022 16:10:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.19 on epoch=444
06/05/2022 16:10:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.19 on epoch=447
06/05/2022 16:10:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.17 on epoch=449
06/05/2022 16:10:36 - INFO - __main__ - Global step 1800 Train loss 0.18 Classification-F1 0.3148148148148148 on epoch=449
06/05/2022 16:10:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=452
06/05/2022 16:10:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.16 on epoch=454
06/05/2022 16:10:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.16 on epoch=457
06/05/2022 16:10:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=459
06/05/2022 16:10:58 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=462
06/05/2022 16:11:01 - INFO - __main__ - Global step 1850 Train loss 0.17 Classification-F1 0.2071938901207194 on epoch=462
06/05/2022 16:11:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.15 on epoch=464
06/05/2022 16:11:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.17 on epoch=467
06/05/2022 16:11:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.16 on epoch=469
06/05/2022 16:11:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.16 on epoch=472
06/05/2022 16:11:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.19 on epoch=474
06/05/2022 16:11:25 - INFO - __main__ - Global step 1900 Train loss 0.16 Classification-F1 0.28057014253563395 on epoch=474
06/05/2022 16:11:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.19 on epoch=477
06/05/2022 16:11:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.19 on epoch=479
06/05/2022 16:11:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.17 on epoch=482
06/05/2022 16:11:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.16 on epoch=484
06/05/2022 16:11:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.15 on epoch=487
06/05/2022 16:11:50 - INFO - __main__ - Global step 1950 Train loss 0.17 Classification-F1 0.15056603773584903 on epoch=487
06/05/2022 16:11:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.16 on epoch=489
06/05/2022 16:11:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.18 on epoch=492
06/05/2022 16:12:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.16 on epoch=494
06/05/2022 16:12:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.16 on epoch=497
06/05/2022 16:12:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.17 on epoch=499
06/05/2022 16:12:14 - INFO - __main__ - Global step 2000 Train loss 0.16 Classification-F1 0.22805507745266781 on epoch=499
06/05/2022 16:12:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.16 on epoch=502
06/05/2022 16:12:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.18 on epoch=504
06/05/2022 16:12:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.16 on epoch=507
06/05/2022 16:12:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.15 on epoch=509
06/05/2022 16:12:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.17 on epoch=512
06/05/2022 16:12:38 - INFO - __main__ - Global step 2050 Train loss 0.16 Classification-F1 0.15932773109243697 on epoch=512
06/05/2022 16:12:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=514
06/05/2022 16:12:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.17 on epoch=517
06/05/2022 16:12:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.17 on epoch=519
06/05/2022 16:12:56 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=522
06/05/2022 16:13:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=524
06/05/2022 16:13:02 - INFO - __main__ - Global step 2100 Train loss 0.15 Classification-F1 0.18035343035343035 on epoch=524
06/05/2022 16:13:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.15 on epoch=527
06/05/2022 16:13:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=529
06/05/2022 16:13:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.16 on epoch=532
06/05/2022 16:13:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=534
06/05/2022 16:13:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.14 on epoch=537
06/05/2022 16:13:28 - INFO - __main__ - Global step 2150 Train loss 0.15 Classification-F1 0.23756613756613754 on epoch=537
06/05/2022 16:13:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.14 on epoch=539
06/05/2022 16:13:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.14 on epoch=542
06/05/2022 16:13:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.18 on epoch=544
06/05/2022 16:13:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.15 on epoch=547
06/05/2022 16:13:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.16 on epoch=549
06/05/2022 16:13:53 - INFO - __main__ - Global step 2200 Train loss 0.15 Classification-F1 0.2942942942942943 on epoch=549
06/05/2022 16:13:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.13 on epoch=552
06/05/2022 16:14:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.16 on epoch=554
06/05/2022 16:14:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.16 on epoch=557
06/05/2022 16:14:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.13 on epoch=559
06/05/2022 16:14:15 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=562
06/05/2022 16:14:18 - INFO - __main__ - Global step 2250 Train loss 0.14 Classification-F1 0.37259552042160743 on epoch=562
06/05/2022 16:14:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.15 on epoch=564
06/05/2022 16:14:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.16 on epoch=567
06/05/2022 16:14:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=569
06/05/2022 16:14:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=572
06/05/2022 16:14:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.18 on epoch=574
06/05/2022 16:14:42 - INFO - __main__ - Global step 2300 Train loss 0.15 Classification-F1 0.30907944514501895 on epoch=574
06/05/2022 16:14:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.12 on epoch=577
06/05/2022 16:14:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.15 on epoch=579
06/05/2022 16:14:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.15 on epoch=582
06/05/2022 16:15:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=584
06/05/2022 16:15:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.13 on epoch=587
06/05/2022 16:15:07 - INFO - __main__ - Global step 2350 Train loss 0.13 Classification-F1 0.3987415134956119 on epoch=587
06/05/2022 16:15:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.12 on epoch=589
06/05/2022 16:15:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.14 on epoch=592
06/05/2022 16:15:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.14 on epoch=594
06/05/2022 16:15:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=597
06/05/2022 16:15:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=599
06/05/2022 16:15:32 - INFO - __main__ - Global step 2400 Train loss 0.13 Classification-F1 0.6190476190476191 on epoch=599
06/05/2022 16:15:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5652830188679245 -> 0.6190476190476191 on epoch=599, global_step=2400
06/05/2022 16:15:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.14 on epoch=602
06/05/2022 16:15:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.14 on epoch=604
06/05/2022 16:15:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.14 on epoch=607
06/05/2022 16:15:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.14 on epoch=609
06/05/2022 16:15:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.13 on epoch=612
06/05/2022 16:15:57 - INFO - __main__ - Global step 2450 Train loss 0.14 Classification-F1 0.6398336187912894 on epoch=612
06/05/2022 16:15:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6190476190476191 -> 0.6398336187912894 on epoch=612, global_step=2450
06/05/2022 16:16:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.13 on epoch=614
06/05/2022 16:16:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.14 on epoch=617
06/05/2022 16:16:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.12 on epoch=619
06/05/2022 16:16:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.12 on epoch=622
06/05/2022 16:16:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.16 on epoch=624
06/05/2022 16:16:21 - INFO - __main__ - Global step 2500 Train loss 0.13 Classification-F1 0.31461523917564754 on epoch=624
06/05/2022 16:16:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.17 on epoch=627
06/05/2022 16:16:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.15 on epoch=629
06/05/2022 16:16:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.14 on epoch=632
06/05/2022 16:16:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.14 on epoch=634
06/05/2022 16:16:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.13 on epoch=637
06/05/2022 16:16:46 - INFO - __main__ - Global step 2550 Train loss 0.14 Classification-F1 0.24640434192672997 on epoch=637
06/05/2022 16:16:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.14 on epoch=639
06/05/2022 16:16:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.11 on epoch=642
06/05/2022 16:16:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.14 on epoch=644
06/05/2022 16:17:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=647
06/05/2022 16:17:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.21 on epoch=649
06/05/2022 16:17:11 - INFO - __main__ - Global step 2600 Train loss 0.14 Classification-F1 0.2844736842105263 on epoch=649
06/05/2022 16:17:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=652
06/05/2022 16:17:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=654
06/05/2022 16:17:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.12 on epoch=657
06/05/2022 16:17:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=659
06/05/2022 16:17:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=662
06/05/2022 16:17:35 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.503078982597055 on epoch=662
06/05/2022 16:17:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=664
06/05/2022 16:17:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.12 on epoch=667
06/05/2022 16:17:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=669
06/05/2022 16:17:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=672
06/05/2022 16:17:57 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=674
06/05/2022 16:18:00 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.22398658093374335 on epoch=674
06/05/2022 16:18:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=677
06/05/2022 16:18:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.14 on epoch=679
06/05/2022 16:18:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=682
06/05/2022 16:18:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.12 on epoch=684
06/05/2022 16:18:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.12 on epoch=687
06/05/2022 16:18:25 - INFO - __main__ - Global step 2750 Train loss 0.11 Classification-F1 0.3333333333333333 on epoch=687
06/05/2022 16:18:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.11 on epoch=689
06/05/2022 16:18:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=692
06/05/2022 16:18:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=694
06/05/2022 16:18:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=697
06/05/2022 16:18:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.13 on epoch=699
06/05/2022 16:18:49 - INFO - __main__ - Global step 2800 Train loss 0.10 Classification-F1 0.43001658374792706 on epoch=699
06/05/2022 16:18:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=702
06/05/2022 16:18:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=704
06/05/2022 16:19:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.12 on epoch=707
06/05/2022 16:19:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.13 on epoch=709
06/05/2022 16:19:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.11 on epoch=712
06/05/2022 16:19:14 - INFO - __main__ - Global step 2850 Train loss 0.10 Classification-F1 0.26136363636363635 on epoch=712
06/05/2022 16:19:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=714
06/05/2022 16:19:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=717
06/05/2022 16:19:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=719
06/05/2022 16:19:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=722
06/05/2022 16:19:36 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=724
06/05/2022 16:19:39 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.16910436980859514 on epoch=724
06/05/2022 16:19:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.10 on epoch=727
06/05/2022 16:19:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=729
06/05/2022 16:19:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=732
06/05/2022 16:19:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.13 on epoch=734
06/05/2022 16:20:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.11 on epoch=737
06/05/2022 16:20:03 - INFO - __main__ - Global step 2950 Train loss 0.09 Classification-F1 0.5333333333333333 on epoch=737
06/05/2022 16:20:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.09 on epoch=739
06/05/2022 16:20:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=742
06/05/2022 16:20:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=744
06/05/2022 16:20:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=747
06/05/2022 16:20:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.10 on epoch=749
06/05/2022 16:20:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 16:20:27 - INFO - __main__ - Printing 3 examples
06/05/2022 16:20:27 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 16:20:27 - INFO - __main__ - ['refuted']
06/05/2022 16:20:27 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 16:20:27 - INFO - __main__ - ['refuted']
06/05/2022 16:20:27 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 16:20:27 - INFO - __main__ - ['refuted']
06/05/2022 16:20:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:20:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:20:27 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 16:20:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 16:20:27 - INFO - __main__ - Printing 3 examples
06/05/2022 16:20:27 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 16:20:27 - INFO - __main__ - ['refuted']
06/05/2022 16:20:27 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 16:20:27 - INFO - __main__ - ['refuted']
06/05/2022 16:20:27 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 16:20:27 - INFO - __main__ - ['refuted']
06/05/2022 16:20:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:20:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:20:27 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 16:20:28 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.29806687565308254 on epoch=749
06/05/2022 16:20:28 - INFO - __main__ - save last model!
06/05/2022 16:20:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 16:20:28 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 16:20:28 - INFO - __main__ - Printing 3 examples
06/05/2022 16:20:28 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 16:20:28 - INFO - __main__ - ['entailed']
06/05/2022 16:20:28 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 16:20:28 - INFO - __main__ - ['entailed']
06/05/2022 16:20:28 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 16:20:28 - INFO - __main__ - ['entailed']
06/05/2022 16:20:28 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:20:42 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 16:20:42 - INFO - __main__ - task name: tab_fact
06/05/2022 16:20:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 16:20:43 - INFO - __main__ - Starting training!
06/05/2022 16:20:52 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:21:05 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 16:29:13 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_100_0.5_8_predictions.txt
06/05/2022 16:29:13 - INFO - __main__ - Classification-F1 on test data: 0.1387
06/05/2022 16:29:14 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.5, bsz=8, dev_performance=0.6398336187912894, test_performance=0.13873770863557108
06/05/2022 16:29:14 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.4, bsz=8 ...
06/05/2022 16:29:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 16:29:15 - INFO - __main__ - Printing 3 examples
06/05/2022 16:29:15 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 16:29:15 - INFO - __main__ - ['refuted']
06/05/2022 16:29:15 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 16:29:15 - INFO - __main__ - ['refuted']
06/05/2022 16:29:15 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 16:29:15 - INFO - __main__ - ['refuted']
06/05/2022 16:29:15 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:29:15 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:29:15 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 16:29:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 16:29:15 - INFO - __main__ - Printing 3 examples
06/05/2022 16:29:15 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 16:29:15 - INFO - __main__ - ['refuted']
06/05/2022 16:29:15 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 16:29:15 - INFO - __main__ - ['refuted']
06/05/2022 16:29:15 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 16:29:15 - INFO - __main__ - ['refuted']
06/05/2022 16:29:15 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:29:15 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:29:15 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 16:29:29 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 16:29:29 - INFO - __main__ - task name: tab_fact
06/05/2022 16:29:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 16:29:30 - INFO - __main__ - Starting training!
06/05/2022 16:29:35 - INFO - __main__ - Step 10 Global step 10 Train loss 5.02 on epoch=2
06/05/2022 16:29:39 - INFO - __main__ - Step 20 Global step 20 Train loss 2.35 on epoch=4
06/05/2022 16:29:44 - INFO - __main__ - Step 30 Global step 30 Train loss 1.12 on epoch=7
06/05/2022 16:29:48 - INFO - __main__ - Step 40 Global step 40 Train loss 0.65 on epoch=9
06/05/2022 16:29:53 - INFO - __main__ - Step 50 Global step 50 Train loss 0.54 on epoch=12
06/05/2022 16:29:55 - INFO - __main__ - Global step 50 Train loss 1.93 Classification-F1 0.3333333333333333 on epoch=12
06/05/2022 16:29:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/05/2022 16:30:00 - INFO - __main__ - Step 60 Global step 60 Train loss 0.48 on epoch=14
06/05/2022 16:30:04 - INFO - __main__ - Step 70 Global step 70 Train loss 0.35 on epoch=17
06/05/2022 16:30:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.30 on epoch=19
06/05/2022 16:30:13 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=22
06/05/2022 16:30:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.25 on epoch=24
06/05/2022 16:30:20 - INFO - __main__ - Global step 100 Train loss 0.34 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 16:30:24 - INFO - __main__ - Step 110 Global step 110 Train loss 0.31 on epoch=27
06/05/2022 16:30:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=29
06/05/2022 16:30:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.28 on epoch=32
06/05/2022 16:30:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.24 on epoch=34
06/05/2022 16:30:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=37
06/05/2022 16:30:44 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.4947797300738477 on epoch=37
06/05/2022 16:30:44 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.4947797300738477 on epoch=37, global_step=150
06/05/2022 16:30:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=39
06/05/2022 16:30:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.25 on epoch=42
06/05/2022 16:30:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/05/2022 16:31:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=47
06/05/2022 16:31:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=49
06/05/2022 16:31:09 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.47602339181286546 on epoch=49
06/05/2022 16:31:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/05/2022 16:31:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.27 on epoch=54
06/05/2022 16:31:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=57
06/05/2022 16:31:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.20 on epoch=59
06/05/2022 16:31:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=62
06/05/2022 16:31:33 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 16:31:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=64
06/05/2022 16:31:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/05/2022 16:31:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=69
06/05/2022 16:31:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/05/2022 16:31:55 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/05/2022 16:31:58 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=74
06/05/2022 16:32:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/05/2022 16:32:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/05/2022 16:32:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/05/2022 16:32:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/05/2022 16:32:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/05/2022 16:32:22 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 16:32:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/05/2022 16:32:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=92
06/05/2022 16:32:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=94
06/05/2022 16:32:39 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/05/2022 16:32:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.19 on epoch=99
06/05/2022 16:32:46 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=99
06/05/2022 16:32:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/05/2022 16:32:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=104
06/05/2022 16:32:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/05/2022 16:33:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=109
06/05/2022 16:33:08 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=112
06/05/2022 16:33:10 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 16:33:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/05/2022 16:33:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=117
06/05/2022 16:33:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=119
06/05/2022 16:33:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/05/2022 16:33:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=124
06/05/2022 16:33:35 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=124
06/05/2022 16:33:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
06/05/2022 16:33:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/05/2022 16:33:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/05/2022 16:33:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=134
06/05/2022 16:33:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/05/2022 16:33:59 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=137
06/05/2022 16:34:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/05/2022 16:34:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/05/2022 16:34:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/05/2022 16:34:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=147
06/05/2022 16:34:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/05/2022 16:34:23 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/05/2022 16:34:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/05/2022 16:34:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=154
06/05/2022 16:34:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/05/2022 16:34:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=159
06/05/2022 16:34:45 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/05/2022 16:34:48 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=162
06/05/2022 16:34:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/05/2022 16:34:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/05/2022 16:35:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/05/2022 16:35:05 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/05/2022 16:35:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/05/2022 16:35:12 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 16:35:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/05/2022 16:35:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/05/2022 16:35:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=182
06/05/2022 16:35:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/05/2022 16:35:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/05/2022 16:35:36 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=187
06/05/2022 16:35:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=189
06/05/2022 16:35:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=192
06/05/2022 16:35:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=194
06/05/2022 16:35:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=197
06/05/2022 16:35:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=199
06/05/2022 16:36:01 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=199
06/05/2022 16:36:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/05/2022 16:36:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/05/2022 16:36:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=207
06/05/2022 16:36:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=209
06/05/2022 16:36:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=212
06/05/2022 16:36:25 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=212
06/05/2022 16:36:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/05/2022 16:36:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/05/2022 16:36:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=219
06/05/2022 16:36:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=222
06/05/2022 16:36:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/05/2022 16:36:49 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.30700280112044814 on epoch=224
06/05/2022 16:36:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=227
06/05/2022 16:36:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=229
06/05/2022 16:37:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=232
06/05/2022 16:37:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/05/2022 16:37:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=237
06/05/2022 16:37:14 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.5272229822161423 on epoch=237
06/05/2022 16:37:14 - INFO - __main__ - Saving model with best Classification-F1: 0.4947797300738477 -> 0.5272229822161423 on epoch=237, global_step=950
06/05/2022 16:37:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=239
06/05/2022 16:37:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=242
06/05/2022 16:37:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/05/2022 16:37:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=247
06/05/2022 16:37:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=249
06/05/2022 16:37:38 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.2804972804972805 on epoch=249
06/05/2022 16:37:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=252
06/05/2022 16:37:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/05/2022 16:37:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=257
06/05/2022 16:37:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=259
06/05/2022 16:38:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=262
06/05/2022 16:38:02 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.3727353727353727 on epoch=262
06/05/2022 16:38:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=264
06/05/2022 16:38:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/05/2022 16:38:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=269
06/05/2022 16:38:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=272
06/05/2022 16:38:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=274
06/05/2022 16:38:27 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.4817813765182186 on epoch=274
06/05/2022 16:38:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=277
06/05/2022 16:38:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=279
06/05/2022 16:38:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=282
06/05/2022 16:38:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=284
06/05/2022 16:38:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=287
06/05/2022 16:38:51 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.5921568627450979 on epoch=287
06/05/2022 16:38:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5272229822161423 -> 0.5921568627450979 on epoch=287, global_step=1150
06/05/2022 16:38:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=289
06/05/2022 16:39:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=292
06/05/2022 16:39:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=294
06/05/2022 16:39:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=297
06/05/2022 16:39:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=299
06/05/2022 16:39:15 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.4909862142099682 on epoch=299
06/05/2022 16:39:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=302
06/05/2022 16:39:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/05/2022 16:39:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=307
06/05/2022 16:39:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=309
06/05/2022 16:39:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=312
06/05/2022 16:39:39 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.4832395400048935 on epoch=312
06/05/2022 16:39:44 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=314
06/05/2022 16:39:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=317
06/05/2022 16:39:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=319
06/05/2022 16:39:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/05/2022 16:40:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=324
06/05/2022 16:40:04 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.5555555555555556 on epoch=324
06/05/2022 16:40:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=327
06/05/2022 16:40:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=329
06/05/2022 16:40:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=332
06/05/2022 16:40:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=334
06/05/2022 16:40:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/05/2022 16:40:37 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.5405128205128205 on epoch=337
06/05/2022 16:40:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=339
06/05/2022 16:40:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=342
06/05/2022 16:40:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=344
06/05/2022 16:40:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=347
06/05/2022 16:40:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=349
06/05/2022 16:41:02 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.5195195195195195 on epoch=349
06/05/2022 16:41:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/05/2022 16:41:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=354
06/05/2022 16:41:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/05/2022 16:41:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=359
06/05/2022 16:41:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=362
06/05/2022 16:41:36 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.5155067155067155 on epoch=362
06/05/2022 16:41:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=364
06/05/2022 16:41:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=367
06/05/2022 16:41:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
06/05/2022 16:41:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/05/2022 16:41:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/05/2022 16:42:00 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.25171624713958807 on epoch=374
06/05/2022 16:42:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/05/2022 16:42:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/05/2022 16:42:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/05/2022 16:42:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=384
06/05/2022 16:42:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=387
06/05/2022 16:42:25 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.5195195195195195 on epoch=387
06/05/2022 16:42:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=389
06/05/2022 16:42:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/05/2022 16:42:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=394
06/05/2022 16:42:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/05/2022 16:42:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
06/05/2022 16:42:49 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.5465587044534412 on epoch=399
06/05/2022 16:42:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=402
06/05/2022 16:42:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/05/2022 16:43:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/05/2022 16:43:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/05/2022 16:43:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/05/2022 16:43:14 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.3399289700659563 on epoch=412
06/05/2022 16:43:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=414
06/05/2022 16:43:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/05/2022 16:43:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/05/2022 16:43:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/05/2022 16:43:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
06/05/2022 16:43:39 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.4217338217338217 on epoch=424
06/05/2022 16:43:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
06/05/2022 16:43:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/05/2022 16:43:52 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/05/2022 16:43:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/05/2022 16:44:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/05/2022 16:44:03 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.3425553319919517 on epoch=437
06/05/2022 16:44:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/05/2022 16:44:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=442
06/05/2022 16:44:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/05/2022 16:44:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/05/2022 16:44:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/05/2022 16:44:28 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.5145583557621727 on epoch=449
06/05/2022 16:44:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=452
06/05/2022 16:44:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=454
06/05/2022 16:44:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/05/2022 16:44:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/05/2022 16:44:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/05/2022 16:44:52 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.47813194959229055 on epoch=462
06/05/2022 16:44:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/05/2022 16:45:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/05/2022 16:45:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/05/2022 16:45:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/05/2022 16:45:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/05/2022 16:45:17 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.33300016658337495 on epoch=474
06/05/2022 16:45:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/05/2022 16:45:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/05/2022 16:45:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/05/2022 16:45:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/05/2022 16:45:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/05/2022 16:45:41 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.20299277605779156 on epoch=487
06/05/2022 16:45:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/05/2022 16:45:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/05/2022 16:45:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=494
06/05/2022 16:45:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/05/2022 16:46:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=499
06/05/2022 16:46:06 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.32376068376068373 on epoch=499
06/05/2022 16:46:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/05/2022 16:46:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/05/2022 16:46:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/05/2022 16:46:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/05/2022 16:46:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/05/2022 16:46:31 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.4980392156862745 on epoch=512
06/05/2022 16:46:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/05/2022 16:46:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/05/2022 16:46:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=519
06/05/2022 16:46:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=522
06/05/2022 16:46:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/05/2022 16:46:55 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.5195195195195195 on epoch=524
06/05/2022 16:47:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/05/2022 16:47:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/05/2022 16:47:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/05/2022 16:47:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/05/2022 16:47:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/05/2022 16:47:20 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.36739417989417983 on epoch=537
06/05/2022 16:47:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/05/2022 16:47:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=542
06/05/2022 16:47:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/05/2022 16:47:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/05/2022 16:47:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/05/2022 16:47:45 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.5440923605993613 on epoch=549
06/05/2022 16:47:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/05/2022 16:47:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/05/2022 16:47:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/05/2022 16:48:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/05/2022 16:48:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/05/2022 16:48:10 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.34449441945693815 on epoch=562
06/05/2022 16:48:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/05/2022 16:48:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/05/2022 16:48:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/05/2022 16:48:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/05/2022 16:48:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/05/2022 16:48:35 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.49556650246305417 on epoch=574
06/05/2022 16:48:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/05/2022 16:48:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/05/2022 16:48:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/05/2022 16:48:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/05/2022 16:48:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/05/2022 16:49:00 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5195195195195195 on epoch=587
06/05/2022 16:49:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/05/2022 16:49:09 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/05/2022 16:49:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/05/2022 16:49:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=597
06/05/2022 16:49:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/05/2022 16:49:26 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.46875 on epoch=599
06/05/2022 16:49:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/05/2022 16:49:35 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/05/2022 16:49:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/05/2022 16:49:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/05/2022 16:49:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/05/2022 16:49:51 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5058530510585305 on epoch=612
06/05/2022 16:49:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/05/2022 16:50:00 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/05/2022 16:50:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/05/2022 16:50:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/05/2022 16:50:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/05/2022 16:50:16 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.46666666666666656 on epoch=624
06/05/2022 16:50:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/05/2022 16:50:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/05/2022 16:50:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/05/2022 16:50:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/05/2022 16:50:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=637
06/05/2022 16:50:40 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.5076923076923077 on epoch=637
06/05/2022 16:50:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
06/05/2022 16:50:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/05/2022 16:50:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/05/2022 16:50:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/05/2022 16:51:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/05/2022 16:51:06 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.47813194959229055 on epoch=649
06/05/2022 16:51:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/05/2022 16:51:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/05/2022 16:51:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/05/2022 16:51:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/05/2022 16:51:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/05/2022 16:51:31 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.4519207242476144 on epoch=662
06/05/2022 16:51:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/05/2022 16:51:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/05/2022 16:51:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/05/2022 16:51:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/05/2022 16:51:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/05/2022 16:51:57 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5058530510585305 on epoch=674
06/05/2022 16:52:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/05/2022 16:52:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/05/2022 16:52:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/05/2022 16:52:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 16:52:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/05/2022 16:52:22 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.464039408866995 on epoch=687
06/05/2022 16:52:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/05/2022 16:52:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/05/2022 16:52:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/05/2022 16:52:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/05/2022 16:52:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/05/2022 16:52:47 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.46031746031746035 on epoch=699
06/05/2022 16:52:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/05/2022 16:52:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/05/2022 16:53:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 16:53:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/05/2022 16:53:10 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/05/2022 16:53:13 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.46666666666666656 on epoch=712
06/05/2022 16:53:17 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/05/2022 16:53:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/05/2022 16:53:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/05/2022 16:53:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/05/2022 16:53:36 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/05/2022 16:53:39 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.4832395400048935 on epoch=724
06/05/2022 16:53:43 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 16:53:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/05/2022 16:53:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/05/2022 16:53:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/05/2022 16:54:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/05/2022 16:54:04 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.34577114427860695 on epoch=737
06/05/2022 16:54:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/05/2022 16:54:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
06/05/2022 16:54:17 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/05/2022 16:54:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/05/2022 16:54:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/05/2022 16:54:27 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 16:54:27 - INFO - __main__ - Printing 3 examples
06/05/2022 16:54:27 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 16:54:27 - INFO - __main__ - ['refuted']
06/05/2022 16:54:27 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 16:54:27 - INFO - __main__ - ['refuted']
06/05/2022 16:54:27 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 16:54:27 - INFO - __main__ - ['refuted']
06/05/2022 16:54:27 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:54:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:54:28 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 16:54:28 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 16:54:28 - INFO - __main__ - Printing 3 examples
06/05/2022 16:54:28 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 16:54:28 - INFO - __main__ - ['refuted']
06/05/2022 16:54:28 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 16:54:28 - INFO - __main__ - ['refuted']
06/05/2022 16:54:28 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 16:54:28 - INFO - __main__ - ['refuted']
06/05/2022 16:54:28 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:54:28 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:54:28 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 16:54:29 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.4874874874874875 on epoch=749
06/05/2022 16:54:29 - INFO - __main__ - save last model!
06/05/2022 16:54:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 16:54:29 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 16:54:29 - INFO - __main__ - Printing 3 examples
06/05/2022 16:54:29 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 16:54:29 - INFO - __main__ - ['entailed']
06/05/2022 16:54:29 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 16:54:29 - INFO - __main__ - ['entailed']
06/05/2022 16:54:29 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 16:54:29 - INFO - __main__ - ['entailed']
06/05/2022 16:54:29 - INFO - __main__ - Tokenizing Input ...
06/05/2022 16:54:42 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 16:54:42 - INFO - __main__ - task name: tab_fact
06/05/2022 16:54:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 16:54:43 - INFO - __main__ - Starting training!
06/05/2022 16:54:53 - INFO - __main__ - Tokenizing Output ...
06/05/2022 16:55:06 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 17:03:38 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_100_0.4_8_predictions.txt
06/05/2022 17:03:39 - INFO - __main__ - Classification-F1 on test data: 0.4870
06/05/2022 17:03:39 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.4, bsz=8, dev_performance=0.5921568627450979, test_performance=0.48697196049122665
06/05/2022 17:03:39 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.3, bsz=8 ...
06/05/2022 17:03:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 17:03:40 - INFO - __main__ - Printing 3 examples
06/05/2022 17:03:40 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 17:03:40 - INFO - __main__ - ['refuted']
06/05/2022 17:03:40 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 17:03:40 - INFO - __main__ - ['refuted']
06/05/2022 17:03:40 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 17:03:40 - INFO - __main__ - ['refuted']
06/05/2022 17:03:40 - INFO - __main__ - Tokenizing Input ...
06/05/2022 17:03:40 - INFO - __main__ - Tokenizing Output ...
06/05/2022 17:03:40 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 17:03:40 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 17:03:40 - INFO - __main__ - Printing 3 examples
06/05/2022 17:03:40 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 17:03:40 - INFO - __main__ - ['refuted']
06/05/2022 17:03:40 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 17:03:40 - INFO - __main__ - ['refuted']
06/05/2022 17:03:40 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 17:03:40 - INFO - __main__ - ['refuted']
06/05/2022 17:03:40 - INFO - __main__ - Tokenizing Input ...
06/05/2022 17:03:40 - INFO - __main__ - Tokenizing Output ...
06/05/2022 17:03:40 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 17:03:59 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 17:03:59 - INFO - __main__ - task name: tab_fact
06/05/2022 17:04:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 17:04:00 - INFO - __main__ - Starting training!
06/05/2022 17:04:05 - INFO - __main__ - Step 10 Global step 10 Train loss 5.49 on epoch=2
06/05/2022 17:04:09 - INFO - __main__ - Step 20 Global step 20 Train loss 3.00 on epoch=4
06/05/2022 17:04:14 - INFO - __main__ - Step 30 Global step 30 Train loss 1.28 on epoch=7
06/05/2022 17:04:18 - INFO - __main__ - Step 40 Global step 40 Train loss 0.82 on epoch=9
06/05/2022 17:04:23 - INFO - __main__ - Step 50 Global step 50 Train loss 0.64 on epoch=12
06/05/2022 17:04:25 - INFO - __main__ - Global step 50 Train loss 2.24 Classification-F1 0.4909862142099682 on epoch=12
06/05/2022 17:04:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4909862142099682 on epoch=12, global_step=50
06/05/2022 17:04:30 - INFO - __main__ - Step 60 Global step 60 Train loss 0.45 on epoch=14
06/05/2022 17:04:34 - INFO - __main__ - Step 70 Global step 70 Train loss 0.43 on epoch=17
06/05/2022 17:04:39 - INFO - __main__ - Step 80 Global step 80 Train loss 0.35 on epoch=19
06/05/2022 17:04:43 - INFO - __main__ - Step 90 Global step 90 Train loss 0.34 on epoch=22
06/05/2022 17:04:48 - INFO - __main__ - Step 100 Global step 100 Train loss 0.35 on epoch=24
06/05/2022 17:04:51 - INFO - __main__ - Global step 100 Train loss 0.38 Classification-F1 0.22456140350877193 on epoch=24
06/05/2022 17:04:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.31 on epoch=27
06/05/2022 17:05:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.26 on epoch=29
06/05/2022 17:05:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.31 on epoch=32
06/05/2022 17:05:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.27 on epoch=34
06/05/2022 17:05:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.26 on epoch=37
06/05/2022 17:05:16 - INFO - __main__ - Global step 150 Train loss 0.28 Classification-F1 0.47602339181286546 on epoch=37
06/05/2022 17:05:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.25 on epoch=39
06/05/2022 17:05:25 - INFO - __main__ - Step 170 Global step 170 Train loss 0.23 on epoch=42
06/05/2022 17:05:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.21 on epoch=44
06/05/2022 17:05:35 - INFO - __main__ - Step 190 Global step 190 Train loss 0.29 on epoch=47
06/05/2022 17:05:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.25 on epoch=49
06/05/2022 17:05:42 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3816425120772947 on epoch=49
06/05/2022 17:05:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.23 on epoch=52
06/05/2022 17:05:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=54
06/05/2022 17:05:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=57
06/05/2022 17:06:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=59
06/05/2022 17:06:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
06/05/2022 17:06:07 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 17:06:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.23 on epoch=64
06/05/2022 17:06:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/05/2022 17:06:21 - INFO - __main__ - Step 280 Global step 280 Train loss 0.19 on epoch=69
06/05/2022 17:06:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/05/2022 17:06:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
06/05/2022 17:06:33 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=74
06/05/2022 17:06:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=77
06/05/2022 17:06:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=79
06/05/2022 17:06:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/05/2022 17:06:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=84
06/05/2022 17:06:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=87
06/05/2022 17:06:58 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 17:07:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/05/2022 17:07:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/05/2022 17:07:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/05/2022 17:07:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/05/2022 17:07:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/05/2022 17:07:24 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.3671451355661882 on epoch=99
06/05/2022 17:07:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=102
06/05/2022 17:07:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/05/2022 17:07:37 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/05/2022 17:07:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/05/2022 17:07:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/05/2022 17:07:48 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 17:07:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/05/2022 17:07:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/05/2022 17:08:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=119
06/05/2022 17:08:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
06/05/2022 17:08:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/05/2022 17:08:12 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.32631578947368417 on epoch=124
06/05/2022 17:08:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
06/05/2022 17:08:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/05/2022 17:08:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/05/2022 17:08:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/05/2022 17:08:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/05/2022 17:08:37 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=137
06/05/2022 17:08:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/05/2022 17:08:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=142
06/05/2022 17:08:50 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/05/2022 17:08:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/05/2022 17:08:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/05/2022 17:09:02 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=149
06/05/2022 17:09:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/05/2022 17:09:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/05/2022 17:09:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/05/2022 17:09:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/05/2022 17:09:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/05/2022 17:09:26 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=162
06/05/2022 17:09:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/05/2022 17:09:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/05/2022 17:09:39 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/05/2022 17:09:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=172
06/05/2022 17:09:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/05/2022 17:09:50 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 17:09:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/05/2022 17:09:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/05/2022 17:10:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=182
06/05/2022 17:10:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=184
06/05/2022 17:10:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=187
06/05/2022 17:10:15 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.3984415584415584 on epoch=187
06/05/2022 17:10:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
06/05/2022 17:10:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=192
06/05/2022 17:10:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=194
06/05/2022 17:10:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/05/2022 17:10:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/05/2022 17:10:39 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.23097273097273097 on epoch=199
06/05/2022 17:10:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/05/2022 17:10:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/05/2022 17:10:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=207
06/05/2022 17:10:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/05/2022 17:11:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/05/2022 17:11:04 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.3816425120772947 on epoch=212
06/05/2022 17:11:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=214
06/05/2022 17:11:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/05/2022 17:11:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=219
06/05/2022 17:11:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=222
06/05/2022 17:11:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=224
06/05/2022 17:11:28 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.3511520737327189 on epoch=224
06/05/2022 17:11:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=227
06/05/2022 17:11:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/05/2022 17:11:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=232
06/05/2022 17:11:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/05/2022 17:11:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=237
06/05/2022 17:11:53 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.44976664210267747 on epoch=237
06/05/2022 17:11:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=239
06/05/2022 17:12:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=242
06/05/2022 17:12:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=244
06/05/2022 17:12:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=247
06/05/2022 17:12:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=249
06/05/2022 17:12:17 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.4652837798905215 on epoch=249
06/05/2022 17:12:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/05/2022 17:12:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=254
06/05/2022 17:12:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=257
06/05/2022 17:12:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=259
06/05/2022 17:12:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/05/2022 17:12:42 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.3352038907594463 on epoch=262
06/05/2022 17:12:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=264
06/05/2022 17:12:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=267
06/05/2022 17:12:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=269
06/05/2022 17:13:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=272
06/05/2022 17:13:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
06/05/2022 17:13:07 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.3727353727353727 on epoch=274
06/05/2022 17:13:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/05/2022 17:13:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
06/05/2022 17:13:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=282
06/05/2022 17:13:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
06/05/2022 17:13:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=287
06/05/2022 17:13:32 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.30476190476190473 on epoch=287
06/05/2022 17:13:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/05/2022 17:13:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=292
06/05/2022 17:13:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/05/2022 17:13:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=297
06/05/2022 17:13:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/05/2022 17:13:56 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.47602339181286546 on epoch=299
06/05/2022 17:14:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=302
06/05/2022 17:14:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/05/2022 17:14:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=307
06/05/2022 17:14:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=309
06/05/2022 17:14:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=312
06/05/2022 17:14:21 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.51417004048583 on epoch=312
06/05/2022 17:14:21 - INFO - __main__ - Saving model with best Classification-F1: 0.4909862142099682 -> 0.51417004048583 on epoch=312, global_step=1250
06/05/2022 17:14:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/05/2022 17:14:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=317
06/05/2022 17:14:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=319
06/05/2022 17:14:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=322
06/05/2022 17:14:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=324
06/05/2022 17:14:46 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.4217338217338217 on epoch=324
06/05/2022 17:14:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=327
06/05/2022 17:14:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=329
06/05/2022 17:14:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=332
06/05/2022 17:15:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=334
06/05/2022 17:15:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/05/2022 17:15:11 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.3117794486215539 on epoch=337
06/05/2022 17:15:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/05/2022 17:15:20 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=342
06/05/2022 17:15:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=344
06/05/2022 17:15:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
06/05/2022 17:15:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=349
06/05/2022 17:15:36 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.4920634920634921 on epoch=349
06/05/2022 17:15:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=352
06/05/2022 17:15:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/05/2022 17:15:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=357
06/05/2022 17:15:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=359
06/05/2022 17:15:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/05/2022 17:16:00 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.30537634408602155 on epoch=362
06/05/2022 17:16:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=364
06/05/2022 17:16:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/05/2022 17:16:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/05/2022 17:16:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=372
06/05/2022 17:16:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/05/2022 17:16:26 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.2769230769230769 on epoch=374
06/05/2022 17:16:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=377
06/05/2022 17:16:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=379
06/05/2022 17:16:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/05/2022 17:16:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=384
06/05/2022 17:16:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=387
06/05/2022 17:16:50 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.29696969696969694 on epoch=387
06/05/2022 17:16:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/05/2022 17:16:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/05/2022 17:17:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/05/2022 17:17:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/05/2022 17:17:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/05/2022 17:17:15 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.29969578444154715 on epoch=399
06/05/2022 17:17:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/05/2022 17:17:24 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/05/2022 17:17:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=407
06/05/2022 17:17:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/05/2022 17:17:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
06/05/2022 17:17:40 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.30069444444444443 on epoch=412
06/05/2022 17:17:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/05/2022 17:17:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/05/2022 17:17:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/05/2022 17:17:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=422
06/05/2022 17:18:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
06/05/2022 17:18:05 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.36046720575022456 on epoch=424
06/05/2022 17:18:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=427
06/05/2022 17:18:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/05/2022 17:18:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/05/2022 17:18:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/05/2022 17:18:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/05/2022 17:18:30 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.33160149485005924 on epoch=437
06/05/2022 17:18:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/05/2022 17:18:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/05/2022 17:18:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/05/2022 17:18:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=447
06/05/2022 17:18:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/05/2022 17:18:55 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.29757343550446996 on epoch=449
06/05/2022 17:19:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/05/2022 17:19:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/05/2022 17:19:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/05/2022 17:19:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=459
06/05/2022 17:19:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
06/05/2022 17:19:20 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.49090909090909085 on epoch=462
06/05/2022 17:19:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=464
06/05/2022 17:19:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/05/2022 17:19:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/05/2022 17:19:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/05/2022 17:19:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/05/2022 17:19:45 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.31464019851116626 on epoch=474
06/05/2022 17:19:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/05/2022 17:19:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/05/2022 17:19:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/05/2022 17:20:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/05/2022 17:20:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/05/2022 17:20:10 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.4666666666666667 on epoch=487
06/05/2022 17:20:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=489
06/05/2022 17:20:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/05/2022 17:20:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=494
06/05/2022 17:20:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/05/2022 17:20:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=499
06/05/2022 17:20:36 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.2731593579051206 on epoch=499
06/05/2022 17:20:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/05/2022 17:20:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/05/2022 17:20:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/05/2022 17:20:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/05/2022 17:20:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/05/2022 17:21:02 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.43529411764705883 on epoch=512
06/05/2022 17:21:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/05/2022 17:21:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/05/2022 17:21:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/05/2022 17:21:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/05/2022 17:21:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=524
06/05/2022 17:21:27 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.25808234318872614 on epoch=524
06/05/2022 17:21:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/05/2022 17:21:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/05/2022 17:21:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/05/2022 17:21:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/05/2022 17:21:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/05/2022 17:21:52 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.46666666666666656 on epoch=537
06/05/2022 17:21:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/05/2022 17:22:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/05/2022 17:22:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/05/2022 17:22:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/05/2022 17:22:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/05/2022 17:22:17 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.464039408866995 on epoch=549
06/05/2022 17:22:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/05/2022 17:22:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/05/2022 17:22:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/05/2022 17:22:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/05/2022 17:22:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/05/2022 17:22:42 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.4217338217338217 on epoch=562
06/05/2022 17:22:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/05/2022 17:22:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/05/2022 17:22:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=569
06/05/2022 17:23:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/05/2022 17:23:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/05/2022 17:23:07 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.30439814814814814 on epoch=574
06/05/2022 17:23:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/05/2022 17:23:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/05/2022 17:23:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/05/2022 17:23:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/05/2022 17:23:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/05/2022 17:23:31 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.4217338217338217 on epoch=587
06/05/2022 17:23:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/05/2022 17:23:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/05/2022 17:23:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/05/2022 17:23:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/05/2022 17:23:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/05/2022 17:23:57 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.2880617035546613 on epoch=599
06/05/2022 17:24:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/05/2022 17:24:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/05/2022 17:24:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/05/2022 17:24:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/05/2022 17:24:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/05/2022 17:24:22 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.4519207242476144 on epoch=612
06/05/2022 17:24:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/05/2022 17:24:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/05/2022 17:24:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/05/2022 17:24:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/05/2022 17:24:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/05/2022 17:24:47 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.20248049052396877 on epoch=624
06/05/2022 17:24:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/05/2022 17:24:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/05/2022 17:25:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/05/2022 17:25:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/05/2022 17:25:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/05/2022 17:25:12 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.2726220016542597 on epoch=637
06/05/2022 17:25:17 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/05/2022 17:25:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/05/2022 17:25:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/05/2022 17:25:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/05/2022 17:25:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/05/2022 17:25:38 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.30439814814814814 on epoch=649
06/05/2022 17:25:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=652
06/05/2022 17:25:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/05/2022 17:25:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/05/2022 17:25:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/05/2022 17:26:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/05/2022 17:26:03 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.32126089872568747 on epoch=662
06/05/2022 17:26:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/05/2022 17:26:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/05/2022 17:26:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/05/2022 17:26:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/05/2022 17:26:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/05/2022 17:26:28 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.21247464503042596 on epoch=674
06/05/2022 17:26:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/05/2022 17:26:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/05/2022 17:26:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/05/2022 17:26:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 17:26:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=687
06/05/2022 17:26:52 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.27135260884014617 on epoch=687
06/05/2022 17:26:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/05/2022 17:27:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/05/2022 17:27:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/05/2022 17:27:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/05/2022 17:27:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/05/2022 17:27:17 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.2849936948297604 on epoch=699
06/05/2022 17:27:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/05/2022 17:27:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/05/2022 17:27:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/05/2022 17:27:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/05/2022 17:27:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/05/2022 17:27:42 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.21443246019517204 on epoch=712
06/05/2022 17:27:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/05/2022 17:27:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/05/2022 17:27:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/05/2022 17:28:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/05/2022 17:28:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/05/2022 17:28:08 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.26200135226504395 on epoch=724
06/05/2022 17:28:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 17:28:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=729
06/05/2022 17:28:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/05/2022 17:28:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/05/2022 17:28:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 17:28:33 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.436950146627566 on epoch=737
06/05/2022 17:28:37 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/05/2022 17:28:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/05/2022 17:28:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/05/2022 17:28:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/05/2022 17:28:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/05/2022 17:28:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 17:28:56 - INFO - __main__ - Printing 3 examples
06/05/2022 17:28:56 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 17:28:56 - INFO - __main__ - ['refuted']
06/05/2022 17:28:56 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 17:28:56 - INFO - __main__ - ['refuted']
06/05/2022 17:28:56 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 17:28:56 - INFO - __main__ - ['refuted']
06/05/2022 17:28:56 - INFO - __main__ - Tokenizing Input ...
06/05/2022 17:28:56 - INFO - __main__ - Tokenizing Output ...
06/05/2022 17:28:57 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 17:28:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 17:28:57 - INFO - __main__ - Printing 3 examples
06/05/2022 17:28:57 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 17:28:57 - INFO - __main__ - ['refuted']
06/05/2022 17:28:57 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 17:28:57 - INFO - __main__ - ['refuted']
06/05/2022 17:28:57 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 17:28:57 - INFO - __main__ - ['refuted']
06/05/2022 17:28:57 - INFO - __main__ - Tokenizing Input ...
06/05/2022 17:28:57 - INFO - __main__ - Tokenizing Output ...
06/05/2022 17:28:57 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 17:28:58 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.293631100082713 on epoch=749
06/05/2022 17:28:58 - INFO - __main__ - save last model!
06/05/2022 17:28:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 17:28:58 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 17:28:58 - INFO - __main__ - Printing 3 examples
06/05/2022 17:28:58 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 17:28:58 - INFO - __main__ - ['entailed']
06/05/2022 17:28:58 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 17:28:58 - INFO - __main__ - ['entailed']
06/05/2022 17:28:58 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 17:28:58 - INFO - __main__ - ['entailed']
06/05/2022 17:28:58 - INFO - __main__ - Tokenizing Input ...
06/05/2022 17:29:11 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 17:29:11 - INFO - __main__ - task name: tab_fact
06/05/2022 17:29:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 17:29:12 - INFO - __main__ - Starting training!
06/05/2022 17:29:22 - INFO - __main__ - Tokenizing Output ...
06/05/2022 17:29:35 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 17:37:45 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_100_0.3_8_predictions.txt
06/05/2022 17:37:45 - INFO - __main__ - Classification-F1 on test data: 0.1095
06/05/2022 17:37:46 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.3, bsz=8, dev_performance=0.51417004048583, test_performance=0.10950759334795186
06/05/2022 17:37:46 - INFO - __main__ - Running ... prefix=tab_fact_32_100, lr=0.2, bsz=8 ...
06/05/2022 17:37:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 17:37:47 - INFO - __main__ - Printing 3 examples
06/05/2022 17:37:47 - INFO - __main__ -  [tab_fact] statement: tampa bay play no game at home during the month of november [SEP] table_caption: 2007 - 08 tampa bay lightning season [SEP] table_text: date#visitor#score#home#decision#attendance#record [n] november 1#tampa bay#0 - 4#ny islanders#denis#11008#5 - 6 - 1 [n] november 3#atlanta#6 - 4#tampa bay#holmqvist#19155#5 - 7 - 1 [n] november 5#tampa bay#3 - 4#florida#holmqvist#10149#5 - 8 - 1 [n] november 7#florida#1 - 3#tampa bay#holmqvist#16526#6 - 8 - 1 [n] november 8#tampa bay#5 - 1#carolina#holmqvist#14017#7 - 8 - 1 [n] november 10#tampa bay#5 - 2#washington#holmqvist#14617#8 - 8 - 1 [n] november 14#carolina#1 - 6#tampa bay#holmqvist#17444#9 - 8 - 1 [n] november 16#washington#2 - 5#tampa bay#holmqvist#19526#10 - 8 - 1 [n] november 19#tampa bay#3 - 4#atlanta#holmqvist#13419#10 - 8 - 2 [n] november 21#ny rangers#2 - 1#tampa bay#holmqvist#20110#10 - 9 - 2 [n] november 23#tampa bay#3 - 4#carolina#holmqvist#18033#10 - 10 - 2 [n] november 24#new jersey#3 - 2#tampa bay#holmqvist#19077#10 - 11 - 2 [n] november 28#tampa bay#1 - 5#chicago#holmqvist#11122#10 - 12 - 2 [n] november 29#tampa bay#2 - 4#detroit#denis#17001#10 - 13 - 2 [n] 
06/05/2022 17:37:47 - INFO - __main__ - ['refuted']
06/05/2022 17:37:47 - INFO - __main__ -  [tab_fact] statement: there be more than 9 silver medalist [SEP] table_caption: archery at the asian games [SEP] table_text: year#location#gold#silver#bronze [n] 1978#bangkok#kim jin - ho#yuriko goto#kim hyang - mi [n] 1982#new delhi#o gwang - sun#kim jin - ho#kim mi - young [n] 1986#seoul#park jung - ah#kim jin - ho#kim mi - ja [n] 1990#beijing#lee jang - mi#lee eun - kyung#kim soo - nyung [n] 1994#hiroshima#lee eun - kyung#lim jung - ah#han hee - jeong [n] 1998#bangkok#kim jo - sun#lee eun - kyung#lin sang [n] 2002#busan#yuan shu - chi#kim mun - jeong#yun mi - jin [n] 2006#doha#park sung - hyun#yun ok - hee#zhao ling [n] 2010#guangzhou#yun ok - hee#cheng ming#kwon un - sil [n] 
06/05/2022 17:37:47 - INFO - __main__ - ['refuted']
06/05/2022 17:37:47 - INFO - __main__ -  [tab_fact] statement: the average point score in achieve second place in the speedway world pair championship be 18 [SEP] table_caption: speedway world pairs championship [SEP] table_text: year#venue#winners#runner - up#3rd place [n] 1968#kempten#sweden (24 pts)#(21 pts)#(16 pts) [n] 1969#stockholm#new zealand (28 pts)#sweden (27 pts)#england (21 pts) [n] year#venue#winners#runner - up#3rd place [n] 1970#malmö#new zealand (28 pts)#sweden (25 pts)#england (19 pts) [n] 1971#rybnik#(30 pts)#new zealand (25 pts)#sweden (22 pts) [n] 1972#borås#england (24 + 3 pts)#new zealand (24 + 2 pts)#sweden b (22 + 3 pts) [n] 1973#borås#sweden (24 pts)#(21 + 3 pts)#(21 + 2 pts) [n] 1974#manchester#sweden (28 pts)#australia (23 pts)#new zealand (21 pts) [n] 1975#wrocław#sweden (24 pts)#(23 pts)#(20 + 3 pts) [n] 1976#eskilstuna#england (27 pts)#(24 pts)#sweden (22 pts) [n] 1977#manchester#england (28 pts)#sweden (18 pts)#west germany (18 pts) [n] 1978#chorzów#england (24 + 3 pts)#new zealand (24 + 2 pts)#(21 pts) [n] 1979#vojens#(25 pts)#england (24 pts)#(20 pts) [n] 1980#krško#england (29 pts)#(22 pts)#(21 pts) [n] 1981#chorzów#united states (23 pts)#new zealand (22 pts)#(21 pts) [n] 1982#liverpool#united states (30 pts)#england (22 pts)#(21 pts) [n] 1983#gothenburg#england (25 pts)#australia (24 pts)#(19 pts) [n] 1984#lonigo#england (27 pts)#(25 + 3 pts)#new zealand (25 + 2 pts) [n] 1985#rybnik#(29 pts)#england (27 pts)#united states (22 pts) [n] 1986#pocking#(46 + 5 pts)#united states (46 + 4 pts)#czechoslovakia (32 pts) [n] 1987#pardubice#(52 pts)#england (44 pts)#united states (36 pts) [n] 1988#bradford#(45 pts)#england (41 pts)#united states (39 pts) [n] 1989#leszno#(48 pts)#sweden (44 pts)#england (37 pts) [n] 1990#landshut#(43 pts)#australia (41 pts)#(33 pts) [n] 1991#poznań#(28 pts)#sweden (24 pts)#(19 pts) [n] 1992#lonigo#united states (23 + 3 pts)#england (23 + 2 pts)#sweden (22 pts) [n] 1993#vojens#sweden (26 pts)#united states (23 pts)#(21 pts) [n] 
06/05/2022 17:37:47 - INFO - __main__ - ['refuted']
06/05/2022 17:37:47 - INFO - __main__ - Tokenizing Input ...
06/05/2022 17:37:47 - INFO - __main__ - Tokenizing Output ...
06/05/2022 17:37:47 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 17:37:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 17:37:47 - INFO - __main__ - Printing 3 examples
06/05/2022 17:37:47 - INFO - __main__ -  [tab_fact] statement: the steam torpedo boat be the only type to be construct in a single year [SEP] table_caption: guangdong fleet [SEP] table_text: name (pinyin)#name (wade giles)#characters#type#construction [n] leihu#lei - hu#雷虎#steam torpedo boat#1884 , stettin , germany [n] leilong#lei - lung#雷龍#steam torpedo boat#1884 , stettin , germany [n] leidui#lei - tui#雷兑#steam torpedo boat#1885 , schichau , germany [n] leigan#lei - kan#雷乾#steam torpedo boat#1885 , schichau , germany [n] leiqian#lei - ch'ien#雷坎#steam torpedo boat#1885 , schichau , germany [n] leikun#lei - k'un#雷坤#steam torpedo boat#1885 , schichau , germany [n] leili#lei - li#雷離#steam torpedo boat#1885 , schichau , germany [n] leigen#lei - gen#雷艮#steam torpedo boat#1885 , schichau , germany [n] leixun#lei - hsun#雷巽#steam torpedo boat#1885 , schichau , germany [n] leizhen#lei - chen#雷震#steam torpedo boat#1885 , schichau , germany [n] leizhong#lei - chung#雷中#steam torpedo boat#1885 , schichau , germany [n] guangheng#kuang - heng#廣亨#composite shallow - draft gunboat#1886 , canton [n] guangli#kuang - li#廣利#composite shallow - draft gunboat#1886 , canton [n] guangyuan#kuang - yuan#廣元#composite shallow - draft gunboat#1886 , canton [n] guangzhen#kuang - chen#廣貞#composite shallow - draft gunboat#1886 , canton [n] guanggeng#kuang - keng#廣庚#wooden gunboat#c1887 , foochow navy yard [n] guangxing#kuang - hsing#廣興#wooden gunboat#c1887 , foochow navy yard [n] guangzhen#kuang - chen#廣鎮#wooden gunboat#c1887 , foochow navy yard [n] guangkui#kuang - k'uei#廣癸#wooden gunboat#c1887 , foochow navy yard [n] guangjia#kuang - chia#廣甲#composite cruiser#1887 , foochow navy yard [n] guangyi#kuang - i#廣乙#steel torpedo gunboat#1892 , foochow navy yard [n] guangbing#kuang - ping#廣丙#steel torpedo gunboat#1892 , foochow navy yard [n] guangding#kuang - ting#廣丁#steel torpedo gunboat#1892 , foochow navy yard [n] 
06/05/2022 17:37:47 - INFO - __main__ - ['refuted']
06/05/2022 17:37:47 - INFO - __main__ -  [tab_fact] statement: xle02008 be the production code for number 9 [SEP] table_caption: list of the league episodes [SEP] table_text: no#-#title#directed by#written by#original air date#production code#us viewers (million) [n] 7#1#vegas draft#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 16 , 2010#xle02001#1.71 [n] 8#2#bro - lo el cuã±ado#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 23 , 2010#xle02002#1.05 [n] 9#3#the white knuckler#jeff schaffer#jeff schaffer & jackie marcus schaffer#september 30 , 2010#xle02003#0.89 [n] 10#4#the kluneberg#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 7 , 2010#xle02004#0.82 [n] 11#5#the marathon#jackie marcus schaffer#craig digregorio#october 14 , 2010#xle02005#0.86 [n] 12#6#the anniversary party#jeff schaffer#nick kroll & paul scheer#october 21 , 2010#xle02006#0.62 [n] 13#7#ghost monkey#jeff schaffer#jeff schaffer & jackie marcus schaffer#october 28 , 2010#xle02007#0.67 [n] 14#8#the tie#jackie marcus schaffer#dan o'keefe#november 4 , 2010#xle02008#1.01 [n] 15#9#the expert witness#jeff schaffer#nick kroll & paul scheer#november 11 , 2010#xle02009#1.00 [n] 16#10#high school reunion#jeff schaffer#jeff schaffer & jackie marcus schaffer#november 18 , 2010#xle02010#1.04 [n] 18#12#kegel the elf#jeff schaffer#jeff schaffer & jackie marcus schaffer#december 9 , 2010#xle02012#1.05 [n] 
06/05/2022 17:37:47 - INFO - __main__ - ['refuted']
06/05/2022 17:37:47 - INFO - __main__ -  [tab_fact] statement: helpful tracy receive fewer than 145000 view [SEP] table_caption: none [SEP] table_text: #original title#directed by#written by#original airdate#prod code#viewers [n] 1 - 1#tracy returns#susan tully#elly brewer#8 july 2002#1.1#267000 [n] 1 - 2#dares#david skynner#elly brewer#15 july 2002#1.2#363000 [n] 1 - 3#sneaking in ben#susan tully#andy walker#22 july 2002#1.3#499000 [n] 1 - 4#cam 's first visit#susan tully#elly brewer#29 july 2002#1.4#233000 [n] 1 - 5#child of the week#susan tully#elly brewer#29 july 2002#1.5#278000 [n] 1 - 6#the truth is revealed#susan tully#carol russell#5 august 2002#1.6#315000 [n] 1 - 7#never ever wanna see him again#susan tully#mary morris#5 august 2002#1.7#221000 [n] 1 - 8#1000 words about tracy#susan tully#arnold evans#12 august 2002#1.8#261000 [n] 1 - 9#bad peter#susan tully#mary morris#12 august 2002#1.9#242000 [n] 1 - 10#cam 's place#susan tully#andy walker#19 august 2002#1.10#423000 [n] 1 - 11#dumping ground virus#david skynner#elly brewer#19 august 2002#1.11#444000 [n] 1 - 12#justine 's tv#susan tully#elly brewer#26 august 2002#1.12#417000 [n] 1 - 13#tracy and cam row#susan tully#elly brewer#26 august 2002#1.13#526000 [n] 1 - 14#sleepover#david skynner#mary morris#3 september 2002#1.14#658000 [n] 1 - 15#parent 's evening#susan tully#laura summers#3 september 2002#1.15#215000 [n] 1 - 16#the postcard#susan tully#roger griffiths#10 september 2002#1.16#215000 [n] 1 - 18#helpful tracy#david skynner#mary morris#10 september 2002#1.17#145000 [n] 1 - 19#friend#david skynner#laura summers#17 september 2002#1.19#815000 [n] 1 - 20#treasure hunt#david skynner#laura summers#24 september 2002#1.20#234000 [n] 1 - 21#romance#david skynner#elly brewer#24 september 2002#1.21#415000 [n] 1 - 22#temporary care worker#david skynner#othniel smith#1 october 2002#1.22#615000 [n] 1 - 23#cut the weed#david skynner#graham alborough#1 october 2002#1.23#522000 [n] 1 - 24#need armbands#david skynner#laura summers#8 october 2002#1.24#195000 [n] 1 - 25#miss you#david skynner#mary morris#8 october 2002#1.25#395000 [n] 
06/05/2022 17:37:47 - INFO - __main__ - ['refuted']
06/05/2022 17:37:47 - INFO - __main__ - Tokenizing Input ...
06/05/2022 17:37:47 - INFO - __main__ - Tokenizing Output ...
06/05/2022 17:37:47 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 17:38:07 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 17:38:07 - INFO - __main__ - task name: tab_fact
06/05/2022 17:38:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 17:38:07 - INFO - __main__ - Starting training!
06/05/2022 17:38:12 - INFO - __main__ - Step 10 Global step 10 Train loss 5.64 on epoch=2
06/05/2022 17:38:17 - INFO - __main__ - Step 20 Global step 20 Train loss 4.40 on epoch=4
06/05/2022 17:38:22 - INFO - __main__ - Step 30 Global step 30 Train loss 3.58 on epoch=7
06/05/2022 17:38:26 - INFO - __main__ - Step 40 Global step 40 Train loss 2.65 on epoch=9
06/05/2022 17:38:31 - INFO - __main__ - Step 50 Global step 50 Train loss 1.71 on epoch=12
06/05/2022 17:38:34 - INFO - __main__ - Global step 50 Train loss 3.60 Classification-F1 0.3347193347193347 on epoch=12
06/05/2022 17:38:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3347193347193347 on epoch=12, global_step=50
06/05/2022 17:38:38 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=14
06/05/2022 17:38:43 - INFO - __main__ - Step 70 Global step 70 Train loss 0.77 on epoch=17
06/05/2022 17:38:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.57 on epoch=19
06/05/2022 17:38:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.48 on epoch=22
06/05/2022 17:38:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.48 on epoch=24
06/05/2022 17:38:59 - INFO - __main__ - Global step 100 Train loss 0.67 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 17:39:03 - INFO - __main__ - Step 110 Global step 110 Train loss 0.36 on epoch=27
06/05/2022 17:39:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.35 on epoch=29
06/05/2022 17:39:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.33 on epoch=32
06/05/2022 17:39:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.37 on epoch=34
06/05/2022 17:39:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=37
06/05/2022 17:39:24 - INFO - __main__ - Global step 150 Train loss 0.33 Classification-F1 0.3333333333333333 on epoch=37
06/05/2022 17:39:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=39
06/05/2022 17:39:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.30 on epoch=42
06/05/2022 17:39:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/05/2022 17:39:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/05/2022 17:39:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=49
06/05/2022 17:39:49 - INFO - __main__ - Global step 200 Train loss 0.27 Classification-F1 0.32631578947368417 on epoch=49
06/05/2022 17:39:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=52
06/05/2022 17:39:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.23 on epoch=54
06/05/2022 17:40:03 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=57
06/05/2022 17:40:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=59
06/05/2022 17:40:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=62
06/05/2022 17:40:14 - INFO - __main__ - Global step 250 Train loss 0.26 Classification-F1 0.5405128205128205 on epoch=62
06/05/2022 17:40:14 - INFO - __main__ - Saving model with best Classification-F1: 0.3347193347193347 -> 0.5405128205128205 on epoch=62, global_step=250
06/05/2022 17:40:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=64
06/05/2022 17:40:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=67
06/05/2022 17:40:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/05/2022 17:40:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/05/2022 17:40:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.27 on epoch=74
06/05/2022 17:40:40 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.3591989987484355 on epoch=74
06/05/2022 17:40:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/05/2022 17:40:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/05/2022 17:40:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/05/2022 17:40:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=84
06/05/2022 17:41:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=87
06/05/2022 17:41:05 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 17:41:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/05/2022 17:41:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=92
06/05/2022 17:41:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/05/2022 17:41:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/05/2022 17:41:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/05/2022 17:41:31 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.3671451355661882 on epoch=99
06/05/2022 17:41:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/05/2022 17:41:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=104
06/05/2022 17:41:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=107
06/05/2022 17:41:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=109
06/05/2022 17:41:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=112
06/05/2022 17:41:56 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 17:42:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/05/2022 17:42:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/05/2022 17:42:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=119
06/05/2022 17:42:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=122
06/05/2022 17:42:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/05/2022 17:42:22 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.29679117319566756 on epoch=124
06/05/2022 17:42:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=127
06/05/2022 17:42:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
06/05/2022 17:42:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=132
06/05/2022 17:42:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/05/2022 17:42:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=137
06/05/2022 17:42:47 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.20576131687242802 on epoch=137
06/05/2022 17:42:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/05/2022 17:42:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=142
06/05/2022 17:43:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=144
06/05/2022 17:43:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=147
06/05/2022 17:43:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/05/2022 17:43:13 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.2604032604032604 on epoch=149
06/05/2022 17:43:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=152
06/05/2022 17:43:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/05/2022 17:43:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/05/2022 17:43:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=159
06/05/2022 17:43:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/05/2022 17:43:38 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.38535211267605635 on epoch=162
06/05/2022 17:43:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/05/2022 17:43:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=167
06/05/2022 17:43:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/05/2022 17:43:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/05/2022 17:44:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=174
06/05/2022 17:44:04 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.24947735191637632 on epoch=174
06/05/2022 17:44:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/05/2022 17:44:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/05/2022 17:44:17 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=182
06/05/2022 17:44:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/05/2022 17:44:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/05/2022 17:44:29 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.25318761384335153 on epoch=187
06/05/2022 17:44:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/05/2022 17:44:38 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
06/05/2022 17:44:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=194
06/05/2022 17:44:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=197
06/05/2022 17:44:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=199
06/05/2022 17:44:54 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.2965659507341342 on epoch=199
06/05/2022 17:44:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/05/2022 17:45:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/05/2022 17:45:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/05/2022 17:45:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=209
06/05/2022 17:45:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=212
06/05/2022 17:45:20 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.2799145299145299 on epoch=212
06/05/2022 17:45:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/05/2022 17:45:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/05/2022 17:45:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/05/2022 17:45:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=222
06/05/2022 17:45:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/05/2022 17:45:45 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.28960445239515004 on epoch=224
06/05/2022 17:45:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/05/2022 17:45:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/05/2022 17:45:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/05/2022 17:46:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=234
06/05/2022 17:46:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=237
06/05/2022 17:46:11 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.2993827160493827 on epoch=237
06/05/2022 17:46:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=239
06/05/2022 17:46:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/05/2022 17:46:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=244
06/05/2022 17:46:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=247
06/05/2022 17:46:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=249
06/05/2022 17:46:36 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.3079777365491651 on epoch=249
06/05/2022 17:46:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/05/2022 17:46:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=254
06/05/2022 17:46:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=257
06/05/2022 17:46:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=259
06/05/2022 17:46:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=262
06/05/2022 17:47:02 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.3481481481481481 on epoch=262
06/05/2022 17:47:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=264
06/05/2022 17:47:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=267
06/05/2022 17:47:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=269
06/05/2022 17:47:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=272
06/05/2022 17:47:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
06/05/2022 17:47:27 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.5497835497835498 on epoch=274
06/05/2022 17:47:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5405128205128205 -> 0.5497835497835498 on epoch=274, global_step=1100
06/05/2022 17:47:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=277
06/05/2022 17:47:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
06/05/2022 17:47:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=282
06/05/2022 17:47:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=284
06/05/2022 17:47:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=287
06/05/2022 17:47:53 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.3558330855387055 on epoch=287
06/05/2022 17:47:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=289
06/05/2022 17:48:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=292
06/05/2022 17:48:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=294
06/05/2022 17:48:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=297
06/05/2022 17:48:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=299
06/05/2022 17:48:18 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.4995112414467253 on epoch=299
06/05/2022 17:48:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=302
06/05/2022 17:48:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=304
06/05/2022 17:48:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=307
06/05/2022 17:48:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=309
06/05/2022 17:48:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=312
06/05/2022 17:48:44 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.3356515979466799 on epoch=312
06/05/2022 17:48:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
06/05/2022 17:48:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=317
06/05/2022 17:48:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=319
06/05/2022 17:49:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=322
06/05/2022 17:49:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=324
06/05/2022 17:49:09 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.3146087743102668 on epoch=324
06/05/2022 17:49:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=327
06/05/2022 17:49:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=329
06/05/2022 17:49:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=332
06/05/2022 17:49:27 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=334
06/05/2022 17:49:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=337
06/05/2022 17:49:35 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.3359774369821964 on epoch=337
06/05/2022 17:49:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=339
06/05/2022 17:49:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=342
06/05/2022 17:49:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=344
06/05/2022 17:49:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=347
06/05/2022 17:49:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=349
06/05/2022 17:50:00 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.5307917888563051 on epoch=349
06/05/2022 17:50:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=352
06/05/2022 17:50:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=354
06/05/2022 17:50:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=357
06/05/2022 17:50:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=359
06/05/2022 17:50:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=362
06/05/2022 17:50:26 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.1695238095238095 on epoch=362
06/05/2022 17:50:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=364
06/05/2022 17:50:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=367
06/05/2022 17:50:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=369
06/05/2022 17:50:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=372
06/05/2022 17:50:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=374
06/05/2022 17:50:51 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.51417004048583 on epoch=374
06/05/2022 17:50:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/05/2022 17:51:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=379
06/05/2022 17:51:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=382
06/05/2022 17:51:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=384
06/05/2022 17:51:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.16 on epoch=387
06/05/2022 17:51:16 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.5126504544338 on epoch=387
06/05/2022 17:51:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=389
06/05/2022 17:51:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=392
06/05/2022 17:51:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.18 on epoch=394
06/05/2022 17:51:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=397
06/05/2022 17:51:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=399
06/05/2022 17:51:41 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.5294117647058825 on epoch=399
06/05/2022 17:51:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=402
06/05/2022 17:51:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=404
06/05/2022 17:51:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=407
06/05/2022 17:52:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=409
06/05/2022 17:52:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=412
06/05/2022 17:52:07 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.4748717948717949 on epoch=412
06/05/2022 17:52:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=414
06/05/2022 17:52:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=417
06/05/2022 17:52:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/05/2022 17:52:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=422
06/05/2022 17:52:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/05/2022 17:52:32 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.5620723362658846 on epoch=424
06/05/2022 17:52:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5497835497835498 -> 0.5620723362658846 on epoch=424, global_step=1700
06/05/2022 17:52:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=427
06/05/2022 17:52:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=429
06/05/2022 17:52:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=432
06/05/2022 17:52:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=434
06/05/2022 17:52:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=437
06/05/2022 17:52:58 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.5330817610062892 on epoch=437
06/05/2022 17:53:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=439
06/05/2022 17:53:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=442
06/05/2022 17:53:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/05/2022 17:53:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=447
06/05/2022 17:53:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/05/2022 17:53:23 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.5307917888563051 on epoch=449
06/05/2022 17:53:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=452
06/05/2022 17:53:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/05/2022 17:53:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=457
06/05/2022 17:53:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=459
06/05/2022 17:53:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/05/2022 17:53:49 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.5076923076923077 on epoch=462
06/05/2022 17:53:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/05/2022 17:53:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=467
06/05/2022 17:54:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=469
06/05/2022 17:54:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/05/2022 17:54:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=474
06/05/2022 17:54:14 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.5515515515515517 on epoch=474
06/05/2022 17:54:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/05/2022 17:54:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=479
06/05/2022 17:54:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/05/2022 17:54:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/05/2022 17:54:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=487
06/05/2022 17:54:39 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.5195195195195195 on epoch=487
06/05/2022 17:54:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/05/2022 17:54:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/05/2022 17:54:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/05/2022 17:54:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/05/2022 17:55:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/05/2022 17:55:05 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.335978835978836 on epoch=499
06/05/2022 17:55:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/05/2022 17:55:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=504
06/05/2022 17:55:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=507
06/05/2022 17:55:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/05/2022 17:55:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/05/2022 17:55:30 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5294117647058825 on epoch=512
06/05/2022 17:55:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/05/2022 17:55:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/05/2022 17:55:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/05/2022 17:55:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=522
06/05/2022 17:55:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=524
06/05/2022 17:55:56 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.4682306940371457 on epoch=524
06/05/2022 17:56:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/05/2022 17:56:05 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/05/2022 17:56:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/05/2022 17:56:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/05/2022 17:56:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/05/2022 17:56:21 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.3398989898989899 on epoch=537
06/05/2022 17:56:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/05/2022 17:56:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=542
06/05/2022 17:56:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/05/2022 17:56:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/05/2022 17:56:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=549
06/05/2022 17:56:47 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.5307917888563051 on epoch=549
06/05/2022 17:56:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/05/2022 17:56:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/05/2022 17:57:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/05/2022 17:57:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/05/2022 17:57:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/05/2022 17:57:12 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.4874874874874875 on epoch=562
06/05/2022 17:57:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/05/2022 17:57:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/05/2022 17:57:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=569
06/05/2022 17:57:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/05/2022 17:57:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/05/2022 17:57:38 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.3569775132275132 on epoch=574
06/05/2022 17:57:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/05/2022 17:57:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=579
06/05/2022 17:57:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/05/2022 17:57:56 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/05/2022 17:58:01 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/05/2022 17:58:04 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.53125 on epoch=587
06/05/2022 17:58:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/05/2022 17:58:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/05/2022 17:58:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/05/2022 17:58:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=597
06/05/2022 17:58:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/05/2022 17:58:29 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.5294117647058825 on epoch=599
06/05/2022 17:58:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/05/2022 17:58:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/05/2022 17:58:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/05/2022 17:58:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/05/2022 17:58:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/05/2022 17:58:55 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.5294117647058825 on epoch=612
06/05/2022 17:59:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/05/2022 17:59:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/05/2022 17:59:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/05/2022 17:59:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/05/2022 17:59:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/05/2022 17:59:21 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.5467643467643467 on epoch=624
06/05/2022 17:59:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/05/2022 17:59:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/05/2022 17:59:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=632
06/05/2022 17:59:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/05/2022 17:59:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/05/2022 17:59:47 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.4874874874874875 on epoch=637
06/05/2022 17:59:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/05/2022 17:59:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/05/2022 18:00:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=644
06/05/2022 18:00:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/05/2022 18:00:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/05/2022 18:00:12 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.5755342667649226 on epoch=649
06/05/2022 18:00:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5620723362658846 -> 0.5755342667649226 on epoch=649, global_step=2600
06/05/2022 18:00:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/05/2022 18:00:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/05/2022 18:00:26 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/05/2022 18:00:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/05/2022 18:00:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=662
06/05/2022 18:00:38 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.3566583953680728 on epoch=662
06/05/2022 18:00:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=664
06/05/2022 18:00:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=667
06/05/2022 18:00:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/05/2022 18:00:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/05/2022 18:01:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/05/2022 18:01:03 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.5145583557621727 on epoch=674
06/05/2022 18:01:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/05/2022 18:01:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/05/2022 18:01:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/05/2022 18:01:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 18:01:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/05/2022 18:01:29 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5294117647058825 on epoch=687
06/05/2022 18:01:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/05/2022 18:01:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=692
06/05/2022 18:01:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/05/2022 18:01:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/05/2022 18:01:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/05/2022 18:01:55 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.5467643467643467 on epoch=699
06/05/2022 18:01:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/05/2022 18:02:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/05/2022 18:02:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/05/2022 18:02:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/05/2022 18:02:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=712
06/05/2022 18:02:20 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.48424908424908425 on epoch=712
06/05/2022 18:02:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/05/2022 18:02:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/05/2022 18:02:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/05/2022 18:02:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/05/2022 18:02:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/05/2022 18:02:46 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.4995112414467253 on epoch=724
06/05/2022 18:02:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 18:02:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/05/2022 18:03:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=732
06/05/2022 18:03:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/05/2022 18:03:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 18:03:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5620723362658846 on epoch=737
06/05/2022 18:03:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/05/2022 18:03:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/05/2022 18:03:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/05/2022 18:03:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=747
06/05/2022 18:03:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/05/2022 18:03:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:03:36 - INFO - __main__ - Printing 3 examples
06/05/2022 18:03:36 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 18:03:36 - INFO - __main__ - ['refuted']
06/05/2022 18:03:36 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 18:03:36 - INFO - __main__ - ['refuted']
06/05/2022 18:03:36 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 18:03:36 - INFO - __main__ - ['refuted']
06/05/2022 18:03:36 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:03:36 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:03:36 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 18:03:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:03:36 - INFO - __main__ - Printing 3 examples
06/05/2022 18:03:36 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 18:03:36 - INFO - __main__ - ['refuted']
06/05/2022 18:03:36 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 18:03:36 - INFO - __main__ - ['refuted']
06/05/2022 18:03:36 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 18:03:36 - INFO - __main__ - ['refuted']
06/05/2022 18:03:36 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:03:36 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:03:36 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 18:03:37 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.5625 on epoch=749
06/05/2022 18:03:37 - INFO - __main__ - save last model!
06/05/2022 18:03:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 18:03:37 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 18:03:37 - INFO - __main__ - Printing 3 examples
06/05/2022 18:03:37 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 18:03:37 - INFO - __main__ - ['entailed']
06/05/2022 18:03:37 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 18:03:37 - INFO - __main__ - ['entailed']
06/05/2022 18:03:37 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 18:03:37 - INFO - __main__ - ['entailed']
06/05/2022 18:03:37 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:03:51 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 18:03:51 - INFO - __main__ - task name: tab_fact
06/05/2022 18:03:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 18:03:52 - INFO - __main__ - Starting training!
06/05/2022 18:04:01 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:04:14 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 18:12:32 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_100_0.2_8_predictions.txt
06/05/2022 18:12:32 - INFO - __main__ - Classification-F1 on test data: 0.2006
06/05/2022 18:12:33 - INFO - __main__ - prefix=tab_fact_32_100, lr=0.2, bsz=8, dev_performance=0.5755342667649226, test_performance=0.20055965509659085
06/05/2022 18:12:33 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.5, bsz=8 ...
06/05/2022 18:12:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:12:34 - INFO - __main__ - Printing 3 examples
06/05/2022 18:12:34 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 18:12:34 - INFO - __main__ - ['refuted']
06/05/2022 18:12:34 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 18:12:34 - INFO - __main__ - ['refuted']
06/05/2022 18:12:34 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 18:12:34 - INFO - __main__ - ['refuted']
06/05/2022 18:12:34 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:12:34 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:12:34 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 18:12:34 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:12:34 - INFO - __main__ - Printing 3 examples
06/05/2022 18:12:34 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 18:12:34 - INFO - __main__ - ['refuted']
06/05/2022 18:12:34 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 18:12:34 - INFO - __main__ - ['refuted']
06/05/2022 18:12:34 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 18:12:34 - INFO - __main__ - ['refuted']
06/05/2022 18:12:34 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:12:34 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:12:34 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 18:12:53 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 18:12:53 - INFO - __main__ - task name: tab_fact
06/05/2022 18:12:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 18:12:54 - INFO - __main__ - Starting training!
06/05/2022 18:12:58 - INFO - __main__ - Step 10 Global step 10 Train loss 5.24 on epoch=2
06/05/2022 18:13:03 - INFO - __main__ - Step 20 Global step 20 Train loss 3.52 on epoch=4
06/05/2022 18:13:08 - INFO - __main__ - Step 30 Global step 30 Train loss 1.65 on epoch=7
06/05/2022 18:13:12 - INFO - __main__ - Step 40 Global step 40 Train loss 0.91 on epoch=9
06/05/2022 18:13:17 - INFO - __main__ - Step 50 Global step 50 Train loss 0.61 on epoch=12
06/05/2022 18:13:19 - INFO - __main__ - Global step 50 Train loss 2.39 Classification-F1 0.3333333333333333 on epoch=12
06/05/2022 18:13:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/05/2022 18:13:24 - INFO - __main__ - Step 60 Global step 60 Train loss 0.43 on epoch=14
06/05/2022 18:13:28 - INFO - __main__ - Step 70 Global step 70 Train loss 0.34 on epoch=17
06/05/2022 18:13:33 - INFO - __main__ - Step 80 Global step 80 Train loss 0.34 on epoch=19
06/05/2022 18:13:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.31 on epoch=22
06/05/2022 18:13:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.26 on epoch=24
06/05/2022 18:13:44 - INFO - __main__ - Global step 100 Train loss 0.34 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 18:13:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.27 on epoch=27
06/05/2022 18:13:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.28 on epoch=29
06/05/2022 18:13:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.25 on epoch=32
06/05/2022 18:14:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/05/2022 18:14:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=37
06/05/2022 18:14:10 - INFO - __main__ - Global step 150 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=37
06/05/2022 18:14:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=39
06/05/2022 18:14:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/05/2022 18:14:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.22 on epoch=44
06/05/2022 18:14:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=47
06/05/2022 18:14:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.24 on epoch=49
06/05/2022 18:14:35 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.45718194254445965 on epoch=49
06/05/2022 18:14:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.45718194254445965 on epoch=49, global_step=200
06/05/2022 18:14:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.27 on epoch=52
06/05/2022 18:14:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.23 on epoch=54
06/05/2022 18:14:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.19 on epoch=57
06/05/2022 18:14:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.22 on epoch=59
06/05/2022 18:14:57 - INFO - __main__ - Step 250 Global step 250 Train loss 0.21 on epoch=62
06/05/2022 18:15:00 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.39756367663344405 on epoch=62
06/05/2022 18:15:04 - INFO - __main__ - Step 260 Global step 260 Train loss 0.23 on epoch=64
06/05/2022 18:15:09 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/05/2022 18:15:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.21 on epoch=69
06/05/2022 18:15:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.21 on epoch=72
06/05/2022 18:15:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/05/2022 18:15:25 - INFO - __main__ - Global step 300 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=74
06/05/2022 18:15:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=77
06/05/2022 18:15:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/05/2022 18:15:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/05/2022 18:15:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/05/2022 18:15:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=87
06/05/2022 18:15:50 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 18:15:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/05/2022 18:15:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/05/2022 18:16:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
06/05/2022 18:16:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/05/2022 18:16:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/05/2022 18:16:15 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=99
06/05/2022 18:16:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/05/2022 18:16:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/05/2022 18:16:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/05/2022 18:16:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/05/2022 18:16:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/05/2022 18:16:41 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 18:16:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/05/2022 18:16:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/05/2022 18:16:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/05/2022 18:16:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=122
06/05/2022 18:17:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/05/2022 18:17:06 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=124
06/05/2022 18:17:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=127
06/05/2022 18:17:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
06/05/2022 18:17:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/05/2022 18:17:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/05/2022 18:17:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=137
06/05/2022 18:17:32 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=137
06/05/2022 18:17:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/05/2022 18:17:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/05/2022 18:17:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/05/2022 18:17:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/05/2022 18:17:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=149
06/05/2022 18:17:57 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=149
06/05/2022 18:18:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/05/2022 18:18:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/05/2022 18:18:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/05/2022 18:18:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/05/2022 18:18:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/05/2022 18:18:23 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=162
06/05/2022 18:18:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/05/2022 18:18:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/05/2022 18:18:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/05/2022 18:18:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/05/2022 18:18:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/05/2022 18:18:48 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 18:18:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=177
06/05/2022 18:18:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/05/2022 18:19:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/05/2022 18:19:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/05/2022 18:19:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=187
06/05/2022 18:19:14 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.34299516908212563 on epoch=187
06/05/2022 18:19:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/05/2022 18:19:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=192
06/05/2022 18:19:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/05/2022 18:19:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/05/2022 18:19:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=199
06/05/2022 18:19:39 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.40566959921798634 on epoch=199
06/05/2022 18:19:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=202
06/05/2022 18:19:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=204
06/05/2022 18:19:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/05/2022 18:19:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/05/2022 18:20:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/05/2022 18:20:05 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.4832395400048935 on epoch=212
06/05/2022 18:20:05 - INFO - __main__ - Saving model with best Classification-F1: 0.45718194254445965 -> 0.4832395400048935 on epoch=212, global_step=850
06/05/2022 18:20:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/05/2022 18:20:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=217
06/05/2022 18:20:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=219
06/05/2022 18:20:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=222
06/05/2022 18:20:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/05/2022 18:20:31 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.3333333333333333 on epoch=224
06/05/2022 18:20:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=227
06/05/2022 18:20:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/05/2022 18:20:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=232
06/05/2022 18:20:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/05/2022 18:20:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/05/2022 18:20:57 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.3671451355661882 on epoch=237
06/05/2022 18:21:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=239
06/05/2022 18:21:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=242
06/05/2022 18:21:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=244
06/05/2022 18:21:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=247
06/05/2022 18:21:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=249
06/05/2022 18:21:23 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.3511520737327189 on epoch=249
06/05/2022 18:21:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/05/2022 18:21:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=254
06/05/2022 18:21:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
06/05/2022 18:21:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
06/05/2022 18:21:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=262
06/05/2022 18:21:49 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.4947797300738477 on epoch=262
06/05/2022 18:21:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4832395400048935 -> 0.4947797300738477 on epoch=262, global_step=1050
06/05/2022 18:21:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=264
06/05/2022 18:21:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=267
06/05/2022 18:22:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/05/2022 18:22:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=272
06/05/2022 18:22:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=274
06/05/2022 18:22:15 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.3671451355661882 on epoch=274
06/05/2022 18:22:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=277
06/05/2022 18:22:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=279
06/05/2022 18:22:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=282
06/05/2022 18:22:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=284
06/05/2022 18:22:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=287
06/05/2022 18:22:40 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.4817813765182186 on epoch=287
06/05/2022 18:22:45 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=289
06/05/2022 18:22:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=292
06/05/2022 18:22:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/05/2022 18:22:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
06/05/2022 18:23:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=299
06/05/2022 18:23:06 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.5270935960591133 on epoch=299
06/05/2022 18:23:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4947797300738477 -> 0.5270935960591133 on epoch=299, global_step=1200
06/05/2022 18:23:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=302
06/05/2022 18:23:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/05/2022 18:23:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=307
06/05/2022 18:23:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=309
06/05/2022 18:23:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=312
06/05/2022 18:23:33 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.45718194254445965 on epoch=312
06/05/2022 18:23:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=314
06/05/2022 18:23:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/05/2022 18:23:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=319
06/05/2022 18:23:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/05/2022 18:23:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/05/2022 18:23:59 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5145583557621727 on epoch=324
06/05/2022 18:24:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=327
06/05/2022 18:24:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/05/2022 18:24:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=332
06/05/2022 18:24:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=334
06/05/2022 18:24:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=337
06/05/2022 18:24:25 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.5249204665959704 on epoch=337
06/05/2022 18:24:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/05/2022 18:24:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
06/05/2022 18:24:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
06/05/2022 18:24:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/05/2022 18:24:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=349
06/05/2022 18:24:52 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5536037199690003 on epoch=349
06/05/2022 18:24:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5270935960591133 -> 0.5536037199690003 on epoch=349, global_step=1400
06/05/2022 18:24:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=352
06/05/2022 18:25:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/05/2022 18:25:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/05/2022 18:25:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/05/2022 18:25:15 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=362
06/05/2022 18:25:19 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.5307917888563051 on epoch=362
06/05/2022 18:25:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/05/2022 18:25:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/05/2022 18:25:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=369
06/05/2022 18:25:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/05/2022 18:25:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/05/2022 18:25:46 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.5696139476961395 on epoch=374
06/05/2022 18:25:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5536037199690003 -> 0.5696139476961395 on epoch=374, global_step=1500
06/05/2022 18:25:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/05/2022 18:25:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/05/2022 18:26:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/05/2022 18:26:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=384
06/05/2022 18:26:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/05/2022 18:26:12 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.46880856760374834 on epoch=387
06/05/2022 18:26:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/05/2022 18:26:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/05/2022 18:26:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/05/2022 18:26:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/05/2022 18:26:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=399
06/05/2022 18:26:38 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.5536037199690003 on epoch=399
06/05/2022 18:26:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/05/2022 18:26:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/05/2022 18:26:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/05/2022 18:26:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/05/2022 18:27:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/05/2022 18:27:05 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.5458771715194519 on epoch=412
06/05/2022 18:27:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/05/2022 18:27:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/05/2022 18:27:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/05/2022 18:27:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/05/2022 18:27:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/05/2022 18:27:31 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.5465587044534412 on epoch=424
06/05/2022 18:27:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/05/2022 18:27:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/05/2022 18:27:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/05/2022 18:27:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/05/2022 18:27:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/05/2022 18:27:58 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.5270935960591133 on epoch=437
06/05/2022 18:28:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/05/2022 18:28:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/05/2022 18:28:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=444
06/05/2022 18:28:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/05/2022 18:28:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/05/2022 18:28:24 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.5458771715194519 on epoch=449
06/05/2022 18:28:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/05/2022 18:28:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/05/2022 18:28:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/05/2022 18:28:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/05/2022 18:28:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/05/2022 18:28:50 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.5620723362658846 on epoch=462
06/05/2022 18:28:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/05/2022 18:28:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/05/2022 18:29:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/05/2022 18:29:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/05/2022 18:29:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/05/2022 18:29:16 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.5696139476961395 on epoch=474
06/05/2022 18:29:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/05/2022 18:29:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/05/2022 18:29:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/05/2022 18:29:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/05/2022 18:29:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/05/2022 18:29:42 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.5307917888563051 on epoch=487
06/05/2022 18:29:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/05/2022 18:29:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/05/2022 18:29:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/05/2022 18:30:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/05/2022 18:30:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/05/2022 18:30:08 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.5873015873015872 on epoch=499
06/05/2022 18:30:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5696139476961395 -> 0.5873015873015872 on epoch=499, global_step=2000
06/05/2022 18:30:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/05/2022 18:30:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/05/2022 18:30:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/05/2022 18:30:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/05/2022 18:30:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/05/2022 18:30:34 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5405128205128205 on epoch=512
06/05/2022 18:30:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/05/2022 18:30:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/05/2022 18:30:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/05/2022 18:30:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/05/2022 18:30:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/05/2022 18:31:00 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5330817610062892 on epoch=524
06/05/2022 18:31:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/05/2022 18:31:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/05/2022 18:31:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/05/2022 18:31:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/05/2022 18:31:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/05/2022 18:31:26 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.5755342667649226 on epoch=537
06/05/2022 18:31:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/05/2022 18:31:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/05/2022 18:31:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/05/2022 18:31:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/05/2022 18:31:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/05/2022 18:31:51 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5273745861981156 on epoch=549
06/05/2022 18:31:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/05/2022 18:32:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/05/2022 18:32:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/05/2022 18:32:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/05/2022 18:32:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/05/2022 18:32:17 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5 on epoch=562
06/05/2022 18:32:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/05/2022 18:32:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/05/2022 18:32:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/05/2022 18:32:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/05/2022 18:32:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/05/2022 18:32:43 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.5058530510585305 on epoch=574
06/05/2022 18:32:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/05/2022 18:32:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/05/2022 18:32:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/05/2022 18:33:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/05/2022 18:33:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/05/2022 18:33:08 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.5330817610062892 on epoch=587
06/05/2022 18:33:13 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/05/2022 18:33:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/05/2022 18:33:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=594
06/05/2022 18:33:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/05/2022 18:33:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/05/2022 18:33:34 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.537733499377335 on epoch=599
06/05/2022 18:33:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/05/2022 18:33:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/05/2022 18:33:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/05/2022 18:33:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/05/2022 18:33:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/05/2022 18:34:00 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.5555555555555556 on epoch=612
06/05/2022 18:34:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/05/2022 18:34:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/05/2022 18:34:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/05/2022 18:34:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/05/2022 18:34:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/05/2022 18:34:26 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.5555555555555556 on epoch=624
06/05/2022 18:34:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/05/2022 18:34:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/05/2022 18:34:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/05/2022 18:34:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/05/2022 18:34:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/05/2022 18:34:51 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5835835835835835 on epoch=637
06/05/2022 18:34:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/05/2022 18:35:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/05/2022 18:35:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/05/2022 18:35:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/05/2022 18:35:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/05/2022 18:35:18 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5155067155067155 on epoch=649
06/05/2022 18:35:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/05/2022 18:35:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/05/2022 18:35:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/05/2022 18:35:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/05/2022 18:35:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/05/2022 18:35:44 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5780219780219781 on epoch=662
06/05/2022 18:35:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/05/2022 18:35:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/05/2022 18:35:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/05/2022 18:36:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/05/2022 18:36:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/05/2022 18:36:10 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5873015873015872 on epoch=674
06/05/2022 18:36:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/05/2022 18:36:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/05/2022 18:36:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/05/2022 18:36:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 18:36:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/05/2022 18:36:36 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5696139476961395 on epoch=687
06/05/2022 18:36:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=689
06/05/2022 18:36:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/05/2022 18:36:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/05/2022 18:36:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/05/2022 18:36:59 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/05/2022 18:37:02 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.49220246238030096 on epoch=699
06/05/2022 18:37:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/05/2022 18:37:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/05/2022 18:37:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 18:37:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/05/2022 18:37:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/05/2022 18:37:28 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5599694423223835 on epoch=712
06/05/2022 18:37:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/05/2022 18:37:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/05/2022 18:37:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/05/2022 18:37:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/05/2022 18:37:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/05/2022 18:37:53 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5730170496664195 on epoch=724
06/05/2022 18:37:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 18:38:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/05/2022 18:38:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/05/2022 18:38:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/05/2022 18:38:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 18:38:19 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5730170496664195 on epoch=737
06/05/2022 18:38:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/05/2022 18:38:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/05/2022 18:38:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/05/2022 18:38:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/05/2022 18:38:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/05/2022 18:38:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:38:43 - INFO - __main__ - Printing 3 examples
06/05/2022 18:38:43 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 18:38:43 - INFO - __main__ - ['refuted']
06/05/2022 18:38:43 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 18:38:43 - INFO - __main__ - ['refuted']
06/05/2022 18:38:43 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 18:38:43 - INFO - __main__ - ['refuted']
06/05/2022 18:38:43 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:38:43 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:38:43 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 18:38:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:38:43 - INFO - __main__ - Printing 3 examples
06/05/2022 18:38:43 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 18:38:43 - INFO - __main__ - ['refuted']
06/05/2022 18:38:43 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 18:38:43 - INFO - __main__ - ['refuted']
06/05/2022 18:38:43 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 18:38:43 - INFO - __main__ - ['refuted']
06/05/2022 18:38:43 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:38:43 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:38:43 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 18:38:45 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5730170496664195 on epoch=749
06/05/2022 18:38:45 - INFO - __main__ - save last model!
06/05/2022 18:38:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 18:38:45 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 18:38:45 - INFO - __main__ - Printing 3 examples
06/05/2022 18:38:45 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 18:38:45 - INFO - __main__ - ['entailed']
06/05/2022 18:38:45 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 18:38:45 - INFO - __main__ - ['entailed']
06/05/2022 18:38:45 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 18:38:45 - INFO - __main__ - ['entailed']
06/05/2022 18:38:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:39:02 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 18:39:02 - INFO - __main__ - task name: tab_fact
06/05/2022 18:39:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 18:39:03 - INFO - __main__ - Starting training!
06/05/2022 18:39:10 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:39:23 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 18:48:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_13_0.5_8_predictions.txt
06/05/2022 18:48:15 - INFO - __main__ - Classification-F1 on test data: 0.4913
06/05/2022 18:48:15 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.5, bsz=8, dev_performance=0.5873015873015872, test_performance=0.4913107453734413
06/05/2022 18:48:15 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.4, bsz=8 ...
06/05/2022 18:48:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:48:16 - INFO - __main__ - Printing 3 examples
06/05/2022 18:48:16 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 18:48:16 - INFO - __main__ - ['refuted']
06/05/2022 18:48:16 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 18:48:16 - INFO - __main__ - ['refuted']
06/05/2022 18:48:16 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 18:48:16 - INFO - __main__ - ['refuted']
06/05/2022 18:48:16 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:48:17 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:48:17 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 18:48:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 18:48:17 - INFO - __main__ - Printing 3 examples
06/05/2022 18:48:17 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 18:48:17 - INFO - __main__ - ['refuted']
06/05/2022 18:48:17 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 18:48:17 - INFO - __main__ - ['refuted']
06/05/2022 18:48:17 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 18:48:17 - INFO - __main__ - ['refuted']
06/05/2022 18:48:17 - INFO - __main__ - Tokenizing Input ...
06/05/2022 18:48:17 - INFO - __main__ - Tokenizing Output ...
06/05/2022 18:48:17 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 18:48:33 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 18:48:33 - INFO - __main__ - task name: tab_fact
06/05/2022 18:48:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 18:48:34 - INFO - __main__ - Starting training!
06/05/2022 18:48:39 - INFO - __main__ - Step 10 Global step 10 Train loss 4.96 on epoch=2
06/05/2022 18:48:43 - INFO - __main__ - Step 20 Global step 20 Train loss 1.91 on epoch=4
06/05/2022 18:48:48 - INFO - __main__ - Step 30 Global step 30 Train loss 0.85 on epoch=7
06/05/2022 18:48:52 - INFO - __main__ - Step 40 Global step 40 Train loss 0.57 on epoch=9
06/05/2022 18:48:57 - INFO - __main__ - Step 50 Global step 50 Train loss 0.45 on epoch=12
06/05/2022 18:49:00 - INFO - __main__ - Global step 50 Train loss 1.75 Classification-F1 0.3333333333333333 on epoch=12
06/05/2022 18:49:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/05/2022 18:49:04 - INFO - __main__ - Step 60 Global step 60 Train loss 0.39 on epoch=14
06/05/2022 18:49:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.34 on epoch=17
06/05/2022 18:49:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.33 on epoch=19
06/05/2022 18:49:18 - INFO - __main__ - Step 90 Global step 90 Train loss 0.28 on epoch=22
06/05/2022 18:49:22 - INFO - __main__ - Step 100 Global step 100 Train loss 0.28 on epoch=24
06/05/2022 18:49:25 - INFO - __main__ - Global step 100 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 18:49:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.29 on epoch=27
06/05/2022 18:49:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=29
06/05/2022 18:49:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.26 on epoch=32
06/05/2022 18:49:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/05/2022 18:49:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.27 on epoch=37
06/05/2022 18:49:50 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=37
06/05/2022 18:49:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=39
06/05/2022 18:49:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.25 on epoch=42
06/05/2022 18:50:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=44
06/05/2022 18:50:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=47
06/05/2022 18:50:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.23 on epoch=49
06/05/2022 18:50:16 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 18:50:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/05/2022 18:50:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=54
06/05/2022 18:50:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.22 on epoch=57
06/05/2022 18:50:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.22 on epoch=59
06/05/2022 18:50:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.20 on epoch=62
06/05/2022 18:50:41 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 18:50:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/05/2022 18:50:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/05/2022 18:50:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=69
06/05/2022 18:50:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/05/2022 18:51:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/05/2022 18:51:06 - INFO - __main__ - Global step 300 Train loss 0.22 Classification-F1 0.36374269005847953 on epoch=74
06/05/2022 18:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.36374269005847953 on epoch=74, global_step=300
06/05/2022 18:51:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=77
06/05/2022 18:51:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/05/2022 18:51:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/05/2022 18:51:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/05/2022 18:51:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/05/2022 18:51:31 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.45705196182396607 on epoch=87
06/05/2022 18:51:31 - INFO - __main__ - Saving model with best Classification-F1: 0.36374269005847953 -> 0.45705196182396607 on epoch=87, global_step=350
06/05/2022 18:51:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/05/2022 18:51:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/05/2022 18:51:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/05/2022 18:51:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/05/2022 18:51:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/05/2022 18:51:57 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.3671451355661882 on epoch=99
06/05/2022 18:52:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/05/2022 18:52:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/05/2022 18:52:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/05/2022 18:52:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/05/2022 18:52:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/05/2022 18:52:22 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.39756367663344405 on epoch=112
06/05/2022 18:52:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/05/2022 18:52:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/05/2022 18:52:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/05/2022 18:52:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/05/2022 18:52:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/05/2022 18:52:47 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.25290350591555416 on epoch=124
06/05/2022 18:52:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/05/2022 18:52:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/05/2022 18:53:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/05/2022 18:53:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/05/2022 18:53:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/05/2022 18:53:12 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.3554409236059936 on epoch=137
06/05/2022 18:53:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=139
06/05/2022 18:53:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/05/2022 18:53:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/05/2022 18:53:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=147
06/05/2022 18:53:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=149
06/05/2022 18:53:38 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.3671451355661882 on epoch=149
06/05/2022 18:53:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/05/2022 18:53:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/05/2022 18:53:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=157
06/05/2022 18:53:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/05/2022 18:54:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=162
06/05/2022 18:54:03 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.19253048780487803 on epoch=162
06/05/2022 18:54:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/05/2022 18:54:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/05/2022 18:54:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/05/2022 18:54:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/05/2022 18:54:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/05/2022 18:54:28 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.22222222222222224 on epoch=174
06/05/2022 18:54:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/05/2022 18:54:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/05/2022 18:54:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/05/2022 18:54:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/05/2022 18:54:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/05/2022 18:54:54 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.15730337078651685 on epoch=187
06/05/2022 18:54:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=189
06/05/2022 18:55:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/05/2022 18:55:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/05/2022 18:55:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=197
06/05/2022 18:55:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=199
06/05/2022 18:55:19 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.3816425120772947 on epoch=199
06/05/2022 18:55:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=202
06/05/2022 18:55:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/05/2022 18:55:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/05/2022 18:55:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=209
06/05/2022 18:55:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/05/2022 18:55:44 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.3816425120772947 on epoch=212
06/05/2022 18:55:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/05/2022 18:55:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=217
06/05/2022 18:55:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=219
06/05/2022 18:56:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=222
06/05/2022 18:56:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/05/2022 18:56:10 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.3671451355661882 on epoch=224
06/05/2022 18:56:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=227
06/05/2022 18:56:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=229
06/05/2022 18:56:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=232
06/05/2022 18:56:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/05/2022 18:56:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/05/2022 18:56:35 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.40116959064327484 on epoch=237
06/05/2022 18:56:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=239
06/05/2022 18:56:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=242
06/05/2022 18:56:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/05/2022 18:56:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=247
06/05/2022 18:56:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/05/2022 18:57:01 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.15076923076923077 on epoch=249
06/05/2022 18:57:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/05/2022 18:57:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=254
06/05/2022 18:57:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=257
06/05/2022 18:57:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=259
06/05/2022 18:57:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/05/2022 18:57:27 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.13015873015873017 on epoch=262
06/05/2022 18:57:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=264
06/05/2022 18:57:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=267
06/05/2022 18:57:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/05/2022 18:57:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=272
06/05/2022 18:57:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
06/05/2022 18:57:52 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.2378771551724138 on epoch=274
06/05/2022 18:57:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/05/2022 18:58:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=279
06/05/2022 18:58:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=282
06/05/2022 18:58:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=284
06/05/2022 18:58:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=287
06/05/2022 18:58:17 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.2196796338672769 on epoch=287
06/05/2022 18:58:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=289
06/05/2022 18:58:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=292
06/05/2022 18:58:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=294
06/05/2022 18:58:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=297
06/05/2022 18:58:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=299
06/05/2022 18:58:43 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.21521942110177406 on epoch=299
06/05/2022 18:58:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=302
06/05/2022 18:58:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=304
06/05/2022 18:58:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=307
06/05/2022 18:59:01 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/05/2022 18:59:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/05/2022 18:59:08 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.37798791699500917 on epoch=312
06/05/2022 18:59:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=314
06/05/2022 18:59:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/05/2022 18:59:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=319
06/05/2022 18:59:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=322
06/05/2022 18:59:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=324
06/05/2022 18:59:33 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.3818181818181818 on epoch=324
06/05/2022 18:59:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=327
06/05/2022 18:59:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=329
06/05/2022 18:59:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=332
06/05/2022 18:59:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=334
06/05/2022 18:59:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=337
06/05/2022 18:59:59 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.44209215442092153 on epoch=337
06/05/2022 19:00:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=339
06/05/2022 19:00:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
06/05/2022 19:00:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=344
06/05/2022 19:00:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=347
06/05/2022 19:00:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/05/2022 19:00:24 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.24449784973437894 on epoch=349
06/05/2022 19:00:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/05/2022 19:00:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/05/2022 19:00:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/05/2022 19:00:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/05/2022 19:00:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=362
06/05/2022 19:00:50 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.35202020202020207 on epoch=362
06/05/2022 19:00:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/05/2022 19:00:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/05/2022 19:01:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
06/05/2022 19:01:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=372
06/05/2022 19:01:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/05/2022 19:01:15 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.30008354218880534 on epoch=374
06/05/2022 19:01:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/05/2022 19:01:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=379
06/05/2022 19:01:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=382
06/05/2022 19:01:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=384
06/05/2022 19:01:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=387
06/05/2022 19:01:41 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.290687989338664 on epoch=387
06/05/2022 19:01:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=389
06/05/2022 19:01:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=392
06/05/2022 19:01:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=394
06/05/2022 19:01:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=397
06/05/2022 19:02:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
06/05/2022 19:02:06 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.44976664210267747 on epoch=399
06/05/2022 19:02:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/05/2022 19:02:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=404
06/05/2022 19:02:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/05/2022 19:02:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=409
06/05/2022 19:02:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=412
06/05/2022 19:02:32 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.24993597951344432 on epoch=412
06/05/2022 19:02:36 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/05/2022 19:02:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/05/2022 19:02:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=419
06/05/2022 19:02:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/05/2022 19:02:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
06/05/2022 19:02:57 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.48424908424908425 on epoch=424
06/05/2022 19:02:57 - INFO - __main__ - Saving model with best Classification-F1: 0.45705196182396607 -> 0.48424908424908425 on epoch=424, global_step=1700
06/05/2022 19:03:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=427
06/05/2022 19:03:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=429
06/05/2022 19:03:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/05/2022 19:03:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
06/05/2022 19:03:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/05/2022 19:03:23 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.31903017617303336 on epoch=437
06/05/2022 19:03:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
06/05/2022 19:03:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/05/2022 19:03:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/05/2022 19:03:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/05/2022 19:03:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=449
06/05/2022 19:03:48 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.32993379853283233 on epoch=449
06/05/2022 19:03:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=452
06/05/2022 19:03:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/05/2022 19:04:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/05/2022 19:04:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/05/2022 19:04:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/05/2022 19:04:13 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.2210953346855984 on epoch=462
06/05/2022 19:04:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/05/2022 19:04:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/05/2022 19:04:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/05/2022 19:04:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/05/2022 19:04:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/05/2022 19:04:39 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.45705196182396607 on epoch=474
06/05/2022 19:04:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/05/2022 19:04:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/05/2022 19:04:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=482
06/05/2022 19:04:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/05/2022 19:05:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/05/2022 19:05:04 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.25054945054945055 on epoch=487
06/05/2022 19:05:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/05/2022 19:05:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=492
06/05/2022 19:05:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/05/2022 19:05:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/05/2022 19:05:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/05/2022 19:05:30 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.45299145299145294 on epoch=499
06/05/2022 19:05:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/05/2022 19:05:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/05/2022 19:05:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=507
06/05/2022 19:05:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/05/2022 19:05:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/05/2022 19:05:55 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.3727353727353727 on epoch=512
06/05/2022 19:05:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/05/2022 19:06:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/05/2022 19:06:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
06/05/2022 19:06:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/05/2022 19:06:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/05/2022 19:06:20 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.51417004048583 on epoch=524
06/05/2022 19:06:20 - INFO - __main__ - Saving model with best Classification-F1: 0.48424908424908425 -> 0.51417004048583 on epoch=524, global_step=2100
06/05/2022 19:06:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/05/2022 19:06:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/05/2022 19:06:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/05/2022 19:06:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/05/2022 19:06:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/05/2022 19:06:46 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.3092592592592593 on epoch=537
06/05/2022 19:06:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/05/2022 19:06:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/05/2022 19:06:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/05/2022 19:07:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/05/2022 19:07:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/05/2022 19:07:11 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.30460208492245106 on epoch=549
06/05/2022 19:07:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=552
06/05/2022 19:07:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/05/2022 19:07:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/05/2022 19:07:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/05/2022 19:07:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/05/2022 19:07:36 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.22777777777777777 on epoch=562
06/05/2022 19:07:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/05/2022 19:07:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/05/2022 19:07:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/05/2022 19:07:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/05/2022 19:07:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/05/2022 19:08:01 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.30476190476190473 on epoch=574
06/05/2022 19:08:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/05/2022 19:08:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/05/2022 19:08:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/05/2022 19:08:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/05/2022 19:08:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/05/2022 19:08:27 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.21589421314480234 on epoch=587
06/05/2022 19:08:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/05/2022 19:08:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/05/2022 19:08:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/05/2022 19:08:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/05/2022 19:08:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/05/2022 19:08:52 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.25537414965986394 on epoch=599
06/05/2022 19:08:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/05/2022 19:09:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/05/2022 19:09:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/05/2022 19:09:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/05/2022 19:09:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/05/2022 19:09:18 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.2657407407407407 on epoch=612
06/05/2022 19:09:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/05/2022 19:09:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/05/2022 19:09:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/05/2022 19:09:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/05/2022 19:09:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/05/2022 19:09:43 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.45705196182396607 on epoch=624
06/05/2022 19:09:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/05/2022 19:09:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/05/2022 19:09:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/05/2022 19:10:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/05/2022 19:10:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/05/2022 19:10:09 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.2632485426603074 on epoch=637
06/05/2022 19:10:13 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/05/2022 19:10:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/05/2022 19:10:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/05/2022 19:10:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/05/2022 19:10:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/05/2022 19:10:34 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5076923076923077 on epoch=649
06/05/2022 19:10:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/05/2022 19:10:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/05/2022 19:10:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/05/2022 19:10:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/05/2022 19:10:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/05/2022 19:11:00 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5238095238095238 on epoch=662
06/05/2022 19:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.51417004048583 -> 0.5238095238095238 on epoch=662, global_step=2650
06/05/2022 19:11:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/05/2022 19:11:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/05/2022 19:11:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/05/2022 19:11:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/05/2022 19:11:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/05/2022 19:11:26 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.4947797300738477 on epoch=674
06/05/2022 19:11:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/05/2022 19:11:35 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/05/2022 19:11:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/05/2022 19:11:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/05/2022 19:11:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/05/2022 19:11:52 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.32993379853283233 on epoch=687
06/05/2022 19:11:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/05/2022 19:12:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/05/2022 19:12:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/05/2022 19:12:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/05/2022 19:12:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/05/2022 19:12:18 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.473972602739726 on epoch=699
06/05/2022 19:12:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/05/2022 19:12:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/05/2022 19:12:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 19:12:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/05/2022 19:12:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/05/2022 19:12:43 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.49556650246305417 on epoch=712
06/05/2022 19:12:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/05/2022 19:12:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/05/2022 19:12:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/05/2022 19:13:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/05/2022 19:13:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/05/2022 19:13:09 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.48424908424908425 on epoch=724
06/05/2022 19:13:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 19:13:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/05/2022 19:13:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/05/2022 19:13:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/05/2022 19:13:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/05/2022 19:13:34 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.2846270928462709 on epoch=737
06/05/2022 19:13:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/05/2022 19:13:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/05/2022 19:13:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/05/2022 19:13:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/05/2022 19:13:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/05/2022 19:13:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:13:58 - INFO - __main__ - Printing 3 examples
06/05/2022 19:13:58 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 19:13:58 - INFO - __main__ - ['refuted']
06/05/2022 19:13:58 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 19:13:58 - INFO - __main__ - ['refuted']
06/05/2022 19:13:58 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 19:13:58 - INFO - __main__ - ['refuted']
06/05/2022 19:13:58 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:13:58 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:13:58 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 19:13:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:13:58 - INFO - __main__ - Printing 3 examples
06/05/2022 19:13:58 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 19:13:58 - INFO - __main__ - ['refuted']
06/05/2022 19:13:58 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 19:13:58 - INFO - __main__ - ['refuted']
06/05/2022 19:13:58 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 19:13:58 - INFO - __main__ - ['refuted']
06/05/2022 19:13:58 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:13:58 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:13:59 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 19:14:00 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.4832395400048935 on epoch=749
06/05/2022 19:14:00 - INFO - __main__ - save last model!
06/05/2022 19:14:00 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 19:14:00 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 19:14:00 - INFO - __main__ - Printing 3 examples
06/05/2022 19:14:00 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 19:14:00 - INFO - __main__ - ['entailed']
06/05/2022 19:14:00 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 19:14:00 - INFO - __main__ - ['entailed']
06/05/2022 19:14:00 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 19:14:00 - INFO - __main__ - ['entailed']
06/05/2022 19:14:00 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:14:13 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 19:14:13 - INFO - __main__ - task name: tab_fact
06/05/2022 19:14:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:14:14 - INFO - __main__ - Starting training!
06/05/2022 19:14:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:14:37 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 19:23:10 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_13_0.4_8_predictions.txt
06/05/2022 19:23:10 - INFO - __main__ - Classification-F1 on test data: 0.1661
06/05/2022 19:23:11 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.4, bsz=8, dev_performance=0.5238095238095238, test_performance=0.16608806864469905
06/05/2022 19:23:11 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.3, bsz=8 ...
06/05/2022 19:23:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:23:12 - INFO - __main__ - Printing 3 examples
06/05/2022 19:23:12 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 19:23:12 - INFO - __main__ - ['refuted']
06/05/2022 19:23:12 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 19:23:12 - INFO - __main__ - ['refuted']
06/05/2022 19:23:12 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 19:23:12 - INFO - __main__ - ['refuted']
06/05/2022 19:23:12 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:23:12 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:23:12 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 19:23:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:23:12 - INFO - __main__ - Printing 3 examples
06/05/2022 19:23:12 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 19:23:12 - INFO - __main__ - ['refuted']
06/05/2022 19:23:12 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 19:23:12 - INFO - __main__ - ['refuted']
06/05/2022 19:23:12 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 19:23:12 - INFO - __main__ - ['refuted']
06/05/2022 19:23:12 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:23:12 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:23:12 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 19:23:31 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 19:23:31 - INFO - __main__ - task name: tab_fact
06/05/2022 19:23:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:23:32 - INFO - __main__ - Starting training!
06/05/2022 19:23:36 - INFO - __main__ - Step 10 Global step 10 Train loss 5.14 on epoch=2
06/05/2022 19:23:41 - INFO - __main__ - Step 20 Global step 20 Train loss 2.59 on epoch=4
06/05/2022 19:23:45 - INFO - __main__ - Step 30 Global step 30 Train loss 1.12 on epoch=7
06/05/2022 19:23:50 - INFO - __main__ - Step 40 Global step 40 Train loss 0.63 on epoch=9
06/05/2022 19:23:55 - INFO - __main__ - Step 50 Global step 50 Train loss 0.60 on epoch=12
06/05/2022 19:23:57 - INFO - __main__ - Global step 50 Train loss 2.02 Classification-F1 0.2045454545454545 on epoch=12
06/05/2022 19:23:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2045454545454545 on epoch=12, global_step=50
06/05/2022 19:24:02 - INFO - __main__ - Step 60 Global step 60 Train loss 0.46 on epoch=14
06/05/2022 19:24:07 - INFO - __main__ - Step 70 Global step 70 Train loss 0.38 on epoch=17
06/05/2022 19:24:11 - INFO - __main__ - Step 80 Global step 80 Train loss 0.35 on epoch=19
06/05/2022 19:24:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.29 on epoch=22
06/05/2022 19:24:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=24
06/05/2022 19:24:23 - INFO - __main__ - Global step 100 Train loss 0.36 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 19:24:23 - INFO - __main__ - Saving model with best Classification-F1: 0.2045454545454545 -> 0.3333333333333333 on epoch=24, global_step=100
06/05/2022 19:24:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.30 on epoch=27
06/05/2022 19:24:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.24 on epoch=29
06/05/2022 19:24:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.27 on epoch=32
06/05/2022 19:24:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=34
06/05/2022 19:24:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=37
06/05/2022 19:24:48 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=37
06/05/2022 19:24:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=39
06/05/2022 19:24:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/05/2022 19:25:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/05/2022 19:25:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.23 on epoch=47
06/05/2022 19:25:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.28 on epoch=49
06/05/2022 19:25:13 - INFO - __main__ - Global step 200 Train loss 0.26 Classification-F1 0.46218487394957986 on epoch=49
06/05/2022 19:25:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.46218487394957986 on epoch=49, global_step=200
06/05/2022 19:25:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=52
06/05/2022 19:25:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=54
06/05/2022 19:25:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=57
06/05/2022 19:25:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/05/2022 19:25:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=62
06/05/2022 19:25:39 - INFO - __main__ - Global step 250 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 19:25:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/05/2022 19:25:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/05/2022 19:25:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/05/2022 19:25:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.22 on epoch=72
06/05/2022 19:26:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/05/2022 19:26:04 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=74
06/05/2022 19:26:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/05/2022 19:26:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/05/2022 19:26:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/05/2022 19:26:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/05/2022 19:26:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=87
06/05/2022 19:26:30 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 19:26:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=89
06/05/2022 19:26:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=92
06/05/2022 19:26:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/05/2022 19:26:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=97
06/05/2022 19:26:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/05/2022 19:26:55 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.45705196182396607 on epoch=99
06/05/2022 19:27:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=102
06/05/2022 19:27:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/05/2022 19:27:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=107
06/05/2022 19:27:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/05/2022 19:27:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/05/2022 19:27:21 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 19:27:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/05/2022 19:27:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/05/2022 19:27:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/05/2022 19:27:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
06/05/2022 19:27:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/05/2022 19:27:46 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=124
06/05/2022 19:27:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/05/2022 19:27:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/05/2022 19:28:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/05/2022 19:28:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=134
06/05/2022 19:28:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/05/2022 19:28:12 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=137
06/05/2022 19:28:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=139
06/05/2022 19:28:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/05/2022 19:28:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/05/2022 19:28:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/05/2022 19:28:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/05/2022 19:28:38 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=149
06/05/2022 19:28:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/05/2022 19:28:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/05/2022 19:28:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/05/2022 19:28:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=159
06/05/2022 19:29:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=162
06/05/2022 19:29:03 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.40116959064327484 on epoch=162
06/05/2022 19:29:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/05/2022 19:29:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=167
06/05/2022 19:29:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/05/2022 19:29:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/05/2022 19:29:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=174
06/05/2022 19:29:28 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 19:29:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/05/2022 19:29:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/05/2022 19:29:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=182
06/05/2022 19:29:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/05/2022 19:29:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/05/2022 19:29:54 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.39756367663344405 on epoch=187
06/05/2022 19:29:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
06/05/2022 19:30:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/05/2022 19:30:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=194
06/05/2022 19:30:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/05/2022 19:30:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/05/2022 19:30:19 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.39756367663344405 on epoch=199
06/05/2022 19:30:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=202
06/05/2022 19:30:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/05/2022 19:30:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/05/2022 19:30:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/05/2022 19:30:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/05/2022 19:30:44 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.4079058031959629 on epoch=212
06/05/2022 19:30:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/05/2022 19:30:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/05/2022 19:30:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=219
06/05/2022 19:31:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=222
06/05/2022 19:31:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=224
06/05/2022 19:31:10 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=224
06/05/2022 19:31:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/05/2022 19:31:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=229
06/05/2022 19:31:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=232
06/05/2022 19:31:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
06/05/2022 19:31:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=237
06/05/2022 19:31:35 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.47813194959229055 on epoch=237
06/05/2022 19:31:35 - INFO - __main__ - Saving model with best Classification-F1: 0.46218487394957986 -> 0.47813194959229055 on epoch=237, global_step=950
06/05/2022 19:31:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=239
06/05/2022 19:31:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=242
06/05/2022 19:31:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/05/2022 19:31:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=247
06/05/2022 19:31:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=249
06/05/2022 19:32:01 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.3333333333333333 on epoch=249
06/05/2022 19:32:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=252
06/05/2022 19:32:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=254
06/05/2022 19:32:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/05/2022 19:32:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=259
06/05/2022 19:32:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=262
06/05/2022 19:32:26 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.47885474126608885 on epoch=262
06/05/2022 19:32:26 - INFO - __main__ - Saving model with best Classification-F1: 0.47813194959229055 -> 0.47885474126608885 on epoch=262, global_step=1050
06/05/2022 19:32:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=264
06/05/2022 19:32:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=267
06/05/2022 19:32:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=269
06/05/2022 19:32:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=272
06/05/2022 19:32:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=274
06/05/2022 19:32:52 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.3333333333333333 on epoch=274
06/05/2022 19:32:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=277
06/05/2022 19:33:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
06/05/2022 19:33:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=282
06/05/2022 19:33:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=284
06/05/2022 19:33:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=287
06/05/2022 19:33:17 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.4181818181818182 on epoch=287
06/05/2022 19:33:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=289
06/05/2022 19:33:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=292
06/05/2022 19:33:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/05/2022 19:33:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=297
06/05/2022 19:33:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=299
06/05/2022 19:33:42 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.3333333333333333 on epoch=299
06/05/2022 19:33:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=302
06/05/2022 19:33:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/05/2022 19:33:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=307
06/05/2022 19:34:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=309
06/05/2022 19:34:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=312
06/05/2022 19:34:08 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.46867924528301885 on epoch=312
06/05/2022 19:34:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/05/2022 19:34:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=317
06/05/2022 19:34:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/05/2022 19:34:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=322
06/05/2022 19:34:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/05/2022 19:34:33 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.44379029997196523 on epoch=324
06/05/2022 19:34:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=327
06/05/2022 19:34:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=329
06/05/2022 19:34:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=332
06/05/2022 19:34:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/05/2022 19:34:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=337
06/05/2022 19:34:58 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.5058530510585305 on epoch=337
06/05/2022 19:34:58 - INFO - __main__ - Saving model with best Classification-F1: 0.47885474126608885 -> 0.5058530510585305 on epoch=337, global_step=1350
06/05/2022 19:35:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=339
06/05/2022 19:35:07 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=342
06/05/2022 19:35:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=344
06/05/2022 19:35:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
06/05/2022 19:35:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=349
06/05/2022 19:35:24 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.39756367663344405 on epoch=349
06/05/2022 19:35:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=352
06/05/2022 19:35:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=354
06/05/2022 19:35:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=357
06/05/2022 19:35:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=359
06/05/2022 19:35:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=362
06/05/2022 19:35:49 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.5413886829750433 on epoch=362
06/05/2022 19:35:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5058530510585305 -> 0.5413886829750433 on epoch=362, global_step=1450
06/05/2022 19:35:53 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=364
06/05/2022 19:35:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=367
06/05/2022 19:36:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=369
06/05/2022 19:36:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=372
06/05/2022 19:36:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/05/2022 19:36:14 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.3720213064199608 on epoch=374
06/05/2022 19:36:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/05/2022 19:36:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=379
06/05/2022 19:36:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=382
06/05/2022 19:36:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=384
06/05/2022 19:36:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=387
06/05/2022 19:36:39 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.48747093774218553 on epoch=387
06/05/2022 19:36:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=389
06/05/2022 19:36:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=392
06/05/2022 19:36:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=394
06/05/2022 19:36:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/05/2022 19:37:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=399
06/05/2022 19:37:04 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.5076923076923077 on epoch=399
06/05/2022 19:37:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/05/2022 19:37:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/05/2022 19:37:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=407
06/05/2022 19:37:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=409
06/05/2022 19:37:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=412
06/05/2022 19:37:30 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.5440923605993613 on epoch=412
06/05/2022 19:37:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5413886829750433 -> 0.5440923605993613 on epoch=412, global_step=1650
06/05/2022 19:37:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=414
06/05/2022 19:37:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/05/2022 19:37:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=419
06/05/2022 19:37:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/05/2022 19:37:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/05/2022 19:37:55 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.48747093774218553 on epoch=424
06/05/2022 19:38:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/05/2022 19:38:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=429
06/05/2022 19:38:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=432
06/05/2022 19:38:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/05/2022 19:38:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/05/2022 19:38:21 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.5607843137254902 on epoch=437
06/05/2022 19:38:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5440923605993613 -> 0.5607843137254902 on epoch=437, global_step=1750
06/05/2022 19:38:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=439
06/05/2022 19:38:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/05/2022 19:38:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/05/2022 19:38:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=447
06/05/2022 19:38:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/05/2022 19:38:47 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.4909862142099682 on epoch=449
06/05/2022 19:38:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/05/2022 19:38:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/05/2022 19:39:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/05/2022 19:39:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=459
06/05/2022 19:39:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/05/2022 19:39:13 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.5076923076923077 on epoch=462
06/05/2022 19:39:17 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=464
06/05/2022 19:39:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/05/2022 19:39:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=469
06/05/2022 19:39:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=472
06/05/2022 19:39:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=474
06/05/2022 19:39:38 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.48051948051948057 on epoch=474
06/05/2022 19:39:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/05/2022 19:39:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=479
06/05/2022 19:39:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/05/2022 19:39:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/05/2022 19:40:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=487
06/05/2022 19:40:04 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.5145583557621727 on epoch=487
06/05/2022 19:40:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=489
06/05/2022 19:40:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/05/2022 19:40:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/05/2022 19:40:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/05/2022 19:40:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/05/2022 19:40:31 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.45705196182396607 on epoch=499
06/05/2022 19:40:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=502
06/05/2022 19:40:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/05/2022 19:40:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/05/2022 19:40:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/05/2022 19:40:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/05/2022 19:40:56 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.45705196182396607 on epoch=512
06/05/2022 19:41:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/05/2022 19:41:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=517
06/05/2022 19:41:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=519
06/05/2022 19:41:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/05/2022 19:41:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/05/2022 19:41:22 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.5238095238095238 on epoch=524
06/05/2022 19:41:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/05/2022 19:41:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/05/2022 19:41:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/05/2022 19:41:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=534
06/05/2022 19:41:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/05/2022 19:41:47 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.4980392156862745 on epoch=537
06/05/2022 19:41:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/05/2022 19:41:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/05/2022 19:42:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=544
06/05/2022 19:42:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/05/2022 19:42:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=549
06/05/2022 19:42:13 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.47885474126608885 on epoch=549
06/05/2022 19:42:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=552
06/05/2022 19:42:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/05/2022 19:42:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/05/2022 19:42:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=559
06/05/2022 19:42:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/05/2022 19:42:39 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.5467643467643467 on epoch=562
06/05/2022 19:42:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/05/2022 19:42:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/05/2022 19:42:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/05/2022 19:42:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/05/2022 19:43:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/05/2022 19:43:05 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.5205373288555928 on epoch=574
06/05/2022 19:43:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/05/2022 19:43:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/05/2022 19:43:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/05/2022 19:43:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=584
06/05/2022 19:43:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
06/05/2022 19:43:30 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.5270935960591133 on epoch=587
06/05/2022 19:43:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/05/2022 19:43:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/05/2022 19:43:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/05/2022 19:43:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=597
06/05/2022 19:43:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/05/2022 19:43:55 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.46880856760374834 on epoch=599
06/05/2022 19:44:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/05/2022 19:44:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/05/2022 19:44:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/05/2022 19:44:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/05/2022 19:44:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/05/2022 19:44:20 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.45705196182396607 on epoch=612
06/05/2022 19:44:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/05/2022 19:44:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/05/2022 19:44:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/05/2022 19:44:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/05/2022 19:44:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/05/2022 19:44:46 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.500880503144654 on epoch=624
06/05/2022 19:44:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/05/2022 19:44:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/05/2022 19:45:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/05/2022 19:45:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/05/2022 19:45:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/05/2022 19:45:11 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.4920634920634921 on epoch=637
06/05/2022 19:45:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/05/2022 19:45:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/05/2022 19:45:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=644
06/05/2022 19:45:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/05/2022 19:45:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/05/2022 19:45:37 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.3720213064199608 on epoch=649
06/05/2022 19:45:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/05/2022 19:45:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/05/2022 19:45:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/05/2022 19:45:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=659
06/05/2022 19:46:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/05/2022 19:46:03 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.5755342667649226 on epoch=662
06/05/2022 19:46:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5607843137254902 -> 0.5755342667649226 on epoch=662, global_step=2650
06/05/2022 19:46:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/05/2022 19:46:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/05/2022 19:46:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/05/2022 19:46:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/05/2022 19:46:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/05/2022 19:46:29 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.4874874874874875 on epoch=674
06/05/2022 19:46:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/05/2022 19:46:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/05/2022 19:46:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/05/2022 19:46:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 19:46:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/05/2022 19:46:54 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5458771715194519 on epoch=687
06/05/2022 19:46:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/05/2022 19:47:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/05/2022 19:47:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/05/2022 19:47:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/05/2022 19:47:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/05/2022 19:47:20 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.5270935960591133 on epoch=699
06/05/2022 19:47:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/05/2022 19:47:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=704
06/05/2022 19:47:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 19:47:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=709
06/05/2022 19:47:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/05/2022 19:47:45 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.45440454662877805 on epoch=712
06/05/2022 19:47:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/05/2022 19:47:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/05/2022 19:47:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/05/2022 19:48:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/05/2022 19:48:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/05/2022 19:48:12 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.39756367663344405 on epoch=724
06/05/2022 19:48:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 19:48:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=729
06/05/2022 19:48:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/05/2022 19:48:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/05/2022 19:48:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 19:48:37 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.45440454662877805 on epoch=737
06/05/2022 19:48:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/05/2022 19:48:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/05/2022 19:48:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/05/2022 19:48:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/05/2022 19:49:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/05/2022 19:49:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:49:01 - INFO - __main__ - Printing 3 examples
06/05/2022 19:49:01 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 19:49:01 - INFO - __main__ - ['refuted']
06/05/2022 19:49:01 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 19:49:01 - INFO - __main__ - ['refuted']
06/05/2022 19:49:01 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 19:49:01 - INFO - __main__ - ['refuted']
06/05/2022 19:49:01 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:49:01 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:49:01 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 19:49:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:49:01 - INFO - __main__ - Printing 3 examples
06/05/2022 19:49:01 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 19:49:01 - INFO - __main__ - ['refuted']
06/05/2022 19:49:01 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 19:49:01 - INFO - __main__ - ['refuted']
06/05/2022 19:49:01 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 19:49:01 - INFO - __main__ - ['refuted']
06/05/2022 19:49:01 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:49:01 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:49:02 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 19:49:03 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.5145583557621727 on epoch=749
06/05/2022 19:49:03 - INFO - __main__ - save last model!
06/05/2022 19:49:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 19:49:03 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 19:49:03 - INFO - __main__ - Printing 3 examples
06/05/2022 19:49:03 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 19:49:03 - INFO - __main__ - ['entailed']
06/05/2022 19:49:03 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 19:49:03 - INFO - __main__ - ['entailed']
06/05/2022 19:49:03 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 19:49:03 - INFO - __main__ - ['entailed']
06/05/2022 19:49:03 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:49:17 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 19:49:17 - INFO - __main__ - task name: tab_fact
06/05/2022 19:49:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:49:18 - INFO - __main__ - Starting training!
06/05/2022 19:49:27 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:49:40 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 19:57:57 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_13_0.3_8_predictions.txt
06/05/2022 19:57:57 - INFO - __main__ - Classification-F1 on test data: 0.4963
06/05/2022 19:57:58 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.3, bsz=8, dev_performance=0.5755342667649226, test_performance=0.4962955097490078
06/05/2022 19:57:58 - INFO - __main__ - Running ... prefix=tab_fact_32_13, lr=0.2, bsz=8 ...
06/05/2022 19:57:58 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:57:58 - INFO - __main__ - Printing 3 examples
06/05/2022 19:57:58 - INFO - __main__ -  [tab_fact] statement: 5000 f be equivalent to a power - to - weight ratio of 8035 w / kg c / 5 [SEP] table_caption: power - to - weight ratio [SEP] table_text: capacity#volts#temp#energy - to - weight ratio#power - to - weight ratio [n] 2000 f#4.0v#25degree#54 kj / kg to 2.0v#44.4 w / kg 5a [n] 2000 f#4.0v#25degree#31 kj / kg to 2.0v#850 w / kg 10a [n] 5000 f#2.7v#25degree#19.58 kj / kg to 1.35v#5.44 w / kg c / 1 (1.875a) [n] 5000 f#2.7v#25degree#5.2 kj / kg to 1.35v#5200 w / kg 2547a [n] 30.693 f#3500v#85degree#1471.98 kj / kg#80.35 w / kg c / 5 [n] 30.693 f#3500v#85degree#1471.98 kj / kg#8035 w∕kg 20c [n] 20.5 mf#3300v#degree#2.3 kj / kg#6.8 mw / kg 100ka [n] 
06/05/2022 19:57:58 - INFO - __main__ - ['refuted']
06/05/2022 19:57:58 - INFO - __main__ -  [tab_fact] statement: score of 2 - 2 have less than 26.0 point [SEP] table_caption: 1992 - 93 toronto maple leafs season [SEP] table_text: game#date#visitor#score#home#record#points [n] 24#december 1#toronto#3 - 8#new jersey#11 - 10 - 3#25 [n] 25#december 3#toronto#3 - 4#chicago#11 - 11 - 3#25 [n] 26#december 5#chicago#2 - 2#toronto#11 - 11 - 4#26 [n] 27#december 6#toronto#0 - 6#ny rangers#11 - 12 - 4#26 [n] 28#december 9#detroit#5 - 3#toronto#12 - 12 - 4#28 [n] 29#december 11#calgary#3 - 6#toronto#12 - 13 - 4#28 [n] 30#december 15#toronto#5 - 6#minnesota#12 - 14 - 4#28 [n] 31#december 19#ottawa#5 - 1#toronto#13 - 14 - 4#30 [n] 32#december 20#toronto#4 - 5#buffalo#13 - 15 - 4#30 [n] 33#december 22#toronto#4 - 4#detroit#13 - 15 - 5#31 [n] 34#december 26#detroit#1 - 5#toronto#13 - 16 - 5#31 [n] 35#december 27#toronto#6 - 3#st louis#14 - 16 - 5#33 [n] 36#december 29#toronto#3 - 2#ny islanders#15 - 16 - 5#35 [n] 37#december 31#toronto#3 - 3#pittsburgh#15 - 16 - 6#36 [n] 
06/05/2022 19:57:58 - INFO - __main__ - ['refuted']
06/05/2022 19:57:58 - INFO - __main__ -  [tab_fact] statement: western prince park be the venue for round 6 event between home team footscray and away team fitzroy [SEP] table_caption: 1955 vfl season [SEP] table_text: home team#home team score#away team#away team score#venue#crowd#date [n] north melbourne#10.14 (74)#richmond#7.10 (52)#arden street oval#13000#21 may 1955 [n] collingwood#15.11 (101)#essendon#6.11 (47)#victoria park#35000#21 may 1955 [n] carlton#11.9 (75)#south melbourne#12.11 (83)#princes park#23000#21 may 1955 [n] melbourne#11.5 (71)#hawthorn#6.8 (44)#mcg#28338#21 may 1955 [n] st kilda#4.5 (29)#geelong#6.12 (48)#junction oval#11000#21 may 1955 [n] footscray#8.10 (58)#fitzroy#10.6 (66)#western oval#24517#21 may 1955 [n] 
06/05/2022 19:57:58 - INFO - __main__ - ['refuted']
06/05/2022 19:57:58 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:57:59 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:57:59 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 19:57:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 19:57:59 - INFO - __main__ - Printing 3 examples
06/05/2022 19:57:59 - INFO - __main__ -  [tab_fact] statement: track 10.0 be by morningwood [SEP] table_caption: list of songs from burnout revenge and burnout legends [SEP] table_text: track#song title#artist#album#legends track [n] 1#lights and sounds#yellowcard#5.4 lights and sounds#yes [n] 2#break on through (to the other side)#the doors#5.4 the doors#no [n] 3#shotgun#the outline#5.4 you smash it , we'll build around it#yes [n] 4#life burns!#apocalyptica#5.4 apocalyptica#no [n] 5#top of the world#the all - american rejects#5.4 move along#no [n] 6#the big jump#the chemical brothers#5.4 push the button#no [n] 7#stand up#pennywise#5.4 the fuse#yes [n] 8#tuned to a different station#dogs#5.4 turn against this land#yes [n] 9#the world#the starting line#5.4 based on a true story#no [n] 10#daft punk is playing at my house#lcd soundsystem#5.4 lcd soundsystem#no [n] 11#do what you want#ok go#5.4 oh no#yes [n] 12#band - girls - money#tsar#5.4 band - girls - money#yes [n] 13#come on#andy hunter degree#5.4 life#no [n] 14#almost here#the academy is#5.4 almost here#yes [n] 15#riot radio#the dead 60s#5.4 the dead 60s#yes [n] 16#nü rock#morningwood#5.4 morningwood#yes [n] 17#today#junkie xl#4.2 today#yes [n] 18#heard that sound#mxpx#5.4 panic#yes [n] 19#bundy#animal alpha#5.4 pheromones#yes [n] 20#i want#goldfinger#5.4 disconnection notice#yes [n] 21#hand of blood#bullet for my valentine#5.4 hand of blood#no [n] 22#dance , dance#fall out boy#5.4 from under the cork tree#no [n] 23#all the rage#funeral for a friend#5.4 hours#no [n] 24#apply some pressure#maxïmo park#5.4 a certain trigger#no [n] 25#better world#infusion#5.4 six feet above yesterday#no [n] 26#an honest mistake#the bravery#5.4 the bravery#no [n] 27#ink#finch#5.4 say hello to sunshine#yes [n] 28#the hey man!#emanuel#5.4 soundtrack to a headrush#yes [n] 29#as the tables turn#cky#5.4 an answer can be found#no [n] 30#red flag#billy talent#5.4 billy talent ii#yes [n] 31#wake the dead#comeback kid#5.4 wake the dead#yes [n] 32#helicopter#bloc party#5.4 silent alarm#no [n] 33#flyover#asian dub foundation#5.4 tank#no [n] 34#straight to video#mindless self indulgence#5.4 you'll rebel to anything#yes [n] 35#beast and the harlot#avenged sevenfold#5.4 city of evil#no [n] 36#first day#timo maas#5.4 pictures#no [n] 37#the great escape#we are scientists#5.4 with love and squalor#yes [n] 38#fight#unwritten law#5.4 here 's to the mourning#no [n] 39#fear and loathing#the black velvets#5.4 the black velvets#yes [n] 40#lullaby#thrice#5.4 vheissu#no [n] 41#shot down#nine black alps#5.4 everything is#yes [n] 
06/05/2022 19:57:59 - INFO - __main__ - ['refuted']
06/05/2022 19:57:59 - INFO - __main__ -  [tab_fact] statement: all the match list in the table be win by josé acasuso and play on a clay surface [SEP] table_caption: sebastián prieto [SEP] table_text: outcome#date#tournament#surface#partnering#opponent in the final#score [n] winner#november 9 , 1998#santiago , chile#clay#mariano hood#massimo bertolini devin bowen#7 - 6 , 6 - 7 , 7 - 6 [n] winner#october 4 , 1999#palermo , italy#clay#mariano hood#lan bale alberto martín#6 - 3 , 6 - 1 [n] winner#january 28 , 2001#bogotá , colombia#clay#mariano hood#martín rodríguez andré sá#6 - 2 , 6 - 4 [n] winner#february 17 , 2003#buenos aires , argentina#clay#mariano hood#lucas arnold ker david nalbandian#6 - 2 , 6 - 2 [n] winner#july 18 , 2005#stuttgart , germany#clay#josé acasuso#mariano hood tommy robredo#7 - 6 (4) , 6 - 3 [n] winner#september 12 , 2005#bucharest , romania#clay#josé acasuso#victor hănescu andrei pavel#6 - 3 , 4 - 6 , 6 - 3 [n] winner#january 30 , 2006#viña del mar , chile#clay#josé acasuso#františek čermák leoš friedl#7 - 6 (2) , 6 - 4 [n] winner#february 19 , 2007#buenos aires , argentina#clay#martín garcía#albert montañés rubén ramírez hidalgo#6 - 4 , 6 - 2 [n] winner#february 2 , 2008#viña del mar , chile#clay#josé acasuso#máximo gonzález juan mónaco#6 - 1 , 3 - 0 , ret [n] winner#february 21 , 2010#buenos aires , argentina#clay#horacio zeballos#simon greul peter luczak#7 - 6 (4) , 6 - 3 [n] 
06/05/2022 19:57:59 - INFO - __main__ - ['refuted']
06/05/2022 19:57:59 - INFO - __main__ -  [tab_fact] statement: waverley park be the venue for 5 of the game [SEP] table_caption: 1996 ansett australia cup [SEP] table_text: home team#home team score#away team#away team score#ground#crowd#date#time [n] adelaide#18.16 (124)#melbourne#10.5 (65)#football park#24143#friday 23 february 1996#8:00 pm [n] hawthorn#9.19 (73)#st kilda#19.13 (127)#waverley park#16061#saturday , 23 february 1996#8:00 pm [n] fremantle#7.15 (57)#west coast#10.11 (71)#marrara stadium#9078#sunday , 25 february 1996#7:05 pm [n] fitzroy#12.15 (87)#footscray#16.15 (111)#waverley park#4818#monday , 26 february 1996#8:00 pm [n] collingwood#14.10 (94)#richmond#8.14 (62)#waverley park#13307#wednesday 25 february 1996#8:00 pm [n] sydney#20.8 (128)#north melbourne#22.18 (150)#bruce stadium#9405#sunday , 2 march 1996#2:00 pm [n] carlton#14.12 (96)#essendon#8.14 (62)#waverley park#23837#saturday , 2 march 1996#8:00 pm [n] brisbane#14. 25 (109)#geelong#9.9 (63)#the gabba#18325#monday , 4 march 1996#7:00 pm [n] 
06/05/2022 19:57:59 - INFO - __main__ - ['refuted']
06/05/2022 19:57:59 - INFO - __main__ - Tokenizing Input ...
06/05/2022 19:57:59 - INFO - __main__ - Tokenizing Output ...
06/05/2022 19:57:59 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 19:58:18 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 19:58:18 - INFO - __main__ - task name: tab_fact
06/05/2022 19:58:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 19:58:18 - INFO - __main__ - Starting training!
06/05/2022 19:58:23 - INFO - __main__ - Step 10 Global step 10 Train loss 5.45 on epoch=2
06/05/2022 19:58:28 - INFO - __main__ - Step 20 Global step 20 Train loss 3.93 on epoch=4
06/05/2022 19:58:32 - INFO - __main__ - Step 30 Global step 30 Train loss 2.44 on epoch=7
06/05/2022 19:58:37 - INFO - __main__ - Step 40 Global step 40 Train loss 1.45 on epoch=9
06/05/2022 19:58:41 - INFO - __main__ - Step 50 Global step 50 Train loss 1.05 on epoch=12
06/05/2022 19:58:44 - INFO - __main__ - Global step 50 Train loss 2.86 Classification-F1 0.3333333333333333 on epoch=12
06/05/2022 19:58:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/05/2022 19:58:49 - INFO - __main__ - Step 60 Global step 60 Train loss 0.86 on epoch=14
06/05/2022 19:58:53 - INFO - __main__ - Step 70 Global step 70 Train loss 0.69 on epoch=17
06/05/2022 19:58:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.58 on epoch=19
06/05/2022 19:59:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.54 on epoch=22
06/05/2022 19:59:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.43 on epoch=24
06/05/2022 19:59:10 - INFO - __main__ - Global step 100 Train loss 0.62 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 19:59:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.43 on epoch=27
06/05/2022 19:59:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.41 on epoch=29
06/05/2022 19:59:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.36 on epoch=32
06/05/2022 19:59:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.33 on epoch=34
06/05/2022 19:59:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.30 on epoch=37
06/05/2022 19:59:35 - INFO - __main__ - Global step 150 Train loss 0.36 Classification-F1 0.3671451355661882 on epoch=37
06/05/2022 19:59:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3671451355661882 on epoch=37, global_step=150
06/05/2022 19:59:40 - INFO - __main__ - Step 160 Global step 160 Train loss 0.28 on epoch=39
06/05/2022 19:59:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.33 on epoch=42
06/05/2022 19:59:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=44
06/05/2022 19:59:53 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=47
06/05/2022 19:59:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.30 on epoch=49
06/05/2022 20:00:00 - INFO - __main__ - Global step 200 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 20:00:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.28 on epoch=52
06/05/2022 20:00:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.28 on epoch=54
06/05/2022 20:00:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.25 on epoch=57
06/05/2022 20:00:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=59
06/05/2022 20:00:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=62
06/05/2022 20:00:26 - INFO - __main__ - Global step 250 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 20:00:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/05/2022 20:00:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=67
06/05/2022 20:00:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=69
06/05/2022 20:00:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/05/2022 20:00:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/05/2022 20:00:51 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.4330011074197121 on epoch=74
06/05/2022 20:00:51 - INFO - __main__ - Saving model with best Classification-F1: 0.3671451355661882 -> 0.4330011074197121 on epoch=74, global_step=300
06/05/2022 20:00:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/05/2022 20:01:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/05/2022 20:01:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/05/2022 20:01:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.24 on epoch=84
06/05/2022 20:01:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=87
06/05/2022 20:01:16 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.3511520737327189 on epoch=87
06/05/2022 20:01:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/05/2022 20:01:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/05/2022 20:01:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/05/2022 20:01:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/05/2022 20:01:39 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/05/2022 20:01:41 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.3816425120772947 on epoch=99
06/05/2022 20:01:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
06/05/2022 20:01:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/05/2022 20:01:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/05/2022 20:01:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/05/2022 20:02:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/05/2022 20:02:06 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 20:02:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/05/2022 20:02:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/05/2022 20:02:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/05/2022 20:02:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=122
06/05/2022 20:02:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/05/2022 20:02:32 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.3846153846153846 on epoch=124
06/05/2022 20:02:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=127
06/05/2022 20:02:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/05/2022 20:02:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/05/2022 20:02:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=134
06/05/2022 20:02:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/05/2022 20:02:58 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.4330011074197121 on epoch=137
06/05/2022 20:03:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/05/2022 20:03:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/05/2022 20:03:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=144
06/05/2022 20:03:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=147
06/05/2022 20:03:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/05/2022 20:03:24 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/05/2022 20:03:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/05/2022 20:03:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/05/2022 20:03:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=157
06/05/2022 20:03:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/05/2022 20:03:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/05/2022 20:03:50 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.4181818181818182 on epoch=162
06/05/2022 20:03:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/05/2022 20:03:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/05/2022 20:04:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=169
06/05/2022 20:04:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/05/2022 20:04:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=174
06/05/2022 20:04:15 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.45705196182396607 on epoch=174
06/05/2022 20:04:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4330011074197121 -> 0.45705196182396607 on epoch=174, global_step=700
06/05/2022 20:04:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/05/2022 20:04:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/05/2022 20:04:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=182
06/05/2022 20:04:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=184
06/05/2022 20:04:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=187
06/05/2022 20:04:41 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=187
06/05/2022 20:04:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
06/05/2022 20:04:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=192
06/05/2022 20:04:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/05/2022 20:04:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=197
06/05/2022 20:05:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=199
06/05/2022 20:05:07 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.4465035829009143 on epoch=199
06/05/2022 20:05:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/05/2022 20:05:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=204
06/05/2022 20:05:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=207
06/05/2022 20:05:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=209
06/05/2022 20:05:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/05/2022 20:05:32 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.40026773761713513 on epoch=212
06/05/2022 20:05:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/05/2022 20:05:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=217
06/05/2022 20:05:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/05/2022 20:05:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=222
06/05/2022 20:05:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/05/2022 20:05:58 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.4206019084903352 on epoch=224
06/05/2022 20:06:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/05/2022 20:06:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/05/2022 20:06:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=232
06/05/2022 20:06:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
06/05/2022 20:06:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/05/2022 20:06:23 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.4231177094379639 on epoch=237
06/05/2022 20:06:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/05/2022 20:06:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=242
06/05/2022 20:06:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/05/2022 20:06:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=247
06/05/2022 20:06:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=249
06/05/2022 20:06:49 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.3818181818181818 on epoch=249
06/05/2022 20:06:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/05/2022 20:06:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=254
06/05/2022 20:07:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=257
06/05/2022 20:07:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
06/05/2022 20:07:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/05/2022 20:07:14 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.42840679919331603 on epoch=262
06/05/2022 20:07:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=264
06/05/2022 20:07:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=267
06/05/2022 20:07:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=269
06/05/2022 20:07:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=272
06/05/2022 20:07:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
06/05/2022 20:07:40 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.4116101917520357 on epoch=274
06/05/2022 20:07:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=277
06/05/2022 20:07:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
06/05/2022 20:07:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=282
06/05/2022 20:07:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=284
06/05/2022 20:08:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=287
06/05/2022 20:08:06 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.46843853820598 on epoch=287
06/05/2022 20:08:06 - INFO - __main__ - Saving model with best Classification-F1: 0.45705196182396607 -> 0.46843853820598 on epoch=287, global_step=1150
06/05/2022 20:08:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=289
06/05/2022 20:08:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/05/2022 20:08:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=294
06/05/2022 20:08:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=297
06/05/2022 20:08:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=299
06/05/2022 20:08:31 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.45299145299145294 on epoch=299
06/05/2022 20:08:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=302
06/05/2022 20:08:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=304
06/05/2022 20:08:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=307
06/05/2022 20:08:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/05/2022 20:08:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=312
06/05/2022 20:08:57 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.403921568627451 on epoch=312
06/05/2022 20:09:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
06/05/2022 20:09:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=317
06/05/2022 20:09:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=319
06/05/2022 20:09:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/05/2022 20:09:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=324
06/05/2022 20:09:23 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.38688282977155486 on epoch=324
06/05/2022 20:09:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=327
06/05/2022 20:09:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=329
06/05/2022 20:09:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=332
06/05/2022 20:09:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=334
06/05/2022 20:09:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=337
06/05/2022 20:09:48 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.46666666666666656 on epoch=337
06/05/2022 20:09:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=339
06/05/2022 20:09:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=342
06/05/2022 20:10:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=344
06/05/2022 20:10:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
06/05/2022 20:10:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/05/2022 20:10:14 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.4420512820512821 on epoch=349
06/05/2022 20:10:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=352
06/05/2022 20:10:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=354
06/05/2022 20:10:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/05/2022 20:10:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=359
06/05/2022 20:10:37 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=362
06/05/2022 20:10:40 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.45718194254445965 on epoch=362
06/05/2022 20:10:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=364
06/05/2022 20:10:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/05/2022 20:10:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=369
06/05/2022 20:10:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/05/2022 20:11:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/05/2022 20:11:06 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.4682306940371457 on epoch=374
06/05/2022 20:11:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=377
06/05/2022 20:11:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=379
06/05/2022 20:11:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=382
06/05/2022 20:11:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=384
06/05/2022 20:11:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=387
06/05/2022 20:11:32 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.44209215442092153 on epoch=387
06/05/2022 20:11:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=389
06/05/2022 20:11:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=392
06/05/2022 20:11:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/05/2022 20:11:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/05/2022 20:11:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
06/05/2022 20:11:57 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.45440454662877805 on epoch=399
06/05/2022 20:12:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/05/2022 20:12:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=404
06/05/2022 20:12:11 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=407
06/05/2022 20:12:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=409
06/05/2022 20:12:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
06/05/2022 20:12:23 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.45705196182396607 on epoch=412
06/05/2022 20:12:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
06/05/2022 20:12:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
06/05/2022 20:12:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=419
06/05/2022 20:12:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/05/2022 20:12:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/05/2022 20:12:49 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.41700404858299595 on epoch=424
06/05/2022 20:12:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/05/2022 20:12:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=429
06/05/2022 20:13:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/05/2022 20:13:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
06/05/2022 20:13:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/05/2022 20:13:14 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.464039408866995 on epoch=437
06/05/2022 20:13:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=439
06/05/2022 20:13:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/05/2022 20:13:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/05/2022 20:13:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/05/2022 20:13:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=449
06/05/2022 20:13:40 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.44976664210267747 on epoch=449
06/05/2022 20:13:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/05/2022 20:13:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=454
06/05/2022 20:13:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/05/2022 20:13:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/05/2022 20:14:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=462
06/05/2022 20:14:05 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.45705196182396607 on epoch=462
06/05/2022 20:14:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=464
06/05/2022 20:14:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=467
06/05/2022 20:14:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/05/2022 20:14:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=472
06/05/2022 20:14:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/05/2022 20:14:31 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.40116959064327484 on epoch=474
06/05/2022 20:14:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/05/2022 20:14:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/05/2022 20:14:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/05/2022 20:14:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=484
06/05/2022 20:14:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/05/2022 20:14:56 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.4375 on epoch=487
06/05/2022 20:15:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/05/2022 20:15:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/05/2022 20:15:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=494
06/05/2022 20:15:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=497
06/05/2022 20:15:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/05/2022 20:15:21 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.5238095238095238 on epoch=499
06/05/2022 20:15:21 - INFO - __main__ - Saving model with best Classification-F1: 0.46843853820598 -> 0.5238095238095238 on epoch=499, global_step=2000
06/05/2022 20:15:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/05/2022 20:15:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/05/2022 20:15:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=507
06/05/2022 20:15:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/05/2022 20:15:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/05/2022 20:15:47 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.4874874874874875 on epoch=512
06/05/2022 20:15:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/05/2022 20:15:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/05/2022 20:16:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/05/2022 20:16:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/05/2022 20:16:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=524
06/05/2022 20:16:13 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.4420512820512821 on epoch=524
06/05/2022 20:16:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=527
06/05/2022 20:16:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/05/2022 20:16:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/05/2022 20:16:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/05/2022 20:16:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=537
06/05/2022 20:16:39 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.46218487394957986 on epoch=537
06/05/2022 20:16:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/05/2022 20:16:48 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/05/2022 20:16:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/05/2022 20:16:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/05/2022 20:17:01 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=549
06/05/2022 20:17:04 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.41125541125541126 on epoch=549
06/05/2022 20:17:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/05/2022 20:17:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/05/2022 20:17:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/05/2022 20:17:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=559
06/05/2022 20:17:27 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/05/2022 20:17:30 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.46875 on epoch=562
06/05/2022 20:17:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=564
06/05/2022 20:17:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/05/2022 20:17:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/05/2022 20:17:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/05/2022 20:17:53 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/05/2022 20:17:56 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.4420512820512821 on epoch=574
06/05/2022 20:18:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/05/2022 20:18:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/05/2022 20:18:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=582
06/05/2022 20:18:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/05/2022 20:18:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/05/2022 20:18:21 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.3818181818181818 on epoch=587
06/05/2022 20:18:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/05/2022 20:18:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/05/2022 20:18:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/05/2022 20:18:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/05/2022 20:18:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/05/2022 20:18:47 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.464039408866995 on epoch=599
06/05/2022 20:18:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=602
06/05/2022 20:18:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=604
06/05/2022 20:19:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/05/2022 20:19:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/05/2022 20:19:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/05/2022 20:19:13 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.47813194959229055 on epoch=612
06/05/2022 20:19:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/05/2022 20:19:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/05/2022 20:19:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/05/2022 20:19:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/05/2022 20:19:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
06/05/2022 20:19:38 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.4285714285714286 on epoch=624
06/05/2022 20:19:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/05/2022 20:19:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/05/2022 20:19:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/05/2022 20:19:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/05/2022 20:20:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/05/2022 20:20:04 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.4817813765182186 on epoch=637
06/05/2022 20:20:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/05/2022 20:20:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=642
06/05/2022 20:20:18 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/05/2022 20:20:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=647
06/05/2022 20:20:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/05/2022 20:20:30 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.464039408866995 on epoch=649
06/05/2022 20:20:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/05/2022 20:20:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/05/2022 20:20:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/05/2022 20:20:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=659
06/05/2022 20:20:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=662
06/05/2022 20:20:56 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.473972602739726 on epoch=662
06/05/2022 20:21:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=664
06/05/2022 20:21:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=667
06/05/2022 20:21:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/05/2022 20:21:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/05/2022 20:21:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/05/2022 20:21:22 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.46031746031746035 on epoch=674
06/05/2022 20:21:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/05/2022 20:21:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/05/2022 20:21:35 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/05/2022 20:21:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/05/2022 20:21:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=687
06/05/2022 20:21:47 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.4874874874874875 on epoch=687
06/05/2022 20:21:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/05/2022 20:21:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/05/2022 20:22:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/05/2022 20:22:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/05/2022 20:22:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=699
06/05/2022 20:22:12 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.464039408866995 on epoch=699
06/05/2022 20:22:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/05/2022 20:22:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/05/2022 20:22:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/05/2022 20:22:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/05/2022 20:22:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/05/2022 20:22:38 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.4748717948717949 on epoch=712
06/05/2022 20:22:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/05/2022 20:22:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/05/2022 20:22:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=719
06/05/2022 20:22:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/05/2022 20:23:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/05/2022 20:23:04 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.4493927125506073 on epoch=724
06/05/2022 20:23:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/05/2022 20:23:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/05/2022 20:23:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/05/2022 20:23:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/05/2022 20:23:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/05/2022 20:23:29 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.44209215442092153 on epoch=737
06/05/2022 20:23:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/05/2022 20:23:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/05/2022 20:23:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/05/2022 20:23:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/05/2022 20:23:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/05/2022 20:23:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 20:23:53 - INFO - __main__ - Printing 3 examples
06/05/2022 20:23:53 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 20:23:53 - INFO - __main__ - ['entailed']
06/05/2022 20:23:53 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 20:23:53 - INFO - __main__ - ['entailed']
06/05/2022 20:23:53 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 20:23:53 - INFO - __main__ - ['entailed']
06/05/2022 20:23:53 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:23:53 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:23:53 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 20:23:53 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 20:23:53 - INFO - __main__ - Printing 3 examples
06/05/2022 20:23:53 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 20:23:53 - INFO - __main__ - ['entailed']
06/05/2022 20:23:53 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 20:23:53 - INFO - __main__ - ['entailed']
06/05/2022 20:23:53 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 20:23:53 - INFO - __main__ - ['entailed']
06/05/2022 20:23:53 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:23:54 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:23:54 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 20:23:55 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.4519207242476144 on epoch=749
06/05/2022 20:23:55 - INFO - __main__ - save last model!
06/05/2022 20:23:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 20:23:55 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 20:23:55 - INFO - __main__ - Printing 3 examples
06/05/2022 20:23:55 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 20:23:55 - INFO - __main__ - ['entailed']
06/05/2022 20:23:55 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 20:23:55 - INFO - __main__ - ['entailed']
06/05/2022 20:23:55 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 20:23:55 - INFO - __main__ - ['entailed']
06/05/2022 20:23:55 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:24:10 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 20:24:10 - INFO - __main__ - task name: tab_fact
06/05/2022 20:24:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:24:11 - INFO - __main__ - Starting training!
06/05/2022 20:24:19 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:24:32 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 20:33:20 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_13_0.2_8_predictions.txt
06/05/2022 20:33:20 - INFO - __main__ - Classification-F1 on test data: 0.4995
06/05/2022 20:33:21 - INFO - __main__ - prefix=tab_fact_32_13, lr=0.2, bsz=8, dev_performance=0.5238095238095238, test_performance=0.4994911110055029
06/05/2022 20:33:21 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.5, bsz=8 ...
06/05/2022 20:33:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 20:33:22 - INFO - __main__ - Printing 3 examples
06/05/2022 20:33:22 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 20:33:22 - INFO - __main__ - ['entailed']
06/05/2022 20:33:22 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 20:33:22 - INFO - __main__ - ['entailed']
06/05/2022 20:33:22 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 20:33:22 - INFO - __main__ - ['entailed']
06/05/2022 20:33:22 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:33:22 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:33:22 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 20:33:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 20:33:22 - INFO - __main__ - Printing 3 examples
06/05/2022 20:33:22 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 20:33:22 - INFO - __main__ - ['entailed']
06/05/2022 20:33:22 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 20:33:22 - INFO - __main__ - ['entailed']
06/05/2022 20:33:22 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 20:33:22 - INFO - __main__ - ['entailed']
06/05/2022 20:33:22 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:33:22 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:33:22 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 20:33:41 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 20:33:41 - INFO - __main__ - task name: tab_fact
06/05/2022 20:33:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 20:33:42 - INFO - __main__ - Starting training!
06/05/2022 20:33:47 - INFO - __main__ - Step 10 Global step 10 Train loss 4.67 on epoch=2
06/05/2022 20:33:51 - INFO - __main__ - Step 20 Global step 20 Train loss 2.15 on epoch=4
06/05/2022 20:33:56 - INFO - __main__ - Step 30 Global step 30 Train loss 1.07 on epoch=7
06/05/2022 20:34:00 - INFO - __main__ - Step 40 Global step 40 Train loss 0.65 on epoch=9
06/05/2022 20:34:05 - INFO - __main__ - Step 50 Global step 50 Train loss 0.53 on epoch=12
06/05/2022 20:34:08 - INFO - __main__ - Global step 50 Train loss 1.81 Classification-F1 0.3333333333333333 on epoch=12
06/05/2022 20:34:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/05/2022 20:34:12 - INFO - __main__ - Step 60 Global step 60 Train loss 0.41 on epoch=14
06/05/2022 20:34:17 - INFO - __main__ - Step 70 Global step 70 Train loss 0.39 on epoch=17
06/05/2022 20:34:21 - INFO - __main__ - Step 80 Global step 80 Train loss 0.66 on epoch=19
06/05/2022 20:34:26 - INFO - __main__ - Step 90 Global step 90 Train loss 3.55 on epoch=22
06/05/2022 20:34:30 - INFO - __main__ - Step 100 Global step 100 Train loss 5.64 on epoch=24
06/05/2022 20:35:16 - INFO - __main__ - Global step 100 Train loss 2.13 Classification-F1 0.007101218865924748 on epoch=24
06/05/2022 20:35:21 - INFO - __main__ - Step 110 Global step 110 Train loss 4.93 on epoch=27
06/05/2022 20:35:26 - INFO - __main__ - Step 120 Global step 120 Train loss 4.07 on epoch=29
06/05/2022 20:35:30 - INFO - __main__ - Step 130 Global step 130 Train loss 4.31 on epoch=32
06/05/2022 20:35:35 - INFO - __main__ - Step 140 Global step 140 Train loss 2.07 on epoch=34
06/05/2022 20:35:39 - INFO - __main__ - Step 150 Global step 150 Train loss 2.02 on epoch=37
06/05/2022 20:35:42 - INFO - __main__ - Global step 150 Train loss 3.48 Classification-F1 0.22713414634146342 on epoch=37
06/05/2022 20:35:47 - INFO - __main__ - Step 160 Global step 160 Train loss 1.44 on epoch=39
06/05/2022 20:35:52 - INFO - __main__ - Step 170 Global step 170 Train loss 1.29 on epoch=42
06/05/2022 20:35:56 - INFO - __main__ - Step 180 Global step 180 Train loss 1.11 on epoch=44
06/05/2022 20:36:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.96 on epoch=47
06/05/2022 20:36:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.97 on epoch=49
06/05/2022 20:36:11 - INFO - __main__ - Global step 200 Train loss 1.16 Classification-F1 0.2051282051282051 on epoch=49
06/05/2022 20:36:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.94 on epoch=52
06/05/2022 20:36:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.69 on epoch=54
06/05/2022 20:36:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.68 on epoch=57
06/05/2022 20:36:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=59
06/05/2022 20:36:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.58 on epoch=62
06/05/2022 20:36:36 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 20:36:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.61 on epoch=64
06/05/2022 20:36:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=67
06/05/2022 20:36:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=69
06/05/2022 20:36:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=72
06/05/2022 20:36:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/05/2022 20:37:02 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.3333333333333333 on epoch=74
06/05/2022 20:37:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=77
06/05/2022 20:37:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=79
06/05/2022 20:37:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.52 on epoch=82
06/05/2022 20:37:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=84
06/05/2022 20:37:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=87
06/05/2022 20:37:28 - INFO - __main__ - Global step 350 Train loss 0.55 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 20:37:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.62 on epoch=89
06/05/2022 20:37:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.50 on epoch=92
06/05/2022 20:37:41 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=94
06/05/2022 20:37:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=97
06/05/2022 20:37:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=99
06/05/2022 20:37:53 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.3333333333333333 on epoch=99
06/05/2022 20:37:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.46 on epoch=102
06/05/2022 20:38:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.43 on epoch=104
06/05/2022 20:38:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
06/05/2022 20:38:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=109
06/05/2022 20:38:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=112
06/05/2022 20:38:19 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 20:38:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=114
06/05/2022 20:38:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=117
06/05/2022 20:38:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=119
06/05/2022 20:38:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.33 on epoch=122
06/05/2022 20:38:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=124
06/05/2022 20:38:44 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.3333333333333333 on epoch=124
06/05/2022 20:38:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=127
06/05/2022 20:38:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.40 on epoch=129
06/05/2022 20:38:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=132
06/05/2022 20:39:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/05/2022 20:39:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=137
06/05/2022 20:39:10 - INFO - __main__ - Global step 550 Train loss 0.36 Classification-F1 0.3333333333333333 on epoch=137
06/05/2022 20:39:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.39 on epoch=139
06/05/2022 20:39:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=142
06/05/2022 20:39:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=144
06/05/2022 20:39:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=147
06/05/2022 20:39:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=149
06/05/2022 20:39:35 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.2175438596491228 on epoch=149
06/05/2022 20:39:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=152
06/05/2022 20:39:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=154
06/05/2022 20:39:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=157
06/05/2022 20:39:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.33 on epoch=159
06/05/2022 20:39:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=162
06/05/2022 20:40:01 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=162
06/05/2022 20:40:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=164
06/05/2022 20:40:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=167
06/05/2022 20:40:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.33 on epoch=169
06/05/2022 20:40:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=172
06/05/2022 20:40:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=174
06/05/2022 20:40:26 - INFO - __main__ - Global step 700 Train loss 0.32 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 20:40:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.29 on epoch=177
06/05/2022 20:40:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.28 on epoch=179
06/05/2022 20:40:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=182
06/05/2022 20:40:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=184
06/05/2022 20:40:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=187
06/05/2022 20:40:52 - INFO - __main__ - Global step 750 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=187
06/05/2022 20:40:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=189
06/05/2022 20:41:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=192
06/05/2022 20:41:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=194
06/05/2022 20:41:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.33 on epoch=197
06/05/2022 20:41:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=199
06/05/2022 20:41:17 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.3333333333333333 on epoch=199
06/05/2022 20:41:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.34 on epoch=202
06/05/2022 20:41:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=204
06/05/2022 20:41:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=207
06/05/2022 20:41:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=209
06/05/2022 20:41:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=212
06/05/2022 20:41:43 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=212
06/05/2022 20:41:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.28 on epoch=214
06/05/2022 20:41:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=217
06/05/2022 20:41:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=219
06/05/2022 20:42:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=222
06/05/2022 20:42:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=224
06/05/2022 20:42:09 - INFO - __main__ - Global step 900 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=224
06/05/2022 20:42:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.32 on epoch=227
06/05/2022 20:42:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=229
06/05/2022 20:42:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=232
06/05/2022 20:42:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=234
06/05/2022 20:42:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.28 on epoch=237
06/05/2022 20:42:34 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=237
06/05/2022 20:42:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.25 on epoch=239
06/05/2022 20:42:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.28 on epoch=242
06/05/2022 20:42:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.30 on epoch=244
06/05/2022 20:42:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=247
06/05/2022 20:42:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.28 on epoch=249
06/05/2022 20:43:00 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=249
06/05/2022 20:43:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=252
06/05/2022 20:43:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=254
06/05/2022 20:43:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.26 on epoch=257
06/05/2022 20:43:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.28 on epoch=259
06/05/2022 20:43:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=262
06/05/2022 20:43:25 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=262
06/05/2022 20:43:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.28 on epoch=264
06/05/2022 20:43:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.25 on epoch=267
06/05/2022 20:43:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=269
06/05/2022 20:43:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=272
06/05/2022 20:43:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.25 on epoch=274
06/05/2022 20:43:51 - INFO - __main__ - Global step 1100 Train loss 0.26 Classification-F1 0.3333333333333333 on epoch=274
06/05/2022 20:43:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=277
06/05/2022 20:44:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.24 on epoch=279
06/05/2022 20:44:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.25 on epoch=282
06/05/2022 20:44:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=284
06/05/2022 20:44:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=287
06/05/2022 20:44:16 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=287
06/05/2022 20:44:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.28 on epoch=289
06/05/2022 20:44:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.24 on epoch=292
06/05/2022 20:44:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=294
06/05/2022 20:44:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=297
06/05/2022 20:44:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=299
06/05/2022 20:44:42 - INFO - __main__ - Global step 1200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=299
06/05/2022 20:44:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.27 on epoch=302
06/05/2022 20:44:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.25 on epoch=304
06/05/2022 20:44:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=307
06/05/2022 20:45:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.25 on epoch=309
06/05/2022 20:45:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=312
06/05/2022 20:45:08 - INFO - __main__ - Global step 1250 Train loss 0.26 Classification-F1 0.3671451355661882 on epoch=312
06/05/2022 20:45:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3671451355661882 on epoch=312, global_step=1250
06/05/2022 20:45:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.26 on epoch=314
06/05/2022 20:45:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.25 on epoch=317
06/05/2022 20:45:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.24 on epoch=319
06/05/2022 20:45:26 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.24 on epoch=322
06/05/2022 20:45:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=324
06/05/2022 20:45:33 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=324
06/05/2022 20:45:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.25 on epoch=327
06/05/2022 20:45:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.26 on epoch=329
06/05/2022 20:45:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=332
06/05/2022 20:45:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=334
06/05/2022 20:45:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=337
06/05/2022 20:45:59 - INFO - __main__ - Global step 1350 Train loss 0.23 Classification-F1 0.5270935960591133 on epoch=337
06/05/2022 20:45:59 - INFO - __main__ - Saving model with best Classification-F1: 0.3671451355661882 -> 0.5270935960591133 on epoch=337, global_step=1350
06/05/2022 20:46:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=339
06/05/2022 20:46:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.25 on epoch=342
06/05/2022 20:46:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.22 on epoch=344
06/05/2022 20:46:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.22 on epoch=347
06/05/2022 20:46:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.24 on epoch=349
06/05/2022 20:46:24 - INFO - __main__ - Global step 1400 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=349
06/05/2022 20:46:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.28 on epoch=352
06/05/2022 20:46:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.21 on epoch=354
06/05/2022 20:46:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.28 on epoch=357
06/05/2022 20:46:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.24 on epoch=359
06/05/2022 20:46:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=362
06/05/2022 20:46:50 - INFO - __main__ - Global step 1450 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=362
06/05/2022 20:46:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.23 on epoch=364
06/05/2022 20:46:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.25 on epoch=367
06/05/2022 20:47:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.25 on epoch=369
06/05/2022 20:47:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.23 on epoch=372
06/05/2022 20:47:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.24 on epoch=374
06/05/2022 20:47:15 - INFO - __main__ - Global step 1500 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=374
06/05/2022 20:47:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.24 on epoch=377
06/05/2022 20:47:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.23 on epoch=379
06/05/2022 20:47:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=382
06/05/2022 20:47:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.22 on epoch=384
06/05/2022 20:47:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.23 on epoch=387
06/05/2022 20:47:41 - INFO - __main__ - Global step 1550 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=387
06/05/2022 20:47:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.22 on epoch=389
06/05/2022 20:47:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.22 on epoch=392
06/05/2022 20:47:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.23 on epoch=394
06/05/2022 20:47:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.21 on epoch=397
06/05/2022 20:48:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.23 on epoch=399
06/05/2022 20:48:06 - INFO - __main__ - Global step 1600 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=399
06/05/2022 20:48:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.25 on epoch=402
06/05/2022 20:48:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.24 on epoch=404
06/05/2022 20:48:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=407
06/05/2022 20:48:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.23 on epoch=409
06/05/2022 20:48:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.22 on epoch=412
06/05/2022 20:48:32 - INFO - __main__ - Global step 1650 Train loss 0.22 Classification-F1 0.2175438596491228 on epoch=412
06/05/2022 20:48:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.23 on epoch=414
06/05/2022 20:48:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.24 on epoch=417
06/05/2022 20:48:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.22 on epoch=419
06/05/2022 20:48:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.23 on epoch=422
06/05/2022 20:48:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.23 on epoch=424
06/05/2022 20:48:57 - INFO - __main__ - Global step 1700 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=424
06/05/2022 20:49:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.23 on epoch=427
06/05/2022 20:49:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.22 on epoch=429
06/05/2022 20:49:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.21 on epoch=432
06/05/2022 20:49:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.22 on epoch=434
06/05/2022 20:49:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.23 on epoch=437
06/05/2022 20:49:23 - INFO - __main__ - Global step 1750 Train loss 0.22 Classification-F1 0.2175438596491228 on epoch=437
06/05/2022 20:49:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.22 on epoch=439
06/05/2022 20:49:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.19 on epoch=442
06/05/2022 20:49:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.20 on epoch=444
06/05/2022 20:49:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.22 on epoch=447
06/05/2022 20:49:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.24 on epoch=449
06/05/2022 20:49:49 - INFO - __main__ - Global step 1800 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=449
06/05/2022 20:49:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.24 on epoch=452
06/05/2022 20:49:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.24 on epoch=454
06/05/2022 20:50:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.23 on epoch=457
06/05/2022 20:50:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.20 on epoch=459
06/05/2022 20:50:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.20 on epoch=462
06/05/2022 20:50:14 - INFO - __main__ - Global step 1850 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=462
06/05/2022 20:50:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.23 on epoch=464
06/05/2022 20:50:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.19 on epoch=467
06/05/2022 20:50:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.23 on epoch=469
06/05/2022 20:50:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.21 on epoch=472
06/05/2022 20:50:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.20 on epoch=474
06/05/2022 20:50:39 - INFO - __main__ - Global step 1900 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=474
06/05/2022 20:50:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.19 on epoch=477
06/05/2022 20:50:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.23 on epoch=479
06/05/2022 20:50:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.21 on epoch=482
06/05/2022 20:50:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.20 on epoch=484
06/05/2022 20:51:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.21 on epoch=487
06/05/2022 20:51:05 - INFO - __main__ - Global step 1950 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=487
06/05/2022 20:51:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.22 on epoch=489
06/05/2022 20:51:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.24 on epoch=492
06/05/2022 20:51:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.20 on epoch=494
06/05/2022 20:51:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.21 on epoch=497
06/05/2022 20:51:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.20 on epoch=499
06/05/2022 20:51:30 - INFO - __main__ - Global step 2000 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=499
06/05/2022 20:51:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.19 on epoch=502
06/05/2022 20:51:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.20 on epoch=504
06/05/2022 20:51:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.19 on epoch=507
06/05/2022 20:51:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.21 on epoch=509
06/05/2022 20:51:53 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.22 on epoch=512
06/05/2022 20:51:56 - INFO - __main__ - Global step 2050 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=512
06/05/2022 20:52:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.19 on epoch=514
06/05/2022 20:52:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.22 on epoch=517
06/05/2022 20:52:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.19 on epoch=519
06/05/2022 20:52:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.19 on epoch=522
06/05/2022 20:52:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.21 on epoch=524
06/05/2022 20:52:21 - INFO - __main__ - Global step 2100 Train loss 0.20 Classification-F1 0.2078853046594982 on epoch=524
06/05/2022 20:52:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.21 on epoch=527
06/05/2022 20:52:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.22 on epoch=529
06/05/2022 20:52:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.18 on epoch=532
06/05/2022 20:52:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.18 on epoch=534
06/05/2022 20:52:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.20 on epoch=537
06/05/2022 20:52:46 - INFO - __main__ - Global step 2150 Train loss 0.20 Classification-F1 0.24949124949124948 on epoch=537
06/05/2022 20:52:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.21 on epoch=539
06/05/2022 20:52:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.23 on epoch=542
06/05/2022 20:53:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.20 on epoch=544
06/05/2022 20:53:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.20 on epoch=547
06/05/2022 20:53:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.24 on epoch=549
06/05/2022 20:53:12 - INFO - __main__ - Global step 2200 Train loss 0.22 Classification-F1 0.24242424242424243 on epoch=549
06/05/2022 20:53:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.17 on epoch=552
06/05/2022 20:53:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.24 on epoch=554
06/05/2022 20:53:25 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.20 on epoch=557
06/05/2022 20:53:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.21 on epoch=559
06/05/2022 20:53:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.20 on epoch=562
06/05/2022 20:53:37 - INFO - __main__ - Global step 2250 Train loss 0.20 Classification-F1 0.20883534136546186 on epoch=562
06/05/2022 20:53:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.21 on epoch=564
06/05/2022 20:53:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.22 on epoch=567
06/05/2022 20:53:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.19 on epoch=569
06/05/2022 20:53:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.20 on epoch=572
06/05/2022 20:54:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.23 on epoch=574
06/05/2022 20:54:03 - INFO - __main__ - Global step 2300 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=574
06/05/2022 20:54:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.18 on epoch=577
06/05/2022 20:54:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.20 on epoch=579
06/05/2022 20:54:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.22 on epoch=582
06/05/2022 20:54:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.22 on epoch=584
06/05/2022 20:54:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.20 on epoch=587
06/05/2022 20:54:28 - INFO - __main__ - Global step 2350 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=587
06/05/2022 20:54:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.19 on epoch=589
06/05/2022 20:54:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.21 on epoch=592
06/05/2022 20:54:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.18 on epoch=594
06/05/2022 20:54:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.20 on epoch=597
06/05/2022 20:54:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.19 on epoch=599
06/05/2022 20:54:54 - INFO - __main__ - Global step 2400 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=599
06/05/2022 20:54:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.20 on epoch=602
06/05/2022 20:55:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.21 on epoch=604
06/05/2022 20:55:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.19 on epoch=607
06/05/2022 20:55:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.22 on epoch=609
06/05/2022 20:55:16 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.20 on epoch=612
06/05/2022 20:55:19 - INFO - __main__ - Global step 2450 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=612
06/05/2022 20:55:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.24 on epoch=614
06/05/2022 20:55:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.20 on epoch=617
06/05/2022 20:55:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.20 on epoch=619
06/05/2022 20:55:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.20 on epoch=622
06/05/2022 20:55:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.20 on epoch=624
06/05/2022 20:55:44 - INFO - __main__ - Global step 2500 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=624
06/05/2022 20:55:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.22 on epoch=627
06/05/2022 20:55:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.20 on epoch=629
06/05/2022 20:55:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.23 on epoch=632
06/05/2022 20:56:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.20 on epoch=634
06/05/2022 20:56:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.19 on epoch=637
06/05/2022 20:56:09 - INFO - __main__ - Global step 2550 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=637
06/05/2022 20:56:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.22 on epoch=639
06/05/2022 20:56:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.22 on epoch=642
06/05/2022 20:56:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.20 on epoch=644
06/05/2022 20:56:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.19 on epoch=647
06/05/2022 20:56:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.18 on epoch=649
06/05/2022 20:56:35 - INFO - __main__ - Global step 2600 Train loss 0.20 Classification-F1 0.26143790849673204 on epoch=649
06/05/2022 20:56:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.18 on epoch=652
06/05/2022 20:56:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.21 on epoch=654
06/05/2022 20:56:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.17 on epoch=657
06/05/2022 20:56:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.23 on epoch=659
06/05/2022 20:56:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.21 on epoch=662
06/05/2022 20:57:00 - INFO - __main__ - Global step 2650 Train loss 0.20 Classification-F1 0.28522238163558106 on epoch=662
06/05/2022 20:57:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.20 on epoch=664
06/05/2022 20:57:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.19 on epoch=667
06/05/2022 20:57:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.17 on epoch=669
06/05/2022 20:57:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.17 on epoch=672
06/05/2022 20:57:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.17 on epoch=674
06/05/2022 20:57:26 - INFO - __main__ - Global step 2700 Train loss 0.18 Classification-F1 0.5599694423223835 on epoch=674
06/05/2022 20:57:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5270935960591133 -> 0.5599694423223835 on epoch=674, global_step=2700
06/05/2022 20:57:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.22 on epoch=677
06/05/2022 20:57:35 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.23 on epoch=679
06/05/2022 20:57:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.21 on epoch=682
06/05/2022 20:57:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.19 on epoch=684
06/05/2022 20:57:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.17 on epoch=687
06/05/2022 20:57:52 - INFO - __main__ - Global step 2750 Train loss 0.20 Classification-F1 0.32333833083458274 on epoch=687
06/05/2022 20:57:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.18 on epoch=689
06/05/2022 20:58:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.20 on epoch=692
06/05/2022 20:58:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.19 on epoch=694
06/05/2022 20:58:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.19 on epoch=697
06/05/2022 20:58:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.18 on epoch=699
06/05/2022 20:58:17 - INFO - __main__ - Global step 2800 Train loss 0.19 Classification-F1 0.34118262689691264 on epoch=699
06/05/2022 20:58:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.22 on epoch=702
06/05/2022 20:58:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.20 on epoch=704
06/05/2022 20:58:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.22 on epoch=707
06/05/2022 20:58:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.21 on epoch=709
06/05/2022 20:58:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.21 on epoch=712
06/05/2022 20:58:42 - INFO - __main__ - Global step 2850 Train loss 0.21 Classification-F1 0.5467643467643467 on epoch=712
06/05/2022 20:58:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.18 on epoch=714
06/05/2022 20:58:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.22 on epoch=717
06/05/2022 20:58:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.18 on epoch=719
06/05/2022 20:59:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.20 on epoch=722
06/05/2022 20:59:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.22 on epoch=724
06/05/2022 20:59:08 - INFO - __main__ - Global step 2900 Train loss 0.20 Classification-F1 0.5076923076923077 on epoch=724
06/05/2022 20:59:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.21 on epoch=727
06/05/2022 20:59:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.17 on epoch=729
06/05/2022 20:59:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.20 on epoch=732
06/05/2022 20:59:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.18 on epoch=734
06/05/2022 20:59:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.19 on epoch=737
06/05/2022 20:59:33 - INFO - __main__ - Global step 2950 Train loss 0.19 Classification-F1 0.5373493975903615 on epoch=737
06/05/2022 20:59:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.17 on epoch=739
06/05/2022 20:59:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.18 on epoch=742
06/05/2022 20:59:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.17 on epoch=744
06/05/2022 20:59:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.16 on epoch=747
06/05/2022 20:59:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.23 on epoch=749
06/05/2022 20:59:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 20:59:57 - INFO - __main__ - Printing 3 examples
06/05/2022 20:59:57 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 20:59:57 - INFO - __main__ - ['entailed']
06/05/2022 20:59:57 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 20:59:57 - INFO - __main__ - ['entailed']
06/05/2022 20:59:57 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 20:59:57 - INFO - __main__ - ['entailed']
06/05/2022 20:59:57 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:59:57 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:59:57 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 20:59:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 20:59:57 - INFO - __main__ - Printing 3 examples
06/05/2022 20:59:57 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 20:59:57 - INFO - __main__ - ['entailed']
06/05/2022 20:59:57 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 20:59:57 - INFO - __main__ - ['entailed']
06/05/2022 20:59:57 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 20:59:57 - INFO - __main__ - ['entailed']
06/05/2022 20:59:57 - INFO - __main__ - Tokenizing Input ...
06/05/2022 20:59:57 - INFO - __main__ - Tokenizing Output ...
06/05/2022 20:59:58 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 20:59:59 - INFO - __main__ - Global step 3000 Train loss 0.18 Classification-F1 0.46843853820598 on epoch=749
06/05/2022 20:59:59 - INFO - __main__ - save last model!
06/05/2022 20:59:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 20:59:59 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 20:59:59 - INFO - __main__ - Printing 3 examples
06/05/2022 20:59:59 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 20:59:59 - INFO - __main__ - ['entailed']
06/05/2022 20:59:59 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 20:59:59 - INFO - __main__ - ['entailed']
06/05/2022 20:59:59 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 20:59:59 - INFO - __main__ - ['entailed']
06/05/2022 20:59:59 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:00:13 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 21:00:13 - INFO - __main__ - task name: tab_fact
06/05/2022 21:00:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:00:14 - INFO - __main__ - Starting training!
06/05/2022 21:00:23 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:00:36 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 21:09:35 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_21_0.5_8_predictions.txt
06/05/2022 21:09:35 - INFO - __main__ - Classification-F1 on test data: 0.3149
06/05/2022 21:09:36 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.5, bsz=8, dev_performance=0.5599694423223835, test_performance=0.314943169417314
06/05/2022 21:09:36 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.4, bsz=8 ...
06/05/2022 21:09:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 21:09:37 - INFO - __main__ - Printing 3 examples
06/05/2022 21:09:37 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 21:09:37 - INFO - __main__ - ['entailed']
06/05/2022 21:09:37 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 21:09:37 - INFO - __main__ - ['entailed']
06/05/2022 21:09:37 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 21:09:37 - INFO - __main__ - ['entailed']
06/05/2022 21:09:37 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:09:37 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:09:37 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 21:09:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 21:09:37 - INFO - __main__ - Printing 3 examples
06/05/2022 21:09:37 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 21:09:37 - INFO - __main__ - ['entailed']
06/05/2022 21:09:37 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 21:09:37 - INFO - __main__ - ['entailed']
06/05/2022 21:09:37 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 21:09:37 - INFO - __main__ - ['entailed']
06/05/2022 21:09:37 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:09:37 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:09:37 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 21:09:56 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 21:09:56 - INFO - __main__ - task name: tab_fact
06/05/2022 21:09:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:09:57 - INFO - __main__ - Starting training!
06/05/2022 21:10:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.73 on epoch=2
06/05/2022 21:10:06 - INFO - __main__ - Step 20 Global step 20 Train loss 1.90 on epoch=4
06/05/2022 21:10:11 - INFO - __main__ - Step 30 Global step 30 Train loss 0.85 on epoch=7
06/05/2022 21:10:15 - INFO - __main__ - Step 40 Global step 40 Train loss 0.49 on epoch=9
06/05/2022 21:10:20 - INFO - __main__ - Step 50 Global step 50 Train loss 0.49 on epoch=12
06/05/2022 21:10:22 - INFO - __main__ - Global step 50 Train loss 1.69 Classification-F1 0.5155067155067155 on epoch=12
06/05/2022 21:10:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.5155067155067155 on epoch=12, global_step=50
06/05/2022 21:10:27 - INFO - __main__ - Step 60 Global step 60 Train loss 0.39 on epoch=14
06/05/2022 21:10:31 - INFO - __main__ - Step 70 Global step 70 Train loss 0.39 on epoch=17
06/05/2022 21:10:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.34 on epoch=19
06/05/2022 21:10:40 - INFO - __main__ - Step 90 Global step 90 Train loss 0.30 on epoch=22
06/05/2022 21:10:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.33 on epoch=24
06/05/2022 21:10:48 - INFO - __main__ - Global step 100 Train loss 0.35 Classification-F1 0.4295900178253119 on epoch=24
06/05/2022 21:10:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.32 on epoch=27
06/05/2022 21:10:57 - INFO - __main__ - Step 120 Global step 120 Train loss 0.28 on epoch=29
06/05/2022 21:11:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.27 on epoch=32
06/05/2022 21:11:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.25 on epoch=34
06/05/2022 21:11:10 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/05/2022 21:11:13 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=37
06/05/2022 21:11:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.25 on epoch=39
06/05/2022 21:11:22 - INFO - __main__ - Step 170 Global step 170 Train loss 0.26 on epoch=42
06/05/2022 21:11:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.22 on epoch=44
06/05/2022 21:11:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/05/2022 21:11:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/05/2022 21:11:38 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 21:11:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.22 on epoch=52
06/05/2022 21:11:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.23 on epoch=54
06/05/2022 21:11:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=57
06/05/2022 21:11:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=59
06/05/2022 21:12:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.20 on epoch=62
06/05/2022 21:12:04 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 21:12:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.23 on epoch=64
06/05/2022 21:12:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.22 on epoch=67
06/05/2022 21:12:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/05/2022 21:12:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/05/2022 21:12:26 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
06/05/2022 21:12:29 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=74
06/05/2022 21:12:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/05/2022 21:12:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/05/2022 21:12:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/05/2022 21:12:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/05/2022 21:12:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=87
06/05/2022 21:12:55 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 21:12:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/05/2022 21:13:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=92
06/05/2022 21:13:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
06/05/2022 21:13:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/05/2022 21:13:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/05/2022 21:13:20 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.3671451355661882 on epoch=99
06/05/2022 21:13:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/05/2022 21:13:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/05/2022 21:13:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=107
06/05/2022 21:13:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/05/2022 21:13:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=112
06/05/2022 21:13:45 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=112
06/05/2022 21:13:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/05/2022 21:13:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/05/2022 21:13:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/05/2022 21:14:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=122
06/05/2022 21:14:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/05/2022 21:14:10 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=124
06/05/2022 21:14:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=127
06/05/2022 21:14:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/05/2022 21:14:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=132
06/05/2022 21:14:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/05/2022 21:14:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/05/2022 21:14:35 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.42840679919331603 on epoch=137
06/05/2022 21:14:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/05/2022 21:14:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/05/2022 21:14:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=144
06/05/2022 21:14:53 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/05/2022 21:14:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/05/2022 21:15:01 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.2175438596491228 on epoch=149
06/05/2022 21:15:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/05/2022 21:15:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/05/2022 21:15:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/05/2022 21:15:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/05/2022 21:15:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/05/2022 21:15:26 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.2175438596491228 on epoch=162
06/05/2022 21:15:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/05/2022 21:15:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/05/2022 21:15:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/05/2022 21:15:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/05/2022 21:15:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/05/2022 21:15:51 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 21:15:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=177
06/05/2022 21:16:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/05/2022 21:16:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/05/2022 21:16:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/05/2022 21:16:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/05/2022 21:16:17 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=187
06/05/2022 21:16:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/05/2022 21:16:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=192
06/05/2022 21:16:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/05/2022 21:16:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/05/2022 21:16:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=199
06/05/2022 21:16:42 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=199
06/05/2022 21:16:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/05/2022 21:16:51 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/05/2022 21:16:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=207
06/05/2022 21:17:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=209
06/05/2022 21:17:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=212
06/05/2022 21:17:08 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.3671451355661882 on epoch=212
06/05/2022 21:17:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=214
06/05/2022 21:17:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/05/2022 21:17:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=219
06/05/2022 21:17:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=222
06/05/2022 21:17:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/05/2022 21:17:33 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=224
06/05/2022 21:17:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=227
06/05/2022 21:17:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/05/2022 21:17:46 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=232
06/05/2022 21:17:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/05/2022 21:17:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=237
06/05/2022 21:17:58 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.3333333333333333 on epoch=237
06/05/2022 21:18:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/05/2022 21:18:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=242
06/05/2022 21:18:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/05/2022 21:18:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=247
06/05/2022 21:18:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=249
06/05/2022 21:18:24 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.500880503144654 on epoch=249
06/05/2022 21:18:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/05/2022 21:18:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/05/2022 21:18:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=257
06/05/2022 21:18:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=259
06/05/2022 21:18:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=262
06/05/2022 21:18:49 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.429800307219662 on epoch=262
06/05/2022 21:18:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=264
06/05/2022 21:18:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=267
06/05/2022 21:19:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=269
06/05/2022 21:19:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
06/05/2022 21:19:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
06/05/2022 21:19:15 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.3992490613266583 on epoch=274
06/05/2022 21:19:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=277
06/05/2022 21:19:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
06/05/2022 21:19:28 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=282
06/05/2022 21:19:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=284
06/05/2022 21:19:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=287
06/05/2022 21:19:40 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.22456140350877193 on epoch=287
06/05/2022 21:19:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=289
06/05/2022 21:19:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=292
06/05/2022 21:19:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=294
06/05/2022 21:19:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=297
06/05/2022 21:20:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=299
06/05/2022 21:20:06 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.473972602739726 on epoch=299
06/05/2022 21:20:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/05/2022 21:20:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=304
06/05/2022 21:20:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=307
06/05/2022 21:20:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=309
06/05/2022 21:20:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=312
06/05/2022 21:20:31 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.3055555555555555 on epoch=312
06/05/2022 21:20:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/05/2022 21:20:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=317
06/05/2022 21:20:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=319
06/05/2022 21:20:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/05/2022 21:20:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/05/2022 21:20:57 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.38000000000000006 on epoch=324
06/05/2022 21:21:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=327
06/05/2022 21:21:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/05/2022 21:21:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=332
06/05/2022 21:21:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=334
06/05/2022 21:21:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=337
06/05/2022 21:21:22 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.3333333333333333 on epoch=337
06/05/2022 21:21:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=339
06/05/2022 21:21:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/05/2022 21:21:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=344
06/05/2022 21:21:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/05/2022 21:21:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=349
06/05/2022 21:21:47 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.2742648972157169 on epoch=349
06/05/2022 21:21:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=352
06/05/2022 21:21:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/05/2022 21:22:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=357
06/05/2022 21:22:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=359
06/05/2022 21:22:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
06/05/2022 21:22:13 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.20820512820512818 on epoch=362
06/05/2022 21:22:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
06/05/2022 21:22:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/05/2022 21:22:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/05/2022 21:22:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/05/2022 21:22:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/05/2022 21:22:38 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.2696969696969697 on epoch=374
06/05/2022 21:22:42 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/05/2022 21:22:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/05/2022 21:22:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=382
06/05/2022 21:22:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/05/2022 21:23:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/05/2022 21:23:03 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.24187483212463068 on epoch=387
06/05/2022 21:23:08 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=389
06/05/2022 21:23:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/05/2022 21:23:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/05/2022 21:23:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/05/2022 21:23:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/05/2022 21:23:28 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.35576603522765043 on epoch=399
06/05/2022 21:23:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/05/2022 21:23:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/05/2022 21:23:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/05/2022 21:23:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/05/2022 21:23:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/05/2022 21:23:54 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.4682306940371457 on epoch=412
06/05/2022 21:23:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/05/2022 21:24:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/05/2022 21:24:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=419
06/05/2022 21:24:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/05/2022 21:24:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/05/2022 21:24:19 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.25297242600556535 on epoch=424
06/05/2022 21:24:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/05/2022 21:24:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/05/2022 21:24:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/05/2022 21:24:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/05/2022 21:24:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/05/2022 21:24:45 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.3118440779610195 on epoch=437
06/05/2022 21:24:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/05/2022 21:24:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/05/2022 21:24:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/05/2022 21:25:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/05/2022 21:25:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/05/2022 21:25:10 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.5294117647058825 on epoch=449
06/05/2022 21:25:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5155067155067155 -> 0.5294117647058825 on epoch=449, global_step=1800
06/05/2022 21:25:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/05/2022 21:25:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/05/2022 21:25:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/05/2022 21:25:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/05/2022 21:25:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/05/2022 21:25:35 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.3036926643484021 on epoch=462
06/05/2022 21:25:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/05/2022 21:25:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/05/2022 21:25:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/05/2022 21:25:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/05/2022 21:25:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/05/2022 21:26:00 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.5238095238095238 on epoch=474
06/05/2022 21:26:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/05/2022 21:26:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/05/2022 21:26:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/05/2022 21:26:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/05/2022 21:26:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/05/2022 21:26:25 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.3566583953680728 on epoch=487
06/05/2022 21:26:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/05/2022 21:26:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/05/2022 21:26:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/05/2022 21:26:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/05/2022 21:26:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/05/2022 21:26:50 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.5458771715194519 on epoch=499
06/05/2022 21:26:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5294117647058825 -> 0.5458771715194519 on epoch=499, global_step=2000
06/05/2022 21:26:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/05/2022 21:26:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/05/2022 21:27:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/05/2022 21:27:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/05/2022 21:27:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/05/2022 21:27:15 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.48424908424908425 on epoch=512
06/05/2022 21:27:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/05/2022 21:27:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/05/2022 21:27:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/05/2022 21:27:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=522
06/05/2022 21:27:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/05/2022 21:27:40 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.48424908424908425 on epoch=524
06/05/2022 21:27:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/05/2022 21:27:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/05/2022 21:27:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/05/2022 21:27:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/05/2022 21:28:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/05/2022 21:28:05 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.5270935960591133 on epoch=537
06/05/2022 21:28:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/05/2022 21:28:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/05/2022 21:28:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/05/2022 21:28:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/05/2022 21:28:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/05/2022 21:28:31 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.35202020202020207 on epoch=549
06/05/2022 21:28:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/05/2022 21:28:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/05/2022 21:28:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/05/2022 21:28:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/05/2022 21:28:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/05/2022 21:28:56 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.3356492969396195 on epoch=562
06/05/2022 21:29:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/05/2022 21:29:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/05/2022 21:29:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/05/2022 21:29:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/05/2022 21:29:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/05/2022 21:29:21 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.26825769431403235 on epoch=574
06/05/2022 21:29:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/05/2022 21:29:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/05/2022 21:29:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/05/2022 21:29:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/05/2022 21:29:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/05/2022 21:29:46 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.3247097844112769 on epoch=587
06/05/2022 21:29:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/05/2022 21:29:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/05/2022 21:30:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/05/2022 21:30:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/05/2022 21:30:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/05/2022 21:30:12 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5205373288555928 on epoch=599
06/05/2022 21:30:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/05/2022 21:30:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/05/2022 21:30:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/05/2022 21:30:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/05/2022 21:30:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/05/2022 21:30:37 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5294117647058825 on epoch=612
06/05/2022 21:30:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/05/2022 21:30:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/05/2022 21:30:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/05/2022 21:30:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/05/2022 21:30:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/05/2022 21:31:02 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.5730170496664195 on epoch=624
06/05/2022 21:31:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5458771715194519 -> 0.5730170496664195 on epoch=624, global_step=2500
06/05/2022 21:31:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/05/2022 21:31:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/05/2022 21:31:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/05/2022 21:31:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/05/2022 21:31:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/05/2022 21:31:27 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.3329991645781119 on epoch=637
06/05/2022 21:31:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/05/2022 21:31:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/05/2022 21:31:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/05/2022 21:31:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/05/2022 21:31:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/05/2022 21:31:52 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5307917888563051 on epoch=649
06/05/2022 21:31:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/05/2022 21:32:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=654
06/05/2022 21:32:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/05/2022 21:32:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/05/2022 21:32:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/05/2022 21:32:18 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.3557213930348258 on epoch=662
06/05/2022 21:32:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/05/2022 21:32:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/05/2022 21:32:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/05/2022 21:32:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/05/2022 21:32:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/05/2022 21:32:43 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.4995112414467253 on epoch=674
06/05/2022 21:32:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/05/2022 21:32:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/05/2022 21:32:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/05/2022 21:33:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 21:33:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/05/2022 21:33:08 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.3557213930348258 on epoch=687
06/05/2022 21:33:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/05/2022 21:33:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/05/2022 21:33:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/05/2022 21:33:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/05/2022 21:33:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/05/2022 21:33:33 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.5730170496664195 on epoch=699
06/05/2022 21:33:38 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/05/2022 21:33:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/05/2022 21:33:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 21:33:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/05/2022 21:33:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/05/2022 21:33:59 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.37973822879483254 on epoch=712
06/05/2022 21:34:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/05/2022 21:34:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/05/2022 21:34:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/05/2022 21:34:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/05/2022 21:34:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/05/2022 21:34:24 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.3666412407831172 on epoch=724
06/05/2022 21:34:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 21:34:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/05/2022 21:34:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/05/2022 21:34:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/05/2022 21:34:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 21:34:49 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.335978835978836 on epoch=737
06/05/2022 21:34:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/05/2022 21:34:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/05/2022 21:35:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/05/2022 21:35:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/05/2022 21:35:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/05/2022 21:35:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 21:35:13 - INFO - __main__ - Printing 3 examples
06/05/2022 21:35:13 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 21:35:13 - INFO - __main__ - ['entailed']
06/05/2022 21:35:13 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 21:35:13 - INFO - __main__ - ['entailed']
06/05/2022 21:35:13 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 21:35:13 - INFO - __main__ - ['entailed']
06/05/2022 21:35:13 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:35:13 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:35:13 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 21:35:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 21:35:13 - INFO - __main__ - Printing 3 examples
06/05/2022 21:35:13 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 21:35:13 - INFO - __main__ - ['entailed']
06/05/2022 21:35:13 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 21:35:13 - INFO - __main__ - ['entailed']
06/05/2022 21:35:13 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 21:35:13 - INFO - __main__ - ['entailed']
06/05/2022 21:35:13 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:35:13 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:35:13 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 21:35:14 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5145583557621727 on epoch=749
06/05/2022 21:35:14 - INFO - __main__ - save last model!
06/05/2022 21:35:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 21:35:14 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 21:35:14 - INFO - __main__ - Printing 3 examples
06/05/2022 21:35:14 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 21:35:14 - INFO - __main__ - ['entailed']
06/05/2022 21:35:14 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 21:35:14 - INFO - __main__ - ['entailed']
06/05/2022 21:35:14 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 21:35:14 - INFO - __main__ - ['entailed']
06/05/2022 21:35:14 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:35:32 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 21:35:32 - INFO - __main__ - task name: tab_fact
06/05/2022 21:35:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:35:33 - INFO - __main__ - Starting training!
06/05/2022 21:35:39 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:35:53 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 21:44:14 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_21_0.4_8_predictions.txt
06/05/2022 21:44:14 - INFO - __main__ - Classification-F1 on test data: 0.0835
06/05/2022 21:44:14 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.4, bsz=8, dev_performance=0.5730170496664195, test_performance=0.08346332713411508
06/05/2022 21:44:14 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.3, bsz=8 ...
06/05/2022 21:44:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 21:44:15 - INFO - __main__ - Printing 3 examples
06/05/2022 21:44:15 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 21:44:15 - INFO - __main__ - ['entailed']
06/05/2022 21:44:15 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 21:44:15 - INFO - __main__ - ['entailed']
06/05/2022 21:44:15 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 21:44:15 - INFO - __main__ - ['entailed']
06/05/2022 21:44:15 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:44:15 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:44:15 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 21:44:15 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 21:44:15 - INFO - __main__ - Printing 3 examples
06/05/2022 21:44:15 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 21:44:15 - INFO - __main__ - ['entailed']
06/05/2022 21:44:15 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 21:44:15 - INFO - __main__ - ['entailed']
06/05/2022 21:44:15 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 21:44:15 - INFO - __main__ - ['entailed']
06/05/2022 21:44:15 - INFO - __main__ - Tokenizing Input ...
06/05/2022 21:44:15 - INFO - __main__ - Tokenizing Output ...
06/05/2022 21:44:16 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 21:44:34 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 21:44:34 - INFO - __main__ - task name: tab_fact
06/05/2022 21:44:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 21:44:35 - INFO - __main__ - Starting training!
06/05/2022 21:44:40 - INFO - __main__ - Step 10 Global step 10 Train loss 4.91 on epoch=2
06/05/2022 21:44:44 - INFO - __main__ - Step 20 Global step 20 Train loss 3.05 on epoch=4
06/05/2022 21:44:49 - INFO - __main__ - Step 30 Global step 30 Train loss 1.60 on epoch=7
06/05/2022 21:44:53 - INFO - __main__ - Step 40 Global step 40 Train loss 0.87 on epoch=9
06/05/2022 21:44:58 - INFO - __main__ - Step 50 Global step 50 Train loss 0.57 on epoch=12
06/05/2022 21:45:00 - INFO - __main__ - Global step 50 Train loss 2.20 Classification-F1 0.3333333333333333 on epoch=12
06/05/2022 21:45:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/05/2022 21:45:05 - INFO - __main__ - Step 60 Global step 60 Train loss 0.48 on epoch=14
06/05/2022 21:45:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.46 on epoch=17
06/05/2022 21:45:14 - INFO - __main__ - Step 80 Global step 80 Train loss 0.40 on epoch=19
06/05/2022 21:45:18 - INFO - __main__ - Step 90 Global step 90 Train loss 0.36 on epoch=22
06/05/2022 21:45:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.34 on epoch=24
06/05/2022 21:45:26 - INFO - __main__ - Global step 100 Train loss 0.41 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 21:45:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.33 on epoch=27
06/05/2022 21:45:35 - INFO - __main__ - Step 120 Global step 120 Train loss 0.29 on epoch=29
06/05/2022 21:45:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.35 on epoch=32
06/05/2022 21:45:44 - INFO - __main__ - Step 140 Global step 140 Train loss 0.27 on epoch=34
06/05/2022 21:45:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.26 on epoch=37
06/05/2022 21:45:51 - INFO - __main__ - Global step 150 Train loss 0.30 Classification-F1 0.3333333333333333 on epoch=37
06/05/2022 21:45:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.30 on epoch=39
06/05/2022 21:46:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=42
06/05/2022 21:46:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=44
06/05/2022 21:46:09 - INFO - __main__ - Step 190 Global step 190 Train loss 0.30 on epoch=47
06/05/2022 21:46:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.23 on epoch=49
06/05/2022 21:46:16 - INFO - __main__ - Global step 200 Train loss 0.28 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 21:46:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=52
06/05/2022 21:46:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.25 on epoch=54
06/05/2022 21:46:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.22 on epoch=57
06/05/2022 21:46:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.28 on epoch=59
06/05/2022 21:46:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.23 on epoch=62
06/05/2022 21:46:41 - INFO - __main__ - Global step 250 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 21:46:46 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=64
06/05/2022 21:46:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=67
06/05/2022 21:46:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.20 on epoch=69
06/05/2022 21:46:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/05/2022 21:47:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.26 on epoch=74
06/05/2022 21:47:06 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.22695035460992907 on epoch=74
06/05/2022 21:47:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/05/2022 21:47:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=79
06/05/2022 21:47:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=82
06/05/2022 21:47:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/05/2022 21:47:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/05/2022 21:47:31 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 21:47:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/05/2022 21:47:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/05/2022 21:47:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/05/2022 21:47:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/05/2022 21:47:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/05/2022 21:47:56 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.3671451355661882 on epoch=99
06/05/2022 21:47:56 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.3671451355661882 on epoch=99, global_step=400
06/05/2022 21:48:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=102
06/05/2022 21:48:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/05/2022 21:48:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=107
06/05/2022 21:48:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=109
06/05/2022 21:48:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/05/2022 21:48:22 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.3992490613266583 on epoch=112
06/05/2022 21:48:22 - INFO - __main__ - Saving model with best Classification-F1: 0.3671451355661882 -> 0.3992490613266583 on epoch=112, global_step=450
06/05/2022 21:48:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/05/2022 21:48:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/05/2022 21:48:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/05/2022 21:48:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=122
06/05/2022 21:48:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/05/2022 21:48:47 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.22456140350877193 on epoch=124
06/05/2022 21:48:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=127
06/05/2022 21:48:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/05/2022 21:49:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=132
06/05/2022 21:49:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/05/2022 21:49:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/05/2022 21:49:12 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.21212121212121213 on epoch=137
06/05/2022 21:49:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=139
06/05/2022 21:49:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/05/2022 21:49:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/05/2022 21:49:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=147
06/05/2022 21:49:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/05/2022 21:49:37 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.21245421245421245 on epoch=149
06/05/2022 21:49:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/05/2022 21:49:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=154
06/05/2022 21:49:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/05/2022 21:49:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/05/2022 21:50:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/05/2022 21:50:03 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.22456140350877193 on epoch=162
06/05/2022 21:50:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/05/2022 21:50:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/05/2022 21:50:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/05/2022 21:50:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/05/2022 21:50:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=174
06/05/2022 21:50:28 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.2051282051282051 on epoch=174
06/05/2022 21:50:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/05/2022 21:50:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=179
06/05/2022 21:50:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/05/2022 21:50:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=184
06/05/2022 21:50:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=187
06/05/2022 21:50:54 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.2471523748119493 on epoch=187
06/05/2022 21:50:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
06/05/2022 21:51:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=192
06/05/2022 21:51:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/05/2022 21:51:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/05/2022 21:51:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/05/2022 21:51:19 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.2068965517241379 on epoch=199
06/05/2022 21:51:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/05/2022 21:51:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=204
06/05/2022 21:51:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=207
06/05/2022 21:51:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=209
06/05/2022 21:51:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/05/2022 21:51:44 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.2471523748119493 on epoch=212
06/05/2022 21:51:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/05/2022 21:51:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/05/2022 21:51:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=219
06/05/2022 21:52:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=222
06/05/2022 21:52:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=224
06/05/2022 21:52:10 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=224
06/05/2022 21:52:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=227
06/05/2022 21:52:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/05/2022 21:52:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/05/2022 21:52:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/05/2022 21:52:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=237
06/05/2022 21:52:35 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.22456140350877193 on epoch=237
06/05/2022 21:52:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/05/2022 21:52:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=242
06/05/2022 21:52:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/05/2022 21:52:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=247
06/05/2022 21:52:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=249
06/05/2022 21:53:00 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.3891547049441786 on epoch=249
06/05/2022 21:53:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/05/2022 21:53:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=254
06/05/2022 21:53:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=257
06/05/2022 21:53:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=259
06/05/2022 21:53:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=262
06/05/2022 21:53:25 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.22456140350877193 on epoch=262
06/05/2022 21:53:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=264
06/05/2022 21:53:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=267
06/05/2022 21:53:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/05/2022 21:53:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=272
06/05/2022 21:53:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=274
06/05/2022 21:53:50 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.2793650793650793 on epoch=274
06/05/2022 21:53:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=277
06/05/2022 21:53:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=279
06/05/2022 21:54:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=282
06/05/2022 21:54:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=284
06/05/2022 21:54:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=287
06/05/2022 21:54:15 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.2589959060547296 on epoch=287
06/05/2022 21:54:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=289
06/05/2022 21:54:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=292
06/05/2022 21:54:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=294
06/05/2022 21:54:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=297
06/05/2022 21:54:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=299
06/05/2022 21:54:40 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.35478499363306887 on epoch=299
06/05/2022 21:54:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=302
06/05/2022 21:54:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=304
06/05/2022 21:54:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=307
06/05/2022 21:54:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=309
06/05/2022 21:55:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=312
06/05/2022 21:55:06 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.33001508295625936 on epoch=312
06/05/2022 21:55:10 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.19 on epoch=314
06/05/2022 21:55:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=317
06/05/2022 21:55:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/05/2022 21:55:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=322
06/05/2022 21:55:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/05/2022 21:55:31 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.4589371980676329 on epoch=324
06/05/2022 21:55:31 - INFO - __main__ - Saving model with best Classification-F1: 0.3992490613266583 -> 0.4589371980676329 on epoch=324, global_step=1300
06/05/2022 21:55:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=327
06/05/2022 21:55:40 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=329
06/05/2022 21:55:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=332
06/05/2022 21:55:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=334
06/05/2022 21:55:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.18 on epoch=337
06/05/2022 21:55:56 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.29365079365079366 on epoch=337
06/05/2022 21:56:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=339
06/05/2022 21:56:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=342
06/05/2022 21:56:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=344
06/05/2022 21:56:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=347
06/05/2022 21:56:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=349
06/05/2022 21:56:22 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.503078982597055 on epoch=349
06/05/2022 21:56:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4589371980676329 -> 0.503078982597055 on epoch=349, global_step=1400
06/05/2022 21:56:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=352
06/05/2022 21:56:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=354
06/05/2022 21:56:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/05/2022 21:56:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=359
06/05/2022 21:56:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=362
06/05/2022 21:56:47 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.3813209494324045 on epoch=362
06/05/2022 21:56:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=364
06/05/2022 21:56:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=367
06/05/2022 21:57:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=369
06/05/2022 21:57:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=372
06/05/2022 21:57:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/05/2022 21:57:12 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.380952380952381 on epoch=374
06/05/2022 21:57:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.15 on epoch=377
06/05/2022 21:57:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=379
06/05/2022 21:57:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=382
06/05/2022 21:57:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/05/2022 21:57:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=387
06/05/2022 21:57:38 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.3979727484214024 on epoch=387
06/05/2022 21:57:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=389
06/05/2022 21:57:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=392
06/05/2022 21:57:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=394
06/05/2022 21:57:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=397
06/05/2022 21:58:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=399
06/05/2022 21:58:03 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.5273745861981156 on epoch=399
06/05/2022 21:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.503078982597055 -> 0.5273745861981156 on epoch=399, global_step=1600
06/05/2022 21:58:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/05/2022 21:58:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=404
06/05/2022 21:58:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/05/2022 21:58:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=409
06/05/2022 21:58:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
06/05/2022 21:58:29 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5666666666666667 on epoch=412
06/05/2022 21:58:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5273745861981156 -> 0.5666666666666667 on epoch=412, global_step=1650
06/05/2022 21:58:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/05/2022 21:58:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=417
06/05/2022 21:58:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=419
06/05/2022 21:58:47 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/05/2022 21:58:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=424
06/05/2022 21:58:56 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.539313399778516 on epoch=424
06/05/2022 21:59:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/05/2022 21:59:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/05/2022 21:59:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=432
06/05/2022 21:59:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=434
06/05/2022 21:59:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
06/05/2022 21:59:23 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.539313399778516 on epoch=437
06/05/2022 21:59:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/05/2022 21:59:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/05/2022 21:59:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/05/2022 21:59:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=447
06/05/2022 21:59:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/05/2022 21:59:51 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.5465587044534412 on epoch=449
06/05/2022 21:59:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/05/2022 22:00:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/05/2022 22:00:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/05/2022 22:00:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/05/2022 22:00:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/05/2022 22:00:16 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.26136363636363635 on epoch=462
06/05/2022 22:00:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=464
06/05/2022 22:00:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=467
06/05/2022 22:00:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=469
06/05/2022 22:00:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/05/2022 22:00:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/05/2022 22:00:41 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.3383367839889579 on epoch=474
06/05/2022 22:00:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/05/2022 22:00:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/05/2022 22:00:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/05/2022 22:01:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=484
06/05/2022 22:01:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/05/2022 22:01:09 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.571619812583668 on epoch=487
06/05/2022 22:01:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5666666666666667 -> 0.571619812583668 on epoch=487, global_step=1950
06/05/2022 22:01:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/05/2022 22:01:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/05/2022 22:01:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=494
06/05/2022 22:01:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/05/2022 22:01:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/05/2022 22:01:36 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.36556995679627785 on epoch=499
06/05/2022 22:01:41 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/05/2022 22:01:45 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/05/2022 22:01:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/05/2022 22:01:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/05/2022 22:01:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/05/2022 22:02:03 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.5515515515515517 on epoch=512
06/05/2022 22:02:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/05/2022 22:02:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=517
06/05/2022 22:02:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/05/2022 22:02:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/05/2022 22:02:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/05/2022 22:02:29 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.26785714285714285 on epoch=524
06/05/2022 22:02:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/05/2022 22:02:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/05/2022 22:02:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/05/2022 22:02:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/05/2022 22:02:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/05/2022 22:02:54 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.5730170496664195 on epoch=537
06/05/2022 22:02:54 - INFO - __main__ - Saving model with best Classification-F1: 0.571619812583668 -> 0.5730170496664195 on epoch=537, global_step=2150
06/05/2022 22:02:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/05/2022 22:03:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=542
06/05/2022 22:03:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/05/2022 22:03:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/05/2022 22:03:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/05/2022 22:03:19 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.5607843137254902 on epoch=549
06/05/2022 22:03:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/05/2022 22:03:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/05/2022 22:03:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/05/2022 22:03:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/05/2022 22:03:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/05/2022 22:03:44 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.5789473684210527 on epoch=562
06/05/2022 22:03:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5730170496664195 -> 0.5789473684210527 on epoch=562, global_step=2250
06/05/2022 22:03:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/05/2022 22:03:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/05/2022 22:03:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=569
06/05/2022 22:04:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/05/2022 22:04:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/05/2022 22:04:10 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.5607843137254902 on epoch=574
06/05/2022 22:04:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/05/2022 22:04:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/05/2022 22:04:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/05/2022 22:04:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/05/2022 22:04:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/05/2022 22:04:35 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.268909688843916 on epoch=587
06/05/2022 22:04:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/05/2022 22:04:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/05/2022 22:04:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/05/2022 22:04:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/05/2022 22:04:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/05/2022 22:05:00 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5797215655371684 on epoch=599
06/05/2022 22:05:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5789473684210527 -> 0.5797215655371684 on epoch=599, global_step=2400
06/05/2022 22:05:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/05/2022 22:05:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/05/2022 22:05:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/05/2022 22:05:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/05/2022 22:05:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/05/2022 22:05:25 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.35202020202020207 on epoch=612
06/05/2022 22:05:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/05/2022 22:05:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/05/2022 22:05:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/05/2022 22:05:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/05/2022 22:05:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/05/2022 22:05:52 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.3547588561673069 on epoch=624
06/05/2022 22:05:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=627
06/05/2022 22:06:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/05/2022 22:06:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/05/2022 22:06:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/05/2022 22:06:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/05/2022 22:06:17 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.36739417989417983 on epoch=637
06/05/2022 22:06:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/05/2022 22:06:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/05/2022 22:06:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/05/2022 22:06:35 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/05/2022 22:06:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/05/2022 22:06:42 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.36017316017316015 on epoch=649
06/05/2022 22:06:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/05/2022 22:06:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/05/2022 22:06:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/05/2022 22:07:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/05/2022 22:07:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/05/2022 22:07:08 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5126504544338 on epoch=662
06/05/2022 22:07:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/05/2022 22:07:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/05/2022 22:07:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/05/2022 22:07:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/05/2022 22:07:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/05/2022 22:07:33 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5413886829750433 on epoch=674
06/05/2022 22:07:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=677
06/05/2022 22:07:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/05/2022 22:07:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/05/2022 22:07:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/05/2022 22:07:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/05/2022 22:07:59 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.37979593557635544 on epoch=687
06/05/2022 22:08:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/05/2022 22:08:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/05/2022 22:08:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/05/2022 22:08:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/05/2022 22:08:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/05/2022 22:08:25 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.3779761904761905 on epoch=699
06/05/2022 22:08:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/05/2022 22:08:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/05/2022 22:08:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 22:08:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/05/2022 22:08:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/05/2022 22:08:50 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.3777115416459678 on epoch=712
06/05/2022 22:08:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/05/2022 22:09:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/05/2022 22:09:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/05/2022 22:09:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/05/2022 22:09:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/05/2022 22:09:16 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.2519561815336463 on epoch=724
06/05/2022 22:09:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 22:09:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/05/2022 22:09:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/05/2022 22:09:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/05/2022 22:09:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 22:09:42 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.577195987276731 on epoch=737
06/05/2022 22:09:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/05/2022 22:09:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/05/2022 22:09:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/05/2022 22:10:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/05/2022 22:10:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/05/2022 22:10:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:10:06 - INFO - __main__ - Printing 3 examples
06/05/2022 22:10:06 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 22:10:06 - INFO - __main__ - ['entailed']
06/05/2022 22:10:06 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 22:10:06 - INFO - __main__ - ['entailed']
06/05/2022 22:10:06 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 22:10:06 - INFO - __main__ - ['entailed']
06/05/2022 22:10:06 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:10:06 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:10:06 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 22:10:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:10:06 - INFO - __main__ - Printing 3 examples
06/05/2022 22:10:06 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 22:10:06 - INFO - __main__ - ['entailed']
06/05/2022 22:10:06 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 22:10:06 - INFO - __main__ - ['entailed']
06/05/2022 22:10:06 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 22:10:06 - INFO - __main__ - ['entailed']
06/05/2022 22:10:06 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:10:06 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:10:06 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 22:10:07 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.26191677175283734 on epoch=749
06/05/2022 22:10:07 - INFO - __main__ - save last model!
06/05/2022 22:10:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 22:10:07 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 22:10:07 - INFO - __main__ - Printing 3 examples
06/05/2022 22:10:07 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 22:10:07 - INFO - __main__ - ['entailed']
06/05/2022 22:10:07 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 22:10:07 - INFO - __main__ - ['entailed']
06/05/2022 22:10:07 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 22:10:07 - INFO - __main__ - ['entailed']
06/05/2022 22:10:07 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:10:25 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 22:10:25 - INFO - __main__ - task name: tab_fact
06/05/2022 22:10:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:10:25 - INFO - __main__ - Starting training!
06/05/2022 22:10:32 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:10:45 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 22:19:19 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_21_0.3_8_predictions.txt
06/05/2022 22:19:19 - INFO - __main__ - Classification-F1 on test data: 0.1626
06/05/2022 22:19:20 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.3, bsz=8, dev_performance=0.5797215655371684, test_performance=0.16257483338289758
06/05/2022 22:19:20 - INFO - __main__ - Running ... prefix=tab_fact_32_21, lr=0.2, bsz=8 ...
06/05/2022 22:19:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:19:21 - INFO - __main__ - Printing 3 examples
06/05/2022 22:19:21 - INFO - __main__ -  [tab_fact] statement: the hellman award and the sydney theater award both nominated glinda from wicked [SEP] table_caption: lucy durack [SEP] table_text: year#award ceremony#role#production#result [n] 2008#green room awards#glinda#wicked#nominated [n] 2009#helpmann awards#glinda#wicked#nominated [n] 2009#sydney theatre awards#glinda#wicked#nominated [n] 2012#sydney theatre awards#elle woods#legally blonde#won [n] 2013#helpmann awards#elle woods#legally blonde#won [n] 
06/05/2022 22:19:21 - INFO - __main__ - ['entailed']
06/05/2022 22:19:21 - INFO - __main__ -  [tab_fact] statement: each of the team play an equal number of game [SEP] table_caption: wru division five south east [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus [n] porth harlequins rfc#20#0#3#642#173#100#19#12 [n] st joseph 's rfc#20#0#3#503#179#69#17#9 [n] pontyclun rfc#20#1#5#468#218#66#24#7 [n] deri rfc#20#0#6#476#285#65#33#7 [n] st albans rfc#20#0#9#402#423#58#61#7 [n] cowbridge rfc#20#0#12#329#379#37#54#3 [n] old penarthians rfc#20#0#11#231#369#29#53#2 [n] penygraig rfc#20#1#13#260#436#30#63#2 [n] ogmore vale rfc#20#0#14#208#475#27#71#2 [n] canton rfc#20#0#16#248#499#34#67#3 [n] dinas powys rfc#20#0#17#161#492#20#73#1 [n] 
06/05/2022 22:19:21 - INFO - __main__ - ['entailed']
06/05/2022 22:19:21 - INFO - __main__ -  [tab_fact] statement: there be a total of 3 driver from the jordan ford entrant [SEP] table_caption: 2003 formula one season [SEP] table_text: entrant#constructor#chassis#engine#tyre#driver#rounds#free practice driver (s) [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#michael schumacher#all#n / a [n] scuderia ferrari marlboro#ferrari#f2002 f2003 - ga#ferrari 051 ferrari 052#b#rubens barrichello#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#juan pablo montoya#all#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#ralf schumacher#1 - 13 , 15 - 16#n / a [n] bmw williamsf1 team#williams - bmw#fw25#bmw p83#m#marc gené#14#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#david coulthard#all#n / a [n] west mclaren mercedes#mclaren - mercedes#mp4 - 17d#mercedes fo110 m mercedes fo110p#m#kimi räikkönen#all#n / a [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#jarno trulli#all#allan mcnish franck montagny [n] mild seven renault f1 team#renault#r23 r23b#renault rs23#m#fernando alonso#all#allan mcnish franck montagny [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#nick heidfeld#all#n / a [n] sauber petronas#sauber - petronas#c22#petronas 03a#b#heinz - harald frentzen#all#n / a [n] jordan ford#jordan - ford#ej13#ford rs1#b#giancarlo fisichella#all#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#ralph firman#1 - 12 , 15 - 16#zsolt baumgartner björn wirdheim satoshi motoyama [n] jordan ford#jordan - ford#ej13#ford rs1#b#zsolt baumgartner#13 - 14#zsolt baumgartner björn wirdheim satoshi motoyama [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#mark webber#all#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#antônio pizzonia#1 - 11#n / a [n] jaguar racing#jaguar - cosworth#r4#cosworth cr - 5#m#justin wilson#12 - 16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jacques villeneuve#1 - 15#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#takuma sato#16#n / a [n] lucky strike bar honda#bar - honda#005#honda ra003e#b#jenson button#all#n / a [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#justin wilson#1 - 11#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#nicolas kiesa#12 - 16#matteo bobbi gianmaria bruni [n] european minardi cosworth#minardi - cosworth#ps03#cosworth cr - 3#b#jos verstappen#all#matteo bobbi gianmaria bruni [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#olivier panis#all#n / a [n] panasonic toyota racing#toyota#tf103#toyota rvx - 03#m#cristiano da matta#all#n / a [n] 
06/05/2022 22:19:21 - INFO - __main__ - ['entailed']
06/05/2022 22:19:21 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:19:21 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:19:21 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 22:19:21 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:19:21 - INFO - __main__ - Printing 3 examples
06/05/2022 22:19:21 - INFO - __main__ -  [tab_fact] statement: audiogo be the company for pinborough , sarah sarah pinborough [SEP] table_caption: list of doctor who audiobooks [SEP] table_text: title#author#reader#format#company#release date#notes [n] another life#anghelides , peter peter anghelides#barrowman , john john barrowman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] slow decay#lane , andy andy lane#gorman , burn burn gorman#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] border princes#abnett , dan dan abnett#myles , eve eve myles#3 - cd#bbc audio#2007 - 04 - 02 2 april 2007#abridged [n] hidden#saville , steven steven savile#mori , naoko naoko mori#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] everyone says hello#abnett , dan dan abnett#gorman , burn burn gorman#2 - cd#bbc audio#2008 - 02 - 04 4 february 2008#an original audiobook , not published in book form [n] in the shadows#lidster , joseph joseph lidster#myles , eve eve myles#2 - cd#bbc audio#2009 - 05 - 07 7 may 2009#an original audiobook , not published in book form [n] the sin eaters#minchin , brian brian minchin#david - lloyd , gareth gareth david - lloyd#2 - cd#bbc audio#2009 - 06 - 04 4 june 2009#an original audiobook , not published in book form [n] department x#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] ghost train#goss , james james goss#owen , kai kai owen#2 - cd#bbc audio#2011 - 04 - 03 3 march 2011#an original audiobook , not published in book form [n] long time dead#pinborough , sarah sarah pinborough#varma , idria indira varma#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] the men who sold the world#adams , guy guy adams#telfer , john john telfer#download#audiogo#2011 - 10 - 01 october 2011#unabridged [n] army of one#edginton , ian ian edginton#owen , kai kai owen#download / cd#audiogo#2012 - 03 - 08 8 march 2012#an original audiobook , not published in book form [n] fallout#llewellyn , david david llewellyn#price , tom tom price#download / cd#audiogo#2012 - 04 - 05 5 april 2012#an original audiobook , not published in book form [n] red skies#lidster , joseph joseph lidster#telfer , john john telfer#download / cd#audiogo#2012 - 05 - 03 3 may 2012#an original audiobook , not published in book form [n] 
06/05/2022 22:19:21 - INFO - __main__ - ['entailed']
06/05/2022 22:19:21 - INFO - __main__ -  [tab_fact] statement: the majority of àlex corretja 's game take place on clay surface [SEP] table_caption: àlex corretja [SEP] table_text: outcome#date#championship#surface#opponent in the final#score in the final [n] runner - up#2 november 1992#guarujá , brazil#hard#carsten arriens#6 - 7 , 3 - 6 [n] runner - up#3 october 1994#palermo , italy#clay#alberto berasategui#6 - 2 , 6 - 7 (6 - 8) , 4 - 6 [n] winner#14 november 1994#buenos aires , argentina#clay#javier frana#6 - 3 , 5 - 7 , 7 - 6 (7 - 5) [n] runner - up#13 may 1996#hamburg , germany#clay#roberto carretero#6 - 2 , 4 - 6 , 4 - 6 , 4 - 6 [n] runner - up#29 july 1996#kitzbühel , austria#clay#alberto berasategui#2 - 6 , 4 - 6 , 4 - 6 [n] runner - up#7 october 1996#marbella , spain#clay#marc - kevin goellner#6 - 7 (4 - 7) , 6 - 7 (2 - 7) [n] winner#14 april 1997#estoril , portugal#clay#francisco clavet#6 - 3 , 7 - 5 [n] runner - up#28 april 1997#monte carlo , monaco#clay#marcelo ríos#4 - 6 , 4 - 6 , 3 - 6 [n] runner - up#5 may 1997#munich , germany#clay#mark philippoussis#6 - 7 , 6 - 1 , 4 - 6 [n] winner#19 may 1997#rome , italy#clay#marcelo ríos#7 - 5 , 7 - 5 , 6 - 3 [n] winner#21 july 1997#stuttgart outdoor , germany#clay#karol kučera#6 - 2 , 7 - 5 [n] winner#16 february 1998#dubai , uae#hard#félix mantilla botella#7 - 6 (7 - 0) , 6 - 0 [n] runner - up#11 may 1998#hamburg , germany#clay#albert costa#2 - 6 , 0 - 6 , 0 - 1 , ret [n] runner - up#8 june 1998#french open , paris , france#clay#carlos moyà#3 - 6 , 5 - 7 , 3 - 6 [n] winner#13 july 1998#gstaad , switzerland#clay#boris becker#7 - 6 (7 - 5) , 7 - 5 , 6 - 3 [n] winner#24 august 1998#indianapolis , us#hard#andre agassi#2 - 6 , 6 - 2 , 6 - 3 [n] winner#26 october 1998#lyon , france#carpet#tommy haas#2 - 6 , 7 - 6 (8 - 6) , 6 - 1 [n] winner#30 november 1998#tennis masters cup , hanover , germany#hard#carlos moyà#3 - 6 , 3 - 6 , 7 - 5 , 6 - 3 , 7 - 5 [n] runner - up#18 january 1999#sydney , australia#hard#todd martin#3 - 6 , 6 - 7 [n] runner - up#30 august 1999#long island , us#hard#magnus norman#6 - 7 (4 - 7) , 6 - 4 , 3 - 6 [n] runner - up#20 september 1999#mallorca , spain#clay#juan carlos ferrero#6 - 2 , 5 - 7 , 3 - 6 [n] winner#20 march 2000#indian wells , us#hard#thomas enqvist#6 - 4 , 6 - 4 , 6 - 3 [n] winner#17 july 2000#gstaad , switzerland#clay#mariano puerta#6 - 1 , 6 - 3 [n] winner#30 july 2000#kitzbühel , austria#clay#emilio benfele álvarez#6 - 3 , 6 - 1 , 3 - 0 retired [n] winner#21 august 2000#washington , us#hard#andre agassi#6 - 2 , 6 - 3 [n] winner#23 october 2000#toulouse , france#hard#carlos moyà#6 - 3 , 6 - 2 [n] runner - up#11 june 2001#french open , paris , france#clay#gustavo kuerten#7 - 6 (7 - 3) , 5 - 7 , 2 - 6 , 0 - 6 [n] winner#23 july 2001#amsterdam , netherlands#clay#younes el aynaoui#6 - 3 , 5 - 7 , 7 - 6 (7 - 0) , 3 - 6 , 6 - 4 [n] winner#15 july 2002#gstaad , switzerland#clay#gastón gaudio#6 - 3 , 7 - 6 (7 - 3) , 7 - 6 (7 - 3) [n] winner#29 july 2002#kitzbühel , austria#clay#juan carlos ferrero#6 - 4 , 6 - 1 , 6 - 3 [n] 
06/05/2022 22:19:21 - INFO - __main__ - ['entailed']
06/05/2022 22:19:21 - INFO - __main__ -  [tab_fact] statement: 2 pick come from missouri state [SEP] table_caption: atlanta falcons draft history [SEP] table_text: round#pick#overall#name#position#college [n] 1#2#2#tony casillas#defensive tackle#oklahoma [n] 1#17#17#tim green#linebacker#syracuse [n] 6#16#154#floyd dixon#wide receiver#stephen f austin [n] 6#21#159#keith williams#wide receiver#southwest missouri state [n] 8#3#197#kevin hudgens#defensive end#idaho state [n] 9#3#224#kevin starks#tight end#minnesota [n] 10#3#252#tony baker#running back#east carolina [n] 11#3#280#chris hegg#quarterback#northeast missouri state [n] 12#3#308#steve griffin#wide receiver#purdue [n] 
06/05/2022 22:19:21 - INFO - __main__ - ['entailed']
06/05/2022 22:19:21 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:19:21 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:19:21 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 22:19:40 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 22:19:40 - INFO - __main__ - task name: tab_fact
06/05/2022 22:19:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:19:41 - INFO - __main__ - Starting training!
06/05/2022 22:19:46 - INFO - __main__ - Step 10 Global step 10 Train loss 5.28 on epoch=2
06/05/2022 22:19:50 - INFO - __main__ - Step 20 Global step 20 Train loss 3.42 on epoch=4
06/05/2022 22:19:55 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=7
06/05/2022 22:19:59 - INFO - __main__ - Step 40 Global step 40 Train loss 1.17 on epoch=9
06/05/2022 22:20:04 - INFO - __main__ - Step 50 Global step 50 Train loss 0.80 on epoch=12
06/05/2022 22:20:07 - INFO - __main__ - Global step 50 Train loss 2.54 Classification-F1 0.3333333333333333 on epoch=12
06/05/2022 22:20:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/05/2022 22:20:11 - INFO - __main__ - Step 60 Global step 60 Train loss 0.54 on epoch=14
06/05/2022 22:20:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.51 on epoch=17
06/05/2022 22:20:20 - INFO - __main__ - Step 80 Global step 80 Train loss 0.47 on epoch=19
06/05/2022 22:20:25 - INFO - __main__ - Step 90 Global step 90 Train loss 0.39 on epoch=22
06/05/2022 22:20:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.29 on epoch=24
06/05/2022 22:20:32 - INFO - __main__ - Global step 100 Train loss 0.44 Classification-F1 0.5873015873015872 on epoch=24
06/05/2022 22:20:32 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.5873015873015872 on epoch=24, global_step=100
06/05/2022 22:20:37 - INFO - __main__ - Step 110 Global step 110 Train loss 0.31 on epoch=27
06/05/2022 22:20:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.33 on epoch=29
06/05/2022 22:20:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=32
06/05/2022 22:20:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/05/2022 22:20:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=37
06/05/2022 22:20:57 - INFO - __main__ - Global step 150 Train loss 0.30 Classification-F1 0.5866701110824076 on epoch=37
06/05/2022 22:21:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.33 on epoch=39
06/05/2022 22:21:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.29 on epoch=42
06/05/2022 22:21:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=44
06/05/2022 22:21:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.27 on epoch=47
06/05/2022 22:21:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.31 on epoch=49
06/05/2022 22:21:23 - INFO - __main__ - Global step 200 Train loss 0.29 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 22:21:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.22 on epoch=52
06/05/2022 22:21:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.23 on epoch=54
06/05/2022 22:21:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.22 on epoch=57
06/05/2022 22:21:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=59
06/05/2022 22:21:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=62
06/05/2022 22:21:48 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 22:21:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.24 on epoch=64
06/05/2022 22:21:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/05/2022 22:22:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/05/2022 22:22:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=72
06/05/2022 22:22:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.20 on epoch=74
06/05/2022 22:22:14 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=74
06/05/2022 22:22:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=77
06/05/2022 22:22:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/05/2022 22:22:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/05/2022 22:22:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/05/2022 22:22:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=87
06/05/2022 22:22:39 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 22:22:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/05/2022 22:22:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/05/2022 22:22:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/05/2022 22:22:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
06/05/2022 22:23:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
06/05/2022 22:23:05 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=99
06/05/2022 22:23:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/05/2022 22:23:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/05/2022 22:23:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/05/2022 22:23:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/05/2022 22:23:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/05/2022 22:23:30 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.5465587044534412 on epoch=112
06/05/2022 22:23:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=114
06/05/2022 22:23:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=117
06/05/2022 22:23:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/05/2022 22:23:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=122
06/05/2022 22:23:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=124
06/05/2022 22:23:56 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=124
06/05/2022 22:24:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
06/05/2022 22:24:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/05/2022 22:24:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/05/2022 22:24:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=134
06/05/2022 22:24:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/05/2022 22:24:21 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=137
06/05/2022 22:24:26 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/05/2022 22:24:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=142
06/05/2022 22:24:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=144
06/05/2022 22:24:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
06/05/2022 22:24:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/05/2022 22:24:47 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=149
06/05/2022 22:24:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/05/2022 22:24:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/05/2022 22:25:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=157
06/05/2022 22:25:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=159
06/05/2022 22:25:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=162
06/05/2022 22:25:12 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.32631578947368417 on epoch=162
06/05/2022 22:25:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=164
06/05/2022 22:25:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/05/2022 22:25:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/05/2022 22:25:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=172
06/05/2022 22:25:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.21 on epoch=174
06/05/2022 22:25:38 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 22:25:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/05/2022 22:25:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=179
06/05/2022 22:25:51 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=182
06/05/2022 22:25:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/05/2022 22:26:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=187
06/05/2022 22:26:03 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.32631578947368417 on epoch=187
06/05/2022 22:26:08 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=189
06/05/2022 22:26:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=192
06/05/2022 22:26:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/05/2022 22:26:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/05/2022 22:26:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=199
06/05/2022 22:26:29 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.3591989987484355 on epoch=199
06/05/2022 22:26:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/05/2022 22:26:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/05/2022 22:26:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/05/2022 22:26:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=209
06/05/2022 22:26:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/05/2022 22:26:54 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.3511520737327189 on epoch=212
06/05/2022 22:26:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=214
06/05/2022 22:27:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/05/2022 22:27:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/05/2022 22:27:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=222
06/05/2022 22:27:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/05/2022 22:27:20 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.36374269005847953 on epoch=224
06/05/2022 22:27:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=227
06/05/2022 22:27:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/05/2022 22:27:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=232
06/05/2022 22:27:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=234
06/05/2022 22:27:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=237
06/05/2022 22:27:45 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.4079058031959629 on epoch=237
06/05/2022 22:27:50 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/05/2022 22:27:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=242
06/05/2022 22:27:59 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=244
06/05/2022 22:28:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=247
06/05/2022 22:28:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=249
06/05/2022 22:28:11 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.3191489361702127 on epoch=249
06/05/2022 22:28:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/05/2022 22:28:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=254
06/05/2022 22:28:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=257
06/05/2022 22:28:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=259
06/05/2022 22:28:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=262
06/05/2022 22:28:36 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.3511520737327189 on epoch=262
06/05/2022 22:28:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=264
06/05/2022 22:28:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=267
06/05/2022 22:28:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=269
06/05/2022 22:28:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=272
06/05/2022 22:28:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=274
06/05/2022 22:29:02 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=274
06/05/2022 22:29:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=277
06/05/2022 22:29:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=279
06/05/2022 22:29:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=282
06/05/2022 22:29:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=284
06/05/2022 22:29:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.17 on epoch=287
06/05/2022 22:29:27 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.3043478260869565 on epoch=287
06/05/2022 22:29:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=289
06/05/2022 22:29:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=292
06/05/2022 22:29:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=294
06/05/2022 22:29:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/05/2022 22:29:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=299
06/05/2022 22:29:53 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.577195987276731 on epoch=299
06/05/2022 22:29:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=302
06/05/2022 22:30:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=304
06/05/2022 22:30:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=307
06/05/2022 22:30:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=309
06/05/2022 22:30:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=312
06/05/2022 22:30:18 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.48424908424908425 on epoch=312
06/05/2022 22:30:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=314
06/05/2022 22:30:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=317
06/05/2022 22:30:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=319
06/05/2022 22:30:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.19 on epoch=322
06/05/2022 22:30:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=324
06/05/2022 22:30:46 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.5205373288555928 on epoch=324
06/05/2022 22:30:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=327
06/05/2022 22:30:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=329
06/05/2022 22:30:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=332
06/05/2022 22:31:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=334
06/05/2022 22:31:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=337
06/05/2022 22:31:13 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.32472263619804603 on epoch=337
06/05/2022 22:31:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=339
06/05/2022 22:31:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=342
06/05/2022 22:31:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=344
06/05/2022 22:31:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=347
06/05/2022 22:31:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=349
06/05/2022 22:31:39 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.3333333333333333 on epoch=349
06/05/2022 22:31:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=352
06/05/2022 22:31:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=354
06/05/2022 22:31:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=357
06/05/2022 22:31:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=359
06/05/2022 22:32:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=362
06/05/2022 22:32:04 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.5126504544338 on epoch=362
06/05/2022 22:32:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=364
06/05/2022 22:32:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=367
06/05/2022 22:32:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=369
06/05/2022 22:32:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=372
06/05/2022 22:32:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/05/2022 22:32:30 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.3018575851393189 on epoch=374
06/05/2022 22:32:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=377
06/05/2022 22:32:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=379
06/05/2022 22:32:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=382
06/05/2022 22:32:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=384
06/05/2022 22:32:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=387
06/05/2022 22:32:55 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.3671451355661882 on epoch=387
06/05/2022 22:33:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=389
06/05/2022 22:33:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=392
06/05/2022 22:33:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=394
06/05/2022 22:33:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=397
06/05/2022 22:33:18 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=399
06/05/2022 22:33:21 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.48424908424908425 on epoch=399
06/05/2022 22:33:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=402
06/05/2022 22:33:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=404
06/05/2022 22:33:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=407
06/05/2022 22:33:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=409
06/05/2022 22:33:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=412
06/05/2022 22:33:47 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.4375 on epoch=412
06/05/2022 22:33:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=414
06/05/2022 22:33:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=417
06/05/2022 22:34:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=419
06/05/2022 22:34:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=422
06/05/2022 22:34:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/05/2022 22:34:12 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.4519207242476144 on epoch=424
06/05/2022 22:34:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=427
06/05/2022 22:34:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=429
06/05/2022 22:34:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=432
06/05/2022 22:34:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=434
06/05/2022 22:34:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=437
06/05/2022 22:34:37 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.48747093774218553 on epoch=437
06/05/2022 22:34:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=439
06/05/2022 22:34:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=442
06/05/2022 22:34:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=444
06/05/2022 22:34:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=447
06/05/2022 22:35:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=449
06/05/2022 22:35:03 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.4980392156862745 on epoch=449
06/05/2022 22:35:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=452
06/05/2022 22:35:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=454
06/05/2022 22:35:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/05/2022 22:35:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.14 on epoch=459
06/05/2022 22:35:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=462
06/05/2022 22:35:29 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.5145583557621727 on epoch=462
06/05/2022 22:35:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=464
06/05/2022 22:35:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=467
06/05/2022 22:35:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.15 on epoch=469
06/05/2022 22:35:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=472
06/05/2022 22:35:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=474
06/05/2022 22:35:54 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.500880503144654 on epoch=474
06/05/2022 22:35:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=477
06/05/2022 22:36:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=479
06/05/2022 22:36:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=482
06/05/2022 22:36:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=484
06/05/2022 22:36:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=487
06/05/2022 22:36:20 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.4465035829009143 on epoch=487
06/05/2022 22:36:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=489
06/05/2022 22:36:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=492
06/05/2022 22:36:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=494
06/05/2022 22:36:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/05/2022 22:36:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/05/2022 22:36:45 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.4832395400048935 on epoch=499
06/05/2022 22:36:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=502
06/05/2022 22:36:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/05/2022 22:36:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=507
06/05/2022 22:37:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/05/2022 22:37:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=512
06/05/2022 22:37:10 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.2909574468085106 on epoch=512
06/05/2022 22:37:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=514
06/05/2022 22:37:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=517
06/05/2022 22:37:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=519
06/05/2022 22:37:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=522
06/05/2022 22:37:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=524
06/05/2022 22:37:36 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.3148717948717949 on epoch=524
06/05/2022 22:37:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/05/2022 22:37:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/05/2022 22:37:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=532
06/05/2022 22:37:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=534
06/05/2022 22:37:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/05/2022 22:38:01 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.45299145299145294 on epoch=537
06/05/2022 22:38:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/05/2022 22:38:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/05/2022 22:38:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/05/2022 22:38:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=547
06/05/2022 22:38:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=549
06/05/2022 22:38:26 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.46218487394957986 on epoch=549
06/05/2022 22:38:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=552
06/05/2022 22:38:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/05/2022 22:38:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=557
06/05/2022 22:38:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=559
06/05/2022 22:38:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=562
06/05/2022 22:38:52 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.22856058689602832 on epoch=562
06/05/2022 22:38:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
06/05/2022 22:39:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/05/2022 22:39:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/05/2022 22:39:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=572
06/05/2022 22:39:14 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=574
06/05/2022 22:39:17 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.5155067155067155 on epoch=574
06/05/2022 22:39:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=577
06/05/2022 22:39:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=579
06/05/2022 22:39:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=582
06/05/2022 22:39:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=584
06/05/2022 22:39:40 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=587
06/05/2022 22:39:42 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.5145583557621727 on epoch=587
06/05/2022 22:39:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/05/2022 22:39:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/05/2022 22:39:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=594
06/05/2022 22:40:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=597
06/05/2022 22:40:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/05/2022 22:40:08 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.5145583557621727 on epoch=599
06/05/2022 22:40:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=602
06/05/2022 22:40:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=604
06/05/2022 22:40:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=607
06/05/2022 22:40:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/05/2022 22:40:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=612
06/05/2022 22:40:33 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.5126504544338 on epoch=612
06/05/2022 22:40:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/05/2022 22:40:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=617
06/05/2022 22:40:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/05/2022 22:40:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=622
06/05/2022 22:40:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/05/2022 22:40:58 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.5330817610062892 on epoch=624
06/05/2022 22:41:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=627
06/05/2022 22:41:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/05/2022 22:41:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=632
06/05/2022 22:41:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/05/2022 22:41:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=637
06/05/2022 22:41:23 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.23703516316721474 on epoch=637
06/05/2022 22:41:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=639
06/05/2022 22:41:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=642
06/05/2022 22:41:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/05/2022 22:41:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/05/2022 22:41:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/05/2022 22:41:49 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.2244766089428793 on epoch=649
06/05/2022 22:41:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/05/2022 22:41:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/05/2022 22:42:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=657
06/05/2022 22:42:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=659
06/05/2022 22:42:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=662
06/05/2022 22:42:14 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.5058530510585305 on epoch=662
06/05/2022 22:42:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=664
06/05/2022 22:42:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/05/2022 22:42:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=669
06/05/2022 22:42:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/05/2022 22:42:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/05/2022 22:42:40 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.37686939182452645 on epoch=674
06/05/2022 22:42:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/05/2022 22:42:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=679
06/05/2022 22:42:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/05/2022 22:42:58 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/05/2022 22:43:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=687
06/05/2022 22:43:05 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.5458771715194519 on epoch=687
06/05/2022 22:43:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/05/2022 22:43:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=692
06/05/2022 22:43:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=694
06/05/2022 22:43:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/05/2022 22:43:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/05/2022 22:43:30 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.2931623931623932 on epoch=699
06/05/2022 22:43:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/05/2022 22:43:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=704
06/05/2022 22:43:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/05/2022 22:43:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=709
06/05/2022 22:43:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/05/2022 22:43:56 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.3346600331674958 on epoch=712
06/05/2022 22:44:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/05/2022 22:44:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=717
06/05/2022 22:44:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/05/2022 22:44:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=722
06/05/2022 22:44:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/05/2022 22:44:21 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.5058530510585305 on epoch=724
06/05/2022 22:44:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/05/2022 22:44:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/05/2022 22:44:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/05/2022 22:44:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/05/2022 22:44:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/05/2022 22:44:47 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.46666666666666656 on epoch=737
06/05/2022 22:44:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/05/2022 22:44:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/05/2022 22:45:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/05/2022 22:45:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/05/2022 22:45:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/05/2022 22:45:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:45:11 - INFO - __main__ - Printing 3 examples
06/05/2022 22:45:11 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/05/2022 22:45:11 - INFO - __main__ - ['refuted']
06/05/2022 22:45:11 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/05/2022 22:45:11 - INFO - __main__ - ['refuted']
06/05/2022 22:45:11 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/05/2022 22:45:11 - INFO - __main__ - ['refuted']
06/05/2022 22:45:11 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:45:11 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:45:11 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 22:45:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:45:11 - INFO - __main__ - Printing 3 examples
06/05/2022 22:45:11 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/05/2022 22:45:11 - INFO - __main__ - ['refuted']
06/05/2022 22:45:11 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/05/2022 22:45:11 - INFO - __main__ - ['refuted']
06/05/2022 22:45:11 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/05/2022 22:45:11 - INFO - __main__ - ['refuted']
06/05/2022 22:45:11 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:45:11 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:45:11 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 22:45:12 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.46666666666666656 on epoch=749
06/05/2022 22:45:12 - INFO - __main__ - save last model!
06/05/2022 22:45:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 22:45:12 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 22:45:12 - INFO - __main__ - Printing 3 examples
06/05/2022 22:45:12 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 22:45:12 - INFO - __main__ - ['entailed']
06/05/2022 22:45:12 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 22:45:12 - INFO - __main__ - ['entailed']
06/05/2022 22:45:12 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 22:45:12 - INFO - __main__ - ['entailed']
06/05/2022 22:45:12 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:45:26 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 22:45:26 - INFO - __main__ - task name: tab_fact
06/05/2022 22:45:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:45:27 - INFO - __main__ - Starting training!
06/05/2022 22:45:36 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:45:50 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 22:54:19 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_21_0.2_8_predictions.txt
06/05/2022 22:54:19 - INFO - __main__ - Classification-F1 on test data: 0.0303
06/05/2022 22:54:19 - INFO - __main__ - prefix=tab_fact_32_21, lr=0.2, bsz=8, dev_performance=0.5873015873015872, test_performance=0.030282795694068877
06/05/2022 22:54:19 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.5, bsz=8 ...
06/05/2022 22:54:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:54:20 - INFO - __main__ - Printing 3 examples
06/05/2022 22:54:20 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/05/2022 22:54:20 - INFO - __main__ - ['refuted']
06/05/2022 22:54:20 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/05/2022 22:54:20 - INFO - __main__ - ['refuted']
06/05/2022 22:54:20 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/05/2022 22:54:20 - INFO - __main__ - ['refuted']
06/05/2022 22:54:20 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:54:20 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:54:20 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 22:54:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 22:54:20 - INFO - __main__ - Printing 3 examples
06/05/2022 22:54:20 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/05/2022 22:54:20 - INFO - __main__ - ['refuted']
06/05/2022 22:54:20 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/05/2022 22:54:20 - INFO - __main__ - ['refuted']
06/05/2022 22:54:20 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/05/2022 22:54:20 - INFO - __main__ - ['refuted']
06/05/2022 22:54:20 - INFO - __main__ - Tokenizing Input ...
06/05/2022 22:54:21 - INFO - __main__ - Tokenizing Output ...
06/05/2022 22:54:21 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 22:54:39 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 22:54:39 - INFO - __main__ - task name: tab_fact
06/05/2022 22:54:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 22:54:40 - INFO - __main__ - Starting training!
06/05/2022 22:54:44 - INFO - __main__ - Step 10 Global step 10 Train loss 4.67 on epoch=2
06/05/2022 22:54:49 - INFO - __main__ - Step 20 Global step 20 Train loss 1.89 on epoch=4
06/05/2022 22:54:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.02 on epoch=7
06/05/2022 22:54:58 - INFO - __main__ - Step 40 Global step 40 Train loss 0.62 on epoch=9
06/05/2022 22:55:03 - INFO - __main__ - Step 50 Global step 50 Train loss 0.46 on epoch=12
06/05/2022 22:55:05 - INFO - __main__ - Global step 50 Train loss 1.73 Classification-F1 0.16666666666666666 on epoch=12
06/05/2022 22:55:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16666666666666666 on epoch=12, global_step=50
06/05/2022 22:55:10 - INFO - __main__ - Step 60 Global step 60 Train loss 0.42 on epoch=14
06/05/2022 22:55:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.36 on epoch=17
06/05/2022 22:55:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.32 on epoch=19
06/05/2022 22:55:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.30 on epoch=22
06/05/2022 22:55:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.32 on epoch=24
06/05/2022 22:55:30 - INFO - __main__ - Global step 100 Train loss 0.35 Classification-F1 0.22695035460992907 on epoch=24
06/05/2022 22:55:30 - INFO - __main__ - Saving model with best Classification-F1: 0.16666666666666666 -> 0.22695035460992907 on epoch=24, global_step=100
06/05/2022 22:55:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=27
06/05/2022 22:55:40 - INFO - __main__ - Step 120 Global step 120 Train loss 0.31 on epoch=29
06/05/2022 22:55:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.22 on epoch=32
06/05/2022 22:55:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.27 on epoch=34
06/05/2022 22:55:53 - INFO - __main__ - Step 150 Global step 150 Train loss 0.24 on epoch=37
06/05/2022 22:55:56 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.17316017316017318 on epoch=37
06/05/2022 22:56:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.24 on epoch=39
06/05/2022 22:56:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.24 on epoch=42
06/05/2022 22:56:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/05/2022 22:56:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/05/2022 22:56:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.26 on epoch=49
06/05/2022 22:56:21 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 22:56:21 - INFO - __main__ - Saving model with best Classification-F1: 0.22695035460992907 -> 0.3333333333333333 on epoch=49, global_step=200
06/05/2022 22:56:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/05/2022 22:56:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=54
06/05/2022 22:56:35 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=57
06/05/2022 22:56:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.20 on epoch=59
06/05/2022 22:56:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.21 on epoch=62
06/05/2022 22:56:46 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 22:56:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/05/2022 22:56:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/05/2022 22:57:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=69
06/05/2022 22:57:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/05/2022 22:57:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/05/2022 22:57:12 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.24432694426085041 on epoch=74
06/05/2022 22:57:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=77
06/05/2022 22:57:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.19 on epoch=79
06/05/2022 22:57:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/05/2022 22:57:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=84
06/05/2022 22:57:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=87
06/05/2022 22:57:37 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.22456140350877193 on epoch=87
06/05/2022 22:57:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/05/2022 22:57:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/05/2022 22:57:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=94
06/05/2022 22:57:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/05/2022 22:57:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/05/2022 22:58:02 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.1735159817351598 on epoch=99
06/05/2022 22:58:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.25 on epoch=102
06/05/2022 22:58:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/05/2022 22:58:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=107
06/05/2022 22:58:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/05/2022 22:58:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=112
06/05/2022 22:58:28 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.07936507936507936 on epoch=112
06/05/2022 22:58:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/05/2022 22:58:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=117
06/05/2022 22:58:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/05/2022 22:58:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=122
06/05/2022 22:58:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/05/2022 22:58:53 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.18108068955526582 on epoch=124
06/05/2022 22:58:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/05/2022 22:59:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/05/2022 22:59:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/05/2022 22:59:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/05/2022 22:59:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/05/2022 22:59:18 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.2448255470136014 on epoch=137
06/05/2022 22:59:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/05/2022 22:59:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/05/2022 22:59:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/05/2022 22:59:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/05/2022 22:59:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/05/2022 22:59:43 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.2074074074074074 on epoch=149
06/05/2022 22:59:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=152
06/05/2022 22:59:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/05/2022 22:59:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=157
06/05/2022 23:00:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=159
06/05/2022 23:00:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/05/2022 23:00:08 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.1426704014939309 on epoch=162
06/05/2022 23:00:13 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/05/2022 23:00:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=167
06/05/2022 23:00:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=169
06/05/2022 23:00:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/05/2022 23:00:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/05/2022 23:00:34 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 23:00:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=177
06/05/2022 23:00:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/05/2022 23:00:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/05/2022 23:00:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=184
06/05/2022 23:00:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/05/2022 23:00:59 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.23230032753842275 on epoch=187
06/05/2022 23:01:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/05/2022 23:01:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=192
06/05/2022 23:01:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=194
06/05/2022 23:01:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/05/2022 23:01:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=199
06/05/2022 23:01:24 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.45718194254445965 on epoch=199
06/05/2022 23:01:24 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.45718194254445965 on epoch=199, global_step=800
06/05/2022 23:01:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/05/2022 23:01:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=204
06/05/2022 23:01:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/05/2022 23:01:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/05/2022 23:01:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=212
06/05/2022 23:01:49 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.45705196182396607 on epoch=212
06/05/2022 23:01:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/05/2022 23:01:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=217
06/05/2022 23:02:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=219
06/05/2022 23:02:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=222
06/05/2022 23:02:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=224
06/05/2022 23:02:14 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.2698600433668441 on epoch=224
06/05/2022 23:02:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=227
06/05/2022 23:02:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=229
06/05/2022 23:02:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=232
06/05/2022 23:02:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/05/2022 23:02:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/05/2022 23:02:40 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.3818181818181818 on epoch=237
06/05/2022 23:02:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/05/2022 23:02:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=242
06/05/2022 23:02:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/05/2022 23:02:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=247
06/05/2022 23:03:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=249
06/05/2022 23:03:05 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.43333333333333335 on epoch=249
06/05/2022 23:03:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=252
06/05/2022 23:03:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=254
06/05/2022 23:03:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/05/2022 23:03:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
06/05/2022 23:03:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=262
06/05/2022 23:03:31 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.46031746031746035 on epoch=262
06/05/2022 23:03:31 - INFO - __main__ - Saving model with best Classification-F1: 0.45718194254445965 -> 0.46031746031746035 on epoch=262, global_step=1050
06/05/2022 23:03:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=264
06/05/2022 23:03:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/05/2022 23:03:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=269
06/05/2022 23:03:49 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=272
06/05/2022 23:03:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
06/05/2022 23:03:56 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.47885474126608885 on epoch=274
06/05/2022 23:03:56 - INFO - __main__ - Saving model with best Classification-F1: 0.46031746031746035 -> 0.47885474126608885 on epoch=274, global_step=1100
06/05/2022 23:04:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=277
06/05/2022 23:04:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=279
06/05/2022 23:04:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=282
06/05/2022 23:04:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=284
06/05/2022 23:04:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/05/2022 23:04:22 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.4206019084903352 on epoch=287
06/05/2022 23:04:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/05/2022 23:04:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=292
06/05/2022 23:04:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=294
06/05/2022 23:04:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
06/05/2022 23:04:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/05/2022 23:04:47 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.41125541125541126 on epoch=299
06/05/2022 23:04:52 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=302
06/05/2022 23:04:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=304
06/05/2022 23:05:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/05/2022 23:05:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/05/2022 23:05:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=312
06/05/2022 23:05:12 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.436950146627566 on epoch=312
06/05/2022 23:05:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/05/2022 23:05:21 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=317
06/05/2022 23:05:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/05/2022 23:05:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=322
06/05/2022 23:05:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=324
06/05/2022 23:05:38 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.3818181818181818 on epoch=324
06/05/2022 23:05:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/05/2022 23:05:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/05/2022 23:05:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/05/2022 23:05:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/05/2022 23:06:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=337
06/05/2022 23:06:03 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.3666666666666667 on epoch=337
06/05/2022 23:06:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/05/2022 23:06:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/05/2022 23:06:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=344
06/05/2022 23:06:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/05/2022 23:06:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=349
06/05/2022 23:06:28 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.2969727718586166 on epoch=349
06/05/2022 23:06:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/05/2022 23:06:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/05/2022 23:06:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/05/2022 23:06:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/05/2022 23:06:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/05/2022 23:06:54 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.251984126984127 on epoch=362
06/05/2022 23:06:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/05/2022 23:07:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/05/2022 23:07:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/05/2022 23:07:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/05/2022 23:07:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/05/2022 23:07:19 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.28437871834098244 on epoch=374
06/05/2022 23:07:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/05/2022 23:07:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/05/2022 23:07:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/05/2022 23:07:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/05/2022 23:07:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/05/2022 23:07:44 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.44209215442092153 on epoch=387
06/05/2022 23:07:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/05/2022 23:07:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/05/2022 23:07:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/05/2022 23:08:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/05/2022 23:08:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/05/2022 23:08:10 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.4909862142099682 on epoch=399
06/05/2022 23:08:10 - INFO - __main__ - Saving model with best Classification-F1: 0.47885474126608885 -> 0.4909862142099682 on epoch=399, global_step=1600
06/05/2022 23:08:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/05/2022 23:08:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/05/2022 23:08:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/05/2022 23:08:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/05/2022 23:08:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/05/2022 23:08:35 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.4682306940371457 on epoch=412
06/05/2022 23:08:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/05/2022 23:08:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/05/2022 23:08:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/05/2022 23:08:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/05/2022 23:08:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/05/2022 23:09:00 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.46880856760374834 on epoch=424
06/05/2022 23:09:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/05/2022 23:09:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/05/2022 23:09:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/05/2022 23:09:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=434
06/05/2022 23:09:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/05/2022 23:09:25 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.31717171717171716 on epoch=437
06/05/2022 23:09:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/05/2022 23:09:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/05/2022 23:09:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/05/2022 23:09:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/05/2022 23:09:48 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/05/2022 23:09:50 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.48051948051948057 on epoch=449
06/05/2022 23:09:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/05/2022 23:09:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/05/2022 23:10:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/05/2022 23:10:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/05/2022 23:10:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/05/2022 23:10:16 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.4009852216748768 on epoch=462
06/05/2022 23:10:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/05/2022 23:10:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/05/2022 23:10:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/05/2022 23:10:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/05/2022 23:10:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/05/2022 23:10:41 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.43529411764705883 on epoch=474
06/05/2022 23:10:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/05/2022 23:10:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/05/2022 23:10:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/05/2022 23:10:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/05/2022 23:11:03 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/05/2022 23:11:06 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.4206019084903352 on epoch=487
06/05/2022 23:11:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/05/2022 23:11:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/05/2022 23:11:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/05/2022 23:11:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/05/2022 23:11:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/05/2022 23:11:31 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.46031746031746035 on epoch=499
06/05/2022 23:11:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/05/2022 23:11:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/05/2022 23:11:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/05/2022 23:11:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/05/2022 23:11:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/05/2022 23:11:57 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.40026773761713513 on epoch=512
06/05/2022 23:12:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/05/2022 23:12:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/05/2022 23:12:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/05/2022 23:12:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/05/2022 23:12:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/05/2022 23:12:22 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.43529411764705883 on epoch=524
06/05/2022 23:12:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/05/2022 23:12:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/05/2022 23:12:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/05/2022 23:12:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/05/2022 23:12:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/05/2022 23:12:47 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.4682306940371457 on epoch=537
06/05/2022 23:12:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/05/2022 23:12:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/05/2022 23:13:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/05/2022 23:13:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/05/2022 23:13:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/05/2022 23:13:13 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.46666666666666656 on epoch=549
06/05/2022 23:13:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/05/2022 23:13:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/05/2022 23:13:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/05/2022 23:13:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/05/2022 23:13:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/05/2022 23:13:38 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.45440454662877805 on epoch=562
06/05/2022 23:13:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/05/2022 23:13:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/05/2022 23:13:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/05/2022 23:13:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/05/2022 23:14:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/05/2022 23:14:03 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.5294117647058825 on epoch=574
06/05/2022 23:14:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4909862142099682 -> 0.5294117647058825 on epoch=574, global_step=2300
06/05/2022 23:14:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/05/2022 23:14:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/05/2022 23:14:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/05/2022 23:14:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/05/2022 23:14:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/05/2022 23:14:28 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.5145583557621727 on epoch=587
06/05/2022 23:14:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/05/2022 23:14:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/05/2022 23:14:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/05/2022 23:14:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/05/2022 23:14:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/05/2022 23:14:54 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.2925373134328358 on epoch=599
06/05/2022 23:14:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/05/2022 23:15:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/05/2022 23:15:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/05/2022 23:15:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/05/2022 23:15:16 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/05/2022 23:15:19 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.47813194959229055 on epoch=612
06/05/2022 23:15:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/05/2022 23:15:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/05/2022 23:15:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/05/2022 23:15:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/05/2022 23:15:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/05/2022 23:15:44 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.3149801587301587 on epoch=624
06/05/2022 23:15:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/05/2022 23:15:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/05/2022 23:15:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/05/2022 23:16:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/05/2022 23:16:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/05/2022 23:16:09 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.4874874874874875 on epoch=637
06/05/2022 23:16:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/05/2022 23:16:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/05/2022 23:16:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/05/2022 23:16:27 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/05/2022 23:16:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/05/2022 23:16:35 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.335978835978836 on epoch=649
06/05/2022 23:16:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/05/2022 23:16:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/05/2022 23:16:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/05/2022 23:16:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/05/2022 23:16:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/05/2022 23:17:00 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.4812085482682388 on epoch=662
06/05/2022 23:17:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/05/2022 23:17:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/05/2022 23:17:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/05/2022 23:17:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/05/2022 23:17:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/05/2022 23:17:25 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.46867924528301885 on epoch=674
06/05/2022 23:17:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/05/2022 23:17:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/05/2022 23:17:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/05/2022 23:17:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 23:17:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/05/2022 23:17:50 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.46867924528301885 on epoch=687
06/05/2022 23:17:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/05/2022 23:17:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/05/2022 23:18:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/05/2022 23:18:09 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/05/2022 23:18:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/05/2022 23:18:16 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.48424908424908425 on epoch=699
06/05/2022 23:18:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/05/2022 23:18:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/05/2022 23:18:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 23:18:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/05/2022 23:18:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/05/2022 23:18:41 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.4832395400048935 on epoch=712
06/05/2022 23:18:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/05/2022 23:18:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/05/2022 23:18:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/05/2022 23:18:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/05/2022 23:19:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/05/2022 23:19:06 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.45299145299145294 on epoch=724
06/05/2022 23:19:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/05/2022 23:19:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/05/2022 23:19:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/05/2022 23:19:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/05/2022 23:19:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 23:19:31 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.4519207242476144 on epoch=737
06/05/2022 23:19:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/05/2022 23:19:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/05/2022 23:19:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/05/2022 23:19:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/05/2022 23:19:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/05/2022 23:19:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 23:19:55 - INFO - __main__ - Printing 3 examples
06/05/2022 23:19:55 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/05/2022 23:19:55 - INFO - __main__ - ['refuted']
06/05/2022 23:19:55 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/05/2022 23:19:55 - INFO - __main__ - ['refuted']
06/05/2022 23:19:55 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/05/2022 23:19:55 - INFO - __main__ - ['refuted']
06/05/2022 23:19:55 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:19:55 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:19:55 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 23:19:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 23:19:55 - INFO - __main__ - Printing 3 examples
06/05/2022 23:19:55 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/05/2022 23:19:55 - INFO - __main__ - ['refuted']
06/05/2022 23:19:55 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/05/2022 23:19:55 - INFO - __main__ - ['refuted']
06/05/2022 23:19:55 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/05/2022 23:19:55 - INFO - __main__ - ['refuted']
06/05/2022 23:19:55 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:19:56 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:19:56 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 23:19:57 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.436950146627566 on epoch=749
06/05/2022 23:19:57 - INFO - __main__ - save last model!
06/05/2022 23:19:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 23:19:57 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 23:19:57 - INFO - __main__ - Printing 3 examples
06/05/2022 23:19:57 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 23:19:57 - INFO - __main__ - ['entailed']
06/05/2022 23:19:57 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 23:19:57 - INFO - __main__ - ['entailed']
06/05/2022 23:19:57 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 23:19:57 - INFO - __main__ - ['entailed']
06/05/2022 23:19:57 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:20:14 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 23:20:14 - INFO - __main__ - task name: tab_fact
06/05/2022 23:20:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:20:15 - INFO - __main__ - Starting training!
06/05/2022 23:20:24 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:20:39 - INFO - __main__ - Loaded 12792 examples from test data
06/05/2022 23:28:59 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_42_0.5_8_predictions.txt
06/05/2022 23:28:59 - INFO - __main__ - Classification-F1 on test data: 0.2002
06/05/2022 23:28:59 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.5, bsz=8, dev_performance=0.5294117647058825, test_performance=0.20024663420690608
06/05/2022 23:28:59 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.4, bsz=8 ...
06/05/2022 23:29:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 23:29:00 - INFO - __main__ - Printing 3 examples
06/05/2022 23:29:00 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/05/2022 23:29:00 - INFO - __main__ - ['refuted']
06/05/2022 23:29:00 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/05/2022 23:29:00 - INFO - __main__ - ['refuted']
06/05/2022 23:29:00 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/05/2022 23:29:00 - INFO - __main__ - ['refuted']
06/05/2022 23:29:00 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:29:00 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:29:00 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 23:29:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 23:29:00 - INFO - __main__ - Printing 3 examples
06/05/2022 23:29:00 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/05/2022 23:29:00 - INFO - __main__ - ['refuted']
06/05/2022 23:29:00 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/05/2022 23:29:00 - INFO - __main__ - ['refuted']
06/05/2022 23:29:00 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/05/2022 23:29:00 - INFO - __main__ - ['refuted']
06/05/2022 23:29:00 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:29:00 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:29:00 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 23:29:16 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 23:29:16 - INFO - __main__ - task name: tab_fact
06/05/2022 23:29:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:29:17 - INFO - __main__ - Starting training!
06/05/2022 23:29:22 - INFO - __main__ - Step 10 Global step 10 Train loss 4.79 on epoch=2
06/05/2022 23:29:26 - INFO - __main__ - Step 20 Global step 20 Train loss 2.42 on epoch=4
06/05/2022 23:29:31 - INFO - __main__ - Step 30 Global step 30 Train loss 1.03 on epoch=7
06/05/2022 23:29:35 - INFO - __main__ - Step 40 Global step 40 Train loss 0.70 on epoch=9
06/05/2022 23:29:40 - INFO - __main__ - Step 50 Global step 50 Train loss 0.48 on epoch=12
06/05/2022 23:29:43 - INFO - __main__ - Global step 50 Train loss 1.88 Classification-F1 0.5925642984466514 on epoch=12
06/05/2022 23:29:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.5925642984466514 on epoch=12, global_step=50
06/05/2022 23:29:47 - INFO - __main__ - Step 60 Global step 60 Train loss 0.43 on epoch=14
06/05/2022 23:29:52 - INFO - __main__ - Step 70 Global step 70 Train loss 0.36 on epoch=17
06/05/2022 23:29:56 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=19
06/05/2022 23:30:00 - INFO - __main__ - Step 90 Global step 90 Train loss 0.33 on epoch=22
06/05/2022 23:30:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.29 on epoch=24
06/05/2022 23:30:08 - INFO - __main__ - Global step 100 Train loss 0.34 Classification-F1 0.3333333333333333 on epoch=24
06/05/2022 23:30:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.27 on epoch=27
06/05/2022 23:30:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.28 on epoch=29
06/05/2022 23:30:21 - INFO - __main__ - Step 130 Global step 130 Train loss 0.27 on epoch=32
06/05/2022 23:30:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.27 on epoch=34
06/05/2022 23:30:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.25 on epoch=37
06/05/2022 23:30:33 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.5921568627450979 on epoch=37
06/05/2022 23:30:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=39
06/05/2022 23:30:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.24 on epoch=42
06/05/2022 23:30:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.24 on epoch=44
06/05/2022 23:30:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=47
06/05/2022 23:30:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.25 on epoch=49
06/05/2022 23:30:58 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/05/2022 23:31:02 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/05/2022 23:31:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=54
06/05/2022 23:31:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.21 on epoch=57
06/05/2022 23:31:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.22 on epoch=59
06/05/2022 23:31:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
06/05/2022 23:31:23 - INFO - __main__ - Global step 250 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=62
06/05/2022 23:31:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/05/2022 23:31:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=67
06/05/2022 23:31:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/05/2022 23:31:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=72
06/05/2022 23:31:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/05/2022 23:31:48 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.34299516908212563 on epoch=74
06/05/2022 23:31:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.20 on epoch=77
06/05/2022 23:31:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=79
06/05/2022 23:32:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/05/2022 23:32:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=84
06/05/2022 23:32:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/05/2022 23:32:13 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=87
06/05/2022 23:32:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/05/2022 23:32:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/05/2022 23:32:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=94
06/05/2022 23:32:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/05/2022 23:32:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/05/2022 23:32:38 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.2175438596491228 on epoch=99
06/05/2022 23:32:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/05/2022 23:32:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/05/2022 23:32:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=107
06/05/2022 23:32:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=109
06/05/2022 23:33:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/05/2022 23:33:03 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.264002919175333 on epoch=112
06/05/2022 23:33:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/05/2022 23:33:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/05/2022 23:33:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=119
06/05/2022 23:33:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
06/05/2022 23:33:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/05/2022 23:33:28 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.24843260188087776 on epoch=124
06/05/2022 23:33:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/05/2022 23:33:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/05/2022 23:33:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/05/2022 23:33:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/05/2022 23:33:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/05/2022 23:33:53 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.19555555555555557 on epoch=137
06/05/2022 23:33:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/05/2022 23:34:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/05/2022 23:34:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/05/2022 23:34:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/05/2022 23:34:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=149
06/05/2022 23:34:19 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.19430920696743484 on epoch=149
06/05/2022 23:34:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/05/2022 23:34:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/05/2022 23:34:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/05/2022 23:34:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/05/2022 23:34:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=162
06/05/2022 23:34:44 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.3191341991341991 on epoch=162
06/05/2022 23:34:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=164
06/05/2022 23:34:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/05/2022 23:34:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/05/2022 23:35:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/05/2022 23:35:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=174
06/05/2022 23:35:09 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=174
06/05/2022 23:35:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/05/2022 23:35:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=179
06/05/2022 23:35:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
06/05/2022 23:35:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/05/2022 23:35:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/05/2022 23:35:35 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.31047619047619046 on epoch=187
06/05/2022 23:35:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/05/2022 23:35:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/05/2022 23:35:48 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=194
06/05/2022 23:35:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=197
06/05/2022 23:35:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.17 on epoch=199
06/05/2022 23:36:00 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.3666666666666667 on epoch=199
06/05/2022 23:36:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=202
06/05/2022 23:36:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/05/2022 23:36:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/05/2022 23:36:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=209
06/05/2022 23:36:23 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/05/2022 23:36:26 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.1651989067719405 on epoch=212
06/05/2022 23:36:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/05/2022 23:36:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/05/2022 23:36:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=219
06/05/2022 23:36:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=222
06/05/2022 23:36:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=224
06/05/2022 23:36:51 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.3816425120772947 on epoch=224
06/05/2022 23:36:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=227
06/05/2022 23:37:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=229
06/05/2022 23:37:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=232
06/05/2022 23:37:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=234
06/05/2022 23:37:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=237
06/05/2022 23:37:16 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.4295900178253119 on epoch=237
06/05/2022 23:37:20 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=239
06/05/2022 23:37:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=242
06/05/2022 23:37:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=244
06/05/2022 23:37:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=247
06/05/2022 23:37:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/05/2022 23:37:41 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.39047619047619053 on epoch=249
06/05/2022 23:37:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/05/2022 23:37:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=254
06/05/2022 23:37:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=257
06/05/2022 23:37:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/05/2022 23:38:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=262
06/05/2022 23:38:06 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.16913546997037437 on epoch=262
06/05/2022 23:38:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=264
06/05/2022 23:38:15 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=267
06/05/2022 23:38:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=269
06/05/2022 23:38:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=272
06/05/2022 23:38:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=274
06/05/2022 23:38:31 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.4217338217338217 on epoch=274
06/05/2022 23:38:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/05/2022 23:38:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=279
06/05/2022 23:38:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=282
06/05/2022 23:38:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=284
06/05/2022 23:38:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=287
06/05/2022 23:38:56 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.38928309273305606 on epoch=287
06/05/2022 23:39:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=289
06/05/2022 23:39:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=292
06/05/2022 23:39:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=294
06/05/2022 23:39:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=297
06/05/2022 23:39:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=299
06/05/2022 23:39:21 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.39139139139139134 on epoch=299
06/05/2022 23:39:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=302
06/05/2022 23:39:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=304
06/05/2022 23:39:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/05/2022 23:39:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=309
06/05/2022 23:39:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=312
06/05/2022 23:39:46 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.4812085482682388 on epoch=312
06/05/2022 23:39:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=314
06/05/2022 23:39:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=317
06/05/2022 23:40:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
06/05/2022 23:40:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/05/2022 23:40:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/05/2022 23:40:12 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.3621262458471761 on epoch=324
06/05/2022 23:40:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=327
06/05/2022 23:40:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/05/2022 23:40:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=332
06/05/2022 23:40:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=334
06/05/2022 23:40:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=337
06/05/2022 23:40:38 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.3621262458471761 on epoch=337
06/05/2022 23:40:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=339
06/05/2022 23:40:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=342
06/05/2022 23:40:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/05/2022 23:40:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=347
06/05/2022 23:41:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=349
06/05/2022 23:41:04 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.4092307692307692 on epoch=349
06/05/2022 23:41:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=352
06/05/2022 23:41:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=354
06/05/2022 23:41:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/05/2022 23:41:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/05/2022 23:41:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/05/2022 23:41:29 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.40625 on epoch=362
06/05/2022 23:41:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/05/2022 23:41:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=367
06/05/2022 23:41:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/05/2022 23:41:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/05/2022 23:41:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/05/2022 23:41:54 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.41125541125541126 on epoch=374
06/05/2022 23:41:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=377
06/05/2022 23:42:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=379
06/05/2022 23:42:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/05/2022 23:42:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/05/2022 23:42:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/05/2022 23:42:19 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.3882717644019633 on epoch=387
06/05/2022 23:42:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=389
06/05/2022 23:42:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=392
06/05/2022 23:42:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/05/2022 23:42:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/05/2022 23:42:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/05/2022 23:42:47 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.4920634920634921 on epoch=399
06/05/2022 23:42:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/05/2022 23:42:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/05/2022 23:43:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=407
06/05/2022 23:43:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/05/2022 23:43:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/05/2022 23:43:12 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.4832395400048935 on epoch=412
06/05/2022 23:43:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=414
06/05/2022 23:43:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/05/2022 23:43:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/05/2022 23:43:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=422
06/05/2022 23:43:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/05/2022 23:43:38 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.34547008547008545 on epoch=424
06/05/2022 23:43:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/05/2022 23:43:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/05/2022 23:43:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=432
06/05/2022 23:43:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=434
06/05/2022 23:44:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/05/2022 23:44:04 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.46666666666666656 on epoch=437
06/05/2022 23:44:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=439
06/05/2022 23:44:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/05/2022 23:44:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/05/2022 23:44:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/05/2022 23:44:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/05/2022 23:44:29 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.44209215442092153 on epoch=449
06/05/2022 23:44:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/05/2022 23:44:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/05/2022 23:44:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/05/2022 23:44:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=459
06/05/2022 23:44:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/05/2022 23:44:54 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.4519207242476144 on epoch=462
06/05/2022 23:44:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/05/2022 23:45:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/05/2022 23:45:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=469
06/05/2022 23:45:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/05/2022 23:45:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/05/2022 23:45:19 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.4465035829009143 on epoch=474
06/05/2022 23:45:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/05/2022 23:45:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=479
06/05/2022 23:45:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=482
06/05/2022 23:45:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/05/2022 23:45:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/05/2022 23:45:45 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.5155067155067155 on epoch=487
06/05/2022 23:45:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/05/2022 23:45:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/05/2022 23:45:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/05/2022 23:46:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/05/2022 23:46:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/05/2022 23:46:10 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.5330817610062892 on epoch=499
06/05/2022 23:46:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/05/2022 23:46:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=504
06/05/2022 23:46:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=507
06/05/2022 23:46:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/05/2022 23:46:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/05/2022 23:46:36 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.5058530510585305 on epoch=512
06/05/2022 23:46:41 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/05/2022 23:46:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/05/2022 23:46:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/05/2022 23:46:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/05/2022 23:46:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/05/2022 23:47:02 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.5307917888563051 on epoch=524
06/05/2022 23:47:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/05/2022 23:47:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=529
06/05/2022 23:47:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/05/2022 23:47:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=534
06/05/2022 23:47:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/05/2022 23:47:28 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.4420512820512821 on epoch=537
06/05/2022 23:47:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/05/2022 23:47:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/05/2022 23:47:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=544
06/05/2022 23:47:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/05/2022 23:47:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/05/2022 23:47:57 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.5155067155067155 on epoch=549
06/05/2022 23:48:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/05/2022 23:48:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/05/2022 23:48:11 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/05/2022 23:48:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/05/2022 23:48:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=562
06/05/2022 23:48:23 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.4682306940371457 on epoch=562
06/05/2022 23:48:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/05/2022 23:48:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/05/2022 23:48:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/05/2022 23:48:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=572
06/05/2022 23:48:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/05/2022 23:48:48 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.42342342342342343 on epoch=574
06/05/2022 23:48:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/05/2022 23:48:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=579
06/05/2022 23:49:02 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/05/2022 23:49:06 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/05/2022 23:49:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/05/2022 23:49:14 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.3361368096439585 on epoch=587
06/05/2022 23:49:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/05/2022 23:49:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/05/2022 23:49:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/05/2022 23:49:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/05/2022 23:49:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/05/2022 23:49:39 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.43647798742138366 on epoch=599
06/05/2022 23:49:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/05/2022 23:49:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/05/2022 23:49:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=607
06/05/2022 23:49:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/05/2022 23:50:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/05/2022 23:50:05 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.5 on epoch=612
06/05/2022 23:50:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/05/2022 23:50:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/05/2022 23:50:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/05/2022 23:50:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/05/2022 23:50:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/05/2022 23:50:30 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.43333333333333335 on epoch=624
06/05/2022 23:50:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/05/2022 23:50:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/05/2022 23:50:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/05/2022 23:50:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/05/2022 23:50:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/05/2022 23:50:56 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.4519207242476144 on epoch=637
06/05/2022 23:51:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=639
06/05/2022 23:51:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/05/2022 23:51:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/05/2022 23:51:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/05/2022 23:51:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/05/2022 23:51:22 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.5 on epoch=649
06/05/2022 23:51:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/05/2022 23:51:31 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/05/2022 23:51:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/05/2022 23:51:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/05/2022 23:51:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/05/2022 23:51:47 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.3882717644019633 on epoch=662
06/05/2022 23:51:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/05/2022 23:51:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/05/2022 23:52:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=669
06/05/2022 23:52:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/05/2022 23:52:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/05/2022 23:52:13 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.4812085482682388 on epoch=674
06/05/2022 23:52:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/05/2022 23:52:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/05/2022 23:52:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/05/2022 23:52:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/05/2022 23:52:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/05/2022 23:52:39 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.4980392156862745 on epoch=687
06/05/2022 23:52:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/05/2022 23:52:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/05/2022 23:52:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/05/2022 23:52:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/05/2022 23:53:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/05/2022 23:53:04 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.4920634920634921 on epoch=699
06/05/2022 23:53:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/05/2022 23:53:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/05/2022 23:53:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/05/2022 23:53:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/05/2022 23:53:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/05/2022 23:53:30 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.47813194959229055 on epoch=712
06/05/2022 23:53:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/05/2022 23:53:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/05/2022 23:53:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/05/2022 23:53:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/05/2022 23:53:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/05/2022 23:53:56 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.4995112414467253 on epoch=724
06/05/2022 23:54:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/05/2022 23:54:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/05/2022 23:54:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/05/2022 23:54:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/05/2022 23:54:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/05/2022 23:54:21 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.4832395400048935 on epoch=737
06/05/2022 23:54:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/05/2022 23:54:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=742
06/05/2022 23:54:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/05/2022 23:54:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/05/2022 23:54:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/05/2022 23:54:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 23:54:45 - INFO - __main__ - Printing 3 examples
06/05/2022 23:54:45 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/05/2022 23:54:45 - INFO - __main__ - ['refuted']
06/05/2022 23:54:45 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/05/2022 23:54:45 - INFO - __main__ - ['refuted']
06/05/2022 23:54:45 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/05/2022 23:54:45 - INFO - __main__ - ['refuted']
06/05/2022 23:54:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:54:45 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:54:45 - INFO - __main__ - Loaded 64 examples from train data
06/05/2022 23:54:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/05/2022 23:54:45 - INFO - __main__ - Printing 3 examples
06/05/2022 23:54:45 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/05/2022 23:54:45 - INFO - __main__ - ['refuted']
06/05/2022 23:54:45 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/05/2022 23:54:45 - INFO - __main__ - ['refuted']
06/05/2022 23:54:45 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/05/2022 23:54:45 - INFO - __main__ - ['refuted']
06/05/2022 23:54:45 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:54:45 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:54:46 - INFO - __main__ - Loaded 64 examples from dev data
06/05/2022 23:54:47 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.48424908424908425 on epoch=749
06/05/2022 23:54:47 - INFO - __main__ - save last model!
06/05/2022 23:54:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/05/2022 23:54:47 - INFO - __main__ - Start tokenizing ... 12792 instances
06/05/2022 23:54:47 - INFO - __main__ - Printing 3 examples
06/05/2022 23:54:47 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 23:54:47 - INFO - __main__ - ['entailed']
06/05/2022 23:54:47 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 23:54:47 - INFO - __main__ - ['entailed']
06/05/2022 23:54:47 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/05/2022 23:54:47 - INFO - __main__ - ['entailed']
06/05/2022 23:54:47 - INFO - __main__ - Tokenizing Input ...
06/05/2022 23:55:01 - INFO - __main__ - try to initialize prompt embeddings
06/05/2022 23:55:01 - INFO - __main__ - task name: tab_fact
06/05/2022 23:55:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/05/2022 23:55:02 - INFO - __main__ - Starting training!
06/05/2022 23:55:11 - INFO - __main__ - Tokenizing Output ...
06/05/2022 23:55:24 - INFO - __main__ - Loaded 12792 examples from test data
06/06/2022 00:03:49 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_42_0.4_8_predictions.txt
06/06/2022 00:03:49 - INFO - __main__ - Classification-F1 on test data: 0.2493
06/06/2022 00:03:49 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.4, bsz=8, dev_performance=0.5925642984466514, test_performance=0.24933310175510676
06/06/2022 00:03:49 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.3, bsz=8 ...
06/06/2022 00:03:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 00:03:50 - INFO - __main__ - Printing 3 examples
06/06/2022 00:03:50 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/06/2022 00:03:50 - INFO - __main__ - ['refuted']
06/06/2022 00:03:50 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/06/2022 00:03:50 - INFO - __main__ - ['refuted']
06/06/2022 00:03:50 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/06/2022 00:03:50 - INFO - __main__ - ['refuted']
06/06/2022 00:03:50 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:03:50 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:03:50 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 00:03:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 00:03:50 - INFO - __main__ - Printing 3 examples
06/06/2022 00:03:50 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/06/2022 00:03:50 - INFO - __main__ - ['refuted']
06/06/2022 00:03:50 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/06/2022 00:03:50 - INFO - __main__ - ['refuted']
06/06/2022 00:03:50 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/06/2022 00:03:50 - INFO - __main__ - ['refuted']
06/06/2022 00:03:50 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:03:51 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:03:51 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 00:04:10 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 00:04:10 - INFO - __main__ - task name: tab_fact
06/06/2022 00:04:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 00:04:10 - INFO - __main__ - Starting training!
06/06/2022 00:04:15 - INFO - __main__ - Step 10 Global step 10 Train loss 5.05 on epoch=2
06/06/2022 00:04:20 - INFO - __main__ - Step 20 Global step 20 Train loss 2.69 on epoch=4
06/06/2022 00:04:24 - INFO - __main__ - Step 30 Global step 30 Train loss 1.22 on epoch=7
06/06/2022 00:04:29 - INFO - __main__ - Step 40 Global step 40 Train loss 0.77 on epoch=9
06/06/2022 00:04:33 - INFO - __main__ - Step 50 Global step 50 Train loss 0.61 on epoch=12
06/06/2022 00:04:36 - INFO - __main__ - Global step 50 Train loss 2.07 Classification-F1 0.32631578947368417 on epoch=12
06/06/2022 00:04:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.32631578947368417 on epoch=12, global_step=50
06/06/2022 00:04:40 - INFO - __main__ - Step 60 Global step 60 Train loss 0.50 on epoch=14
06/06/2022 00:04:45 - INFO - __main__ - Step 70 Global step 70 Train loss 0.41 on epoch=17
06/06/2022 00:04:50 - INFO - __main__ - Step 80 Global step 80 Train loss 0.40 on epoch=19
06/06/2022 00:04:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.40 on epoch=22
06/06/2022 00:04:58 - INFO - __main__ - Step 100 Global step 100 Train loss 0.30 on epoch=24
06/06/2022 00:05:01 - INFO - __main__ - Global step 100 Train loss 0.40 Classification-F1 0.4487674487674488 on epoch=24
06/06/2022 00:05:01 - INFO - __main__ - Saving model with best Classification-F1: 0.32631578947368417 -> 0.4487674487674488 on epoch=24, global_step=100
06/06/2022 00:05:06 - INFO - __main__ - Step 110 Global step 110 Train loss 0.35 on epoch=27
06/06/2022 00:05:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.27 on epoch=29
06/06/2022 00:05:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.33 on epoch=32
06/06/2022 00:05:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=34
06/06/2022 00:05:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.28 on epoch=37
06/06/2022 00:05:26 - INFO - __main__ - Global step 150 Train loss 0.31 Classification-F1 0.3333333333333333 on epoch=37
06/06/2022 00:05:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=39
06/06/2022 00:05:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/06/2022 00:05:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.29 on epoch=44
06/06/2022 00:05:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/06/2022 00:05:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.30 on epoch=49
06/06/2022 00:05:51 - INFO - __main__ - Global step 200 Train loss 0.28 Classification-F1 0.39047619047619053 on epoch=49
06/06/2022 00:05:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.25 on epoch=52
06/06/2022 00:06:00 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=54
06/06/2022 00:06:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.23 on epoch=57
06/06/2022 00:06:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/06/2022 00:06:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.26 on epoch=62
06/06/2022 00:06:16 - INFO - __main__ - Global step 250 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=62
06/06/2022 00:06:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/06/2022 00:06:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/06/2022 00:06:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=69
06/06/2022 00:06:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/06/2022 00:06:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=74
06/06/2022 00:06:42 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=74
06/06/2022 00:06:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.22 on epoch=77
06/06/2022 00:06:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.25 on epoch=79
06/06/2022 00:06:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/06/2022 00:07:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/06/2022 00:07:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/06/2022 00:07:07 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=87
06/06/2022 00:07:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.18 on epoch=89
06/06/2022 00:07:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.21 on epoch=92
06/06/2022 00:07:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=94
06/06/2022 00:07:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/06/2022 00:07:29 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/06/2022 00:07:32 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.4345381526104417 on epoch=99
06/06/2022 00:07:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=102
06/06/2022 00:07:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/06/2022 00:07:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/06/2022 00:07:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=109
06/06/2022 00:07:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=112
06/06/2022 00:07:57 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=112
06/06/2022 00:08:02 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=114
06/06/2022 00:08:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=117
06/06/2022 00:08:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/06/2022 00:08:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=122
06/06/2022 00:08:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/06/2022 00:08:23 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=124
06/06/2022 00:08:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=127
06/06/2022 00:08:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
06/06/2022 00:08:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/06/2022 00:08:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/06/2022 00:08:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/06/2022 00:08:48 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.2607594936708861 on epoch=137
06/06/2022 00:08:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/06/2022 00:08:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=142
06/06/2022 00:09:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/06/2022 00:09:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/06/2022 00:09:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/06/2022 00:09:13 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/06/2022 00:09:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=152
06/06/2022 00:09:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/06/2022 00:09:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/06/2022 00:09:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/06/2022 00:09:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=162
06/06/2022 00:09:39 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=162
06/06/2022 00:09:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/06/2022 00:09:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/06/2022 00:09:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/06/2022 00:09:57 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/06/2022 00:10:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/06/2022 00:10:04 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=174
06/06/2022 00:10:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/06/2022 00:10:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=179
06/06/2022 00:10:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
06/06/2022 00:10:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/06/2022 00:10:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/06/2022 00:10:30 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=187
06/06/2022 00:10:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.19 on epoch=189
06/06/2022 00:10:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/06/2022 00:10:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/06/2022 00:10:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/06/2022 00:10:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/06/2022 00:10:55 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=199
06/06/2022 00:10:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=202
06/06/2022 00:11:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=204
06/06/2022 00:11:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=207
06/06/2022 00:11:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=209
06/06/2022 00:11:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/06/2022 00:11:20 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.3087234893957584 on epoch=212
06/06/2022 00:11:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/06/2022 00:11:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/06/2022 00:11:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/06/2022 00:11:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=222
06/06/2022 00:11:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=224
06/06/2022 00:11:45 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.21505376344086022 on epoch=224
06/06/2022 00:11:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=227
06/06/2022 00:11:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=229
06/06/2022 00:11:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=232
06/06/2022 00:12:04 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/06/2022 00:12:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=237
06/06/2022 00:12:11 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.45718194254445965 on epoch=237
06/06/2022 00:12:11 - INFO - __main__ - Saving model with best Classification-F1: 0.4487674487674488 -> 0.45718194254445965 on epoch=237, global_step=950
06/06/2022 00:12:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=239
06/06/2022 00:12:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=242
06/06/2022 00:12:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/06/2022 00:12:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=247
06/06/2022 00:12:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=249
06/06/2022 00:12:37 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.22456140350877193 on epoch=249
06/06/2022 00:12:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/06/2022 00:12:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/06/2022 00:12:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/06/2022 00:12:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=259
06/06/2022 00:12:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=262
06/06/2022 00:13:02 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.2207657095297545 on epoch=262
06/06/2022 00:13:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=264
06/06/2022 00:13:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=267
06/06/2022 00:13:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=269
06/06/2022 00:13:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
06/06/2022 00:13:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=274
06/06/2022 00:13:28 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.22456140350877193 on epoch=274
06/06/2022 00:13:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/06/2022 00:13:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=279
06/06/2022 00:13:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=282
06/06/2022 00:13:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=284
06/06/2022 00:13:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=287
06/06/2022 00:13:53 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.2648018648018648 on epoch=287
06/06/2022 00:13:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/06/2022 00:14:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=292
06/06/2022 00:14:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=294
06/06/2022 00:14:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=297
06/06/2022 00:14:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=299
06/06/2022 00:14:19 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.3176206509539843 on epoch=299
06/06/2022 00:14:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=302
06/06/2022 00:14:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=304
06/06/2022 00:14:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=307
06/06/2022 00:14:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=309
06/06/2022 00:14:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=312
06/06/2022 00:14:45 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.2123655913978495 on epoch=312
06/06/2022 00:14:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=314
06/06/2022 00:14:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=317
06/06/2022 00:14:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=319
06/06/2022 00:15:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=322
06/06/2022 00:15:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=324
06/06/2022 00:15:11 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.20499999999999996 on epoch=324
06/06/2022 00:15:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=327
06/06/2022 00:15:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=329
06/06/2022 00:15:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=332
06/06/2022 00:15:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=334
06/06/2022 00:15:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/06/2022 00:15:36 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.29479377958079783 on epoch=337
06/06/2022 00:15:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=339
06/06/2022 00:15:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=342
06/06/2022 00:15:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=344
06/06/2022 00:15:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=347
06/06/2022 00:15:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.11 on epoch=349
06/06/2022 00:16:02 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.3002849002849003 on epoch=349
06/06/2022 00:16:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=352
06/06/2022 00:16:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=354
06/06/2022 00:16:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=357
06/06/2022 00:16:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=359
06/06/2022 00:16:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=362
06/06/2022 00:16:28 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.3106295149638803 on epoch=362
06/06/2022 00:16:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=364
06/06/2022 00:16:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=367
06/06/2022 00:16:42 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=369
06/06/2022 00:16:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=372
06/06/2022 00:16:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=374
06/06/2022 00:16:54 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.22941970310391363 on epoch=374
06/06/2022 00:16:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/06/2022 00:17:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=379
06/06/2022 00:17:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=382
06/06/2022 00:17:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=384
06/06/2022 00:17:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=387
06/06/2022 00:17:20 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.46031746031746035 on epoch=387
06/06/2022 00:17:20 - INFO - __main__ - Saving model with best Classification-F1: 0.45718194254445965 -> 0.46031746031746035 on epoch=387, global_step=1550
06/06/2022 00:17:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=389
06/06/2022 00:17:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=392
06/06/2022 00:17:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=394
06/06/2022 00:17:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=397
06/06/2022 00:17:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=399
06/06/2022 00:17:45 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.41832473593711617 on epoch=399
06/06/2022 00:17:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=402
06/06/2022 00:17:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=404
06/06/2022 00:17:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=407
06/06/2022 00:18:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=409
06/06/2022 00:18:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/06/2022 00:18:11 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.22823529411764704 on epoch=412
06/06/2022 00:18:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=414
06/06/2022 00:18:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=417
06/06/2022 00:18:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=419
06/06/2022 00:18:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=422
06/06/2022 00:18:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=424
06/06/2022 00:18:36 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.38714090287277697 on epoch=424
06/06/2022 00:18:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=427
06/06/2022 00:18:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=429
06/06/2022 00:18:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=432
06/06/2022 00:18:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=434
06/06/2022 00:18:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=437
06/06/2022 00:19:02 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.4832395400048935 on epoch=437
06/06/2022 00:19:02 - INFO - __main__ - Saving model with best Classification-F1: 0.46031746031746035 -> 0.4832395400048935 on epoch=437, global_step=1750
06/06/2022 00:19:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=439
06/06/2022 00:19:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=442
06/06/2022 00:19:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/06/2022 00:19:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=447
06/06/2022 00:19:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=449
06/06/2022 00:19:28 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.4102117061021171 on epoch=449
06/06/2022 00:19:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=452
06/06/2022 00:19:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=454
06/06/2022 00:19:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=457
06/06/2022 00:19:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=459
06/06/2022 00:19:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=462
06/06/2022 00:19:53 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.44976664210267747 on epoch=462
06/06/2022 00:19:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=464
06/06/2022 00:20:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=467
06/06/2022 00:20:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=469
06/06/2022 00:20:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=472
06/06/2022 00:20:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/06/2022 00:20:19 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.4206019084903352 on epoch=474
06/06/2022 00:20:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/06/2022 00:20:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=479
06/06/2022 00:20:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=482
06/06/2022 00:20:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=484
06/06/2022 00:20:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=487
06/06/2022 00:20:45 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.40566959921798634 on epoch=487
06/06/2022 00:20:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=489
06/06/2022 00:20:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=492
06/06/2022 00:20:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/06/2022 00:21:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/06/2022 00:21:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=499
06/06/2022 00:21:11 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.41832473593711617 on epoch=499
06/06/2022 00:21:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=502
06/06/2022 00:21:20 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=504
06/06/2022 00:21:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=507
06/06/2022 00:21:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/06/2022 00:21:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/06/2022 00:21:36 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.4116101917520357 on epoch=512
06/06/2022 00:21:41 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/06/2022 00:21:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/06/2022 00:21:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=519
06/06/2022 00:21:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=522
06/06/2022 00:21:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=524
06/06/2022 00:22:02 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.375 on epoch=524
06/06/2022 00:22:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/06/2022 00:22:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/06/2022 00:22:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=532
06/06/2022 00:22:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=534
06/06/2022 00:22:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/06/2022 00:22:28 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.436950146627566 on epoch=537
06/06/2022 00:22:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=539
06/06/2022 00:22:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/06/2022 00:22:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/06/2022 00:22:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/06/2022 00:22:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=549
06/06/2022 00:22:54 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.39756367663344405 on epoch=549
06/06/2022 00:22:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/06/2022 00:23:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=554
06/06/2022 00:23:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/06/2022 00:23:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/06/2022 00:23:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/06/2022 00:23:19 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.4295900178253119 on epoch=562
06/06/2022 00:23:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=564
06/06/2022 00:23:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/06/2022 00:23:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/06/2022 00:23:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=572
06/06/2022 00:23:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/06/2022 00:23:45 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.42342342342342343 on epoch=574
06/06/2022 00:23:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=577
06/06/2022 00:23:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=579
06/06/2022 00:23:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/06/2022 00:24:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/06/2022 00:24:08 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/06/2022 00:24:11 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.46031746031746035 on epoch=587
06/06/2022 00:24:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/06/2022 00:24:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/06/2022 00:24:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/06/2022 00:24:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/06/2022 00:24:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=599
06/06/2022 00:24:37 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.45705196182396607 on epoch=599
06/06/2022 00:24:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/06/2022 00:24:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/06/2022 00:24:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/06/2022 00:24:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=609
06/06/2022 00:25:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=612
06/06/2022 00:25:03 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.4832395400048935 on epoch=612
06/06/2022 00:25:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/06/2022 00:25:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/06/2022 00:25:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 00:25:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/06/2022 00:25:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/06/2022 00:25:29 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.44976664210267747 on epoch=624
06/06/2022 00:25:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/06/2022 00:25:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/06/2022 00:25:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/06/2022 00:25:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/06/2022 00:25:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/06/2022 00:25:55 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.403921568627451 on epoch=637
06/06/2022 00:25:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
06/06/2022 00:26:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/06/2022 00:26:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/06/2022 00:26:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/06/2022 00:26:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=649
06/06/2022 00:26:21 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.4465035829009143 on epoch=649
06/06/2022 00:26:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/06/2022 00:26:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/06/2022 00:26:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/06/2022 00:26:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=659
06/06/2022 00:26:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/06/2022 00:26:46 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.4206019084903352 on epoch=662
06/06/2022 00:26:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/06/2022 00:26:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/06/2022 00:27:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=669
06/06/2022 00:27:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/06/2022 00:27:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/06/2022 00:27:12 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.4217338217338217 on epoch=674
06/06/2022 00:27:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/06/2022 00:27:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/06/2022 00:27:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/06/2022 00:27:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/06/2022 00:27:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/06/2022 00:27:38 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.4554554554554554 on epoch=687
06/06/2022 00:27:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/06/2022 00:27:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/06/2022 00:27:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/06/2022 00:27:56 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/06/2022 00:28:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/06/2022 00:28:04 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.45299145299145294 on epoch=699
06/06/2022 00:28:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/06/2022 00:28:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=704
06/06/2022 00:28:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/06/2022 00:28:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 00:28:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/06/2022 00:28:29 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.4519207242476144 on epoch=712
06/06/2022 00:28:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 00:28:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 00:28:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 00:28:47 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/06/2022 00:28:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/06/2022 00:28:55 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.3666666666666667 on epoch=724
06/06/2022 00:29:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/06/2022 00:29:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/06/2022 00:29:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=732
06/06/2022 00:29:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/06/2022 00:29:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/06/2022 00:29:21 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.403921568627451 on epoch=737
06/06/2022 00:29:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/06/2022 00:29:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 00:29:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/06/2022 00:29:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/06/2022 00:29:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/06/2022 00:29:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 00:29:45 - INFO - __main__ - Printing 3 examples
06/06/2022 00:29:45 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/06/2022 00:29:45 - INFO - __main__ - ['refuted']
06/06/2022 00:29:45 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/06/2022 00:29:45 - INFO - __main__ - ['refuted']
06/06/2022 00:29:45 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/06/2022 00:29:45 - INFO - __main__ - ['refuted']
06/06/2022 00:29:45 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:29:45 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:29:45 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 00:29:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 00:29:45 - INFO - __main__ - Printing 3 examples
06/06/2022 00:29:45 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/06/2022 00:29:45 - INFO - __main__ - ['refuted']
06/06/2022 00:29:45 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/06/2022 00:29:45 - INFO - __main__ - ['refuted']
06/06/2022 00:29:45 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/06/2022 00:29:45 - INFO - __main__ - ['refuted']
06/06/2022 00:29:45 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:29:45 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:29:45 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 00:29:46 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.44209215442092153 on epoch=749
06/06/2022 00:29:46 - INFO - __main__ - save last model!
06/06/2022 00:29:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 00:29:47 - INFO - __main__ - Start tokenizing ... 12792 instances
06/06/2022 00:29:47 - INFO - __main__ - Printing 3 examples
06/06/2022 00:29:47 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 00:29:47 - INFO - __main__ - ['entailed']
06/06/2022 00:29:47 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 00:29:47 - INFO - __main__ - ['entailed']
06/06/2022 00:29:47 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 00:29:47 - INFO - __main__ - ['entailed']
06/06/2022 00:29:47 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:30:04 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 00:30:04 - INFO - __main__ - task name: tab_fact
06/06/2022 00:30:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 00:30:04 - INFO - __main__ - Starting training!
06/06/2022 00:30:13 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:30:28 - INFO - __main__ - Loaded 12792 examples from test data
06/06/2022 00:42:22 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_42_0.3_8_predictions.txt
06/06/2022 00:42:22 - INFO - __main__ - Classification-F1 on test data: 0.3193
06/06/2022 00:42:22 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.3, bsz=8, dev_performance=0.4832395400048935, test_performance=0.3192718657163723
06/06/2022 00:42:22 - INFO - __main__ - Running ... prefix=tab_fact_32_42, lr=0.2, bsz=8 ...
06/06/2022 00:42:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 00:42:23 - INFO - __main__ - Printing 3 examples
06/06/2022 00:42:23 - INFO - __main__ -  [tab_fact] statement: more than 6 player make their debut between august 2 and august 30 2007 [SEP] table_caption: 2007 - 08 newcastle jets season [SEP] table_text: name#position#from (club)#date joined#debut [n] noel spencer#midfield#sydney fc#7 may 2007#round 1 [n] adam griffiths#defender#brentford#17 may 2007#round 1 [n] jorge drovandi#forward#rosario central#2 august 2007#round 1 [n] denni#midfield#santo andré#17 august 2007#round 1 [n] scott tunbridge#forward#hamilton academical#4 july 2007#round 11 [n] mário jardel#forward#anorthosis#13 august 2007#round 4 [n] ben mcnamara#goalkeeper#lake macquarie city#18 august 2007#uncapped [n] jason hoffman#forward#hamilton olympic#30 august 2007#round 2 [n] stephen laybutt#defender#gent#30 august 2007#round 6 [n] james holland#midfield#ais#14 october 2007#round 8 [n] ben kantarovski#midfield#broadmeadow magic#12 january 2008#uncapped [n] song jin - hyung#midfield#fc seoul#18 january 2008#semi final (2nd leg) [n] 
06/06/2022 00:42:23 - INFO - __main__ - ['refuted']
06/06/2022 00:42:23 - INFO - __main__ -  [tab_fact] statement: the boston celtics' cumulative point throughout the series be more than 2 greater than that of the indiana pacer [SEP] table_caption: 1990 - 91 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#series [n] 1#april 26#indiana pacers#w 127 - 120#r lewis (28)#l bird (12)#l bird (12)#boston garden#1 - 0 [n] 2#april 28#indiana pacers#l 118 - 130#r lewis , b shaw (22)#r parish (12)#l bird (10)#boston garden#1 - 1 [n] 3#may 1#indiana pacers#w 112 - 105#k mchale (22)#l bird (9)#b shaw (7)#market square arena#2 - 1 [n] 4#may 3#indiana pacers#l 113 - 116#k mchale (24)#r parish (12)#l bird (8)#market square arena#2 - 2 [n] 5#may 5#indiana pacers#w 124 - 121#l bird (32)#l bird (9)#b shaw (9)#boston garden#3 - 2 [n] 
06/06/2022 00:42:23 - INFO - __main__ - ['refuted']
06/06/2022 00:42:23 - INFO - __main__ -  [tab_fact] statement: kidwelly rfc have 409 point against them [SEP] table_caption: wru division two west [SEP] table_text: club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] club#played#drawn#lost#points for#points against#tries for#tries against#try bonus#losing bonus#points [n] maesteg rfc#22#2#1#615#271#78#24#12#0#92 [n] waunarlwydd rfc#22#1#7#594#359#73#38#10#5#73 [n] bp llandarcy rfc#22#1#7#376#320#43#36#3#5#66 [n] kidwelly rfc#22#0#9#558#393#68#39#6#6#64 [n] aberavon quins rfc#22#0#9#449#424#56#45#6#3#61 [n] ammanford rfc#22#1#10#409#348#45#33#4#8#58 [n] loughor rfc#22#1#11#427#479#47#60#5#4#51 [n] aberystwyth rfc#22#0#12#390#509#46#71#5#4#49 [n] pontyberem rfc#22#0#12#353#520#35#67#4#3#47 [n] mumbles rfc#22#1#14#372#471#51#55#5#4#39 [n] pencoed rfc#22#0#19#321#505#34#62#0#10#22 [n] dunvant rfc#22#1#17#324#589#33#79#0#2#20 [n] 
06/06/2022 00:42:23 - INFO - __main__ - ['refuted']
06/06/2022 00:42:23 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:42:23 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:42:23 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 00:42:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 00:42:23 - INFO - __main__ - Printing 3 examples
06/06/2022 00:42:23 - INFO - __main__ -  [tab_fact] statement: 5 - 4 be the agg when team 1 be l'etoile de morne - - l'eau [SEP] table_caption: 1987 concacaf champions' cup [SEP] table_text: team 1#agg#team 2#1st leg#2nd leg [n] golden star#4 - 0#uptown rebels#3 - 0#1 - 0 [n] mg renegades#3 - 4#club franciscain#2 - 0#1 - 4 [n] l'etoile de morne - ã  - l'eau#3 - 3 (4 - 3 pen)#harbour view fc#3 - 1#0 - 2 [n] vsadc#5 - 3#asg juventus de sainte - anne#5 - 1#0 - 2 [n] rick 's superstars#1 - 5#trintoc#1 - 2#0 - 3 [n] 
06/06/2022 00:42:23 - INFO - __main__ - ['refuted']
06/06/2022 00:42:23 - INFO - __main__ -  [tab_fact] statement: dallas star draft player austin , jamie , ondrej and luke in the third round [SEP] table_caption: 2007 - 08 dallas stars season [SEP] table_text: round#player#position#nationality#college / junior / club team (league) [n] 2#nico sacchetti#centre#united states#virginia high school ( ushs - mn ) [n] 3#sergei korostin#right wing#russia#dynamo moscow ( rus ) [n] 4#colton sceviour#right wing#canada#portland winter hawks ( whl ) [n] 5#austin smith#right wing#united states#gunnery prep [n] 5#jamie benn#left wing#canada#victoria grizzlies ( bchl ) [n] 5#ondrej roman#left wing#czech republic#spokane chiefs ( whl ) [n] 4#michael neal#left wing#canada#belleville bulls ( ohl ) [n] 5#luke gazdic#left wing#canada#erie otters ( ohl ) [n] 
06/06/2022 00:42:23 - INFO - __main__ - ['refuted']
06/06/2022 00:42:23 - INFO - __main__ -  [tab_fact] statement: wayne ferreira play in dubai , uae after he play in tokyo , japan [SEP] table_caption: wayne ferreira [SEP] table_text: outcome#date#championship#surface#opponent#score [n] runner - up#17 february 1992#memphis , us#hard (i)#malivai washington#3 - 6 , 2 - 6 [n] winner#15 june 1992#queen 's club , uk#grass#shuzo matsuoka#6 - 3 , 6 - 4 [n] runner - up#20 july 1992#stuttgart outdoor , germany#clay#andrei medvedev#1 - 6 , 4 - 6 , 7 - 6 (7 - 5) , 6 - 2 , 1 - 6 [n] winner#31 august 1992#schenectady , us#hard#jamie morgan#6 - 2 , 6 - 7 (5 - 7) , 6 - 2 [n] runner - up#8 march 1993#indian wells , us#hard#jim courier#3 - 6 , 3 - 6 , 1 - 6 [n] runner - up#14 june 1993#queen 's club , uk#grass#michael stich#3 - 6 , 4 - 6 [n] winner#10 january 1994#oahu , us#hard#richey reneberg#6 - 4 , 6 - 7 (3 - 7) , 6 - 1 [n] runner - up#28 february 1994#rotterdam , netherlands#carpet#michael stich#6 - 4 , 3 - 6 , 0 - 6 [n] runner - up#20 june 1994#manchester , uk#grass#patrick rafter#6 - 7 (5 - 7) , 6 - 7 (4 - 7) [n] winner#22 august 1994#indianapolis , us#hard#olivier delaître#6 - 2 , 6 - 1 [n] winner#19 september 1994#bordeaux , france#hard#jeff tarango#6 - 0 , 7 - 5 [n] winner#3 october 1994#basel , switzerland#hard (i)#patrick mcenroe#4 - 6 , 6 - 2 , 7 - 6 (9 - 7) , 6 - 3 [n] winner#17 october 1994#tel - aviv , israel#hard#amos mansdorf#7 - 6 (7 - 4) , 6 - 3 [n] winner#13 february 1995#dubai , uae#hard#andrea gaudenzi#6 - 3 , 6 - 3 [n] winner#8 may 1995#munich , germany#clay#michael stich#7 - 5 , 7 - 6 (8 - 6) [n] winner#16 october 1995#ostrava , czech republic#carpet#malivai washington#3 - 6 , 6 - 4 , 6 - 3 [n] winner#23 october 1995#lyon , france#carpet#pete sampras#7 - 6 (7 - 2) , 5 - 7 , 6 - 3 [n] winner#11 march 1996#scottsdale , us#hard#marcelo ríos#2 - 6 , 6 - 3 , 6 - 3 [n] runner - up#22 july 1996#washington , dc , us#hard#michael chang#2 - 6 , 4 - 6 [n] winner#26 august 1996#toronto , canada#hard#todd woodbridge#6 - 2 , 6 - 4 [n] runner - up#19 april 1999#tokyo , japan#hard#nicolas kiefer#6 - 7 (5 - 7) , 5 - 7 [n] winner#6 november 2000#stuttgart , germany#hard (i)#lleyton hewitt#7 - 6 (8 - 6) , 3 - 6 , 6 - 7 (5 - 7) , 7 - 6 (7 - 2) , 6 - 2 [n] winner#4 august 2003#los angeles , us#hard#lleyton hewitt#6 - 3 , 4 - 6 , 7 - 5 [n] 
06/06/2022 00:42:23 - INFO - __main__ - ['refuted']
06/06/2022 00:42:23 - INFO - __main__ - Tokenizing Input ...
06/06/2022 00:42:24 - INFO - __main__ - Tokenizing Output ...
06/06/2022 00:42:24 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 00:42:42 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 00:42:42 - INFO - __main__ - task name: tab_fact
06/06/2022 00:42:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 00:42:43 - INFO - __main__ - Starting training!
06/06/2022 00:42:48 - INFO - __main__ - Step 10 Global step 10 Train loss 5.57 on epoch=2
06/06/2022 00:42:53 - INFO - __main__ - Step 20 Global step 20 Train loss 4.00 on epoch=4
06/06/2022 00:42:57 - INFO - __main__ - Step 30 Global step 30 Train loss 2.38 on epoch=7
06/06/2022 00:43:02 - INFO - __main__ - Step 40 Global step 40 Train loss 1.29 on epoch=9
06/06/2022 00:43:06 - INFO - __main__ - Step 50 Global step 50 Train loss 0.90 on epoch=12
06/06/2022 00:43:09 - INFO - __main__ - Global step 50 Train loss 2.83 Classification-F1 0.16129032258064516 on epoch=12
06/06/2022 00:43:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16129032258064516 on epoch=12, global_step=50
06/06/2022 00:43:14 - INFO - __main__ - Step 60 Global step 60 Train loss 0.84 on epoch=14
06/06/2022 00:43:18 - INFO - __main__ - Step 70 Global step 70 Train loss 0.65 on epoch=17
06/06/2022 00:43:23 - INFO - __main__ - Step 80 Global step 80 Train loss 0.59 on epoch=19
06/06/2022 00:43:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.47 on epoch=22
06/06/2022 00:43:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.41 on epoch=24
06/06/2022 00:43:34 - INFO - __main__ - Global step 100 Train loss 0.59 Classification-F1 0.32631578947368417 on epoch=24
06/06/2022 00:43:35 - INFO - __main__ - Saving model with best Classification-F1: 0.16129032258064516 -> 0.32631578947368417 on epoch=24, global_step=100
06/06/2022 00:43:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.43 on epoch=27
06/06/2022 00:43:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.39 on epoch=29
06/06/2022 00:43:48 - INFO - __main__ - Step 130 Global step 130 Train loss 0.38 on epoch=32
06/06/2022 00:43:53 - INFO - __main__ - Step 140 Global step 140 Train loss 0.35 on epoch=34
06/06/2022 00:43:57 - INFO - __main__ - Step 150 Global step 150 Train loss 0.32 on epoch=37
06/06/2022 00:44:00 - INFO - __main__ - Global step 150 Train loss 0.37 Classification-F1 0.4796747967479674 on epoch=37
06/06/2022 00:44:00 - INFO - __main__ - Saving model with best Classification-F1: 0.32631578947368417 -> 0.4796747967479674 on epoch=37, global_step=150
06/06/2022 00:44:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=39
06/06/2022 00:44:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.38 on epoch=42
06/06/2022 00:44:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.28 on epoch=44
06/06/2022 00:44:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.28 on epoch=47
06/06/2022 00:44:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/06/2022 00:44:25 - INFO - __main__ - Global step 200 Train loss 0.30 Classification-F1 0.335970464135021 on epoch=49
06/06/2022 00:44:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.29 on epoch=52
06/06/2022 00:44:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.28 on epoch=54
06/06/2022 00:44:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=57
06/06/2022 00:44:43 - INFO - __main__ - Step 240 Global step 240 Train loss 0.27 on epoch=59
06/06/2022 00:44:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.27 on epoch=62
06/06/2022 00:44:50 - INFO - __main__ - Global step 250 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=62
06/06/2022 00:44:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.25 on epoch=64
06/06/2022 00:44:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/06/2022 00:45:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=69
06/06/2022 00:45:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=72
06/06/2022 00:45:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/06/2022 00:45:15 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.3591989987484355 on epoch=74
06/06/2022 00:45:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=77
06/06/2022 00:45:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=79
06/06/2022 00:45:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/06/2022 00:45:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/06/2022 00:45:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=87
06/06/2022 00:45:40 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.22222222222222224 on epoch=87
06/06/2022 00:45:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/06/2022 00:45:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=92
06/06/2022 00:45:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/06/2022 00:45:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/06/2022 00:46:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
06/06/2022 00:46:05 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=99
06/06/2022 00:46:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=102
06/06/2022 00:46:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=104
06/06/2022 00:46:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=107
06/06/2022 00:46:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=109
06/06/2022 00:46:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/06/2022 00:46:30 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=112
06/06/2022 00:46:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/06/2022 00:46:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=117
06/06/2022 00:46:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/06/2022 00:46:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=122
06/06/2022 00:46:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/06/2022 00:46:56 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.2346616065781151 on epoch=124
06/06/2022 00:47:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=127
06/06/2022 00:47:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
06/06/2022 00:47:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=132
06/06/2022 00:47:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=134
06/06/2022 00:47:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/06/2022 00:47:21 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.40026773761713513 on epoch=137
06/06/2022 00:47:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=139
06/06/2022 00:47:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/06/2022 00:47:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/06/2022 00:47:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=147
06/06/2022 00:47:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/06/2022 00:47:46 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.21505376344086022 on epoch=149
06/06/2022 00:47:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/06/2022 00:47:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/06/2022 00:47:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/06/2022 00:48:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/06/2022 00:48:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/06/2022 00:48:11 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.2525728240013954 on epoch=162
06/06/2022 00:48:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/06/2022 00:48:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=167
06/06/2022 00:48:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/06/2022 00:48:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=172
06/06/2022 00:48:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/06/2022 00:48:36 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=174
06/06/2022 00:48:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/06/2022 00:48:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/06/2022 00:48:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/06/2022 00:48:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/06/2022 00:48:59 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/06/2022 00:49:01 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.2463605823068309 on epoch=187
06/06/2022 00:49:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.25 on epoch=189
06/06/2022 00:49:10 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=192
06/06/2022 00:49:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=194
06/06/2022 00:49:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=197
06/06/2022 00:49:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/06/2022 00:49:27 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.23789473684210527 on epoch=199
06/06/2022 00:49:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/06/2022 00:49:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=204
06/06/2022 00:49:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/06/2022 00:49:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=209
06/06/2022 00:49:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/06/2022 00:49:52 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.24841269841269842 on epoch=212
06/06/2022 00:49:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=214
06/06/2022 00:50:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/06/2022 00:50:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=219
06/06/2022 00:50:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=222
06/06/2022 00:50:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=224
06/06/2022 00:50:17 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.28987240829346095 on epoch=224
06/06/2022 00:50:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/06/2022 00:50:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=229
06/06/2022 00:50:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=232
06/06/2022 00:50:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=234
06/06/2022 00:50:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=237
06/06/2022 00:50:42 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.4554554554554554 on epoch=237
06/06/2022 00:50:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=239
06/06/2022 00:50:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/06/2022 00:50:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=244
06/06/2022 00:51:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=247
06/06/2022 00:51:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=249
06/06/2022 00:51:08 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.28266178266178266 on epoch=249
06/06/2022 00:51:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/06/2022 00:51:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=254
06/06/2022 00:51:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=257
06/06/2022 00:51:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=259
06/06/2022 00:51:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=262
06/06/2022 00:51:33 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.27625693326176415 on epoch=262
06/06/2022 00:51:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=264
06/06/2022 00:51:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=267
06/06/2022 00:51:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/06/2022 00:51:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=272
06/06/2022 00:51:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=274
06/06/2022 00:51:58 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.29587197672304055 on epoch=274
06/06/2022 00:52:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/06/2022 00:52:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=279
06/06/2022 00:52:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=282
06/06/2022 00:52:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=284
06/06/2022 00:52:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=287
06/06/2022 00:52:23 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.2518518518518518 on epoch=287
06/06/2022 00:52:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/06/2022 00:52:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=292
06/06/2022 00:52:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=294
06/06/2022 00:52:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=297
06/06/2022 00:52:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=299
06/06/2022 00:52:49 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.18686868686868685 on epoch=299
06/06/2022 00:52:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/06/2022 00:52:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=304
06/06/2022 00:53:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=307
06/06/2022 00:53:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=309
06/06/2022 00:53:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/06/2022 00:53:14 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.2926829268292683 on epoch=312
06/06/2022 00:53:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=314
06/06/2022 00:53:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=317
06/06/2022 00:53:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=319
06/06/2022 00:53:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=322
06/06/2022 00:53:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=324
06/06/2022 00:53:40 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.21407274895646988 on epoch=324
06/06/2022 00:53:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=327
06/06/2022 00:53:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=329
06/06/2022 00:53:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=332
06/06/2022 00:53:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=334
06/06/2022 00:54:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=337
06/06/2022 00:54:05 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.32170334585793525 on epoch=337
06/06/2022 00:54:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=339
06/06/2022 00:54:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/06/2022 00:54:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/06/2022 00:54:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/06/2022 00:54:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=349
06/06/2022 00:54:30 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.1623015873015873 on epoch=349
06/06/2022 00:54:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=352
06/06/2022 00:54:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/06/2022 00:54:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=357
06/06/2022 00:54:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/06/2022 00:54:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=362
06/06/2022 00:54:56 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.272561682397748 on epoch=362
06/06/2022 00:55:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=364
06/06/2022 00:55:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/06/2022 00:55:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/06/2022 00:55:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=372
06/06/2022 00:55:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=374
06/06/2022 00:55:21 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.26236940666272424 on epoch=374
06/06/2022 00:55:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=377
06/06/2022 00:55:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/06/2022 00:55:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=382
06/06/2022 00:55:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/06/2022 00:55:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=387
06/06/2022 00:55:46 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.24722222222222223 on epoch=387
06/06/2022 00:55:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=389
06/06/2022 00:55:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/06/2022 00:56:00 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=394
06/06/2022 00:56:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/06/2022 00:56:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
06/06/2022 00:56:11 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.2752016129032258 on epoch=399
06/06/2022 00:56:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=402
06/06/2022 00:56:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/06/2022 00:56:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=407
06/06/2022 00:56:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=409
06/06/2022 00:56:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=412
06/06/2022 00:56:37 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.29488536155202816 on epoch=412
06/06/2022 00:56:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/06/2022 00:56:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/06/2022 00:56:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=419
06/06/2022 00:56:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=422
06/06/2022 00:56:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=424
06/06/2022 00:57:02 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.25114638447971777 on epoch=424
06/06/2022 00:57:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=427
06/06/2022 00:57:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/06/2022 00:57:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=432
06/06/2022 00:57:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/06/2022 00:57:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
06/06/2022 00:57:27 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.19226750261233022 on epoch=437
06/06/2022 00:57:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/06/2022 00:57:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=442
06/06/2022 00:57:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=444
06/06/2022 00:57:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=447
06/06/2022 00:57:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=449
06/06/2022 00:57:52 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.2856182795698925 on epoch=449
06/06/2022 00:57:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=452
06/06/2022 00:58:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/06/2022 00:58:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/06/2022 00:58:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/06/2022 00:58:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/06/2022 00:58:18 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.2773510838026967 on epoch=462
06/06/2022 00:58:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/06/2022 00:58:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/06/2022 00:58:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=469
06/06/2022 00:58:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/06/2022 00:58:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=474
06/06/2022 00:58:43 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.2528324388789505 on epoch=474
06/06/2022 00:58:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/06/2022 00:58:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=479
06/06/2022 00:58:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=482
06/06/2022 00:59:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/06/2022 00:59:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=487
06/06/2022 00:59:08 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.4206019084903352 on epoch=487
06/06/2022 00:59:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/06/2022 00:59:17 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/06/2022 00:59:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/06/2022 00:59:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/06/2022 00:59:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/06/2022 00:59:33 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.32631578947368417 on epoch=499
06/06/2022 00:59:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/06/2022 00:59:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/06/2022 00:59:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=507
06/06/2022 00:59:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/06/2022 00:59:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/06/2022 00:59:59 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.24592198581560284 on epoch=512
06/06/2022 01:00:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/06/2022 01:00:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/06/2022 01:00:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/06/2022 01:00:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/06/2022 01:00:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=524
06/06/2022 01:00:24 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.4202898550724638 on epoch=524
06/06/2022 01:00:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=527
06/06/2022 01:00:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/06/2022 01:00:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/06/2022 01:00:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/06/2022 01:00:47 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/06/2022 01:00:50 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.21071428571428574 on epoch=537
06/06/2022 01:00:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/06/2022 01:00:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=542
06/06/2022 01:01:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/06/2022 01:01:08 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/06/2022 01:01:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/06/2022 01:01:15 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.2909574468085106 on epoch=549
06/06/2022 01:01:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=552
06/06/2022 01:01:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/06/2022 01:01:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=557
06/06/2022 01:01:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/06/2022 01:01:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=562
06/06/2022 01:01:40 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.21594982078853048 on epoch=562
06/06/2022 01:01:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/06/2022 01:01:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/06/2022 01:01:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/06/2022 01:01:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/06/2022 01:02:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/06/2022 01:02:05 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.2770719903206291 on epoch=574
06/06/2022 01:02:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/06/2022 01:02:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/06/2022 01:02:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/06/2022 01:02:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/06/2022 01:02:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=587
06/06/2022 01:02:31 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.2148148148148148 on epoch=587
06/06/2022 01:02:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/06/2022 01:02:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/06/2022 01:02:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/06/2022 01:02:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/06/2022 01:02:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/06/2022 01:02:56 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.4385964912280702 on epoch=599
06/06/2022 01:03:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=602
06/06/2022 01:03:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/06/2022 01:03:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/06/2022 01:03:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=609
06/06/2022 01:03:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/06/2022 01:03:21 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.2406027487994701 on epoch=612
06/06/2022 01:03:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/06/2022 01:03:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=617
06/06/2022 01:03:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 01:03:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/06/2022 01:03:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=624
06/06/2022 01:03:47 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.2554865424430642 on epoch=624
06/06/2022 01:03:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/06/2022 01:03:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/06/2022 01:04:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/06/2022 01:04:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/06/2022 01:04:09 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/06/2022 01:04:12 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.2346616065781151 on epoch=637
06/06/2022 01:04:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/06/2022 01:04:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=642
06/06/2022 01:04:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/06/2022 01:04:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/06/2022 01:04:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 01:04:37 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.23173758865248228 on epoch=649
06/06/2022 01:04:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/06/2022 01:04:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/06/2022 01:04:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=657
06/06/2022 01:04:55 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/06/2022 01:04:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/06/2022 01:05:02 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.2466596343178622 on epoch=662
06/06/2022 01:05:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
06/06/2022 01:05:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/06/2022 01:05:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
06/06/2022 01:05:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=672
06/06/2022 01:05:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/06/2022 01:05:27 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.26111983254840393 on epoch=674
06/06/2022 01:05:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/06/2022 01:05:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 01:05:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/06/2022 01:05:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/06/2022 01:05:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/06/2022 01:05:52 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.26176417963857573 on epoch=687
06/06/2022 01:05:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/06/2022 01:06:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 01:06:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/06/2022 01:06:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/06/2022 01:06:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 01:06:17 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.3816425120772947 on epoch=699
06/06/2022 01:06:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=702
06/06/2022 01:06:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 01:06:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 01:06:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/06/2022 01:06:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/06/2022 01:06:43 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.38918345705196183 on epoch=712
06/06/2022 01:06:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/06/2022 01:06:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 01:06:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/06/2022 01:07:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/06/2022 01:07:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/06/2022 01:07:08 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.35212038303693577 on epoch=724
06/06/2022 01:07:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 01:07:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 01:07:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/06/2022 01:07:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/06/2022 01:07:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 01:07:33 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.2604282022886674 on epoch=737
06/06/2022 01:07:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/06/2022 01:07:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 01:07:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/06/2022 01:07:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/06/2022 01:07:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/06/2022 01:07:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:07:57 - INFO - __main__ - Printing 3 examples
06/06/2022 01:07:57 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 01:07:57 - INFO - __main__ - ['entailed']
06/06/2022 01:07:57 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 01:07:57 - INFO - __main__ - ['entailed']
06/06/2022 01:07:57 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 01:07:57 - INFO - __main__ - ['entailed']
06/06/2022 01:07:57 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:07:57 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:07:57 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 01:07:57 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:07:57 - INFO - __main__ - Printing 3 examples
06/06/2022 01:07:57 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 01:07:57 - INFO - __main__ - ['entailed']
06/06/2022 01:07:57 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 01:07:57 - INFO - __main__ - ['entailed']
06/06/2022 01:07:57 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 01:07:57 - INFO - __main__ - ['entailed']
06/06/2022 01:07:57 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:07:57 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:07:57 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 01:07:58 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.3816425120772947 on epoch=749
06/06/2022 01:07:58 - INFO - __main__ - save last model!
06/06/2022 01:07:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 01:07:59 - INFO - __main__ - Start tokenizing ... 12792 instances
06/06/2022 01:07:59 - INFO - __main__ - Printing 3 examples
06/06/2022 01:07:59 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 01:07:59 - INFO - __main__ - ['entailed']
06/06/2022 01:07:59 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 01:07:59 - INFO - __main__ - ['entailed']
06/06/2022 01:07:59 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 01:07:59 - INFO - __main__ - ['entailed']
06/06/2022 01:07:59 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:08:16 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 01:08:16 - INFO - __main__ - task name: tab_fact
06/06/2022 01:08:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:08:17 - INFO - __main__ - Starting training!
06/06/2022 01:08:24 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:08:37 - INFO - __main__ - Loaded 12792 examples from test data
06/06/2022 01:17:00 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_42_0.2_8_predictions.txt
06/06/2022 01:17:00 - INFO - __main__ - Classification-F1 on test data: 0.0510
06/06/2022 01:17:00 - INFO - __main__ - prefix=tab_fact_32_42, lr=0.2, bsz=8, dev_performance=0.4796747967479674, test_performance=0.05103081430802774
06/06/2022 01:17:00 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.5, bsz=8 ...
06/06/2022 01:17:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:17:01 - INFO - __main__ - Printing 3 examples
06/06/2022 01:17:01 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 01:17:01 - INFO - __main__ - ['entailed']
06/06/2022 01:17:01 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 01:17:01 - INFO - __main__ - ['entailed']
06/06/2022 01:17:01 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 01:17:01 - INFO - __main__ - ['entailed']
06/06/2022 01:17:01 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:17:01 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:17:01 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 01:17:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:17:01 - INFO - __main__ - Printing 3 examples
06/06/2022 01:17:01 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 01:17:01 - INFO - __main__ - ['entailed']
06/06/2022 01:17:01 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 01:17:01 - INFO - __main__ - ['entailed']
06/06/2022 01:17:01 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 01:17:01 - INFO - __main__ - ['entailed']
06/06/2022 01:17:01 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:17:01 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:17:01 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 01:17:17 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 01:17:17 - INFO - __main__ - task name: tab_fact
06/06/2022 01:17:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:17:18 - INFO - __main__ - Starting training!
06/06/2022 01:17:23 - INFO - __main__ - Step 10 Global step 10 Train loss 4.69 on epoch=2
06/06/2022 01:17:27 - INFO - __main__ - Step 20 Global step 20 Train loss 1.82 on epoch=4
06/06/2022 01:17:32 - INFO - __main__ - Step 30 Global step 30 Train loss 0.80 on epoch=7
06/06/2022 01:17:36 - INFO - __main__ - Step 40 Global step 40 Train loss 0.56 on epoch=9
06/06/2022 01:17:41 - INFO - __main__ - Step 50 Global step 50 Train loss 0.45 on epoch=12
06/06/2022 01:17:43 - INFO - __main__ - Global step 50 Train loss 1.67 Classification-F1 0.3333333333333333 on epoch=12
06/06/2022 01:17:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/06/2022 01:17:48 - INFO - __main__ - Step 60 Global step 60 Train loss 0.37 on epoch=14
06/06/2022 01:17:52 - INFO - __main__ - Step 70 Global step 70 Train loss 0.36 on epoch=17
06/06/2022 01:17:57 - INFO - __main__ - Step 80 Global step 80 Train loss 0.29 on epoch=19
06/06/2022 01:18:01 - INFO - __main__ - Step 90 Global step 90 Train loss 0.29 on epoch=22
06/06/2022 01:18:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.27 on epoch=24
06/06/2022 01:18:08 - INFO - __main__ - Global step 100 Train loss 0.32 Classification-F1 0.4920634920634921 on epoch=24
06/06/2022 01:18:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.4920634920634921 on epoch=24, global_step=100
06/06/2022 01:18:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.28 on epoch=27
06/06/2022 01:18:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.25 on epoch=29
06/06/2022 01:18:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.29 on epoch=32
06/06/2022 01:18:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.28 on epoch=34
06/06/2022 01:18:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.26 on epoch=37
06/06/2022 01:18:34 - INFO - __main__ - Global step 150 Train loss 0.27 Classification-F1 0.3333333333333333 on epoch=37
06/06/2022 01:18:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.26 on epoch=39
06/06/2022 01:18:43 - INFO - __main__ - Step 170 Global step 170 Train loss 1.32 on epoch=42
06/06/2022 01:18:47 - INFO - __main__ - Step 180 Global step 180 Train loss 2.54 on epoch=44
06/06/2022 01:18:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.30 on epoch=47
06/06/2022 01:18:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.25 on epoch=49
06/06/2022 01:18:59 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.4832395400048935 on epoch=49
06/06/2022 01:19:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.23 on epoch=52
06/06/2022 01:19:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=54
06/06/2022 01:19:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=57
06/06/2022 01:19:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.24 on epoch=59
06/06/2022 01:19:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.25 on epoch=62
06/06/2022 01:19:24 - INFO - __main__ - Global step 250 Train loss 0.24 Classification-F1 0.4554554554554554 on epoch=62
06/06/2022 01:19:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.27 on epoch=64
06/06/2022 01:19:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/06/2022 01:19:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/06/2022 01:19:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/06/2022 01:19:47 - INFO - __main__ - Step 300 Global step 300 Train loss 0.22 on epoch=74
06/06/2022 01:19:50 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.43647798742138366 on epoch=74
06/06/2022 01:19:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/06/2022 01:19:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.20 on epoch=79
06/06/2022 01:20:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=82
06/06/2022 01:20:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/06/2022 01:20:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
06/06/2022 01:20:15 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.3060931899641577 on epoch=87
06/06/2022 01:20:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/06/2022 01:20:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/06/2022 01:20:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/06/2022 01:20:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=97
06/06/2022 01:20:37 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=99
06/06/2022 01:20:40 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.33710407239819 on epoch=99
06/06/2022 01:20:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=102
06/06/2022 01:20:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=104
06/06/2022 01:20:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=107
06/06/2022 01:20:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=109
06/06/2022 01:21:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=112
06/06/2022 01:21:05 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.473972602739726 on epoch=112
06/06/2022 01:21:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/06/2022 01:21:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=117
06/06/2022 01:21:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=119
06/06/2022 01:21:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=122
06/06/2022 01:21:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/06/2022 01:21:30 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.22695035460992907 on epoch=124
06/06/2022 01:21:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=127
06/06/2022 01:21:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/06/2022 01:21:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=132
06/06/2022 01:21:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=134
06/06/2022 01:21:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/06/2022 01:21:55 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=137
06/06/2022 01:22:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=139
06/06/2022 01:22:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=142
06/06/2022 01:22:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/06/2022 01:22:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=147
06/06/2022 01:22:18 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/06/2022 01:22:21 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=149
06/06/2022 01:22:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=152
06/06/2022 01:22:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/06/2022 01:22:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/06/2022 01:22:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/06/2022 01:22:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/06/2022 01:22:46 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=162
06/06/2022 01:22:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/06/2022 01:22:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/06/2022 01:22:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/06/2022 01:23:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/06/2022 01:23:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=174
06/06/2022 01:23:11 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=174
06/06/2022 01:23:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/06/2022 01:23:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=179
06/06/2022 01:23:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=182
06/06/2022 01:23:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/06/2022 01:23:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=187
06/06/2022 01:23:36 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.49556650246305417 on epoch=187
06/06/2022 01:23:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4920634920634921 -> 0.49556650246305417 on epoch=187, global_step=750
06/06/2022 01:23:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=189
06/06/2022 01:23:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/06/2022 01:23:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/06/2022 01:23:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=197
06/06/2022 01:23:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=199
06/06/2022 01:24:02 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=199
06/06/2022 01:24:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=202
06/06/2022 01:24:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=204
06/06/2022 01:24:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=207
06/06/2022 01:24:20 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=209
06/06/2022 01:24:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/06/2022 01:24:27 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=212
06/06/2022 01:24:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/06/2022 01:24:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=217
06/06/2022 01:24:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=219
06/06/2022 01:24:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=222
06/06/2022 01:24:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/06/2022 01:24:53 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.4920634920634921 on epoch=224
06/06/2022 01:24:57 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=227
06/06/2022 01:25:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=229
06/06/2022 01:25:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=232
06/06/2022 01:25:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=234
06/06/2022 01:25:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=237
06/06/2022 01:25:18 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.4980392156862745 on epoch=237
06/06/2022 01:25:18 - INFO - __main__ - Saving model with best Classification-F1: 0.49556650246305417 -> 0.4980392156862745 on epoch=237, global_step=950
06/06/2022 01:25:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=239
06/06/2022 01:25:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=242
06/06/2022 01:25:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/06/2022 01:25:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=247
06/06/2022 01:25:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=249
06/06/2022 01:25:43 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.4920634920634921 on epoch=249
06/06/2022 01:25:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=252
06/06/2022 01:25:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=254
06/06/2022 01:25:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=257
06/06/2022 01:26:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=259
06/06/2022 01:26:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=262
06/06/2022 01:26:08 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=262
06/06/2022 01:26:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=264
06/06/2022 01:26:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=267
06/06/2022 01:26:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=269
06/06/2022 01:26:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=272
06/06/2022 01:26:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=274
06/06/2022 01:26:33 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.5126504544338 on epoch=274
06/06/2022 01:26:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4980392156862745 -> 0.5126504544338 on epoch=274, global_step=1100
06/06/2022 01:26:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=277
06/06/2022 01:26:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.24 on epoch=279
06/06/2022 01:26:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=282
06/06/2022 01:26:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=284
06/06/2022 01:26:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.21 on epoch=287
06/06/2022 01:26:58 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.3371428571428572 on epoch=287
06/06/2022 01:27:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.20 on epoch=289
06/06/2022 01:27:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=292
06/06/2022 01:27:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=294
06/06/2022 01:27:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=297
06/06/2022 01:27:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=299
06/06/2022 01:27:24 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.3883928571428572 on epoch=299
06/06/2022 01:27:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=302
06/06/2022 01:27:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=304
06/06/2022 01:27:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=307
06/06/2022 01:27:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.19 on epoch=309
06/06/2022 01:27:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=312
06/06/2022 01:27:49 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=312
06/06/2022 01:27:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=314
06/06/2022 01:27:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=317
06/06/2022 01:28:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.22 on epoch=319
06/06/2022 01:28:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.21 on epoch=322
06/06/2022 01:28:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=324
06/06/2022 01:28:15 - INFO - __main__ - Global step 1300 Train loss 0.21 Classification-F1 0.41075141075141075 on epoch=324
06/06/2022 01:28:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=327
06/06/2022 01:28:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=329
06/06/2022 01:28:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.19 on epoch=332
06/06/2022 01:28:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.17 on epoch=334
06/06/2022 01:28:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=337
06/06/2022 01:28:40 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.4493927125506073 on epoch=337
06/06/2022 01:28:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=339
06/06/2022 01:28:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=342
06/06/2022 01:28:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=344
06/06/2022 01:28:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.21 on epoch=347
06/06/2022 01:29:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=349
06/06/2022 01:29:05 - INFO - __main__ - Global step 1400 Train loss 0.18 Classification-F1 0.39047619047619053 on epoch=349
06/06/2022 01:29:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=352
06/06/2022 01:29:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=354
06/06/2022 01:29:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.19 on epoch=357
06/06/2022 01:29:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.18 on epoch=359
06/06/2022 01:29:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.21 on epoch=362
06/06/2022 01:29:31 - INFO - __main__ - Global step 1450 Train loss 0.19 Classification-F1 0.3329800388623918 on epoch=362
06/06/2022 01:29:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=364
06/06/2022 01:29:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=367
06/06/2022 01:29:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.17 on epoch=369
06/06/2022 01:29:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=372
06/06/2022 01:29:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=374
06/06/2022 01:29:56 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.36049382716049383 on epoch=374
06/06/2022 01:30:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=377
06/06/2022 01:30:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.20 on epoch=379
06/06/2022 01:30:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=382
06/06/2022 01:30:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=384
06/06/2022 01:30:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=387
06/06/2022 01:30:21 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.46880856760374834 on epoch=387
06/06/2022 01:30:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=389
06/06/2022 01:30:31 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=392
06/06/2022 01:30:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.18 on epoch=394
06/06/2022 01:30:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.15 on epoch=397
06/06/2022 01:30:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.20 on epoch=399
06/06/2022 01:30:47 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.3347193347193347 on epoch=399
06/06/2022 01:30:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.15 on epoch=402
06/06/2022 01:30:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=404
06/06/2022 01:31:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.17 on epoch=407
06/06/2022 01:31:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.21 on epoch=409
06/06/2022 01:31:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.18 on epoch=412
06/06/2022 01:31:12 - INFO - __main__ - Global step 1650 Train loss 0.17 Classification-F1 0.5515515515515517 on epoch=412
06/06/2022 01:31:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5126504544338 -> 0.5515515515515517 on epoch=412, global_step=1650
06/06/2022 01:31:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.18 on epoch=414
06/06/2022 01:31:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.20 on epoch=417
06/06/2022 01:31:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.19 on epoch=419
06/06/2022 01:31:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.18 on epoch=422
06/06/2022 01:31:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.16 on epoch=424
06/06/2022 01:31:38 - INFO - __main__ - Global step 1700 Train loss 0.18 Classification-F1 0.4458874458874459 on epoch=424
06/06/2022 01:31:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=427
06/06/2022 01:31:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.20 on epoch=429
06/06/2022 01:31:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=432
06/06/2022 01:31:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.15 on epoch=434
06/06/2022 01:32:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.18 on epoch=437
06/06/2022 01:32:03 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.5270935960591133 on epoch=437
06/06/2022 01:32:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.19 on epoch=439
06/06/2022 01:32:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=442
06/06/2022 01:32:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=444
06/06/2022 01:32:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.19 on epoch=447
06/06/2022 01:32:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=449
06/06/2022 01:32:28 - INFO - __main__ - Global step 1800 Train loss 0.17 Classification-F1 0.2216900444748546 on epoch=449
06/06/2022 01:32:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=452
06/06/2022 01:32:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.15 on epoch=454
06/06/2022 01:32:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=457
06/06/2022 01:32:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.15 on epoch=459
06/06/2022 01:32:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.17 on epoch=462
06/06/2022 01:32:53 - INFO - __main__ - Global step 1850 Train loss 0.15 Classification-F1 0.3884201819685691 on epoch=462
06/06/2022 01:32:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.17 on epoch=464
06/06/2022 01:33:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.17 on epoch=467
06/06/2022 01:33:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.16 on epoch=469
06/06/2022 01:33:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.15 on epoch=472
06/06/2022 01:33:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=474
06/06/2022 01:33:18 - INFO - __main__ - Global step 1900 Train loss 0.16 Classification-F1 0.42216142270861834 on epoch=474
06/06/2022 01:33:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.18 on epoch=477
06/06/2022 01:33:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.14 on epoch=479
06/06/2022 01:33:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.18 on epoch=482
06/06/2022 01:33:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.15 on epoch=484
06/06/2022 01:33:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.14 on epoch=487
06/06/2022 01:33:44 - INFO - __main__ - Global step 1950 Train loss 0.16 Classification-F1 0.323549965059399 on epoch=487
06/06/2022 01:33:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.16 on epoch=489
06/06/2022 01:33:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.15 on epoch=492
06/06/2022 01:33:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.15 on epoch=494
06/06/2022 01:34:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.16 on epoch=497
06/06/2022 01:34:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.17 on epoch=499
06/06/2022 01:34:09 - INFO - __main__ - Global step 2000 Train loss 0.16 Classification-F1 0.35767692575204313 on epoch=499
06/06/2022 01:34:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.16 on epoch=502
06/06/2022 01:34:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=504
06/06/2022 01:34:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=507
06/06/2022 01:34:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.15 on epoch=509
06/06/2022 01:34:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=512
06/06/2022 01:34:34 - INFO - __main__ - Global step 2050 Train loss 0.14 Classification-F1 0.34140524674371675 on epoch=512
06/06/2022 01:34:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=514
06/06/2022 01:34:43 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.13 on epoch=517
06/06/2022 01:34:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=519
06/06/2022 01:34:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=522
06/06/2022 01:34:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=524
06/06/2022 01:35:00 - INFO - __main__ - Global step 2100 Train loss 0.14 Classification-F1 0.3052039381153305 on epoch=524
06/06/2022 01:35:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=527
06/06/2022 01:35:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=529
06/06/2022 01:35:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=532
06/06/2022 01:35:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.13 on epoch=534
06/06/2022 01:35:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=537
06/06/2022 01:35:25 - INFO - __main__ - Global step 2150 Train loss 0.12 Classification-F1 0.4995112414467253 on epoch=537
06/06/2022 01:35:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=539
06/06/2022 01:35:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=542
06/06/2022 01:35:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.15 on epoch=544
06/06/2022 01:35:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=547
06/06/2022 01:35:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=549
06/06/2022 01:35:50 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.3333333333333333 on epoch=549
06/06/2022 01:35:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=552
06/06/2022 01:35:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=554
06/06/2022 01:36:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=557
06/06/2022 01:36:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.10 on epoch=559
06/06/2022 01:36:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=562
06/06/2022 01:36:16 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.46031746031746035 on epoch=562
06/06/2022 01:36:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.13 on epoch=564
06/06/2022 01:36:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.12 on epoch=567
06/06/2022 01:36:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=569
06/06/2022 01:36:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=572
06/06/2022 01:36:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=574
06/06/2022 01:36:41 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.4465035829009143 on epoch=574
06/06/2022 01:36:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=577
06/06/2022 01:36:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=579
06/06/2022 01:36:55 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=582
06/06/2022 01:36:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=584
06/06/2022 01:37:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=587
06/06/2022 01:37:07 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.19705882352941176 on epoch=587
06/06/2022 01:37:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=589
06/06/2022 01:37:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=592
06/06/2022 01:37:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=594
06/06/2022 01:37:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=597
06/06/2022 01:37:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=599
06/06/2022 01:37:32 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.32158317872603587 on epoch=599
06/06/2022 01:37:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=602
06/06/2022 01:37:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=604
06/06/2022 01:37:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=607
06/06/2022 01:37:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.13 on epoch=609
06/06/2022 01:37:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=612
06/06/2022 01:37:57 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.2693400167084377 on epoch=612
06/06/2022 01:38:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=614
06/06/2022 01:38:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=617
06/06/2022 01:38:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/06/2022 01:38:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=622
06/06/2022 01:38:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=624
06/06/2022 01:38:23 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.36374269005847953 on epoch=624
06/06/2022 01:38:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=627
06/06/2022 01:38:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=629
06/06/2022 01:38:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=632
06/06/2022 01:38:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=634
06/06/2022 01:38:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=637
06/06/2022 01:38:48 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.2595704948646125 on epoch=637
06/06/2022 01:38:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/06/2022 01:38:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=642
06/06/2022 01:39:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=644
06/06/2022 01:39:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=647
06/06/2022 01:39:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=649
06/06/2022 01:39:13 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.24344344344344346 on epoch=649
06/06/2022 01:39:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.11 on epoch=652
06/06/2022 01:39:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/06/2022 01:39:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/06/2022 01:39:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/06/2022 01:39:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=662
06/06/2022 01:39:38 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.2528324388789505 on epoch=662
06/06/2022 01:39:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=664
06/06/2022 01:39:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=667
06/06/2022 01:39:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=669
06/06/2022 01:39:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/06/2022 01:40:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/06/2022 01:40:04 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.2450980392156863 on epoch=674
06/06/2022 01:40:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=677
06/06/2022 01:40:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/06/2022 01:40:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=682
06/06/2022 01:40:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/06/2022 01:40:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/06/2022 01:40:30 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.27111111111111114 on epoch=687
06/06/2022 01:40:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/06/2022 01:40:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/06/2022 01:40:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=694
06/06/2022 01:40:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/06/2022 01:40:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/06/2022 01:40:55 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.23252937538651822 on epoch=699
06/06/2022 01:41:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/06/2022 01:41:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=704
06/06/2022 01:41:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
06/06/2022 01:41:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 01:41:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=712
06/06/2022 01:41:21 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.4465035829009143 on epoch=712
06/06/2022 01:41:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=714
06/06/2022 01:41:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=717
06/06/2022 01:41:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/06/2022 01:41:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/06/2022 01:41:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=724
06/06/2022 01:41:46 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.2685286600949251 on epoch=724
06/06/2022 01:41:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 01:41:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=729
06/06/2022 01:42:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/06/2022 01:42:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/06/2022 01:42:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 01:42:12 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.341991341991342 on epoch=737
06/06/2022 01:42:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/06/2022 01:42:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=742
06/06/2022 01:42:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/06/2022 01:42:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/06/2022 01:42:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/06/2022 01:42:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:42:36 - INFO - __main__ - Printing 3 examples
06/06/2022 01:42:36 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 01:42:36 - INFO - __main__ - ['entailed']
06/06/2022 01:42:36 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 01:42:36 - INFO - __main__ - ['entailed']
06/06/2022 01:42:36 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 01:42:36 - INFO - __main__ - ['entailed']
06/06/2022 01:42:36 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:42:36 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:42:36 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 01:42:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:42:36 - INFO - __main__ - Printing 3 examples
06/06/2022 01:42:36 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 01:42:36 - INFO - __main__ - ['entailed']
06/06/2022 01:42:36 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 01:42:36 - INFO - __main__ - ['entailed']
06/06/2022 01:42:36 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 01:42:36 - INFO - __main__ - ['entailed']
06/06/2022 01:42:36 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:42:36 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:42:36 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 01:42:37 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.2683982683982684 on epoch=749
06/06/2022 01:42:37 - INFO - __main__ - save last model!
06/06/2022 01:42:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 01:42:37 - INFO - __main__ - Start tokenizing ... 12792 instances
06/06/2022 01:42:37 - INFO - __main__ - Printing 3 examples
06/06/2022 01:42:37 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 01:42:37 - INFO - __main__ - ['entailed']
06/06/2022 01:42:37 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 01:42:37 - INFO - __main__ - ['entailed']
06/06/2022 01:42:37 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 01:42:37 - INFO - __main__ - ['entailed']
06/06/2022 01:42:38 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:42:55 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 01:42:55 - INFO - __main__ - task name: tab_fact
06/06/2022 01:42:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:42:55 - INFO - __main__ - Starting training!
06/06/2022 01:43:04 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:43:18 - INFO - __main__ - Loaded 12792 examples from test data
06/06/2022 01:51:44 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_87_0.5_8_predictions.txt
06/06/2022 01:51:44 - INFO - __main__ - Classification-F1 on test data: 0.1613
06/06/2022 01:51:44 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.5, bsz=8, dev_performance=0.5515515515515517, test_performance=0.16132133238935845
06/06/2022 01:51:44 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.4, bsz=8 ...
06/06/2022 01:51:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:51:45 - INFO - __main__ - Printing 3 examples
06/06/2022 01:51:45 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 01:51:45 - INFO - __main__ - ['entailed']
06/06/2022 01:51:45 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 01:51:45 - INFO - __main__ - ['entailed']
06/06/2022 01:51:45 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 01:51:45 - INFO - __main__ - ['entailed']
06/06/2022 01:51:45 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:51:45 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:51:45 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 01:51:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 01:51:45 - INFO - __main__ - Printing 3 examples
06/06/2022 01:51:45 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 01:51:45 - INFO - __main__ - ['entailed']
06/06/2022 01:51:45 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 01:51:45 - INFO - __main__ - ['entailed']
06/06/2022 01:51:45 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 01:51:45 - INFO - __main__ - ['entailed']
06/06/2022 01:51:45 - INFO - __main__ - Tokenizing Input ...
06/06/2022 01:51:45 - INFO - __main__ - Tokenizing Output ...
06/06/2022 01:51:45 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 01:52:00 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 01:52:00 - INFO - __main__ - task name: tab_fact
06/06/2022 01:52:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 01:52:01 - INFO - __main__ - Starting training!
06/06/2022 01:52:06 - INFO - __main__ - Step 10 Global step 10 Train loss 4.57 on epoch=2
06/06/2022 01:52:10 - INFO - __main__ - Step 20 Global step 20 Train loss 1.89 on epoch=4
06/06/2022 01:52:15 - INFO - __main__ - Step 30 Global step 30 Train loss 0.76 on epoch=7
06/06/2022 01:52:19 - INFO - __main__ - Step 40 Global step 40 Train loss 0.48 on epoch=9
06/06/2022 01:52:24 - INFO - __main__ - Step 50 Global step 50 Train loss 0.46 on epoch=12
06/06/2022 01:52:26 - INFO - __main__ - Global step 50 Train loss 1.63 Classification-F1 0.42216142270861834 on epoch=12
06/06/2022 01:52:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.42216142270861834 on epoch=12, global_step=50
06/06/2022 01:52:31 - INFO - __main__ - Step 60 Global step 60 Train loss 0.37 on epoch=14
06/06/2022 01:52:35 - INFO - __main__ - Step 70 Global step 70 Train loss 0.30 on epoch=17
06/06/2022 01:52:40 - INFO - __main__ - Step 80 Global step 80 Train loss 0.42 on epoch=19
06/06/2022 01:52:45 - INFO - __main__ - Step 90 Global step 90 Train loss 0.33 on epoch=22
06/06/2022 01:52:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.27 on epoch=24
06/06/2022 01:52:52 - INFO - __main__ - Global step 100 Train loss 0.34 Classification-F1 0.4920634920634921 on epoch=24
06/06/2022 01:52:52 - INFO - __main__ - Saving model with best Classification-F1: 0.42216142270861834 -> 0.4920634920634921 on epoch=24, global_step=100
06/06/2022 01:52:56 - INFO - __main__ - Step 110 Global step 110 Train loss 0.27 on epoch=27
06/06/2022 01:53:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.23 on epoch=29
06/06/2022 01:53:05 - INFO - __main__ - Step 130 Global step 130 Train loss 0.23 on epoch=32
06/06/2022 01:53:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/06/2022 01:53:14 - INFO - __main__ - Step 150 Global step 150 Train loss 0.23 on epoch=37
06/06/2022 01:53:17 - INFO - __main__ - Global step 150 Train loss 0.24 Classification-F1 0.4748717948717949 on epoch=37
06/06/2022 01:53:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.28 on epoch=39
06/06/2022 01:53:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.25 on epoch=42
06/06/2022 01:53:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.26 on epoch=44
06/06/2022 01:53:35 - INFO - __main__ - Step 190 Global step 190 Train loss 0.22 on epoch=47
06/06/2022 01:53:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=49
06/06/2022 01:53:42 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3333333333333333 on epoch=49
06/06/2022 01:53:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.23 on epoch=52
06/06/2022 01:53:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.21 on epoch=54
06/06/2022 01:53:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.24 on epoch=57
06/06/2022 01:54:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.18 on epoch=59
06/06/2022 01:54:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.19 on epoch=62
06/06/2022 01:54:07 - INFO - __main__ - Global step 250 Train loss 0.21 Classification-F1 0.4920634920634921 on epoch=62
06/06/2022 01:54:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.20 on epoch=64
06/06/2022 01:54:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.24 on epoch=67
06/06/2022 01:54:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.20 on epoch=69
06/06/2022 01:54:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.21 on epoch=72
06/06/2022 01:54:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/06/2022 01:54:32 - INFO - __main__ - Global step 300 Train loss 0.22 Classification-F1 0.3306505700871898 on epoch=74
06/06/2022 01:54:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.17 on epoch=77
06/06/2022 01:54:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.21 on epoch=79
06/06/2022 01:54:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.21 on epoch=82
06/06/2022 01:54:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=84
06/06/2022 01:54:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=87
06/06/2022 01:54:57 - INFO - __main__ - Global step 350 Train loss 0.20 Classification-F1 0.2175438596491228 on epoch=87
06/06/2022 01:55:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=89
06/06/2022 01:55:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/06/2022 01:55:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=94
06/06/2022 01:55:15 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=97
06/06/2022 01:55:20 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/06/2022 01:55:23 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.5272229822161423 on epoch=99
06/06/2022 01:55:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4920634920634921 -> 0.5272229822161423 on epoch=99, global_step=400
06/06/2022 01:55:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/06/2022 01:55:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=104
06/06/2022 01:55:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/06/2022 01:55:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/06/2022 01:55:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/06/2022 01:55:48 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.3333333333333333 on epoch=112
06/06/2022 01:55:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=114
06/06/2022 01:55:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/06/2022 01:56:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/06/2022 01:56:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/06/2022 01:56:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/06/2022 01:56:13 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.3671451355661882 on epoch=124
06/06/2022 01:56:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=127
06/06/2022 01:56:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
06/06/2022 01:56:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=132
06/06/2022 01:56:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/06/2022 01:56:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=137
06/06/2022 01:56:39 - INFO - __main__ - Global step 550 Train loss 0.19 Classification-F1 0.3333333333333333 on epoch=137
06/06/2022 01:56:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=139
06/06/2022 01:56:48 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/06/2022 01:56:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=144
06/06/2022 01:56:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/06/2022 01:57:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=149
06/06/2022 01:57:04 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.5467643467643467 on epoch=149
06/06/2022 01:57:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5272229822161423 -> 0.5467643467643467 on epoch=149, global_step=600
06/06/2022 01:57:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/06/2022 01:57:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/06/2022 01:57:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=157
06/06/2022 01:57:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=159
06/06/2022 01:57:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=162
06/06/2022 01:57:29 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.537733499377335 on epoch=162
06/06/2022 01:57:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
06/06/2022 01:57:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=167
06/06/2022 01:57:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=169
06/06/2022 01:57:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=172
06/06/2022 01:57:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=174
06/06/2022 01:57:55 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.2346616065781151 on epoch=174
06/06/2022 01:57:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=177
06/06/2022 01:58:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=179
06/06/2022 01:58:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=182
06/06/2022 01:58:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=184
06/06/2022 01:58:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=187
06/06/2022 01:58:20 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.3275316455696203 on epoch=187
06/06/2022 01:58:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=189
06/06/2022 01:58:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/06/2022 01:58:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=194
06/06/2022 01:58:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=197
06/06/2022 01:58:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/06/2022 01:58:45 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.4213381555153707 on epoch=199
06/06/2022 01:58:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/06/2022 01:58:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=204
06/06/2022 01:58:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/06/2022 01:59:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=209
06/06/2022 01:59:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/06/2022 01:59:10 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.19993069993069995 on epoch=212
06/06/2022 01:59:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=214
06/06/2022 01:59:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=217
06/06/2022 01:59:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=219
06/06/2022 01:59:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=222
06/06/2022 01:59:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=224
06/06/2022 01:59:36 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.48051948051948057 on epoch=224
06/06/2022 01:59:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=227
06/06/2022 01:59:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=229
06/06/2022 01:59:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/06/2022 01:59:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=234
06/06/2022 01:59:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=237
06/06/2022 02:00:01 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.2840108401084011 on epoch=237
06/06/2022 02:00:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=239
06/06/2022 02:00:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=242
06/06/2022 02:00:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/06/2022 02:00:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=247
06/06/2022 02:00:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=249
06/06/2022 02:00:26 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.17947368421052629 on epoch=249
06/06/2022 02:00:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=252
06/06/2022 02:00:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=254
06/06/2022 02:00:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=257
06/06/2022 02:00:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=259
06/06/2022 02:00:49 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/06/2022 02:00:52 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.21176963936259435 on epoch=262
06/06/2022 02:00:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=264
06/06/2022 02:01:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/06/2022 02:01:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=269
06/06/2022 02:01:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=272
06/06/2022 02:01:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=274
06/06/2022 02:01:17 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.256140350877193 on epoch=274
06/06/2022 02:01:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=277
06/06/2022 02:01:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/06/2022 02:01:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/06/2022 02:01:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
06/06/2022 02:01:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=287
06/06/2022 02:01:42 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.19166666666666665 on epoch=287
06/06/2022 02:01:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=289
06/06/2022 02:01:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=292
06/06/2022 02:01:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=294
06/06/2022 02:02:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=297
06/06/2022 02:02:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=299
06/06/2022 02:02:07 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.19946808510638298 on epoch=299
06/06/2022 02:02:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/06/2022 02:02:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
06/06/2022 02:02:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=307
06/06/2022 02:02:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=309
06/06/2022 02:02:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/06/2022 02:02:33 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.1291208791208791 on epoch=312
06/06/2022 02:02:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/06/2022 02:02:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/06/2022 02:02:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=319
06/06/2022 02:02:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/06/2022 02:02:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/06/2022 02:02:58 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.31444444444444447 on epoch=324
06/06/2022 02:03:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=327
06/06/2022 02:03:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/06/2022 02:03:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=332
06/06/2022 02:03:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/06/2022 02:03:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/06/2022 02:03:23 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.45440454662877805 on epoch=337
06/06/2022 02:03:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/06/2022 02:03:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
06/06/2022 02:03:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/06/2022 02:03:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/06/2022 02:03:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/06/2022 02:03:49 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.4682306940371457 on epoch=349
06/06/2022 02:03:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/06/2022 02:03:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/06/2022 02:04:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/06/2022 02:04:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/06/2022 02:04:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/06/2022 02:04:14 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.4181818181818182 on epoch=362
06/06/2022 02:04:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/06/2022 02:04:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/06/2022 02:04:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=369
06/06/2022 02:04:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/06/2022 02:04:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/06/2022 02:04:39 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.45705196182396607 on epoch=374
06/06/2022 02:04:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/06/2022 02:04:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=379
06/06/2022 02:04:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/06/2022 02:04:57 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/06/2022 02:05:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=387
06/06/2022 02:05:04 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.4947797300738477 on epoch=387
06/06/2022 02:05:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=389
06/06/2022 02:05:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/06/2022 02:05:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/06/2022 02:05:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/06/2022 02:05:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/06/2022 02:05:29 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.3054247339961626 on epoch=399
06/06/2022 02:05:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/06/2022 02:05:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/06/2022 02:05:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/06/2022 02:05:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/06/2022 02:05:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/06/2022 02:05:54 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.48051948051948057 on epoch=412
06/06/2022 02:05:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/06/2022 02:06:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/06/2022 02:06:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/06/2022 02:06:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/06/2022 02:06:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/06/2022 02:06:20 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.46880856760374834 on epoch=424
06/06/2022 02:06:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/06/2022 02:06:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/06/2022 02:06:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/06/2022 02:06:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/06/2022 02:06:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=437
06/06/2022 02:06:45 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.500880503144654 on epoch=437
06/06/2022 02:06:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/06/2022 02:06:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/06/2022 02:06:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/06/2022 02:07:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/06/2022 02:07:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/06/2022 02:07:10 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.4748717948717949 on epoch=449
06/06/2022 02:07:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/06/2022 02:07:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/06/2022 02:07:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/06/2022 02:07:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/06/2022 02:07:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=462
06/06/2022 02:07:35 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.3818181818181818 on epoch=462
06/06/2022 02:07:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/06/2022 02:07:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/06/2022 02:07:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/06/2022 02:07:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/06/2022 02:07:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/06/2022 02:08:00 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.48747093774218553 on epoch=474
06/06/2022 02:08:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/06/2022 02:08:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/06/2022 02:08:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/06/2022 02:08:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/06/2022 02:08:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/06/2022 02:08:26 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.4458874458874459 on epoch=487
06/06/2022 02:08:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/06/2022 02:08:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/06/2022 02:08:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/06/2022 02:08:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/06/2022 02:08:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/06/2022 02:08:51 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.41125541125541126 on epoch=499
06/06/2022 02:08:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/06/2022 02:09:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/06/2022 02:09:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/06/2022 02:09:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/06/2022 02:09:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/06/2022 02:09:16 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.2793263646922184 on epoch=512
06/06/2022 02:09:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=514
06/06/2022 02:09:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=517
06/06/2022 02:09:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/06/2022 02:09:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/06/2022 02:09:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/06/2022 02:09:41 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.4181818181818182 on epoch=524
06/06/2022 02:09:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/06/2022 02:09:50 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/06/2022 02:09:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/06/2022 02:10:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/06/2022 02:10:04 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/06/2022 02:10:07 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.43333333333333335 on epoch=537
06/06/2022 02:10:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/06/2022 02:10:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=542
06/06/2022 02:10:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/06/2022 02:10:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/06/2022 02:10:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/06/2022 02:10:32 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.2713675213675214 on epoch=549
06/06/2022 02:10:37 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/06/2022 02:10:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/06/2022 02:10:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/06/2022 02:10:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/06/2022 02:10:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/06/2022 02:10:57 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.23925667828106853 on epoch=562
06/06/2022 02:11:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/06/2022 02:11:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/06/2022 02:11:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/06/2022 02:11:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/06/2022 02:11:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/06/2022 02:11:23 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.30467571644042235 on epoch=574
06/06/2022 02:11:27 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/06/2022 02:11:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/06/2022 02:11:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/06/2022 02:11:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/06/2022 02:11:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/06/2022 02:11:48 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.30489064113395287 on epoch=587
06/06/2022 02:11:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/06/2022 02:11:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 02:12:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/06/2022 02:12:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/06/2022 02:12:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/06/2022 02:12:13 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.2545045045045045 on epoch=599
06/06/2022 02:12:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 02:12:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 02:12:27 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/06/2022 02:12:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 02:12:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/06/2022 02:12:38 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.22333333333333333 on epoch=612
06/06/2022 02:12:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/06/2022 02:12:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/06/2022 02:12:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/06/2022 02:12:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 02:13:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/06/2022 02:13:03 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.23019350127783864 on epoch=624
06/06/2022 02:13:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/06/2022 02:13:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/06/2022 02:13:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 02:13:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/06/2022 02:13:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/06/2022 02:13:28 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.3846153846153846 on epoch=637
06/06/2022 02:13:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/06/2022 02:13:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 02:13:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/06/2022 02:13:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/06/2022 02:13:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/06/2022 02:13:53 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.30186054599200135 on epoch=649
06/06/2022 02:13:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/06/2022 02:14:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 02:14:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 02:14:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/06/2022 02:14:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/06/2022 02:14:18 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.4874874874874875 on epoch=662
06/06/2022 02:14:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 02:14:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 02:14:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 02:14:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 02:14:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 02:14:43 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.473972602739726 on epoch=674
06/06/2022 02:14:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 02:14:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 02:14:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/06/2022 02:15:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/06/2022 02:15:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/06/2022 02:15:09 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.4748717948717949 on epoch=687
06/06/2022 02:15:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 02:15:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/06/2022 02:15:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/06/2022 02:15:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 02:15:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 02:15:34 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.4748717948717949 on epoch=699
06/06/2022 02:15:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 02:15:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/06/2022 02:15:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 02:15:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 02:15:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 02:15:59 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.4920634920634921 on epoch=712
06/06/2022 02:16:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 02:16:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/06/2022 02:16:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 02:16:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/06/2022 02:16:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/06/2022 02:16:24 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.29131504922644164 on epoch=724
06/06/2022 02:16:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 02:16:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/06/2022 02:16:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 02:16:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 02:16:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/06/2022 02:16:49 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.4213381555153707 on epoch=737
06/06/2022 02:16:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/06/2022 02:16:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 02:17:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/06/2022 02:17:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/06/2022 02:17:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/06/2022 02:17:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 02:17:13 - INFO - __main__ - Printing 3 examples
06/06/2022 02:17:13 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 02:17:13 - INFO - __main__ - ['entailed']
06/06/2022 02:17:13 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 02:17:13 - INFO - __main__ - ['entailed']
06/06/2022 02:17:13 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 02:17:13 - INFO - __main__ - ['entailed']
06/06/2022 02:17:13 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:17:13 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:17:14 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 02:17:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 02:17:14 - INFO - __main__ - Printing 3 examples
06/06/2022 02:17:14 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 02:17:14 - INFO - __main__ - ['entailed']
06/06/2022 02:17:14 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 02:17:14 - INFO - __main__ - ['entailed']
06/06/2022 02:17:14 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 02:17:14 - INFO - __main__ - ['entailed']
06/06/2022 02:17:14 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:17:14 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:17:14 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 02:17:15 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.20128205128205123 on epoch=749
06/06/2022 02:17:15 - INFO - __main__ - save last model!
06/06/2022 02:17:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 02:17:15 - INFO - __main__ - Start tokenizing ... 12792 instances
06/06/2022 02:17:15 - INFO - __main__ - Printing 3 examples
06/06/2022 02:17:15 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 02:17:15 - INFO - __main__ - ['entailed']
06/06/2022 02:17:15 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 02:17:15 - INFO - __main__ - ['entailed']
06/06/2022 02:17:15 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 02:17:15 - INFO - __main__ - ['entailed']
06/06/2022 02:17:15 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:17:32 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 02:17:32 - INFO - __main__ - task name: tab_fact
06/06/2022 02:17:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 02:17:33 - INFO - __main__ - Starting training!
06/06/2022 02:17:39 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:17:52 - INFO - __main__ - Loaded 12792 examples from test data
06/06/2022 02:26:10 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_87_0.4_8_predictions.txt
06/06/2022 02:26:10 - INFO - __main__ - Classification-F1 on test data: 0.1307
06/06/2022 02:26:11 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.4, bsz=8, dev_performance=0.5467643467643467, test_performance=0.13073406656809936
06/06/2022 02:26:11 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.3, bsz=8 ...
06/06/2022 02:26:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 02:26:12 - INFO - __main__ - Printing 3 examples
06/06/2022 02:26:12 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 02:26:12 - INFO - __main__ - ['entailed']
06/06/2022 02:26:12 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 02:26:12 - INFO - __main__ - ['entailed']
06/06/2022 02:26:12 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 02:26:12 - INFO - __main__ - ['entailed']
06/06/2022 02:26:12 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:26:12 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:26:12 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 02:26:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 02:26:12 - INFO - __main__ - Printing 3 examples
06/06/2022 02:26:12 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 02:26:12 - INFO - __main__ - ['entailed']
06/06/2022 02:26:12 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 02:26:12 - INFO - __main__ - ['entailed']
06/06/2022 02:26:12 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 02:26:12 - INFO - __main__ - ['entailed']
06/06/2022 02:26:12 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:26:12 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:26:12 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 02:26:27 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 02:26:27 - INFO - __main__ - task name: tab_fact
06/06/2022 02:26:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 02:26:28 - INFO - __main__ - Starting training!
06/06/2022 02:26:33 - INFO - __main__ - Step 10 Global step 10 Train loss 5.26 on epoch=2
06/06/2022 02:26:38 - INFO - __main__ - Step 20 Global step 20 Train loss 3.22 on epoch=4
06/06/2022 02:26:42 - INFO - __main__ - Step 30 Global step 30 Train loss 1.81 on epoch=7
06/06/2022 02:26:47 - INFO - __main__ - Step 40 Global step 40 Train loss 0.88 on epoch=9
06/06/2022 02:26:52 - INFO - __main__ - Step 50 Global step 50 Train loss 0.64 on epoch=12
06/06/2022 02:26:54 - INFO - __main__ - Global step 50 Train loss 2.36 Classification-F1 0.3333333333333333 on epoch=12
06/06/2022 02:26:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3333333333333333 on epoch=12, global_step=50
06/06/2022 02:26:59 - INFO - __main__ - Step 60 Global step 60 Train loss 0.54 on epoch=14
06/06/2022 02:27:03 - INFO - __main__ - Step 70 Global step 70 Train loss 0.41 on epoch=17
06/06/2022 02:27:08 - INFO - __main__ - Step 80 Global step 80 Train loss 0.36 on epoch=19
06/06/2022 02:27:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.36 on epoch=22
06/06/2022 02:27:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.33 on epoch=24
06/06/2022 02:27:20 - INFO - __main__ - Global step 100 Train loss 0.40 Classification-F1 0.3333333333333333 on epoch=24
06/06/2022 02:27:24 - INFO - __main__ - Step 110 Global step 110 Train loss 0.33 on epoch=27
06/06/2022 02:27:29 - INFO - __main__ - Step 120 Global step 120 Train loss 0.28 on epoch=29
06/06/2022 02:27:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.32 on epoch=32
06/06/2022 02:27:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.26 on epoch=34
06/06/2022 02:27:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.27 on epoch=37
06/06/2022 02:27:45 - INFO - __main__ - Global step 150 Train loss 0.29 Classification-F1 0.39756367663344405 on epoch=37
06/06/2022 02:27:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3333333333333333 -> 0.39756367663344405 on epoch=37, global_step=150
06/06/2022 02:27:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.27 on epoch=39
06/06/2022 02:27:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.28 on epoch=42
06/06/2022 02:27:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.25 on epoch=44
06/06/2022 02:28:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.25 on epoch=47
06/06/2022 02:28:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.22 on epoch=49
06/06/2022 02:28:10 - INFO - __main__ - Global step 200 Train loss 0.25 Classification-F1 0.3671451355661882 on epoch=49
06/06/2022 02:28:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.24 on epoch=52
06/06/2022 02:28:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.24 on epoch=54
06/06/2022 02:28:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=57
06/06/2022 02:28:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=59
06/06/2022 02:28:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=62
06/06/2022 02:28:35 - INFO - __main__ - Global step 250 Train loss 0.25 Classification-F1 0.2471523748119493 on epoch=62
06/06/2022 02:28:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.22 on epoch=64
06/06/2022 02:28:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/06/2022 02:28:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.25 on epoch=69
06/06/2022 02:28:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.26 on epoch=72
06/06/2022 02:28:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=74
06/06/2022 02:29:00 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.3333333333333333 on epoch=74
06/06/2022 02:29:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/06/2022 02:29:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=79
06/06/2022 02:29:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=82
06/06/2022 02:29:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=84
06/06/2022 02:29:23 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=87
06/06/2022 02:29:25 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.4947797300738477 on epoch=87
06/06/2022 02:29:25 - INFO - __main__ - Saving model with best Classification-F1: 0.39756367663344405 -> 0.4947797300738477 on epoch=87, global_step=350
06/06/2022 02:29:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/06/2022 02:29:34 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/06/2022 02:29:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=94
06/06/2022 02:29:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=97
06/06/2022 02:29:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=99
06/06/2022 02:29:50 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3333333333333333 on epoch=99
06/06/2022 02:29:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=102
06/06/2022 02:29:59 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=104
06/06/2022 02:30:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=107
06/06/2022 02:30:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=109
06/06/2022 02:30:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/06/2022 02:30:15 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.3327922077922078 on epoch=112
06/06/2022 02:30:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=114
06/06/2022 02:30:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/06/2022 02:30:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/06/2022 02:30:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=122
06/06/2022 02:30:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
06/06/2022 02:30:41 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.5625 on epoch=124
06/06/2022 02:30:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4947797300738477 -> 0.5625 on epoch=124, global_step=500
06/06/2022 02:30:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=127
06/06/2022 02:30:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=129
06/06/2022 02:30:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=132
06/06/2022 02:30:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/06/2022 02:31:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/06/2022 02:31:06 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.23232323232323235 on epoch=137
06/06/2022 02:31:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.20 on epoch=139
06/06/2022 02:31:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=142
06/06/2022 02:31:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/06/2022 02:31:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=147
06/06/2022 02:31:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=149
06/06/2022 02:31:31 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.30721059223474684 on epoch=149
06/06/2022 02:31:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=152
06/06/2022 02:31:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/06/2022 02:31:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=157
06/06/2022 02:31:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/06/2022 02:31:54 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/06/2022 02:31:57 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.2253691600096829 on epoch=162
06/06/2022 02:32:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/06/2022 02:32:06 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=167
06/06/2022 02:32:10 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/06/2022 02:32:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=172
06/06/2022 02:32:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/06/2022 02:32:22 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.17233468286099868 on epoch=174
06/06/2022 02:32:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=177
06/06/2022 02:32:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/06/2022 02:32:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
06/06/2022 02:32:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=184
06/06/2022 02:32:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=187
06/06/2022 02:32:47 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.1743943191311612 on epoch=187
06/06/2022 02:32:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=189
06/06/2022 02:32:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=192
06/06/2022 02:33:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=194
06/06/2022 02:33:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=197
06/06/2022 02:33:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/06/2022 02:33:12 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.4181818181818182 on epoch=199
06/06/2022 02:33:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/06/2022 02:33:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/06/2022 02:33:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=207
06/06/2022 02:33:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=209
06/06/2022 02:33:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/06/2022 02:33:37 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.3511520737327189 on epoch=212
06/06/2022 02:33:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/06/2022 02:33:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=217
06/06/2022 02:33:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=219
06/06/2022 02:33:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=222
06/06/2022 02:34:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=224
06/06/2022 02:34:03 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.3546576879910213 on epoch=224
06/06/2022 02:34:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/06/2022 02:34:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=229
06/06/2022 02:34:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=232
06/06/2022 02:34:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=234
06/06/2022 02:34:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/06/2022 02:34:28 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.20157289776164547 on epoch=237
06/06/2022 02:34:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=239
06/06/2022 02:34:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=242
06/06/2022 02:34:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=244
06/06/2022 02:34:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=247
06/06/2022 02:34:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=249
06/06/2022 02:34:53 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.17852564102564106 on epoch=249
06/06/2022 02:34:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=252
06/06/2022 02:35:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=254
06/06/2022 02:35:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/06/2022 02:35:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=259
06/06/2022 02:35:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=262
06/06/2022 02:35:19 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.2799539170506913 on epoch=262
06/06/2022 02:35:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=264
06/06/2022 02:35:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=267
06/06/2022 02:35:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=269
06/06/2022 02:35:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/06/2022 02:35:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=274
06/06/2022 02:35:44 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.18949096880131364 on epoch=274
06/06/2022 02:35:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=277
06/06/2022 02:35:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=279
06/06/2022 02:35:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=282
06/06/2022 02:36:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=284
06/06/2022 02:36:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=287
06/06/2022 02:36:10 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.2989594946116685 on epoch=287
06/06/2022 02:36:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=289
06/06/2022 02:36:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=292
06/06/2022 02:36:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=294
06/06/2022 02:36:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=297
06/06/2022 02:36:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=299
06/06/2022 02:36:35 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.17460317460317462 on epoch=299
06/06/2022 02:36:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=302
06/06/2022 02:36:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=304
06/06/2022 02:36:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=307
06/06/2022 02:36:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=309
06/06/2022 02:36:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=312
06/06/2022 02:37:01 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.3328092243186583 on epoch=312
06/06/2022 02:37:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=314
06/06/2022 02:37:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=317
06/06/2022 02:37:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=319
06/06/2022 02:37:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=322
06/06/2022 02:37:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=324
06/06/2022 02:37:26 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.18081343943412906 on epoch=324
06/06/2022 02:37:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=327
06/06/2022 02:37:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=329
06/06/2022 02:37:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=332
06/06/2022 02:37:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=334
06/06/2022 02:37:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=337
06/06/2022 02:37:52 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.2244766089428793 on epoch=337
06/06/2022 02:37:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=339
06/06/2022 02:38:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=342
06/06/2022 02:38:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=344
06/06/2022 02:38:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/06/2022 02:38:14 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=349
06/06/2022 02:38:17 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.21505376344086022 on epoch=349
06/06/2022 02:38:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=352
06/06/2022 02:38:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=354
06/06/2022 02:38:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=357
06/06/2022 02:38:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=359
06/06/2022 02:38:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=362
06/06/2022 02:38:42 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.20693277310924368 on epoch=362
06/06/2022 02:38:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=364
06/06/2022 02:38:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/06/2022 02:38:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=369
06/06/2022 02:39:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=372
06/06/2022 02:39:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=374
06/06/2022 02:39:08 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.39999999999999997 on epoch=374
06/06/2022 02:39:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=377
06/06/2022 02:39:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=379
06/06/2022 02:39:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/06/2022 02:39:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/06/2022 02:39:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/06/2022 02:39:33 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.2833746898263027 on epoch=387
06/06/2022 02:39:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=389
06/06/2022 02:39:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=392
06/06/2022 02:39:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=394
06/06/2022 02:39:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/06/2022 02:39:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/06/2022 02:39:59 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.22036985149901933 on epoch=399
06/06/2022 02:40:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=402
06/06/2022 02:40:08 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=404
06/06/2022 02:40:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=407
06/06/2022 02:40:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/06/2022 02:40:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=412
06/06/2022 02:40:24 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.17946203418324458 on epoch=412
06/06/2022 02:40:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/06/2022 02:40:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
06/06/2022 02:40:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/06/2022 02:40:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/06/2022 02:40:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=424
06/06/2022 02:40:49 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.20485542825968361 on epoch=424
06/06/2022 02:40:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/06/2022 02:40:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/06/2022 02:41:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/06/2022 02:41:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/06/2022 02:41:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/06/2022 02:41:14 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.2558275058275058 on epoch=437
06/06/2022 02:41:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=439
06/06/2022 02:41:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/06/2022 02:41:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=444
06/06/2022 02:41:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/06/2022 02:41:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=449
06/06/2022 02:41:40 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.13869969040247676 on epoch=449
06/06/2022 02:41:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=452
06/06/2022 02:41:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=454
06/06/2022 02:41:53 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/06/2022 02:41:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/06/2022 02:42:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/06/2022 02:42:05 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.20315964523281596 on epoch=462
06/06/2022 02:42:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/06/2022 02:42:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/06/2022 02:42:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=469
06/06/2022 02:42:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/06/2022 02:42:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/06/2022 02:42:30 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.2519057519057519 on epoch=474
06/06/2022 02:42:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/06/2022 02:42:39 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/06/2022 02:42:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/06/2022 02:42:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/06/2022 02:42:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/06/2022 02:42:56 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.20640120967741937 on epoch=487
06/06/2022 02:43:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/06/2022 02:43:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/06/2022 02:43:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/06/2022 02:43:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/06/2022 02:43:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/06/2022 02:43:21 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.2568965517241379 on epoch=499
06/06/2022 02:43:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/06/2022 02:43:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/06/2022 02:43:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/06/2022 02:43:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/06/2022 02:43:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=512
06/06/2022 02:43:46 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.28951486697965567 on epoch=512
06/06/2022 02:43:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/06/2022 02:43:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/06/2022 02:44:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/06/2022 02:44:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/06/2022 02:44:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/06/2022 02:44:12 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.18835978835978834 on epoch=524
06/06/2022 02:44:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/06/2022 02:44:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/06/2022 02:44:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/06/2022 02:44:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/06/2022 02:44:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/06/2022 02:44:37 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.2803418803418804 on epoch=537
06/06/2022 02:44:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=539
06/06/2022 02:44:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/06/2022 02:44:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/06/2022 02:44:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/06/2022 02:45:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=549
06/06/2022 02:45:03 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.3882717644019633 on epoch=549
06/06/2022 02:45:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/06/2022 02:45:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/06/2022 02:45:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/06/2022 02:45:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/06/2022 02:45:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/06/2022 02:45:29 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.3882717644019633 on epoch=562
06/06/2022 02:45:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=564
06/06/2022 02:45:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.12 on epoch=567
06/06/2022 02:45:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/06/2022 02:45:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/06/2022 02:45:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/06/2022 02:45:54 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.40427672955974847 on epoch=574
06/06/2022 02:45:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/06/2022 02:46:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=579
06/06/2022 02:46:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/06/2022 02:46:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/06/2022 02:46:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/06/2022 02:46:19 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.23822081575246135 on epoch=587
06/06/2022 02:46:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=589
06/06/2022 02:46:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/06/2022 02:46:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/06/2022 02:46:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/06/2022 02:46:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/06/2022 02:46:45 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.37833125778331256 on epoch=599
06/06/2022 02:46:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/06/2022 02:46:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/06/2022 02:46:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/06/2022 02:47:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/06/2022 02:47:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/06/2022 02:47:10 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.3904761904761905 on epoch=612
06/06/2022 02:47:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/06/2022 02:47:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/06/2022 02:47:24 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=619
06/06/2022 02:47:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/06/2022 02:47:33 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/06/2022 02:47:35 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.2689873417721519 on epoch=624
06/06/2022 02:47:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/06/2022 02:47:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/06/2022 02:47:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/06/2022 02:47:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/06/2022 02:47:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/06/2022 02:48:01 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.37798791699500917 on epoch=637
06/06/2022 02:48:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/06/2022 02:48:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/06/2022 02:48:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=644
06/06/2022 02:48:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/06/2022 02:48:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/06/2022 02:48:26 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.3666666666666667 on epoch=649
06/06/2022 02:48:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/06/2022 02:48:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/06/2022 02:48:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/06/2022 02:48:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/06/2022 02:48:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/06/2022 02:48:51 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.41487521620953793 on epoch=662
06/06/2022 02:48:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/06/2022 02:49:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 02:49:05 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/06/2022 02:49:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/06/2022 02:49:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/06/2022 02:49:16 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.3846153846153846 on epoch=674
06/06/2022 02:49:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 02:49:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/06/2022 02:49:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=682
06/06/2022 02:49:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/06/2022 02:49:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/06/2022 02:49:42 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.36440030557677616 on epoch=687
06/06/2022 02:49:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=689
06/06/2022 02:49:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/06/2022 02:49:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/06/2022 02:50:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 02:50:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/06/2022 02:50:07 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.4465035829009143 on epoch=699
06/06/2022 02:50:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/06/2022 02:50:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 02:50:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/06/2022 02:50:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 02:50:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/06/2022 02:50:32 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.3266888150609081 on epoch=712
06/06/2022 02:50:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/06/2022 02:50:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/06/2022 02:50:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 02:50:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=722
06/06/2022 02:50:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/06/2022 02:50:57 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.2803418803418804 on epoch=724
06/06/2022 02:51:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/06/2022 02:51:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/06/2022 02:51:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 02:51:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/06/2022 02:51:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/06/2022 02:51:22 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.3882717644019633 on epoch=737
06/06/2022 02:51:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/06/2022 02:51:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/06/2022 02:51:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/06/2022 02:51:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/06/2022 02:51:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 02:51:46 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 02:51:46 - INFO - __main__ - Printing 3 examples
06/06/2022 02:51:46 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 02:51:46 - INFO - __main__ - ['entailed']
06/06/2022 02:51:46 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 02:51:46 - INFO - __main__ - ['entailed']
06/06/2022 02:51:46 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 02:51:46 - INFO - __main__ - ['entailed']
06/06/2022 02:51:46 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:51:46 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:51:46 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 02:51:46 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 02:51:46 - INFO - __main__ - Printing 3 examples
06/06/2022 02:51:46 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 02:51:46 - INFO - __main__ - ['entailed']
06/06/2022 02:51:46 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 02:51:46 - INFO - __main__ - ['entailed']
06/06/2022 02:51:46 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 02:51:46 - INFO - __main__ - ['entailed']
06/06/2022 02:51:46 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:51:46 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:51:46 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 02:51:47 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.36599732262382867 on epoch=749
06/06/2022 02:51:47 - INFO - __main__ - save last model!
06/06/2022 02:51:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 02:51:47 - INFO - __main__ - Start tokenizing ... 12792 instances
06/06/2022 02:51:47 - INFO - __main__ - Printing 3 examples
06/06/2022 02:51:47 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 02:51:47 - INFO - __main__ - ['entailed']
06/06/2022 02:51:47 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 02:51:47 - INFO - __main__ - ['entailed']
06/06/2022 02:51:47 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 02:51:47 - INFO - __main__ - ['entailed']
06/06/2022 02:51:47 - INFO - __main__ - Tokenizing Input ...
06/06/2022 02:52:02 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 02:52:02 - INFO - __main__ - task name: tab_fact
06/06/2022 02:52:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 02:52:03 - INFO - __main__ - Starting training!
06/06/2022 02:52:14 - INFO - __main__ - Tokenizing Output ...
06/06/2022 02:52:29 - INFO - __main__ - Loaded 12792 examples from test data
06/06/2022 03:00:46 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_87_0.3_8_predictions.txt
06/06/2022 03:00:46 - INFO - __main__ - Classification-F1 on test data: 0.1539
06/06/2022 03:00:47 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.3, bsz=8, dev_performance=0.5625, test_performance=0.15390904089390786
06/06/2022 03:00:47 - INFO - __main__ - Running ... prefix=tab_fact_32_87, lr=0.2, bsz=8 ...
06/06/2022 03:00:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 03:00:48 - INFO - __main__ - Printing 3 examples
06/06/2022 03:00:48 - INFO - __main__ -  [tab_fact] statement: the episode title sin of the father have a share value of 10 [SEP] table_caption: none [SEP] table_text: #episode#air date#timeslot (est)#rating#share#18 - 49 (rating / share)#viewers (m)#weekly rank  [n] 1#a death in the family#october 1 , 2009#thursday 10:00 pm#7.6#13#4.6 / 13#11.58#20 [n] 2#the way we were#october 8 , 2009#thursday 10:00 pm#6.2#11#3.6 / 10#9.50#25 [n] 3#right here , right now#october 15 , 2009#thursday 10:00 pm#6.8#12#3.8 / 11#10.36#21 [n] 4#pushing the limits#october 22 , 2009#thursday 10:00 pm#6.7#11#3.7 / 10#9.928#28 [n] 5#strange bedfellows#october 29 , 2009#thursday 10:00 pm#6.1#10#3.6 / 9#9.155#29 [n] 6#slip slidin™ away#november 5 , 2009#thursday 10:00 pm#6.0#10#3.4 / 10#9.11#27 [n] 7#the hard part#november 12 , 2009#thursday 10:00 pm#6.7#11#3.9 / 11#10.249#tba [n] 8#sins of the father#november 19 , 2009#thursday 10:00 pm#6.0#10#3.1 / 9#8.926#tba [n] 9#the parent trap#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 10#blowups#december 3 , 2009#thursday 10:00 pm#6.3#10#3.2 / 8#9.211#24 [n] 11#another second chance#january 14 , 2010#thursday 10:00 pm#7.1#12#4.2 / 12#10.963#tba [n] 12#best laid plans#january 21 , 2010#thursday 10:00 pm#6.6#11#3.6 / 10#9.637#tba [n] 13#shotgun#february 4 , 2010#thursday 10:00 pm#6.2#11#3.3 / 10#9.254#tba [n] 14#love bites#february 11 , 2010#thursday 10:00 pm#6.1#10#3.1 / 9#9.036#26 [n] 15#'til death do us part#february 18 , 2010#thursday 10:00 pm#5.1#8#2.8 / 7#7.593#32 [n] 16#fear of flying#march 4 , 2010#thursday 10:00 pm#5.2#9#2.7 / 8#7.572#36 [n] 17#triangles#march 11 , 2010#thursday 10:00 pm#5.3#9#2.8 / 8#7.656#tba [n] 18#pulling the plug#march 25 , 2010#thursday 10:00 pm#5.8#10#2.9 / 8#8.705#tba [n] 19#eyes wide open#april 1 , 2010#thursday 10:00 pm#5.3#9#2.6 / 8#7.822#tba [n] 20#second choices#april 22 , 2010#thursday 9:00 pm#5.1#9#2.3 / 6#7.491#tba [n] 21#war#april 29 , 2010#thursday 10:00 pm#5.4#9#2.9 / 9#7.775#tba [n] 22#in the name of love#may 6 , 2010#thursday 10:00 pm#5.7#10#2.8 / 8#8.152#tba [n] 
06/06/2022 03:00:48 - INFO - __main__ - ['entailed']
06/06/2022 03:00:48 - INFO - __main__ -  [tab_fact] statement: all team draw exactly 1 game out of 5 [SEP] table_caption: 2001 in paraguayan football [SEP] table_text: position#team#played#wins#draws#losses#scored#conceded#bonus points#points [n] 1#12 de octubre#5#3#1#1#10#4#-#10 [n] 2#olimpia#5#3#1#1#8#5#-#10 [n] 3#libertad#5#2#1#2#11#11#-#7 [n] 4#guaraní#5#2#1#2#4#5#-#7 [n] 5#sportivo luqueño#5#1#1#3#7#13#-#7 [n] 6#sol de america#5#1#1#3#8#10#-#4 [n] 
06/06/2022 03:00:48 - INFO - __main__ - ['entailed']
06/06/2022 03:00:48 - INFO - __main__ -  [tab_fact] statement: new york be 1 of 5 team to beat the raptor during february 2008 [SEP] table_caption: 2007 - 08 toronto raptors season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 46#february 1#la lakers#l 101 - 121 (ot)#andrea bargnani (28)#chris bosh (15)#juan dixon (6)#air canada centre 19800#25 - 21 [n] 47#february 4#miami#w 114 - 82 (ot)#chris bosh (24)#jamario moon (9)#josé calderón (10)#american airlines arena 19600#26 - 21 [n] 48#february 8#la clippers#l 98 - 102 (ot)#chris bosh (29)#chris bosh (12)#josé calderón (14)#air canada centre 19800#26 - 22 [n] 49#february 10#minnesota#w 105 - 82 (ot)#andrea bargnani (16)#chris bosh , carlos delfino (9)#t j ford (13)#target center 13785#27 - 22 [n] 50#february 11#san antonio#l 88 - 93 (ot)#josé calderón (27)#chris bosh , carlos delfino , jamario moon (8)#josé calderón (6)#air canada centre 19800#27 - 23 [n] 51#february 13#new jersey#w 109 - 91 (ot)#chris bosh (27)#chris bosh , carlos delfino (9)#josé calderón (12)#air canada centre 19800#28 - 23 [n] 52#february 20#orlando#w 127 - 110 (ot)#chris bosh (40)#jamario moon (12)#josé calderón (13)#air canada centre 19800#29 - 23 [n] 53#february 22#new york#l 99 - 103 (ot)#chris bosh (23)#chris bosh , jamario moon (8)#josé calderón (6)#madison square garden 19763#29 - 24 [n] 54#february 24#new york#w 115 - 92 (ot)#andrea bargnani (25)#jamario moon , radoslav nesterović (8)#josé calderón (7)#air canada centre 19800#30 - 24 [n] 55#february 25#indiana#w 102 - 98 (ot)#chris bosh (24)#anthony parker (11)#t j ford (7)#conseco fieldhouse 10468#31 - 24 [n] 56#february 27#minnesota#w 107 - 85 (ot)#chris bosh (28)#chris bosh , jamario moon (7)#josé calderón (7)#air canada centre 18325#32 - 24 [n] 57#february 29#indiana#l 111 - 122 (ot)#andrea bargnani (27)#andrea bargnani (9)#josé calderón (11)#air canada centre 19800#32 - 25 [n] 
06/06/2022 03:00:48 - INFO - __main__ - ['entailed']
06/06/2022 03:00:48 - INFO - __main__ - Tokenizing Input ...
06/06/2022 03:00:48 - INFO - __main__ - Tokenizing Output ...
06/06/2022 03:00:48 - INFO - __main__ - Loaded 64 examples from train data
06/06/2022 03:00:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/06/2022 03:00:48 - INFO - __main__ - Printing 3 examples
06/06/2022 03:00:48 - INFO - __main__ -  [tab_fact] statement: the average attendance of each game during december of the 2009 - 10 boston celtic season be 18293.23 [SEP] table_caption: 2009 - 10 boston celtics season [SEP] table_text: game#date#team#score#high points#high rebounds#high assists#location attendance#record [n] 18#december 1#charlotte#w 108 - 90 (ot)#ray allen (27)#kendrick perkins (12)#rajon rondo (9)#time warner cable arena 15129#14 - 4 [n] 19#december 3#san antonio#w 90 - 83 (ot)#kevin garnett (20)#kevin garnett , kendrick perkins (7)#rajon rondo (12)#at&t center 18581#15 - 4 [n] 20#december 4#oklahoma city#w 105 - 87 (ot)#kevin garnett (23)#kevin garnett , kendrick perkins (8)#rajon rondo (6)#ford center 18203#16 - 4 [n] 21#december 8#milwaukee#w 98 - 89 (ot)#kevin garnett (25)#kevin garnett , rajon rondo (9)#rajon rondo (13)#td garden 18624#17 - 4 [n] 22#december 10#washington#w 104 - 102 (ot)#rajon rondo (21)#kendrick perkins (11)#rajon rondo (11)#verizon center 20173#18 - 4 [n] 23#december 12#chicago#w 106 - 80 (ot)#rajon rondo (16)#kevin garnett (10)#rajon rondo (14)#united center 21257#19 - 4 [n] 24#december 14#memphis#w 110 - 105 (ot)#paul pierce (19)#kevin garnett (8)#rajon rondo (9)#fedexforum 14193#20 - 4 [n] 25#december 18#philadelphia#l 97 - 98 (ot)#kevin garnett (21)#kendrick perkins (16)#rajon rondo (10)#td garden 18624#20 - 5 [n] 26#december 20#minnesota#w 122 - 104 (ot)#paul pierce (29)#kendrick perkins (11)#rajon rondo (15)#td garden 18624#21 - 5 [n] 27#december 22#indiana#w 103 - 94 (ot)#ray allen (23)#rasheed wallace (13)#rajon rondo (9)#td garden 18624#22 - 5 [n] 28#december 25#orlando#w 86 - 77 (ot)#ray allen (18)#rajon rondo (13)#rajon rondo (8)#amway arena 17461#23 - 5 [n] 29#december 27#la clippers#l 90 - 92 (ot)#rajon rondo (20)#tony allen (10)#rajon rondo (6)#staples center 19060#23 - 6 [n] 30#december 28#golden state#l 99 - 103 (ot)#rajon rondo (30)#kendrick perkins (14)#rajon rondo (15)#oracle arena 19259#23 - 7 [n] 
06/06/2022 03:00:48 - INFO - __main__ - ['entailed']
06/06/2022 03:00:48 - INFO - __main__ -  [tab_fact] statement: the opponent be new york ranger on october 8 [SEP] table_caption: 2009 - 10 washington capitals season [SEP] table_text: game#date#opponent#score#location#attendance#record#points [n] 1#october 1#boston bruins#4 - 1#td garden#17565#1 - 0 - 0#2 [n] 2#october 3#toronto maple leafs#6 - 4#verizon center#18277#2 - 0 - 0#4 [n] 3#october 6#philadelphia flyers#6 - 5 ot#wachovia center#19567#2 - 0 - 1#5 [n] 4#october 8#new york rangers#4 - 3#verizon center#18277#2 - 1 - 1#5 [n] 5#october 10#detroit red wings#3 - 2#joe louis arena#19122#2 - 2 - 1#5 [n] 6#october 12#new jersey devils#3 - 2 so#verizon center#18277#2 - 2 - 2#6 [n] 7#october 15#san jose sharks#4 - 1#verizon center#18277#3 - 2 - 2#8 [n] 8#october 17#nashville predators#3 - 2 so#verizon center#18277#4 - 2 - 2#10 [n] 9#october 22#atlanta thrashers#5 - 4#philips arena#13192#5 - 2 - 2#12 [n] 10#october 24#new york islanders#3 - 2 ot#nassau veterans memorial coliseum#11541#6 - 2 - 2#14 [n] 11#october 27#philadelphia flyers#4 - 2#verizon center#18277#7 - 2 - 2#16 [n] 12#october 29#atlanta thrashers#4 - 3#philips arena#12893#8 - 2 - 2#18 [n] 
06/06/2022 03:00:48 - INFO - __main__ - ['entailed']
06/06/2022 03:00:48 - INFO - __main__ -  [tab_fact] statement: 4 of the 6 cooper - climax car have mechanical issue that cause them to drop out of the race [SEP] table_caption: 1957 german grand prix [SEP] table_text: driver#constructor#laps#time / retired#grid [n] juan manuel fangio#maserati#22#3:30:38.3#1 [n] mike hawthorn#ferrari#22#+ 3.6 secs#2 [n] peter collins#ferrari#22#+ 35.6 secs#4 [n] luigi musso#ferrari#22#+ 3:37.6#8 [n] stirling moss#vanwall#22#+ 4:37.2#7 [n] jean behra#maserati#22#+ 4:38.5#3 [n] harry schell#maserati#22#+ 6:47.5#6 [n] masten gregory#maserati#21#+ 1 lap#10 [n] tony brooks#vanwall#21#+ 1 lap#5 [n] giorgio scarlatti#maserati#21#+ 1 lap#13 [n] bruce halford#maserati#21#+ 1 lap#16 [n] edgar barth#porsche#21#+ 1 lap#12 [n] brian naylor#cooper - climax#20#+ 2 laps#17 [n] carel godin de beaufort#porsche#20#+ 2 laps#20 [n] tony marsh#cooper - climax#17#+ 5 laps#22 [n] hans herrmann#maserati#14#chassis#11 [n] umberto maglioli#porsche#13#engine#15 [n] roy salvadori#cooper - climax#11#suspension#14 [n] paco godia#maserati#11#steering#21 [n] stuart lewis - evans#vanwall#10#gearbox#9 [n] jack brabham#cooper - climax#6#transmission#18 [n] paul england#cooper - climax#4#distributor#23 [n] dick gibson#cooper - climax#3#steering#24 [n] horace gould#maserati#2#axle#19 [n] 
06/06/2022 03:00:48 - INFO - __main__ - ['entailed']
06/06/2022 03:00:48 - INFO - __main__ - Tokenizing Input ...
06/06/2022 03:00:48 - INFO - __main__ - Tokenizing Output ...
06/06/2022 03:00:48 - INFO - __main__ - Loaded 64 examples from dev data
06/06/2022 03:01:07 - INFO - __main__ - try to initialize prompt embeddings
06/06/2022 03:01:07 - INFO - __main__ - task name: tab_fact
06/06/2022 03:01:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/06/2022 03:01:08 - INFO - __main__ - Starting training!
06/06/2022 03:01:13 - INFO - __main__ - Step 10 Global step 10 Train loss 5.76 on epoch=2
06/06/2022 03:01:17 - INFO - __main__ - Step 20 Global step 20 Train loss 4.34 on epoch=4
06/06/2022 03:01:22 - INFO - __main__ - Step 30 Global step 30 Train loss 2.68 on epoch=7
06/06/2022 03:01:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.43 on epoch=9
06/06/2022 03:01:31 - INFO - __main__ - Step 50 Global step 50 Train loss 0.84 on epoch=12
06/06/2022 03:01:33 - INFO - __main__ - Global step 50 Train loss 3.01 Classification-F1 0.22456140350877193 on epoch=12
06/06/2022 03:01:33 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.22456140350877193 on epoch=12, global_step=50
06/06/2022 03:01:38 - INFO - __main__ - Step 60 Global step 60 Train loss 0.77 on epoch=14
06/06/2022 03:01:42 - INFO - __main__ - Step 70 Global step 70 Train loss 0.54 on epoch=17
06/06/2022 03:01:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.49 on epoch=19
06/06/2022 03:01:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.38 on epoch=22
06/06/2022 03:01:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.40 on epoch=24
06/06/2022 03:01:59 - INFO - __main__ - Global step 100 Train loss 0.52 Classification-F1 0.5440923605993613 on epoch=24
06/06/2022 03:01:59 - INFO - __main__ - Saving model with best Classification-F1: 0.22456140350877193 -> 0.5440923605993613 on epoch=24, global_step=100
06/06/2022 03:02:03 - INFO - __main__ - Step 110 Global step 110 Train loss 0.34 on epoch=27
06/06/2022 03:02:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.34 on epoch=29
06/06/2022 03:02:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.33 on epoch=32
06/06/2022 03:02:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.31 on epoch=34
06/06/2022 03:02:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.30 on epoch=37
06/06/2022 03:02:24 - INFO - __main__ - Global step 150 Train loss 0.33 Classification-F1 0.4920634920634921 on epoch=37
06/06/2022 03:02:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.29 on epoch=39
06/06/2022 03:02:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.27 on epoch=42
06/06/2022 03:02:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.30 on epoch=44
06/06/2022 03:02:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.26 on epoch=47
06/06/2022 03:02:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.27 on epoch=49
06/06/2022 03:02:49 - INFO - __main__ - Global step 200 Train loss 0.28 Classification-F1 0.4920634920634921 on epoch=49
06/06/2022 03:02:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.22 on epoch=52
06/06/2022 03:02:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.28 on epoch=54
06/06/2022 03:03:03 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=57
06/06/2022 03:03:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.25 on epoch=59
06/06/2022 03:03:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.24 on epoch=62
06/06/2022 03:03:14 - INFO - __main__ - Global step 250 Train loss 0.25 Classification-F1 0.46218487394957986 on epoch=62
06/06/2022 03:03:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=64
06/06/2022 03:03:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.26 on epoch=67
06/06/2022 03:03:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=69
06/06/2022 03:03:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=72
06/06/2022 03:03:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.24 on epoch=74
06/06/2022 03:03:39 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.4920634920634921 on epoch=74
06/06/2022 03:03:44 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=77
06/06/2022 03:03:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=79
06/06/2022 03:03:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/06/2022 03:03:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/06/2022 03:04:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/06/2022 03:04:04 - INFO - __main__ - Global step 350 Train loss 0.23 Classification-F1 0.3333333333333333 on epoch=87
06/06/2022 03:04:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/06/2022 03:04:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/06/2022 03:04:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=94
06/06/2022 03:04:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=97
06/06/2022 03:04:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=99
06/06/2022 03:04:29 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.3333333333333333 on epoch=99
06/06/2022 03:04:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/06/2022 03:04:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/06/2022 03:04:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/06/2022 03:04:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=109
06/06/2022 03:04:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/06/2022 03:04:54 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.4920634920634921 on epoch=112
06/06/2022 03:04:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/06/2022 03:05:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/06/2022 03:05:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/06/2022 03:05:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=122
06/06/2022 03:05:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/06/2022 03:05:19 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.4920634920634921 on epoch=124
06/06/2022 03:05:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=127
06/06/2022 03:05:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=129
06/06/2022 03:05:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/06/2022 03:05:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/06/2022 03:05:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=137
06/06/2022 03:05:44 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.5440923605993613 on epoch=137
06/06/2022 03:05:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/06/2022 03:05:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/06/2022 03:05:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=144
06/06/2022 03:06:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=147
06/06/2022 03:06:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=149
06/06/2022 03:06:09 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.5097603162836669 on epoch=149
06/06/2022 03:06:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/06/2022 03:06:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/06/2022 03:06:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=157
06/06/2022 03:06:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=159
06/06/2022 03:06:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/06/2022 03:06:34 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.4920634920634921 on epoch=162
06/06/2022 03:06:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=164
06/06/2022 03:06:43 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=167
06/06/2022 03:06:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=169
06/06/2022 03:06:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=172
06/06/2022 03:06:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.78 on epoch=174
06/06/2022 03:06:59 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.473972602739726 on epoch=174
06/06/2022 03:07:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/06/2022 03:07:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=179
06/06/2022 03:07:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=182
06/06/2022 03:07:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=184
06/06/2022 03:07:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=187
06/06/2022 03:07:24 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.28518518518518515 on epoch=187
06/06/2022 03:07:29 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=189
06/06/2022 03:07:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=192
06/06/2022 03:07:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=194
06/06/2022 03:07:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=197
06/06/2022 03:07:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=199
06/06/2022 03:07:50 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.4920634920634921 on epoch=199
06/06/2022 03:07:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/06/2022 03:07:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=204
06/06/2022 03:08:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=207
06/06/2022 03:08:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=209
06/06/2022 03:08:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=212
06/06/2022 03:08:15 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.5097603162836669 on epoch=212
06/06/2022 03:08:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=214
06/06/2022 03:08:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=217
06/06/2022 03:08:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=219
06/06/2022 03:08:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=222
06/06/2022 03:08:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.20 on epoch=224
06/06/2022 03:08:40 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.5270935960591133 on epoch=224
06/06/2022 03:08:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=227
06/06/2022 03:08:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=229
06/06/2022 03:08:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=232
06/06/2022 03:08:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/06/2022 03:09:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=237
06/06/2022 03:09:05 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.5097603162836669 on epoch=237
06/06/2022 03:09:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=239
06/06/2022 03:09:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=242
06/06/2022 03:09:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/06/2022 03:09:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=247
06/06/2022 03:09:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=249
06/06/2022 03:09:30 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.49090909090909085 on epoch=249
06/06/2022 03:09:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=252
06/06/2022 03:09:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/06/2022 03:09:44 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=257
06/06/2022 03:09:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=259
06/06/2022 03:09:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=262
06/06/2022 03:09:55 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.5126504544338 on epoch=262
06/06/2022 03:10:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=264
06/06/2022 03:10:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=267
06/06/2022 03:10:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/06/2022 03:10:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=272
06/06/2022 03:10:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=274
06/06/2022 03:10:20 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.5497835497835498 on epoch=274
06/06/2022 03:10:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5440923605993613 -> 0.5497835497835498 on epoch=274, global_step=1100
06/06/2022 03:10:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=277
06/06/2022 03:10:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.23 on epoch=279
06/06/2022 03:10:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=282
06/06/2022 03:10:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=284
06/06/2022 03:10:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=287
06/06/2022 03:10:45 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.49556650246305417 on epoch=287
06/06/2022 03:10:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=289
06/06/2022 03:10:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=292
06/06/2022 03:10:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=294
06/06/2022 03:11:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=297
06/06/2022 03:11:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=299
06/06/2022 03:11:10 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.3383736559139785 on epoch=299
06/06/2022 03:11:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.19 on epoch=302
06/06/2022 03:11:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=304
06/06/2022 03:11:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=307
06/06/2022 03:11:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=309
06/06/2022 03:11:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=312
06/06/2022 03:11:36 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.2753357753357753 on epoch=312
06/06/2022 03:11:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=314
06/06/2022 03:11:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=317
06/06/2022 03:11:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=319
06/06/2022 03:11:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=322
06/06/2022 03:11:58 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=324
06/06/2022 03:12:01 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.3684965005481069 on epoch=324
06/06/2022 03:12:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=327
06/06/2022 03:12:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=329
06/06/2022 03:12:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=332
06/06/2022 03:12:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=334
06/06/2022 03:12:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=337
06/06/2022 03:12:26 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.4748717948717949 on epoch=337
06/06/2022 03:12:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=339
06/06/2022 03:12:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=342
06/06/2022 03:12:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=344
06/06/2022 03:12:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=347
06/06/2022 03:12:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=349
06/06/2022 03:12:52 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.24058149058149056 on epoch=349
06/06/2022 03:12:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=352
06/06/2022 03:13:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=354
06/06/2022 03:13:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=357
06/06/2022 03:13:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=359
06/06/2022 03:13:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=362
06/06/2022 03:13:17 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.362689878818911 on epoch=362
06/06/2022 03:13:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=364
06/06/2022 03:13:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=367
06/06/2022 03:13:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=369
06/06/2022 03:13:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=372
06/06/2022 03:13:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=374
06/06/2022 03:13:43 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.2675438596491228 on epoch=374
06/06/2022 03:13:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=377
06/06/2022 03:13:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=379
06/06/2022 03:13:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=382
06/06/2022 03:14:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=384
06/06/2022 03:14:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=387
06/06/2022 03:14:08 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.3465748587570621 on epoch=387
06/06/2022 03:14:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=389
06/06/2022 03:14:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=392
06/06/2022 03:14:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=394
06/06/2022 03:14:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.16 on epoch=397
06/06/2022 03:14:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=399
06/06/2022 03:14:33 - INFO - __main__ - Global step 1600 Train loss 0.15 Classification-F1 0.3264320220841959 on epoch=399
06/06/2022 03:14:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=402
06/06/2022 03:14:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=404
06/06/2022 03:14:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=407
06/06/2022 03:14:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=409
06/06/2022 03:14:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=412
06/06/2022 03:14:58 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.2786231884057971 on epoch=412
06/06/2022 03:15:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=414
06/06/2022 03:15:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=417
06/06/2022 03:15:12 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=419
06/06/2022 03:15:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=422
06/06/2022 03:15:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=424
06/06/2022 03:15:23 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.48051948051948057 on epoch=424
06/06/2022 03:15:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=427
06/06/2022 03:15:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=429
06/06/2022 03:15:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=432
06/06/2022 03:15:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=434
06/06/2022 03:15:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=437
06/06/2022 03:15:49 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.3816425120772947 on epoch=437
06/06/2022 03:15:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=439
06/06/2022 03:15:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=442
06/06/2022 03:16:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=444
06/06/2022 03:16:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/06/2022 03:16:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=449
06/06/2022 03:16:14 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.46867924528301885 on epoch=449
06/06/2022 03:16:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=452
06/06/2022 03:16:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=454
06/06/2022 03:16:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/06/2022 03:16:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=459
06/06/2022 03:16:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=462
06/06/2022 03:16:39 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.464039408866995 on epoch=462
06/06/2022 03:16:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=464
06/06/2022 03:16:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=467
06/06/2022 03:16:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=469
06/06/2022 03:16:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=472
06/06/2022 03:17:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=474
06/06/2022 03:17:05 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.22828282828282828 on epoch=474
06/06/2022 03:17:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=477
06/06/2022 03:17:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=479
06/06/2022 03:17:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=482
06/06/2022 03:17:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=484
06/06/2022 03:17:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=487
06/06/2022 03:17:31 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.40427672955974847 on epoch=487
06/06/2022 03:17:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=489
06/06/2022 03:17:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=492
06/06/2022 03:17:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=494
06/06/2022 03:17:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=497
06/06/2022 03:17:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/06/2022 03:17:56 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.25771689497716893 on epoch=499
06/06/2022 03:18:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=502
06/06/2022 03:18:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=504
06/06/2022 03:18:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=507
06/06/2022 03:18:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=509
06/06/2022 03:18:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=512
06/06/2022 03:18:22 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.28415300546448086 on epoch=512
06/06/2022 03:18:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/06/2022 03:18:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=517
06/06/2022 03:18:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=519
06/06/2022 03:18:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/06/2022 03:18:44 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=524
06/06/2022 03:18:47 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.30946502057613173 on epoch=524
06/06/2022 03:18:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/06/2022 03:18:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=529
06/06/2022 03:19:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/06/2022 03:19:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=534
06/06/2022 03:19:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/06/2022 03:19:13 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.3671451355661882 on epoch=537
06/06/2022 03:19:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=539
06/06/2022 03:19:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=542
06/06/2022 03:19:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=544
06/06/2022 03:19:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=547
06/06/2022 03:19:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/06/2022 03:19:38 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.40566959921798634 on epoch=549
06/06/2022 03:19:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=552
06/06/2022 03:19:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=554
06/06/2022 03:19:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=557
06/06/2022 03:19:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=559
06/06/2022 03:20:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=562
06/06/2022 03:20:04 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.4217338217338217 on epoch=562
06/06/2022 03:20:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=564
06/06/2022 03:20:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=567
06/06/2022 03:20:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=569
06/06/2022 03:20:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=572
06/06/2022 03:20:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=574
06/06/2022 03:20:29 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.40566959921798634 on epoch=574
06/06/2022 03:20:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/06/2022 03:20:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=579
06/06/2022 03:20:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=582
06/06/2022 03:20:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/06/2022 03:20:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=587
06/06/2022 03:20:55 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.37662337662337664 on epoch=587
06/06/2022 03:20:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=589
06/06/2022 03:21:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/06/2022 03:21:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=594
06/06/2022 03:21:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=597
06/06/2022 03:21:18 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=599
06/06/2022 03:21:23 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.4217338217338217 on epoch=599
06/06/2022 03:21:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=602
06/06/2022 03:21:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=604
06/06/2022 03:21:36 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/06/2022 03:21:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/06/2022 03:21:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=612
06/06/2022 03:21:49 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.4375 on epoch=612
06/06/2022 03:21:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/06/2022 03:21:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=617
06/06/2022 03:22:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/06/2022 03:22:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/06/2022 03:22:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=624
06/06/2022 03:22:16 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.4213381555153707 on epoch=624
06/06/2022 03:22:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=627
06/06/2022 03:22:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=629
06/06/2022 03:22:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/06/2022 03:22:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/06/2022 03:22:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/06/2022 03:22:42 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.34299516908212563 on epoch=637
06/06/2022 03:22:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/06/2022 03:22:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/06/2022 03:22:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=644
06/06/2022 03:23:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/06/2022 03:23:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/06/2022 03:23:10 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.48424908424908425 on epoch=649
06/06/2022 03:23:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=652
06/06/2022 03:23:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/06/2022 03:23:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=657
06/06/2022 03:23:29 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/06/2022 03:23:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/06/2022 03:23:37 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.4682306940371457 on epoch=662
06/06/2022 03:23:42 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=664
06/06/2022 03:23:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/06/2022 03:23:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/06/2022 03:23:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/06/2022 03:24:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/06/2022 03:24:05 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.464039408866995 on epoch=674
06/06/2022 03:24:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/06/2022 03:24:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=679
06/06/2022 03:24:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=682
06/06/2022 03:24:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/06/2022 03:24:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/06/2022 03:24:33 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.45440454662877805 on epoch=687
06/06/2022 03:24:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/06/2022 03:24:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/06/2022 03:24:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/06/2022 03:24:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/06/2022 03:24:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=699
06/06/2022 03:25:03 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.4519207242476144 on epoch=699
06/06/2022 03:25:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/06/2022 03:25:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/06/2022 03:25:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/06/2022 03:25:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/06/2022 03:25:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/06/2022 03:25:32 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.3054247339961626 on epoch=712
06/06/2022 03:25:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/06/2022 03:25:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/06/2022 03:25:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/06/2022 03:25:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/06/2022 03:25:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/06/2022 03:26:07 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.47885474126608885 on epoch=724
06/06/2022 03:26:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/06/2022 03:26:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/06/2022 03:26:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/06/2022 03:26:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/06/2022 03:26:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=737
06/06/2022 03:26:41 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.2698600433668441 on epoch=737
06/06/2022 03:26:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/06/2022 03:26:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/06/2022 03:26:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/06/2022 03:26:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/06/2022 03:27:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/06/2022 03:27:10 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.46880856760374834 on epoch=749
06/06/2022 03:27:11 - INFO - __main__ - save last model!
06/06/2022 03:27:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/06/2022 03:27:11 - INFO - __main__ - Start tokenizing ... 12792 instances
06/06/2022 03:27:11 - INFO - __main__ - Printing 3 examples
06/06/2022 03:27:11 - INFO - __main__ -  [tab_fact] statement: during the third round of the turkish cup , there be no new entry during that stage [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 03:27:11 - INFO - __main__ - ['entailed']
06/06/2022 03:27:11 - INFO - __main__ -  [tab_fact] statement: the highest number of winner from a previous round in the turkish cup be 54 in round 3 [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 03:27:11 - INFO - __main__ - ['entailed']
06/06/2022 03:27:11 - INFO - __main__ -  [tab_fact] statement: süper lig be the most common league to win a round in the turkish cup [SEP] table_caption: turkish cup [SEP] table_text: round#clubs remaining#clubs involved#winners from previous round#new entries this round#leagues entering at this round [n] first round#156#86#none#86#tff third league & turkish regional amateur league [n] second round#113#108#43#65#süper lig & tff first league & tff second league [n] third round#59#54#54#none#none [n] fourth round#32#32#27#5#süper lig [n] fifth round#16#16#16#none#none [n] group stage#8#8#8#none#none [n] semi - finals#4#4#4#none#none [n] final#2#2#2#none#none [n] 
06/06/2022 03:27:11 - INFO - __main__ - ['entailed']
06/06/2022 03:27:11 - INFO - __main__ - Tokenizing Input ...
06/06/2022 03:27:38 - INFO - __main__ - Tokenizing Output ...
06/06/2022 03:27:52 - INFO - __main__ - Loaded 12792 examples from test data
06/06/2022 03:44:19 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down32shot/singletask-tab_fact/tab_fact_32_87_0.2_8_predictions.txt
06/06/2022 03:44:19 - INFO - __main__ - Classification-F1 on test data: 0.2363
06/06/2022 03:44:19 - INFO - __main__ - prefix=tab_fact_32_87, lr=0.2, bsz=8, dev_performance=0.5497835497835498, test_performance=0.23631929328670512
