05/18/2022 14:46:09 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/18/2022 14:46:09 - INFO - __main__ - models/T5-base-cls2cls/singletask-dbpedia_14
05/18/2022 14:46:09 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/18/2022 14:46:09 - INFO - __main__ - models/T5-base-cls2cls/singletask-dbpedia_14
05/18/2022 14:46:10 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/18/2022 14:46:10 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/18/2022 14:46:10 - INFO - __main__ - args.device: cuda:0
05/18/2022 14:46:10 - INFO - __main__ - Using 2 gpus
05/18/2022 14:46:10 - INFO - __main__ - args.device: cuda:1
05/18/2022 14:46:10 - INFO - __main__ - Using 2 gpus
05/18/2022 14:46:10 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/18/2022 14:46:10 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/18/2022 14:46:15 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/18/2022 14:46:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/18/2022 14:46:16 - INFO - __main__ - Printing 3 examples
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ - Tokenizing Input ...
05/18/2022 14:46:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/18/2022 14:46:16 - INFO - __main__ - Printing 3 examples
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ - Tokenizing Input ...
05/18/2022 14:46:16 - INFO - __main__ - Tokenizing Output ...
05/18/2022 14:46:16 - INFO - __main__ - Tokenizing Output ...
05/18/2022 14:46:16 - INFO - __main__ - Loaded 224 examples from train data
05/18/2022 14:46:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/18/2022 14:46:16 - INFO - __main__ - Printing 3 examples
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/18/2022 14:46:16 - INFO - __main__ - ['Animal']
05/18/2022 14:46:16 - INFO - __main__ - Tokenizing Input ...
05/18/2022 14:46:16 - INFO - __main__ - Tokenizing Output ...
05/18/2022 14:46:17 - INFO - __main__ - Loaded 224 examples from train data
05/18/2022 14:46:17 - INFO - __main__ - Start tokenizing ... 224 instances
05/18/2022 14:46:17 - INFO - __main__ - Printing 3 examples
05/18/2022 14:46:17 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/18/2022 14:46:17 - INFO - __main__ - ['Animal']
05/18/2022 14:46:17 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/18/2022 14:46:17 - INFO - __main__ - ['Animal']
05/18/2022 14:46:17 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/18/2022 14:46:17 - INFO - __main__ - ['Animal']
05/18/2022 14:46:17 - INFO - __main__ - Tokenizing Input ...
05/18/2022 14:46:17 - INFO - __main__ - Tokenizing Output ...
05/18/2022 14:46:17 - INFO - __main__ - Loaded 224 examples from dev data
05/18/2022 14:46:17 - INFO - __main__ - Loaded 224 examples from dev data
05/18/2022 14:46:23 - INFO - __main__ - try to initialize prompt embeddings
05/18/2022 14:46:23 - INFO - __main__ - task name: dbpedia_14
05/18/2022 14:46:23 - INFO - __main__ - try to initialize prompt embeddings
05/18/2022 14:46:23 - INFO - __main__ - task name: dbpedia_14
05/18/2022 14:46:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/18/2022 14:46:23 - INFO - __main__ - Starting training!
05/18/2022 14:46:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/18/2022 14:46:23 - INFO - __main__ - Starting training!
05/18/2022 14:46:25 - INFO - __main__ - Step 10 Global step 10 Train loss 6.49 on epoch=0
05/18/2022 14:46:27 - INFO - __main__ - Step 20 Global step 20 Train loss 4.96 on epoch=1
05/18/2022 14:46:28 - INFO - __main__ - Step 30 Global step 30 Train loss 4.61 on epoch=2
05/18/2022 14:46:29 - INFO - __main__ - Step 40 Global step 40 Train loss 6.87 on epoch=2
05/18/2022 14:46:30 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
05/18/2022 14:47:37 - INFO - __main__ - Global step 50 Train loss 6.00 Classification-F1 0.0 on epoch=3
05/18/2022 14:47:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/18/2022 14:47:38 - INFO - __main__ - Step 60 Global step 60 Train loss 7.15 on epoch=4
05/18/2022 14:47:40 - INFO - __main__ - Step 70 Global step 70 Train loss 7.60 on epoch=4
05/18/2022 14:47:41 - INFO - __main__ - Step 80 Global step 80 Train loss 7.17 on epoch=5
05/18/2022 14:47:42 - INFO - __main__ - Step 90 Global step 90 Train loss 7.26 on epoch=6
05/18/2022 14:47:43 - INFO - __main__ - Step 100 Global step 100 Train loss 7.25 on epoch=7
05/18/2022 14:48:43 - INFO - __main__ - Global step 100 Train loss 7.29 Classification-F1 0.0 on epoch=7
05/18/2022 14:48:44 - INFO - __main__ - Step 110 Global step 110 Train loss 7.32 on epoch=7
05/18/2022 14:48:45 - INFO - __main__ - Step 120 Global step 120 Train loss 7.61 on epoch=8
05/18/2022 14:48:46 - INFO - __main__ - Step 130 Global step 130 Train loss 7.39 on epoch=9
05/18/2022 14:48:47 - INFO - __main__ - Step 140 Global step 140 Train loss 7.79 on epoch=9
05/18/2022 14:48:49 - INFO - __main__ - Step 150 Global step 150 Train loss 7.56 on epoch=10
05/18/2022 14:49:34 - INFO - __main__ - Global step 150 Train loss 7.53 Classification-F1 0.0 on epoch=10
05/18/2022 14:49:35 - INFO - __main__ - Step 160 Global step 160 Train loss 7.65 on epoch=11
05/18/2022 14:49:36 - INFO - __main__ - Step 170 Global step 170 Train loss 7.60 on epoch=12
05/18/2022 14:49:37 - INFO - __main__ - Step 180 Global step 180 Train loss 7.62 on epoch=12
05/18/2022 14:49:38 - INFO - __main__ - Step 190 Global step 190 Train loss 7.52 on epoch=13
05/18/2022 14:49:40 - INFO - __main__ - Step 200 Global step 200 Train loss 7.46 on epoch=14
05/18/2022 14:50:41 - INFO - __main__ - Global step 200 Train loss 7.57 Classification-F1 0.0 on epoch=14
05/18/2022 14:50:43 - INFO - __main__ - Step 210 Global step 210 Train loss 7.64 on epoch=14
05/18/2022 14:50:44 - INFO - __main__ - Step 220 Global step 220 Train loss 7.53 on epoch=15
05/18/2022 14:50:45 - INFO - __main__ - Step 230 Global step 230 Train loss 7.57 on epoch=16
05/18/2022 14:50:46 - INFO - __main__ - Step 240 Global step 240 Train loss 7.51 on epoch=17
05/18/2022 14:50:47 - INFO - __main__ - Step 250 Global step 250 Train loss 7.54 on epoch=17
05/18/2022 14:51:32 - INFO - __main__ - Global step 250 Train loss 7.56 Classification-F1 0.0 on epoch=17
05/18/2022 14:51:33 - INFO - __main__ - Step 260 Global step 260 Train loss 7.59 on epoch=18
05/18/2022 14:51:34 - INFO - __main__ - Step 270 Global step 270 Train loss 7.21 on epoch=19
05/18/2022 14:51:36 - INFO - __main__ - Step 280 Global step 280 Train loss 7.44 on epoch=19
05/18/2022 14:51:37 - INFO - __main__ - Step 290 Global step 290 Train loss 7.36 on epoch=20
05/18/2022 14:51:38 - INFO - __main__ - Step 300 Global step 300 Train loss 7.38 on epoch=21
05/18/2022 14:52:31 - INFO - __main__ - Global step 300 Train loss 7.40 Classification-F1 0.0 on epoch=21
05/18/2022 14:52:32 - INFO - __main__ - Step 310 Global step 310 Train loss 7.35 on epoch=22
05/18/2022 14:52:33 - INFO - __main__ - Step 320 Global step 320 Train loss 7.38 on epoch=22
05/18/2022 14:52:35 - INFO - __main__ - Step 330 Global step 330 Train loss 7.55 on epoch=23
05/18/2022 14:52:36 - INFO - __main__ - Step 340 Global step 340 Train loss 7.24 on epoch=24
05/18/2022 14:52:37 - INFO - __main__ - Step 350 Global step 350 Train loss 7.55 on epoch=24
05/18/2022 14:53:43 - INFO - __main__ - Global step 350 Train loss 7.41 Classification-F1 0.0 on epoch=24
05/18/2022 14:53:45 - INFO - __main__ - Step 360 Global step 360 Train loss 7.38 on epoch=25
05/18/2022 14:53:46 - INFO - __main__ - Step 370 Global step 370 Train loss 7.50 on epoch=26
05/18/2022 14:53:47 - INFO - __main__ - Step 380 Global step 380 Train loss 7.41 on epoch=27
05/18/2022 14:53:48 - INFO - __main__ - Step 390 Global step 390 Train loss 7.40 on epoch=27
05/18/2022 14:53:50 - INFO - __main__ - Step 400 Global step 400 Train loss 7.47 on epoch=28
05/18/2022 14:54:10 - INFO - __main__ - Global step 400 Train loss 7.43 Classification-F1 0.0 on epoch=28
05/18/2022 14:54:11 - INFO - __main__ - Step 410 Global step 410 Train loss 7.42 on epoch=29
05/18/2022 14:54:13 - INFO - __main__ - Step 420 Global step 420 Train loss 7.71 on epoch=29
05/18/2022 14:54:14 - INFO - __main__ - Step 430 Global step 430 Train loss 7.52 on epoch=30
05/18/2022 14:54:15 - INFO - __main__ - Step 440 Global step 440 Train loss 7.35 on epoch=31
05/18/2022 14:54:16 - INFO - __main__ - Step 450 Global step 450 Train loss 7.40 on epoch=32
05/18/2022 14:54:48 - INFO - __main__ - Global step 450 Train loss 7.48 Classification-F1 0.0 on epoch=32
05/18/2022 14:54:49 - INFO - __main__ - Step 460 Global step 460 Train loss 7.44 on epoch=32
05/18/2022 14:54:50 - INFO - __main__ - Step 470 Global step 470 Train loss 7.37 on epoch=33
05/21/2022 21:22:23 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/21/2022 21:22:23 - INFO - __main__ - models/T5-base-cls2cls/singletask-dbpedia_14
05/21/2022 21:22:23 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
05/21/2022 21:22:23 - INFO - __main__ - models/T5-base-cls2cls/singletask-dbpedia_14
05/21/2022 21:22:24 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:22:24 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:22:24 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:22:24 - INFO - __main__ - Using 2 gpus
05/21/2022 21:22:24 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:22:24 - INFO - __main__ - Using 2 gpus
05/21/2022 21:22:24 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 21:22:24 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 21:22:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/02/2022 05:23:50 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
06/02/2022 05:23:50 - INFO - __main__ - models/T5-base-cls2cls/singletask-dbpedia_14
06/02/2022 05:23:50 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-cls2cls', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-cls2cls/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='6,7')
06/02/2022 05:23:50 - INFO - __main__ - models/T5-base-cls2cls/singletask-dbpedia_14
06/02/2022 05:23:51 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/02/2022 05:23:51 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/02/2022 05:23:51 - INFO - __main__ - args.device: cuda:0
06/02/2022 05:23:51 - INFO - __main__ - Using 2 gpus
06/02/2022 05:23:51 - INFO - __main__ - args.device: cuda:1
06/02/2022 05:23:51 - INFO - __main__ - Using 2 gpus
06/02/2022 05:23:51 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/02/2022 05:23:51 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/02/2022 05:23:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/02/2022 05:23:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 05:23:57 - INFO - __main__ - Printing 3 examples
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 05:23:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 05:23:57 - INFO - __main__ - Printing 3 examples
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 05:23:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 05:23:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 05:23:57 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 05:23:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 05:23:57 - INFO - __main__ - Printing 3 examples
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 05:23:57 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 05:23:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 05:23:57 - INFO - __main__ - Printing 3 examples
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 05:23:57 - INFO - __main__ - ['Animal']
06/02/2022 05:23:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 05:23:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 05:23:58 - INFO - __main__ - Tokenizing Output ...
06/02/2022 05:23:58 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 05:23:58 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 05:24:04 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 05:24:04 - INFO - __main__ - task name: dbpedia_14
06/02/2022 05:24:04 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 05:24:04 - INFO - __main__ - task name: dbpedia_14
06/02/2022 05:24:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 05:24:04 - INFO - __main__ - Starting training!
06/02/2022 05:24:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 05:24:04 - INFO - __main__ - Starting training!
06/02/2022 05:24:06 - INFO - __main__ - Step 10 Global step 10 Train loss 6.49 on epoch=0
06/02/2022 05:24:07 - INFO - __main__ - Step 20 Global step 20 Train loss 4.96 on epoch=1
06/02/2022 05:24:09 - INFO - __main__ - Step 30 Global step 30 Train loss 4.61 on epoch=2
06/02/2022 05:24:10 - INFO - __main__ - Step 40 Global step 40 Train loss 6.87 on epoch=2
06/02/2022 05:24:11 - INFO - __main__ - Step 50 Global step 50 Train loss 7.07 on epoch=3
06/02/2022 05:25:20 - INFO - __main__ - Global step 50 Train loss 6.00 Classification-F1 0.0 on epoch=3
06/02/2022 05:25:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 05:25:21 - INFO - __main__ - Step 60 Global step 60 Train loss 7.15 on epoch=4
06/02/2022 05:25:23 - INFO - __main__ - Step 70 Global step 70 Train loss 7.60 on epoch=4
06/02/2022 05:25:24 - INFO - __main__ - Step 80 Global step 80 Train loss 7.17 on epoch=5
06/02/2022 05:25:25 - INFO - __main__ - Step 90 Global step 90 Train loss 7.26 on epoch=6
06/02/2022 05:25:26 - INFO - __main__ - Step 100 Global step 100 Train loss 7.25 on epoch=7
06/02/2022 05:26:27 - INFO - __main__ - Global step 100 Train loss 7.29 Classification-F1 0.0 on epoch=7
06/02/2022 05:26:28 - INFO - __main__ - Step 110 Global step 110 Train loss 7.32 on epoch=7
06/02/2022 05:26:30 - INFO - __main__ - Step 120 Global step 120 Train loss 7.61 on epoch=8
06/02/2022 05:26:31 - INFO - __main__ - Step 130 Global step 130 Train loss 7.39 on epoch=9
06/02/2022 05:26:32 - INFO - __main__ - Step 140 Global step 140 Train loss 7.79 on epoch=9
06/02/2022 05:26:33 - INFO - __main__ - Step 150 Global step 150 Train loss 7.56 on epoch=10
06/02/2022 05:27:20 - INFO - __main__ - Global step 150 Train loss 7.53 Classification-F1 0.0 on epoch=10
06/02/2022 05:27:21 - INFO - __main__ - Step 160 Global step 160 Train loss 7.65 on epoch=11
06/02/2022 05:27:22 - INFO - __main__ - Step 170 Global step 170 Train loss 7.60 on epoch=12
06/02/2022 05:27:24 - INFO - __main__ - Step 180 Global step 180 Train loss 7.62 on epoch=12
06/02/2022 05:27:25 - INFO - __main__ - Step 190 Global step 190 Train loss 7.52 on epoch=13
06/02/2022 05:27:26 - INFO - __main__ - Step 200 Global step 200 Train loss 7.46 on epoch=14
06/02/2022 05:28:29 - INFO - __main__ - Global step 200 Train loss 7.57 Classification-F1 0.0 on epoch=14
06/02/2022 05:28:31 - INFO - __main__ - Step 210 Global step 210 Train loss 7.64 on epoch=14
06/02/2022 05:28:32 - INFO - __main__ - Step 220 Global step 220 Train loss 7.53 on epoch=15
06/02/2022 05:28:33 - INFO - __main__ - Step 230 Global step 230 Train loss 7.57 on epoch=16
06/02/2022 05:28:35 - INFO - __main__ - Step 240 Global step 240 Train loss 7.51 on epoch=17
06/02/2022 05:28:36 - INFO - __main__ - Step 250 Global step 250 Train loss 7.54 on epoch=17
06/02/2022 05:29:21 - INFO - __main__ - Global step 250 Train loss 7.56 Classification-F1 0.0 on epoch=17
06/02/2022 05:29:23 - INFO - __main__ - Step 260 Global step 260 Train loss 7.59 on epoch=18
06/02/2022 05:29:24 - INFO - __main__ - Step 270 Global step 270 Train loss 7.21 on epoch=19
06/02/2022 05:29:25 - INFO - __main__ - Step 280 Global step 280 Train loss 7.44 on epoch=19
06/02/2022 05:29:27 - INFO - __main__ - Step 290 Global step 290 Train loss 7.36 on epoch=20
06/02/2022 05:29:28 - INFO - __main__ - Step 300 Global step 300 Train loss 7.38 on epoch=21
06/02/2022 05:30:22 - INFO - __main__ - Global step 300 Train loss 7.40 Classification-F1 0.0 on epoch=21
06/02/2022 05:30:23 - INFO - __main__ - Step 310 Global step 310 Train loss 7.35 on epoch=22
06/02/2022 05:30:24 - INFO - __main__ - Step 320 Global step 320 Train loss 7.38 on epoch=22
06/02/2022 05:30:26 - INFO - __main__ - Step 330 Global step 330 Train loss 7.55 on epoch=23
06/02/2022 05:30:27 - INFO - __main__ - Step 340 Global step 340 Train loss 7.24 on epoch=24
06/02/2022 05:30:28 - INFO - __main__ - Step 350 Global step 350 Train loss 7.55 on epoch=24
06/02/2022 05:31:36 - INFO - __main__ - Global step 350 Train loss 7.41 Classification-F1 0.0 on epoch=24
06/02/2022 05:31:37 - INFO - __main__ - Step 360 Global step 360 Train loss 7.38 on epoch=25
06/02/2022 05:31:38 - INFO - __main__ - Step 370 Global step 370 Train loss 7.50 on epoch=26
06/02/2022 05:31:40 - INFO - __main__ - Step 380 Global step 380 Train loss 7.41 on epoch=27
06/02/2022 05:31:41 - INFO - __main__ - Step 390 Global step 390 Train loss 7.40 on epoch=27
06/02/2022 05:31:42 - INFO - __main__ - Step 400 Global step 400 Train loss 7.47 on epoch=28
06/02/2022 05:32:03 - INFO - __main__ - Global step 400 Train loss 7.43 Classification-F1 0.0 on epoch=28
06/02/2022 05:32:04 - INFO - __main__ - Step 410 Global step 410 Train loss 7.42 on epoch=29
06/02/2022 05:32:05 - INFO - __main__ - Step 420 Global step 420 Train loss 7.71 on epoch=29
06/02/2022 05:32:07 - INFO - __main__ - Step 430 Global step 430 Train loss 7.52 on epoch=30
06/02/2022 05:32:08 - INFO - __main__ - Step 440 Global step 440 Train loss 7.35 on epoch=31
06/02/2022 05:32:09 - INFO - __main__ - Step 450 Global step 450 Train loss 7.40 on epoch=32
06/02/2022 05:32:41 - INFO - __main__ - Global step 450 Train loss 7.48 Classification-F1 0.0 on epoch=32
06/02/2022 05:32:42 - INFO - __main__ - Step 460 Global step 460 Train loss 7.44 on epoch=32
06/02/2022 05:32:44 - INFO - __main__ - Step 470 Global step 470 Train loss 7.37 on epoch=33
06/02/2022 05:32:45 - INFO - __main__ - Step 480 Global step 480 Train loss 7.31 on epoch=34
06/02/2022 05:32:46 - INFO - __main__ - Step 490 Global step 490 Train loss 7.58 on epoch=34
06/02/2022 05:32:47 - INFO - __main__ - Step 500 Global step 500 Train loss 7.42 on epoch=35
06/02/2022 05:33:19 - INFO - __main__ - Global step 500 Train loss 7.42 Classification-F1 0.0 on epoch=35
06/02/2022 05:33:21 - INFO - __main__ - Step 510 Global step 510 Train loss 7.46 on epoch=36
06/02/2022 05:33:22 - INFO - __main__ - Step 520 Global step 520 Train loss 7.39 on epoch=37
06/02/2022 05:33:23 - INFO - __main__ - Step 530 Global step 530 Train loss 7.29 on epoch=37
06/02/2022 05:33:24 - INFO - __main__ - Step 540 Global step 540 Train loss 7.32 on epoch=38
06/02/2022 05:33:26 - INFO - __main__ - Step 550 Global step 550 Train loss 7.21 on epoch=39
06/02/2022 05:34:26 - INFO - __main__ - Global step 550 Train loss 7.34 Classification-F1 0.0 on epoch=39
06/02/2022 05:34:27 - INFO - __main__ - Step 560 Global step 560 Train loss 7.40 on epoch=39
06/02/2022 05:34:28 - INFO - __main__ - Step 570 Global step 570 Train loss 7.45 on epoch=40
06/02/2022 05:34:30 - INFO - __main__ - Step 580 Global step 580 Train loss 7.37 on epoch=41
06/02/2022 05:34:31 - INFO - __main__ - Step 590 Global step 590 Train loss 7.23 on epoch=42
06/02/2022 05:34:32 - INFO - __main__ - Step 600 Global step 600 Train loss 7.32 on epoch=42
06/02/2022 05:35:08 - INFO - __main__ - Global step 600 Train loss 7.35 Classification-F1 0.0 on epoch=42
06/02/2022 05:35:09 - INFO - __main__ - Step 610 Global step 610 Train loss 7.28 on epoch=43
06/02/2022 05:35:10 - INFO - __main__ - Step 620 Global step 620 Train loss 7.16 on epoch=44
06/02/2022 05:35:12 - INFO - __main__ - Step 630 Global step 630 Train loss 7.33 on epoch=44
06/02/2022 05:35:13 - INFO - __main__ - Step 640 Global step 640 Train loss 7.36 on epoch=45
06/02/2022 05:35:14 - INFO - __main__ - Step 650 Global step 650 Train loss 7.40 on epoch=46
06/02/2022 05:36:21 - INFO - __main__ - Global step 650 Train loss 7.31 Classification-F1 0.0 on epoch=46
06/02/2022 05:36:23 - INFO - __main__ - Step 660 Global step 660 Train loss 7.27 on epoch=47
06/02/2022 05:36:24 - INFO - __main__ - Step 670 Global step 670 Train loss 7.34 on epoch=47
06/02/2022 05:36:25 - INFO - __main__ - Step 680 Global step 680 Train loss 7.44 on epoch=48
06/02/2022 05:36:27 - INFO - __main__ - Step 690 Global step 690 Train loss 7.13 on epoch=49
06/02/2022 05:36:28 - INFO - __main__ - Step 700 Global step 700 Train loss 7.49 on epoch=49
06/02/2022 05:37:24 - INFO - __main__ - Global step 700 Train loss 7.33 Classification-F1 0.0 on epoch=49
06/02/2022 05:37:26 - INFO - __main__ - Step 710 Global step 710 Train loss 7.24 on epoch=50
06/02/2022 05:37:27 - INFO - __main__ - Step 720 Global step 720 Train loss 7.30 on epoch=51
06/02/2022 05:37:28 - INFO - __main__ - Step 730 Global step 730 Train loss 7.13 on epoch=52
06/02/2022 05:37:30 - INFO - __main__ - Step 740 Global step 740 Train loss 7.16 on epoch=52
06/02/2022 05:37:31 - INFO - __main__ - Step 750 Global step 750 Train loss 7.19 on epoch=53
06/02/2022 05:38:04 - INFO - __main__ - Global step 750 Train loss 7.20 Classification-F1 0.0 on epoch=53
06/02/2022 05:38:06 - INFO - __main__ - Step 760 Global step 760 Train loss 7.12 on epoch=54
06/02/2022 05:38:07 - INFO - __main__ - Step 770 Global step 770 Train loss 7.28 on epoch=54
06/02/2022 05:38:08 - INFO - __main__ - Step 780 Global step 780 Train loss 7.29 on epoch=55
06/02/2022 05:38:10 - INFO - __main__ - Step 790 Global step 790 Train loss 7.30 on epoch=56
06/02/2022 05:38:11 - INFO - __main__ - Step 800 Global step 800 Train loss 7.16 on epoch=57
06/02/2022 05:38:44 - INFO - __main__ - Global step 800 Train loss 7.23 Classification-F1 0.0 on epoch=57
06/02/2022 05:38:46 - INFO - __main__ - Step 810 Global step 810 Train loss 7.15 on epoch=57
06/02/2022 05:38:47 - INFO - __main__ - Step 820 Global step 820 Train loss 7.28 on epoch=58
06/02/2022 05:38:48 - INFO - __main__ - Step 830 Global step 830 Train loss 7.02 on epoch=59
06/02/2022 05:38:50 - INFO - __main__ - Step 840 Global step 840 Train loss 7.34 on epoch=59
06/02/2022 05:38:51 - INFO - __main__ - Step 850 Global step 850 Train loss 7.06 on epoch=60
06/02/2022 05:39:07 - INFO - __main__ - Global step 850 Train loss 7.17 Classification-F1 0.0 on epoch=60
06/02/2022 05:39:09 - INFO - __main__ - Step 860 Global step 860 Train loss 7.26 on epoch=61
06/02/2022 05:39:10 - INFO - __main__ - Step 870 Global step 870 Train loss 7.07 on epoch=62
06/02/2022 05:39:11 - INFO - __main__ - Step 880 Global step 880 Train loss 7.14 on epoch=62
06/02/2022 05:39:13 - INFO - __main__ - Step 890 Global step 890 Train loss 7.19 on epoch=63
06/02/2022 05:39:14 - INFO - __main__ - Step 900 Global step 900 Train loss 7.12 on epoch=64
06/02/2022 05:39:50 - INFO - __main__ - Global step 900 Train loss 7.16 Classification-F1 0.0 on epoch=64
06/02/2022 05:39:51 - INFO - __main__ - Step 910 Global step 910 Train loss 7.29 on epoch=64
06/02/2022 05:39:52 - INFO - __main__ - Step 920 Global step 920 Train loss 7.11 on epoch=65
06/02/2022 05:39:54 - INFO - __main__ - Step 930 Global step 930 Train loss 7.15 on epoch=66
06/02/2022 05:39:55 - INFO - __main__ - Step 940 Global step 940 Train loss 7.04 on epoch=67
06/02/2022 05:39:56 - INFO - __main__ - Step 950 Global step 950 Train loss 7.00 on epoch=67
06/02/2022 05:40:43 - INFO - __main__ - Global step 950 Train loss 7.12 Classification-F1 0.0 on epoch=67
06/02/2022 05:40:44 - INFO - __main__ - Step 960 Global step 960 Train loss 7.11 on epoch=68
06/02/2022 05:40:45 - INFO - __main__ - Step 970 Global step 970 Train loss 6.91 on epoch=69
06/02/2022 05:40:47 - INFO - __main__ - Step 980 Global step 980 Train loss 7.10 on epoch=69
06/02/2022 05:40:48 - INFO - __main__ - Step 990 Global step 990 Train loss 7.03 on epoch=70
06/02/2022 05:40:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 7.07 on epoch=71
06/02/2022 05:41:38 - INFO - __main__ - Global step 1000 Train loss 7.04 Classification-F1 0.0 on epoch=71
06/02/2022 05:41:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 6.93 on epoch=72
06/02/2022 05:41:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 7.04 on epoch=72
06/02/2022 05:41:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 7.03 on epoch=73
06/02/2022 05:41:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 6.93 on epoch=74
06/02/2022 05:41:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 7.15 on epoch=74
06/02/2022 05:42:17 - INFO - __main__ - Global step 1050 Train loss 7.02 Classification-F1 0.0 on epoch=74
06/02/2022 05:42:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 7.02 on epoch=75
06/02/2022 05:42:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 7.15 on epoch=76
06/02/2022 05:42:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 6.98 on epoch=77
06/02/2022 05:42:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 6.97 on epoch=77
06/02/2022 05:42:23 - INFO - __main__ - Step 1100 Global step 1100 Train loss 6.99 on epoch=78
06/02/2022 05:43:12 - INFO - __main__ - Global step 1100 Train loss 7.02 Classification-F1 0.0 on epoch=78
06/02/2022 05:43:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 6.98 on epoch=79
06/02/2022 05:43:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 7.09 on epoch=79
06/02/2022 05:43:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 7.03 on epoch=80
06/02/2022 05:43:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 7.01 on epoch=81
06/02/2022 05:43:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 6.91 on epoch=82
06/02/2022 05:44:28 - INFO - __main__ - Global step 1150 Train loss 7.01 Classification-F1 0.0 on epoch=82
06/02/2022 05:44:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 7.02 on epoch=82
06/02/2022 05:44:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 6.98 on epoch=83
06/02/2022 05:44:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 6.88 on epoch=84
06/02/2022 05:44:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 7.06 on epoch=84
06/02/2022 05:44:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 6.87 on epoch=85
06/02/2022 05:45:07 - INFO - __main__ - Global step 1200 Train loss 6.96 Classification-F1 0.0 on epoch=85
06/02/2022 05:45:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 6.88 on epoch=86
06/02/2022 05:45:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 6.82 on epoch=87
06/02/2022 05:45:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 6.85 on epoch=87
06/02/2022 05:45:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 6.90 on epoch=88
06/02/2022 05:45:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 6.73 on epoch=89
06/02/2022 05:45:30 - INFO - __main__ - Global step 1250 Train loss 6.84 Classification-F1 0.0 on epoch=89
06/02/2022 05:45:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 6.94 on epoch=89
06/02/2022 05:45:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 6.75 on epoch=90
06/02/2022 05:45:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 6.83 on epoch=91
06/02/2022 05:45:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 6.71 on epoch=92
06/02/2022 05:45:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 6.81 on epoch=92
06/02/2022 05:46:01 - INFO - __main__ - Global step 1300 Train loss 6.81 Classification-F1 0.0 on epoch=92
06/02/2022 05:46:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 6.76 on epoch=93
06/02/2022 05:46:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 6.71 on epoch=94
06/02/2022 05:46:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 6.64 on epoch=94
06/02/2022 05:46:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 6.53 on epoch=95
06/02/2022 05:46:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 6.53 on epoch=96
06/02/2022 05:46:25 - INFO - __main__ - Global step 1350 Train loss 6.63 Classification-F1 0.0 on epoch=96
06/02/2022 05:46:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 6.61 on epoch=97
06/02/2022 05:46:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 6.61 on epoch=97
06/02/2022 05:46:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 6.70 on epoch=98
06/02/2022 05:46:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 6.47 on epoch=99
06/02/2022 05:46:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 6.64 on epoch=99
06/02/2022 05:47:22 - INFO - __main__ - Global step 1400 Train loss 6.61 Classification-F1 0.0 on epoch=99
06/02/2022 05:47:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 6.57 on epoch=100
06/02/2022 05:47:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 6.62 on epoch=101
06/02/2022 05:47:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 6.49 on epoch=102
06/02/2022 05:47:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 6.58 on epoch=102
06/02/2022 05:47:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 6.61 on epoch=103
06/02/2022 05:48:05 - INFO - __main__ - Global step 1450 Train loss 6.58 Classification-F1 0.0 on epoch=103
06/02/2022 05:48:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 6.46 on epoch=104
06/02/2022 05:48:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 6.64 on epoch=104
06/02/2022 05:48:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 6.53 on epoch=105
06/02/2022 05:48:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 6.52 on epoch=106
06/02/2022 05:48:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 6.37 on epoch=107
06/02/2022 05:48:46 - INFO - __main__ - Global step 1500 Train loss 6.50 Classification-F1 0.0 on epoch=107
06/02/2022 05:48:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 6.36 on epoch=107
06/02/2022 05:48:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 6.38 on epoch=108
06/02/2022 05:48:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 6.43 on epoch=109
06/02/2022 05:48:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 6.54 on epoch=109
06/02/2022 05:48:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 6.35 on epoch=110
06/02/2022 05:49:36 - INFO - __main__ - Global step 1550 Train loss 6.41 Classification-F1 0.0 on epoch=110
06/02/2022 05:49:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 6.32 on epoch=111
06/02/2022 05:49:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 6.35 on epoch=112
06/02/2022 05:49:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 6.34 on epoch=112
06/02/2022 05:49:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 6.39 on epoch=113
06/02/2022 05:49:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 6.25 on epoch=114
06/02/2022 05:50:26 - INFO - __main__ - Global step 1600 Train loss 6.33 Classification-F1 0.0 on epoch=114
06/02/2022 05:50:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 6.40 on epoch=114
06/02/2022 05:50:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 6.49 on epoch=115
06/02/2022 05:50:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 6.28 on epoch=116
06/02/2022 05:50:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 6.24 on epoch=117
06/02/2022 05:50:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 6.31 on epoch=117
06/02/2022 05:51:16 - INFO - __main__ - Global step 1650 Train loss 6.34 Classification-F1 0.0 on epoch=117
06/02/2022 05:51:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 6.23 on epoch=118
06/02/2022 05:51:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 6.24 on epoch=119
06/02/2022 05:51:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 6.23 on epoch=119
06/02/2022 05:51:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 6.27 on epoch=120
06/02/2022 05:51:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 6.29 on epoch=121
06/02/2022 05:51:56 - INFO - __main__ - Global step 1700 Train loss 6.25 Classification-F1 0.0 on epoch=121
06/02/2022 05:51:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 6.21 on epoch=122
06/02/2022 05:51:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 6.23 on epoch=122
06/02/2022 05:52:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 6.20 on epoch=123
06/02/2022 05:52:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 6.09 on epoch=124
06/02/2022 05:52:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 6.25 on epoch=124
06/02/2022 05:52:27 - INFO - __main__ - Global step 1750 Train loss 6.20 Classification-F1 0.0 on epoch=124
06/02/2022 05:52:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 6.07 on epoch=125
06/02/2022 05:52:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 6.11 on epoch=126
06/02/2022 05:52:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 6.05 on epoch=127
06/02/2022 05:52:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 6.09 on epoch=127
06/02/2022 05:52:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 6.15 on epoch=128
06/02/2022 05:53:07 - INFO - __main__ - Global step 1800 Train loss 6.09 Classification-F1 0.0 on epoch=128
06/02/2022 05:53:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 6.19 on epoch=129
06/02/2022 05:53:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 6.23 on epoch=129
06/02/2022 05:53:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 6.06 on epoch=130
06/02/2022 05:53:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 6.04 on epoch=131
06/02/2022 05:53:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 5.99 on epoch=132
06/02/2022 05:53:40 - INFO - __main__ - Global step 1850 Train loss 6.10 Classification-F1 0.0 on epoch=132
06/02/2022 05:53:42 - INFO - __main__ - Step 1860 Global step 1860 Train loss 6.09 on epoch=132
06/02/2022 05:53:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 6.17 on epoch=133
06/02/2022 05:53:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 6.00 on epoch=134
06/02/2022 05:53:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 6.12 on epoch=134
06/02/2022 05:53:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 6.10 on epoch=135
06/02/2022 05:54:00 - INFO - __main__ - Global step 1900 Train loss 6.10 Classification-F1 0.0 on epoch=135
06/02/2022 05:54:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 6.01 on epoch=136
06/02/2022 05:54:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 5.92 on epoch=137
06/02/2022 05:54:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 5.90 on epoch=137
06/02/2022 05:54:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 6.00 on epoch=138
06/02/2022 05:54:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 5.80 on epoch=139
06/02/2022 05:54:29 - INFO - __main__ - Global step 1950 Train loss 5.92 Classification-F1 0.0 on epoch=139
06/02/2022 05:54:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 6.06 on epoch=139
06/02/2022 05:54:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 6.03 on epoch=140
06/02/2022 05:54:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 5.86 on epoch=141
06/02/2022 05:54:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 5.88 on epoch=142
06/02/2022 05:54:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 5.83 on epoch=142
06/02/2022 05:55:04 - INFO - __main__ - Global step 2000 Train loss 5.93 Classification-F1 0.0 on epoch=142
06/02/2022 05:55:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 5.89 on epoch=143
06/02/2022 05:55:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 5.73 on epoch=144
06/02/2022 05:55:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 5.77 on epoch=144
06/02/2022 05:55:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 5.86 on epoch=145
06/02/2022 05:55:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 5.78 on epoch=146
06/02/2022 05:55:44 - INFO - __main__ - Global step 2050 Train loss 5.80 Classification-F1 0.0 on epoch=146
06/02/2022 05:55:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 5.52 on epoch=147
06/02/2022 05:55:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 5.66 on epoch=147
06/02/2022 05:55:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 5.66 on epoch=148
06/02/2022 05:55:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 5.71 on epoch=149
06/02/2022 05:55:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 5.76 on epoch=149
06/02/2022 05:56:32 - INFO - __main__ - Global step 2100 Train loss 5.66 Classification-F1 0.0 on epoch=149
06/02/2022 05:56:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 5.65 on epoch=150
06/02/2022 05:56:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 5.49 on epoch=151
06/02/2022 05:56:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 5.53 on epoch=152
06/02/2022 05:56:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 5.56 on epoch=152
06/02/2022 05:56:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 5.48 on epoch=153
06/02/2022 05:57:48 - INFO - __main__ - Global step 2150 Train loss 5.54 Classification-F1 0.0 on epoch=153
06/02/2022 05:57:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 5.55 on epoch=154
06/02/2022 05:57:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 5.80 on epoch=154
06/02/2022 05:57:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 5.60 on epoch=155
06/02/2022 05:57:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 5.53 on epoch=156
06/02/2022 05:57:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 5.47 on epoch=157
06/02/2022 05:58:34 - INFO - __main__ - Global step 2200 Train loss 5.59 Classification-F1 0.0 on epoch=157
06/02/2022 05:58:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 5.59 on epoch=157
06/02/2022 05:58:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 5.57 on epoch=158
06/02/2022 05:58:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 5.53 on epoch=159
06/02/2022 05:58:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 5.51 on epoch=159
06/02/2022 05:58:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 5.57 on epoch=160
06/02/2022 05:59:13 - INFO - __main__ - Global step 2250 Train loss 5.55 Classification-F1 0.0 on epoch=160
06/02/2022 05:59:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 5.51 on epoch=161
06/02/2022 05:59:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 5.43 on epoch=162
06/02/2022 05:59:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 5.51 on epoch=162
06/02/2022 05:59:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 5.34 on epoch=163
06/02/2022 05:59:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 5.37 on epoch=164
06/02/2022 05:59:32 - INFO - __main__ - Global step 2300 Train loss 5.43 Classification-F1 0.0 on epoch=164
06/02/2022 05:59:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 5.35 on epoch=164
06/02/2022 05:59:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 5.34 on epoch=165
06/02/2022 05:59:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 5.24 on epoch=166
06/02/2022 05:59:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 5.14 on epoch=167
06/02/2022 05:59:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 5.25 on epoch=167
06/02/2022 05:59:48 - INFO - __main__ - Global step 2350 Train loss 5.26 Classification-F1 0.0 on epoch=167
06/02/2022 05:59:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 5.26 on epoch=168
06/02/2022 05:59:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 5.24 on epoch=169
06/02/2022 05:59:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 5.20 on epoch=169
06/02/2022 05:59:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 5.25 on epoch=170
06/02/2022 05:59:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 5.07 on epoch=171
06/02/2022 06:00:04 - INFO - __main__ - Global step 2400 Train loss 5.20 Classification-F1 0.0 on epoch=171
06/02/2022 06:00:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 5.19 on epoch=172
06/02/2022 06:00:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 5.06 on epoch=172
06/02/2022 06:00:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 5.02 on epoch=173
06/02/2022 06:00:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 4.95 on epoch=174
06/02/2022 06:00:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 5.01 on epoch=174
06/02/2022 06:00:26 - INFO - __main__ - Global step 2450 Train loss 5.04 Classification-F1 0.0 on epoch=174
06/02/2022 06:00:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 5.12 on epoch=175
06/02/2022 06:00:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 4.93 on epoch=176
06/02/2022 06:00:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 4.94 on epoch=177
06/02/2022 06:00:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 4.91 on epoch=177
06/02/2022 06:00:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 4.84 on epoch=178
06/02/2022 06:00:43 - INFO - __main__ - Global step 2500 Train loss 4.95 Classification-F1 0.0 on epoch=178
06/02/2022 06:00:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 4.85 on epoch=179
06/02/2022 06:00:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 4.83 on epoch=179
06/02/2022 06:00:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 4.96 on epoch=180
06/02/2022 06:00:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 4.93 on epoch=181
06/02/2022 06:00:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 4.75 on epoch=182
06/02/2022 06:00:54 - INFO - __main__ - Global step 2550 Train loss 4.86 Classification-F1 0.0 on epoch=182
06/02/2022 06:00:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 4.73 on epoch=182
06/02/2022 06:00:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 4.77 on epoch=183
06/02/2022 06:00:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 4.56 on epoch=184
06/02/2022 06:00:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 4.79 on epoch=184
06/02/2022 06:01:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 4.73 on epoch=185
06/02/2022 06:01:03 - INFO - __main__ - Global step 2600 Train loss 4.71 Classification-F1 0.0 on epoch=185
06/02/2022 06:01:04 - INFO - __main__ - Step 2610 Global step 2610 Train loss 4.60 on epoch=186
06/02/2022 06:01:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 4.63 on epoch=187
06/02/2022 06:01:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 4.55 on epoch=187
06/02/2022 06:01:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 4.59 on epoch=188
06/02/2022 06:01:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 4.62 on epoch=189
06/02/2022 06:01:13 - INFO - __main__ - Global step 2650 Train loss 4.60 Classification-F1 0.0021052631578947364 on epoch=189
06/02/2022 06:01:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0021052631578947364 on epoch=189, global_step=2650
06/02/2022 06:01:14 - INFO - __main__ - Step 2660 Global step 2660 Train loss 4.59 on epoch=189
06/02/2022 06:01:16 - INFO - __main__ - Step 2670 Global step 2670 Train loss 4.56 on epoch=190
06/02/2022 06:01:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 4.46 on epoch=191
06/02/2022 06:01:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 4.44 on epoch=192
06/02/2022 06:01:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 4.36 on epoch=192
06/02/2022 06:01:23 - INFO - __main__ - Global step 2700 Train loss 4.48 Classification-F1 0.015381591232984423 on epoch=192
06/02/2022 06:01:23 - INFO - __main__ - Saving model with best Classification-F1: 0.0021052631578947364 -> 0.015381591232984423 on epoch=192, global_step=2700
06/02/2022 06:01:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 4.36 on epoch=193
06/02/2022 06:01:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 4.45 on epoch=194
06/02/2022 06:01:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 4.37 on epoch=194
06/02/2022 06:01:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 4.38 on epoch=195
06/02/2022 06:01:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 4.33 on epoch=196
06/02/2022 06:01:32 - INFO - __main__ - Global step 2750 Train loss 4.38 Classification-F1 0.0222971401999535 on epoch=196
06/02/2022 06:01:32 - INFO - __main__ - Saving model with best Classification-F1: 0.015381591232984423 -> 0.0222971401999535 on epoch=196, global_step=2750
06/02/2022 06:01:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 4.35 on epoch=197
06/02/2022 06:01:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 4.23 on epoch=197
06/02/2022 06:01:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 4.19 on epoch=198
06/02/2022 06:01:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 4.27 on epoch=199
06/02/2022 06:01:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 4.19 on epoch=199
06/02/2022 06:01:41 - INFO - __main__ - Global step 2800 Train loss 4.24 Classification-F1 0.04568833166456256 on epoch=199
06/02/2022 06:01:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0222971401999535 -> 0.04568833166456256 on epoch=199, global_step=2800
06/02/2022 06:01:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 4.30 on epoch=200
06/02/2022 06:01:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 4.13 on epoch=201
06/02/2022 06:01:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 4.02 on epoch=202
06/02/2022 06:01:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 4.06 on epoch=202
06/02/2022 06:01:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 4.12 on epoch=203
06/02/2022 06:01:50 - INFO - __main__ - Global step 2850 Train loss 4.13 Classification-F1 0.02915593705293276 on epoch=203
06/02/2022 06:01:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 4.05 on epoch=204
06/02/2022 06:01:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 3.98 on epoch=204
06/02/2022 06:01:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 3.96 on epoch=205
06/02/2022 06:01:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 3.91 on epoch=206
06/02/2022 06:01:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 3.93 on epoch=207
06/02/2022 06:01:59 - INFO - __main__ - Global step 2900 Train loss 3.97 Classification-F1 0.029714989444053486 on epoch=207
06/02/2022 06:02:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 3.91 on epoch=207
06/02/2022 06:02:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 3.81 on epoch=208
06/02/2022 06:02:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 3.94 on epoch=209
06/02/2022 06:02:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 3.79 on epoch=209
06/02/2022 06:02:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 3.91 on epoch=210
06/02/2022 06:02:08 - INFO - __main__ - Global step 2950 Train loss 3.87 Classification-F1 0.0377889288723421 on epoch=210
06/02/2022 06:02:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 3.76 on epoch=211
06/02/2022 06:02:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 3.80 on epoch=212
06/02/2022 06:02:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 3.63 on epoch=212
06/02/2022 06:02:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 3.83 on epoch=213
06/02/2022 06:02:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 3.79 on epoch=214
06/02/2022 06:02:15 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:02:15 - INFO - __main__ - Printing 3 examples
06/02/2022 06:02:15 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 06:02:15 - INFO - __main__ - ['Animal']
06/02/2022 06:02:15 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 06:02:15 - INFO - __main__ - ['Animal']
06/02/2022 06:02:15 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 06:02:15 - INFO - __main__ - ['Animal']
06/02/2022 06:02:15 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:02:15 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:02:16 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:02:16 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:02:16 - INFO - __main__ - Printing 3 examples
06/02/2022 06:02:16 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 06:02:16 - INFO - __main__ - ['Animal']
06/02/2022 06:02:16 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 06:02:16 - INFO - __main__ - ['Animal']
06/02/2022 06:02:16 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 06:02:16 - INFO - __main__ - ['Animal']
06/02/2022 06:02:16 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:02:16 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:02:16 - INFO - __main__ - Global step 3000 Train loss 3.76 Classification-F1 0.030836887979745122 on epoch=214
06/02/2022 06:02:16 - INFO - __main__ - save last model!
06/02/2022 06:02:16 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:02:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 06:02:16 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 06:02:16 - INFO - __main__ - Printing 3 examples
06/02/2022 06:02:16 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 06:02:16 - INFO - __main__ - ['Animal']
06/02/2022 06:02:16 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 06:02:16 - INFO - __main__ - ['Animal']
06/02/2022 06:02:16 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 06:02:16 - INFO - __main__ - ['Village']
06/02/2022 06:02:16 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:02:18 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:02:21 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 06:02:22 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:02:22 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:02:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:02:23 - INFO - __main__ - Starting training!
06/02/2022 06:02:51 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/02/2022 06:02:51 - INFO - __main__ - Classification-F1 on test data: 0.0394
06/02/2022 06:02:51 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.04568833166456256, test_performance=0.03941476260400863
06/02/2022 06:02:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/02/2022 06:02:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:02:52 - INFO - __main__ - Printing 3 examples
06/02/2022 06:02:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 06:02:52 - INFO - __main__ - ['Animal']
06/02/2022 06:02:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 06:02:52 - INFO - __main__ - ['Animal']
06/02/2022 06:02:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 06:02:52 - INFO - __main__ - ['Animal']
06/02/2022 06:02:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:02:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:02:52 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:02:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:02:52 - INFO - __main__ - Printing 3 examples
06/02/2022 06:02:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 06:02:52 - INFO - __main__ - ['Animal']
06/02/2022 06:02:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 06:02:52 - INFO - __main__ - ['Animal']
06/02/2022 06:02:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 06:02:52 - INFO - __main__ - ['Animal']
06/02/2022 06:02:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:02:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:02:53 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:02:59 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:02:59 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:02:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:02:59 - INFO - __main__ - Starting training!
06/02/2022 06:03:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.64 on epoch=0
06/02/2022 06:03:02 - INFO - __main__ - Step 20 Global step 20 Train loss 6.49 on epoch=1
06/02/2022 06:03:03 - INFO - __main__ - Step 30 Global step 30 Train loss 5.65 on epoch=2
06/02/2022 06:03:04 - INFO - __main__ - Step 40 Global step 40 Train loss 5.30 on epoch=2
06/02/2022 06:03:06 - INFO - __main__ - Step 50 Global step 50 Train loss 5.14 on epoch=3
06/02/2022 06:03:43 - INFO - __main__ - Global step 50 Train loss 5.84 Classification-F1 0.0 on epoch=3
06/02/2022 06:03:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 06:03:44 - INFO - __main__ - Step 60 Global step 60 Train loss 4.97 on epoch=4
06/02/2022 06:03:45 - INFO - __main__ - Step 70 Global step 70 Train loss 4.81 on epoch=4
06/02/2022 06:03:46 - INFO - __main__ - Step 80 Global step 80 Train loss 4.23 on epoch=5
06/02/2022 06:03:48 - INFO - __main__ - Step 90 Global step 90 Train loss 3.85 on epoch=6
06/02/2022 06:03:49 - INFO - __main__ - Step 100 Global step 100 Train loss 3.45 on epoch=7
06/02/2022 06:03:52 - INFO - __main__ - Global step 100 Train loss 4.26 Classification-F1 0.11930693831532661 on epoch=7
06/02/2022 06:03:52 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.11930693831532661 on epoch=7, global_step=100
06/02/2022 06:03:54 - INFO - __main__ - Step 110 Global step 110 Train loss 2.90 on epoch=7
06/02/2022 06:03:55 - INFO - __main__ - Step 120 Global step 120 Train loss 2.64 on epoch=8
06/02/2022 06:03:56 - INFO - __main__ - Step 130 Global step 130 Train loss 2.65 on epoch=9
06/02/2022 06:03:57 - INFO - __main__ - Step 140 Global step 140 Train loss 2.54 on epoch=9
06/02/2022 06:03:59 - INFO - __main__ - Step 150 Global step 150 Train loss 2.25 on epoch=10
06/02/2022 06:04:02 - INFO - __main__ - Global step 150 Train loss 2.60 Classification-F1 0.22759701641962485 on epoch=10
06/02/2022 06:04:02 - INFO - __main__ - Saving model with best Classification-F1: 0.11930693831532661 -> 0.22759701641962485 on epoch=10, global_step=150
06/02/2022 06:04:03 - INFO - __main__ - Step 160 Global step 160 Train loss 2.09 on epoch=11
06/02/2022 06:04:04 - INFO - __main__ - Step 170 Global step 170 Train loss 1.88 on epoch=12
06/02/2022 06:04:06 - INFO - __main__ - Step 180 Global step 180 Train loss 1.74 on epoch=12
06/02/2022 06:04:07 - INFO - __main__ - Step 190 Global step 190 Train loss 1.73 on epoch=13
06/02/2022 06:04:08 - INFO - __main__ - Step 200 Global step 200 Train loss 1.49 on epoch=14
06/02/2022 06:04:11 - INFO - __main__ - Global step 200 Train loss 1.79 Classification-F1 0.32180990754397953 on epoch=14
06/02/2022 06:04:11 - INFO - __main__ - Saving model with best Classification-F1: 0.22759701641962485 -> 0.32180990754397953 on epoch=14, global_step=200
06/02/2022 06:04:13 - INFO - __main__ - Step 210 Global step 210 Train loss 1.42 on epoch=14
06/02/2022 06:04:14 - INFO - __main__ - Step 220 Global step 220 Train loss 1.31 on epoch=15
06/02/2022 06:04:15 - INFO - __main__ - Step 230 Global step 230 Train loss 1.26 on epoch=16
06/02/2022 06:04:16 - INFO - __main__ - Step 240 Global step 240 Train loss 1.39 on epoch=17
06/02/2022 06:04:18 - INFO - __main__ - Step 250 Global step 250 Train loss 1.14 on epoch=17
06/02/2022 06:04:21 - INFO - __main__ - Global step 250 Train loss 1.30 Classification-F1 0.40293559218697356 on epoch=17
06/02/2022 06:04:21 - INFO - __main__ - Saving model with best Classification-F1: 0.32180990754397953 -> 0.40293559218697356 on epoch=17, global_step=250
06/02/2022 06:04:23 - INFO - __main__ - Step 260 Global step 260 Train loss 1.24 on epoch=18
06/02/2022 06:04:24 - INFO - __main__ - Step 270 Global step 270 Train loss 1.22 on epoch=19
06/02/2022 06:04:25 - INFO - __main__ - Step 280 Global step 280 Train loss 1.10 on epoch=19
06/02/2022 06:04:26 - INFO - __main__ - Step 290 Global step 290 Train loss 1.09 on epoch=20
06/02/2022 06:04:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.97 on epoch=21
06/02/2022 06:04:31 - INFO - __main__ - Global step 300 Train loss 1.12 Classification-F1 0.48748724779543084 on epoch=21
06/02/2022 06:04:31 - INFO - __main__ - Saving model with best Classification-F1: 0.40293559218697356 -> 0.48748724779543084 on epoch=21, global_step=300
06/02/2022 06:04:33 - INFO - __main__ - Step 310 Global step 310 Train loss 1.03 on epoch=22
06/02/2022 06:04:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.89 on epoch=22
06/02/2022 06:04:35 - INFO - __main__ - Step 330 Global step 330 Train loss 1.00 on epoch=23
06/02/2022 06:04:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.94 on epoch=24
06/02/2022 06:04:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.84 on epoch=24
06/02/2022 06:04:41 - INFO - __main__ - Global step 350 Train loss 0.94 Classification-F1 0.4509160683968868 on epoch=24
06/02/2022 06:04:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.87 on epoch=25
06/02/2022 06:04:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.83 on epoch=26
06/02/2022 06:04:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.89 on epoch=27
06/02/2022 06:04:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.71 on epoch=27
06/02/2022 06:04:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.73 on epoch=28
06/02/2022 06:04:52 - INFO - __main__ - Global step 400 Train loss 0.80 Classification-F1 0.531482864514081 on epoch=28
06/02/2022 06:04:52 - INFO - __main__ - Saving model with best Classification-F1: 0.48748724779543084 -> 0.531482864514081 on epoch=28, global_step=400
06/02/2022 06:04:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.80 on epoch=29
06/02/2022 06:04:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.69 on epoch=29
06/02/2022 06:04:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.72 on epoch=30
06/02/2022 06:04:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.67 on epoch=31
06/02/2022 06:04:58 - INFO - __main__ - Step 450 Global step 450 Train loss 0.67 on epoch=32
06/02/2022 06:05:02 - INFO - __main__ - Global step 450 Train loss 0.71 Classification-F1 0.5588445480588052 on epoch=32
06/02/2022 06:05:02 - INFO - __main__ - Saving model with best Classification-F1: 0.531482864514081 -> 0.5588445480588052 on epoch=32, global_step=450
06/02/2022 06:05:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.68 on epoch=32
06/02/2022 06:05:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.70 on epoch=33
06/02/2022 06:05:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.66 on epoch=34
06/02/2022 06:05:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.66 on epoch=34
06/02/2022 06:05:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.67 on epoch=35
06/02/2022 06:05:12 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.49471841037328634 on epoch=35
06/02/2022 06:05:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.65 on epoch=36
06/02/2022 06:05:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.71 on epoch=37
06/02/2022 06:05:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.68 on epoch=37
06/02/2022 06:05:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=38
06/02/2022 06:05:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.54 on epoch=39
06/02/2022 06:05:22 - INFO - __main__ - Global step 550 Train loss 0.63 Classification-F1 0.5102690810158907 on epoch=39
06/02/2022 06:05:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.57 on epoch=39
06/02/2022 06:05:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.57 on epoch=40
06/02/2022 06:05:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.58 on epoch=41
06/02/2022 06:05:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.57 on epoch=42
06/02/2022 06:05:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.57 on epoch=42
06/02/2022 06:05:32 - INFO - __main__ - Global step 600 Train loss 0.57 Classification-F1 0.6107792453041192 on epoch=42
06/02/2022 06:05:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5588445480588052 -> 0.6107792453041192 on epoch=42, global_step=600
06/02/2022 06:05:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.56 on epoch=43
06/02/2022 06:05:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.63 on epoch=44
06/02/2022 06:05:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.53 on epoch=44
06/02/2022 06:05:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.54 on epoch=45
06/02/2022 06:05:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.58 on epoch=46
06/02/2022 06:05:42 - INFO - __main__ - Global step 650 Train loss 0.57 Classification-F1 0.5686136964822777 on epoch=46
06/02/2022 06:05:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.51 on epoch=47
06/02/2022 06:05:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.49 on epoch=47
06/02/2022 06:05:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.48 on epoch=48
06/02/2022 06:05:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.45 on epoch=49
06/02/2022 06:05:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.52 on epoch=49
06/02/2022 06:05:52 - INFO - __main__ - Global step 700 Train loss 0.49 Classification-F1 0.594970741929654 on epoch=49
06/02/2022 06:05:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.47 on epoch=50
06/02/2022 06:05:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.49 on epoch=51
06/02/2022 06:05:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.47 on epoch=52
06/02/2022 06:05:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.46 on epoch=52
06/02/2022 06:05:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.46 on epoch=53
06/02/2022 06:06:02 - INFO - __main__ - Global step 750 Train loss 0.47 Classification-F1 0.6595020123245929 on epoch=53
06/02/2022 06:06:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6107792453041192 -> 0.6595020123245929 on epoch=53, global_step=750
06/02/2022 06:06:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=54
06/02/2022 06:06:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.51 on epoch=54
06/02/2022 06:06:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.46 on epoch=55
06/02/2022 06:06:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.53 on epoch=56
06/02/2022 06:06:09 - INFO - __main__ - Step 800 Global step 800 Train loss 0.47 on epoch=57
06/02/2022 06:06:12 - INFO - __main__ - Global step 800 Train loss 0.48 Classification-F1 0.5725832865908167 on epoch=57
06/02/2022 06:06:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.50 on epoch=57
06/02/2022 06:06:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.44 on epoch=58
06/02/2022 06:06:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.44 on epoch=59
06/02/2022 06:06:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.33 on epoch=59
06/02/2022 06:06:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.42 on epoch=60
06/02/2022 06:06:22 - INFO - __main__ - Global step 850 Train loss 0.43 Classification-F1 0.5180655351094494 on epoch=60
06/02/2022 06:06:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.41 on epoch=61
06/02/2022 06:06:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.47 on epoch=62
06/02/2022 06:06:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.39 on epoch=62
06/02/2022 06:06:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.46 on epoch=63
06/02/2022 06:06:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.40 on epoch=64
06/02/2022 06:06:32 - INFO - __main__ - Global step 900 Train loss 0.43 Classification-F1 0.5988523154926408 on epoch=64
06/02/2022 06:06:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.38 on epoch=64
06/02/2022 06:06:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.34 on epoch=65
06/02/2022 06:06:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.37 on epoch=66
06/02/2022 06:06:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.35 on epoch=67
06/02/2022 06:06:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.38 on epoch=67
06/02/2022 06:06:42 - INFO - __main__ - Global step 950 Train loss 0.36 Classification-F1 0.6394622806387512 on epoch=67
06/02/2022 06:06:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.52 on epoch=68
06/02/2022 06:06:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=69
06/02/2022 06:06:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.33 on epoch=69
06/02/2022 06:06:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=70
06/02/2022 06:06:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.30 on epoch=71
06/02/2022 06:06:52 - INFO - __main__ - Global step 1000 Train loss 0.35 Classification-F1 0.8996954452803708 on epoch=71
06/02/2022 06:06:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6595020123245929 -> 0.8996954452803708 on epoch=71, global_step=1000
06/02/2022 06:06:53 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.38 on epoch=72
06/02/2022 06:06:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.36 on epoch=72
06/02/2022 06:06:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.39 on epoch=73
06/02/2022 06:06:57 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.40 on epoch=74
06/02/2022 06:06:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.39 on epoch=74
06/02/2022 06:07:02 - INFO - __main__ - Global step 1050 Train loss 0.38 Classification-F1 0.666202003777458 on epoch=74
06/02/2022 06:07:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.30 on epoch=75
06/02/2022 06:07:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.35 on epoch=76
06/02/2022 06:07:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=77
06/02/2022 06:07:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.32 on epoch=77
06/02/2022 06:07:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
06/02/2022 06:07:12 - INFO - __main__ - Global step 1100 Train loss 0.32 Classification-F1 0.7528160674618195 on epoch=78
06/02/2022 06:07:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.35 on epoch=79
06/02/2022 06:07:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.29 on epoch=79
06/02/2022 06:07:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.37 on epoch=80
06/02/2022 06:07:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.35 on epoch=81
06/02/2022 06:07:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=82
06/02/2022 06:07:22 - INFO - __main__ - Global step 1150 Train loss 0.33 Classification-F1 0.6633966958957402 on epoch=82
06/02/2022 06:07:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.31 on epoch=82
06/02/2022 06:07:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=83
06/02/2022 06:07:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.26 on epoch=84
06/02/2022 06:07:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.24 on epoch=84
06/02/2022 06:07:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.34 on epoch=85
06/02/2022 06:07:31 - INFO - __main__ - Global step 1200 Train loss 0.27 Classification-F1 0.48803831808872133 on epoch=85
06/02/2022 06:07:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.36 on epoch=86
06/02/2022 06:07:34 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.46 on epoch=87
06/02/2022 06:07:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=87
06/02/2022 06:07:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.29 on epoch=88
06/02/2022 06:07:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.26 on epoch=89
06/02/2022 06:07:41 - INFO - __main__ - Global step 1250 Train loss 0.31 Classification-F1 0.7281268042042268 on epoch=89
06/02/2022 06:07:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.30 on epoch=89
06/02/2022 06:07:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.35 on epoch=90
06/02/2022 06:07:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=91
06/02/2022 06:07:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.27 on epoch=92
06/02/2022 06:07:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=92
06/02/2022 06:07:51 - INFO - __main__ - Global step 1300 Train loss 0.27 Classification-F1 0.5666506548479983 on epoch=92
06/02/2022 06:07:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=93
06/02/2022 06:07:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/02/2022 06:07:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.27 on epoch=94
06/02/2022 06:07:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=95
06/02/2022 06:07:58 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/02/2022 06:08:01 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.8272951308455934 on epoch=96
06/02/2022 06:08:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.26 on epoch=97
06/02/2022 06:08:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=97
06/02/2022 06:08:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.21 on epoch=98
06/02/2022 06:08:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=99
06/02/2022 06:08:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=99
06/02/2022 06:08:11 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.7379445427215825 on epoch=99
06/02/2022 06:08:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=100
06/02/2022 06:08:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=101
06/02/2022 06:08:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=102
06/02/2022 06:08:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=102
06/02/2022 06:08:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=103
06/02/2022 06:08:21 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.8532585843069715 on epoch=103
06/02/2022 06:08:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=104
06/02/2022 06:08:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=104
06/02/2022 06:08:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
06/02/2022 06:08:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/02/2022 06:08:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=107
06/02/2022 06:08:31 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.75395338521304 on epoch=107
06/02/2022 06:08:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=107
06/02/2022 06:08:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=108
06/02/2022 06:08:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=109
06/02/2022 06:08:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=109
06/02/2022 06:08:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=110
06/02/2022 06:08:40 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.9039702528127573 on epoch=110
06/02/2022 06:08:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8996954452803708 -> 0.9039702528127573 on epoch=110, global_step=1550
06/02/2022 06:08:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=111
06/02/2022 06:08:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=112
06/02/2022 06:08:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=112
06/02/2022 06:08:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.23 on epoch=113
06/02/2022 06:08:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.18 on epoch=114
06/02/2022 06:08:51 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.7990357562627539 on epoch=114
06/02/2022 06:08:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.21 on epoch=114
06/02/2022 06:08:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.23 on epoch=115
06/02/2022 06:08:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=116
06/02/2022 06:08:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=117
06/02/2022 06:08:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=117
06/02/2022 06:09:00 - INFO - __main__ - Global step 1650 Train loss 0.18 Classification-F1 0.7809770398198717 on epoch=117
06/02/2022 06:09:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=118
06/02/2022 06:09:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.17 on epoch=119
06/02/2022 06:09:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.13 on epoch=119
06/02/2022 06:09:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=120
06/02/2022 06:09:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.18 on epoch=121
06/02/2022 06:09:10 - INFO - __main__ - Global step 1700 Train loss 0.15 Classification-F1 0.6824098875969375 on epoch=121
06/02/2022 06:09:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=122
06/02/2022 06:09:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=122
06/02/2022 06:09:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=123
06/02/2022 06:09:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=124
06/02/2022 06:09:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.20 on epoch=124
06/02/2022 06:09:20 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.67761928454449 on epoch=124
06/02/2022 06:09:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=125
06/02/2022 06:09:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/02/2022 06:09:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=127
06/02/2022 06:09:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=127
06/02/2022 06:09:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=128
06/02/2022 06:09:30 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.7635590690144769 on epoch=128
06/02/2022 06:09:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=129
06/02/2022 06:09:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=129
06/02/2022 06:09:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/02/2022 06:09:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/02/2022 06:09:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/02/2022 06:09:40 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7421642065551965 on epoch=132
06/02/2022 06:09:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/02/2022 06:09:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=133
06/02/2022 06:09:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=134
06/02/2022 06:09:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=134
06/02/2022 06:09:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=135
06/02/2022 06:09:50 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.7579266543851376 on epoch=135
06/02/2022 06:09:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=136
06/02/2022 06:09:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=137
06/02/2022 06:09:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=137
06/02/2022 06:09:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=138
06/02/2022 06:09:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=139
06/02/2022 06:10:00 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.8940781417378507 on epoch=139
06/02/2022 06:10:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=139
06/02/2022 06:10:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=140
06/02/2022 06:10:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=141
06/02/2022 06:10:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=142
06/02/2022 06:10:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=142
06/02/2022 06:10:10 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.8312192239938245 on epoch=142
06/02/2022 06:10:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/02/2022 06:10:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/02/2022 06:10:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.17 on epoch=144
06/02/2022 06:10:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.15 on epoch=145
06/02/2022 06:10:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=146
06/02/2022 06:10:20 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.7076081563221651 on epoch=146
06/02/2022 06:10:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/02/2022 06:10:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/02/2022 06:10:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=148
06/02/2022 06:10:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/02/2022 06:10:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=149
06/02/2022 06:10:30 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.7474033732098249 on epoch=149
06/02/2022 06:10:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=150
06/02/2022 06:10:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/02/2022 06:10:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=152
06/02/2022 06:10:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=152
06/02/2022 06:10:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
06/02/2022 06:10:40 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.7680112842100788 on epoch=153
06/02/2022 06:10:41 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
06/02/2022 06:10:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
06/02/2022 06:10:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/02/2022 06:10:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/02/2022 06:10:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.18 on epoch=157
06/02/2022 06:10:50 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.6336871442125236 on epoch=157
06/02/2022 06:10:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=157
06/02/2022 06:10:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=158
06/02/2022 06:10:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=159
06/02/2022 06:10:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/02/2022 06:10:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 06:11:00 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.7397865643526672 on epoch=160
06/02/2022 06:11:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=161
06/02/2022 06:11:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=162
06/02/2022 06:11:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=162
06/02/2022 06:11:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=163
06/02/2022 06:11:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=164
06/02/2022 06:11:10 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.7834171442093644 on epoch=164
06/02/2022 06:11:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/02/2022 06:11:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.11 on epoch=165
06/02/2022 06:11:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/02/2022 06:11:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/02/2022 06:11:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=167
06/02/2022 06:11:20 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7914357106092157 on epoch=167
06/02/2022 06:11:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
06/02/2022 06:11:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.11 on epoch=169
06/02/2022 06:11:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=169
06/02/2022 06:11:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
06/02/2022 06:11:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/02/2022 06:11:30 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.7323991288518868 on epoch=171
06/02/2022 06:11:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.12 on epoch=172
06/02/2022 06:11:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/02/2022 06:11:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=173
06/02/2022 06:11:35 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/02/2022 06:11:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
06/02/2022 06:11:40 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.717265378147204 on epoch=174
06/02/2022 06:11:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/02/2022 06:11:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=176
06/02/2022 06:11:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=177
06/02/2022 06:11:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/02/2022 06:11:46 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/02/2022 06:11:50 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.8960690182448563 on epoch=178
06/02/2022 06:11:51 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/02/2022 06:11:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
06/02/2022 06:11:54 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=180
06/02/2022 06:11:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/02/2022 06:11:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/02/2022 06:12:00 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.8092920078792352 on epoch=182
06/02/2022 06:12:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 06:12:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=183
06/02/2022 06:12:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/02/2022 06:12:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/02/2022 06:12:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=185
06/02/2022 06:12:10 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.8256808066474137 on epoch=185
06/02/2022 06:12:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=186
06/02/2022 06:12:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/02/2022 06:12:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/02/2022 06:12:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/02/2022 06:12:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/02/2022 06:12:20 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.955076128691946 on epoch=189
06/02/2022 06:12:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9039702528127573 -> 0.955076128691946 on epoch=189, global_step=2650
06/02/2022 06:12:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=189
06/02/2022 06:12:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/02/2022 06:12:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
06/02/2022 06:12:25 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=192
06/02/2022 06:12:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/02/2022 06:12:30 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.9015433980583166 on epoch=192
06/02/2022 06:12:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=193
06/02/2022 06:12:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=194
06/02/2022 06:12:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/02/2022 06:12:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/02/2022 06:12:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/02/2022 06:12:40 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.9646166237756099 on epoch=196
06/02/2022 06:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.955076128691946 -> 0.9646166237756099 on epoch=196, global_step=2750
06/02/2022 06:12:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/02/2022 06:12:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 06:12:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 06:12:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=199
06/02/2022 06:12:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/02/2022 06:12:50 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8822682326107373 on epoch=199
06/02/2022 06:12:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
06/02/2022 06:12:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 06:12:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 06:12:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=202
06/02/2022 06:12:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=203
06/02/2022 06:13:00 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.7985097752949901 on epoch=203
06/02/2022 06:13:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/02/2022 06:13:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=204
06/02/2022 06:13:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/02/2022 06:13:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/02/2022 06:13:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=207
06/02/2022 06:13:09 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.8150115373638855 on epoch=207
06/02/2022 06:13:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=207
06/02/2022 06:13:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/02/2022 06:13:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/02/2022 06:13:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
06/02/2022 06:13:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.13 on epoch=210
06/02/2022 06:13:19 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.8847496435194641 on epoch=210
06/02/2022 06:13:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
06/02/2022 06:13:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/02/2022 06:13:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/02/2022 06:13:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 06:13:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/02/2022 06:13:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:13:27 - INFO - __main__ - Printing 3 examples
06/02/2022 06:13:27 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 06:13:27 - INFO - __main__ - ['Animal']
06/02/2022 06:13:27 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 06:13:27 - INFO - __main__ - ['Animal']
06/02/2022 06:13:27 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 06:13:27 - INFO - __main__ - ['Animal']
06/02/2022 06:13:27 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:13:27 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:13:27 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:13:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:13:27 - INFO - __main__ - Printing 3 examples
06/02/2022 06:13:27 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 06:13:27 - INFO - __main__ - ['Animal']
06/02/2022 06:13:27 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 06:13:27 - INFO - __main__ - ['Animal']
06/02/2022 06:13:27 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 06:13:27 - INFO - __main__ - ['Animal']
06/02/2022 06:13:27 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:13:27 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:13:28 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:13:29 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.890380321238955 on epoch=214
06/02/2022 06:13:29 - INFO - __main__ - save last model!
06/02/2022 06:13:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 06:13:29 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 06:13:29 - INFO - __main__ - Printing 3 examples
06/02/2022 06:13:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 06:13:29 - INFO - __main__ - ['Animal']
06/02/2022 06:13:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 06:13:29 - INFO - __main__ - ['Animal']
06/02/2022 06:13:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 06:13:29 - INFO - __main__ - ['Village']
06/02/2022 06:13:29 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:13:31 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:13:33 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:13:33 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:13:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:13:34 - INFO - __main__ - Starting training!
06/02/2022 06:13:35 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 06:14:44 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/02/2022 06:14:44 - INFO - __main__ - Classification-F1 on test data: 0.5523
06/02/2022 06:14:44 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9646166237756099, test_performance=0.5523426552165959
06/02/2022 06:14:44 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/02/2022 06:14:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:14:45 - INFO - __main__ - Printing 3 examples
06/02/2022 06:14:45 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 06:14:45 - INFO - __main__ - ['Animal']
06/02/2022 06:14:45 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 06:14:45 - INFO - __main__ - ['Animal']
06/02/2022 06:14:45 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 06:14:45 - INFO - __main__ - ['Animal']
06/02/2022 06:14:45 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:14:45 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:14:45 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:14:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:14:45 - INFO - __main__ - Printing 3 examples
06/02/2022 06:14:45 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 06:14:45 - INFO - __main__ - ['Animal']
06/02/2022 06:14:45 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 06:14:45 - INFO - __main__ - ['Animal']
06/02/2022 06:14:45 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 06:14:45 - INFO - __main__ - ['Animal']
06/02/2022 06:14:45 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:14:45 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:14:45 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:14:51 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:14:51 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:14:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:14:51 - INFO - __main__ - Starting training!
06/02/2022 06:14:53 - INFO - __main__ - Step 10 Global step 10 Train loss 6.92 on epoch=0
06/02/2022 06:14:54 - INFO - __main__ - Step 20 Global step 20 Train loss 6.66 on epoch=1
06/02/2022 06:14:55 - INFO - __main__ - Step 30 Global step 30 Train loss 6.68 on epoch=2
06/02/2022 06:14:56 - INFO - __main__ - Step 40 Global step 40 Train loss 6.83 on epoch=2
06/02/2022 06:14:58 - INFO - __main__ - Step 50 Global step 50 Train loss 6.95 on epoch=3
06/02/2022 06:16:16 - INFO - __main__ - Global step 50 Train loss 6.81 Classification-F1 0.0 on epoch=3
06/02/2022 06:16:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 06:16:17 - INFO - __main__ - Step 60 Global step 60 Train loss 6.15 on epoch=4
06/02/2022 06:16:18 - INFO - __main__ - Step 70 Global step 70 Train loss 6.15 on epoch=4
06/02/2022 06:16:20 - INFO - __main__ - Step 80 Global step 80 Train loss 5.67 on epoch=5
06/02/2022 06:16:21 - INFO - __main__ - Step 90 Global step 90 Train loss 5.35 on epoch=6
06/02/2022 06:16:22 - INFO - __main__ - Step 100 Global step 100 Train loss 5.10 on epoch=7
06/02/2022 06:17:05 - INFO - __main__ - Global step 100 Train loss 5.68 Classification-F1 0.0 on epoch=7
06/02/2022 06:17:06 - INFO - __main__ - Step 110 Global step 110 Train loss 5.07 on epoch=7
06/02/2022 06:17:07 - INFO - __main__ - Step 120 Global step 120 Train loss 5.23 on epoch=8
06/02/2022 06:17:09 - INFO - __main__ - Step 130 Global step 130 Train loss 5.03 on epoch=9
06/02/2022 06:17:10 - INFO - __main__ - Step 140 Global step 140 Train loss 4.64 on epoch=9
06/02/2022 06:17:11 - INFO - __main__ - Step 150 Global step 150 Train loss 4.44 on epoch=10
06/02/2022 06:17:16 - INFO - __main__ - Global step 150 Train loss 4.88 Classification-F1 0.003676470588235294 on epoch=10
06/02/2022 06:17:16 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.003676470588235294 on epoch=10, global_step=150
06/02/2022 06:17:18 - INFO - __main__ - Step 160 Global step 160 Train loss 4.17 on epoch=11
06/02/2022 06:17:19 - INFO - __main__ - Step 170 Global step 170 Train loss 3.65 on epoch=12
06/02/2022 06:17:20 - INFO - __main__ - Step 180 Global step 180 Train loss 3.37 on epoch=12
06/02/2022 06:17:22 - INFO - __main__ - Step 190 Global step 190 Train loss 3.33 on epoch=13
06/02/2022 06:17:23 - INFO - __main__ - Step 200 Global step 200 Train loss 3.05 on epoch=14
06/02/2022 06:17:26 - INFO - __main__ - Global step 200 Train loss 3.51 Classification-F1 0.08824262760221015 on epoch=14
06/02/2022 06:17:26 - INFO - __main__ - Saving model with best Classification-F1: 0.003676470588235294 -> 0.08824262760221015 on epoch=14, global_step=200
06/02/2022 06:17:27 - INFO - __main__ - Step 210 Global step 210 Train loss 2.92 on epoch=14
06/02/2022 06:17:28 - INFO - __main__ - Step 220 Global step 220 Train loss 3.20 on epoch=15
06/02/2022 06:17:29 - INFO - __main__ - Step 230 Global step 230 Train loss 2.78 on epoch=16
06/02/2022 06:17:31 - INFO - __main__ - Step 240 Global step 240 Train loss 2.61 on epoch=17
06/02/2022 06:17:32 - INFO - __main__ - Step 250 Global step 250 Train loss 2.71 on epoch=17
06/02/2022 06:17:35 - INFO - __main__ - Global step 250 Train loss 2.84 Classification-F1 0.15468989243064196 on epoch=17
06/02/2022 06:17:36 - INFO - __main__ - Saving model with best Classification-F1: 0.08824262760221015 -> 0.15468989243064196 on epoch=17, global_step=250
06/02/2022 06:17:37 - INFO - __main__ - Step 260 Global step 260 Train loss 2.56 on epoch=18
06/02/2022 06:17:38 - INFO - __main__ - Step 270 Global step 270 Train loss 2.75 on epoch=19
06/02/2022 06:17:39 - INFO - __main__ - Step 280 Global step 280 Train loss 2.19 on epoch=19
06/02/2022 06:17:41 - INFO - __main__ - Step 290 Global step 290 Train loss 2.59 on epoch=20
06/02/2022 06:17:42 - INFO - __main__ - Step 300 Global step 300 Train loss 2.13 on epoch=21
06/02/2022 06:17:45 - INFO - __main__ - Global step 300 Train loss 2.44 Classification-F1 0.22680362667336218 on epoch=21
06/02/2022 06:17:45 - INFO - __main__ - Saving model with best Classification-F1: 0.15468989243064196 -> 0.22680362667336218 on epoch=21, global_step=300
06/02/2022 06:17:47 - INFO - __main__ - Step 310 Global step 310 Train loss 2.10 on epoch=22
06/02/2022 06:17:48 - INFO - __main__ - Step 320 Global step 320 Train loss 2.05 on epoch=22
06/02/2022 06:17:49 - INFO - __main__ - Step 330 Global step 330 Train loss 1.81 on epoch=23
06/02/2022 06:17:51 - INFO - __main__ - Step 340 Global step 340 Train loss 1.78 on epoch=24
06/02/2022 06:17:52 - INFO - __main__ - Step 350 Global step 350 Train loss 1.62 on epoch=24
06/02/2022 06:17:56 - INFO - __main__ - Global step 350 Train loss 1.87 Classification-F1 0.24408351601230477 on epoch=24
06/02/2022 06:17:56 - INFO - __main__ - Saving model with best Classification-F1: 0.22680362667336218 -> 0.24408351601230477 on epoch=24, global_step=350
06/02/2022 06:17:57 - INFO - __main__ - Step 360 Global step 360 Train loss 1.57 on epoch=25
06/02/2022 06:17:58 - INFO - __main__ - Step 370 Global step 370 Train loss 1.53 on epoch=26
06/02/2022 06:17:59 - INFO - __main__ - Step 380 Global step 380 Train loss 1.49 on epoch=27
06/02/2022 06:18:01 - INFO - __main__ - Step 390 Global step 390 Train loss 1.26 on epoch=27
06/02/2022 06:18:02 - INFO - __main__ - Step 400 Global step 400 Train loss 1.45 on epoch=28
06/02/2022 06:18:06 - INFO - __main__ - Global step 400 Train loss 1.46 Classification-F1 0.3237697837755792 on epoch=28
06/02/2022 06:18:06 - INFO - __main__ - Saving model with best Classification-F1: 0.24408351601230477 -> 0.3237697837755792 on epoch=28, global_step=400
06/02/2022 06:18:07 - INFO - __main__ - Step 410 Global step 410 Train loss 1.43 on epoch=29
06/02/2022 06:18:08 - INFO - __main__ - Step 420 Global step 420 Train loss 1.25 on epoch=29
06/02/2022 06:18:10 - INFO - __main__ - Step 430 Global step 430 Train loss 1.36 on epoch=30
06/02/2022 06:18:11 - INFO - __main__ - Step 440 Global step 440 Train loss 1.13 on epoch=31
06/02/2022 06:18:12 - INFO - __main__ - Step 450 Global step 450 Train loss 1.13 on epoch=32
06/02/2022 06:18:16 - INFO - __main__ - Global step 450 Train loss 1.26 Classification-F1 0.3328191913700778 on epoch=32
06/02/2022 06:18:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3237697837755792 -> 0.3328191913700778 on epoch=32, global_step=450
06/02/2022 06:18:17 - INFO - __main__ - Step 460 Global step 460 Train loss 1.06 on epoch=32
06/02/2022 06:18:18 - INFO - __main__ - Step 470 Global step 470 Train loss 1.19 on epoch=33
06/02/2022 06:18:20 - INFO - __main__ - Step 480 Global step 480 Train loss 1.01 on epoch=34
06/02/2022 06:18:21 - INFO - __main__ - Step 490 Global step 490 Train loss 1.06 on epoch=34
06/02/2022 06:18:22 - INFO - __main__ - Step 500 Global step 500 Train loss 1.10 on epoch=35
06/02/2022 06:18:25 - INFO - __main__ - Global step 500 Train loss 1.08 Classification-F1 0.3718673730149609 on epoch=35
06/02/2022 06:18:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3328191913700778 -> 0.3718673730149609 on epoch=35, global_step=500
06/02/2022 06:18:27 - INFO - __main__ - Step 510 Global step 510 Train loss 1.16 on epoch=36
06/02/2022 06:18:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.94 on epoch=37
06/02/2022 06:18:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.92 on epoch=37
06/02/2022 06:18:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.92 on epoch=38
06/02/2022 06:18:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.95 on epoch=39
06/02/2022 06:18:35 - INFO - __main__ - Global step 550 Train loss 0.98 Classification-F1 0.40833969843450696 on epoch=39
06/02/2022 06:18:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3718673730149609 -> 0.40833969843450696 on epoch=39, global_step=550
06/02/2022 06:18:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.92 on epoch=39
06/02/2022 06:18:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.83 on epoch=40
06/02/2022 06:18:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.85 on epoch=41
06/02/2022 06:18:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.85 on epoch=42
06/02/2022 06:18:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.94 on epoch=42
06/02/2022 06:18:45 - INFO - __main__ - Global step 600 Train loss 0.88 Classification-F1 0.5311793983949968 on epoch=42
06/02/2022 06:18:45 - INFO - __main__ - Saving model with best Classification-F1: 0.40833969843450696 -> 0.5311793983949968 on epoch=42, global_step=600
06/02/2022 06:18:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.83 on epoch=43
06/02/2022 06:18:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.74 on epoch=44
06/02/2022 06:18:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.86 on epoch=44
06/02/2022 06:18:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.60 on epoch=45
06/02/2022 06:18:51 - INFO - __main__ - Step 650 Global step 650 Train loss 0.71 on epoch=46
06/02/2022 06:18:55 - INFO - __main__ - Global step 650 Train loss 0.75 Classification-F1 0.6009914987500377 on epoch=46
06/02/2022 06:18:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5311793983949968 -> 0.6009914987500377 on epoch=46, global_step=650
06/02/2022 06:18:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.83 on epoch=47
06/02/2022 06:18:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.76 on epoch=47
06/02/2022 06:18:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.73 on epoch=48
06/02/2022 06:19:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.71 on epoch=49
06/02/2022 06:19:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.71 on epoch=49
06/02/2022 06:19:05 - INFO - __main__ - Global step 700 Train loss 0.75 Classification-F1 0.5016965393452746 on epoch=49
06/02/2022 06:19:06 - INFO - __main__ - Step 710 Global step 710 Train loss 1.15 on epoch=50
06/02/2022 06:19:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.94 on epoch=51
06/02/2022 06:19:09 - INFO - __main__ - Step 730 Global step 730 Train loss 1.13 on epoch=52
06/02/2022 06:19:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.78 on epoch=52
06/02/2022 06:19:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.71 on epoch=53
06/02/2022 06:19:14 - INFO - __main__ - Global step 750 Train loss 0.94 Classification-F1 0.5177945162065006 on epoch=53
06/02/2022 06:19:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.74 on epoch=54
06/02/2022 06:19:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.65 on epoch=54
06/02/2022 06:19:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.57 on epoch=55
06/02/2022 06:19:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.68 on epoch=56
06/02/2022 06:19:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.65 on epoch=57
06/02/2022 06:19:24 - INFO - __main__ - Global step 800 Train loss 0.66 Classification-F1 0.5759293852113501 on epoch=57
06/02/2022 06:19:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.63 on epoch=57
06/02/2022 06:19:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.63 on epoch=58
06/02/2022 06:19:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.58 on epoch=59
06/02/2022 06:19:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.64 on epoch=59
06/02/2022 06:19:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.58 on epoch=60
06/02/2022 06:19:34 - INFO - __main__ - Global step 850 Train loss 0.61 Classification-F1 0.5981396630116376 on epoch=60
06/02/2022 06:19:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.65 on epoch=61
06/02/2022 06:19:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.64 on epoch=62
06/02/2022 06:19:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.56 on epoch=62
06/02/2022 06:19:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.58 on epoch=63
06/02/2022 06:19:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.49 on epoch=64
06/02/2022 06:19:44 - INFO - __main__ - Global step 900 Train loss 0.59 Classification-F1 0.6240289185532291 on epoch=64
06/02/2022 06:19:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6009914987500377 -> 0.6240289185532291 on epoch=64, global_step=900
06/02/2022 06:19:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.60 on epoch=64
06/02/2022 06:19:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.69 on epoch=65
06/02/2022 06:19:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.54 on epoch=66
06/02/2022 06:19:49 - INFO - __main__ - Step 940 Global step 940 Train loss 0.58 on epoch=67
06/02/2022 06:19:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.51 on epoch=67
06/02/2022 06:19:54 - INFO - __main__ - Global step 950 Train loss 0.58 Classification-F1 0.6451852558100465 on epoch=67
06/02/2022 06:19:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6240289185532291 -> 0.6451852558100465 on epoch=67, global_step=950
06/02/2022 06:19:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.49 on epoch=68
06/02/2022 06:19:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.58 on epoch=69
06/02/2022 06:19:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.52 on epoch=69
06/02/2022 06:19:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.57 on epoch=70
06/02/2022 06:20:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.45 on epoch=71
06/02/2022 06:20:04 - INFO - __main__ - Global step 1000 Train loss 0.52 Classification-F1 0.6339148019107991 on epoch=71
06/02/2022 06:20:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.65 on epoch=72
06/02/2022 06:20:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.49 on epoch=72
06/02/2022 06:20:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.47 on epoch=73
06/02/2022 06:20:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.50 on epoch=74
06/02/2022 06:20:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.55 on epoch=74
06/02/2022 06:20:14 - INFO - __main__ - Global step 1050 Train loss 0.53 Classification-F1 0.5525847256024812 on epoch=74
06/02/2022 06:20:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.52 on epoch=75
06/02/2022 06:20:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.55 on epoch=76
06/02/2022 06:20:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.55 on epoch=77
06/02/2022 06:20:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.47 on epoch=77
06/02/2022 06:20:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.51 on epoch=78
06/02/2022 06:20:23 - INFO - __main__ - Global step 1100 Train loss 0.52 Classification-F1 0.5771197682919093 on epoch=78
06/02/2022 06:20:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.50 on epoch=79
06/02/2022 06:20:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.51 on epoch=79
06/02/2022 06:20:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.51 on epoch=80
06/02/2022 06:20:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.42 on epoch=81
06/02/2022 06:20:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.51 on epoch=82
06/02/2022 06:20:33 - INFO - __main__ - Global step 1150 Train loss 0.49 Classification-F1 0.6527692816355056 on epoch=82
06/02/2022 06:20:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6451852558100465 -> 0.6527692816355056 on epoch=82, global_step=1150
06/02/2022 06:20:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.45 on epoch=82
06/02/2022 06:20:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.46 on epoch=83
06/02/2022 06:20:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.51 on epoch=84
06/02/2022 06:20:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.50 on epoch=84
06/02/2022 06:20:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.52 on epoch=85
06/02/2022 06:20:43 - INFO - __main__ - Global step 1200 Train loss 0.49 Classification-F1 0.5844037202186607 on epoch=85
06/02/2022 06:20:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.48 on epoch=86
06/02/2022 06:20:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.49 on epoch=87
06/02/2022 06:20:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.52 on epoch=87
06/02/2022 06:20:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.54 on epoch=88
06/02/2022 06:20:49 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.45 on epoch=89
06/02/2022 06:20:53 - INFO - __main__ - Global step 1250 Train loss 0.50 Classification-F1 0.7319371914049615 on epoch=89
06/02/2022 06:20:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6527692816355056 -> 0.7319371914049615 on epoch=89, global_step=1250
06/02/2022 06:20:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.40 on epoch=89
06/02/2022 06:20:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.43 on epoch=90
06/02/2022 06:20:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.37 on epoch=91
06/02/2022 06:20:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.53 on epoch=92
06/02/2022 06:20:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.50 on epoch=92
06/02/2022 06:21:03 - INFO - __main__ - Global step 1300 Train loss 0.44 Classification-F1 0.6529797698291157 on epoch=92
06/02/2022 06:21:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.43 on epoch=93
06/02/2022 06:21:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.46 on epoch=94
06/02/2022 06:21:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.43 on epoch=94
06/02/2022 06:21:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.43 on epoch=95
06/02/2022 06:21:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.43 on epoch=96
06/02/2022 06:21:13 - INFO - __main__ - Global step 1350 Train loss 0.43 Classification-F1 0.7287378419013075 on epoch=96
06/02/2022 06:21:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.49 on epoch=97
06/02/2022 06:21:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.39 on epoch=97
06/02/2022 06:21:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.49 on epoch=98
06/02/2022 06:21:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.38 on epoch=99
06/02/2022 06:21:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.44 on epoch=99
06/02/2022 06:21:23 - INFO - __main__ - Global step 1400 Train loss 0.44 Classification-F1 0.6687631149294906 on epoch=99
06/02/2022 06:21:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.41 on epoch=100
06/02/2022 06:21:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.45 on epoch=101
06/02/2022 06:21:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.39 on epoch=102
06/02/2022 06:21:28 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.38 on epoch=102
06/02/2022 06:21:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.48 on epoch=103
06/02/2022 06:21:33 - INFO - __main__ - Global step 1450 Train loss 0.42 Classification-F1 0.6894626927522957 on epoch=103
06/02/2022 06:21:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.36 on epoch=104
06/02/2022 06:21:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.38 on epoch=104
06/02/2022 06:21:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.44 on epoch=105
06/02/2022 06:21:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.35 on epoch=106
06/02/2022 06:21:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.40 on epoch=107
06/02/2022 06:21:42 - INFO - __main__ - Global step 1500 Train loss 0.39 Classification-F1 0.6029710844608976 on epoch=107
06/02/2022 06:21:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.33 on epoch=107
06/02/2022 06:21:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.44 on epoch=108
06/02/2022 06:21:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.35 on epoch=109
06/02/2022 06:21:48 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.31 on epoch=109
06/02/2022 06:21:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.40 on epoch=110
06/02/2022 06:21:52 - INFO - __main__ - Global step 1550 Train loss 0.37 Classification-F1 0.6782383124887869 on epoch=110
06/02/2022 06:21:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.35 on epoch=111
06/02/2022 06:21:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.40 on epoch=112
06/02/2022 06:21:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.28 on epoch=112
06/02/2022 06:21:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.44 on epoch=113
06/02/2022 06:21:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.35 on epoch=114
06/02/2022 06:22:02 - INFO - __main__ - Global step 1600 Train loss 0.36 Classification-F1 0.6946580182915308 on epoch=114
06/02/2022 06:22:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.34 on epoch=114
06/02/2022 06:22:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.41 on epoch=115
06/02/2022 06:22:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.23 on epoch=116
06/02/2022 06:22:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.36 on epoch=117
06/02/2022 06:22:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.29 on epoch=117
06/02/2022 06:22:12 - INFO - __main__ - Global step 1650 Train loss 0.33 Classification-F1 0.6754401156744958 on epoch=117
06/02/2022 06:22:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.39 on epoch=118
06/02/2022 06:22:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.37 on epoch=119
06/02/2022 06:22:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.42 on epoch=119
06/02/2022 06:22:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.39 on epoch=120
06/02/2022 06:22:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.27 on epoch=121
06/02/2022 06:22:22 - INFO - __main__ - Global step 1700 Train loss 0.37 Classification-F1 0.662173994283624 on epoch=121
06/02/2022 06:22:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.36 on epoch=122
06/02/2022 06:22:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.27 on epoch=122
06/02/2022 06:22:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.26 on epoch=123
06/02/2022 06:22:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.36 on epoch=124
06/02/2022 06:22:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.36 on epoch=124
06/02/2022 06:22:32 - INFO - __main__ - Global step 1750 Train loss 0.32 Classification-F1 0.5515641757308117 on epoch=124
06/02/2022 06:22:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.34 on epoch=125
06/02/2022 06:22:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.29 on epoch=126
06/02/2022 06:22:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.27 on epoch=127
06/02/2022 06:22:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.23 on epoch=127
06/02/2022 06:22:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.31 on epoch=128
06/02/2022 06:22:42 - INFO - __main__ - Global step 1800 Train loss 0.29 Classification-F1 0.585582969561447 on epoch=128
06/02/2022 06:22:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.29 on epoch=129
06/02/2022 06:22:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.30 on epoch=129
06/02/2022 06:22:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.29 on epoch=130
06/02/2022 06:22:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.34 on epoch=131
06/02/2022 06:22:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.32 on epoch=132
06/02/2022 06:22:52 - INFO - __main__ - Global step 1850 Train loss 0.31 Classification-F1 0.698624931532335 on epoch=132
06/02/2022 06:22:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.38 on epoch=132
06/02/2022 06:22:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.28 on epoch=133
06/02/2022 06:22:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.32 on epoch=134
06/02/2022 06:22:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.29 on epoch=134
06/02/2022 06:22:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.28 on epoch=135
06/02/2022 06:23:02 - INFO - __main__ - Global step 1900 Train loss 0.31 Classification-F1 0.6182588022560603 on epoch=135
06/02/2022 06:23:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.26 on epoch=136
06/02/2022 06:23:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.36 on epoch=137
06/02/2022 06:23:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.30 on epoch=137
06/02/2022 06:23:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.38 on epoch=138
06/02/2022 06:23:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.27 on epoch=139
06/02/2022 06:23:12 - INFO - __main__ - Global step 1950 Train loss 0.31 Classification-F1 0.6555549495273687 on epoch=139
06/02/2022 06:23:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.19 on epoch=139
06/02/2022 06:23:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.27 on epoch=140
06/02/2022 06:23:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.22 on epoch=141
06/02/2022 06:23:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.35 on epoch=142
06/02/2022 06:23:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.24 on epoch=142
06/02/2022 06:23:22 - INFO - __main__ - Global step 2000 Train loss 0.25 Classification-F1 0.7412466763760863 on epoch=142
06/02/2022 06:23:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7319371914049615 -> 0.7412466763760863 on epoch=142, global_step=2000
06/02/2022 06:23:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.29 on epoch=143
06/02/2022 06:23:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.20 on epoch=144
06/02/2022 06:23:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.23 on epoch=144
06/02/2022 06:23:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.20 on epoch=145
06/02/2022 06:23:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.27 on epoch=146
06/02/2022 06:23:32 - INFO - __main__ - Global step 2050 Train loss 0.24 Classification-F1 0.7454556426708411 on epoch=146
06/02/2022 06:23:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7412466763760863 -> 0.7454556426708411 on epoch=146, global_step=2050
06/02/2022 06:23:34 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.26 on epoch=147
06/02/2022 06:23:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.16 on epoch=147
06/02/2022 06:23:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.19 on epoch=148
06/02/2022 06:23:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.23 on epoch=149
06/02/2022 06:23:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.28 on epoch=149
06/02/2022 06:23:42 - INFO - __main__ - Global step 2100 Train loss 0.22 Classification-F1 0.8012265362523309 on epoch=149
06/02/2022 06:23:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7454556426708411 -> 0.8012265362523309 on epoch=149, global_step=2100
06/02/2022 06:23:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.26 on epoch=150
06/02/2022 06:23:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.20 on epoch=151
06/02/2022 06:23:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.21 on epoch=152
06/02/2022 06:23:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.20 on epoch=152
06/02/2022 06:23:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.22 on epoch=153
06/02/2022 06:23:52 - INFO - __main__ - Global step 2150 Train loss 0.22 Classification-F1 0.7744701268536689 on epoch=153
06/02/2022 06:23:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.21 on epoch=154
06/02/2022 06:23:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.24 on epoch=154
06/02/2022 06:23:56 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.22 on epoch=155
06/02/2022 06:23:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.26 on epoch=156
06/02/2022 06:23:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.22 on epoch=157
06/02/2022 06:24:02 - INFO - __main__ - Global step 2200 Train loss 0.23 Classification-F1 0.6211409313088906 on epoch=157
06/02/2022 06:24:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.18 on epoch=157
06/02/2022 06:24:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.22 on epoch=158
06/02/2022 06:24:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.18 on epoch=159
06/02/2022 06:24:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.28 on epoch=159
06/02/2022 06:24:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.25 on epoch=160
06/02/2022 06:24:12 - INFO - __main__ - Global step 2250 Train loss 0.22 Classification-F1 0.7176623342024557 on epoch=160
06/02/2022 06:24:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=161
06/02/2022 06:24:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.26 on epoch=162
06/02/2022 06:24:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.18 on epoch=162
06/02/2022 06:24:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.24 on epoch=163
06/02/2022 06:24:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.22 on epoch=164
06/02/2022 06:24:21 - INFO - __main__ - Global step 2300 Train loss 0.21 Classification-F1 0.622857453155547 on epoch=164
06/02/2022 06:24:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.20 on epoch=164
06/02/2022 06:24:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.20 on epoch=165
06/02/2022 06:24:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.21 on epoch=166
06/02/2022 06:24:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.23 on epoch=167
06/02/2022 06:24:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.21 on epoch=167
06/02/2022 06:24:31 - INFO - __main__ - Global step 2350 Train loss 0.21 Classification-F1 0.791741021894075 on epoch=167
06/02/2022 06:24:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.22 on epoch=168
06/02/2022 06:24:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.13 on epoch=169
06/02/2022 06:24:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.19 on epoch=169
06/02/2022 06:24:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.22 on epoch=170
06/02/2022 06:24:38 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.21 on epoch=171
06/02/2022 06:24:41 - INFO - __main__ - Global step 2400 Train loss 0.20 Classification-F1 0.7465563694204334 on epoch=171
06/02/2022 06:24:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.24 on epoch=172
06/02/2022 06:24:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.17 on epoch=172
06/02/2022 06:24:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.17 on epoch=173
06/02/2022 06:24:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.20 on epoch=174
06/02/2022 06:24:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.23 on epoch=174
06/02/2022 06:24:51 - INFO - __main__ - Global step 2450 Train loss 0.20 Classification-F1 0.7711283169181651 on epoch=174
06/02/2022 06:24:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.17 on epoch=175
06/02/2022 06:24:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.17 on epoch=176
06/02/2022 06:24:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.16 on epoch=177
06/02/2022 06:24:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.18 on epoch=177
06/02/2022 06:24:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.20 on epoch=178
06/02/2022 06:25:01 - INFO - __main__ - Global step 2500 Train loss 0.18 Classification-F1 0.8134781122523724 on epoch=178
06/02/2022 06:25:01 - INFO - __main__ - Saving model with best Classification-F1: 0.8012265362523309 -> 0.8134781122523724 on epoch=178, global_step=2500
06/02/2022 06:25:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.14 on epoch=179
06/02/2022 06:25:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.21 on epoch=179
06/02/2022 06:25:05 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.15 on epoch=180
06/02/2022 06:25:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.16 on epoch=181
06/02/2022 06:25:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.12 on epoch=182
06/02/2022 06:25:11 - INFO - __main__ - Global step 2550 Train loss 0.16 Classification-F1 0.7871145467490261 on epoch=182
06/02/2022 06:25:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.13 on epoch=182
06/02/2022 06:25:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.18 on epoch=183
06/02/2022 06:25:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.16 on epoch=184
06/02/2022 06:25:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.20 on epoch=184
06/02/2022 06:25:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.17 on epoch=185
06/02/2022 06:25:21 - INFO - __main__ - Global step 2600 Train loss 0.17 Classification-F1 0.6847961366436282 on epoch=185
06/02/2022 06:25:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=186
06/02/2022 06:25:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.19 on epoch=187
06/02/2022 06:25:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.24 on epoch=187
06/02/2022 06:25:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.13 on epoch=188
06/02/2022 06:25:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=189
06/02/2022 06:25:31 - INFO - __main__ - Global step 2650 Train loss 0.16 Classification-F1 0.7494069882915946 on epoch=189
06/02/2022 06:25:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.16 on epoch=189
06/02/2022 06:25:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.18 on epoch=190
06/02/2022 06:25:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.12 on epoch=191
06/02/2022 06:25:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.18 on epoch=192
06/02/2022 06:25:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.13 on epoch=192
06/02/2022 06:25:41 - INFO - __main__ - Global step 2700 Train loss 0.16 Classification-F1 0.7069156639928699 on epoch=192
06/02/2022 06:25:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=193
06/02/2022 06:25:43 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.13 on epoch=194
06/02/2022 06:25:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.15 on epoch=194
06/02/2022 06:25:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.20 on epoch=195
06/02/2022 06:25:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.16 on epoch=196
06/02/2022 06:25:51 - INFO - __main__ - Global step 2750 Train loss 0.15 Classification-F1 0.7672707182462051 on epoch=196
06/02/2022 06:25:52 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.14 on epoch=197
06/02/2022 06:25:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.12 on epoch=197
06/02/2022 06:25:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.13 on epoch=198
06/02/2022 06:25:56 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.14 on epoch=199
06/02/2022 06:25:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.15 on epoch=199
06/02/2022 06:26:01 - INFO - __main__ - Global step 2800 Train loss 0.14 Classification-F1 0.7452775721485958 on epoch=199
06/02/2022 06:26:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.12 on epoch=200
06/02/2022 06:26:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=201
06/02/2022 06:26:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.17 on epoch=202
06/02/2022 06:26:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.12 on epoch=202
06/02/2022 06:26:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.12 on epoch=203
06/02/2022 06:26:11 - INFO - __main__ - Global step 2850 Train loss 0.13 Classification-F1 0.9462988125273368 on epoch=203
06/02/2022 06:26:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8134781122523724 -> 0.9462988125273368 on epoch=203, global_step=2850
06/02/2022 06:26:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.13 on epoch=204
06/02/2022 06:26:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.13 on epoch=204
06/02/2022 06:26:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.13 on epoch=205
06/02/2022 06:26:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.11 on epoch=206
06/02/2022 06:26:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.17 on epoch=207
06/02/2022 06:26:20 - INFO - __main__ - Global step 2900 Train loss 0.13 Classification-F1 0.8853137690172305 on epoch=207
06/02/2022 06:26:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.08 on epoch=207
06/02/2022 06:26:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.12 on epoch=208
06/02/2022 06:26:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=209
06/02/2022 06:26:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.12 on epoch=209
06/02/2022 06:26:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.12 on epoch=210
06/02/2022 06:26:30 - INFO - __main__ - Global step 2950 Train loss 0.11 Classification-F1 0.8516024414126881 on epoch=210
06/02/2022 06:26:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.14 on epoch=211
06/02/2022 06:26:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.27 on epoch=212
06/02/2022 06:26:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.11 on epoch=212
06/02/2022 06:26:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.09 on epoch=213
06/02/2022 06:26:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.12 on epoch=214
06/02/2022 06:26:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:26:38 - INFO - __main__ - Printing 3 examples
06/02/2022 06:26:38 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 06:26:38 - INFO - __main__ - ['Animal']
06/02/2022 06:26:38 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 06:26:38 - INFO - __main__ - ['Animal']
06/02/2022 06:26:38 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 06:26:38 - INFO - __main__ - ['Animal']
06/02/2022 06:26:38 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:26:38 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:26:38 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:26:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:26:38 - INFO - __main__ - Printing 3 examples
06/02/2022 06:26:38 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 06:26:38 - INFO - __main__ - ['Animal']
06/02/2022 06:26:38 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 06:26:38 - INFO - __main__ - ['Animal']
06/02/2022 06:26:38 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 06:26:38 - INFO - __main__ - ['Animal']
06/02/2022 06:26:38 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:26:38 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:26:39 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:26:40 - INFO - __main__ - Global step 3000 Train loss 0.14 Classification-F1 0.7477551913706109 on epoch=214
06/02/2022 06:26:40 - INFO - __main__ - save last model!
06/02/2022 06:26:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 06:26:40 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 06:26:40 - INFO - __main__ - Printing 3 examples
06/02/2022 06:26:40 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 06:26:40 - INFO - __main__ - ['Animal']
06/02/2022 06:26:40 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 06:26:40 - INFO - __main__ - ['Animal']
06/02/2022 06:26:40 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 06:26:40 - INFO - __main__ - ['Village']
06/02/2022 06:26:40 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:26:42 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:26:45 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:26:45 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:26:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:26:45 - INFO - __main__ - Starting training!
06/02/2022 06:26:46 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 06:27:56 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/02/2022 06:27:56 - INFO - __main__ - Classification-F1 on test data: 0.3959
06/02/2022 06:27:56 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9462988125273368, test_performance=0.3958817646322715
06/02/2022 06:27:56 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/02/2022 06:27:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:27:57 - INFO - __main__ - Printing 3 examples
06/02/2022 06:27:57 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/02/2022 06:27:57 - INFO - __main__ - ['Animal']
06/02/2022 06:27:57 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/02/2022 06:27:57 - INFO - __main__ - ['Animal']
06/02/2022 06:27:57 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/02/2022 06:27:57 - INFO - __main__ - ['Animal']
06/02/2022 06:27:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:27:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:27:57 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:27:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:27:57 - INFO - __main__ - Printing 3 examples
06/02/2022 06:27:57 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/02/2022 06:27:57 - INFO - __main__ - ['Animal']
06/02/2022 06:27:57 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/02/2022 06:27:57 - INFO - __main__ - ['Animal']
06/02/2022 06:27:57 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/02/2022 06:27:57 - INFO - __main__ - ['Animal']
06/02/2022 06:27:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:27:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:27:58 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:28:04 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:28:04 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:28:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:28:04 - INFO - __main__ - Starting training!
06/02/2022 06:28:06 - INFO - __main__ - Step 10 Global step 10 Train loss 6.66 on epoch=0
06/02/2022 06:28:07 - INFO - __main__ - Step 20 Global step 20 Train loss 5.82 on epoch=1
06/02/2022 06:28:08 - INFO - __main__ - Step 30 Global step 30 Train loss 5.22 on epoch=2
06/02/2022 06:28:09 - INFO - __main__ - Step 40 Global step 40 Train loss 4.91 on epoch=2
06/02/2022 06:28:11 - INFO - __main__ - Step 50 Global step 50 Train loss 4.65 on epoch=3
06/02/2022 06:28:55 - INFO - __main__ - Global step 50 Train loss 5.45 Classification-F1 0.0 on epoch=3
06/02/2022 06:28:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 06:28:56 - INFO - __main__ - Step 60 Global step 60 Train loss 4.72 on epoch=4
06/02/2022 06:28:57 - INFO - __main__ - Step 70 Global step 70 Train loss 4.13 on epoch=4
06/02/2022 06:28:59 - INFO - __main__ - Step 80 Global step 80 Train loss 3.91 on epoch=5
06/02/2022 06:29:00 - INFO - __main__ - Step 90 Global step 90 Train loss 3.66 on epoch=6
06/02/2022 06:29:01 - INFO - __main__ - Step 100 Global step 100 Train loss 3.22 on epoch=7
06/02/2022 06:29:05 - INFO - __main__ - Global step 100 Train loss 3.93 Classification-F1 0.07601845549634656 on epoch=7
06/02/2022 06:29:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.07601845549634656 on epoch=7, global_step=100
06/02/2022 06:29:07 - INFO - __main__ - Step 110 Global step 110 Train loss 3.24 on epoch=7
06/02/2022 06:29:08 - INFO - __main__ - Step 120 Global step 120 Train loss 3.12 on epoch=8
06/02/2022 06:29:09 - INFO - __main__ - Step 130 Global step 130 Train loss 3.03 on epoch=9
06/02/2022 06:29:10 - INFO - __main__ - Step 140 Global step 140 Train loss 2.81 on epoch=9
06/02/2022 06:29:12 - INFO - __main__ - Step 150 Global step 150 Train loss 2.85 on epoch=10
06/02/2022 06:29:16 - INFO - __main__ - Global step 150 Train loss 3.01 Classification-F1 0.14923458317700192 on epoch=10
06/02/2022 06:29:16 - INFO - __main__ - Saving model with best Classification-F1: 0.07601845549634656 -> 0.14923458317700192 on epoch=10, global_step=150
06/02/2022 06:29:17 - INFO - __main__ - Step 160 Global step 160 Train loss 2.62 on epoch=11
06/02/2022 06:29:18 - INFO - __main__ - Step 170 Global step 170 Train loss 2.41 on epoch=12
06/02/2022 06:29:19 - INFO - __main__ - Step 180 Global step 180 Train loss 2.54 on epoch=12
06/02/2022 06:29:21 - INFO - __main__ - Step 190 Global step 190 Train loss 2.26 on epoch=13
06/02/2022 06:29:22 - INFO - __main__ - Step 200 Global step 200 Train loss 2.20 on epoch=14
06/02/2022 06:29:26 - INFO - __main__ - Global step 200 Train loss 2.40 Classification-F1 0.24636837665823175 on epoch=14
06/02/2022 06:29:26 - INFO - __main__ - Saving model with best Classification-F1: 0.14923458317700192 -> 0.24636837665823175 on epoch=14, global_step=200
06/02/2022 06:29:28 - INFO - __main__ - Step 210 Global step 210 Train loss 2.21 on epoch=14
06/02/2022 06:29:29 - INFO - __main__ - Step 220 Global step 220 Train loss 1.98 on epoch=15
06/02/2022 06:29:30 - INFO - __main__ - Step 230 Global step 230 Train loss 2.12 on epoch=16
06/02/2022 06:29:31 - INFO - __main__ - Step 240 Global step 240 Train loss 2.12 on epoch=17
06/02/2022 06:29:33 - INFO - __main__ - Step 250 Global step 250 Train loss 1.81 on epoch=17
06/02/2022 06:29:36 - INFO - __main__ - Global step 250 Train loss 2.05 Classification-F1 0.27068896507904294 on epoch=17
06/02/2022 06:29:36 - INFO - __main__ - Saving model with best Classification-F1: 0.24636837665823175 -> 0.27068896507904294 on epoch=17, global_step=250
06/02/2022 06:29:38 - INFO - __main__ - Step 260 Global step 260 Train loss 1.80 on epoch=18
06/02/2022 06:29:39 - INFO - __main__ - Step 270 Global step 270 Train loss 1.79 on epoch=19
06/02/2022 06:29:40 - INFO - __main__ - Step 280 Global step 280 Train loss 1.67 on epoch=19
06/02/2022 06:29:41 - INFO - __main__ - Step 290 Global step 290 Train loss 1.67 on epoch=20
06/02/2022 06:29:43 - INFO - __main__ - Step 300 Global step 300 Train loss 1.75 on epoch=21
06/02/2022 06:29:46 - INFO - __main__ - Global step 300 Train loss 1.73 Classification-F1 0.28614172973792346 on epoch=21
06/02/2022 06:29:46 - INFO - __main__ - Saving model with best Classification-F1: 0.27068896507904294 -> 0.28614172973792346 on epoch=21, global_step=300
06/02/2022 06:29:48 - INFO - __main__ - Step 310 Global step 310 Train loss 1.88 on epoch=22
06/02/2022 06:29:49 - INFO - __main__ - Step 320 Global step 320 Train loss 1.69 on epoch=22
06/02/2022 06:29:50 - INFO - __main__ - Step 330 Global step 330 Train loss 1.58 on epoch=23
06/02/2022 06:29:51 - INFO - __main__ - Step 340 Global step 340 Train loss 1.63 on epoch=24
06/02/2022 06:29:53 - INFO - __main__ - Step 350 Global step 350 Train loss 1.61 on epoch=24
06/02/2022 06:29:56 - INFO - __main__ - Global step 350 Train loss 1.68 Classification-F1 0.39548278601481895 on epoch=24
06/02/2022 06:29:56 - INFO - __main__ - Saving model with best Classification-F1: 0.28614172973792346 -> 0.39548278601481895 on epoch=24, global_step=350
06/02/2022 06:29:58 - INFO - __main__ - Step 360 Global step 360 Train loss 1.50 on epoch=25
06/02/2022 06:29:59 - INFO - __main__ - Step 370 Global step 370 Train loss 1.50 on epoch=26
06/02/2022 06:30:00 - INFO - __main__ - Step 380 Global step 380 Train loss 1.44 on epoch=27
06/02/2022 06:30:01 - INFO - __main__ - Step 390 Global step 390 Train loss 1.41 on epoch=27
06/02/2022 06:30:03 - INFO - __main__ - Step 400 Global step 400 Train loss 1.34 on epoch=28
06/02/2022 06:30:06 - INFO - __main__ - Global step 400 Train loss 1.44 Classification-F1 0.3850169291253482 on epoch=28
06/02/2022 06:30:07 - INFO - __main__ - Step 410 Global step 410 Train loss 1.16 on epoch=29
06/02/2022 06:30:08 - INFO - __main__ - Step 420 Global step 420 Train loss 1.25 on epoch=29
06/02/2022 06:30:10 - INFO - __main__ - Step 430 Global step 430 Train loss 1.20 on epoch=30
06/02/2022 06:30:11 - INFO - __main__ - Step 440 Global step 440 Train loss 1.04 on epoch=31
06/02/2022 06:30:12 - INFO - __main__ - Step 450 Global step 450 Train loss 1.11 on epoch=32
06/02/2022 06:30:16 - INFO - __main__ - Global step 450 Train loss 1.15 Classification-F1 0.3716235596754509 on epoch=32
06/02/2022 06:30:17 - INFO - __main__ - Step 460 Global step 460 Train loss 1.22 on epoch=32
06/02/2022 06:30:19 - INFO - __main__ - Step 470 Global step 470 Train loss 1.02 on epoch=33
06/02/2022 06:30:20 - INFO - __main__ - Step 480 Global step 480 Train loss 1.01 on epoch=34
06/02/2022 06:30:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.98 on epoch=34
06/02/2022 06:30:22 - INFO - __main__ - Step 500 Global step 500 Train loss 1.27 on epoch=35
06/02/2022 06:30:26 - INFO - __main__ - Global step 500 Train loss 1.10 Classification-F1 0.5059088103047761 on epoch=35
06/02/2022 06:30:26 - INFO - __main__ - Saving model with best Classification-F1: 0.39548278601481895 -> 0.5059088103047761 on epoch=35, global_step=500
06/02/2022 06:30:28 - INFO - __main__ - Step 510 Global step 510 Train loss 1.05 on epoch=36
06/02/2022 06:30:29 - INFO - __main__ - Step 520 Global step 520 Train loss 1.03 on epoch=37
06/02/2022 06:30:30 - INFO - __main__ - Step 530 Global step 530 Train loss 1.12 on epoch=37
06/02/2022 06:30:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.96 on epoch=38
06/02/2022 06:30:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.90 on epoch=39
06/02/2022 06:30:37 - INFO - __main__ - Global step 550 Train loss 1.01 Classification-F1 0.48096318874684957 on epoch=39
06/02/2022 06:30:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.87 on epoch=39
06/02/2022 06:30:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.91 on epoch=40
06/02/2022 06:30:40 - INFO - __main__ - Step 580 Global step 580 Train loss 1.03 on epoch=41
06/02/2022 06:30:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.87 on epoch=42
06/02/2022 06:30:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.94 on epoch=42
06/02/2022 06:30:47 - INFO - __main__ - Global step 600 Train loss 0.93 Classification-F1 0.5392909159532956 on epoch=42
06/02/2022 06:30:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5059088103047761 -> 0.5392909159532956 on epoch=42, global_step=600
06/02/2022 06:30:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.85 on epoch=43
06/02/2022 06:30:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.86 on epoch=44
06/02/2022 06:30:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.85 on epoch=44
06/02/2022 06:30:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.80 on epoch=45
06/02/2022 06:30:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.74 on epoch=46
06/02/2022 06:30:57 - INFO - __main__ - Global step 650 Train loss 0.82 Classification-F1 0.521453488485035 on epoch=46
06/02/2022 06:30:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.87 on epoch=47
06/02/2022 06:30:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.71 on epoch=47
06/02/2022 06:31:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.78 on epoch=48
06/02/2022 06:31:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.73 on epoch=49
06/02/2022 06:31:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.84 on epoch=49
06/02/2022 06:31:06 - INFO - __main__ - Global step 700 Train loss 0.79 Classification-F1 0.5910748721667444 on epoch=49
06/02/2022 06:31:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5392909159532956 -> 0.5910748721667444 on epoch=49, global_step=700
06/02/2022 06:31:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.71 on epoch=50
06/02/2022 06:31:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.85 on epoch=51
06/02/2022 06:31:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.71 on epoch=52
06/02/2022 06:31:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.84 on epoch=52
06/02/2022 06:31:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.67 on epoch=53
06/02/2022 06:31:17 - INFO - __main__ - Global step 750 Train loss 0.76 Classification-F1 0.638447568738425 on epoch=53
06/02/2022 06:31:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5910748721667444 -> 0.638447568738425 on epoch=53, global_step=750
06/02/2022 06:31:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.72 on epoch=54
06/02/2022 06:31:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.63 on epoch=54
06/02/2022 06:31:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.69 on epoch=55
06/02/2022 06:31:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.73 on epoch=56
06/02/2022 06:31:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.60 on epoch=57
06/02/2022 06:31:27 - INFO - __main__ - Global step 800 Train loss 0.68 Classification-F1 0.4577893285904139 on epoch=57
06/02/2022 06:31:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.72 on epoch=57
06/02/2022 06:31:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.61 on epoch=58
06/02/2022 06:31:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.62 on epoch=59
06/02/2022 06:31:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.68 on epoch=59
06/02/2022 06:31:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.72 on epoch=60
06/02/2022 06:31:37 - INFO - __main__ - Global step 850 Train loss 0.67 Classification-F1 0.6281310801206995 on epoch=60
06/02/2022 06:31:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.63 on epoch=61
06/02/2022 06:31:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.70 on epoch=62
06/02/2022 06:31:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.71 on epoch=62
06/02/2022 06:31:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.53 on epoch=63
06/02/2022 06:31:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.57 on epoch=64
06/02/2022 06:31:47 - INFO - __main__ - Global step 900 Train loss 0.63 Classification-F1 0.6457229142629907 on epoch=64
06/02/2022 06:31:47 - INFO - __main__ - Saving model with best Classification-F1: 0.638447568738425 -> 0.6457229142629907 on epoch=64, global_step=900
06/02/2022 06:31:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.60 on epoch=64
06/02/2022 06:31:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.58 on epoch=65
06/02/2022 06:31:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.54 on epoch=66
06/02/2022 06:31:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.68 on epoch=67
06/02/2022 06:31:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.82 on epoch=67
06/02/2022 06:31:56 - INFO - __main__ - Global step 950 Train loss 0.64 Classification-F1 0.46316373286160556 on epoch=67
06/02/2022 06:31:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.69 on epoch=68
06/02/2022 06:31:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.68 on epoch=69
06/02/2022 06:32:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.59 on epoch=69
06/02/2022 06:32:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.70 on epoch=70
06/02/2022 06:32:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.62 on epoch=71
06/02/2022 06:32:06 - INFO - __main__ - Global step 1000 Train loss 0.66 Classification-F1 0.6067799368602961 on epoch=71
06/02/2022 06:32:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.65 on epoch=72
06/02/2022 06:32:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.50 on epoch=72
06/02/2022 06:32:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.48 on epoch=73
06/02/2022 06:32:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.63 on epoch=74
06/02/2022 06:32:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.49 on epoch=74
06/02/2022 06:32:15 - INFO - __main__ - Global step 1050 Train loss 0.55 Classification-F1 0.5185331932253116 on epoch=74
06/02/2022 06:32:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.56 on epoch=75
06/02/2022 06:32:18 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.55 on epoch=76
06/02/2022 06:32:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.61 on epoch=77
06/02/2022 06:32:20 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.50 on epoch=77
06/02/2022 06:32:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.58 on epoch=78
06/02/2022 06:32:25 - INFO - __main__ - Global step 1100 Train loss 0.56 Classification-F1 0.5520691152136205 on epoch=78
06/02/2022 06:32:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.55 on epoch=79
06/02/2022 06:32:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.54 on epoch=79
06/02/2022 06:32:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.49 on epoch=80
06/02/2022 06:32:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.47 on epoch=81
06/02/2022 06:32:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.43 on epoch=82
06/02/2022 06:32:35 - INFO - __main__ - Global step 1150 Train loss 0.50 Classification-F1 0.5493965306148076 on epoch=82
06/02/2022 06:32:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.43 on epoch=82
06/02/2022 06:32:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.45 on epoch=83
06/02/2022 06:32:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.44 on epoch=84
06/02/2022 06:32:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.42 on epoch=84
06/02/2022 06:32:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.40 on epoch=85
06/02/2022 06:32:45 - INFO - __main__ - Global step 1200 Train loss 0.43 Classification-F1 0.7043070881903494 on epoch=85
06/02/2022 06:32:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6457229142629907 -> 0.7043070881903494 on epoch=85, global_step=1200
06/02/2022 06:32:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.42 on epoch=86
06/02/2022 06:32:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.39 on epoch=87
06/02/2022 06:32:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.40 on epoch=87
06/02/2022 06:32:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.44 on epoch=88
06/02/2022 06:32:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.51 on epoch=89
06/02/2022 06:32:55 - INFO - __main__ - Global step 1250 Train loss 0.43 Classification-F1 0.5993011794997277 on epoch=89
06/02/2022 06:32:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.43 on epoch=89
06/02/2022 06:32:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.36 on epoch=90
06/02/2022 06:32:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.40 on epoch=91
06/02/2022 06:33:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.42 on epoch=92
06/02/2022 06:33:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.38 on epoch=92
06/02/2022 06:33:04 - INFO - __main__ - Global step 1300 Train loss 0.40 Classification-F1 0.6559468131979256 on epoch=92
06/02/2022 06:33:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.42 on epoch=93
06/02/2022 06:33:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.38 on epoch=94
06/02/2022 06:33:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.49 on epoch=94
06/02/2022 06:33:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.54 on epoch=95
06/02/2022 06:33:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.41 on epoch=96
06/02/2022 06:33:14 - INFO - __main__ - Global step 1350 Train loss 0.45 Classification-F1 0.6239035704700079 on epoch=96
06/02/2022 06:33:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.39 on epoch=97
06/02/2022 06:33:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.40 on epoch=97
06/02/2022 06:33:18 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.29 on epoch=98
06/02/2022 06:33:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.52 on epoch=99
06/02/2022 06:33:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.34 on epoch=99
06/02/2022 06:33:24 - INFO - __main__ - Global step 1400 Train loss 0.39 Classification-F1 0.46999382977848664 on epoch=99
06/02/2022 06:33:25 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.34 on epoch=100
06/02/2022 06:33:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.38 on epoch=101
06/02/2022 06:33:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.47 on epoch=102
06/02/2022 06:33:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.36 on epoch=102
06/02/2022 06:33:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.40 on epoch=103
06/02/2022 06:33:34 - INFO - __main__ - Global step 1450 Train loss 0.39 Classification-F1 0.5873856586961426 on epoch=103
06/02/2022 06:33:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.36 on epoch=104
06/02/2022 06:33:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.32 on epoch=104
06/02/2022 06:33:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.37 on epoch=105
06/02/2022 06:33:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.37 on epoch=106
06/02/2022 06:33:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.39 on epoch=107
06/02/2022 06:33:44 - INFO - __main__ - Global step 1500 Train loss 0.36 Classification-F1 0.653722619115769 on epoch=107
06/02/2022 06:33:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.33 on epoch=107
06/02/2022 06:33:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.34 on epoch=108
06/02/2022 06:33:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.30 on epoch=109
06/02/2022 06:33:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.33 on epoch=109
06/02/2022 06:33:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.26 on epoch=110
06/02/2022 06:33:54 - INFO - __main__ - Global step 1550 Train loss 0.31 Classification-F1 0.5656557776444273 on epoch=110
06/02/2022 06:33:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.31 on epoch=111
06/02/2022 06:33:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.37 on epoch=112
06/02/2022 06:33:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.31 on epoch=112
06/02/2022 06:33:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.28 on epoch=113
06/02/2022 06:34:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.35 on epoch=114
06/02/2022 06:34:03 - INFO - __main__ - Global step 1600 Train loss 0.32 Classification-F1 0.6976342361736393 on epoch=114
06/02/2022 06:34:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.30 on epoch=114
06/02/2022 06:34:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.39 on epoch=115
06/02/2022 06:34:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.29 on epoch=116
06/02/2022 06:34:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.34 on epoch=117
06/02/2022 06:34:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.28 on epoch=117
06/02/2022 06:34:13 - INFO - __main__ - Global step 1650 Train loss 0.32 Classification-F1 0.6868694860559312 on epoch=117
06/02/2022 06:34:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.27 on epoch=118
06/02/2022 06:34:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.26 on epoch=119
06/02/2022 06:34:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.20 on epoch=119
06/02/2022 06:34:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.27 on epoch=120
06/02/2022 06:34:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.29 on epoch=121
06/02/2022 06:34:23 - INFO - __main__ - Global step 1700 Train loss 0.26 Classification-F1 0.7507551456555253 on epoch=121
06/02/2022 06:34:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7043070881903494 -> 0.7507551456555253 on epoch=121, global_step=1700
06/02/2022 06:34:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.29 on epoch=122
06/02/2022 06:34:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.29 on epoch=122
06/02/2022 06:34:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.30 on epoch=123
06/02/2022 06:34:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.29 on epoch=124
06/02/2022 06:34:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.23 on epoch=124
06/02/2022 06:34:32 - INFO - __main__ - Global step 1750 Train loss 0.28 Classification-F1 0.7556069421906755 on epoch=124
06/02/2022 06:34:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7507551456555253 -> 0.7556069421906755 on epoch=124, global_step=1750
06/02/2022 06:34:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.26 on epoch=125
06/02/2022 06:34:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.25 on epoch=126
06/02/2022 06:34:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.22 on epoch=127
06/02/2022 06:34:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.25 on epoch=127
06/02/2022 06:34:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.26 on epoch=128
06/02/2022 06:34:42 - INFO - __main__ - Global step 1800 Train loss 0.25 Classification-F1 0.6314867728230357 on epoch=128
06/02/2022 06:34:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.27 on epoch=129
06/02/2022 06:34:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.24 on epoch=129
06/02/2022 06:34:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.21 on epoch=130
06/02/2022 06:34:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.28 on epoch=131
06/02/2022 06:34:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.29 on epoch=132
06/02/2022 06:34:52 - INFO - __main__ - Global step 1850 Train loss 0.26 Classification-F1 0.6791342269628267 on epoch=132
06/02/2022 06:34:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.31 on epoch=132
06/02/2022 06:34:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.32 on epoch=133
06/02/2022 06:34:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.24 on epoch=134
06/02/2022 06:34:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.23 on epoch=134
06/02/2022 06:34:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.28 on epoch=135
06/02/2022 06:35:02 - INFO - __main__ - Global step 1900 Train loss 0.28 Classification-F1 0.6873805876748856 on epoch=135
06/02/2022 06:35:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.23 on epoch=136
06/02/2022 06:35:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.23 on epoch=137
06/02/2022 06:35:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.21 on epoch=137
06/02/2022 06:35:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.24 on epoch=138
06/02/2022 06:35:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.22 on epoch=139
06/02/2022 06:35:12 - INFO - __main__ - Global step 1950 Train loss 0.23 Classification-F1 0.8039584034982517 on epoch=139
06/02/2022 06:35:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7556069421906755 -> 0.8039584034982517 on epoch=139, global_step=1950
06/02/2022 06:35:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.21 on epoch=139
06/02/2022 06:35:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.27 on epoch=140
06/02/2022 06:35:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.30 on epoch=141
06/02/2022 06:35:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.27 on epoch=142
06/02/2022 06:35:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.23 on epoch=142
06/02/2022 06:35:22 - INFO - __main__ - Global step 2000 Train loss 0.25 Classification-F1 0.6915238790919371 on epoch=142
06/02/2022 06:35:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.23 on epoch=143
06/02/2022 06:35:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.21 on epoch=144
06/02/2022 06:35:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=144
06/02/2022 06:35:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.24 on epoch=145
06/02/2022 06:35:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.19 on epoch=146
06/02/2022 06:35:32 - INFO - __main__ - Global step 2050 Train loss 0.20 Classification-F1 0.6411720171300819 on epoch=146
06/02/2022 06:35:33 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.25 on epoch=147
06/02/2022 06:35:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.22 on epoch=147
06/02/2022 06:35:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.29 on epoch=148
06/02/2022 06:35:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.16 on epoch=149
06/02/2022 06:35:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.14 on epoch=149
06/02/2022 06:35:42 - INFO - __main__ - Global step 2100 Train loss 0.21 Classification-F1 0.6694695521095769 on epoch=149
06/02/2022 06:35:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.14 on epoch=150
06/02/2022 06:35:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.20 on epoch=151
06/02/2022 06:35:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.18 on epoch=152
06/02/2022 06:35:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.16 on epoch=152
06/02/2022 06:35:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.14 on epoch=153
06/02/2022 06:35:51 - INFO - __main__ - Global step 2150 Train loss 0.16 Classification-F1 0.5566442361526847 on epoch=153
06/02/2022 06:35:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.23 on epoch=154
06/02/2022 06:35:54 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.18 on epoch=154
06/02/2022 06:35:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.19 on epoch=155
06/02/2022 06:35:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.16 on epoch=156
06/02/2022 06:35:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=157
06/02/2022 06:36:01 - INFO - __main__ - Global step 2200 Train loss 0.17 Classification-F1 0.490721310733814 on epoch=157
06/02/2022 06:36:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=157
06/02/2022 06:36:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.15 on epoch=158
06/02/2022 06:36:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.21 on epoch=159
06/02/2022 06:36:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.17 on epoch=159
06/02/2022 06:36:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.12 on epoch=160
06/02/2022 06:36:12 - INFO - __main__ - Global step 2250 Train loss 0.15 Classification-F1 0.5704959878309696 on epoch=160
06/02/2022 06:36:13 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.20 on epoch=161
06/02/2022 06:36:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.19 on epoch=162
06/02/2022 06:36:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.15 on epoch=162
06/02/2022 06:36:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.15 on epoch=163
06/02/2022 06:36:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.13 on epoch=164
06/02/2022 06:36:21 - INFO - __main__ - Global step 2300 Train loss 0.17 Classification-F1 0.5868479363101281 on epoch=164
06/02/2022 06:36:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.19 on epoch=164
06/02/2022 06:36:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=165
06/02/2022 06:36:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.15 on epoch=166
06/02/2022 06:36:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.17 on epoch=167
06/02/2022 06:36:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.14 on epoch=167
06/02/2022 06:36:31 - INFO - __main__ - Global step 2350 Train loss 0.16 Classification-F1 0.5347519444579775 on epoch=167
06/02/2022 06:36:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
06/02/2022 06:36:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.12 on epoch=169
06/02/2022 06:36:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.13 on epoch=169
06/02/2022 06:36:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.16 on epoch=170
06/02/2022 06:36:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/02/2022 06:36:41 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.6238629190504683 on epoch=171
06/02/2022 06:36:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.12 on epoch=172
06/02/2022 06:36:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.18 on epoch=172
06/02/2022 06:36:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=173
06/02/2022 06:36:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.15 on epoch=174
06/02/2022 06:36:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.17 on epoch=174
06/02/2022 06:36:51 - INFO - __main__ - Global step 2450 Train loss 0.15 Classification-F1 0.650506228993506 on epoch=174
06/02/2022 06:36:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=175
06/02/2022 06:36:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.14 on epoch=176
06/02/2022 06:36:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.14 on epoch=177
06/02/2022 06:36:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.11 on epoch=177
06/02/2022 06:36:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.13 on epoch=178
06/02/2022 06:37:01 - INFO - __main__ - Global step 2500 Train loss 0.12 Classification-F1 0.7387926055857745 on epoch=178
06/02/2022 06:37:02 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.10 on epoch=179
06/02/2022 06:37:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.12 on epoch=179
06/02/2022 06:37:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.15 on epoch=180
06/02/2022 06:37:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.12 on epoch=181
06/02/2022 06:37:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.18 on epoch=182
06/02/2022 06:37:10 - INFO - __main__ - Global step 2550 Train loss 0.14 Classification-F1 0.5881034280191239 on epoch=182
06/02/2022 06:37:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=182
06/02/2022 06:37:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.18 on epoch=183
06/02/2022 06:37:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.14 on epoch=184
06/02/2022 06:37:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=184
06/02/2022 06:37:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.21 on epoch=185
06/02/2022 06:37:20 - INFO - __main__ - Global step 2600 Train loss 0.15 Classification-F1 0.6695883825453718 on epoch=185
06/02/2022 06:37:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.13 on epoch=186
06/02/2022 06:37:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=187
06/02/2022 06:37:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=187
06/02/2022 06:37:25 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=188
06/02/2022 06:37:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.12 on epoch=189
06/02/2022 06:37:30 - INFO - __main__ - Global step 2650 Train loss 0.11 Classification-F1 0.7413062273579629 on epoch=189
06/02/2022 06:37:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.15 on epoch=189
06/02/2022 06:37:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.13 on epoch=190
06/02/2022 06:37:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.14 on epoch=191
06/02/2022 06:37:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.16 on epoch=192
06/02/2022 06:37:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/02/2022 06:37:40 - INFO - __main__ - Global step 2700 Train loss 0.13 Classification-F1 0.6450162280900139 on epoch=192
06/02/2022 06:37:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.14 on epoch=193
06/02/2022 06:37:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/02/2022 06:37:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/02/2022 06:37:45 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=195
06/02/2022 06:37:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.12 on epoch=196
06/02/2022 06:37:50 - INFO - __main__ - Global step 2750 Train loss 0.10 Classification-F1 0.6402598396996413 on epoch=196
06/02/2022 06:37:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.12 on epoch=197
06/02/2022 06:37:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=197
06/02/2022 06:37:54 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=198
06/02/2022 06:37:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.12 on epoch=199
06/02/2022 06:37:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=199
06/02/2022 06:38:00 - INFO - __main__ - Global step 2800 Train loss 0.10 Classification-F1 0.577166208606003 on epoch=199
06/02/2022 06:38:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.10 on epoch=200
06/02/2022 06:38:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=201
06/02/2022 06:38:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=202
06/02/2022 06:38:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=202
06/02/2022 06:38:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=203
06/02/2022 06:38:09 - INFO - __main__ - Global step 2850 Train loss 0.09 Classification-F1 0.5826474469810597 on epoch=203
06/02/2022 06:38:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.14 on epoch=204
06/02/2022 06:38:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=204
06/02/2022 06:38:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.10 on epoch=205
06/02/2022 06:38:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.13 on epoch=206
06/02/2022 06:38:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.13 on epoch=207
06/02/2022 06:38:19 - INFO - __main__ - Global step 2900 Train loss 0.11 Classification-F1 0.8195511988606746 on epoch=207
06/02/2022 06:38:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8039584034982517 -> 0.8195511988606746 on epoch=207, global_step=2900
06/02/2022 06:38:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.10 on epoch=207
06/02/2022 06:38:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.09 on epoch=208
06/02/2022 06:38:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=209
06/02/2022 06:38:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.11 on epoch=209
06/02/2022 06:38:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=210
06/02/2022 06:38:29 - INFO - __main__ - Global step 2950 Train loss 0.09 Classification-F1 0.6497251155889409 on epoch=210
06/02/2022 06:38:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.18 on epoch=211
06/02/2022 06:38:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.10 on epoch=212
06/02/2022 06:38:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.09 on epoch=212
06/02/2022 06:38:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.10 on epoch=213
06/02/2022 06:38:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=214
06/02/2022 06:38:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:38:37 - INFO - __main__ - Printing 3 examples
06/02/2022 06:38:37 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 06:38:37 - INFO - __main__ - ['Animal']
06/02/2022 06:38:37 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 06:38:37 - INFO - __main__ - ['Animal']
06/02/2022 06:38:37 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 06:38:37 - INFO - __main__ - ['Animal']
06/02/2022 06:38:37 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:38:37 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:38:37 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:38:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:38:37 - INFO - __main__ - Printing 3 examples
06/02/2022 06:38:37 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 06:38:37 - INFO - __main__ - ['Animal']
06/02/2022 06:38:37 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 06:38:37 - INFO - __main__ - ['Animal']
06/02/2022 06:38:37 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 06:38:37 - INFO - __main__ - ['Animal']
06/02/2022 06:38:37 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:38:37 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:38:37 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:38:39 - INFO - __main__ - Global step 3000 Train loss 0.11 Classification-F1 0.6024667895018723 on epoch=214
06/02/2022 06:38:39 - INFO - __main__ - save last model!
06/02/2022 06:38:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 06:38:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 06:38:39 - INFO - __main__ - Printing 3 examples
06/02/2022 06:38:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 06:38:39 - INFO - __main__ - ['Animal']
06/02/2022 06:38:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 06:38:39 - INFO - __main__ - ['Animal']
06/02/2022 06:38:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 06:38:39 - INFO - __main__ - ['Village']
06/02/2022 06:38:39 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:38:41 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:38:43 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:38:43 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:38:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:38:43 - INFO - __main__ - Starting training!
06/02/2022 06:38:45 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 06:39:51 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/02/2022 06:39:51 - INFO - __main__ - Classification-F1 on test data: 0.3927
06/02/2022 06:39:51 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.8195511988606746, test_performance=0.3927361291941113
06/02/2022 06:39:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/02/2022 06:39:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:39:52 - INFO - __main__ - Printing 3 examples
06/02/2022 06:39:52 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 06:39:52 - INFO - __main__ - ['Animal']
06/02/2022 06:39:52 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 06:39:52 - INFO - __main__ - ['Animal']
06/02/2022 06:39:52 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 06:39:52 - INFO - __main__ - ['Animal']
06/02/2022 06:39:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:39:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:39:53 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:39:53 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:39:53 - INFO - __main__ - Printing 3 examples
06/02/2022 06:39:53 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 06:39:53 - INFO - __main__ - ['Animal']
06/02/2022 06:39:53 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 06:39:53 - INFO - __main__ - ['Animal']
06/02/2022 06:39:53 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 06:39:53 - INFO - __main__ - ['Animal']
06/02/2022 06:39:53 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:39:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:39:53 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:39:58 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:39:58 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:39:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:39:59 - INFO - __main__ - Starting training!
06/02/2022 06:40:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.23 on epoch=0
06/02/2022 06:40:01 - INFO - __main__ - Step 20 Global step 20 Train loss 4.96 on epoch=1
06/02/2022 06:40:02 - INFO - __main__ - Step 30 Global step 30 Train loss 4.39 on epoch=2
06/02/2022 06:40:04 - INFO - __main__ - Step 40 Global step 40 Train loss 3.32 on epoch=2
06/02/2022 06:40:05 - INFO - __main__ - Step 50 Global step 50 Train loss 3.05 on epoch=3
06/02/2022 06:40:07 - INFO - __main__ - Global step 50 Train loss 4.39 Classification-F1 0.13346132163074395 on epoch=3
06/02/2022 06:40:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13346132163074395 on epoch=3, global_step=50
06/02/2022 06:40:09 - INFO - __main__ - Step 60 Global step 60 Train loss 2.44 on epoch=4
06/02/2022 06:40:10 - INFO - __main__ - Step 70 Global step 70 Train loss 2.19 on epoch=4
06/02/2022 06:40:11 - INFO - __main__ - Step 80 Global step 80 Train loss 2.09 on epoch=5
06/02/2022 06:40:12 - INFO - __main__ - Step 90 Global step 90 Train loss 1.90 on epoch=6
06/02/2022 06:40:14 - INFO - __main__ - Step 100 Global step 100 Train loss 1.74 on epoch=7
06/02/2022 06:40:18 - INFO - __main__ - Global step 100 Train loss 2.07 Classification-F1 0.3303713797451169 on epoch=7
06/02/2022 06:40:18 - INFO - __main__ - Saving model with best Classification-F1: 0.13346132163074395 -> 0.3303713797451169 on epoch=7, global_step=100
06/02/2022 06:40:19 - INFO - __main__ - Step 110 Global step 110 Train loss 1.48 on epoch=7
06/02/2022 06:40:20 - INFO - __main__ - Step 120 Global step 120 Train loss 1.41 on epoch=8
06/02/2022 06:40:21 - INFO - __main__ - Step 130 Global step 130 Train loss 1.38 on epoch=9
06/02/2022 06:40:23 - INFO - __main__ - Step 140 Global step 140 Train loss 1.27 on epoch=9
06/02/2022 06:40:24 - INFO - __main__ - Step 150 Global step 150 Train loss 1.21 on epoch=10
06/02/2022 06:40:27 - INFO - __main__ - Global step 150 Train loss 1.35 Classification-F1 0.4241336876511295 on epoch=10
06/02/2022 06:40:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3303713797451169 -> 0.4241336876511295 on epoch=10, global_step=150
06/02/2022 06:40:29 - INFO - __main__ - Step 160 Global step 160 Train loss 1.24 on epoch=11
06/02/2022 06:40:30 - INFO - __main__ - Step 170 Global step 170 Train loss 1.11 on epoch=12
06/02/2022 06:40:31 - INFO - __main__ - Step 180 Global step 180 Train loss 1.13 on epoch=12
06/02/2022 06:40:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=13
06/02/2022 06:40:34 - INFO - __main__ - Step 200 Global step 200 Train loss 1.08 on epoch=14
06/02/2022 06:40:38 - INFO - __main__ - Global step 200 Train loss 1.10 Classification-F1 0.42944865642771124 on epoch=14
06/02/2022 06:40:38 - INFO - __main__ - Saving model with best Classification-F1: 0.4241336876511295 -> 0.42944865642771124 on epoch=14, global_step=200
06/02/2022 06:40:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.94 on epoch=14
06/02/2022 06:40:40 - INFO - __main__ - Step 220 Global step 220 Train loss 1.02 on epoch=15
06/02/2022 06:40:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.86 on epoch=16
06/02/2022 06:40:43 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=17
06/02/2022 06:40:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=17
06/02/2022 06:40:48 - INFO - __main__ - Global step 250 Train loss 0.91 Classification-F1 0.4008365624718963 on epoch=17
06/02/2022 06:40:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.86 on epoch=18
06/02/2022 06:40:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.81 on epoch=19
06/02/2022 06:40:51 - INFO - __main__ - Step 280 Global step 280 Train loss 0.79 on epoch=19
06/02/2022 06:40:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=20
06/02/2022 06:40:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=21
06/02/2022 06:40:57 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.4969993684098682 on epoch=21
06/02/2022 06:40:57 - INFO - __main__ - Saving model with best Classification-F1: 0.42944865642771124 -> 0.4969993684098682 on epoch=21, global_step=300
06/02/2022 06:40:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.75 on epoch=22
06/02/2022 06:41:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=22
06/02/2022 06:41:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.74 on epoch=23
06/02/2022 06:41:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.71 on epoch=24
06/02/2022 06:41:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.63 on epoch=24
06/02/2022 06:41:07 - INFO - __main__ - Global step 350 Train loss 0.70 Classification-F1 0.551998239941952 on epoch=24
06/02/2022 06:41:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4969993684098682 -> 0.551998239941952 on epoch=24, global_step=350
06/02/2022 06:41:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.75 on epoch=25
06/02/2022 06:41:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.64 on epoch=26
06/02/2022 06:41:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=27
06/02/2022 06:41:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.56 on epoch=27
06/02/2022 06:41:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.54 on epoch=28
06/02/2022 06:41:18 - INFO - __main__ - Global step 400 Train loss 0.61 Classification-F1 0.7451074527306333 on epoch=28
06/02/2022 06:41:18 - INFO - __main__ - Saving model with best Classification-F1: 0.551998239941952 -> 0.7451074527306333 on epoch=28, global_step=400
06/02/2022 06:41:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.65 on epoch=29
06/02/2022 06:41:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.67 on epoch=29
06/02/2022 06:41:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.64 on epoch=30
06/02/2022 06:41:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.70 on epoch=31
06/02/2022 06:41:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.63 on epoch=32
06/02/2022 06:41:29 - INFO - __main__ - Global step 450 Train loss 0.66 Classification-F1 0.5548740180056969 on epoch=32
06/02/2022 06:41:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.57 on epoch=32
06/02/2022 06:41:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.68 on epoch=33
06/02/2022 06:41:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.58 on epoch=34
06/02/2022 06:41:34 - INFO - __main__ - Step 490 Global step 490 Train loss 0.52 on epoch=34
06/02/2022 06:41:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.74 on epoch=35
06/02/2022 06:41:39 - INFO - __main__ - Global step 500 Train loss 0.62 Classification-F1 0.7022562859256408 on epoch=35
06/02/2022 06:41:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.47 on epoch=36
06/02/2022 06:41:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.66 on epoch=37
06/02/2022 06:41:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.53 on epoch=37
06/02/2022 06:41:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.59 on epoch=38
06/02/2022 06:41:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.51 on epoch=39
06/02/2022 06:41:49 - INFO - __main__ - Global step 550 Train loss 0.55 Classification-F1 0.7059355314095979 on epoch=39
06/02/2022 06:41:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.51 on epoch=39
06/02/2022 06:41:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.56 on epoch=40
06/02/2022 06:41:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.48 on epoch=41
06/02/2022 06:41:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.52 on epoch=42
06/02/2022 06:41:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=42
06/02/2022 06:42:00 - INFO - __main__ - Global step 600 Train loss 0.51 Classification-F1 0.5852874692929274 on epoch=42
06/02/2022 06:42:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.43 on epoch=43
06/02/2022 06:42:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.54 on epoch=44
06/02/2022 06:42:03 - INFO - __main__ - Step 630 Global step 630 Train loss 0.44 on epoch=44
06/02/2022 06:42:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.55 on epoch=45
06/02/2022 06:42:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.51 on epoch=46
06/02/2022 06:42:09 - INFO - __main__ - Global step 650 Train loss 0.49 Classification-F1 0.528833909019237 on epoch=46
06/02/2022 06:42:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.51 on epoch=47
06/02/2022 06:42:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=47
06/02/2022 06:42:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.45 on epoch=48
06/02/2022 06:42:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.46 on epoch=49
06/02/2022 06:42:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=49
06/02/2022 06:42:19 - INFO - __main__ - Global step 700 Train loss 0.46 Classification-F1 0.6429507644939974 on epoch=49
06/02/2022 06:42:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.40 on epoch=50
06/02/2022 06:42:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.39 on epoch=51
06/02/2022 06:42:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.53 on epoch=52
06/02/2022 06:42:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.44 on epoch=52
06/02/2022 06:42:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.47 on epoch=53
06/02/2022 06:42:30 - INFO - __main__ - Global step 750 Train loss 0.45 Classification-F1 0.7445690171229782 on epoch=53
06/02/2022 06:42:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=54
06/02/2022 06:42:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=54
06/02/2022 06:42:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.40 on epoch=55
06/02/2022 06:42:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.38 on epoch=56
06/02/2022 06:42:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.40 on epoch=57
06/02/2022 06:42:40 - INFO - __main__ - Global step 800 Train loss 0.38 Classification-F1 0.6792589223995577 on epoch=57
06/02/2022 06:42:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=57
06/02/2022 06:42:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.36 on epoch=58
06/02/2022 06:42:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.38 on epoch=59
06/02/2022 06:42:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=59
06/02/2022 06:42:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.36 on epoch=60
06/02/2022 06:42:50 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.4384745198659137 on epoch=60
06/02/2022 06:42:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.30 on epoch=61
06/02/2022 06:42:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.32 on epoch=62
06/02/2022 06:42:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.37 on epoch=62
06/02/2022 06:42:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.27 on epoch=63
06/02/2022 06:42:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.28 on epoch=64
06/02/2022 06:43:00 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.7205713337824446 on epoch=64
06/02/2022 06:43:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=64
06/02/2022 06:43:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=65
06/02/2022 06:43:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=66
06/02/2022 06:43:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=67
06/02/2022 06:43:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.37 on epoch=67
06/02/2022 06:43:10 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.45264725346701257 on epoch=67
06/02/2022 06:43:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=68
06/02/2022 06:43:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.42 on epoch=69
06/02/2022 06:43:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.25 on epoch=69
06/02/2022 06:43:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=70
06/02/2022 06:43:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=71
06/02/2022 06:43:20 - INFO - __main__ - Global step 1000 Train loss 0.28 Classification-F1 0.46090287663577306 on epoch=71
06/02/2022 06:43:21 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.26 on epoch=72
06/02/2022 06:43:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=72
06/02/2022 06:43:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
06/02/2022 06:43:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=74
06/02/2022 06:43:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=74
06/02/2022 06:43:30 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.5618509573917544 on epoch=74
06/02/2022 06:43:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=75
06/02/2022 06:43:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=76
06/02/2022 06:43:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=77
06/02/2022 06:43:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=77
06/02/2022 06:43:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=78
06/02/2022 06:43:40 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.7717598391949079 on epoch=78
06/02/2022 06:43:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7451074527306333 -> 0.7717598391949079 on epoch=78, global_step=1100
06/02/2022 06:43:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=79
06/02/2022 06:43:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=79
06/02/2022 06:43:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=80
06/02/2022 06:43:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
06/02/2022 06:43:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.21 on epoch=82
06/02/2022 06:43:50 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.6132504196979236 on epoch=82
06/02/2022 06:43:51 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.21 on epoch=82
06/02/2022 06:43:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=83
06/02/2022 06:43:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=84
06/02/2022 06:43:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=84
06/02/2022 06:43:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=85
06/02/2022 06:44:01 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.6781339173865457 on epoch=85
06/02/2022 06:44:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=86
06/02/2022 06:44:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=87
06/02/2022 06:44:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
06/02/2022 06:44:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=88
06/02/2022 06:44:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=89
06/02/2022 06:44:10 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.6124042119160965 on epoch=89
06/02/2022 06:44:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/02/2022 06:44:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
06/02/2022 06:44:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=91
06/02/2022 06:44:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=92
06/02/2022 06:44:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=92
06/02/2022 06:44:20 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.7059062271334847 on epoch=92
06/02/2022 06:44:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
06/02/2022 06:44:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/02/2022 06:44:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=94
06/02/2022 06:44:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.20 on epoch=95
06/02/2022 06:44:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=96
06/02/2022 06:44:30 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6561356402881998 on epoch=96
06/02/2022 06:44:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=97
06/02/2022 06:44:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=97
06/02/2022 06:44:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=98
06/02/2022 06:44:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/02/2022 06:44:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/02/2022 06:44:40 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.5679379323487337 on epoch=99
06/02/2022 06:44:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
06/02/2022 06:44:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/02/2022 06:44:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/02/2022 06:44:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=102
06/02/2022 06:44:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=103
06/02/2022 06:44:50 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.6227188264488233 on epoch=103
06/02/2022 06:44:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
06/02/2022 06:44:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=104
06/02/2022 06:44:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=105
06/02/2022 06:44:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/02/2022 06:44:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=107
06/02/2022 06:45:00 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.6697357174942565 on epoch=107
06/02/2022 06:45:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
06/02/2022 06:45:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=108
06/02/2022 06:45:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=109
06/02/2022 06:45:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=109
06/02/2022 06:45:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=110
06/02/2022 06:45:10 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.6778829358711145 on epoch=110
06/02/2022 06:45:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=111
06/02/2022 06:45:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.21 on epoch=112
06/02/2022 06:45:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/02/2022 06:45:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/02/2022 06:45:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/02/2022 06:45:19 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.9470538606449423 on epoch=114
06/02/2022 06:45:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7717598391949079 -> 0.9470538606449423 on epoch=114, global_step=1600
06/02/2022 06:45:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=114
06/02/2022 06:45:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=115
06/02/2022 06:45:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=116
06/02/2022 06:45:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=117
06/02/2022 06:45:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/02/2022 06:45:30 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.8933765070055392 on epoch=117
06/02/2022 06:45:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=118
06/02/2022 06:45:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=119
06/02/2022 06:45:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/02/2022 06:45:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
06/02/2022 06:45:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.16 on epoch=121
06/02/2022 06:45:39 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.7845589368318872 on epoch=121
06/02/2022 06:45:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/02/2022 06:45:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=122
06/02/2022 06:45:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=123
06/02/2022 06:45:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/02/2022 06:45:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/02/2022 06:45:49 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7121400898096408 on epoch=124
06/02/2022 06:45:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/02/2022 06:45:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=126
06/02/2022 06:45:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/02/2022 06:45:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/02/2022 06:45:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=128
06/02/2022 06:45:59 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7590981426733793 on epoch=128
06/02/2022 06:46:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/02/2022 06:46:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
06/02/2022 06:46:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/02/2022 06:46:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/02/2022 06:46:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 06:46:09 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7956305577259367 on epoch=132
06/02/2022 06:46:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/02/2022 06:46:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/02/2022 06:46:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=134
06/02/2022 06:46:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/02/2022 06:46:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/02/2022 06:46:19 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7187672244798139 on epoch=135
06/02/2022 06:46:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/02/2022 06:46:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=137
06/02/2022 06:46:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/02/2022 06:46:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/02/2022 06:46:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=139
06/02/2022 06:46:29 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.8146334887099749 on epoch=139
06/02/2022 06:46:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
06/02/2022 06:46:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/02/2022 06:46:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/02/2022 06:46:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/02/2022 06:46:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/02/2022 06:46:38 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7542006379671191 on epoch=142
06/02/2022 06:46:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/02/2022 06:46:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=144
06/02/2022 06:46:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=144
06/02/2022 06:46:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/02/2022 06:46:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/02/2022 06:46:48 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7404543390857987 on epoch=146
06/02/2022 06:46:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=147
06/02/2022 06:46:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/02/2022 06:46:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=148
06/02/2022 06:46:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/02/2022 06:46:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/02/2022 06:46:58 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6942940348837969 on epoch=149
06/02/2022 06:46:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/02/2022 06:47:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/02/2022 06:47:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/02/2022 06:47:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/02/2022 06:47:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/02/2022 06:47:08 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8128920207342853 on epoch=153
06/02/2022 06:47:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
06/02/2022 06:47:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/02/2022 06:47:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
06/02/2022 06:47:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/02/2022 06:47:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/02/2022 06:47:18 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.687097296671725 on epoch=157
06/02/2022 06:47:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/02/2022 06:47:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/02/2022 06:47:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
06/02/2022 06:47:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/02/2022 06:47:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/02/2022 06:47:28 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7724642056235984 on epoch=160
06/02/2022 06:47:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/02/2022 06:47:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/02/2022 06:47:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/02/2022 06:47:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 06:47:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/02/2022 06:47:38 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7011332107843329 on epoch=164
06/02/2022 06:47:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/02/2022 06:47:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/02/2022 06:47:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=166
06/02/2022 06:47:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/02/2022 06:47:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/02/2022 06:47:48 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7120485325404959 on epoch=167
06/02/2022 06:47:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/02/2022 06:47:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/02/2022 06:47:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 06:47:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=170
06/02/2022 06:47:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=171
06/02/2022 06:47:58 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7710470924684635 on epoch=171
06/02/2022 06:47:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/02/2022 06:48:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/02/2022 06:48:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/02/2022 06:48:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/02/2022 06:48:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/02/2022 06:48:07 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7268576106769543 on epoch=174
06/02/2022 06:48:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=175
06/02/2022 06:48:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/02/2022 06:48:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/02/2022 06:48:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/02/2022 06:48:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/02/2022 06:48:17 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7380183143926307 on epoch=178
06/02/2022 06:48:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/02/2022 06:48:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/02/2022 06:48:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 06:48:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
06/02/2022 06:48:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.24 on epoch=182
06/02/2022 06:48:27 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.8355197641739981 on epoch=182
06/02/2022 06:48:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 06:48:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=183
06/02/2022 06:48:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/02/2022 06:48:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/02/2022 06:48:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/02/2022 06:48:37 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7656288713518874 on epoch=185
06/02/2022 06:48:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
06/02/2022 06:48:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/02/2022 06:48:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/02/2022 06:48:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/02/2022 06:48:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/02/2022 06:48:47 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7455600548440633 on epoch=189
06/02/2022 06:48:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/02/2022 06:48:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/02/2022 06:48:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/02/2022 06:48:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 06:48:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/02/2022 06:48:57 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.676040213306702 on epoch=192
06/02/2022 06:48:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/02/2022 06:48:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/02/2022 06:49:01 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/02/2022 06:49:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/02/2022 06:49:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/02/2022 06:49:07 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8850409760762769 on epoch=196
06/02/2022 06:49:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
06/02/2022 06:49:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
06/02/2022 06:49:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/02/2022 06:49:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.11 on epoch=199
06/02/2022 06:49:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/02/2022 06:49:17 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.8972538229907531 on epoch=199
06/02/2022 06:49:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/02/2022 06:49:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/02/2022 06:49:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=202
06/02/2022 06:49:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/02/2022 06:49:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/02/2022 06:49:27 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.9730205278592374 on epoch=203
06/02/2022 06:49:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9470538606449423 -> 0.9730205278592374 on epoch=203, global_step=2850
06/02/2022 06:49:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/02/2022 06:49:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/02/2022 06:49:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/02/2022 06:49:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/02/2022 06:49:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/02/2022 06:49:37 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9683048806032676 on epoch=207
06/02/2022 06:49:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/02/2022 06:49:39 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 06:49:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/02/2022 06:49:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/02/2022 06:49:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=210
06/02/2022 06:49:47 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7820803814497789 on epoch=210
06/02/2022 06:49:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 06:49:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 06:49:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/02/2022 06:49:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/02/2022 06:49:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/02/2022 06:49:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:49:54 - INFO - __main__ - Printing 3 examples
06/02/2022 06:49:54 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 06:49:54 - INFO - __main__ - ['Animal']
06/02/2022 06:49:54 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 06:49:54 - INFO - __main__ - ['Animal']
06/02/2022 06:49:54 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 06:49:54 - INFO - __main__ - ['Animal']
06/02/2022 06:49:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:49:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:49:55 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:49:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:49:55 - INFO - __main__ - Printing 3 examples
06/02/2022 06:49:55 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 06:49:55 - INFO - __main__ - ['Animal']
06/02/2022 06:49:55 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 06:49:55 - INFO - __main__ - ['Animal']
06/02/2022 06:49:55 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 06:49:55 - INFO - __main__ - ['Animal']
06/02/2022 06:49:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:49:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:49:55 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:49:57 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8252595354913903 on epoch=214
06/02/2022 06:49:57 - INFO - __main__ - save last model!
06/02/2022 06:49:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 06:49:57 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 06:49:57 - INFO - __main__ - Printing 3 examples
06/02/2022 06:49:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 06:49:57 - INFO - __main__ - ['Animal']
06/02/2022 06:49:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 06:49:57 - INFO - __main__ - ['Animal']
06/02/2022 06:49:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 06:49:57 - INFO - __main__ - ['Village']
06/02/2022 06:49:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:49:59 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:50:01 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:50:01 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:50:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:50:02 - INFO - __main__ - Starting training!
06/02/2022 06:50:02 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 06:51:13 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/02/2022 06:51:13 - INFO - __main__ - Classification-F1 on test data: 0.5709
06/02/2022 06:51:13 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9730205278592374, test_performance=0.5708967453193384
06/02/2022 06:51:13 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/02/2022 06:51:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:51:14 - INFO - __main__ - Printing 3 examples
06/02/2022 06:51:14 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 06:51:14 - INFO - __main__ - ['Animal']
06/02/2022 06:51:14 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 06:51:14 - INFO - __main__ - ['Animal']
06/02/2022 06:51:14 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 06:51:14 - INFO - __main__ - ['Animal']
06/02/2022 06:51:14 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:51:14 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:51:14 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 06:51:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 06:51:14 - INFO - __main__ - Printing 3 examples
06/02/2022 06:51:14 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 06:51:14 - INFO - __main__ - ['Animal']
06/02/2022 06:51:14 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 06:51:14 - INFO - __main__ - ['Animal']
06/02/2022 06:51:14 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 06:51:14 - INFO - __main__ - ['Animal']
06/02/2022 06:51:14 - INFO - __main__ - Tokenizing Input ...
06/02/2022 06:51:15 - INFO - __main__ - Tokenizing Output ...
06/02/2022 06:51:15 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 06:51:20 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 06:51:20 - INFO - __main__ - task name: dbpedia_14
06/02/2022 06:51:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 06:51:20 - INFO - __main__ - Starting training!
06/02/2022 06:51:22 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=0
06/02/2022 06:51:23 - INFO - __main__ - Step 20 Global step 20 Train loss 5.55 on epoch=1
06/02/2022 06:51:24 - INFO - __main__ - Step 30 Global step 30 Train loss 5.11 on epoch=2
06/02/2022 06:51:25 - INFO - __main__ - Step 40 Global step 40 Train loss 4.42 on epoch=2
06/02/2022 06:51:27 - INFO - __main__ - Step 50 Global step 50 Train loss 3.87 on epoch=3
06/02/2022 06:51:43 - INFO - __main__ - Global step 50 Train loss 5.10 Classification-F1 0.01955262799995233 on epoch=3
06/02/2022 06:51:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01955262799995233 on epoch=3, global_step=50
06/02/2022 06:51:45 - INFO - __main__ - Step 60 Global step 60 Train loss 3.62 on epoch=4
06/02/2022 06:51:46 - INFO - __main__ - Step 70 Global step 70 Train loss 3.38 on epoch=4
06/02/2022 06:51:47 - INFO - __main__ - Step 80 Global step 80 Train loss 2.76 on epoch=5
06/02/2022 06:51:48 - INFO - __main__ - Step 90 Global step 90 Train loss 2.51 on epoch=6
06/02/2022 06:51:50 - INFO - __main__ - Step 100 Global step 100 Train loss 2.47 on epoch=7
06/02/2022 06:51:54 - INFO - __main__ - Global step 100 Train loss 2.95 Classification-F1 0.10348105561202121 on epoch=7
06/02/2022 06:51:54 - INFO - __main__ - Saving model with best Classification-F1: 0.01955262799995233 -> 0.10348105561202121 on epoch=7, global_step=100
06/02/2022 06:51:55 - INFO - __main__ - Step 110 Global step 110 Train loss 2.01 on epoch=7
06/02/2022 06:51:56 - INFO - __main__ - Step 120 Global step 120 Train loss 1.96 on epoch=8
06/02/2022 06:51:57 - INFO - __main__ - Step 130 Global step 130 Train loss 1.78 on epoch=9
06/02/2022 06:51:59 - INFO - __main__ - Step 140 Global step 140 Train loss 1.70 on epoch=9
06/02/2022 06:52:00 - INFO - __main__ - Step 150 Global step 150 Train loss 1.40 on epoch=10
06/02/2022 06:52:03 - INFO - __main__ - Global step 150 Train loss 1.77 Classification-F1 0.26030484251645697 on epoch=10
06/02/2022 06:52:04 - INFO - __main__ - Saving model with best Classification-F1: 0.10348105561202121 -> 0.26030484251645697 on epoch=10, global_step=150
06/02/2022 06:52:05 - INFO - __main__ - Step 160 Global step 160 Train loss 1.57 on epoch=11
06/02/2022 06:52:06 - INFO - __main__ - Step 170 Global step 170 Train loss 1.49 on epoch=12
06/02/2022 06:52:07 - INFO - __main__ - Step 180 Global step 180 Train loss 1.29 on epoch=12
06/02/2022 06:52:09 - INFO - __main__ - Step 190 Global step 190 Train loss 1.26 on epoch=13
06/02/2022 06:52:10 - INFO - __main__ - Step 200 Global step 200 Train loss 1.25 on epoch=14
06/02/2022 06:52:13 - INFO - __main__ - Global step 200 Train loss 1.37 Classification-F1 0.40562308193561575 on epoch=14
06/02/2022 06:52:13 - INFO - __main__ - Saving model with best Classification-F1: 0.26030484251645697 -> 0.40562308193561575 on epoch=14, global_step=200
06/02/2022 06:52:15 - INFO - __main__ - Step 210 Global step 210 Train loss 1.07 on epoch=14
06/02/2022 06:52:16 - INFO - __main__ - Step 220 Global step 220 Train loss 1.13 on epoch=15
06/02/2022 06:52:17 - INFO - __main__ - Step 230 Global step 230 Train loss 1.02 on epoch=16
06/02/2022 06:52:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.95 on epoch=17
06/02/2022 06:52:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.94 on epoch=17
06/02/2022 06:52:23 - INFO - __main__ - Global step 250 Train loss 1.02 Classification-F1 0.3587067247561507 on epoch=17
06/02/2022 06:52:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.89 on epoch=18
06/02/2022 06:52:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.95 on epoch=19
06/02/2022 06:52:27 - INFO - __main__ - Step 280 Global step 280 Train loss 0.89 on epoch=19
06/02/2022 06:52:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=20
06/02/2022 06:52:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.78 on epoch=21
06/02/2022 06:52:33 - INFO - __main__ - Global step 300 Train loss 0.86 Classification-F1 0.40643728644959043 on epoch=21
06/02/2022 06:52:33 - INFO - __main__ - Saving model with best Classification-F1: 0.40562308193561575 -> 0.40643728644959043 on epoch=21, global_step=300
06/02/2022 06:52:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.78 on epoch=22
06/02/2022 06:52:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.76 on epoch=22
06/02/2022 06:52:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=23
06/02/2022 06:52:38 - INFO - __main__ - Step 340 Global step 340 Train loss 0.71 on epoch=24
06/02/2022 06:52:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=24
06/02/2022 06:52:43 - INFO - __main__ - Global step 350 Train loss 0.73 Classification-F1 0.641365587836493 on epoch=24
06/02/2022 06:52:43 - INFO - __main__ - Saving model with best Classification-F1: 0.40643728644959043 -> 0.641365587836493 on epoch=24, global_step=350
06/02/2022 06:52:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=25
06/02/2022 06:52:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.66 on epoch=26
06/02/2022 06:52:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.63 on epoch=27
06/02/2022 06:52:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.67 on epoch=27
06/02/2022 06:52:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.63 on epoch=28
06/02/2022 06:52:53 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.593530386525874 on epoch=28
06/02/2022 06:52:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.68 on epoch=29
06/02/2022 06:52:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=29
06/02/2022 06:52:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.58 on epoch=30
06/02/2022 06:52:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=31
06/02/2022 06:52:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.54 on epoch=32
06/02/2022 06:53:04 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.6607918417922956 on epoch=32
06/02/2022 06:53:04 - INFO - __main__ - Saving model with best Classification-F1: 0.641365587836493 -> 0.6607918417922956 on epoch=32, global_step=450
06/02/2022 06:53:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=32
06/02/2022 06:53:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.53 on epoch=33
06/02/2022 06:53:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.62 on epoch=34
06/02/2022 06:53:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.50 on epoch=34
06/02/2022 06:53:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.66 on epoch=35
06/02/2022 06:53:14 - INFO - __main__ - Global step 500 Train loss 0.55 Classification-F1 0.6531088978408048 on epoch=35
06/02/2022 06:53:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.46 on epoch=36
06/02/2022 06:53:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=37
06/02/2022 06:53:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/02/2022 06:53:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=38
06/02/2022 06:53:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.49 on epoch=39
06/02/2022 06:53:24 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.5766678458016787 on epoch=39
06/02/2022 06:53:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=39
06/02/2022 06:53:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=40
06/02/2022 06:53:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=41
06/02/2022 06:53:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.45 on epoch=42
06/02/2022 06:53:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=42
06/02/2022 06:53:34 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.5701050279054661 on epoch=42
06/02/2022 06:53:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=43
06/02/2022 06:53:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.44 on epoch=44
06/02/2022 06:53:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=44
06/02/2022 06:53:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=45
06/02/2022 06:53:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.31 on epoch=46
06/02/2022 06:53:44 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.77342283755172 on epoch=46
06/02/2022 06:53:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6607918417922956 -> 0.77342283755172 on epoch=46, global_step=650
06/02/2022 06:53:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.45 on epoch=47
06/02/2022 06:53:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.37 on epoch=47
06/02/2022 06:53:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.35 on epoch=48
06/02/2022 06:53:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.45 on epoch=49
06/02/2022 06:53:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=49
06/02/2022 06:53:54 - INFO - __main__ - Global step 700 Train loss 0.40 Classification-F1 0.6566398726190996 on epoch=49
06/02/2022 06:53:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.37 on epoch=50
06/02/2022 06:53:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.42 on epoch=51
06/02/2022 06:53:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.43 on epoch=52
06/02/2022 06:53:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.33 on epoch=52
06/02/2022 06:54:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=53
06/02/2022 06:54:05 - INFO - __main__ - Global step 750 Train loss 0.36 Classification-F1 0.7338081488262035 on epoch=53
06/02/2022 06:54:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.39 on epoch=54
06/02/2022 06:54:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.40 on epoch=54
06/02/2022 06:54:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=55
06/02/2022 06:54:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=56
06/02/2022 06:54:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.34 on epoch=57
06/02/2022 06:54:16 - INFO - __main__ - Global step 800 Train loss 0.35 Classification-F1 0.842934192244439 on epoch=57
06/02/2022 06:54:16 - INFO - __main__ - Saving model with best Classification-F1: 0.77342283755172 -> 0.842934192244439 on epoch=57, global_step=800
06/02/2022 06:54:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=57
06/02/2022 06:54:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=58
06/02/2022 06:54:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=59
06/02/2022 06:54:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.32 on epoch=59
06/02/2022 06:54:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.35 on epoch=60
06/02/2022 06:54:26 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.7743842713011673 on epoch=60
06/02/2022 06:54:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.33 on epoch=61
06/02/2022 06:54:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=62
06/02/2022 06:54:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=62
06/02/2022 06:54:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=63
06/02/2022 06:54:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=64
06/02/2022 06:54:36 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.7602715713199584 on epoch=64
06/02/2022 06:54:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=64
06/02/2022 06:54:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.28 on epoch=65
06/02/2022 06:54:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=66
06/02/2022 06:54:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=67
06/02/2022 06:54:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.28 on epoch=67
06/02/2022 06:54:46 - INFO - __main__ - Global step 950 Train loss 0.27 Classification-F1 0.7277182913515226 on epoch=67
06/02/2022 06:54:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=68
06/02/2022 06:54:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.27 on epoch=69
06/02/2022 06:54:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=69
06/02/2022 06:54:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/02/2022 06:54:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.29 on epoch=71
06/02/2022 06:54:57 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.7828383754528204 on epoch=71
06/02/2022 06:54:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=72
06/02/2022 06:54:59 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.31 on epoch=72
06/02/2022 06:55:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.26 on epoch=73
06/02/2022 06:55:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=74
06/02/2022 06:55:03 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=74
06/02/2022 06:55:07 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.9215884486737023 on epoch=74
06/02/2022 06:55:07 - INFO - __main__ - Saving model with best Classification-F1: 0.842934192244439 -> 0.9215884486737023 on epoch=74, global_step=1050
06/02/2022 06:55:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=75
06/02/2022 06:55:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=76
06/02/2022 06:55:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.27 on epoch=77
06/02/2022 06:55:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/02/2022 06:55:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=78
06/02/2022 06:55:17 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.7418055543149915 on epoch=78
06/02/2022 06:55:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.29 on epoch=79
06/02/2022 06:55:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=79
06/02/2022 06:55:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=80
06/02/2022 06:55:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
06/02/2022 06:55:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=82
06/02/2022 06:55:28 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.8659956045878313 on epoch=82
06/02/2022 06:55:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=82
06/02/2022 06:55:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=83
06/02/2022 06:55:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=84
06/02/2022 06:55:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=84
06/02/2022 06:55:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=85
06/02/2022 06:55:38 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.9462784747330016 on epoch=85
06/02/2022 06:55:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9215884486737023 -> 0.9462784747330016 on epoch=85, global_step=1200
06/02/2022 06:55:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
06/02/2022 06:55:41 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.25 on epoch=87
06/02/2022 06:55:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
06/02/2022 06:55:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
06/02/2022 06:55:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=89
06/02/2022 06:55:49 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.9278950305431058 on epoch=89
06/02/2022 06:55:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/02/2022 06:55:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
06/02/2022 06:55:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=91
06/02/2022 06:55:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=92
06/02/2022 06:55:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=92
06/02/2022 06:55:59 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.9072417635816947 on epoch=92
06/02/2022 06:56:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=93
06/02/2022 06:56:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=94
06/02/2022 06:56:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=94
06/02/2022 06:56:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.18 on epoch=95
06/02/2022 06:56:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=96
06/02/2022 06:56:09 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.8644258681272028 on epoch=96
06/02/2022 06:56:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=97
06/02/2022 06:56:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=97
06/02/2022 06:56:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=98
06/02/2022 06:56:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=99
06/02/2022 06:56:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/02/2022 06:56:20 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.8037352037589229 on epoch=99
06/02/2022 06:56:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=100
06/02/2022 06:56:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=101
06/02/2022 06:56:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=102
06/02/2022 06:56:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=102
06/02/2022 06:56:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=103
06/02/2022 06:56:30 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.9419118160460666 on epoch=103
06/02/2022 06:56:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/02/2022 06:56:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/02/2022 06:56:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/02/2022 06:56:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=106
06/02/2022 06:56:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.18 on epoch=107
06/02/2022 06:56:40 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.9463594162004979 on epoch=107
06/02/2022 06:56:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9462784747330016 -> 0.9463594162004979 on epoch=107, global_step=1500
06/02/2022 06:56:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=107
06/02/2022 06:56:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
06/02/2022 06:56:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=109
06/02/2022 06:56:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/02/2022 06:56:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.15 on epoch=110
06/02/2022 06:56:50 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.8894475111647788 on epoch=110
06/02/2022 06:56:52 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/02/2022 06:56:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=112
06/02/2022 06:56:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/02/2022 06:56:55 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=113
06/02/2022 06:56:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=114
06/02/2022 06:57:00 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.9554000339138587 on epoch=114
06/02/2022 06:57:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9463594162004979 -> 0.9554000339138587 on epoch=114, global_step=1600
06/02/2022 06:57:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/02/2022 06:57:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=115
06/02/2022 06:57:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=116
06/02/2022 06:57:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=117
06/02/2022 06:57:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=117
06/02/2022 06:57:11 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.9554087617451673 on epoch=117
06/02/2022 06:57:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9554000339138587 -> 0.9554087617451673 on epoch=117, global_step=1650
06/02/2022 06:57:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=118
06/02/2022 06:57:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/02/2022 06:57:14 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/02/2022 06:57:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=120
06/02/2022 06:57:17 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=121
06/02/2022 06:57:20 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.8870082452257092 on epoch=121
06/02/2022 06:57:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.18 on epoch=122
06/02/2022 06:57:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=122
06/02/2022 06:57:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=123
06/02/2022 06:57:26 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/02/2022 06:57:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/02/2022 06:57:30 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.8125369930369256 on epoch=124
06/02/2022 06:57:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=125
06/02/2022 06:57:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=126
06/02/2022 06:57:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.15 on epoch=127
06/02/2022 06:57:35 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=127
06/02/2022 06:57:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/02/2022 06:57:40 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.9416958697895851 on epoch=128
06/02/2022 06:57:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/02/2022 06:57:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
06/02/2022 06:57:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/02/2022 06:57:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
06/02/2022 06:57:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 06:57:50 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.884947886290391 on epoch=132
06/02/2022 06:57:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/02/2022 06:57:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/02/2022 06:57:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
06/02/2022 06:57:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
06/02/2022 06:57:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=135
06/02/2022 06:58:00 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.9278007222216942 on epoch=135
06/02/2022 06:58:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/02/2022 06:58:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=137
06/02/2022 06:58:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=137
06/02/2022 06:58:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/02/2022 06:58:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=139
06/02/2022 06:58:10 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.9458033974536322 on epoch=139
06/02/2022 06:58:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
06/02/2022 06:58:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.15 on epoch=140
06/02/2022 06:58:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
06/02/2022 06:58:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/02/2022 06:58:16 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=142
06/02/2022 06:58:20 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.8443935691466281 on epoch=142
06/02/2022 06:58:21 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=143
06/02/2022 06:58:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=144
06/02/2022 06:58:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/02/2022 06:58:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=145
06/02/2022 06:58:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=146
06/02/2022 06:58:30 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.8547915793883535 on epoch=146
06/02/2022 06:58:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
06/02/2022 06:58:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
06/02/2022 06:58:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/02/2022 06:58:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
06/02/2022 06:58:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=149
06/02/2022 06:58:40 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.8303556557004832 on epoch=149
06/02/2022 06:58:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/02/2022 06:58:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=151
06/02/2022 06:58:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=152
06/02/2022 06:58:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=152
06/02/2022 06:58:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=153
06/02/2022 06:58:50 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.9341016570364538 on epoch=153
06/02/2022 06:58:51 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
06/02/2022 06:58:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/02/2022 06:58:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=155
06/02/2022 06:58:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/02/2022 06:58:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/02/2022 06:59:00 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8633307937055564 on epoch=157
06/02/2022 06:59:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=157
06/02/2022 06:59:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
06/02/2022 06:59:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
06/02/2022 06:59:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/02/2022 06:59:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=160
06/02/2022 06:59:09 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.928307736280881 on epoch=160
06/02/2022 06:59:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.14 on epoch=161
06/02/2022 06:59:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/02/2022 06:59:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/02/2022 06:59:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
06/02/2022 06:59:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/02/2022 06:59:20 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.9410908080156594 on epoch=164
06/02/2022 06:59:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/02/2022 06:59:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=165
06/02/2022 06:59:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=166
06/02/2022 06:59:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=167
06/02/2022 06:59:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/02/2022 06:59:30 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.7889730828076335 on epoch=167
06/02/2022 06:59:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/02/2022 06:59:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/02/2022 06:59:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/02/2022 06:59:35 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/02/2022 06:59:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/02/2022 06:59:40 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8615028276061777 on epoch=171
06/02/2022 06:59:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/02/2022 06:59:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/02/2022 06:59:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/02/2022 06:59:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/02/2022 06:59:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/02/2022 06:59:50 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.9378145784217892 on epoch=174
06/02/2022 06:59:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/02/2022 06:59:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/02/2022 06:59:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
06/02/2022 06:59:55 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.11 on epoch=177
06/02/2022 06:59:56 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=178
06/02/2022 07:00:00 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.9410390305547507 on epoch=178
06/02/2022 07:00:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
06/02/2022 07:00:02 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/02/2022 07:00:04 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/02/2022 07:00:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/02/2022 07:00:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=182
06/02/2022 07:00:09 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.8089029526766719 on epoch=182
06/02/2022 07:00:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=182
06/02/2022 07:00:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/02/2022 07:00:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/02/2022 07:00:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.09 on epoch=184
06/02/2022 07:00:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/02/2022 07:00:19 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.9505260828671643 on epoch=185
06/02/2022 07:00:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
06/02/2022 07:00:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/02/2022 07:00:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/02/2022 07:00:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=188
06/02/2022 07:00:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/02/2022 07:00:29 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8851167661478136 on epoch=189
06/02/2022 07:00:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
06/02/2022 07:00:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/02/2022 07:00:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/02/2022 07:00:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 07:00:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/02/2022 07:00:38 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9507421471470577 on epoch=192
06/02/2022 07:00:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/02/2022 07:00:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/02/2022 07:00:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/02/2022 07:00:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/02/2022 07:00:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/02/2022 07:00:48 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.8571082381392858 on epoch=196
06/02/2022 07:00:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
06/02/2022 07:00:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/02/2022 07:00:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/02/2022 07:00:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=199
06/02/2022 07:00:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
06/02/2022 07:00:58 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.9418538435362684 on epoch=199
06/02/2022 07:01:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/02/2022 07:01:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 07:01:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=202
06/02/2022 07:01:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/02/2022 07:01:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/02/2022 07:01:08 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.9372052979010056 on epoch=203
06/02/2022 07:01:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/02/2022 07:01:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
06/02/2022 07:01:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/02/2022 07:01:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/02/2022 07:01:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/02/2022 07:01:18 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9188177415787343 on epoch=207
06/02/2022 07:01:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/02/2022 07:01:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/02/2022 07:01:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/02/2022 07:01:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/02/2022 07:01:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/02/2022 07:01:28 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9278130438658944 on epoch=210
06/02/2022 07:01:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 07:01:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/02/2022 07:01:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/02/2022 07:01:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 07:01:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.11 on epoch=214
06/02/2022 07:01:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:01:36 - INFO - __main__ - Printing 3 examples
06/02/2022 07:01:36 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 07:01:36 - INFO - __main__ - ['Animal']
06/02/2022 07:01:36 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 07:01:36 - INFO - __main__ - ['Animal']
06/02/2022 07:01:36 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 07:01:36 - INFO - __main__ - ['Animal']
06/02/2022 07:01:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:01:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:01:36 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:01:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:01:36 - INFO - __main__ - Printing 3 examples
06/02/2022 07:01:36 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 07:01:36 - INFO - __main__ - ['Animal']
06/02/2022 07:01:36 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 07:01:36 - INFO - __main__ - ['Animal']
06/02/2022 07:01:36 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 07:01:36 - INFO - __main__ - ['Animal']
06/02/2022 07:01:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:01:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:01:36 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:01:38 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.9418155657618156 on epoch=214
06/02/2022 07:01:38 - INFO - __main__ - save last model!
06/02/2022 07:01:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 07:01:38 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 07:01:38 - INFO - __main__ - Printing 3 examples
06/02/2022 07:01:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 07:01:38 - INFO - __main__ - ['Animal']
06/02/2022 07:01:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 07:01:38 - INFO - __main__ - ['Animal']
06/02/2022 07:01:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 07:01:38 - INFO - __main__ - ['Village']
06/02/2022 07:01:38 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:01:40 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:01:42 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:01:42 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:01:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:01:42 - INFO - __main__ - Starting training!
06/02/2022 07:01:43 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 07:02:53 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/02/2022 07:02:53 - INFO - __main__ - Classification-F1 on test data: 0.7907
06/02/2022 07:02:53 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9554087617451673, test_performance=0.7906987632573859
06/02/2022 07:02:53 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/02/2022 07:02:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:02:54 - INFO - __main__ - Printing 3 examples
06/02/2022 07:02:54 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 07:02:54 - INFO - __main__ - ['Animal']
06/02/2022 07:02:54 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 07:02:54 - INFO - __main__ - ['Animal']
06/02/2022 07:02:54 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 07:02:54 - INFO - __main__ - ['Animal']
06/02/2022 07:02:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:02:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:02:54 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:02:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:02:54 - INFO - __main__ - Printing 3 examples
06/02/2022 07:02:54 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 07:02:54 - INFO - __main__ - ['Animal']
06/02/2022 07:02:54 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 07:02:54 - INFO - __main__ - ['Animal']
06/02/2022 07:02:54 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 07:02:54 - INFO - __main__ - ['Animal']
06/02/2022 07:02:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:02:54 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:02:55 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:03:01 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:03:01 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:03:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:03:01 - INFO - __main__ - Starting training!
06/02/2022 07:03:03 - INFO - __main__ - Step 10 Global step 10 Train loss 6.31 on epoch=0
06/02/2022 07:03:04 - INFO - __main__ - Step 20 Global step 20 Train loss 5.49 on epoch=1
06/02/2022 07:03:05 - INFO - __main__ - Step 30 Global step 30 Train loss 5.16 on epoch=2
06/02/2022 07:03:07 - INFO - __main__ - Step 40 Global step 40 Train loss 4.32 on epoch=2
06/02/2022 07:03:08 - INFO - __main__ - Step 50 Global step 50 Train loss 4.35 on epoch=3
06/02/2022 07:03:18 - INFO - __main__ - Global step 50 Train loss 5.12 Classification-F1 0.016088081057352346 on epoch=3
06/02/2022 07:03:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.016088081057352346 on epoch=3, global_step=50
06/02/2022 07:03:19 - INFO - __main__ - Step 60 Global step 60 Train loss 3.56 on epoch=4
06/02/2022 07:03:20 - INFO - __main__ - Step 70 Global step 70 Train loss 3.27 on epoch=4
06/02/2022 07:03:22 - INFO - __main__ - Step 80 Global step 80 Train loss 2.82 on epoch=5
06/02/2022 07:03:23 - INFO - __main__ - Step 90 Global step 90 Train loss 2.77 on epoch=6
06/02/2022 07:03:24 - INFO - __main__ - Step 100 Global step 100 Train loss 2.39 on epoch=7
06/02/2022 07:03:28 - INFO - __main__ - Global step 100 Train loss 2.96 Classification-F1 0.15562966109986093 on epoch=7
06/02/2022 07:03:28 - INFO - __main__ - Saving model with best Classification-F1: 0.016088081057352346 -> 0.15562966109986093 on epoch=7, global_step=100
06/02/2022 07:03:29 - INFO - __main__ - Step 110 Global step 110 Train loss 2.07 on epoch=7
06/02/2022 07:03:31 - INFO - __main__ - Step 120 Global step 120 Train loss 1.96 on epoch=8
06/02/2022 07:03:32 - INFO - __main__ - Step 130 Global step 130 Train loss 1.83 on epoch=9
06/02/2022 07:03:33 - INFO - __main__ - Step 140 Global step 140 Train loss 1.62 on epoch=9
06/02/2022 07:03:35 - INFO - __main__ - Step 150 Global step 150 Train loss 1.56 on epoch=10
06/02/2022 07:03:38 - INFO - __main__ - Global step 150 Train loss 1.81 Classification-F1 0.20634093103731455 on epoch=10
06/02/2022 07:03:38 - INFO - __main__ - Saving model with best Classification-F1: 0.15562966109986093 -> 0.20634093103731455 on epoch=10, global_step=150
06/02/2022 07:03:39 - INFO - __main__ - Step 160 Global step 160 Train loss 1.48 on epoch=11
06/02/2022 07:03:41 - INFO - __main__ - Step 170 Global step 170 Train loss 1.46 on epoch=12
06/02/2022 07:03:42 - INFO - __main__ - Step 180 Global step 180 Train loss 1.40 on epoch=12
06/02/2022 07:03:43 - INFO - __main__ - Step 190 Global step 190 Train loss 1.41 on epoch=13
06/02/2022 07:03:45 - INFO - __main__ - Step 200 Global step 200 Train loss 1.39 on epoch=14
06/02/2022 07:03:48 - INFO - __main__ - Global step 200 Train loss 1.43 Classification-F1 0.3648407394623455 on epoch=14
06/02/2022 07:03:48 - INFO - __main__ - Saving model with best Classification-F1: 0.20634093103731455 -> 0.3648407394623455 on epoch=14, global_step=200
06/02/2022 07:03:49 - INFO - __main__ - Step 210 Global step 210 Train loss 1.17 on epoch=14
06/02/2022 07:03:50 - INFO - __main__ - Step 220 Global step 220 Train loss 1.24 on epoch=15
06/02/2022 07:03:52 - INFO - __main__ - Step 230 Global step 230 Train loss 1.13 on epoch=16
06/02/2022 07:03:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.96 on epoch=17
06/02/2022 07:03:54 - INFO - __main__ - Step 250 Global step 250 Train loss 1.10 on epoch=17
06/02/2022 07:03:58 - INFO - __main__ - Global step 250 Train loss 1.12 Classification-F1 0.464469889772658 on epoch=17
06/02/2022 07:03:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3648407394623455 -> 0.464469889772658 on epoch=17, global_step=250
06/02/2022 07:03:59 - INFO - __main__ - Step 260 Global step 260 Train loss 1.07 on epoch=18
06/02/2022 07:04:01 - INFO - __main__ - Step 270 Global step 270 Train loss 1.02 on epoch=19
06/02/2022 07:04:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.89 on epoch=19
06/02/2022 07:04:03 - INFO - __main__ - Step 290 Global step 290 Train loss 1.07 on epoch=20
06/02/2022 07:04:05 - INFO - __main__ - Step 300 Global step 300 Train loss 1.62 on epoch=21
06/02/2022 07:04:09 - INFO - __main__ - Global step 300 Train loss 1.13 Classification-F1 0.5199056770841914 on epoch=21
06/02/2022 07:04:09 - INFO - __main__ - Saving model with best Classification-F1: 0.464469889772658 -> 0.5199056770841914 on epoch=21, global_step=300
06/02/2022 07:04:10 - INFO - __main__ - Step 310 Global step 310 Train loss 1.14 on epoch=22
06/02/2022 07:04:11 - INFO - __main__ - Step 320 Global step 320 Train loss 2.23 on epoch=22
06/02/2022 07:04:12 - INFO - __main__ - Step 330 Global step 330 Train loss 1.00 on epoch=23
06/02/2022 07:04:14 - INFO - __main__ - Step 340 Global step 340 Train loss 1.09 on epoch=24
06/02/2022 07:04:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.94 on epoch=24
06/02/2022 07:04:18 - INFO - __main__ - Global step 350 Train loss 1.28 Classification-F1 0.47324089377888745 on epoch=24
06/02/2022 07:04:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.83 on epoch=25
06/02/2022 07:04:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.96 on epoch=26
06/02/2022 07:04:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.83 on epoch=27
06/02/2022 07:04:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.91 on epoch=27
06/02/2022 07:04:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.90 on epoch=28
06/02/2022 07:04:28 - INFO - __main__ - Global step 400 Train loss 0.89 Classification-F1 0.4293707038644556 on epoch=28
06/02/2022 07:04:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.90 on epoch=29
06/02/2022 07:04:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.86 on epoch=29
06/02/2022 07:04:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.92 on epoch=30
06/02/2022 07:04:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.84 on epoch=31
06/02/2022 07:04:34 - INFO - __main__ - Step 450 Global step 450 Train loss 1.67 on epoch=32
06/02/2022 07:04:38 - INFO - __main__ - Global step 450 Train loss 1.04 Classification-F1 0.525712052176653 on epoch=32
06/02/2022 07:04:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5199056770841914 -> 0.525712052176653 on epoch=32, global_step=450
06/02/2022 07:04:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.94 on epoch=32
06/02/2022 07:04:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.73 on epoch=33
06/02/2022 07:04:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.85 on epoch=34
06/02/2022 07:04:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.79 on epoch=34
06/02/2022 07:04:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.73 on epoch=35
06/02/2022 07:04:47 - INFO - __main__ - Global step 500 Train loss 0.81 Classification-F1 0.48367211399444227 on epoch=35
06/02/2022 07:04:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.73 on epoch=36
06/02/2022 07:04:50 - INFO - __main__ - Step 520 Global step 520 Train loss 0.79 on epoch=37
06/02/2022 07:04:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.69 on epoch=37
06/02/2022 07:04:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.77 on epoch=38
06/02/2022 07:04:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.86 on epoch=39
06/02/2022 07:04:57 - INFO - __main__ - Global step 550 Train loss 0.77 Classification-F1 0.4345807816609567 on epoch=39
06/02/2022 07:04:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.71 on epoch=39
06/02/2022 07:04:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.74 on epoch=40
06/02/2022 07:05:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.80 on epoch=41
06/02/2022 07:05:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.77 on epoch=42
06/02/2022 07:05:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.71 on epoch=42
06/02/2022 07:05:06 - INFO - __main__ - Global step 600 Train loss 0.74 Classification-F1 0.5244530923185036 on epoch=42
06/02/2022 07:05:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.71 on epoch=43
06/02/2022 07:05:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.71 on epoch=44
06/02/2022 07:05:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.72 on epoch=44
06/02/2022 07:05:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.70 on epoch=45
06/02/2022 07:05:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.64 on epoch=46
06/02/2022 07:05:16 - INFO - __main__ - Global step 650 Train loss 0.70 Classification-F1 0.5195534298550286 on epoch=46
06/02/2022 07:05:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.71 on epoch=47
06/02/2022 07:05:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.60 on epoch=47
06/02/2022 07:05:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.74 on epoch=48
06/02/2022 07:05:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.70 on epoch=49
06/02/2022 07:05:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.72 on epoch=49
06/02/2022 07:05:25 - INFO - __main__ - Global step 700 Train loss 0.70 Classification-F1 0.5570196788946788 on epoch=49
06/02/2022 07:05:25 - INFO - __main__ - Saving model with best Classification-F1: 0.525712052176653 -> 0.5570196788946788 on epoch=49, global_step=700
06/02/2022 07:05:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.65 on epoch=50
06/02/2022 07:05:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.63 on epoch=51
06/02/2022 07:05:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.74 on epoch=52
06/02/2022 07:05:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.63 on epoch=52
06/02/2022 07:05:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.65 on epoch=53
06/02/2022 07:05:35 - INFO - __main__ - Global step 750 Train loss 0.66 Classification-F1 0.6383441062511965 on epoch=53
06/02/2022 07:05:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5570196788946788 -> 0.6383441062511965 on epoch=53, global_step=750
06/02/2022 07:05:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.74 on epoch=54
06/02/2022 07:05:38 - INFO - __main__ - Step 770 Global step 770 Train loss 0.68 on epoch=54
06/02/2022 07:05:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.83 on epoch=55
06/02/2022 07:05:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.58 on epoch=56
06/02/2022 07:05:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.65 on epoch=57
06/02/2022 07:05:45 - INFO - __main__ - Global step 800 Train loss 0.69 Classification-F1 0.5905354618830118 on epoch=57
06/02/2022 07:05:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.60 on epoch=57
06/02/2022 07:05:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.70 on epoch=58
06/02/2022 07:05:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.66 on epoch=59
06/02/2022 07:05:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.48 on epoch=59
06/02/2022 07:05:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.54 on epoch=60
06/02/2022 07:05:55 - INFO - __main__ - Global step 850 Train loss 0.60 Classification-F1 0.546156830893274 on epoch=60
06/02/2022 07:05:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.58 on epoch=61
06/02/2022 07:05:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.66 on epoch=62
06/02/2022 07:05:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.68 on epoch=62
06/02/2022 07:06:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.63 on epoch=63
06/02/2022 07:06:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.60 on epoch=64
06/02/2022 07:06:05 - INFO - __main__ - Global step 900 Train loss 0.63 Classification-F1 0.5099420260348164 on epoch=64
06/02/2022 07:06:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.60 on epoch=64
06/02/2022 07:06:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.62 on epoch=65
06/02/2022 07:06:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.56 on epoch=66
06/02/2022 07:06:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.64 on epoch=67
06/02/2022 07:06:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.51 on epoch=67
06/02/2022 07:06:14 - INFO - __main__ - Global step 950 Train loss 0.58 Classification-F1 0.5388997729367748 on epoch=67
06/02/2022 07:06:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.49 on epoch=68
06/02/2022 07:06:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.54 on epoch=69
06/02/2022 07:06:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.56 on epoch=69
06/02/2022 07:06:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.66 on epoch=70
06/02/2022 07:06:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.55 on epoch=71
06/02/2022 07:06:24 - INFO - __main__ - Global step 1000 Train loss 0.56 Classification-F1 0.64257123632946 on epoch=71
06/02/2022 07:06:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6383441062511965 -> 0.64257123632946 on epoch=71, global_step=1000
06/02/2022 07:06:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.60 on epoch=72
06/02/2022 07:06:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.51 on epoch=72
06/02/2022 07:06:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.54 on epoch=73
06/02/2022 07:06:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.61 on epoch=74
06/02/2022 07:06:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.43 on epoch=74
06/02/2022 07:06:34 - INFO - __main__ - Global step 1050 Train loss 0.54 Classification-F1 0.6812760086050675 on epoch=74
06/02/2022 07:06:34 - INFO - __main__ - Saving model with best Classification-F1: 0.64257123632946 -> 0.6812760086050675 on epoch=74, global_step=1050
06/02/2022 07:06:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.49 on epoch=75
06/02/2022 07:06:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.48 on epoch=76
06/02/2022 07:06:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.60 on epoch=77
06/02/2022 07:06:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.55 on epoch=77
06/02/2022 07:06:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.47 on epoch=78
06/02/2022 07:06:44 - INFO - __main__ - Global step 1100 Train loss 0.52 Classification-F1 0.7785114238421318 on epoch=78
06/02/2022 07:06:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6812760086050675 -> 0.7785114238421318 on epoch=78, global_step=1100
06/02/2022 07:06:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.46 on epoch=79
06/02/2022 07:06:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.53 on epoch=79
06/02/2022 07:06:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.42 on epoch=80
06/02/2022 07:06:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.46 on epoch=81
06/02/2022 07:06:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.55 on epoch=82
06/02/2022 07:06:54 - INFO - __main__ - Global step 1150 Train loss 0.49 Classification-F1 0.7370559743028184 on epoch=82
06/02/2022 07:06:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.48 on epoch=82
06/02/2022 07:06:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.47 on epoch=83
06/02/2022 07:06:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.52 on epoch=84
06/02/2022 07:06:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.46 on epoch=84
06/02/2022 07:07:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.52 on epoch=85
06/02/2022 07:07:04 - INFO - __main__ - Global step 1200 Train loss 0.49 Classification-F1 0.6672733264428767 on epoch=85
06/02/2022 07:07:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.42 on epoch=86
06/02/2022 07:07:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.49 on epoch=87
06/02/2022 07:07:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.41 on epoch=87
06/02/2022 07:07:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.53 on epoch=88
06/02/2022 07:07:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.51 on epoch=89
06/02/2022 07:07:14 - INFO - __main__ - Global step 1250 Train loss 0.47 Classification-F1 0.6376474677886876 on epoch=89
06/02/2022 07:07:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.47 on epoch=89
06/02/2022 07:07:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.46 on epoch=90
06/02/2022 07:07:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.45 on epoch=91
06/02/2022 07:07:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.45 on epoch=92
06/02/2022 07:07:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.47 on epoch=92
06/02/2022 07:07:23 - INFO - __main__ - Global step 1300 Train loss 0.46 Classification-F1 0.5862141879783009 on epoch=92
06/02/2022 07:07:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.41 on epoch=93
06/02/2022 07:07:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.34 on epoch=94
06/02/2022 07:07:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.40 on epoch=94
06/02/2022 07:07:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.48 on epoch=95
06/02/2022 07:07:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.39 on epoch=96
06/02/2022 07:07:33 - INFO - __main__ - Global step 1350 Train loss 0.40 Classification-F1 0.6574735139608452 on epoch=96
06/02/2022 07:07:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.45 on epoch=97
06/02/2022 07:07:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.40 on epoch=97
06/02/2022 07:07:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.38 on epoch=98
06/02/2022 07:07:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.37 on epoch=99
06/02/2022 07:07:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.34 on epoch=99
06/02/2022 07:07:43 - INFO - __main__ - Global step 1400 Train loss 0.39 Classification-F1 0.7599990965032006 on epoch=99
06/02/2022 07:07:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.38 on epoch=100
06/02/2022 07:07:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.44 on epoch=101
06/02/2022 07:07:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.36 on epoch=102
06/02/2022 07:07:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.35 on epoch=102
06/02/2022 07:07:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.39 on epoch=103
06/02/2022 07:07:53 - INFO - __main__ - Global step 1450 Train loss 0.38 Classification-F1 0.7636088201363344 on epoch=103
06/02/2022 07:07:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.34 on epoch=104
06/02/2022 07:07:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.41 on epoch=104
06/02/2022 07:07:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.35 on epoch=105
06/02/2022 07:07:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.39 on epoch=106
06/02/2022 07:08:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.37 on epoch=107
06/02/2022 07:08:04 - INFO - __main__ - Global step 1500 Train loss 0.37 Classification-F1 0.869272478606095 on epoch=107
06/02/2022 07:08:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7785114238421318 -> 0.869272478606095 on epoch=107, global_step=1500
06/02/2022 07:08:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.34 on epoch=107
06/02/2022 07:08:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.32 on epoch=108
06/02/2022 07:08:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.37 on epoch=109
06/02/2022 07:08:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.26 on epoch=109
06/02/2022 07:08:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.34 on epoch=110
06/02/2022 07:08:14 - INFO - __main__ - Global step 1550 Train loss 0.32 Classification-F1 0.7127361550520039 on epoch=110
06/02/2022 07:08:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.33 on epoch=111
06/02/2022 07:08:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.26 on epoch=112
06/02/2022 07:08:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.36 on epoch=112
06/02/2022 07:08:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.21 on epoch=113
06/02/2022 07:08:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.26 on epoch=114
06/02/2022 07:08:24 - INFO - __main__ - Global step 1600 Train loss 0.28 Classification-F1 0.8880704181802626 on epoch=114
06/02/2022 07:08:24 - INFO - __main__ - Saving model with best Classification-F1: 0.869272478606095 -> 0.8880704181802626 on epoch=114, global_step=1600
06/02/2022 07:08:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.27 on epoch=114
06/02/2022 07:08:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.28 on epoch=115
06/02/2022 07:08:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.28 on epoch=116
06/02/2022 07:08:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.28 on epoch=117
06/02/2022 07:08:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.32 on epoch=117
06/02/2022 07:08:34 - INFO - __main__ - Global step 1650 Train loss 0.29 Classification-F1 0.7544123255973945 on epoch=117
06/02/2022 07:08:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.31 on epoch=118
06/02/2022 07:08:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.29 on epoch=119
06/02/2022 07:08:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.30 on epoch=119
06/02/2022 07:08:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.28 on epoch=120
06/02/2022 07:08:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.23 on epoch=121
06/02/2022 07:08:44 - INFO - __main__ - Global step 1700 Train loss 0.28 Classification-F1 0.6492744417490823 on epoch=121
06/02/2022 07:08:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.30 on epoch=122
06/02/2022 07:08:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.23 on epoch=122
06/02/2022 07:08:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.29 on epoch=123
06/02/2022 07:08:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.27 on epoch=124
06/02/2022 07:08:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.25 on epoch=124
06/02/2022 07:08:54 - INFO - __main__ - Global step 1750 Train loss 0.27 Classification-F1 0.5674372496694131 on epoch=124
06/02/2022 07:08:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.29 on epoch=125
06/02/2022 07:08:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.23 on epoch=126
06/02/2022 07:08:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.40 on epoch=127
06/02/2022 07:08:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.23 on epoch=127
06/02/2022 07:09:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.23 on epoch=128
06/02/2022 07:09:04 - INFO - __main__ - Global step 1800 Train loss 0.27 Classification-F1 0.7106958975104136 on epoch=128
06/02/2022 07:09:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.29 on epoch=129
06/02/2022 07:09:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.27 on epoch=129
06/02/2022 07:09:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.27 on epoch=130
06/02/2022 07:09:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=131
06/02/2022 07:09:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.20 on epoch=132
06/02/2022 07:09:15 - INFO - __main__ - Global step 1850 Train loss 0.24 Classification-F1 0.7415835052848719 on epoch=132
06/02/2022 07:09:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.23 on epoch=132
06/02/2022 07:09:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.26 on epoch=133
06/02/2022 07:09:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.27 on epoch=134
06/02/2022 07:09:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.17 on epoch=134
06/02/2022 07:09:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.30 on epoch=135
06/02/2022 07:09:24 - INFO - __main__ - Global step 1900 Train loss 0.24 Classification-F1 0.5580722280794252 on epoch=135
06/02/2022 07:09:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.20 on epoch=136
06/02/2022 07:09:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.25 on epoch=137
06/02/2022 07:09:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.22 on epoch=137
06/02/2022 07:09:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.22 on epoch=138
06/02/2022 07:09:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.25 on epoch=139
06/02/2022 07:09:34 - INFO - __main__ - Global step 1950 Train loss 0.23 Classification-F1 0.5521085193523932 on epoch=139
06/02/2022 07:09:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.20 on epoch=139
06/02/2022 07:09:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.23 on epoch=140
06/02/2022 07:09:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.21 on epoch=141
06/02/2022 07:09:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.26 on epoch=142
06/02/2022 07:09:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.21 on epoch=142
06/02/2022 07:09:44 - INFO - __main__ - Global step 2000 Train loss 0.22 Classification-F1 0.5423449780994631 on epoch=142
06/02/2022 07:09:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.14 on epoch=143
06/02/2022 07:09:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.21 on epoch=144
06/02/2022 07:09:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.22 on epoch=144
06/02/2022 07:09:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.15 on epoch=145
06/02/2022 07:09:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.16 on epoch=146
06/02/2022 07:09:54 - INFO - __main__ - Global step 2050 Train loss 0.17 Classification-F1 0.7062697723933157 on epoch=146
06/02/2022 07:09:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=147
06/02/2022 07:09:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.26 on epoch=147
06/02/2022 07:09:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.27 on epoch=148
06/02/2022 07:09:59 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.21 on epoch=149
06/02/2022 07:10:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.14 on epoch=149
06/02/2022 07:10:05 - INFO - __main__ - Global step 2100 Train loss 0.20 Classification-F1 0.6723011327996398 on epoch=149
06/02/2022 07:10:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.23 on epoch=150
06/02/2022 07:10:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.19 on epoch=151
06/02/2022 07:10:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.26 on epoch=152
06/02/2022 07:10:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.18 on epoch=152
06/02/2022 07:10:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.16 on epoch=153
06/02/2022 07:10:15 - INFO - __main__ - Global step 2150 Train loss 0.20 Classification-F1 0.763841080381758 on epoch=153
06/02/2022 07:10:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.21 on epoch=154
06/02/2022 07:10:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.15 on epoch=154
06/02/2022 07:10:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.17 on epoch=155
06/02/2022 07:10:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.21 on epoch=156
06/02/2022 07:10:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.19 on epoch=157
06/02/2022 07:10:25 - INFO - __main__ - Global step 2200 Train loss 0.19 Classification-F1 0.800606801528311 on epoch=157
06/02/2022 07:10:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.14 on epoch=157
06/02/2022 07:10:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.18 on epoch=158
06/02/2022 07:10:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.16 on epoch=159
06/02/2022 07:10:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.15 on epoch=159
06/02/2022 07:10:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.12 on epoch=160
06/02/2022 07:10:35 - INFO - __main__ - Global step 2250 Train loss 0.15 Classification-F1 0.8853994315111244 on epoch=160
06/02/2022 07:10:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.25 on epoch=161
06/02/2022 07:10:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.13 on epoch=162
06/02/2022 07:10:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=162
06/02/2022 07:10:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.17 on epoch=163
06/02/2022 07:10:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.17 on epoch=164
06/02/2022 07:10:45 - INFO - __main__ - Global step 2300 Train loss 0.17 Classification-F1 0.9186090324712488 on epoch=164
06/02/2022 07:10:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8880704181802626 -> 0.9186090324712488 on epoch=164, global_step=2300
06/02/2022 07:10:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.13 on epoch=164
06/02/2022 07:10:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.20 on epoch=165
06/02/2022 07:10:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.12 on epoch=166
06/02/2022 07:10:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=167
06/02/2022 07:10:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.19 on epoch=167
06/02/2022 07:10:55 - INFO - __main__ - Global step 2350 Train loss 0.15 Classification-F1 0.8135341627381394 on epoch=167
06/02/2022 07:10:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.15 on epoch=168
06/02/2022 07:10:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.15 on epoch=169
06/02/2022 07:10:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.12 on epoch=169
06/02/2022 07:11:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.16 on epoch=170
06/02/2022 07:11:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.17 on epoch=171
06/02/2022 07:11:05 - INFO - __main__ - Global step 2400 Train loss 0.15 Classification-F1 0.7584061114952928 on epoch=171
06/02/2022 07:11:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.15 on epoch=172
06/02/2022 07:11:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.14 on epoch=172
06/02/2022 07:11:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=173
06/02/2022 07:11:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.15 on epoch=174
06/02/2022 07:11:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.21 on epoch=174
06/02/2022 07:11:15 - INFO - __main__ - Global step 2450 Train loss 0.16 Classification-F1 0.8074710428526249 on epoch=174
06/02/2022 07:11:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.13 on epoch=175
06/02/2022 07:11:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.11 on epoch=176
06/02/2022 07:11:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.13 on epoch=177
06/02/2022 07:11:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.12 on epoch=177
06/02/2022 07:11:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.13 on epoch=178
06/02/2022 07:11:26 - INFO - __main__ - Global step 2500 Train loss 0.13 Classification-F1 0.6758760082634477 on epoch=178
06/02/2022 07:11:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.13 on epoch=179
06/02/2022 07:11:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.18 on epoch=179
06/02/2022 07:11:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.17 on epoch=180
06/02/2022 07:11:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.14 on epoch=181
06/02/2022 07:11:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.12 on epoch=182
06/02/2022 07:11:36 - INFO - __main__ - Global step 2550 Train loss 0.15 Classification-F1 0.6811827545149657 on epoch=182
06/02/2022 07:11:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.19 on epoch=182
06/02/2022 07:11:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.14 on epoch=183
06/02/2022 07:11:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.20 on epoch=184
06/02/2022 07:11:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.14 on epoch=184
06/02/2022 07:11:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=185
06/02/2022 07:11:46 - INFO - __main__ - Global step 2600 Train loss 0.15 Classification-F1 0.823604649255546 on epoch=185
06/02/2022 07:11:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.12 on epoch=186
06/02/2022 07:11:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.15 on epoch=187
06/02/2022 07:11:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.13 on epoch=187
06/02/2022 07:11:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.15 on epoch=188
06/02/2022 07:11:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.12 on epoch=189
06/02/2022 07:11:56 - INFO - __main__ - Global step 2650 Train loss 0.14 Classification-F1 0.8311633056815101 on epoch=189
06/02/2022 07:11:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.13 on epoch=189
06/02/2022 07:11:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.14 on epoch=190
06/02/2022 07:12:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.16 on epoch=191
06/02/2022 07:12:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.12 on epoch=192
06/02/2022 07:12:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.13 on epoch=192
06/02/2022 07:12:06 - INFO - __main__ - Global step 2700 Train loss 0.14 Classification-F1 0.7511168413838046 on epoch=192
06/02/2022 07:12:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.12 on epoch=193
06/02/2022 07:12:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.15 on epoch=194
06/02/2022 07:12:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.13 on epoch=194
06/02/2022 07:12:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.13 on epoch=195
06/02/2022 07:12:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=196
06/02/2022 07:12:16 - INFO - __main__ - Global step 2750 Train loss 0.13 Classification-F1 0.625346171197857 on epoch=196
06/02/2022 07:12:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.13 on epoch=197
06/02/2022 07:12:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.12 on epoch=197
06/02/2022 07:12:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=198
06/02/2022 07:12:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=199
06/02/2022 07:12:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.10 on epoch=199
06/02/2022 07:12:27 - INFO - __main__ - Global step 2800 Train loss 0.11 Classification-F1 0.6644411823913903 on epoch=199
06/02/2022 07:12:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.17 on epoch=200
06/02/2022 07:12:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.11 on epoch=201
06/02/2022 07:12:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.14 on epoch=202
06/02/2022 07:12:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.14 on epoch=202
06/02/2022 07:12:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
06/02/2022 07:12:37 - INFO - __main__ - Global step 2850 Train loss 0.12 Classification-F1 0.5900566169846851 on epoch=203
06/02/2022 07:12:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.12 on epoch=204
06/02/2022 07:12:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.13 on epoch=204
06/02/2022 07:12:41 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.09 on epoch=205
06/02/2022 07:12:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=206
06/02/2022 07:12:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=207
06/02/2022 07:12:47 - INFO - __main__ - Global step 2900 Train loss 0.10 Classification-F1 0.7599558263779083 on epoch=207
06/02/2022 07:12:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.13 on epoch=207
06/02/2022 07:12:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.11 on epoch=208
06/02/2022 07:12:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=209
06/02/2022 07:12:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.11 on epoch=209
06/02/2022 07:12:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=210
06/02/2022 07:12:57 - INFO - __main__ - Global step 2950 Train loss 0.11 Classification-F1 0.7690801106152074 on epoch=210
06/02/2022 07:12:58 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/02/2022 07:13:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.13 on epoch=212
06/02/2022 07:13:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.13 on epoch=212
06/02/2022 07:13:02 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.10 on epoch=213
06/02/2022 07:13:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=214
06/02/2022 07:13:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:13:04 - INFO - __main__ - Printing 3 examples
06/02/2022 07:13:04 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 07:13:04 - INFO - __main__ - ['Animal']
06/02/2022 07:13:04 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 07:13:04 - INFO - __main__ - ['Animal']
06/02/2022 07:13:04 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 07:13:04 - INFO - __main__ - ['Animal']
06/02/2022 07:13:04 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:13:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:13:05 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:13:05 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:13:05 - INFO - __main__ - Printing 3 examples
06/02/2022 07:13:05 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 07:13:05 - INFO - __main__ - ['Animal']
06/02/2022 07:13:05 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 07:13:05 - INFO - __main__ - ['Animal']
06/02/2022 07:13:05 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 07:13:05 - INFO - __main__ - ['Animal']
06/02/2022 07:13:05 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:13:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:13:05 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:13:07 - INFO - __main__ - Global step 3000 Train loss 0.10 Classification-F1 0.7651208345650652 on epoch=214
06/02/2022 07:13:07 - INFO - __main__ - save last model!
06/02/2022 07:13:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 07:13:07 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 07:13:07 - INFO - __main__ - Printing 3 examples
06/02/2022 07:13:07 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 07:13:07 - INFO - __main__ - ['Animal']
06/02/2022 07:13:07 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 07:13:07 - INFO - __main__ - ['Animal']
06/02/2022 07:13:07 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 07:13:07 - INFO - __main__ - ['Village']
06/02/2022 07:13:07 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:13:09 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:13:11 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:13:11 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:13:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:13:12 - INFO - __main__ - Starting training!
06/02/2022 07:13:12 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 07:14:23 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/02/2022 07:14:23 - INFO - __main__ - Classification-F1 on test data: 0.5161
06/02/2022 07:14:23 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9186090324712488, test_performance=0.516115612298006
06/02/2022 07:14:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/02/2022 07:14:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:14:24 - INFO - __main__ - Printing 3 examples
06/02/2022 07:14:24 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/02/2022 07:14:24 - INFO - __main__ - ['Animal']
06/02/2022 07:14:24 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/02/2022 07:14:24 - INFO - __main__ - ['Animal']
06/02/2022 07:14:24 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
06/02/2022 07:14:24 - INFO - __main__ - ['Animal']
06/02/2022 07:14:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:14:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:14:25 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:14:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:14:25 - INFO - __main__ - Printing 3 examples
06/02/2022 07:14:25 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/02/2022 07:14:25 - INFO - __main__ - ['Animal']
06/02/2022 07:14:25 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/02/2022 07:14:25 - INFO - __main__ - ['Animal']
06/02/2022 07:14:25 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/02/2022 07:14:25 - INFO - __main__ - ['Animal']
06/02/2022 07:14:25 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:14:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:14:25 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:14:31 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:14:31 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:14:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:14:31 - INFO - __main__ - Starting training!
06/02/2022 07:14:33 - INFO - __main__ - Step 10 Global step 10 Train loss 6.66 on epoch=0
06/02/2022 07:14:34 - INFO - __main__ - Step 20 Global step 20 Train loss 6.43 on epoch=1
06/02/2022 07:14:35 - INFO - __main__ - Step 30 Global step 30 Train loss 5.48 on epoch=2
06/02/2022 07:14:36 - INFO - __main__ - Step 40 Global step 40 Train loss 5.00 on epoch=2
06/02/2022 07:14:38 - INFO - __main__ - Step 50 Global step 50 Train loss 4.67 on epoch=3
06/02/2022 07:15:24 - INFO - __main__ - Global step 50 Train loss 5.65 Classification-F1 0.0 on epoch=3
06/02/2022 07:15:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 07:15:25 - INFO - __main__ - Step 60 Global step 60 Train loss 4.36 on epoch=4
06/02/2022 07:15:27 - INFO - __main__ - Step 70 Global step 70 Train loss 3.70 on epoch=4
06/02/2022 07:15:28 - INFO - __main__ - Step 80 Global step 80 Train loss 3.13 on epoch=5
06/02/2022 07:15:29 - INFO - __main__ - Step 90 Global step 90 Train loss 2.94 on epoch=6
06/02/2022 07:15:31 - INFO - __main__ - Step 100 Global step 100 Train loss 2.82 on epoch=7
06/02/2022 07:15:35 - INFO - __main__ - Global step 100 Train loss 3.39 Classification-F1 0.17376397167621244 on epoch=7
06/02/2022 07:15:35 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.17376397167621244 on epoch=7, global_step=100
06/02/2022 07:15:36 - INFO - __main__ - Step 110 Global step 110 Train loss 2.48 on epoch=7
06/02/2022 07:15:37 - INFO - __main__ - Step 120 Global step 120 Train loss 2.36 on epoch=8
06/02/2022 07:15:39 - INFO - __main__ - Step 130 Global step 130 Train loss 2.23 on epoch=9
06/02/2022 07:15:40 - INFO - __main__ - Step 140 Global step 140 Train loss 1.96 on epoch=9
06/02/2022 07:15:41 - INFO - __main__ - Step 150 Global step 150 Train loss 1.91 on epoch=10
06/02/2022 07:15:47 - INFO - __main__ - Global step 150 Train loss 2.19 Classification-F1 0.25426621955160444 on epoch=10
06/02/2022 07:15:48 - INFO - __main__ - Saving model with best Classification-F1: 0.17376397167621244 -> 0.25426621955160444 on epoch=10, global_step=150
06/02/2022 07:15:49 - INFO - __main__ - Step 160 Global step 160 Train loss 1.85 on epoch=11
06/02/2022 07:15:50 - INFO - __main__ - Step 170 Global step 170 Train loss 1.69 on epoch=12
06/02/2022 07:15:51 - INFO - __main__ - Step 180 Global step 180 Train loss 1.56 on epoch=12
06/02/2022 07:15:53 - INFO - __main__ - Step 190 Global step 190 Train loss 1.59 on epoch=13
06/02/2022 07:15:54 - INFO - __main__ - Step 200 Global step 200 Train loss 1.46 on epoch=14
06/02/2022 07:15:58 - INFO - __main__ - Global step 200 Train loss 1.63 Classification-F1 0.4198281641968698 on epoch=14
06/02/2022 07:15:58 - INFO - __main__ - Saving model with best Classification-F1: 0.25426621955160444 -> 0.4198281641968698 on epoch=14, global_step=200
06/02/2022 07:15:59 - INFO - __main__ - Step 210 Global step 210 Train loss 1.49 on epoch=14
06/02/2022 07:16:01 - INFO - __main__ - Step 220 Global step 220 Train loss 1.29 on epoch=15
06/02/2022 07:16:02 - INFO - __main__ - Step 230 Global step 230 Train loss 1.32 on epoch=16
06/02/2022 07:16:03 - INFO - __main__ - Step 240 Global step 240 Train loss 1.33 on epoch=17
06/02/2022 07:16:04 - INFO - __main__ - Step 250 Global step 250 Train loss 1.22 on epoch=17
06/02/2022 07:16:08 - INFO - __main__ - Global step 250 Train loss 1.33 Classification-F1 0.4102725649097534 on epoch=17
06/02/2022 07:16:10 - INFO - __main__ - Step 260 Global step 260 Train loss 1.18 on epoch=18
06/02/2022 07:16:11 - INFO - __main__ - Step 270 Global step 270 Train loss 1.28 on epoch=19
06/02/2022 07:16:12 - INFO - __main__ - Step 280 Global step 280 Train loss 1.20 on epoch=19
06/02/2022 07:16:13 - INFO - __main__ - Step 290 Global step 290 Train loss 1.05 on epoch=20
06/02/2022 07:16:15 - INFO - __main__ - Step 300 Global step 300 Train loss 1.02 on epoch=21
06/02/2022 07:16:18 - INFO - __main__ - Global step 300 Train loss 1.15 Classification-F1 0.5012209770220606 on epoch=21
06/02/2022 07:16:18 - INFO - __main__ - Saving model with best Classification-F1: 0.4198281641968698 -> 0.5012209770220606 on epoch=21, global_step=300
06/02/2022 07:16:19 - INFO - __main__ - Step 310 Global step 310 Train loss 1.15 on epoch=22
06/02/2022 07:16:21 - INFO - __main__ - Step 320 Global step 320 Train loss 1.07 on epoch=22
06/02/2022 07:16:22 - INFO - __main__ - Step 330 Global step 330 Train loss 1.04 on epoch=23
06/02/2022 07:16:23 - INFO - __main__ - Step 340 Global step 340 Train loss 1.04 on epoch=24
06/02/2022 07:16:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.96 on epoch=24
06/02/2022 07:16:28 - INFO - __main__ - Global step 350 Train loss 1.05 Classification-F1 0.5607550742028095 on epoch=24
06/02/2022 07:16:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5012209770220606 -> 0.5607550742028095 on epoch=24, global_step=350
06/02/2022 07:16:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.95 on epoch=25
06/02/2022 07:16:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.90 on epoch=26
06/02/2022 07:16:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.80 on epoch=27
06/02/2022 07:16:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.77 on epoch=27
06/02/2022 07:16:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.84 on epoch=28
06/02/2022 07:16:38 - INFO - __main__ - Global step 400 Train loss 0.85 Classification-F1 0.543429979936089 on epoch=28
06/02/2022 07:16:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.80 on epoch=29
06/02/2022 07:16:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.80 on epoch=29
06/02/2022 07:16:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.81 on epoch=30
06/02/2022 07:16:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.92 on epoch=31
06/02/2022 07:16:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.83 on epoch=32
06/02/2022 07:16:48 - INFO - __main__ - Global step 450 Train loss 0.83 Classification-F1 0.5700472784832589 on epoch=32
06/02/2022 07:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5607550742028095 -> 0.5700472784832589 on epoch=32, global_step=450
06/02/2022 07:16:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.84 on epoch=32
06/02/2022 07:16:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.70 on epoch=33
06/02/2022 07:16:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.75 on epoch=34
06/02/2022 07:16:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.75 on epoch=34
06/02/2022 07:16:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.74 on epoch=35
06/02/2022 07:16:58 - INFO - __main__ - Global step 500 Train loss 0.76 Classification-F1 0.722622718852419 on epoch=35
06/02/2022 07:16:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5700472784832589 -> 0.722622718852419 on epoch=35, global_step=500
06/02/2022 07:16:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.77 on epoch=36
06/02/2022 07:17:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.76 on epoch=37
06/02/2022 07:17:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.70 on epoch=37
06/02/2022 07:17:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.74 on epoch=38
06/02/2022 07:17:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.75 on epoch=39
06/02/2022 07:17:08 - INFO - __main__ - Global step 550 Train loss 0.74 Classification-F1 0.612698760118115 on epoch=39
06/02/2022 07:17:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.75 on epoch=39
06/02/2022 07:17:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.73 on epoch=40
06/02/2022 07:17:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.69 on epoch=41
06/02/2022 07:17:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.73 on epoch=42
06/02/2022 07:17:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.65 on epoch=42
06/02/2022 07:17:18 - INFO - __main__ - Global step 600 Train loss 0.71 Classification-F1 0.6352214115916313 on epoch=42
06/02/2022 07:17:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.60 on epoch=43
06/02/2022 07:17:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.61 on epoch=44
06/02/2022 07:17:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.65 on epoch=44
06/02/2022 07:17:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.68 on epoch=45
06/02/2022 07:17:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.67 on epoch=46
06/02/2022 07:17:28 - INFO - __main__ - Global step 650 Train loss 0.64 Classification-F1 0.6099166691569586 on epoch=46
06/02/2022 07:17:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.62 on epoch=47
06/02/2022 07:17:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.63 on epoch=47
06/02/2022 07:17:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.57 on epoch=48
06/02/2022 07:17:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.73 on epoch=49
06/02/2022 07:17:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.60 on epoch=49
06/02/2022 07:17:38 - INFO - __main__ - Global step 700 Train loss 0.63 Classification-F1 0.6533927436856755 on epoch=49
06/02/2022 07:17:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.65 on epoch=50
06/02/2022 07:17:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.61 on epoch=51
06/02/2022 07:17:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.66 on epoch=52
06/02/2022 07:17:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.68 on epoch=52
06/02/2022 07:17:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.57 on epoch=53
06/02/2022 07:17:48 - INFO - __main__ - Global step 750 Train loss 0.63 Classification-F1 0.7055999537616021 on epoch=53
06/02/2022 07:17:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.54 on epoch=54
06/02/2022 07:17:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.60 on epoch=54
06/02/2022 07:17:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.64 on epoch=55
06/02/2022 07:17:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.55 on epoch=56
06/02/2022 07:17:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.53 on epoch=57
06/02/2022 07:17:58 - INFO - __main__ - Global step 800 Train loss 0.57 Classification-F1 0.6563269778524838 on epoch=57
06/02/2022 07:18:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.51 on epoch=57
06/02/2022 07:18:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.50 on epoch=58
06/02/2022 07:18:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.49 on epoch=59
06/02/2022 07:18:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.51 on epoch=59
06/02/2022 07:18:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.52 on epoch=60
06/02/2022 07:18:09 - INFO - __main__ - Global step 850 Train loss 0.51 Classification-F1 0.650287204788573 on epoch=60
06/02/2022 07:18:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.55 on epoch=61
06/02/2022 07:18:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.59 on epoch=62
06/02/2022 07:18:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.49 on epoch=62
06/02/2022 07:18:14 - INFO - __main__ - Step 890 Global step 890 Train loss 0.45 on epoch=63
06/02/2022 07:18:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.48 on epoch=64
06/02/2022 07:18:19 - INFO - __main__ - Global step 900 Train loss 0.51 Classification-F1 0.6957417328255988 on epoch=64
06/02/2022 07:18:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.56 on epoch=64
06/02/2022 07:18:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.42 on epoch=65
06/02/2022 07:18:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.43 on epoch=66
06/02/2022 07:18:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.50 on epoch=67
06/02/2022 07:18:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.44 on epoch=67
06/02/2022 07:18:29 - INFO - __main__ - Global step 950 Train loss 0.47 Classification-F1 0.746652596861601 on epoch=67
06/02/2022 07:18:29 - INFO - __main__ - Saving model with best Classification-F1: 0.722622718852419 -> 0.746652596861601 on epoch=67, global_step=950
06/02/2022 07:18:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.44 on epoch=68
06/02/2022 07:18:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.50 on epoch=69
06/02/2022 07:18:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.40 on epoch=69
06/02/2022 07:18:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.40 on epoch=70
06/02/2022 07:18:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.38 on epoch=71
06/02/2022 07:18:39 - INFO - __main__ - Global step 1000 Train loss 0.42 Classification-F1 0.6971130348146477 on epoch=71
06/02/2022 07:18:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.49 on epoch=72
06/02/2022 07:18:41 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.56 on epoch=72
06/02/2022 07:18:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.41 on epoch=73
06/02/2022 07:18:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.43 on epoch=74
06/02/2022 07:18:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.45 on epoch=74
06/02/2022 07:18:48 - INFO - __main__ - Global step 1050 Train loss 0.47 Classification-F1 0.7101016521131148 on epoch=74
06/02/2022 07:18:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.41 on epoch=75
06/02/2022 07:18:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.37 on epoch=76
06/02/2022 07:18:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.45 on epoch=77
06/02/2022 07:18:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.47 on epoch=77
06/02/2022 07:18:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.35 on epoch=78
06/02/2022 07:18:59 - INFO - __main__ - Global step 1100 Train loss 0.41 Classification-F1 0.7758757412427953 on epoch=78
06/02/2022 07:18:59 - INFO - __main__ - Saving model with best Classification-F1: 0.746652596861601 -> 0.7758757412427953 on epoch=78, global_step=1100
06/02/2022 07:19:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.42 on epoch=79
06/02/2022 07:19:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.44 on epoch=79
06/02/2022 07:19:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.39 on epoch=80
06/02/2022 07:19:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.42 on epoch=81
06/02/2022 07:19:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.53 on epoch=82
06/02/2022 07:19:09 - INFO - __main__ - Global step 1150 Train loss 0.44 Classification-F1 0.7061005042184656 on epoch=82
06/02/2022 07:19:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.35 on epoch=82
06/02/2022 07:19:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.38 on epoch=83
06/02/2022 07:19:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.37 on epoch=84
06/02/2022 07:19:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.32 on epoch=84
06/02/2022 07:19:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.41 on epoch=85
06/02/2022 07:19:19 - INFO - __main__ - Global step 1200 Train loss 0.37 Classification-F1 0.8700502175454737 on epoch=85
06/02/2022 07:19:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7758757412427953 -> 0.8700502175454737 on epoch=85, global_step=1200
06/02/2022 07:19:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.36 on epoch=86
06/02/2022 07:19:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.40 on epoch=87
06/02/2022 07:19:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.41 on epoch=87
06/02/2022 07:19:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.33 on epoch=88
06/02/2022 07:19:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.40 on epoch=89
06/02/2022 07:19:30 - INFO - __main__ - Global step 1250 Train loss 0.38 Classification-F1 0.6867006687602413 on epoch=89
06/02/2022 07:19:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.36 on epoch=89
06/02/2022 07:19:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.37 on epoch=90
06/02/2022 07:19:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.34 on epoch=91
06/02/2022 07:19:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.36 on epoch=92
06/02/2022 07:19:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.29 on epoch=92
06/02/2022 07:19:40 - INFO - __main__ - Global step 1300 Train loss 0.34 Classification-F1 0.6532301665128989 on epoch=92
06/02/2022 07:19:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.30 on epoch=93
06/02/2022 07:19:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=94
06/02/2022 07:19:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.38 on epoch=94
06/02/2022 07:19:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.37 on epoch=95
06/02/2022 07:19:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.27 on epoch=96
06/02/2022 07:19:50 - INFO - __main__ - Global step 1350 Train loss 0.31 Classification-F1 0.8391857720605349 on epoch=96
06/02/2022 07:19:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.34 on epoch=97
06/02/2022 07:19:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.28 on epoch=97
06/02/2022 07:19:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.24 on epoch=98
06/02/2022 07:19:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.29 on epoch=99
06/02/2022 07:19:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.29 on epoch=99
06/02/2022 07:20:00 - INFO - __main__ - Global step 1400 Train loss 0.29 Classification-F1 0.7734858111133016 on epoch=99
06/02/2022 07:20:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.29 on epoch=100
06/02/2022 07:20:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.29 on epoch=101
06/02/2022 07:20:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.26 on epoch=102
06/02/2022 07:20:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.27 on epoch=102
06/02/2022 07:20:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.26 on epoch=103
06/02/2022 07:20:11 - INFO - __main__ - Global step 1450 Train loss 0.28 Classification-F1 0.8805938416422286 on epoch=103
06/02/2022 07:20:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8700502175454737 -> 0.8805938416422286 on epoch=103, global_step=1450
06/02/2022 07:20:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.28 on epoch=104
06/02/2022 07:20:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.29 on epoch=104
06/02/2022 07:20:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.26 on epoch=105
06/02/2022 07:20:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.22 on epoch=106
06/02/2022 07:20:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.23 on epoch=107
06/02/2022 07:20:22 - INFO - __main__ - Global step 1500 Train loss 0.26 Classification-F1 0.813489966879916 on epoch=107
06/02/2022 07:20:23 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.25 on epoch=107
06/02/2022 07:20:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.28 on epoch=108
06/02/2022 07:20:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.30 on epoch=109
06/02/2022 07:20:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.20 on epoch=109
06/02/2022 07:20:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.25 on epoch=110
06/02/2022 07:20:32 - INFO - __main__ - Global step 1550 Train loss 0.26 Classification-F1 0.6844386442646204 on epoch=110
06/02/2022 07:20:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.22 on epoch=111
06/02/2022 07:20:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.22 on epoch=112
06/02/2022 07:20:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.20 on epoch=112
06/02/2022 07:20:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.21 on epoch=113
06/02/2022 07:20:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.25 on epoch=114
06/02/2022 07:20:43 - INFO - __main__ - Global step 1600 Train loss 0.22 Classification-F1 0.9374076096714344 on epoch=114
06/02/2022 07:20:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8805938416422286 -> 0.9374076096714344 on epoch=114, global_step=1600
06/02/2022 07:20:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.28 on epoch=114
06/02/2022 07:20:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.18 on epoch=115
06/02/2022 07:20:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.24 on epoch=116
06/02/2022 07:20:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.28 on epoch=117
06/02/2022 07:20:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.20 on epoch=117
06/02/2022 07:20:54 - INFO - __main__ - Global step 1650 Train loss 0.24 Classification-F1 0.879455455556679 on epoch=117
06/02/2022 07:20:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/02/2022 07:20:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.27 on epoch=119
06/02/2022 07:20:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
06/02/2022 07:20:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.21 on epoch=120
06/02/2022 07:21:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.23 on epoch=121
06/02/2022 07:21:04 - INFO - __main__ - Global step 1700 Train loss 0.20 Classification-F1 0.8824175571060998 on epoch=121
06/02/2022 07:21:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.18 on epoch=122
06/02/2022 07:21:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
06/02/2022 07:21:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=123
06/02/2022 07:21:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.22 on epoch=124
06/02/2022 07:21:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=124
06/02/2022 07:21:15 - INFO - __main__ - Global step 1750 Train loss 0.16 Classification-F1 0.8863316985202412 on epoch=124
06/02/2022 07:21:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=125
06/02/2022 07:21:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.20 on epoch=126
06/02/2022 07:21:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.22 on epoch=127
06/02/2022 07:21:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.22 on epoch=127
06/02/2022 07:21:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=128
06/02/2022 07:21:25 - INFO - __main__ - Global step 1800 Train loss 0.18 Classification-F1 0.7333937493211686 on epoch=128
06/02/2022 07:21:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.28 on epoch=129
06/02/2022 07:21:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.18 on epoch=129
06/02/2022 07:21:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=130
06/02/2022 07:21:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.14 on epoch=131
06/02/2022 07:21:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=132
06/02/2022 07:21:36 - INFO - __main__ - Global step 1850 Train loss 0.18 Classification-F1 0.7073487369858338 on epoch=132
06/02/2022 07:21:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.20 on epoch=132
06/02/2022 07:21:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.20 on epoch=133
06/02/2022 07:21:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.23 on epoch=134
06/02/2022 07:21:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.25 on epoch=134
06/02/2022 07:21:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.18 on epoch=135
06/02/2022 07:21:46 - INFO - __main__ - Global step 1900 Train loss 0.21 Classification-F1 0.7697609588190115 on epoch=135
06/02/2022 07:21:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=136
06/02/2022 07:21:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.19 on epoch=137
06/02/2022 07:21:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.20 on epoch=137
06/02/2022 07:21:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=138
06/02/2022 07:21:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.16 on epoch=139
06/02/2022 07:21:56 - INFO - __main__ - Global step 1950 Train loss 0.16 Classification-F1 0.7245527605556626 on epoch=139
06/02/2022 07:21:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.16 on epoch=139
06/02/2022 07:21:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.14 on epoch=140
06/02/2022 07:22:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=141
06/02/2022 07:22:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.14 on epoch=142
06/02/2022 07:22:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.14 on epoch=142
06/02/2022 07:22:07 - INFO - __main__ - Global step 2000 Train loss 0.14 Classification-F1 0.771731247484331 on epoch=142
06/02/2022 07:22:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=143
06/02/2022 07:22:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/02/2022 07:22:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.16 on epoch=144
06/02/2022 07:22:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.16 on epoch=145
06/02/2022 07:22:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=146
06/02/2022 07:22:18 - INFO - __main__ - Global step 2050 Train loss 0.13 Classification-F1 0.7497461076892376 on epoch=146
06/02/2022 07:22:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=147
06/02/2022 07:22:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.14 on epoch=147
06/02/2022 07:22:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=148
06/02/2022 07:22:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.19 on epoch=149
06/02/2022 07:22:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.15 on epoch=149
06/02/2022 07:22:28 - INFO - __main__ - Global step 2100 Train loss 0.15 Classification-F1 0.7551654966461914 on epoch=149
06/02/2022 07:22:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=150
06/02/2022 07:22:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.12 on epoch=151
06/02/2022 07:22:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=152
06/02/2022 07:22:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.16 on epoch=152
06/02/2022 07:22:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
06/02/2022 07:22:39 - INFO - __main__ - Global step 2150 Train loss 0.12 Classification-F1 0.8221791962956575 on epoch=153
06/02/2022 07:22:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.16 on epoch=154
06/02/2022 07:22:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=154
06/02/2022 07:22:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.21 on epoch=155
06/02/2022 07:22:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.14 on epoch=156
06/02/2022 07:22:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.22 on epoch=157
06/02/2022 07:22:49 - INFO - __main__ - Global step 2200 Train loss 0.17 Classification-F1 0.7109864457350227 on epoch=157
06/02/2022 07:22:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=157
06/02/2022 07:22:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=158
06/02/2022 07:22:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.17 on epoch=159
06/02/2022 07:22:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.15 on epoch=159
06/02/2022 07:22:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.15 on epoch=160
06/02/2022 07:23:00 - INFO - __main__ - Global step 2250 Train loss 0.14 Classification-F1 0.7601634849127952 on epoch=160
06/02/2022 07:23:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.17 on epoch=161
06/02/2022 07:23:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.13 on epoch=162
06/02/2022 07:23:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=162
06/02/2022 07:23:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/02/2022 07:23:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=164
06/02/2022 07:23:10 - INFO - __main__ - Global step 2300 Train loss 0.13 Classification-F1 0.7713801127122404 on epoch=164
06/02/2022 07:23:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.16 on epoch=164
06/02/2022 07:23:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=165
06/02/2022 07:23:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/02/2022 07:23:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=167
06/02/2022 07:23:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/02/2022 07:23:21 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.7488996194152149 on epoch=167
06/02/2022 07:23:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.09 on epoch=168
06/02/2022 07:23:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.11 on epoch=169
06/02/2022 07:23:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.14 on epoch=169
06/02/2022 07:23:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=170
06/02/2022 07:23:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=171
06/02/2022 07:23:31 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.81328125 on epoch=171
06/02/2022 07:23:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.15 on epoch=172
06/02/2022 07:23:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.09 on epoch=172
06/02/2022 07:23:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.12 on epoch=173
06/02/2022 07:23:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=174
06/02/2022 07:23:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.12 on epoch=174
06/02/2022 07:23:42 - INFO - __main__ - Global step 2450 Train loss 0.12 Classification-F1 0.7211408915258782 on epoch=174
06/02/2022 07:23:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=175
06/02/2022 07:23:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/02/2022 07:23:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/02/2022 07:23:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.12 on epoch=177
06/02/2022 07:23:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=178
06/02/2022 07:23:52 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.8175235131132308 on epoch=178
06/02/2022 07:23:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.21 on epoch=179
06/02/2022 07:23:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
06/02/2022 07:23:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.11 on epoch=180
06/02/2022 07:23:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=181
06/02/2022 07:23:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.12 on epoch=182
06/02/2022 07:24:03 - INFO - __main__ - Global step 2550 Train loss 0.12 Classification-F1 0.8726122227972323 on epoch=182
06/02/2022 07:24:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.13 on epoch=182
06/02/2022 07:24:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.11 on epoch=183
06/02/2022 07:24:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=184
06/02/2022 07:24:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.15 on epoch=184
06/02/2022 07:24:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.09 on epoch=185
06/02/2022 07:24:13 - INFO - __main__ - Global step 2600 Train loss 0.11 Classification-F1 0.8222613156332914 on epoch=185
06/02/2022 07:24:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=186
06/02/2022 07:24:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.15 on epoch=187
06/02/2022 07:24:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/02/2022 07:24:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/02/2022 07:24:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=189
06/02/2022 07:24:24 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.8371003447705809 on epoch=189
06/02/2022 07:24:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=189
06/02/2022 07:24:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=190
06/02/2022 07:24:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.09 on epoch=191
06/02/2022 07:24:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=192
06/02/2022 07:24:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.11 on epoch=192
06/02/2022 07:24:34 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.8047579898515681 on epoch=192
06/02/2022 07:24:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=193
06/02/2022 07:24:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/02/2022 07:24:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=194
06/02/2022 07:24:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=195
06/02/2022 07:24:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=196
06/02/2022 07:24:45 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.7598983791039873 on epoch=196
06/02/2022 07:24:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=197
06/02/2022 07:24:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=197
06/02/2022 07:24:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=198
06/02/2022 07:24:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.11 on epoch=199
06/02/2022 07:24:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
06/02/2022 07:24:55 - INFO - __main__ - Global step 2800 Train loss 0.09 Classification-F1 0.8125481052589093 on epoch=199
06/02/2022 07:24:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
06/02/2022 07:24:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=201
06/02/2022 07:24:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=202
06/02/2022 07:25:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=202
06/02/2022 07:25:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=203
06/02/2022 07:25:06 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.7763651717371441 on epoch=203
06/02/2022 07:25:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=204
06/02/2022 07:25:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
06/02/2022 07:25:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=205
06/02/2022 07:25:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.10 on epoch=206
06/02/2022 07:25:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.15 on epoch=207
06/02/2022 07:25:16 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.8093580192340866 on epoch=207
06/02/2022 07:25:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/02/2022 07:25:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=208
06/02/2022 07:25:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.11 on epoch=209
06/02/2022 07:25:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=209
06/02/2022 07:25:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=210
06/02/2022 07:25:27 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.9414308098606011 on epoch=210
06/02/2022 07:25:27 - INFO - __main__ - Saving model with best Classification-F1: 0.9374076096714344 -> 0.9414308098606011 on epoch=210, global_step=2950
06/02/2022 07:25:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
06/02/2022 07:25:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.12 on epoch=212
06/02/2022 07:25:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=212
06/02/2022 07:25:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
06/02/2022 07:25:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.10 on epoch=214
06/02/2022 07:25:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:25:34 - INFO - __main__ - Printing 3 examples
06/02/2022 07:25:34 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 07:25:34 - INFO - __main__ - ['Plant']
06/02/2022 07:25:34 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 07:25:34 - INFO - __main__ - ['Plant']
06/02/2022 07:25:34 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 07:25:34 - INFO - __main__ - ['Plant']
06/02/2022 07:25:34 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:25:34 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:25:35 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:25:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:25:35 - INFO - __main__ - Printing 3 examples
06/02/2022 07:25:35 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 07:25:35 - INFO - __main__ - ['Plant']
06/02/2022 07:25:35 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 07:25:35 - INFO - __main__ - ['Plant']
06/02/2022 07:25:35 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 07:25:35 - INFO - __main__ - ['Plant']
06/02/2022 07:25:35 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:25:35 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:25:35 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:25:37 - INFO - __main__ - Global step 3000 Train loss 0.09 Classification-F1 0.9330914697257201 on epoch=214
06/02/2022 07:25:37 - INFO - __main__ - save last model!
06/02/2022 07:25:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 07:25:37 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 07:25:37 - INFO - __main__ - Printing 3 examples
06/02/2022 07:25:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 07:25:37 - INFO - __main__ - ['Animal']
06/02/2022 07:25:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 07:25:37 - INFO - __main__ - ['Animal']
06/02/2022 07:25:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 07:25:37 - INFO - __main__ - ['Village']
06/02/2022 07:25:37 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:25:39 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:25:40 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:25:40 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:25:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:25:41 - INFO - __main__ - Starting training!
06/02/2022 07:25:43 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 07:26:56 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/02/2022 07:26:56 - INFO - __main__ - Classification-F1 on test data: 0.6371
06/02/2022 07:26:56 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9414308098606011, test_performance=0.637128364631676
06/02/2022 07:26:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/02/2022 07:26:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:26:57 - INFO - __main__ - Printing 3 examples
06/02/2022 07:26:57 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 07:26:57 - INFO - __main__ - ['Plant']
06/02/2022 07:26:57 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 07:26:57 - INFO - __main__ - ['Plant']
06/02/2022 07:26:57 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 07:26:57 - INFO - __main__ - ['Plant']
06/02/2022 07:26:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:26:58 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:26:58 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:26:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:26:58 - INFO - __main__ - Printing 3 examples
06/02/2022 07:26:58 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 07:26:58 - INFO - __main__ - ['Plant']
06/02/2022 07:26:58 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 07:26:58 - INFO - __main__ - ['Plant']
06/02/2022 07:26:58 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 07:26:58 - INFO - __main__ - ['Plant']
06/02/2022 07:26:58 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:26:58 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:26:58 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:27:03 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:27:03 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:27:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:27:04 - INFO - __main__ - Starting training!
06/02/2022 07:27:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.50 on epoch=0
06/02/2022 07:27:06 - INFO - __main__ - Step 20 Global step 20 Train loss 5.29 on epoch=1
06/02/2022 07:27:08 - INFO - __main__ - Step 30 Global step 30 Train loss 4.67 on epoch=2
06/02/2022 07:27:09 - INFO - __main__ - Step 40 Global step 40 Train loss 3.40 on epoch=2
06/02/2022 07:27:10 - INFO - __main__ - Step 50 Global step 50 Train loss 2.87 on epoch=3
06/02/2022 07:27:13 - INFO - __main__ - Global step 50 Train loss 4.55 Classification-F1 0.1267609408135724 on epoch=3
06/02/2022 07:27:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1267609408135724 on epoch=3, global_step=50
06/02/2022 07:27:14 - INFO - __main__ - Step 60 Global step 60 Train loss 2.25 on epoch=4
06/02/2022 07:27:15 - INFO - __main__ - Step 70 Global step 70 Train loss 2.22 on epoch=4
06/02/2022 07:27:17 - INFO - __main__ - Step 80 Global step 80 Train loss 1.79 on epoch=5
06/02/2022 07:27:18 - INFO - __main__ - Step 90 Global step 90 Train loss 1.60 on epoch=6
06/02/2022 07:27:19 - INFO - __main__ - Step 100 Global step 100 Train loss 1.67 on epoch=7
06/02/2022 07:27:22 - INFO - __main__ - Global step 100 Train loss 1.91 Classification-F1 0.4100646069231242 on epoch=7
06/02/2022 07:27:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1267609408135724 -> 0.4100646069231242 on epoch=7, global_step=100
06/02/2022 07:27:24 - INFO - __main__ - Step 110 Global step 110 Train loss 1.24 on epoch=7
06/02/2022 07:27:25 - INFO - __main__ - Step 120 Global step 120 Train loss 1.22 on epoch=8
06/02/2022 07:27:26 - INFO - __main__ - Step 130 Global step 130 Train loss 1.26 on epoch=9
06/02/2022 07:27:27 - INFO - __main__ - Step 140 Global step 140 Train loss 1.10 on epoch=9
06/02/2022 07:27:29 - INFO - __main__ - Step 150 Global step 150 Train loss 1.11 on epoch=10
06/02/2022 07:27:32 - INFO - __main__ - Global step 150 Train loss 1.19 Classification-F1 0.501990749196771 on epoch=10
06/02/2022 07:27:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4100646069231242 -> 0.501990749196771 on epoch=10, global_step=150
06/02/2022 07:27:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=11
06/02/2022 07:27:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=12
06/02/2022 07:27:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.92 on epoch=12
06/02/2022 07:27:37 - INFO - __main__ - Step 190 Global step 190 Train loss 0.90 on epoch=13
06/02/2022 07:27:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.89 on epoch=14
06/02/2022 07:27:41 - INFO - __main__ - Global step 200 Train loss 0.91 Classification-F1 0.4063498635636554 on epoch=14
06/02/2022 07:27:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=14
06/02/2022 07:27:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.69 on epoch=15
06/02/2022 07:27:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=16
06/02/2022 07:27:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.68 on epoch=17
06/02/2022 07:27:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=17
06/02/2022 07:27:51 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.5339842703258596 on epoch=17
06/02/2022 07:27:51 - INFO - __main__ - Saving model with best Classification-F1: 0.501990749196771 -> 0.5339842703258596 on epoch=17, global_step=250
06/02/2022 07:27:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=18
06/02/2022 07:27:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=19
06/02/2022 07:27:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.67 on epoch=19
06/02/2022 07:27:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=20
06/02/2022 07:27:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.66 on epoch=21
06/02/2022 07:28:01 - INFO - __main__ - Global step 300 Train loss 0.60 Classification-F1 0.5842813182350677 on epoch=21
06/02/2022 07:28:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5339842703258596 -> 0.5842813182350677 on epoch=21, global_step=300
06/02/2022 07:28:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.78 on epoch=22
06/02/2022 07:28:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.54 on epoch=22
06/02/2022 07:28:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.62 on epoch=23
06/02/2022 07:28:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.68 on epoch=24
06/02/2022 07:28:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=24
06/02/2022 07:28:12 - INFO - __main__ - Global step 350 Train loss 0.64 Classification-F1 0.6075909680658753 on epoch=24
06/02/2022 07:28:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5842813182350677 -> 0.6075909680658753 on epoch=24, global_step=350
06/02/2022 07:28:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.52 on epoch=25
06/02/2022 07:28:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=26
06/02/2022 07:28:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=27
06/02/2022 07:28:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=27
06/02/2022 07:28:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=28
06/02/2022 07:28:21 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.7009823255705928 on epoch=28
06/02/2022 07:28:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6075909680658753 -> 0.7009823255705928 on epoch=28, global_step=400
06/02/2022 07:28:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=29
06/02/2022 07:28:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.47 on epoch=29
06/02/2022 07:28:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=30
06/02/2022 07:28:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.49 on epoch=31
06/02/2022 07:28:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=32
06/02/2022 07:28:31 - INFO - __main__ - Global step 450 Train loss 0.45 Classification-F1 0.7982035590384735 on epoch=32
06/02/2022 07:28:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7009823255705928 -> 0.7982035590384735 on epoch=32, global_step=450
06/02/2022 07:28:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=32
06/02/2022 07:28:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=33
06/02/2022 07:28:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=34
06/02/2022 07:28:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=34
06/02/2022 07:28:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=35
06/02/2022 07:28:41 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.6285544377467166 on epoch=35
06/02/2022 07:28:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=36
06/02/2022 07:28:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.47 on epoch=37
06/02/2022 07:28:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/02/2022 07:28:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=38
06/02/2022 07:28:47 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=39
06/02/2022 07:28:51 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.6350206761741607 on epoch=39
06/02/2022 07:28:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=39
06/02/2022 07:28:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=40
06/02/2022 07:28:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=41
06/02/2022 07:28:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
06/02/2022 07:28:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
06/02/2022 07:29:01 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.6535462490633268 on epoch=42
06/02/2022 07:29:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.31 on epoch=43
06/02/2022 07:29:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.33 on epoch=44
06/02/2022 07:29:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=44
06/02/2022 07:29:06 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=45
06/02/2022 07:29:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=46
06/02/2022 07:29:11 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.6956879876384096 on epoch=46
06/02/2022 07:29:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/02/2022 07:29:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
06/02/2022 07:29:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=48
06/02/2022 07:29:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
06/02/2022 07:29:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=49
06/02/2022 07:29:21 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.7449112480549468 on epoch=49
06/02/2022 07:29:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=50
06/02/2022 07:29:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=51
06/02/2022 07:29:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=52
06/02/2022 07:29:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.33 on epoch=52
06/02/2022 07:29:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=53
06/02/2022 07:29:31 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.631290073501287 on epoch=53
06/02/2022 07:29:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=54
06/02/2022 07:29:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=54
06/02/2022 07:29:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=55
06/02/2022 07:29:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=56
06/02/2022 07:29:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=57
06/02/2022 07:29:41 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.6575148647314071 on epoch=57
06/02/2022 07:29:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=57
06/02/2022 07:29:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=58
06/02/2022 07:29:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=59
06/02/2022 07:29:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=59
06/02/2022 07:29:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.27 on epoch=60
06/02/2022 07:29:51 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.6693162831498728 on epoch=60
06/02/2022 07:29:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=61
06/02/2022 07:29:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
06/02/2022 07:29:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=62
06/02/2022 07:29:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.23 on epoch=63
06/02/2022 07:29:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=64
06/02/2022 07:30:01 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.5282886515743077 on epoch=64
06/02/2022 07:30:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=64
06/02/2022 07:30:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=65
06/02/2022 07:30:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=66
06/02/2022 07:30:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/02/2022 07:30:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
06/02/2022 07:30:10 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.8720244855619127 on epoch=67
06/02/2022 07:30:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7982035590384735 -> 0.8720244855619127 on epoch=67, global_step=950
06/02/2022 07:30:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=68
06/02/2022 07:30:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=69
06/02/2022 07:30:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=69
06/02/2022 07:30:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=70
06/02/2022 07:30:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.21 on epoch=71
06/02/2022 07:30:20 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.7248840255439765 on epoch=71
06/02/2022 07:30:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
06/02/2022 07:30:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=72
06/02/2022 07:30:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=73
06/02/2022 07:30:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/02/2022 07:30:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/02/2022 07:30:30 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.7953383072943001 on epoch=74
06/02/2022 07:30:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=75
06/02/2022 07:30:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=76
06/02/2022 07:30:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=77
06/02/2022 07:30:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=77
06/02/2022 07:30:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=78
06/02/2022 07:30:40 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.8349765657729368 on epoch=78
06/02/2022 07:30:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/02/2022 07:30:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/02/2022 07:30:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=80
06/02/2022 07:30:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
06/02/2022 07:30:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/02/2022 07:30:50 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.8332661206401126 on epoch=82
06/02/2022 07:30:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=82
06/02/2022 07:30:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/02/2022 07:30:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=84
06/02/2022 07:30:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/02/2022 07:30:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/02/2022 07:31:00 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.6827625439094005 on epoch=85
06/02/2022 07:31:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=86
06/02/2022 07:31:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
06/02/2022 07:31:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/02/2022 07:31:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=88
06/02/2022 07:31:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=89
06/02/2022 07:31:10 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.612645566717084 on epoch=89
06/02/2022 07:31:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/02/2022 07:31:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=90
06/02/2022 07:31:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/02/2022 07:31:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/02/2022 07:31:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=92
06/02/2022 07:31:20 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.6294612957131033 on epoch=92
06/02/2022 07:31:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/02/2022 07:31:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=94
06/02/2022 07:31:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/02/2022 07:31:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/02/2022 07:31:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
06/02/2022 07:31:30 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.6928361143980839 on epoch=96
06/02/2022 07:31:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=97
06/02/2022 07:31:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/02/2022 07:31:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/02/2022 07:31:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=99
06/02/2022 07:31:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/02/2022 07:31:40 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6390226183253158 on epoch=99
06/02/2022 07:31:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=100
06/02/2022 07:31:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=101
06/02/2022 07:31:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/02/2022 07:31:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
06/02/2022 07:31:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
06/02/2022 07:31:50 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.8134928058593243 on epoch=103
06/02/2022 07:31:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/02/2022 07:31:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
06/02/2022 07:31:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/02/2022 07:31:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/02/2022 07:31:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/02/2022 07:32:00 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7159094537626631 on epoch=107
06/02/2022 07:32:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/02/2022 07:32:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/02/2022 07:32:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=109
06/02/2022 07:32:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=109
06/02/2022 07:32:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/02/2022 07:32:10 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.6560293822836999 on epoch=110
06/02/2022 07:32:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/02/2022 07:32:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/02/2022 07:32:14 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/02/2022 07:32:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/02/2022 07:32:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/02/2022 07:32:20 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.781474872145828 on epoch=114
06/02/2022 07:32:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/02/2022 07:32:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=115
06/02/2022 07:32:24 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=116
06/02/2022 07:32:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=117
06/02/2022 07:32:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=117
06/02/2022 07:32:30 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.8808212989581174 on epoch=117
06/02/2022 07:32:30 - INFO - __main__ - Saving model with best Classification-F1: 0.8720244855619127 -> 0.8808212989581174 on epoch=117, global_step=1650
06/02/2022 07:32:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=118
06/02/2022 07:32:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=119
06/02/2022 07:32:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/02/2022 07:32:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
06/02/2022 07:32:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=121
06/02/2022 07:32:40 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8253019641703147 on epoch=121
06/02/2022 07:32:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=122
06/02/2022 07:32:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
06/02/2022 07:32:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/02/2022 07:32:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=124
06/02/2022 07:32:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/02/2022 07:32:50 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.8173246294106176 on epoch=124
06/02/2022 07:32:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
06/02/2022 07:32:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/02/2022 07:32:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/02/2022 07:32:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=127
06/02/2022 07:32:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/02/2022 07:33:00 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7436307293483982 on epoch=128
06/02/2022 07:33:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/02/2022 07:33:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/02/2022 07:33:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=130
06/02/2022 07:33:05 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/02/2022 07:33:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 07:33:09 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.632636569846869 on epoch=132
06/02/2022 07:33:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/02/2022 07:33:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/02/2022 07:33:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
06/02/2022 07:33:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/02/2022 07:33:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/02/2022 07:33:19 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7642325196066184 on epoch=135
06/02/2022 07:33:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=136
06/02/2022 07:33:22 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/02/2022 07:33:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/02/2022 07:33:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/02/2022 07:33:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=139
06/02/2022 07:33:29 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.7187964092943057 on epoch=139
06/02/2022 07:33:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/02/2022 07:33:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
06/02/2022 07:33:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/02/2022 07:33:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=142
06/02/2022 07:33:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/02/2022 07:33:39 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8863451744334098 on epoch=142
06/02/2022 07:33:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8808212989581174 -> 0.8863451744334098 on epoch=142, global_step=2000
06/02/2022 07:33:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=143
06/02/2022 07:33:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=144
06/02/2022 07:33:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/02/2022 07:33:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/02/2022 07:33:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 07:33:48 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.826466615075486 on epoch=146
06/02/2022 07:33:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/02/2022 07:33:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/02/2022 07:33:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/02/2022 07:33:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/02/2022 07:33:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/02/2022 07:33:58 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8174908071859546 on epoch=149
06/02/2022 07:34:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/02/2022 07:34:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/02/2022 07:34:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/02/2022 07:34:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/02/2022 07:34:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/02/2022 07:34:08 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8808302595315943 on epoch=153
06/02/2022 07:34:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/02/2022 07:34:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/02/2022 07:34:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/02/2022 07:34:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
06/02/2022 07:34:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/02/2022 07:34:18 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.8746484590060786 on epoch=157
06/02/2022 07:34:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/02/2022 07:34:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/02/2022 07:34:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/02/2022 07:34:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/02/2022 07:34:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/02/2022 07:34:28 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8811696592210888 on epoch=160
06/02/2022 07:34:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/02/2022 07:34:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=162
06/02/2022 07:34:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/02/2022 07:34:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 07:34:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/02/2022 07:34:38 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.9595228808481627 on epoch=164
06/02/2022 07:34:38 - INFO - __main__ - Saving model with best Classification-F1: 0.8863451744334098 -> 0.9595228808481627 on epoch=164, global_step=2300
06/02/2022 07:34:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/02/2022 07:34:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/02/2022 07:34:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/02/2022 07:34:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/02/2022 07:34:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/02/2022 07:34:48 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8894046455336777 on epoch=167
06/02/2022 07:34:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/02/2022 07:34:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/02/2022 07:34:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/02/2022 07:34:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
06/02/2022 07:34:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/02/2022 07:34:58 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8433360826001955 on epoch=171
06/02/2022 07:34:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/02/2022 07:35:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/02/2022 07:35:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/02/2022 07:35:03 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/02/2022 07:35:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/02/2022 07:35:08 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9461877783776066 on epoch=174
06/02/2022 07:35:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/02/2022 07:35:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/02/2022 07:35:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/02/2022 07:35:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/02/2022 07:35:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/02/2022 07:35:18 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.959819705008103 on epoch=178
06/02/2022 07:35:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9595228808481627 -> 0.959819705008103 on epoch=178, global_step=2500
06/02/2022 07:35:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/02/2022 07:35:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=179
06/02/2022 07:35:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 07:35:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/02/2022 07:35:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
06/02/2022 07:35:28 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9597435455120463 on epoch=182
06/02/2022 07:35:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/02/2022 07:35:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/02/2022 07:35:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/02/2022 07:35:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/02/2022 07:35:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/02/2022 07:35:38 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8812884124897472 on epoch=185
06/02/2022 07:35:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/02/2022 07:35:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/02/2022 07:35:42 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/02/2022 07:35:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/02/2022 07:35:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/02/2022 07:35:48 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8852450980392156 on epoch=189
06/02/2022 07:35:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/02/2022 07:35:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/02/2022 07:35:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
06/02/2022 07:35:54 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 07:35:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/02/2022 07:35:58 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8893110350284987 on epoch=192
06/02/2022 07:36:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/02/2022 07:36:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/02/2022 07:36:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/02/2022 07:36:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/02/2022 07:36:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/02/2022 07:36:09 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9417843799481077 on epoch=196
06/02/2022 07:36:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/02/2022 07:36:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/02/2022 07:36:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.11 on epoch=198
06/02/2022 07:36:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/02/2022 07:36:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/02/2022 07:36:19 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.942023344039473 on epoch=199
06/02/2022 07:36:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=200
06/02/2022 07:36:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/02/2022 07:36:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 07:36:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/02/2022 07:36:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/02/2022 07:36:29 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9642970824693514 on epoch=203
06/02/2022 07:36:29 - INFO - __main__ - Saving model with best Classification-F1: 0.959819705008103 -> 0.9642970824693514 on epoch=203, global_step=2850
06/02/2022 07:36:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/02/2022 07:36:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/02/2022 07:36:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/02/2022 07:36:34 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/02/2022 07:36:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/02/2022 07:36:39 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9645357263139859 on epoch=207
06/02/2022 07:36:39 - INFO - __main__ - Saving model with best Classification-F1: 0.9642970824693514 -> 0.9645357263139859 on epoch=207, global_step=2900
06/02/2022 07:36:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/02/2022 07:36:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/02/2022 07:36:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/02/2022 07:36:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/02/2022 07:36:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
06/02/2022 07:36:49 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9465503503454167 on epoch=210
06/02/2022 07:36:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/02/2022 07:36:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/02/2022 07:36:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/02/2022 07:36:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/02/2022 07:36:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/02/2022 07:36:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:36:57 - INFO - __main__ - Printing 3 examples
06/02/2022 07:36:57 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 07:36:57 - INFO - __main__ - ['Plant']
06/02/2022 07:36:57 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 07:36:57 - INFO - __main__ - ['Plant']
06/02/2022 07:36:57 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 07:36:57 - INFO - __main__ - ['Plant']
06/02/2022 07:36:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:36:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:36:57 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:36:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:36:57 - INFO - __main__ - Printing 3 examples
06/02/2022 07:36:57 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 07:36:57 - INFO - __main__ - ['Plant']
06/02/2022 07:36:57 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 07:36:57 - INFO - __main__ - ['Plant']
06/02/2022 07:36:57 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 07:36:57 - INFO - __main__ - ['Plant']
06/02/2022 07:36:57 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:36:57 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:36:57 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:36:59 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9512229576847943 on epoch=214
06/02/2022 07:36:59 - INFO - __main__ - save last model!
06/02/2022 07:36:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 07:36:59 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 07:36:59 - INFO - __main__ - Printing 3 examples
06/02/2022 07:36:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 07:36:59 - INFO - __main__ - ['Animal']
06/02/2022 07:36:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 07:36:59 - INFO - __main__ - ['Animal']
06/02/2022 07:36:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 07:36:59 - INFO - __main__ - ['Village']
06/02/2022 07:36:59 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:37:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:37:03 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:37:03 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:37:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:37:03 - INFO - __main__ - Starting training!
06/02/2022 07:37:05 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 07:38:16 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/02/2022 07:38:16 - INFO - __main__ - Classification-F1 on test data: 0.6271
06/02/2022 07:38:17 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9645357263139859, test_performance=0.6270717067115955
06/02/2022 07:38:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/02/2022 07:38:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:38:17 - INFO - __main__ - Printing 3 examples
06/02/2022 07:38:17 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 07:38:17 - INFO - __main__ - ['Plant']
06/02/2022 07:38:17 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 07:38:17 - INFO - __main__ - ['Plant']
06/02/2022 07:38:17 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 07:38:17 - INFO - __main__ - ['Plant']
06/02/2022 07:38:17 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:38:18 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:38:18 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:38:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:38:18 - INFO - __main__ - Printing 3 examples
06/02/2022 07:38:18 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 07:38:18 - INFO - __main__ - ['Plant']
06/02/2022 07:38:18 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 07:38:18 - INFO - __main__ - ['Plant']
06/02/2022 07:38:18 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 07:38:18 - INFO - __main__ - ['Plant']
06/02/2022 07:38:18 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:38:18 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:38:18 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:38:23 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:38:23 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:38:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:38:24 - INFO - __main__ - Starting training!
06/02/2022 07:38:25 - INFO - __main__ - Step 10 Global step 10 Train loss 6.42 on epoch=0
06/02/2022 07:38:26 - INFO - __main__ - Step 20 Global step 20 Train loss 5.41 on epoch=1
06/02/2022 07:38:28 - INFO - __main__ - Step 30 Global step 30 Train loss 5.01 on epoch=2
06/02/2022 07:38:29 - INFO - __main__ - Step 40 Global step 40 Train loss 4.33 on epoch=2
06/02/2022 07:38:30 - INFO - __main__ - Step 50 Global step 50 Train loss 3.80 on epoch=3
06/02/2022 07:38:41 - INFO - __main__ - Global step 50 Train loss 5.00 Classification-F1 0.01916466137480353 on epoch=3
06/02/2022 07:38:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01916466137480353 on epoch=3, global_step=50
06/02/2022 07:38:42 - INFO - __main__ - Step 60 Global step 60 Train loss 3.34 on epoch=4
06/02/2022 07:38:44 - INFO - __main__ - Step 70 Global step 70 Train loss 2.81 on epoch=4
06/02/2022 07:38:45 - INFO - __main__ - Step 80 Global step 80 Train loss 2.50 on epoch=5
06/02/2022 07:38:46 - INFO - __main__ - Step 90 Global step 90 Train loss 2.32 on epoch=6
06/02/2022 07:38:47 - INFO - __main__ - Step 100 Global step 100 Train loss 2.23 on epoch=7
06/02/2022 07:38:53 - INFO - __main__ - Global step 100 Train loss 2.64 Classification-F1 0.16015976197455756 on epoch=7
06/02/2022 07:38:53 - INFO - __main__ - Saving model with best Classification-F1: 0.01916466137480353 -> 0.16015976197455756 on epoch=7, global_step=100
06/02/2022 07:38:54 - INFO - __main__ - Step 110 Global step 110 Train loss 1.77 on epoch=7
06/02/2022 07:38:55 - INFO - __main__ - Step 120 Global step 120 Train loss 1.81 on epoch=8
06/02/2022 07:38:56 - INFO - __main__ - Step 130 Global step 130 Train loss 1.71 on epoch=9
06/02/2022 07:38:58 - INFO - __main__ - Step 140 Global step 140 Train loss 1.36 on epoch=9
06/02/2022 07:38:59 - INFO - __main__ - Step 150 Global step 150 Train loss 1.49 on epoch=10
06/02/2022 07:39:03 - INFO - __main__ - Global step 150 Train loss 1.63 Classification-F1 0.29211261849244685 on epoch=10
06/02/2022 07:39:03 - INFO - __main__ - Saving model with best Classification-F1: 0.16015976197455756 -> 0.29211261849244685 on epoch=10, global_step=150
06/02/2022 07:39:04 - INFO - __main__ - Step 160 Global step 160 Train loss 1.20 on epoch=11
06/02/2022 07:39:05 - INFO - __main__ - Step 170 Global step 170 Train loss 1.21 on epoch=12
06/02/2022 07:39:07 - INFO - __main__ - Step 180 Global step 180 Train loss 1.11 on epoch=12
06/02/2022 07:39:08 - INFO - __main__ - Step 190 Global step 190 Train loss 1.08 on epoch=13
06/02/2022 07:39:09 - INFO - __main__ - Step 200 Global step 200 Train loss 1.04 on epoch=14
06/02/2022 07:39:12 - INFO - __main__ - Global step 200 Train loss 1.13 Classification-F1 0.30312698642197805 on epoch=14
06/02/2022 07:39:12 - INFO - __main__ - Saving model with best Classification-F1: 0.29211261849244685 -> 0.30312698642197805 on epoch=14, global_step=200
06/02/2022 07:39:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=14
06/02/2022 07:39:15 - INFO - __main__ - Step 220 Global step 220 Train loss 0.95 on epoch=15
06/02/2022 07:39:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.90 on epoch=16
06/02/2022 07:39:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.88 on epoch=17
06/02/2022 07:39:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.93 on epoch=17
06/02/2022 07:39:22 - INFO - __main__ - Global step 250 Train loss 0.93 Classification-F1 0.34432148859307443 on epoch=17
06/02/2022 07:39:22 - INFO - __main__ - Saving model with best Classification-F1: 0.30312698642197805 -> 0.34432148859307443 on epoch=17, global_step=250
06/02/2022 07:39:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.82 on epoch=18
06/02/2022 07:39:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=19
06/02/2022 07:39:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=19
06/02/2022 07:39:27 - INFO - __main__ - Step 290 Global step 290 Train loss 1.86 on epoch=20
06/02/2022 07:39:28 - INFO - __main__ - Step 300 Global step 300 Train loss 4.57 on epoch=21
06/02/2022 07:39:31 - INFO - __main__ - Global step 300 Train loss 1.76 Classification-F1 0.41785140536945137 on epoch=21
06/02/2022 07:39:31 - INFO - __main__ - Saving model with best Classification-F1: 0.34432148859307443 -> 0.41785140536945137 on epoch=21, global_step=300
06/02/2022 07:39:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.89 on epoch=22
06/02/2022 07:39:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.87 on epoch=22
06/02/2022 07:39:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.73 on epoch=23
06/02/2022 07:39:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.68 on epoch=24
06/02/2022 07:39:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.74 on epoch=24
06/02/2022 07:39:41 - INFO - __main__ - Global step 350 Train loss 0.78 Classification-F1 0.5107392457392458 on epoch=24
06/02/2022 07:39:41 - INFO - __main__ - Saving model with best Classification-F1: 0.41785140536945137 -> 0.5107392457392458 on epoch=24, global_step=350
06/02/2022 07:39:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=25
06/02/2022 07:39:43 - INFO - __main__ - Step 370 Global step 370 Train loss 0.66 on epoch=26
06/02/2022 07:39:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.62 on epoch=27
06/02/2022 07:39:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.68 on epoch=27
06/02/2022 07:39:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.63 on epoch=28
06/02/2022 07:39:50 - INFO - __main__ - Global step 400 Train loss 0.65 Classification-F1 0.5274322345132646 on epoch=28
06/02/2022 07:39:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5107392457392458 -> 0.5274322345132646 on epoch=28, global_step=400
06/02/2022 07:39:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.61 on epoch=29
06/02/2022 07:39:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.65 on epoch=29
06/02/2022 07:39:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.56 on epoch=30
06/02/2022 07:39:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.67 on epoch=31
06/02/2022 07:39:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.71 on epoch=32
06/02/2022 07:40:00 - INFO - __main__ - Global step 450 Train loss 0.64 Classification-F1 0.5023843171081549 on epoch=32
06/02/2022 07:40:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.63 on epoch=32
06/02/2022 07:40:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.55 on epoch=33
06/02/2022 07:40:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.60 on epoch=34
06/02/2022 07:40:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.71 on epoch=34
06/02/2022 07:40:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.62 on epoch=35
06/02/2022 07:40:09 - INFO - __main__ - Global step 500 Train loss 0.62 Classification-F1 0.5211127499377282 on epoch=35
06/02/2022 07:40:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.59 on epoch=36
06/02/2022 07:40:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.58 on epoch=37
06/02/2022 07:40:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.63 on epoch=37
06/02/2022 07:40:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.60 on epoch=38
06/02/2022 07:40:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.62 on epoch=39
06/02/2022 07:40:19 - INFO - __main__ - Global step 550 Train loss 0.60 Classification-F1 0.49911158668677463 on epoch=39
06/02/2022 07:40:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.60 on epoch=39
06/02/2022 07:40:21 - INFO - __main__ - Step 570 Global step 570 Train loss 0.62 on epoch=40
06/02/2022 07:40:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.59 on epoch=41
06/02/2022 07:40:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.54 on epoch=42
06/02/2022 07:40:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.58 on epoch=42
06/02/2022 07:40:28 - INFO - __main__ - Global step 600 Train loss 0.59 Classification-F1 0.5519428747331125 on epoch=42
06/02/2022 07:40:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5274322345132646 -> 0.5519428747331125 on epoch=42, global_step=600
06/02/2022 07:40:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.62 on epoch=43
06/02/2022 07:40:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=44
06/02/2022 07:40:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.58 on epoch=44
06/02/2022 07:40:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.55 on epoch=45
06/02/2022 07:40:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.56 on epoch=46
06/02/2022 07:40:38 - INFO - __main__ - Global step 650 Train loss 0.57 Classification-F1 0.6114219700755453 on epoch=46
06/02/2022 07:40:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5519428747331125 -> 0.6114219700755453 on epoch=46, global_step=650
06/02/2022 07:40:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.54 on epoch=47
06/02/2022 07:40:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.51 on epoch=47
06/02/2022 07:40:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.48 on epoch=48
06/02/2022 07:40:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.57 on epoch=49
06/02/2022 07:40:44 - INFO - __main__ - Step 700 Global step 700 Train loss 0.57 on epoch=49
06/02/2022 07:40:48 - INFO - __main__ - Global step 700 Train loss 0.53 Classification-F1 0.6009254332437499 on epoch=49
06/02/2022 07:40:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.57 on epoch=50
06/02/2022 07:40:51 - INFO - __main__ - Step 720 Global step 720 Train loss 0.50 on epoch=51
06/02/2022 07:40:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.49 on epoch=52
06/02/2022 07:40:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.58 on epoch=52
06/02/2022 07:40:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.45 on epoch=53
06/02/2022 07:40:58 - INFO - __main__ - Global step 750 Train loss 0.52 Classification-F1 0.5763018555675602 on epoch=53
06/02/2022 07:40:59 - INFO - __main__ - Step 760 Global step 760 Train loss 0.50 on epoch=54
06/02/2022 07:41:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.46 on epoch=54
06/02/2022 07:41:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.56 on epoch=55
06/02/2022 07:41:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.53 on epoch=56
06/02/2022 07:41:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.53 on epoch=57
06/02/2022 07:41:08 - INFO - __main__ - Global step 800 Train loss 0.51 Classification-F1 0.5893779334603121 on epoch=57
06/02/2022 07:41:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.45 on epoch=57
06/02/2022 07:41:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.51 on epoch=58
06/02/2022 07:41:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.43 on epoch=59
06/02/2022 07:41:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.47 on epoch=59
06/02/2022 07:41:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.55 on epoch=60
06/02/2022 07:41:18 - INFO - __main__ - Global step 850 Train loss 0.48 Classification-F1 0.6742065639667507 on epoch=60
06/02/2022 07:41:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6114219700755453 -> 0.6742065639667507 on epoch=60, global_step=850
06/02/2022 07:41:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.49 on epoch=61
06/02/2022 07:41:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.47 on epoch=62
06/02/2022 07:41:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.47 on epoch=62
06/02/2022 07:41:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.45 on epoch=63
06/02/2022 07:41:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.40 on epoch=64
06/02/2022 07:41:27 - INFO - __main__ - Global step 900 Train loss 0.46 Classification-F1 0.6079987822634881 on epoch=64
06/02/2022 07:41:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.43 on epoch=64
06/02/2022 07:41:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.60 on epoch=65
06/02/2022 07:41:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.45 on epoch=66
06/02/2022 07:41:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.51 on epoch=67
06/02/2022 07:41:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.49 on epoch=67
06/02/2022 07:41:37 - INFO - __main__ - Global step 950 Train loss 0.49 Classification-F1 0.562783236190099 on epoch=67
06/02/2022 07:41:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.39 on epoch=68
06/02/2022 07:41:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.46 on epoch=69
06/02/2022 07:41:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.49 on epoch=69
06/02/2022 07:41:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=70
06/02/2022 07:41:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.43 on epoch=71
06/02/2022 07:41:46 - INFO - __main__ - Global step 1000 Train loss 0.42 Classification-F1 0.7217596410942934 on epoch=71
06/02/2022 07:41:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6742065639667507 -> 0.7217596410942934 on epoch=71, global_step=1000
06/02/2022 07:41:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.46 on epoch=72
06/02/2022 07:41:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.50 on epoch=72
06/02/2022 07:41:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.48 on epoch=73
06/02/2022 07:41:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.35 on epoch=74
06/02/2022 07:41:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.47 on epoch=74
06/02/2022 07:41:57 - INFO - __main__ - Global step 1050 Train loss 0.45 Classification-F1 0.7851337803653011 on epoch=74
06/02/2022 07:41:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7217596410942934 -> 0.7851337803653011 on epoch=74, global_step=1050
06/02/2022 07:41:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.35 on epoch=75
06/02/2022 07:41:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.43 on epoch=76
06/02/2022 07:42:00 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.46 on epoch=77
06/02/2022 07:42:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.38 on epoch=77
06/02/2022 07:42:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.36 on epoch=78
06/02/2022 07:42:07 - INFO - __main__ - Global step 1100 Train loss 0.40 Classification-F1 0.8411284143256379 on epoch=78
06/02/2022 07:42:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7851337803653011 -> 0.8411284143256379 on epoch=78, global_step=1100
06/02/2022 07:42:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.41 on epoch=79
06/02/2022 07:42:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.40 on epoch=79
06/02/2022 07:42:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.31 on epoch=80
06/02/2022 07:42:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.39 on epoch=81
06/02/2022 07:42:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.30 on epoch=82
06/02/2022 07:42:17 - INFO - __main__ - Global step 1150 Train loss 0.36 Classification-F1 0.915743912165885 on epoch=82
06/02/2022 07:42:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8411284143256379 -> 0.915743912165885 on epoch=82, global_step=1150
06/02/2022 07:42:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.33 on epoch=82
06/02/2022 07:42:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.34 on epoch=83
06/02/2022 07:42:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.42 on epoch=84
06/02/2022 07:42:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.39 on epoch=84
06/02/2022 07:42:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.32 on epoch=85
06/02/2022 07:42:27 - INFO - __main__ - Global step 1200 Train loss 0.36 Classification-F1 0.7822233940615476 on epoch=85
06/02/2022 07:42:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.33 on epoch=86
06/02/2022 07:42:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.33 on epoch=87
06/02/2022 07:42:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.33 on epoch=87
06/02/2022 07:42:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.39 on epoch=88
06/02/2022 07:42:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.43 on epoch=89
06/02/2022 07:42:37 - INFO - __main__ - Global step 1250 Train loss 0.36 Classification-F1 0.5733237719411319 on epoch=89
06/02/2022 07:42:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.35 on epoch=89
06/02/2022 07:42:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.30 on epoch=90
06/02/2022 07:42:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.42 on epoch=91
06/02/2022 07:42:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.27 on epoch=92
06/02/2022 07:42:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.45 on epoch=92
06/02/2022 07:42:47 - INFO - __main__ - Global step 1300 Train loss 0.36 Classification-F1 0.6412153688028039 on epoch=92
06/02/2022 07:42:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.31 on epoch=93
06/02/2022 07:42:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.35 on epoch=94
06/02/2022 07:42:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.26 on epoch=94
06/02/2022 07:42:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.35 on epoch=95
06/02/2022 07:42:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.38 on epoch=96
06/02/2022 07:42:57 - INFO - __main__ - Global step 1350 Train loss 0.33 Classification-F1 0.694395067303595 on epoch=96
06/02/2022 07:42:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.38 on epoch=97
06/02/2022 07:43:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.35 on epoch=97
06/02/2022 07:43:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.21 on epoch=98
06/02/2022 07:43:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.29 on epoch=99
06/02/2022 07:43:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.36 on epoch=99
06/02/2022 07:43:07 - INFO - __main__ - Global step 1400 Train loss 0.32 Classification-F1 0.7936297098255545 on epoch=99
06/02/2022 07:43:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.33 on epoch=100
06/02/2022 07:43:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.35 on epoch=101
06/02/2022 07:43:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.32 on epoch=102
06/02/2022 07:43:12 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.33 on epoch=102
06/02/2022 07:43:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.28 on epoch=103
06/02/2022 07:43:17 - INFO - __main__ - Global step 1450 Train loss 0.32 Classification-F1 0.7098536970282477 on epoch=103
06/02/2022 07:43:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.37 on epoch=104
06/02/2022 07:43:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.32 on epoch=104
06/02/2022 07:43:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.32 on epoch=105
06/02/2022 07:43:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.40 on epoch=106
06/02/2022 07:43:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.29 on epoch=107
06/02/2022 07:43:27 - INFO - __main__ - Global step 1500 Train loss 0.34 Classification-F1 0.5942870787170581 on epoch=107
06/02/2022 07:43:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.32 on epoch=107
06/02/2022 07:43:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.31 on epoch=108
06/02/2022 07:43:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.31 on epoch=109
06/02/2022 07:43:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.29 on epoch=109
06/02/2022 07:43:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.23 on epoch=110
06/02/2022 07:43:36 - INFO - __main__ - Global step 1550 Train loss 0.29 Classification-F1 0.45398952327343184 on epoch=110
06/02/2022 07:43:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.37 on epoch=111
06/02/2022 07:43:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.32 on epoch=112
06/02/2022 07:43:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.23 on epoch=112
06/02/2022 07:43:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.32 on epoch=113
06/02/2022 07:43:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.26 on epoch=114
06/02/2022 07:43:46 - INFO - __main__ - Global step 1600 Train loss 0.30 Classification-F1 0.46210403747855056 on epoch=114
06/02/2022 07:43:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.29 on epoch=114
06/02/2022 07:43:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.21 on epoch=115
06/02/2022 07:43:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.26 on epoch=116
06/02/2022 07:43:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.25 on epoch=117
06/02/2022 07:43:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.28 on epoch=117
06/02/2022 07:43:56 - INFO - __main__ - Global step 1650 Train loss 0.26 Classification-F1 0.4782763899658582 on epoch=117
06/02/2022 07:43:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.26 on epoch=118
06/02/2022 07:43:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.25 on epoch=119
06/02/2022 07:44:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.22 on epoch=119
06/02/2022 07:44:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.25 on epoch=120
06/02/2022 07:44:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.24 on epoch=121
06/02/2022 07:44:06 - INFO - __main__ - Global step 1700 Train loss 0.25 Classification-F1 0.4267436568010103 on epoch=121
06/02/2022 07:44:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=122
06/02/2022 07:44:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.24 on epoch=122
06/02/2022 07:44:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.23 on epoch=123
06/02/2022 07:44:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.26 on epoch=124
06/02/2022 07:44:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.24 on epoch=124
06/02/2022 07:44:16 - INFO - __main__ - Global step 1750 Train loss 0.23 Classification-F1 0.573435840697504 on epoch=124
06/02/2022 07:44:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.21 on epoch=125
06/02/2022 07:44:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.29 on epoch=126
06/02/2022 07:44:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.37 on epoch=127
06/02/2022 07:44:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.21 on epoch=127
06/02/2022 07:44:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.24 on epoch=128
06/02/2022 07:44:26 - INFO - __main__ - Global step 1800 Train loss 0.26 Classification-F1 0.6009582973257588 on epoch=128
06/02/2022 07:44:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.26 on epoch=129
06/02/2022 07:44:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.16 on epoch=129
06/02/2022 07:44:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.16 on epoch=130
06/02/2022 07:44:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.26 on epoch=131
06/02/2022 07:44:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.21 on epoch=132
06/02/2022 07:44:36 - INFO - __main__ - Global step 1850 Train loss 0.21 Classification-F1 0.6656264872571571 on epoch=132
06/02/2022 07:44:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.31 on epoch=132
06/02/2022 07:44:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.19 on epoch=133
06/02/2022 07:44:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.21 on epoch=134
06/02/2022 07:44:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.18 on epoch=134
06/02/2022 07:44:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.20 on epoch=135
06/02/2022 07:44:45 - INFO - __main__ - Global step 1900 Train loss 0.22 Classification-F1 0.5687116652336865 on epoch=135
06/02/2022 07:44:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.23 on epoch=136
06/02/2022 07:44:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.23 on epoch=137
06/02/2022 07:44:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.16 on epoch=137
06/02/2022 07:44:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.17 on epoch=138
06/02/2022 07:44:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.25 on epoch=139
06/02/2022 07:44:56 - INFO - __main__ - Global step 1950 Train loss 0.21 Classification-F1 0.5097241061919844 on epoch=139
06/02/2022 07:44:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.27 on epoch=139
06/02/2022 07:44:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.21 on epoch=140
06/02/2022 07:45:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.20 on epoch=141
06/02/2022 07:45:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
06/02/2022 07:45:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.27 on epoch=142
06/02/2022 07:45:06 - INFO - __main__ - Global step 2000 Train loss 0.21 Classification-F1 0.5787335069668686 on epoch=142
06/02/2022 07:45:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.19 on epoch=143
06/02/2022 07:45:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.16 on epoch=144
06/02/2022 07:45:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.23 on epoch=144
06/02/2022 07:45:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=145
06/02/2022 07:45:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.18 on epoch=146
06/02/2022 07:45:16 - INFO - __main__ - Global step 2050 Train loss 0.17 Classification-F1 0.7328579988751325 on epoch=146
06/02/2022 07:45:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.19 on epoch=147
06/02/2022 07:45:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.18 on epoch=147
06/02/2022 07:45:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.15 on epoch=148
06/02/2022 07:45:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.24 on epoch=149
06/02/2022 07:45:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.14 on epoch=149
06/02/2022 07:45:26 - INFO - __main__ - Global step 2100 Train loss 0.18 Classification-F1 0.6599799776284452 on epoch=149
06/02/2022 07:45:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.22 on epoch=150
06/02/2022 07:45:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.15 on epoch=151
06/02/2022 07:45:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.18 on epoch=152
06/02/2022 07:45:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.16 on epoch=152
06/02/2022 07:45:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.18 on epoch=153
06/02/2022 07:45:36 - INFO - __main__ - Global step 2150 Train loss 0.18 Classification-F1 0.675594703777025 on epoch=153
06/02/2022 07:45:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=154
06/02/2022 07:45:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=154
06/02/2022 07:45:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.22 on epoch=155
06/02/2022 07:45:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.17 on epoch=156
06/02/2022 07:45:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.17 on epoch=157
06/02/2022 07:45:45 - INFO - __main__ - Global step 2200 Train loss 0.16 Classification-F1 0.6742739727659334 on epoch=157
06/02/2022 07:45:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.23 on epoch=157
06/02/2022 07:45:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.19 on epoch=158
06/02/2022 07:45:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.22 on epoch=159
06/02/2022 07:45:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.18 on epoch=159
06/02/2022 07:45:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.21 on epoch=160
06/02/2022 07:45:55 - INFO - __main__ - Global step 2250 Train loss 0.21 Classification-F1 0.6124274424429418 on epoch=160
06/02/2022 07:45:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.15 on epoch=161
06/02/2022 07:45:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.14 on epoch=162
06/02/2022 07:45:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.19 on epoch=162
06/02/2022 07:46:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.16 on epoch=163
06/02/2022 07:46:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=164
06/02/2022 07:46:05 - INFO - __main__ - Global step 2300 Train loss 0.15 Classification-F1 0.6091676152299067 on epoch=164
06/02/2022 07:46:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.12 on epoch=164
06/02/2022 07:46:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.17 on epoch=165
06/02/2022 07:46:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.19 on epoch=166
06/02/2022 07:46:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.12 on epoch=167
06/02/2022 07:46:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.17 on epoch=167
06/02/2022 07:46:15 - INFO - __main__ - Global step 2350 Train loss 0.16 Classification-F1 0.5559545858978809 on epoch=167
06/02/2022 07:46:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.13 on epoch=168
06/02/2022 07:46:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.16 on epoch=169
06/02/2022 07:46:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=169
06/02/2022 07:46:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.14 on epoch=170
06/02/2022 07:46:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.16 on epoch=171
06/02/2022 07:46:25 - INFO - __main__ - Global step 2400 Train loss 0.13 Classification-F1 0.5932500778089013 on epoch=171
06/02/2022 07:46:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.12 on epoch=172
06/02/2022 07:46:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.11 on epoch=172
06/02/2022 07:46:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.19 on epoch=173
06/02/2022 07:46:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=174
06/02/2022 07:46:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.15 on epoch=174
06/02/2022 07:46:36 - INFO - __main__ - Global step 2450 Train loss 0.14 Classification-F1 0.7157625196954385 on epoch=174
06/02/2022 07:46:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.16 on epoch=175
06/02/2022 07:46:38 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.20 on epoch=176
06/02/2022 07:46:39 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=177
06/02/2022 07:46:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.18 on epoch=177
06/02/2022 07:46:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.23 on epoch=178
06/02/2022 07:46:45 - INFO - __main__ - Global step 2500 Train loss 0.17 Classification-F1 0.7731986763236763 on epoch=178
06/02/2022 07:46:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.14 on epoch=179
06/02/2022 07:46:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=179
06/02/2022 07:46:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.13 on epoch=180
06/02/2022 07:46:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.14 on epoch=181
06/02/2022 07:46:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=182
06/02/2022 07:46:56 - INFO - __main__ - Global step 2550 Train loss 0.13 Classification-F1 0.7702533962329063 on epoch=182
06/02/2022 07:46:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.12 on epoch=182
06/02/2022 07:46:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.12 on epoch=183
06/02/2022 07:47:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.14 on epoch=184
06/02/2022 07:47:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=184
06/02/2022 07:47:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.13 on epoch=185
06/02/2022 07:47:06 - INFO - __main__ - Global step 2600 Train loss 0.12 Classification-F1 0.647586091904478 on epoch=185
06/02/2022 07:47:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.18 on epoch=186
06/02/2022 07:47:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.11 on epoch=187
06/02/2022 07:47:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.18 on epoch=187
06/02/2022 07:47:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.14 on epoch=188
06/02/2022 07:47:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=189
06/02/2022 07:47:16 - INFO - __main__ - Global step 2650 Train loss 0.15 Classification-F1 0.6449981482844386 on epoch=189
06/02/2022 07:47:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.13 on epoch=189
06/02/2022 07:47:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.17 on epoch=190
06/02/2022 07:47:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=191
06/02/2022 07:47:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=192
06/02/2022 07:47:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.14 on epoch=192
06/02/2022 07:47:26 - INFO - __main__ - Global step 2700 Train loss 0.12 Classification-F1 0.6115581420867932 on epoch=192
06/02/2022 07:47:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.16 on epoch=193
06/02/2022 07:47:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/02/2022 07:47:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.11 on epoch=194
06/02/2022 07:47:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.11 on epoch=195
06/02/2022 07:47:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.11 on epoch=196
06/02/2022 07:47:36 - INFO - __main__ - Global step 2750 Train loss 0.11 Classification-F1 0.5927728044683394 on epoch=196
06/02/2022 07:47:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.11 on epoch=197
06/02/2022 07:47:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=197
06/02/2022 07:47:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.16 on epoch=198
06/02/2022 07:47:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=199
06/02/2022 07:47:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.09 on epoch=199
06/02/2022 07:47:46 - INFO - __main__ - Global step 2800 Train loss 0.11 Classification-F1 0.5709407878202082 on epoch=199
06/02/2022 07:47:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.14 on epoch=200
06/02/2022 07:47:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.15 on epoch=201
06/02/2022 07:47:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=202
06/02/2022 07:47:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=202
06/02/2022 07:47:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.13 on epoch=203
06/02/2022 07:47:55 - INFO - __main__ - Global step 2850 Train loss 0.12 Classification-F1 0.7765490926633516 on epoch=203
06/02/2022 07:47:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.16 on epoch=204
06/02/2022 07:47:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.15 on epoch=204
06/02/2022 07:47:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.09 on epoch=205
06/02/2022 07:48:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.11 on epoch=206
06/02/2022 07:48:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.09 on epoch=207
06/02/2022 07:48:06 - INFO - __main__ - Global step 2900 Train loss 0.12 Classification-F1 0.835917639847609 on epoch=207
06/02/2022 07:48:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.12 on epoch=207
06/02/2022 07:48:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.11 on epoch=208
06/02/2022 07:48:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.13 on epoch=209
06/02/2022 07:48:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.09 on epoch=209
06/02/2022 07:48:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.11 on epoch=210
06/02/2022 07:48:16 - INFO - __main__ - Global step 2950 Train loss 0.11 Classification-F1 0.7843183905017315 on epoch=210
06/02/2022 07:48:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.12 on epoch=211
06/02/2022 07:48:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.09 on epoch=212
06/02/2022 07:48:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.11 on epoch=212
06/02/2022 07:48:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 07:48:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.12 on epoch=214
06/02/2022 07:48:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:48:23 - INFO - __main__ - Printing 3 examples
06/02/2022 07:48:23 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 07:48:23 - INFO - __main__ - ['Plant']
06/02/2022 07:48:23 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 07:48:23 - INFO - __main__ - ['Plant']
06/02/2022 07:48:23 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 07:48:23 - INFO - __main__ - ['Plant']
06/02/2022 07:48:23 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:48:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:48:24 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:48:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:48:24 - INFO - __main__ - Printing 3 examples
06/02/2022 07:48:24 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 07:48:24 - INFO - __main__ - ['Plant']
06/02/2022 07:48:24 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 07:48:24 - INFO - __main__ - ['Plant']
06/02/2022 07:48:24 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 07:48:24 - INFO - __main__ - ['Plant']
06/02/2022 07:48:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:48:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:48:24 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:48:26 - INFO - __main__ - Global step 3000 Train loss 0.10 Classification-F1 0.769906567349891 on epoch=214
06/02/2022 07:48:26 - INFO - __main__ - save last model!
06/02/2022 07:48:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 07:48:26 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 07:48:26 - INFO - __main__ - Printing 3 examples
06/02/2022 07:48:26 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 07:48:26 - INFO - __main__ - ['Animal']
06/02/2022 07:48:26 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 07:48:26 - INFO - __main__ - ['Animal']
06/02/2022 07:48:26 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 07:48:26 - INFO - __main__ - ['Village']
06/02/2022 07:48:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:48:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:48:30 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:48:30 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:48:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:48:31 - INFO - __main__ - Starting training!
06/02/2022 07:48:31 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 07:49:42 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/02/2022 07:49:42 - INFO - __main__ - Classification-F1 on test data: 0.5255
06/02/2022 07:49:42 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.915743912165885, test_performance=0.5254983956019071
06/02/2022 07:49:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/02/2022 07:49:43 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:49:43 - INFO - __main__ - Printing 3 examples
06/02/2022 07:49:43 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 07:49:43 - INFO - __main__ - ['Plant']
06/02/2022 07:49:43 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 07:49:43 - INFO - __main__ - ['Plant']
06/02/2022 07:49:43 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 07:49:43 - INFO - __main__ - ['Plant']
06/02/2022 07:49:43 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:49:43 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:49:44 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 07:49:44 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 07:49:44 - INFO - __main__ - Printing 3 examples
06/02/2022 07:49:44 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 07:49:44 - INFO - __main__ - ['Plant']
06/02/2022 07:49:44 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 07:49:44 - INFO - __main__ - ['Plant']
06/02/2022 07:49:44 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 07:49:44 - INFO - __main__ - ['Plant']
06/02/2022 07:49:44 - INFO - __main__ - Tokenizing Input ...
06/02/2022 07:49:44 - INFO - __main__ - Tokenizing Output ...
06/02/2022 07:49:44 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 07:49:49 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 07:49:49 - INFO - __main__ - task name: dbpedia_14
06/02/2022 07:49:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 07:49:50 - INFO - __main__ - Starting training!
06/02/2022 07:49:51 - INFO - __main__ - Step 10 Global step 10 Train loss 6.75 on epoch=0
06/02/2022 07:49:52 - INFO - __main__ - Step 20 Global step 20 Train loss 5.35 on epoch=1
06/02/2022 07:49:54 - INFO - __main__ - Step 30 Global step 30 Train loss 5.65 on epoch=2
06/02/2022 07:49:55 - INFO - __main__ - Step 40 Global step 40 Train loss 5.12 on epoch=2
06/02/2022 07:49:56 - INFO - __main__ - Step 50 Global step 50 Train loss 4.91 on epoch=3
06/02/2022 07:50:43 - INFO - __main__ - Global step 50 Train loss 5.56 Classification-F1 0.0 on epoch=3
06/02/2022 07:50:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 07:50:44 - INFO - __main__ - Step 60 Global step 60 Train loss 4.39 on epoch=4
06/02/2022 07:50:45 - INFO - __main__ - Step 70 Global step 70 Train loss 3.98 on epoch=4
06/02/2022 07:50:47 - INFO - __main__ - Step 80 Global step 80 Train loss 3.37 on epoch=5
06/02/2022 07:50:48 - INFO - __main__ - Step 90 Global step 90 Train loss 3.05 on epoch=6
06/02/2022 07:50:49 - INFO - __main__ - Step 100 Global step 100 Train loss 2.96 on epoch=7
06/02/2022 07:50:55 - INFO - __main__ - Global step 100 Train loss 3.55 Classification-F1 0.10146130753372848 on epoch=7
06/02/2022 07:50:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.10146130753372848 on epoch=7, global_step=100
06/02/2022 07:50:56 - INFO - __main__ - Step 110 Global step 110 Train loss 2.58 on epoch=7
06/02/2022 07:50:57 - INFO - __main__ - Step 120 Global step 120 Train loss 2.55 on epoch=8
06/02/2022 07:50:59 - INFO - __main__ - Step 130 Global step 130 Train loss 2.46 on epoch=9
06/02/2022 07:51:00 - INFO - __main__ - Step 140 Global step 140 Train loss 2.29 on epoch=9
06/02/2022 07:51:01 - INFO - __main__ - Step 150 Global step 150 Train loss 2.21 on epoch=10
06/02/2022 07:51:05 - INFO - __main__ - Global step 150 Train loss 2.42 Classification-F1 0.2047307461625123 on epoch=10
06/02/2022 07:51:05 - INFO - __main__ - Saving model with best Classification-F1: 0.10146130753372848 -> 0.2047307461625123 on epoch=10, global_step=150
06/02/2022 07:51:07 - INFO - __main__ - Step 160 Global step 160 Train loss 1.86 on epoch=11
06/02/2022 07:51:08 - INFO - __main__ - Step 170 Global step 170 Train loss 1.87 on epoch=12
06/02/2022 07:51:09 - INFO - __main__ - Step 180 Global step 180 Train loss 1.57 on epoch=12
06/02/2022 07:51:10 - INFO - __main__ - Step 190 Global step 190 Train loss 1.57 on epoch=13
06/02/2022 07:51:12 - INFO - __main__ - Step 200 Global step 200 Train loss 1.52 on epoch=14
06/02/2022 07:51:14 - INFO - __main__ - Global step 200 Train loss 1.68 Classification-F1 0.29811794461624685 on epoch=14
06/02/2022 07:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.2047307461625123 -> 0.29811794461624685 on epoch=14, global_step=200
06/02/2022 07:51:16 - INFO - __main__ - Step 210 Global step 210 Train loss 1.40 on epoch=14
06/02/2022 07:51:17 - INFO - __main__ - Step 220 Global step 220 Train loss 1.33 on epoch=15
06/02/2022 07:51:18 - INFO - __main__ - Step 230 Global step 230 Train loss 1.26 on epoch=16
06/02/2022 07:51:20 - INFO - __main__ - Step 240 Global step 240 Train loss 1.16 on epoch=17
06/02/2022 07:51:21 - INFO - __main__ - Step 250 Global step 250 Train loss 1.03 on epoch=17
06/02/2022 07:51:24 - INFO - __main__ - Global step 250 Train loss 1.24 Classification-F1 0.37688665059289367 on epoch=17
06/02/2022 07:51:24 - INFO - __main__ - Saving model with best Classification-F1: 0.29811794461624685 -> 0.37688665059289367 on epoch=17, global_step=250
06/02/2022 07:51:25 - INFO - __main__ - Step 260 Global step 260 Train loss 1.14 on epoch=18
06/02/2022 07:51:27 - INFO - __main__ - Step 270 Global step 270 Train loss 1.19 on epoch=19
06/02/2022 07:51:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.99 on epoch=19
06/02/2022 07:51:29 - INFO - __main__ - Step 290 Global step 290 Train loss 1.11 on epoch=20
06/02/2022 07:51:30 - INFO - __main__ - Step 300 Global step 300 Train loss 1.00 on epoch=21
06/02/2022 07:51:33 - INFO - __main__ - Global step 300 Train loss 1.09 Classification-F1 0.3981448183228504 on epoch=21
06/02/2022 07:51:34 - INFO - __main__ - Saving model with best Classification-F1: 0.37688665059289367 -> 0.3981448183228504 on epoch=21, global_step=300
06/02/2022 07:51:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.85 on epoch=22
06/02/2022 07:51:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.86 on epoch=22
06/02/2022 07:51:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.95 on epoch=23
06/02/2022 07:51:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.90 on epoch=24
06/02/2022 07:51:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.85 on epoch=24
06/02/2022 07:51:43 - INFO - __main__ - Global step 350 Train loss 0.88 Classification-F1 0.4420445662787761 on epoch=24
06/02/2022 07:51:43 - INFO - __main__ - Saving model with best Classification-F1: 0.3981448183228504 -> 0.4420445662787761 on epoch=24, global_step=350
06/02/2022 07:51:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.86 on epoch=25
06/02/2022 07:51:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.78 on epoch=26
06/02/2022 07:51:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.73 on epoch=27
06/02/2022 07:51:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.73 on epoch=27
06/02/2022 07:51:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.65 on epoch=28
06/02/2022 07:51:53 - INFO - __main__ - Global step 400 Train loss 0.75 Classification-F1 0.5867757934216943 on epoch=28
06/02/2022 07:51:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4420445662787761 -> 0.5867757934216943 on epoch=28, global_step=400
06/02/2022 07:51:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.74 on epoch=29
06/02/2022 07:51:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.68 on epoch=29
06/02/2022 07:51:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.70 on epoch=30
06/02/2022 07:51:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.67 on epoch=31
06/02/2022 07:51:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.66 on epoch=32
06/02/2022 07:52:03 - INFO - __main__ - Global step 450 Train loss 0.69 Classification-F1 0.5921331790893872 on epoch=32
06/02/2022 07:52:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5867757934216943 -> 0.5921331790893872 on epoch=32, global_step=450
06/02/2022 07:52:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.55 on epoch=32
06/02/2022 07:52:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.61 on epoch=33
06/02/2022 07:52:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.56 on epoch=34
06/02/2022 07:52:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=34
06/02/2022 07:52:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.51 on epoch=35
06/02/2022 07:52:13 - INFO - __main__ - Global step 500 Train loss 0.55 Classification-F1 0.5652519035797325 on epoch=35
06/02/2022 07:52:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=36
06/02/2022 07:52:15 - INFO - __main__ - Step 520 Global step 520 Train loss 0.56 on epoch=37
06/02/2022 07:52:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=37
06/02/2022 07:52:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.54 on epoch=38
06/02/2022 07:52:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=39
06/02/2022 07:52:22 - INFO - __main__ - Global step 550 Train loss 0.52 Classification-F1 0.5311627887929277 on epoch=39
06/02/2022 07:52:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.55 on epoch=39
06/02/2022 07:52:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=40
06/02/2022 07:52:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.56 on epoch=41
06/02/2022 07:52:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=42
06/02/2022 07:52:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.60 on epoch=42
06/02/2022 07:52:32 - INFO - __main__ - Global step 600 Train loss 0.54 Classification-F1 0.5598000865685769 on epoch=42
06/02/2022 07:52:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.50 on epoch=43
06/02/2022 07:52:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.48 on epoch=44
06/02/2022 07:52:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=44
06/02/2022 07:52:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.45 on epoch=45
06/02/2022 07:52:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.46 on epoch=46
06/02/2022 07:52:42 - INFO - __main__ - Global step 650 Train loss 0.48 Classification-F1 0.598833564695987 on epoch=46
06/02/2022 07:52:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5921331790893872 -> 0.598833564695987 on epoch=46, global_step=650
06/02/2022 07:52:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.42 on epoch=47
06/02/2022 07:52:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.39 on epoch=47
06/02/2022 07:52:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.59 on epoch=48
06/02/2022 07:52:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=49
06/02/2022 07:52:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.42 on epoch=49
06/02/2022 07:52:52 - INFO - __main__ - Global step 700 Train loss 0.43 Classification-F1 0.6891511297227616 on epoch=49
06/02/2022 07:52:52 - INFO - __main__ - Saving model with best Classification-F1: 0.598833564695987 -> 0.6891511297227616 on epoch=49, global_step=700
06/02/2022 07:52:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.40 on epoch=50
06/02/2022 07:52:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.41 on epoch=51
06/02/2022 07:52:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=52
06/02/2022 07:52:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.34 on epoch=52
06/02/2022 07:52:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=53
06/02/2022 07:53:01 - INFO - __main__ - Global step 750 Train loss 0.38 Classification-F1 0.6546099854658288 on epoch=53
06/02/2022 07:53:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=54
06/02/2022 07:53:04 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=54
06/02/2022 07:53:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=55
06/02/2022 07:53:07 - INFO - __main__ - Step 790 Global step 790 Train loss 0.35 on epoch=56
06/02/2022 07:53:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.36 on epoch=57
06/02/2022 07:53:11 - INFO - __main__ - Global step 800 Train loss 0.39 Classification-F1 0.6877801489952245 on epoch=57
06/02/2022 07:53:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=57
06/02/2022 07:53:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.40 on epoch=58
06/02/2022 07:53:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.30 on epoch=59
06/02/2022 07:53:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.38 on epoch=59
06/02/2022 07:53:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.38 on epoch=60
06/02/2022 07:53:21 - INFO - __main__ - Global step 850 Train loss 0.37 Classification-F1 0.6171924798447052 on epoch=60
06/02/2022 07:53:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.38 on epoch=61
06/02/2022 07:53:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=62
06/02/2022 07:53:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.30 on epoch=62
06/02/2022 07:53:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=63
06/02/2022 07:53:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=64
06/02/2022 07:53:31 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.883279788303227 on epoch=64
06/02/2022 07:53:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6891511297227616 -> 0.883279788303227 on epoch=64, global_step=900
06/02/2022 07:53:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.36 on epoch=64
06/02/2022 07:53:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=65
06/02/2022 07:53:35 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=66
06/02/2022 07:53:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/02/2022 07:53:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.35 on epoch=67
06/02/2022 07:53:41 - INFO - __main__ - Global step 950 Train loss 0.31 Classification-F1 0.8562189349397358 on epoch=67
06/02/2022 07:53:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.38 on epoch=68
06/02/2022 07:53:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.30 on epoch=69
06/02/2022 07:53:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.29 on epoch=69
06/02/2022 07:53:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.33 on epoch=70
06/02/2022 07:53:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=71
06/02/2022 07:53:50 - INFO - __main__ - Global step 1000 Train loss 0.31 Classification-F1 0.7584036112764688 on epoch=71
06/02/2022 07:53:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=72
06/02/2022 07:53:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=72
06/02/2022 07:53:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=73
06/02/2022 07:53:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=74
06/02/2022 07:53:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.26 on epoch=74
06/02/2022 07:54:00 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.7722252815123931 on epoch=74
06/02/2022 07:54:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=75
06/02/2022 07:54:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.31 on epoch=76
06/02/2022 07:54:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.28 on epoch=77
06/02/2022 07:54:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=77
06/02/2022 07:54:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=78
06/02/2022 07:54:10 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.86397726537048 on epoch=78
06/02/2022 07:54:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=79
06/02/2022 07:54:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=79
06/02/2022 07:54:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=80
06/02/2022 07:54:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.22 on epoch=81
06/02/2022 07:54:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.24 on epoch=82
06/02/2022 07:54:20 - INFO - __main__ - Global step 1150 Train loss 0.23 Classification-F1 0.7358885253862373 on epoch=82
06/02/2022 07:54:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.28 on epoch=82
06/02/2022 07:54:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=83
06/02/2022 07:54:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.33 on epoch=84
06/02/2022 07:54:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=84
06/02/2022 07:54:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.26 on epoch=85
06/02/2022 07:54:30 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.6498389697455911 on epoch=85
06/02/2022 07:54:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=86
06/02/2022 07:54:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=87
06/02/2022 07:54:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.27 on epoch=87
06/02/2022 07:54:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=88
06/02/2022 07:54:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=89
06/02/2022 07:54:39 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.5660353783200781 on epoch=89
06/02/2022 07:54:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=89
06/02/2022 07:54:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.25 on epoch=90
06/02/2022 07:54:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=91
06/02/2022 07:54:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.21 on epoch=92
06/02/2022 07:54:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=92
06/02/2022 07:54:49 - INFO - __main__ - Global step 1300 Train loss 0.21 Classification-F1 0.6919032922365156 on epoch=92
06/02/2022 07:54:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.22 on epoch=93
06/02/2022 07:54:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=94
06/02/2022 07:54:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=94
06/02/2022 07:54:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=95
06/02/2022 07:54:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
06/02/2022 07:54:59 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.6107187783480887 on epoch=96
06/02/2022 07:55:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=97
06/02/2022 07:55:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=97
06/02/2022 07:55:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=98
06/02/2022 07:55:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=99
06/02/2022 07:55:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=99
06/02/2022 07:55:09 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.7200963802230684 on epoch=99
06/02/2022 07:55:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=100
06/02/2022 07:55:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=101
06/02/2022 07:55:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=102
06/02/2022 07:55:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.22 on epoch=102
06/02/2022 07:55:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=103
06/02/2022 07:55:19 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.6847135002892043 on epoch=103
06/02/2022 07:55:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.22 on epoch=104
06/02/2022 07:55:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=104
06/02/2022 07:55:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=105
06/02/2022 07:55:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=106
06/02/2022 07:55:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=107
06/02/2022 07:55:29 - INFO - __main__ - Global step 1500 Train loss 0.16 Classification-F1 0.6620157343288393 on epoch=107
06/02/2022 07:55:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=107
06/02/2022 07:55:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=108
06/02/2022 07:55:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.22 on epoch=109
06/02/2022 07:55:34 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=109
06/02/2022 07:55:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=110
06/02/2022 07:55:39 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.535474672795593 on epoch=110
06/02/2022 07:55:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=111
06/02/2022 07:55:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
06/02/2022 07:55:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=112
06/02/2022 07:55:44 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.18 on epoch=113
06/02/2022 07:55:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=114
06/02/2022 07:55:49 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.5488448561242679 on epoch=114
06/02/2022 07:55:50 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.15 on epoch=114
06/02/2022 07:55:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.21 on epoch=115
06/02/2022 07:55:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=116
06/02/2022 07:55:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/02/2022 07:55:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=117
06/02/2022 07:55:59 - INFO - __main__ - Global step 1650 Train loss 0.15 Classification-F1 0.6125996789648832 on epoch=117
06/02/2022 07:56:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/02/2022 07:56:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=119
06/02/2022 07:56:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.16 on epoch=119
06/02/2022 07:56:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
06/02/2022 07:56:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.15 on epoch=121
06/02/2022 07:56:08 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.5909743076674827 on epoch=121
06/02/2022 07:56:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=122
06/02/2022 07:56:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.16 on epoch=122
06/02/2022 07:56:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=123
06/02/2022 07:56:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/02/2022 07:56:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=124
06/02/2022 07:56:18 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.717291805160198 on epoch=124
06/02/2022 07:56:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
06/02/2022 07:56:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=126
06/02/2022 07:56:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
06/02/2022 07:56:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.18 on epoch=127
06/02/2022 07:56:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.20 on epoch=128
06/02/2022 07:56:28 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.6690706056521469 on epoch=128
06/02/2022 07:56:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
06/02/2022 07:56:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
06/02/2022 07:56:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=130
06/02/2022 07:56:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
06/02/2022 07:56:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.13 on epoch=132
06/02/2022 07:56:38 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.5752419453569834 on epoch=132
06/02/2022 07:56:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.14 on epoch=132
06/02/2022 07:56:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.13 on epoch=133
06/02/2022 07:56:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.21 on epoch=134
06/02/2022 07:56:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
06/02/2022 07:56:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=135
06/02/2022 07:56:48 - INFO - __main__ - Global step 1900 Train loss 0.14 Classification-F1 0.5694310643217689 on epoch=135
06/02/2022 07:56:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=136
06/02/2022 07:56:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=137
06/02/2022 07:56:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=137
06/02/2022 07:56:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=138
06/02/2022 07:56:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=139
06/02/2022 07:56:58 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.493445328385352 on epoch=139
06/02/2022 07:56:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/02/2022 07:57:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.15 on epoch=140
06/02/2022 07:57:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=141
06/02/2022 07:57:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=142
06/02/2022 07:57:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=142
06/02/2022 07:57:07 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.583815442110373 on epoch=142
06/02/2022 07:57:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/02/2022 07:57:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=144
06/02/2022 07:57:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.11 on epoch=144
06/02/2022 07:57:13 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=145
06/02/2022 07:57:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/02/2022 07:57:17 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.5236254325738579 on epoch=146
06/02/2022 07:57:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=147
06/02/2022 07:57:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=147
06/02/2022 07:57:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=148
06/02/2022 07:57:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/02/2022 07:57:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.11 on epoch=149
06/02/2022 07:57:27 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.6110495618821455 on epoch=149
06/02/2022 07:57:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=150
06/02/2022 07:57:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/02/2022 07:57:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/02/2022 07:57:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=152
06/02/2022 07:57:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.16 on epoch=153
06/02/2022 07:57:37 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.577707707253298 on epoch=153
06/02/2022 07:57:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
06/02/2022 07:57:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=154
06/02/2022 07:57:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=155
06/02/2022 07:57:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
06/02/2022 07:57:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/02/2022 07:57:47 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.6962087270555012 on epoch=157
06/02/2022 07:57:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.18 on epoch=157
06/02/2022 07:57:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.17 on epoch=158
06/02/2022 07:57:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=159
06/02/2022 07:57:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=159
06/02/2022 07:57:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=160
06/02/2022 07:57:57 - INFO - __main__ - Global step 2250 Train loss 0.13 Classification-F1 0.7030021707731416 on epoch=160
06/02/2022 07:57:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/02/2022 07:57:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/02/2022 07:58:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.15 on epoch=162
06/02/2022 07:58:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/02/2022 07:58:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.11 on epoch=164
06/02/2022 07:58:06 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.7145049757318964 on epoch=164
06/02/2022 07:58:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/02/2022 07:58:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=165
06/02/2022 07:58:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/02/2022 07:58:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/02/2022 07:58:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/02/2022 07:58:16 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.8131789889836003 on epoch=167
06/02/2022 07:58:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
06/02/2022 07:58:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/02/2022 07:58:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=169
06/02/2022 07:58:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/02/2022 07:58:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.11 on epoch=171
06/02/2022 07:58:26 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7472987972667674 on epoch=171
06/02/2022 07:58:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/02/2022 07:58:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/02/2022 07:58:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/02/2022 07:58:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/02/2022 07:58:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
06/02/2022 07:58:36 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.8714584993332619 on epoch=174
06/02/2022 07:58:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=175
06/02/2022 07:58:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/02/2022 07:58:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/02/2022 07:58:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=177
06/02/2022 07:58:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/02/2022 07:58:46 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.7429781479801013 on epoch=178
06/02/2022 07:58:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
06/02/2022 07:58:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/02/2022 07:58:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/02/2022 07:58:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
06/02/2022 07:58:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/02/2022 07:58:56 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.7599940099515651 on epoch=182
06/02/2022 07:58:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 07:58:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/02/2022 07:59:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/02/2022 07:59:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/02/2022 07:59:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/02/2022 07:59:06 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7963486411793457 on epoch=185
06/02/2022 07:59:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/02/2022 07:59:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=187
06/02/2022 07:59:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
06/02/2022 07:59:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=188
06/02/2022 07:59:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/02/2022 07:59:16 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8883784100150323 on epoch=189
06/02/2022 07:59:16 - INFO - __main__ - Saving model with best Classification-F1: 0.883279788303227 -> 0.8883784100150323 on epoch=189, global_step=2650
06/02/2022 07:59:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=189
06/02/2022 07:59:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/02/2022 07:59:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.15 on epoch=191
06/02/2022 07:59:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=192
06/02/2022 07:59:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/02/2022 07:59:26 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.797053863121881 on epoch=192
06/02/2022 07:59:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/02/2022 07:59:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/02/2022 07:59:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/02/2022 07:59:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=195
06/02/2022 07:59:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/02/2022 07:59:36 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.6058515116533012 on epoch=196
06/02/2022 07:59:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/02/2022 07:59:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 07:59:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/02/2022 07:59:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/02/2022 07:59:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
06/02/2022 07:59:46 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6997548791429247 on epoch=199
06/02/2022 07:59:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/02/2022 07:59:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=201
06/02/2022 07:59:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/02/2022 07:59:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/02/2022 07:59:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=203
06/02/2022 07:59:56 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7031650843241609 on epoch=203
06/02/2022 07:59:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/02/2022 07:59:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/02/2022 08:00:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.08 on epoch=205
06/02/2022 08:00:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/02/2022 08:00:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/02/2022 08:00:06 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7094199219726767 on epoch=207
06/02/2022 08:00:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=207
06/02/2022 08:00:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/02/2022 08:00:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/02/2022 08:00:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/02/2022 08:00:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 08:00:16 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7882577471865815 on epoch=210
06/02/2022 08:00:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/02/2022 08:00:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/02/2022 08:00:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/02/2022 08:00:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/02/2022 08:00:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/02/2022 08:00:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:00:24 - INFO - __main__ - Printing 3 examples
06/02/2022 08:00:24 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 08:00:24 - INFO - __main__ - ['Plant']
06/02/2022 08:00:24 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 08:00:24 - INFO - __main__ - ['Plant']
06/02/2022 08:00:24 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 08:00:24 - INFO - __main__ - ['Plant']
06/02/2022 08:00:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:00:24 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:00:24 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:00:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:00:24 - INFO - __main__ - Printing 3 examples
06/02/2022 08:00:24 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 08:00:24 - INFO - __main__ - ['Plant']
06/02/2022 08:00:24 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 08:00:24 - INFO - __main__ - ['Plant']
06/02/2022 08:00:24 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 08:00:24 - INFO - __main__ - ['Plant']
06/02/2022 08:00:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:00:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:00:25 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:00:27 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6472441690483667 on epoch=214
06/02/2022 08:00:27 - INFO - __main__ - save last model!
06/02/2022 08:00:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 08:00:27 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 08:00:27 - INFO - __main__ - Printing 3 examples
06/02/2022 08:00:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 08:00:27 - INFO - __main__ - ['Animal']
06/02/2022 08:00:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 08:00:27 - INFO - __main__ - ['Animal']
06/02/2022 08:00:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 08:00:27 - INFO - __main__ - ['Village']
06/02/2022 08:00:27 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:00:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:00:30 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:00:30 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:00:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:00:30 - INFO - __main__ - Starting training!
06/02/2022 08:00:32 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 08:01:42 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/02/2022 08:01:42 - INFO - __main__ - Classification-F1 on test data: 0.4456
06/02/2022 08:01:42 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.8883784100150323, test_performance=0.44561363500669854
06/02/2022 08:01:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/02/2022 08:01:43 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:01:43 - INFO - __main__ - Printing 3 examples
06/02/2022 08:01:43 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/02/2022 08:01:43 - INFO - __main__ - ['Plant']
06/02/2022 08:01:43 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/02/2022 08:01:43 - INFO - __main__ - ['Plant']
06/02/2022 08:01:43 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/02/2022 08:01:43 - INFO - __main__ - ['Plant']
06/02/2022 08:01:43 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:01:44 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:01:44 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:01:44 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:01:44 - INFO - __main__ - Printing 3 examples
06/02/2022 08:01:44 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/02/2022 08:01:44 - INFO - __main__ - ['Plant']
06/02/2022 08:01:44 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
06/02/2022 08:01:44 - INFO - __main__ - ['Plant']
06/02/2022 08:01:44 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/02/2022 08:01:44 - INFO - __main__ - ['Plant']
06/02/2022 08:01:44 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:01:44 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:01:44 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:01:50 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:01:50 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:01:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:01:51 - INFO - __main__ - Starting training!
06/02/2022 08:01:52 - INFO - __main__ - Step 10 Global step 10 Train loss 6.99 on epoch=0
06/02/2022 08:01:53 - INFO - __main__ - Step 20 Global step 20 Train loss 6.08 on epoch=1
06/02/2022 08:01:55 - INFO - __main__ - Step 30 Global step 30 Train loss 5.50 on epoch=2
06/02/2022 08:01:56 - INFO - __main__ - Step 40 Global step 40 Train loss 5.77 on epoch=2
06/02/2022 08:01:57 - INFO - __main__ - Step 50 Global step 50 Train loss 5.19 on epoch=3
06/02/2022 08:02:28 - INFO - __main__ - Global step 50 Train loss 5.91 Classification-F1 0.0 on epoch=3
06/02/2022 08:02:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 08:02:30 - INFO - __main__ - Step 60 Global step 60 Train loss 4.88 on epoch=4
06/02/2022 08:02:31 - INFO - __main__ - Step 70 Global step 70 Train loss 4.43 on epoch=4
06/02/2022 08:02:32 - INFO - __main__ - Step 80 Global step 80 Train loss 4.10 on epoch=5
06/02/2022 08:02:33 - INFO - __main__ - Step 90 Global step 90 Train loss 3.72 on epoch=6
06/02/2022 08:02:34 - INFO - __main__ - Step 100 Global step 100 Train loss 3.76 on epoch=7
06/02/2022 08:02:38 - INFO - __main__ - Global step 100 Train loss 4.18 Classification-F1 0.08005673813586892 on epoch=7
06/02/2022 08:02:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.08005673813586892 on epoch=7, global_step=100
06/02/2022 08:02:40 - INFO - __main__ - Step 110 Global step 110 Train loss 3.24 on epoch=7
06/02/2022 08:02:41 - INFO - __main__ - Step 120 Global step 120 Train loss 2.97 on epoch=8
06/02/2022 08:02:42 - INFO - __main__ - Step 130 Global step 130 Train loss 2.80 on epoch=9
06/02/2022 08:02:43 - INFO - __main__ - Step 140 Global step 140 Train loss 2.47 on epoch=9
06/02/2022 08:02:45 - INFO - __main__ - Step 150 Global step 150 Train loss 2.47 on epoch=10
06/02/2022 08:02:48 - INFO - __main__ - Global step 150 Train loss 2.79 Classification-F1 0.11057480831623409 on epoch=10
06/02/2022 08:02:48 - INFO - __main__ - Saving model with best Classification-F1: 0.08005673813586892 -> 0.11057480831623409 on epoch=10, global_step=150
06/02/2022 08:02:49 - INFO - __main__ - Step 160 Global step 160 Train loss 2.23 on epoch=11
06/02/2022 08:02:50 - INFO - __main__ - Step 170 Global step 170 Train loss 2.30 on epoch=12
06/02/2022 08:02:51 - INFO - __main__ - Step 180 Global step 180 Train loss 2.14 on epoch=12
06/02/2022 08:02:53 - INFO - __main__ - Step 190 Global step 190 Train loss 2.04 on epoch=13
06/02/2022 08:02:54 - INFO - __main__ - Step 200 Global step 200 Train loss 2.16 on epoch=14
06/02/2022 08:02:57 - INFO - __main__ - Global step 200 Train loss 2.17 Classification-F1 0.14152116701965528 on epoch=14
06/02/2022 08:02:57 - INFO - __main__ - Saving model with best Classification-F1: 0.11057480831623409 -> 0.14152116701965528 on epoch=14, global_step=200
06/02/2022 08:02:59 - INFO - __main__ - Step 210 Global step 210 Train loss 2.02 on epoch=14
06/02/2022 08:03:00 - INFO - __main__ - Step 220 Global step 220 Train loss 1.93 on epoch=15
06/02/2022 08:03:01 - INFO - __main__ - Step 230 Global step 230 Train loss 1.82 on epoch=16
06/02/2022 08:03:02 - INFO - __main__ - Step 240 Global step 240 Train loss 1.63 on epoch=17
06/02/2022 08:03:04 - INFO - __main__ - Step 250 Global step 250 Train loss 1.65 on epoch=17
06/02/2022 08:03:07 - INFO - __main__ - Global step 250 Train loss 1.81 Classification-F1 0.2705547551758105 on epoch=17
06/02/2022 08:03:07 - INFO - __main__ - Saving model with best Classification-F1: 0.14152116701965528 -> 0.2705547551758105 on epoch=17, global_step=250
06/02/2022 08:03:09 - INFO - __main__ - Step 260 Global step 260 Train loss 1.58 on epoch=18
06/02/2022 08:03:10 - INFO - __main__ - Step 270 Global step 270 Train loss 1.49 on epoch=19
06/02/2022 08:03:11 - INFO - __main__ - Step 280 Global step 280 Train loss 1.51 on epoch=19
06/02/2022 08:03:12 - INFO - __main__ - Step 290 Global step 290 Train loss 1.38 on epoch=20
06/02/2022 08:03:14 - INFO - __main__ - Step 300 Global step 300 Train loss 1.43 on epoch=21
06/02/2022 08:03:17 - INFO - __main__ - Global step 300 Train loss 1.48 Classification-F1 0.31452906619262955 on epoch=21
06/02/2022 08:03:17 - INFO - __main__ - Saving model with best Classification-F1: 0.2705547551758105 -> 0.31452906619262955 on epoch=21, global_step=300
06/02/2022 08:03:18 - INFO - __main__ - Step 310 Global step 310 Train loss 1.40 on epoch=22
06/02/2022 08:03:19 - INFO - __main__ - Step 320 Global step 320 Train loss 1.25 on epoch=22
06/02/2022 08:03:20 - INFO - __main__ - Step 330 Global step 330 Train loss 1.19 on epoch=23
06/02/2022 08:03:22 - INFO - __main__ - Step 340 Global step 340 Train loss 1.38 on epoch=24
06/02/2022 08:03:23 - INFO - __main__ - Step 350 Global step 350 Train loss 1.15 on epoch=24
06/02/2022 08:03:26 - INFO - __main__ - Global step 350 Train loss 1.27 Classification-F1 0.3729615477721105 on epoch=24
06/02/2022 08:03:26 - INFO - __main__ - Saving model with best Classification-F1: 0.31452906619262955 -> 0.3729615477721105 on epoch=24, global_step=350
06/02/2022 08:03:27 - INFO - __main__ - Step 360 Global step 360 Train loss 1.15 on epoch=25
06/02/2022 08:03:29 - INFO - __main__ - Step 370 Global step 370 Train loss 1.07 on epoch=26
06/02/2022 08:03:30 - INFO - __main__ - Step 380 Global step 380 Train loss 1.17 on epoch=27
06/02/2022 08:03:31 - INFO - __main__ - Step 390 Global step 390 Train loss 1.05 on epoch=27
06/02/2022 08:03:32 - INFO - __main__ - Step 400 Global step 400 Train loss 1.15 on epoch=28
06/02/2022 08:03:35 - INFO - __main__ - Global step 400 Train loss 1.12 Classification-F1 0.4172925242313343 on epoch=28
06/02/2022 08:03:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3729615477721105 -> 0.4172925242313343 on epoch=28, global_step=400
06/02/2022 08:03:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.93 on epoch=29
06/02/2022 08:03:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.96 on epoch=29
06/02/2022 08:03:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.98 on epoch=30
06/02/2022 08:03:40 - INFO - __main__ - Step 440 Global step 440 Train loss 0.93 on epoch=31
06/02/2022 08:03:42 - INFO - __main__ - Step 450 Global step 450 Train loss 1.57 on epoch=32
06/02/2022 08:03:45 - INFO - __main__ - Global step 450 Train loss 1.07 Classification-F1 0.1619438251634342 on epoch=32
06/02/2022 08:03:46 - INFO - __main__ - Step 460 Global step 460 Train loss 1.27 on epoch=32
06/02/2022 08:03:47 - INFO - __main__ - Step 470 Global step 470 Train loss 1.30 on epoch=33
06/02/2022 08:03:49 - INFO - __main__ - Step 480 Global step 480 Train loss 1.15 on epoch=34
06/02/2022 08:03:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.95 on epoch=34
06/02/2022 08:03:51 - INFO - __main__ - Step 500 Global step 500 Train loss 1.04 on epoch=35
06/02/2022 08:03:54 - INFO - __main__ - Global step 500 Train loss 1.14 Classification-F1 0.26412199896793737 on epoch=35
06/02/2022 08:03:55 - INFO - __main__ - Step 510 Global step 510 Train loss 1.01 on epoch=36
06/02/2022 08:03:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.94 on epoch=37
06/02/2022 08:03:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.82 on epoch=37
06/02/2022 08:03:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.91 on epoch=38
06/02/2022 08:04:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.83 on epoch=39
06/02/2022 08:04:03 - INFO - __main__ - Global step 550 Train loss 0.90 Classification-F1 0.3297218727041188 on epoch=39
06/02/2022 08:04:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.83 on epoch=39
06/02/2022 08:04:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.79 on epoch=40
06/02/2022 08:04:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.84 on epoch=41
06/02/2022 08:04:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.80 on epoch=42
06/02/2022 08:04:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.78 on epoch=42
06/02/2022 08:04:13 - INFO - __main__ - Global step 600 Train loss 0.81 Classification-F1 0.4375963246495349 on epoch=42
06/02/2022 08:04:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4172925242313343 -> 0.4375963246495349 on epoch=42, global_step=600
06/02/2022 08:04:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.76 on epoch=43
06/02/2022 08:04:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.73 on epoch=44
06/02/2022 08:04:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.73 on epoch=44
06/02/2022 08:04:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.71 on epoch=45
06/02/2022 08:04:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.75 on epoch=46
06/02/2022 08:04:22 - INFO - __main__ - Global step 650 Train loss 0.73 Classification-F1 0.5110513872953584 on epoch=46
06/02/2022 08:04:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4375963246495349 -> 0.5110513872953584 on epoch=46, global_step=650
06/02/2022 08:04:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.72 on epoch=47
06/02/2022 08:04:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.73 on epoch=47
06/02/2022 08:04:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.84 on epoch=48
06/02/2022 08:04:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.67 on epoch=49
06/02/2022 08:04:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.69 on epoch=49
06/02/2022 08:04:32 - INFO - __main__ - Global step 700 Train loss 0.73 Classification-F1 0.407332567690624 on epoch=49
06/02/2022 08:04:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.71 on epoch=50
06/02/2022 08:04:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.62 on epoch=51
06/02/2022 08:04:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.67 on epoch=52
06/02/2022 08:04:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.59 on epoch=52
06/02/2022 08:04:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.57 on epoch=53
06/02/2022 08:04:42 - INFO - __main__ - Global step 750 Train loss 0.63 Classification-F1 0.38196095563466786 on epoch=53
06/02/2022 08:04:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.54 on epoch=54
06/02/2022 08:04:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.63 on epoch=54
06/02/2022 08:04:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.67 on epoch=55
06/02/2022 08:04:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.59 on epoch=56
06/02/2022 08:04:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.65 on epoch=57
06/02/2022 08:04:51 - INFO - __main__ - Global step 800 Train loss 0.62 Classification-F1 0.4032230805026415 on epoch=57
06/02/2022 08:04:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.71 on epoch=57
06/02/2022 08:04:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.53 on epoch=58
06/02/2022 08:04:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.64 on epoch=59
06/02/2022 08:04:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.56 on epoch=59
06/02/2022 08:04:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.57 on epoch=60
06/02/2022 08:05:01 - INFO - __main__ - Global step 850 Train loss 0.60 Classification-F1 0.41766331254468825 on epoch=60
06/02/2022 08:05:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.53 on epoch=61
06/02/2022 08:05:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.55 on epoch=62
06/02/2022 08:05:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.48 on epoch=62
06/02/2022 08:05:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.50 on epoch=63
06/02/2022 08:05:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.60 on epoch=64
06/02/2022 08:05:11 - INFO - __main__ - Global step 900 Train loss 0.53 Classification-F1 0.4132019530366257 on epoch=64
06/02/2022 08:05:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.57 on epoch=64
06/02/2022 08:05:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.54 on epoch=65
06/02/2022 08:05:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.51 on epoch=66
06/02/2022 08:05:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.48 on epoch=67
06/02/2022 08:05:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.46 on epoch=67
06/02/2022 08:05:21 - INFO - __main__ - Global step 950 Train loss 0.51 Classification-F1 0.4279602647807213 on epoch=67
06/02/2022 08:05:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.51 on epoch=68
06/02/2022 08:05:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.43 on epoch=69
06/02/2022 08:05:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.54 on epoch=69
06/02/2022 08:05:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.46 on epoch=70
06/02/2022 08:05:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.46 on epoch=71
06/02/2022 08:05:31 - INFO - __main__ - Global step 1000 Train loss 0.48 Classification-F1 0.3866725511703023 on epoch=71
06/02/2022 08:05:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.56 on epoch=72
06/02/2022 08:05:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.57 on epoch=72
06/02/2022 08:05:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.46 on epoch=73
06/02/2022 08:05:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.38 on epoch=74
06/02/2022 08:05:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.51 on epoch=74
06/02/2022 08:05:41 - INFO - __main__ - Global step 1050 Train loss 0.50 Classification-F1 0.5891471213429831 on epoch=74
06/02/2022 08:05:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5110513872953584 -> 0.5891471213429831 on epoch=74, global_step=1050
06/02/2022 08:05:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.54 on epoch=75
06/02/2022 08:05:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.49 on epoch=76
06/02/2022 08:05:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.47 on epoch=77
06/02/2022 08:05:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.47 on epoch=77
06/02/2022 08:05:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.33 on epoch=78
06/02/2022 08:05:51 - INFO - __main__ - Global step 1100 Train loss 0.46 Classification-F1 0.5714571531708637 on epoch=78
06/02/2022 08:05:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.42 on epoch=79
06/02/2022 08:05:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.49 on epoch=79
06/02/2022 08:05:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.48 on epoch=80
06/02/2022 08:05:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.46 on epoch=81
06/02/2022 08:05:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.40 on epoch=82
06/02/2022 08:06:02 - INFO - __main__ - Global step 1150 Train loss 0.45 Classification-F1 0.7455565817612535 on epoch=82
06/02/2022 08:06:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5891471213429831 -> 0.7455565817612535 on epoch=82, global_step=1150
06/02/2022 08:06:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.44 on epoch=82
06/02/2022 08:06:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.34 on epoch=83
06/02/2022 08:06:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.38 on epoch=84
06/02/2022 08:06:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.40 on epoch=84
06/02/2022 08:06:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.53 on epoch=85
06/02/2022 08:06:12 - INFO - __main__ - Global step 1200 Train loss 0.42 Classification-F1 0.7436866380280701 on epoch=85
06/02/2022 08:06:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.44 on epoch=86
06/02/2022 08:06:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.42 on epoch=87
06/02/2022 08:06:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.38 on epoch=87
06/02/2022 08:06:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.36 on epoch=88
06/02/2022 08:06:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.38 on epoch=89
06/02/2022 08:06:22 - INFO - __main__ - Global step 1250 Train loss 0.39 Classification-F1 0.7002233455981084 on epoch=89
06/02/2022 08:06:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.38 on epoch=89
06/02/2022 08:06:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.38 on epoch=90
06/02/2022 08:06:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.43 on epoch=91
06/02/2022 08:06:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.35 on epoch=92
06/02/2022 08:06:29 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.32 on epoch=92
06/02/2022 08:06:33 - INFO - __main__ - Global step 1300 Train loss 0.37 Classification-F1 0.8087556988643396 on epoch=92
06/02/2022 08:06:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7455565817612535 -> 0.8087556988643396 on epoch=92, global_step=1300
06/02/2022 08:06:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.29 on epoch=93
06/02/2022 08:06:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.41 on epoch=94
06/02/2022 08:06:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.41 on epoch=94
06/02/2022 08:06:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.33 on epoch=95
06/02/2022 08:06:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.29 on epoch=96
06/02/2022 08:06:43 - INFO - __main__ - Global step 1350 Train loss 0.34 Classification-F1 0.6868887931670469 on epoch=96
06/02/2022 08:06:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.32 on epoch=97
06/02/2022 08:06:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.44 on epoch=97
06/02/2022 08:06:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.37 on epoch=98
06/02/2022 08:06:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.22 on epoch=99
06/02/2022 08:06:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.35 on epoch=99
06/02/2022 08:06:53 - INFO - __main__ - Global step 1400 Train loss 0.34 Classification-F1 0.7202777066244133 on epoch=99
06/02/2022 08:06:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.33 on epoch=100
06/02/2022 08:06:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.33 on epoch=101
06/02/2022 08:06:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.28 on epoch=102
06/02/2022 08:06:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.33 on epoch=102
06/02/2022 08:07:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.30 on epoch=103
06/02/2022 08:07:03 - INFO - __main__ - Global step 1450 Train loss 0.31 Classification-F1 0.7962470921801551 on epoch=103
06/02/2022 08:07:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.33 on epoch=104
06/02/2022 08:07:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.33 on epoch=104
06/02/2022 08:07:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.30 on epoch=105
06/02/2022 08:07:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.27 on epoch=106
06/02/2022 08:07:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.31 on epoch=107
06/02/2022 08:07:13 - INFO - __main__ - Global step 1500 Train loss 0.31 Classification-F1 0.6354176721133434 on epoch=107
06/02/2022 08:07:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.30 on epoch=107
06/02/2022 08:07:16 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.38 on epoch=108
06/02/2022 08:07:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.29 on epoch=109
06/02/2022 08:07:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.35 on epoch=109
06/02/2022 08:07:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.27 on epoch=110
06/02/2022 08:07:23 - INFO - __main__ - Global step 1550 Train loss 0.32 Classification-F1 0.6596881881539126 on epoch=110
06/02/2022 08:07:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.39 on epoch=111
06/02/2022 08:07:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.20 on epoch=112
06/02/2022 08:07:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.29 on epoch=112
06/02/2022 08:07:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.31 on epoch=113
06/02/2022 08:07:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.25 on epoch=114
06/02/2022 08:07:33 - INFO - __main__ - Global step 1600 Train loss 0.29 Classification-F1 0.7171201979551126 on epoch=114
06/02/2022 08:07:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.31 on epoch=114
06/02/2022 08:07:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.22 on epoch=115
06/02/2022 08:07:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.34 on epoch=116
06/02/2022 08:07:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.27 on epoch=117
06/02/2022 08:07:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.27 on epoch=117
06/02/2022 08:07:44 - INFO - __main__ - Global step 1650 Train loss 0.28 Classification-F1 0.7605291635132261 on epoch=117
06/02/2022 08:07:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.21 on epoch=118
06/02/2022 08:07:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.22 on epoch=119
06/02/2022 08:07:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.20 on epoch=119
06/02/2022 08:07:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.25 on epoch=120
06/02/2022 08:07:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.27 on epoch=121
06/02/2022 08:07:54 - INFO - __main__ - Global step 1700 Train loss 0.23 Classification-F1 0.7365684333649509 on epoch=121
06/02/2022 08:07:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.22 on epoch=122
06/02/2022 08:07:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.27 on epoch=122
06/02/2022 08:07:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.21 on epoch=123
06/02/2022 08:07:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.20 on epoch=124
06/02/2022 08:08:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.26 on epoch=124
06/02/2022 08:08:04 - INFO - __main__ - Global step 1750 Train loss 0.23 Classification-F1 0.6865344224809653 on epoch=124
06/02/2022 08:08:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.30 on epoch=125
06/02/2022 08:08:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.18 on epoch=126
06/02/2022 08:08:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=127
06/02/2022 08:08:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.20 on epoch=127
06/02/2022 08:08:10 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.23 on epoch=128
06/02/2022 08:08:14 - INFO - __main__ - Global step 1800 Train loss 0.21 Classification-F1 0.6654994984968557 on epoch=128
06/02/2022 08:08:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.23 on epoch=129
06/02/2022 08:08:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.26 on epoch=129
06/02/2022 08:08:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.19 on epoch=130
06/02/2022 08:08:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.17 on epoch=131
06/02/2022 08:08:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.18 on epoch=132
06/02/2022 08:08:24 - INFO - __main__ - Global step 1850 Train loss 0.21 Classification-F1 0.7965060432728246 on epoch=132
06/02/2022 08:08:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.15 on epoch=132
06/02/2022 08:08:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.19 on epoch=133
06/02/2022 08:08:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.15 on epoch=134
06/02/2022 08:08:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.15 on epoch=134
06/02/2022 08:08:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.20 on epoch=135
06/02/2022 08:08:34 - INFO - __main__ - Global step 1900 Train loss 0.17 Classification-F1 0.6278590789058222 on epoch=135
06/02/2022 08:08:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.23 on epoch=136
06/02/2022 08:08:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=137
06/02/2022 08:08:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.15 on epoch=137
06/02/2022 08:08:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.20 on epoch=138
06/02/2022 08:08:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.20 on epoch=139
06/02/2022 08:08:44 - INFO - __main__ - Global step 1950 Train loss 0.18 Classification-F1 0.8593915415516213 on epoch=139
06/02/2022 08:08:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8087556988643396 -> 0.8593915415516213 on epoch=139, global_step=1950
06/02/2022 08:08:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=139
06/02/2022 08:08:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.17 on epoch=140
06/02/2022 08:08:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.20 on epoch=141
06/02/2022 08:08:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.14 on epoch=142
06/02/2022 08:08:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=142
06/02/2022 08:08:54 - INFO - __main__ - Global step 2000 Train loss 0.15 Classification-F1 0.7800525290702661 on epoch=142
06/02/2022 08:08:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.27 on epoch=143
06/02/2022 08:08:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.15 on epoch=144
06/02/2022 08:08:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.21 on epoch=144
06/02/2022 08:08:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.15 on epoch=145
06/02/2022 08:09:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
06/02/2022 08:09:04 - INFO - __main__ - Global step 2050 Train loss 0.17 Classification-F1 0.6432031152832043 on epoch=146
06/02/2022 08:09:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/02/2022 08:09:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.18 on epoch=147
06/02/2022 08:09:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=148
06/02/2022 08:09:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.13 on epoch=149
06/02/2022 08:09:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.17 on epoch=149
06/02/2022 08:09:14 - INFO - __main__ - Global step 2100 Train loss 0.14 Classification-F1 0.7491539199611486 on epoch=149
06/02/2022 08:09:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.18 on epoch=150
06/02/2022 08:09:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.15 on epoch=151
06/02/2022 08:09:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.17 on epoch=152
06/02/2022 08:09:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=152
06/02/2022 08:09:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/02/2022 08:09:24 - INFO - __main__ - Global step 2150 Train loss 0.14 Classification-F1 0.7669062365308807 on epoch=153
06/02/2022 08:09:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=154
06/02/2022 08:09:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=154
06/02/2022 08:09:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.13 on epoch=155
06/02/2022 08:09:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/02/2022 08:09:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/02/2022 08:09:33 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.7291440626803184 on epoch=157
06/02/2022 08:09:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.17 on epoch=157
06/02/2022 08:09:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=158
06/02/2022 08:09:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
06/02/2022 08:09:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.12 on epoch=159
06/02/2022 08:09:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.13 on epoch=160
06/02/2022 08:09:43 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.7428194953066338 on epoch=160
06/02/2022 08:09:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=161
06/02/2022 08:09:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.12 on epoch=162
06/02/2022 08:09:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=162
06/02/2022 08:09:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=163
06/02/2022 08:09:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.18 on epoch=164
06/02/2022 08:09:53 - INFO - __main__ - Global step 2300 Train loss 0.12 Classification-F1 0.6640755347066717 on epoch=164
06/02/2022 08:09:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=164
06/02/2022 08:09:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=165
06/02/2022 08:09:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=166
06/02/2022 08:09:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/02/2022 08:10:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.11 on epoch=167
06/02/2022 08:10:03 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.6560578582133032 on epoch=167
06/02/2022 08:10:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=168
06/02/2022 08:10:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.11 on epoch=169
06/02/2022 08:10:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=169
06/02/2022 08:10:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.11 on epoch=170
06/02/2022 08:10:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.17 on epoch=171
06/02/2022 08:10:13 - INFO - __main__ - Global step 2400 Train loss 0.12 Classification-F1 0.6755512493271224 on epoch=171
06/02/2022 08:10:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.12 on epoch=172
06/02/2022 08:10:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=172
06/02/2022 08:10:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.10 on epoch=173
06/02/2022 08:10:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=174
06/02/2022 08:10:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
06/02/2022 08:10:23 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.6484249842771695 on epoch=174
06/02/2022 08:10:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=175
06/02/2022 08:10:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=176
06/02/2022 08:10:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.15 on epoch=177
06/02/2022 08:10:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=177
06/02/2022 08:10:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=178
06/02/2022 08:10:33 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.6720551800459353 on epoch=178
06/02/2022 08:10:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=179
06/02/2022 08:10:36 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.15 on epoch=179
06/02/2022 08:10:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=180
06/02/2022 08:10:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.12 on epoch=181
06/02/2022 08:10:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=182
06/02/2022 08:10:44 - INFO - __main__ - Global step 2550 Train loss 0.11 Classification-F1 0.570024412852228 on epoch=182
06/02/2022 08:10:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=182
06/02/2022 08:10:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.14 on epoch=183
06/02/2022 08:10:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=184
06/02/2022 08:10:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=184
06/02/2022 08:10:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/02/2022 08:10:54 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.7255558493783107 on epoch=185
06/02/2022 08:10:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=186
06/02/2022 08:10:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=187
06/02/2022 08:10:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=187
06/02/2022 08:10:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.12 on epoch=188
06/02/2022 08:11:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=189
06/02/2022 08:11:03 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.7508002654676043 on epoch=189
06/02/2022 08:11:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.11 on epoch=189
06/02/2022 08:11:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.17 on epoch=190
06/02/2022 08:11:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
06/02/2022 08:11:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=192
06/02/2022 08:11:10 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.15 on epoch=192
06/02/2022 08:11:13 - INFO - __main__ - Global step 2700 Train loss 0.11 Classification-F1 0.5785491571995366 on epoch=192
06/02/2022 08:11:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=193
06/02/2022 08:11:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=194
06/02/2022 08:11:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=194
06/02/2022 08:11:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=195
06/02/2022 08:11:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.14 on epoch=196
06/02/2022 08:11:23 - INFO - __main__ - Global step 2750 Train loss 0.10 Classification-F1 0.6717210719319544 on epoch=196
06/02/2022 08:11:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.15 on epoch=197
06/02/2022 08:11:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=197
06/02/2022 08:11:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=198
06/02/2022 08:11:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=199
06/02/2022 08:11:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=199
06/02/2022 08:11:33 - INFO - __main__ - Global step 2800 Train loss 0.10 Classification-F1 0.6789561056217637 on epoch=199
06/02/2022 08:11:34 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.09 on epoch=200
06/02/2022 08:11:35 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 08:11:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.12 on epoch=202
06/02/2022 08:11:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=202
06/02/2022 08:11:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
06/02/2022 08:11:43 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.5764390278757315 on epoch=203
06/02/2022 08:11:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=204
06/02/2022 08:11:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
06/02/2022 08:11:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.12 on epoch=205
06/02/2022 08:11:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
06/02/2022 08:11:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.12 on epoch=207
06/02/2022 08:11:52 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.7068492234484534 on epoch=207
06/02/2022 08:11:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.15 on epoch=207
06/02/2022 08:11:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=208
06/02/2022 08:11:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=209
06/02/2022 08:11:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.10 on epoch=209
06/02/2022 08:11:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.10 on epoch=210
06/02/2022 08:12:02 - INFO - __main__ - Global step 2950 Train loss 0.10 Classification-F1 0.7081184837883964 on epoch=210
06/02/2022 08:12:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=211
06/02/2022 08:12:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=212
06/02/2022 08:12:06 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=212
06/02/2022 08:12:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.10 on epoch=213
06/02/2022 08:12:08 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.11 on epoch=214
06/02/2022 08:12:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:12:10 - INFO - __main__ - Printing 3 examples
06/02/2022 08:12:10 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:12:10 - INFO - __main__ - ['Company']
06/02/2022 08:12:10 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:12:10 - INFO - __main__ - ['Company']
06/02/2022 08:12:10 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:12:10 - INFO - __main__ - ['Company']
06/02/2022 08:12:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:12:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:12:10 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:12:10 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:12:10 - INFO - __main__ - Printing 3 examples
06/02/2022 08:12:10 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:12:10 - INFO - __main__ - ['Company']
06/02/2022 08:12:10 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:12:10 - INFO - __main__ - ['Company']
06/02/2022 08:12:10 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:12:10 - INFO - __main__ - ['Company']
06/02/2022 08:12:10 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:12:10 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:12:10 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:12:12 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.741005893173232 on epoch=214
06/02/2022 08:12:12 - INFO - __main__ - save last model!
06/02/2022 08:12:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 08:12:12 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 08:12:12 - INFO - __main__ - Printing 3 examples
06/02/2022 08:12:12 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 08:12:12 - INFO - __main__ - ['Animal']
06/02/2022 08:12:12 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 08:12:12 - INFO - __main__ - ['Animal']
06/02/2022 08:12:12 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 08:12:12 - INFO - __main__ - ['Village']
06/02/2022 08:12:12 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:12:14 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:12:16 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:12:16 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:12:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:12:17 - INFO - __main__ - Starting training!
06/02/2022 08:12:17 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 08:13:26 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/02/2022 08:13:26 - INFO - __main__ - Classification-F1 on test data: 0.4524
06/02/2022 08:13:27 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.8593915415516213, test_performance=0.45235355548366596
06/02/2022 08:13:27 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/02/2022 08:13:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:13:27 - INFO - __main__ - Printing 3 examples
06/02/2022 08:13:27 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:13:27 - INFO - __main__ - ['Company']
06/02/2022 08:13:27 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:13:27 - INFO - __main__ - ['Company']
06/02/2022 08:13:27 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:13:27 - INFO - __main__ - ['Company']
06/02/2022 08:13:27 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:13:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:13:28 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:13:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:13:28 - INFO - __main__ - Printing 3 examples
06/02/2022 08:13:28 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:13:28 - INFO - __main__ - ['Company']
06/02/2022 08:13:28 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:13:28 - INFO - __main__ - ['Company']
06/02/2022 08:13:28 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:13:28 - INFO - __main__ - ['Company']
06/02/2022 08:13:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:13:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:13:28 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:13:34 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:13:34 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:13:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:13:35 - INFO - __main__ - Starting training!
06/02/2022 08:13:36 - INFO - __main__ - Step 10 Global step 10 Train loss 6.07 on epoch=0
06/02/2022 08:13:37 - INFO - __main__ - Step 20 Global step 20 Train loss 4.89 on epoch=1
06/02/2022 08:13:39 - INFO - __main__ - Step 30 Global step 30 Train loss 4.17 on epoch=2
06/02/2022 08:13:40 - INFO - __main__ - Step 40 Global step 40 Train loss 3.60 on epoch=2
06/02/2022 08:13:41 - INFO - __main__ - Step 50 Global step 50 Train loss 3.47 on epoch=3
06/02/2022 08:13:46 - INFO - __main__ - Global step 50 Train loss 4.44 Classification-F1 0.12353518078026128 on epoch=3
06/02/2022 08:13:46 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12353518078026128 on epoch=3, global_step=50
06/02/2022 08:13:47 - INFO - __main__ - Step 60 Global step 60 Train loss 2.99 on epoch=4
06/02/2022 08:13:49 - INFO - __main__ - Step 70 Global step 70 Train loss 2.88 on epoch=4
06/02/2022 08:13:50 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=5
06/02/2022 08:13:51 - INFO - __main__ - Step 90 Global step 90 Train loss 2.39 on epoch=6
06/02/2022 08:13:53 - INFO - __main__ - Step 100 Global step 100 Train loss 2.14 on epoch=7
06/02/2022 08:13:56 - INFO - __main__ - Global step 100 Train loss 2.57 Classification-F1 0.2560526679539371 on epoch=7
06/02/2022 08:13:56 - INFO - __main__ - Saving model with best Classification-F1: 0.12353518078026128 -> 0.2560526679539371 on epoch=7, global_step=100
06/02/2022 08:13:57 - INFO - __main__ - Step 110 Global step 110 Train loss 2.06 on epoch=7
06/02/2022 08:13:58 - INFO - __main__ - Step 120 Global step 120 Train loss 1.71 on epoch=8
06/02/2022 08:14:00 - INFO - __main__ - Step 130 Global step 130 Train loss 1.51 on epoch=9
06/02/2022 08:14:01 - INFO - __main__ - Step 140 Global step 140 Train loss 1.38 on epoch=9
06/02/2022 08:14:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.28 on epoch=10
06/02/2022 08:14:05 - INFO - __main__ - Global step 150 Train loss 1.59 Classification-F1 0.352748788922455 on epoch=10
06/02/2022 08:14:05 - INFO - __main__ - Saving model with best Classification-F1: 0.2560526679539371 -> 0.352748788922455 on epoch=10, global_step=150
06/02/2022 08:14:07 - INFO - __main__ - Step 160 Global step 160 Train loss 1.21 on epoch=11
06/02/2022 08:14:08 - INFO - __main__ - Step 170 Global step 170 Train loss 1.20 on epoch=12
06/02/2022 08:14:09 - INFO - __main__ - Step 180 Global step 180 Train loss 1.11 on epoch=12
06/02/2022 08:14:11 - INFO - __main__ - Step 190 Global step 190 Train loss 1.14 on epoch=13
06/02/2022 08:14:12 - INFO - __main__ - Step 200 Global step 200 Train loss 1.08 on epoch=14
06/02/2022 08:14:15 - INFO - __main__ - Global step 200 Train loss 1.15 Classification-F1 0.20122106703714138 on epoch=14
06/02/2022 08:14:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.97 on epoch=14
06/02/2022 08:14:18 - INFO - __main__ - Step 220 Global step 220 Train loss 1.00 on epoch=15
06/02/2022 08:14:19 - INFO - __main__ - Step 230 Global step 230 Train loss 1.03 on epoch=16
06/02/2022 08:14:20 - INFO - __main__ - Step 240 Global step 240 Train loss 1.15 on epoch=17
06/02/2022 08:14:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.98 on epoch=17
06/02/2022 08:14:24 - INFO - __main__ - Global step 250 Train loss 1.03 Classification-F1 0.38149489963514355 on epoch=17
06/02/2022 08:14:24 - INFO - __main__ - Saving model with best Classification-F1: 0.352748788922455 -> 0.38149489963514355 on epoch=17, global_step=250
06/02/2022 08:14:26 - INFO - __main__ - Step 260 Global step 260 Train loss 1.10 on epoch=18
06/02/2022 08:14:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.99 on epoch=19
06/02/2022 08:14:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.91 on epoch=19
06/02/2022 08:14:30 - INFO - __main__ - Step 290 Global step 290 Train loss 1.11 on epoch=20
06/02/2022 08:14:31 - INFO - __main__ - Step 300 Global step 300 Train loss 1.03 on epoch=21
06/02/2022 08:14:34 - INFO - __main__ - Global step 300 Train loss 1.03 Classification-F1 0.44130194780803295 on epoch=21
06/02/2022 08:14:34 - INFO - __main__ - Saving model with best Classification-F1: 0.38149489963514355 -> 0.44130194780803295 on epoch=21, global_step=300
06/02/2022 08:14:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.93 on epoch=22
06/02/2022 08:14:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.82 on epoch=22
06/02/2022 08:14:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.77 on epoch=23
06/02/2022 08:14:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.86 on epoch=24
06/02/2022 08:14:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.80 on epoch=24
06/02/2022 08:14:44 - INFO - __main__ - Global step 350 Train loss 0.84 Classification-F1 0.3950168522555736 on epoch=24
06/02/2022 08:14:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.71 on epoch=25
06/02/2022 08:14:47 - INFO - __main__ - Step 370 Global step 370 Train loss 0.77 on epoch=26
06/02/2022 08:14:48 - INFO - __main__ - Step 380 Global step 380 Train loss 0.79 on epoch=27
06/02/2022 08:14:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.70 on epoch=27
06/02/2022 08:14:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.56 on epoch=28
06/02/2022 08:14:54 - INFO - __main__ - Global step 400 Train loss 0.70 Classification-F1 0.45603819843325094 on epoch=28
06/02/2022 08:14:54 - INFO - __main__ - Saving model with best Classification-F1: 0.44130194780803295 -> 0.45603819843325094 on epoch=28, global_step=400
06/02/2022 08:14:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.66 on epoch=29
06/02/2022 08:14:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.67 on epoch=29
06/02/2022 08:14:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.63 on epoch=30
06/02/2022 08:14:59 - INFO - __main__ - Step 440 Global step 440 Train loss 0.75 on epoch=31
06/02/2022 08:15:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.85 on epoch=32
06/02/2022 08:15:04 - INFO - __main__ - Global step 450 Train loss 0.71 Classification-F1 0.4351660126980336 on epoch=32
06/02/2022 08:15:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.67 on epoch=32
06/02/2022 08:15:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.55 on epoch=33
06/02/2022 08:15:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.62 on epoch=34
06/02/2022 08:15:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.68 on epoch=34
06/02/2022 08:15:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.63 on epoch=35
06/02/2022 08:15:14 - INFO - __main__ - Global step 500 Train loss 0.63 Classification-F1 0.4214332261607011 on epoch=35
06/02/2022 08:15:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=36
06/02/2022 08:15:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.58 on epoch=37
06/02/2022 08:15:18 - INFO - __main__ - Step 530 Global step 530 Train loss 0.62 on epoch=37
06/02/2022 08:15:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.55 on epoch=38
06/02/2022 08:15:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.55 on epoch=39
06/02/2022 08:15:24 - INFO - __main__ - Global step 550 Train loss 0.58 Classification-F1 0.3455820837565259 on epoch=39
06/02/2022 08:15:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.55 on epoch=39
06/02/2022 08:15:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.49 on epoch=40
06/02/2022 08:15:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.52 on epoch=41
06/02/2022 08:15:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.56 on epoch=42
06/02/2022 08:15:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.58 on epoch=42
06/02/2022 08:15:34 - INFO - __main__ - Global step 600 Train loss 0.54 Classification-F1 0.42679829198834096 on epoch=42
06/02/2022 08:15:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.52 on epoch=43
06/02/2022 08:15:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.45 on epoch=44
06/02/2022 08:15:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.52 on epoch=44
06/02/2022 08:15:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.52 on epoch=45
06/02/2022 08:15:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.56 on epoch=46
06/02/2022 08:15:43 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.3923880494958926 on epoch=46
06/02/2022 08:15:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.59 on epoch=47
06/02/2022 08:15:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.49 on epoch=47
06/02/2022 08:15:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.42 on epoch=48
06/02/2022 08:15:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.45 on epoch=49
06/02/2022 08:15:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.46 on epoch=49
06/02/2022 08:15:53 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.39893250179822076 on epoch=49
06/02/2022 08:15:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.40 on epoch=50
06/02/2022 08:15:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.52 on epoch=51
06/02/2022 08:15:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=52
06/02/2022 08:15:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.42 on epoch=52
06/02/2022 08:16:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=53
06/02/2022 08:16:03 - INFO - __main__ - Global step 750 Train loss 0.41 Classification-F1 0.5293157339371206 on epoch=53
06/02/2022 08:16:03 - INFO - __main__ - Saving model with best Classification-F1: 0.45603819843325094 -> 0.5293157339371206 on epoch=53, global_step=750
06/02/2022 08:16:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=54
06/02/2022 08:16:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.39 on epoch=54
06/02/2022 08:16:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=55
06/02/2022 08:16:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.42 on epoch=56
06/02/2022 08:16:10 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=57
06/02/2022 08:16:14 - INFO - __main__ - Global step 800 Train loss 0.38 Classification-F1 0.6765863489416621 on epoch=57
06/02/2022 08:16:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5293157339371206 -> 0.6765863489416621 on epoch=57, global_step=800
06/02/2022 08:16:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=57
06/02/2022 08:16:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.34 on epoch=58
06/02/2022 08:16:18 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=59
06/02/2022 08:16:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=59
06/02/2022 08:16:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.35 on epoch=60
06/02/2022 08:16:24 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.7759042033235581 on epoch=60
06/02/2022 08:16:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6765863489416621 -> 0.7759042033235581 on epoch=60, global_step=850
06/02/2022 08:16:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.41 on epoch=61
06/02/2022 08:16:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.34 on epoch=62
06/02/2022 08:16:28 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=62
06/02/2022 08:16:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=63
06/02/2022 08:16:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.31 on epoch=64
06/02/2022 08:16:34 - INFO - __main__ - Global step 900 Train loss 0.33 Classification-F1 0.6228243776134289 on epoch=64
06/02/2022 08:16:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.35 on epoch=64
06/02/2022 08:16:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.26 on epoch=65
06/02/2022 08:16:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=66
06/02/2022 08:16:40 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=67
06/02/2022 08:16:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=67
06/02/2022 08:16:44 - INFO - __main__ - Global step 950 Train loss 0.30 Classification-F1 0.7292924797479652 on epoch=67
06/02/2022 08:16:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=68
06/02/2022 08:16:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=69
06/02/2022 08:16:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.29 on epoch=69
06/02/2022 08:16:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.21 on epoch=70
06/02/2022 08:16:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.34 on epoch=71
06/02/2022 08:16:55 - INFO - __main__ - Global step 1000 Train loss 0.28 Classification-F1 0.7427626125299466 on epoch=71
06/02/2022 08:16:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.27 on epoch=72
06/02/2022 08:16:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.25 on epoch=72
06/02/2022 08:16:58 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=73
06/02/2022 08:17:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=74
06/02/2022 08:17:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=74
06/02/2022 08:17:05 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.7292691011091813 on epoch=74
06/02/2022 08:17:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=75
06/02/2022 08:17:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.23 on epoch=76
06/02/2022 08:17:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=77
06/02/2022 08:17:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=77
06/02/2022 08:17:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=78
06/02/2022 08:17:15 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.7648615163015055 on epoch=78
06/02/2022 08:17:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.28 on epoch=79
06/02/2022 08:17:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=79
06/02/2022 08:17:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.27 on epoch=80
06/02/2022 08:17:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.24 on epoch=81
06/02/2022 08:17:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.21 on epoch=82
06/02/2022 08:17:25 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.8030985009149425 on epoch=82
06/02/2022 08:17:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7759042033235581 -> 0.8030985009149425 on epoch=82, global_step=1150
06/02/2022 08:17:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=82
06/02/2022 08:17:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.29 on epoch=83
06/02/2022 08:17:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.28 on epoch=84
06/02/2022 08:17:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=84
06/02/2022 08:17:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=85
06/02/2022 08:17:35 - INFO - __main__ - Global step 1200 Train loss 0.24 Classification-F1 0.6708960081909192 on epoch=85
06/02/2022 08:17:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.27 on epoch=86
06/02/2022 08:17:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=87
06/02/2022 08:17:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.23 on epoch=87
06/02/2022 08:17:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
06/02/2022 08:17:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.32 on epoch=89
06/02/2022 08:17:45 - INFO - __main__ - Global step 1250 Train loss 0.26 Classification-F1 0.7847356572437496 on epoch=89
06/02/2022 08:17:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.28 on epoch=89
06/02/2022 08:17:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=90
06/02/2022 08:17:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=91
06/02/2022 08:17:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=92
06/02/2022 08:17:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.25 on epoch=92
06/02/2022 08:17:55 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.764249468115692 on epoch=92
06/02/2022 08:17:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=93
06/02/2022 08:17:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=94
06/02/2022 08:17:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=94
06/02/2022 08:18:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.24 on epoch=95
06/02/2022 08:18:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=96
06/02/2022 08:18:05 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.847067200831187 on epoch=96
06/02/2022 08:18:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8030985009149425 -> 0.847067200831187 on epoch=96, global_step=1350
06/02/2022 08:18:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.29 on epoch=97
06/02/2022 08:18:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=97
06/02/2022 08:18:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=98
06/02/2022 08:18:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.22 on epoch=99
06/02/2022 08:18:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=99
06/02/2022 08:18:15 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.7760432730867971 on epoch=99
06/02/2022 08:18:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
06/02/2022 08:18:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.24 on epoch=101
06/02/2022 08:18:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.21 on epoch=102
06/02/2022 08:18:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.25 on epoch=102
06/02/2022 08:18:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=103
06/02/2022 08:18:25 - INFO - __main__ - Global step 1450 Train loss 0.20 Classification-F1 0.7880029850953427 on epoch=103
06/02/2022 08:18:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.18 on epoch=104
06/02/2022 08:18:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.24 on epoch=104
06/02/2022 08:18:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=105
06/02/2022 08:18:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.16 on epoch=106
06/02/2022 08:18:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=107
06/02/2022 08:18:35 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.7877159655567806 on epoch=107
06/02/2022 08:18:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=107
06/02/2022 08:18:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=108
06/02/2022 08:18:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=109
06/02/2022 08:18:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.16 on epoch=109
06/02/2022 08:18:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=110
06/02/2022 08:18:46 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.7420723874880455 on epoch=110
06/02/2022 08:18:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=111
06/02/2022 08:18:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.19 on epoch=112
06/02/2022 08:18:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=112
06/02/2022 08:18:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.17 on epoch=113
06/02/2022 08:18:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
06/02/2022 08:18:55 - INFO - __main__ - Global step 1600 Train loss 0.15 Classification-F1 0.9145120560443142 on epoch=114
06/02/2022 08:18:56 - INFO - __main__ - Saving model with best Classification-F1: 0.847067200831187 -> 0.9145120560443142 on epoch=114, global_step=1600
06/02/2022 08:18:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=114
06/02/2022 08:18:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
06/02/2022 08:18:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=116
06/02/2022 08:19:01 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/02/2022 08:19:02 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=117
06/02/2022 08:19:05 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.6926250079026471 on epoch=117
06/02/2022 08:19:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=118
06/02/2022 08:19:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.18 on epoch=119
06/02/2022 08:19:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=119
06/02/2022 08:19:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
06/02/2022 08:19:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/02/2022 08:19:15 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.7798526856164427 on epoch=121
06/02/2022 08:19:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.20 on epoch=122
06/02/2022 08:19:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=122
06/02/2022 08:19:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
06/02/2022 08:19:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.19 on epoch=124
06/02/2022 08:19:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=124
06/02/2022 08:19:25 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.8591107649071359 on epoch=124
06/02/2022 08:19:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=125
06/02/2022 08:19:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.18 on epoch=126
06/02/2022 08:19:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=127
06/02/2022 08:19:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=127
06/02/2022 08:19:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
06/02/2022 08:19:36 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.827364037871628 on epoch=128
06/02/2022 08:19:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=129
06/02/2022 08:19:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/02/2022 08:19:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=130
06/02/2022 08:19:42 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=131
06/02/2022 08:19:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 08:19:47 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.9144998370804821 on epoch=132
06/02/2022 08:19:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=132
06/02/2022 08:19:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/02/2022 08:19:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=134
06/02/2022 08:19:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=134
06/02/2022 08:19:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=135
06/02/2022 08:19:57 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.9776567518503 on epoch=135
06/02/2022 08:19:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9145120560443142 -> 0.9776567518503 on epoch=135, global_step=1900
06/02/2022 08:19:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=136
06/02/2022 08:19:59 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=137
06/02/2022 08:20:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=137
06/02/2022 08:20:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=138
06/02/2022 08:20:03 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=139
06/02/2022 08:20:07 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.8273706119072498 on epoch=139
06/02/2022 08:20:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/02/2022 08:20:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=140
06/02/2022 08:20:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.17 on epoch=141
06/02/2022 08:20:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=142
06/02/2022 08:20:13 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=142
06/02/2022 08:20:17 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.9602170486963113 on epoch=142
06/02/2022 08:20:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/02/2022 08:20:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/02/2022 08:20:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/02/2022 08:20:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=145
06/02/2022 08:20:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=146
06/02/2022 08:20:26 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7915464000462807 on epoch=146
06/02/2022 08:20:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.14 on epoch=147
06/02/2022 08:20:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/02/2022 08:20:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/02/2022 08:20:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
06/02/2022 08:20:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.10 on epoch=149
06/02/2022 08:20:36 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.8436884926152516 on epoch=149
06/02/2022 08:20:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/02/2022 08:20:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
06/02/2022 08:20:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=152
06/02/2022 08:20:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.13 on epoch=152
06/02/2022 08:20:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/02/2022 08:20:46 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.8980198296327327 on epoch=153
06/02/2022 08:20:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/02/2022 08:20:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/02/2022 08:20:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=155
06/02/2022 08:20:51 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
06/02/2022 08:20:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
06/02/2022 08:20:56 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.8957299958106408 on epoch=157
06/02/2022 08:20:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/02/2022 08:20:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/02/2022 08:21:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
06/02/2022 08:21:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.16 on epoch=159
06/02/2022 08:21:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 08:21:06 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.8512982649071359 on epoch=160
06/02/2022 08:21:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/02/2022 08:21:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=162
06/02/2022 08:21:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/02/2022 08:21:11 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=163
06/02/2022 08:21:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/02/2022 08:21:16 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.9686931664161265 on epoch=164
06/02/2022 08:21:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/02/2022 08:21:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=165
06/02/2022 08:21:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=166
06/02/2022 08:21:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=167
06/02/2022 08:21:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=167
06/02/2022 08:21:26 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.9511534724787545 on epoch=167
06/02/2022 08:21:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
06/02/2022 08:21:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=169
06/02/2022 08:21:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=169
06/02/2022 08:21:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/02/2022 08:21:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/02/2022 08:21:36 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.9349523460410557 on epoch=171
06/02/2022 08:21:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=172
06/02/2022 08:21:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/02/2022 08:21:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/02/2022 08:21:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=174
06/02/2022 08:21:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=174
06/02/2022 08:21:47 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.9866027789414886 on epoch=174
06/02/2022 08:21:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9776567518503 -> 0.9866027789414886 on epoch=174, global_step=2450
06/02/2022 08:21:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/02/2022 08:21:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=176
06/02/2022 08:21:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/02/2022 08:21:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=177
06/02/2022 08:21:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/02/2022 08:21:57 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.9098923045808474 on epoch=178
06/02/2022 08:21:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.10 on epoch=179
06/02/2022 08:21:59 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=179
06/02/2022 08:22:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/02/2022 08:22:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=181
06/02/2022 08:22:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=182
06/02/2022 08:22:07 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.9015181455330641 on epoch=182
06/02/2022 08:22:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.09 on epoch=182
06/02/2022 08:22:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/02/2022 08:22:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/02/2022 08:22:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=184
06/02/2022 08:22:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=185
06/02/2022 08:22:17 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.9685702066750453 on epoch=185
06/02/2022 08:22:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/02/2022 08:22:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=187
06/02/2022 08:22:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/02/2022 08:22:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/02/2022 08:22:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=189
06/02/2022 08:22:27 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.9640971931294511 on epoch=189
06/02/2022 08:22:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=189
06/02/2022 08:22:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/02/2022 08:22:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=191
06/02/2022 08:22:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 08:22:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/02/2022 08:22:38 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9687238165060743 on epoch=192
06/02/2022 08:22:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/02/2022 08:22:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/02/2022 08:22:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.10 on epoch=194
06/02/2022 08:22:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/02/2022 08:22:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/02/2022 08:22:48 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.9185353535353535 on epoch=196
06/02/2022 08:22:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=197
06/02/2022 08:22:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/02/2022 08:22:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/02/2022 08:22:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=199
06/02/2022 08:22:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/02/2022 08:22:58 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7989173948475132 on epoch=199
06/02/2022 08:22:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/02/2022 08:23:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=201
06/02/2022 08:23:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=202
06/02/2022 08:23:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=202
06/02/2022 08:23:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/02/2022 08:23:08 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.9060231345715216 on epoch=203
06/02/2022 08:23:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=204
06/02/2022 08:23:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
06/02/2022 08:23:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/02/2022 08:23:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/02/2022 08:23:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/02/2022 08:23:18 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.9063694549178422 on epoch=207
06/02/2022 08:23:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/02/2022 08:23:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/02/2022 08:23:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/02/2022 08:23:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/02/2022 08:23:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/02/2022 08:23:28 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8474951124144672 on epoch=210
06/02/2022 08:23:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=211
06/02/2022 08:23:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/02/2022 08:23:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/02/2022 08:23:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/02/2022 08:23:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=214
06/02/2022 08:23:35 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:23:35 - INFO - __main__ - Printing 3 examples
06/02/2022 08:23:35 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:23:35 - INFO - __main__ - ['Company']
06/02/2022 08:23:35 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:23:35 - INFO - __main__ - ['Company']
06/02/2022 08:23:35 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:23:35 - INFO - __main__ - ['Company']
06/02/2022 08:23:35 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:23:35 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:23:36 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:23:36 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:23:36 - INFO - __main__ - Printing 3 examples
06/02/2022 08:23:36 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:23:36 - INFO - __main__ - ['Company']
06/02/2022 08:23:36 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:23:36 - INFO - __main__ - ['Company']
06/02/2022 08:23:36 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:23:36 - INFO - __main__ - ['Company']
06/02/2022 08:23:36 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:23:36 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:23:36 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:23:37 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8512829912023461 on epoch=214
06/02/2022 08:23:37 - INFO - __main__ - save last model!
06/02/2022 08:23:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 08:23:37 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 08:23:37 - INFO - __main__ - Printing 3 examples
06/02/2022 08:23:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 08:23:37 - INFO - __main__ - ['Animal']
06/02/2022 08:23:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 08:23:37 - INFO - __main__ - ['Animal']
06/02/2022 08:23:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 08:23:37 - INFO - __main__ - ['Village']
06/02/2022 08:23:37 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:23:39 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:23:41 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:23:41 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:23:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:23:42 - INFO - __main__ - Starting training!
06/02/2022 08:23:43 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 08:24:54 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/02/2022 08:24:54 - INFO - __main__ - Classification-F1 on test data: 0.5223
06/02/2022 08:24:54 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9866027789414886, test_performance=0.5223057283772232
06/02/2022 08:24:54 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/02/2022 08:24:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:24:55 - INFO - __main__ - Printing 3 examples
06/02/2022 08:24:55 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:24:55 - INFO - __main__ - ['Company']
06/02/2022 08:24:55 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:24:55 - INFO - __main__ - ['Company']
06/02/2022 08:24:55 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:24:55 - INFO - __main__ - ['Company']
06/02/2022 08:24:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:24:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:24:55 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:24:55 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:24:55 - INFO - __main__ - Printing 3 examples
06/02/2022 08:24:55 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:24:55 - INFO - __main__ - ['Company']
06/02/2022 08:24:55 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:24:55 - INFO - __main__ - ['Company']
06/02/2022 08:24:55 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:24:55 - INFO - __main__ - ['Company']
06/02/2022 08:24:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:24:55 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:24:55 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:25:01 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:25:01 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:25:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:25:02 - INFO - __main__ - Starting training!
06/02/2022 08:25:03 - INFO - __main__ - Step 10 Global step 10 Train loss 6.48 on epoch=0
06/02/2022 08:25:05 - INFO - __main__ - Step 20 Global step 20 Train loss 5.40 on epoch=1
06/02/2022 08:25:06 - INFO - __main__ - Step 30 Global step 30 Train loss 4.83 on epoch=2
06/02/2022 08:25:07 - INFO - __main__ - Step 40 Global step 40 Train loss 4.11 on epoch=2
06/02/2022 08:25:09 - INFO - __main__ - Step 50 Global step 50 Train loss 3.48 on epoch=3
06/02/2022 08:25:17 - INFO - __main__ - Global step 50 Train loss 4.86 Classification-F1 0.055328450960803896 on epoch=3
06/02/2022 08:25:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.055328450960803896 on epoch=3, global_step=50
06/02/2022 08:25:18 - INFO - __main__ - Step 60 Global step 60 Train loss 3.00 on epoch=4
06/02/2022 08:25:19 - INFO - __main__ - Step 70 Global step 70 Train loss 2.85 on epoch=4
06/02/2022 08:25:20 - INFO - __main__ - Step 80 Global step 80 Train loss 2.39 on epoch=5
06/02/2022 08:25:22 - INFO - __main__ - Step 90 Global step 90 Train loss 2.19 on epoch=6
06/02/2022 08:25:23 - INFO - __main__ - Step 100 Global step 100 Train loss 2.09 on epoch=7
06/02/2022 08:25:27 - INFO - __main__ - Global step 100 Train loss 2.50 Classification-F1 0.22965670368918667 on epoch=7
06/02/2022 08:25:27 - INFO - __main__ - Saving model with best Classification-F1: 0.055328450960803896 -> 0.22965670368918667 on epoch=7, global_step=100
06/02/2022 08:25:28 - INFO - __main__ - Step 110 Global step 110 Train loss 1.94 on epoch=7
06/02/2022 08:25:30 - INFO - __main__ - Step 120 Global step 120 Train loss 1.72 on epoch=8
06/02/2022 08:25:31 - INFO - __main__ - Step 130 Global step 130 Train loss 1.67 on epoch=9
06/02/2022 08:25:32 - INFO - __main__ - Step 140 Global step 140 Train loss 1.57 on epoch=9
06/02/2022 08:25:34 - INFO - __main__ - Step 150 Global step 150 Train loss 1.26 on epoch=10
06/02/2022 08:25:37 - INFO - __main__ - Global step 150 Train loss 1.63 Classification-F1 0.2393801543010972 on epoch=10
06/02/2022 08:25:37 - INFO - __main__ - Saving model with best Classification-F1: 0.22965670368918667 -> 0.2393801543010972 on epoch=10, global_step=150
06/02/2022 08:25:38 - INFO - __main__ - Step 160 Global step 160 Train loss 1.29 on epoch=11
06/02/2022 08:25:40 - INFO - __main__ - Step 170 Global step 170 Train loss 1.10 on epoch=12
06/02/2022 08:25:41 - INFO - __main__ - Step 180 Global step 180 Train loss 1.09 on epoch=12
06/02/2022 08:25:43 - INFO - __main__ - Step 190 Global step 190 Train loss 1.08 on epoch=13
06/02/2022 08:25:44 - INFO - __main__ - Step 200 Global step 200 Train loss 1.15 on epoch=14
06/02/2022 08:25:47 - INFO - __main__ - Global step 200 Train loss 1.14 Classification-F1 0.2025691737730641 on epoch=14
06/02/2022 08:25:48 - INFO - __main__ - Step 210 Global step 210 Train loss 1.06 on epoch=14
06/02/2022 08:25:50 - INFO - __main__ - Step 220 Global step 220 Train loss 1.02 on epoch=15
06/02/2022 08:25:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=16
06/02/2022 08:25:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.95 on epoch=17
06/02/2022 08:25:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.91 on epoch=17
06/02/2022 08:25:57 - INFO - __main__ - Global step 250 Train loss 0.96 Classification-F1 0.3214554308984391 on epoch=17
06/02/2022 08:25:57 - INFO - __main__ - Saving model with best Classification-F1: 0.2393801543010972 -> 0.3214554308984391 on epoch=17, global_step=250
06/02/2022 08:25:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.97 on epoch=18
06/02/2022 08:25:59 - INFO - __main__ - Step 270 Global step 270 Train loss 1.01 on epoch=19
06/02/2022 08:26:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.90 on epoch=19
06/02/2022 08:26:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.83 on epoch=20
06/02/2022 08:26:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.86 on epoch=21
06/02/2022 08:26:06 - INFO - __main__ - Global step 300 Train loss 0.92 Classification-F1 0.3155764088943812 on epoch=21
06/02/2022 08:26:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.88 on epoch=22
06/02/2022 08:26:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.73 on epoch=22
06/02/2022 08:26:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.70 on epoch=23
06/02/2022 08:26:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.70 on epoch=24
06/02/2022 08:26:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.69 on epoch=24
06/02/2022 08:26:16 - INFO - __main__ - Global step 350 Train loss 0.74 Classification-F1 0.4456408547154112 on epoch=24
06/02/2022 08:26:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3214554308984391 -> 0.4456408547154112 on epoch=24, global_step=350
06/02/2022 08:26:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.67 on epoch=25
06/02/2022 08:26:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.92 on epoch=26
06/02/2022 08:26:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.71 on epoch=27
06/02/2022 08:26:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.68 on epoch=27
06/02/2022 08:26:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=28
06/02/2022 08:26:25 - INFO - __main__ - Global step 400 Train loss 0.69 Classification-F1 0.37918212565061327 on epoch=28
06/02/2022 08:26:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=29
06/02/2022 08:26:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.63 on epoch=29
06/02/2022 08:26:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.51 on epoch=30
06/02/2022 08:26:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.61 on epoch=31
06/02/2022 08:26:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.66 on epoch=32
06/02/2022 08:26:35 - INFO - __main__ - Global step 450 Train loss 0.59 Classification-F1 0.3514516779927294 on epoch=32
06/02/2022 08:26:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.65 on epoch=32
06/02/2022 08:26:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.59 on epoch=33
06/02/2022 08:26:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.61 on epoch=34
06/02/2022 08:26:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.61 on epoch=34
06/02/2022 08:26:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.57 on epoch=35
06/02/2022 08:26:45 - INFO - __main__ - Global step 500 Train loss 0.61 Classification-F1 0.49621838634443677 on epoch=35
06/02/2022 08:26:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4456408547154112 -> 0.49621838634443677 on epoch=35, global_step=500
06/02/2022 08:26:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.55 on epoch=36
06/02/2022 08:26:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.60 on epoch=37
06/02/2022 08:26:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.61 on epoch=37
06/02/2022 08:26:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=38
06/02/2022 08:26:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.61 on epoch=39
06/02/2022 08:26:54 - INFO - __main__ - Global step 550 Train loss 0.56 Classification-F1 0.41395809944212614 on epoch=39
06/02/2022 08:26:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=39
06/02/2022 08:26:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.43 on epoch=40
06/02/2022 08:26:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.55 on epoch=41
06/02/2022 08:26:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=42
06/02/2022 08:27:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.61 on epoch=42
06/02/2022 08:27:04 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.4334716845588378 on epoch=42
06/02/2022 08:27:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=43
06/02/2022 08:27:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.48 on epoch=44
06/02/2022 08:27:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=44
06/02/2022 08:27:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.58 on epoch=45
06/02/2022 08:27:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.58 on epoch=46
06/02/2022 08:27:14 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.42272002599039515 on epoch=46
06/02/2022 08:27:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.46 on epoch=47
06/02/2022 08:27:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.52 on epoch=47
06/02/2022 08:27:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.46 on epoch=48
06/02/2022 08:27:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.45 on epoch=49
06/02/2022 08:27:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.42 on epoch=49
06/02/2022 08:27:23 - INFO - __main__ - Global step 700 Train loss 0.46 Classification-F1 0.3597269470434356 on epoch=49
06/02/2022 08:27:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.46 on epoch=50
06/02/2022 08:27:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.42 on epoch=51
06/02/2022 08:27:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.50 on epoch=52
06/02/2022 08:27:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.33 on epoch=52
06/02/2022 08:27:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.39 on epoch=53
06/02/2022 08:27:33 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.44029206756781186 on epoch=53
06/02/2022 08:27:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.47 on epoch=54
06/02/2022 08:27:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.39 on epoch=54
06/02/2022 08:27:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=55
06/02/2022 08:27:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.27 on epoch=56
06/02/2022 08:27:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=57
06/02/2022 08:27:43 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.4367298829673964 on epoch=57
06/02/2022 08:27:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=57
06/02/2022 08:27:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=58
06/02/2022 08:27:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=59
06/02/2022 08:27:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.29 on epoch=59
06/02/2022 08:27:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=60
06/02/2022 08:27:52 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.6916666830561732 on epoch=60
06/02/2022 08:27:53 - INFO - __main__ - Saving model with best Classification-F1: 0.49621838634443677 -> 0.6916666830561732 on epoch=60, global_step=850
06/02/2022 08:27:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.36 on epoch=61
06/02/2022 08:27:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=62
06/02/2022 08:27:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.31 on epoch=62
06/02/2022 08:27:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=63
06/02/2022 08:27:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.38 on epoch=64
06/02/2022 08:28:02 - INFO - __main__ - Global step 900 Train loss 0.34 Classification-F1 0.3518448974126272 on epoch=64
06/02/2022 08:28:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=64
06/02/2022 08:28:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=65
06/02/2022 08:28:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.30 on epoch=66
06/02/2022 08:28:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=67
06/02/2022 08:28:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/02/2022 08:28:12 - INFO - __main__ - Global step 950 Train loss 0.26 Classification-F1 0.5607608710864886 on epoch=67
06/02/2022 08:28:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=68
06/02/2022 08:28:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.35 on epoch=69
06/02/2022 08:28:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.40 on epoch=69
06/02/2022 08:28:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=70
06/02/2022 08:28:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.30 on epoch=71
06/02/2022 08:28:22 - INFO - __main__ - Global step 1000 Train loss 0.31 Classification-F1 0.545410295563307 on epoch=71
06/02/2022 08:28:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.33 on epoch=72
06/02/2022 08:28:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=72
06/02/2022 08:28:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.24 on epoch=73
06/02/2022 08:28:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=74
06/02/2022 08:28:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=74
06/02/2022 08:28:32 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.6123138541028618 on epoch=74
06/02/2022 08:28:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=75
06/02/2022 08:28:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=76
06/02/2022 08:28:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=77
06/02/2022 08:28:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.23 on epoch=77
06/02/2022 08:28:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
06/02/2022 08:28:41 - INFO - __main__ - Global step 1100 Train loss 0.25 Classification-F1 0.5666719933356555 on epoch=78
06/02/2022 08:28:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=79
06/02/2022 08:28:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=79
06/02/2022 08:28:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.25 on epoch=80
06/02/2022 08:28:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=81
06/02/2022 08:28:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=82
06/02/2022 08:28:51 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.6336427349532188 on epoch=82
06/02/2022 08:28:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.24 on epoch=82
06/02/2022 08:28:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=83
06/02/2022 08:28:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=84
06/02/2022 08:28:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.27 on epoch=84
06/02/2022 08:28:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=85
06/02/2022 08:29:01 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.6234430847903848 on epoch=85
06/02/2022 08:29:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.29 on epoch=86
06/02/2022 08:29:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=87
06/02/2022 08:29:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=87
06/02/2022 08:29:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.24 on epoch=88
06/02/2022 08:29:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=89
06/02/2022 08:29:11 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.6027438516136334 on epoch=89
06/02/2022 08:29:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/02/2022 08:29:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
06/02/2022 08:29:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=91
06/02/2022 08:29:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.33 on epoch=92
06/02/2022 08:29:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.17 on epoch=92
06/02/2022 08:29:21 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.461565497036104 on epoch=92
06/02/2022 08:29:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
06/02/2022 08:29:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.28 on epoch=94
06/02/2022 08:29:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.23 on epoch=94
06/02/2022 08:29:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=95
06/02/2022 08:29:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.24 on epoch=96
06/02/2022 08:29:31 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.5411294716461651 on epoch=96
06/02/2022 08:29:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=97
06/02/2022 08:29:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.21 on epoch=97
06/02/2022 08:29:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=98
06/02/2022 08:29:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=99
06/02/2022 08:29:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=99
06/02/2022 08:29:40 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.5265559718141717 on epoch=99
06/02/2022 08:29:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.23 on epoch=100
06/02/2022 08:29:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=101
06/02/2022 08:29:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=102
06/02/2022 08:29:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.21 on epoch=102
06/02/2022 08:29:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
06/02/2022 08:29:50 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.6190920336678376 on epoch=103
06/02/2022 08:29:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
06/02/2022 08:29:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.26 on epoch=104
06/02/2022 08:29:54 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.23 on epoch=105
06/02/2022 08:29:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.21 on epoch=106
06/02/2022 08:29:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=107
06/02/2022 08:30:00 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.5199047645265611 on epoch=107
06/02/2022 08:30:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=107
06/02/2022 08:30:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
06/02/2022 08:30:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=109
06/02/2022 08:30:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=109
06/02/2022 08:30:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=110
06/02/2022 08:30:10 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.5873303428196353 on epoch=110
06/02/2022 08:30:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=111
06/02/2022 08:30:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=112
06/02/2022 08:30:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=112
06/02/2022 08:30:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=113
06/02/2022 08:30:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=114
06/02/2022 08:30:19 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.5754826511825286 on epoch=114
06/02/2022 08:30:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.26 on epoch=114
06/02/2022 08:30:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.22 on epoch=115
06/02/2022 08:30:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.18 on epoch=116
06/02/2022 08:30:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.23 on epoch=117
06/02/2022 08:30:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=117
06/02/2022 08:30:29 - INFO - __main__ - Global step 1650 Train loss 0.21 Classification-F1 0.5896901443911062 on epoch=117
06/02/2022 08:30:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.18 on epoch=118
06/02/2022 08:30:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=119
06/02/2022 08:30:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.21 on epoch=119
06/02/2022 08:30:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=120
06/02/2022 08:30:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/02/2022 08:30:39 - INFO - __main__ - Global step 1700 Train loss 0.15 Classification-F1 0.7772795155859673 on epoch=121
06/02/2022 08:30:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6916666830561732 -> 0.7772795155859673 on epoch=121, global_step=1700
06/02/2022 08:30:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=122
06/02/2022 08:30:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.18 on epoch=122
06/02/2022 08:30:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=123
06/02/2022 08:30:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/02/2022 08:30:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/02/2022 08:30:49 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.7767348777143879 on epoch=124
06/02/2022 08:30:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=125
06/02/2022 08:30:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=126
06/02/2022 08:30:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=127
06/02/2022 08:30:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
06/02/2022 08:30:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=128
06/02/2022 08:30:59 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.7328482916844263 on epoch=128
06/02/2022 08:31:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/02/2022 08:31:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/02/2022 08:31:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=130
06/02/2022 08:31:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
06/02/2022 08:31:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.15 on epoch=132
06/02/2022 08:31:09 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.5362404849862233 on epoch=132
06/02/2022 08:31:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=132
06/02/2022 08:31:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/02/2022 08:31:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=134
06/02/2022 08:31:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
06/02/2022 08:31:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
06/02/2022 08:31:19 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.6792516049481993 on epoch=135
06/02/2022 08:31:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=136
06/02/2022 08:31:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=137
06/02/2022 08:31:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/02/2022 08:31:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/02/2022 08:31:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=139
06/02/2022 08:31:29 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.7641080326048564 on epoch=139
06/02/2022 08:31:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.15 on epoch=139
06/02/2022 08:31:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=140
06/02/2022 08:31:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.15 on epoch=141
06/02/2022 08:31:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.14 on epoch=142
06/02/2022 08:31:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.14 on epoch=142
06/02/2022 08:31:38 - INFO - __main__ - Global step 2000 Train loss 0.14 Classification-F1 0.5835259065143343 on epoch=142
06/02/2022 08:31:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=143
06/02/2022 08:31:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.20 on epoch=144
06/02/2022 08:31:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=144
06/02/2022 08:31:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=145
06/02/2022 08:31:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=146
06/02/2022 08:31:48 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.7153178288258933 on epoch=146
06/02/2022 08:31:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=147
06/02/2022 08:31:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.13 on epoch=147
06/02/2022 08:31:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/02/2022 08:31:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
06/02/2022 08:31:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.10 on epoch=149
06/02/2022 08:31:58 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.6302806227445447 on epoch=149
06/02/2022 08:31:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=150
06/02/2022 08:32:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
06/02/2022 08:32:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=152
06/02/2022 08:32:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=152
06/02/2022 08:32:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=153
06/02/2022 08:32:08 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.6623039476815525 on epoch=153
06/02/2022 08:32:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=154
06/02/2022 08:32:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=154
06/02/2022 08:32:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.11 on epoch=155
06/02/2022 08:32:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.13 on epoch=156
06/02/2022 08:32:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=157
06/02/2022 08:32:18 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.7567707434880111 on epoch=157
06/02/2022 08:32:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/02/2022 08:32:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/02/2022 08:32:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.09 on epoch=159
06/02/2022 08:32:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=159
06/02/2022 08:32:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 08:32:28 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7419446267512747 on epoch=160
06/02/2022 08:32:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=161
06/02/2022 08:32:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/02/2022 08:32:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=162
06/02/2022 08:32:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=163
06/02/2022 08:32:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=164
06/02/2022 08:32:38 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7884275231761 on epoch=164
06/02/2022 08:32:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7772795155859673 -> 0.7884275231761 on epoch=164, global_step=2300
06/02/2022 08:32:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=164
06/02/2022 08:32:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.11 on epoch=165
06/02/2022 08:32:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=166
06/02/2022 08:32:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.16 on epoch=167
06/02/2022 08:32:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
06/02/2022 08:32:47 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.8359187223276408 on epoch=167
06/02/2022 08:32:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7884275231761 -> 0.8359187223276408 on epoch=167, global_step=2350
06/02/2022 08:32:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
06/02/2022 08:32:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/02/2022 08:32:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=169
06/02/2022 08:32:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/02/2022 08:32:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.15 on epoch=171
06/02/2022 08:32:57 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.8201629508333137 on epoch=171
06/02/2022 08:32:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=172
06/02/2022 08:33:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/02/2022 08:33:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=173
06/02/2022 08:33:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=174
06/02/2022 08:33:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=174
06/02/2022 08:33:07 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.64722808892998 on epoch=174
06/02/2022 08:33:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/02/2022 08:33:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.11 on epoch=176
06/02/2022 08:33:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=177
06/02/2022 08:33:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/02/2022 08:33:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/02/2022 08:33:17 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.6339100838282526 on epoch=178
06/02/2022 08:33:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
06/02/2022 08:33:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=179
06/02/2022 08:33:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=180
06/02/2022 08:33:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=181
06/02/2022 08:33:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=182
06/02/2022 08:33:27 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7510983490822201 on epoch=182
06/02/2022 08:33:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/02/2022 08:33:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/02/2022 08:33:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=184
06/02/2022 08:33:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/02/2022 08:33:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/02/2022 08:33:36 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.8475111498044966 on epoch=185
06/02/2022 08:33:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8359187223276408 -> 0.8475111498044966 on epoch=185, global_step=2600
06/02/2022 08:33:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=186
06/02/2022 08:33:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=187
06/02/2022 08:33:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/02/2022 08:33:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/02/2022 08:33:43 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/02/2022 08:33:46 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.841863273188878 on epoch=189
06/02/2022 08:33:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.10 on epoch=189
06/02/2022 08:33:49 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/02/2022 08:33:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=191
06/02/2022 08:33:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/02/2022 08:33:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/02/2022 08:33:56 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7524896724006847 on epoch=192
06/02/2022 08:33:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=193
06/02/2022 08:33:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=194
06/02/2022 08:34:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/02/2022 08:34:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/02/2022 08:34:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=196
06/02/2022 08:34:05 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6926033007739288 on epoch=196
06/02/2022 08:34:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=197
06/02/2022 08:34:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/02/2022 08:34:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=198
06/02/2022 08:34:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=199
06/02/2022 08:34:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=199
06/02/2022 08:34:15 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.7839340326107529 on epoch=199
06/02/2022 08:34:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/02/2022 08:34:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/02/2022 08:34:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/02/2022 08:34:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/02/2022 08:34:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=203
06/02/2022 08:34:25 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7850715361375035 on epoch=203
06/02/2022 08:34:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/02/2022 08:34:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/02/2022 08:34:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/02/2022 08:34:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/02/2022 08:34:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/02/2022 08:34:35 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7915507126217508 on epoch=207
06/02/2022 08:34:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/02/2022 08:34:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/02/2022 08:34:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/02/2022 08:34:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/02/2022 08:34:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
06/02/2022 08:34:45 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.9015426792957383 on epoch=210
06/02/2022 08:34:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8475111498044966 -> 0.9015426792957383 on epoch=210, global_step=2950
06/02/2022 08:34:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/02/2022 08:34:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/02/2022 08:34:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
06/02/2022 08:34:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/02/2022 08:34:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=214
06/02/2022 08:34:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:34:52 - INFO - __main__ - Printing 3 examples
06/02/2022 08:34:52 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:34:52 - INFO - __main__ - ['Company']
06/02/2022 08:34:52 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:34:52 - INFO - __main__ - ['Company']
06/02/2022 08:34:52 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:34:52 - INFO - __main__ - ['Company']
06/02/2022 08:34:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:34:52 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:34:52 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:34:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:34:52 - INFO - __main__ - Printing 3 examples
06/02/2022 08:34:52 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:34:52 - INFO - __main__ - ['Company']
06/02/2022 08:34:52 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:34:52 - INFO - __main__ - ['Company']
06/02/2022 08:34:52 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:34:52 - INFO - __main__ - ['Company']
06/02/2022 08:34:52 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:34:53 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:34:53 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:34:55 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8435850439882697 on epoch=214
06/02/2022 08:34:55 - INFO - __main__ - save last model!
06/02/2022 08:34:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 08:34:55 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 08:34:55 - INFO - __main__ - Printing 3 examples
06/02/2022 08:34:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 08:34:55 - INFO - __main__ - ['Animal']
06/02/2022 08:34:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 08:34:55 - INFO - __main__ - ['Animal']
06/02/2022 08:34:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 08:34:55 - INFO - __main__ - ['Village']
06/02/2022 08:34:55 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:34:56 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:34:58 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:34:58 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:34:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:34:58 - INFO - __main__ - Starting training!
06/02/2022 08:35:00 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 08:36:10 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/02/2022 08:36:10 - INFO - __main__ - Classification-F1 on test data: 0.3820
06/02/2022 08:36:10 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.9015426792957383, test_performance=0.3820252701785925
06/02/2022 08:36:10 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/02/2022 08:36:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:36:11 - INFO - __main__ - Printing 3 examples
06/02/2022 08:36:11 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:36:11 - INFO - __main__ - ['Company']
06/02/2022 08:36:11 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:36:11 - INFO - __main__ - ['Company']
06/02/2022 08:36:11 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:36:11 - INFO - __main__ - ['Company']
06/02/2022 08:36:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:36:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:36:12 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:36:12 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:36:12 - INFO - __main__ - Printing 3 examples
06/02/2022 08:36:12 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:36:12 - INFO - __main__ - ['Company']
06/02/2022 08:36:12 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:36:12 - INFO - __main__ - ['Company']
06/02/2022 08:36:12 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:36:12 - INFO - __main__ - ['Company']
06/02/2022 08:36:12 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:36:12 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:36:12 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:36:18 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:36:18 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:36:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:36:19 - INFO - __main__ - Starting training!
06/02/2022 08:36:20 - INFO - __main__ - Step 10 Global step 10 Train loss 6.75 on epoch=0
06/02/2022 08:36:21 - INFO - __main__ - Step 20 Global step 20 Train loss 6.20 on epoch=1
06/02/2022 08:36:23 - INFO - __main__ - Step 30 Global step 30 Train loss 5.66 on epoch=2
06/02/2022 08:36:24 - INFO - __main__ - Step 40 Global step 40 Train loss 5.39 on epoch=2
06/02/2022 08:36:25 - INFO - __main__ - Step 50 Global step 50 Train loss 6.37 on epoch=3
06/02/2022 08:37:00 - INFO - __main__ - Global step 50 Train loss 6.07 Classification-F1 0.0 on epoch=3
06/02/2022 08:37:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 08:37:01 - INFO - __main__ - Step 60 Global step 60 Train loss 6.49 on epoch=4
06/02/2022 08:37:02 - INFO - __main__ - Step 70 Global step 70 Train loss 6.62 on epoch=4
06/02/2022 08:37:04 - INFO - __main__ - Step 80 Global step 80 Train loss 5.60 on epoch=5
06/02/2022 08:37:05 - INFO - __main__ - Step 90 Global step 90 Train loss 5.35 on epoch=6
06/02/2022 08:37:06 - INFO - __main__ - Step 100 Global step 100 Train loss 5.33 on epoch=7
06/02/2022 08:37:19 - INFO - __main__ - Global step 100 Train loss 5.88 Classification-F1 0.0 on epoch=7
06/02/2022 08:37:20 - INFO - __main__ - Step 110 Global step 110 Train loss 5.06 on epoch=7
06/02/2022 08:37:22 - INFO - __main__ - Step 120 Global step 120 Train loss 5.21 on epoch=8
06/02/2022 08:37:23 - INFO - __main__ - Step 130 Global step 130 Train loss 4.94 on epoch=9
06/02/2022 08:37:24 - INFO - __main__ - Step 140 Global step 140 Train loss 5.01 on epoch=9
06/02/2022 08:37:26 - INFO - __main__ - Step 150 Global step 150 Train loss 4.77 on epoch=10
06/02/2022 08:37:40 - INFO - __main__ - Global step 150 Train loss 5.00 Classification-F1 0.0007949125596184419 on epoch=10
06/02/2022 08:37:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0007949125596184419 on epoch=10, global_step=150
06/02/2022 08:37:41 - INFO - __main__ - Step 160 Global step 160 Train loss 4.73 on epoch=11
06/02/2022 08:37:43 - INFO - __main__ - Step 170 Global step 170 Train loss 4.77 on epoch=12
06/02/2022 08:37:44 - INFO - __main__ - Step 180 Global step 180 Train loss 4.60 on epoch=12
06/02/2022 08:37:45 - INFO - __main__ - Step 190 Global step 190 Train loss 4.51 on epoch=13
06/02/2022 08:37:46 - INFO - __main__ - Step 200 Global step 200 Train loss 4.43 on epoch=14
06/02/2022 08:37:53 - INFO - __main__ - Global step 200 Train loss 4.61 Classification-F1 0.014267105018299114 on epoch=14
06/02/2022 08:37:53 - INFO - __main__ - Saving model with best Classification-F1: 0.0007949125596184419 -> 0.014267105018299114 on epoch=14, global_step=200
06/02/2022 08:37:54 - INFO - __main__ - Step 210 Global step 210 Train loss 4.52 on epoch=14
06/02/2022 08:37:55 - INFO - __main__ - Step 220 Global step 220 Train loss 4.20 on epoch=15
06/02/2022 08:37:57 - INFO - __main__ - Step 230 Global step 230 Train loss 3.94 on epoch=16
06/02/2022 08:37:58 - INFO - __main__ - Step 240 Global step 240 Train loss 3.84 on epoch=17
06/02/2022 08:37:59 - INFO - __main__ - Step 250 Global step 250 Train loss 3.81 on epoch=17
06/02/2022 08:38:04 - INFO - __main__ - Global step 250 Train loss 4.06 Classification-F1 0.09828038959691619 on epoch=17
06/02/2022 08:38:04 - INFO - __main__ - Saving model with best Classification-F1: 0.014267105018299114 -> 0.09828038959691619 on epoch=17, global_step=250
06/02/2022 08:38:05 - INFO - __main__ - Step 260 Global step 260 Train loss 3.51 on epoch=18
06/02/2022 08:38:06 - INFO - __main__ - Step 270 Global step 270 Train loss 3.38 on epoch=19
06/02/2022 08:38:08 - INFO - __main__ - Step 280 Global step 280 Train loss 3.43 on epoch=19
06/02/2022 08:38:09 - INFO - __main__ - Step 290 Global step 290 Train loss 3.14 on epoch=20
06/02/2022 08:38:10 - INFO - __main__ - Step 300 Global step 300 Train loss 3.19 on epoch=21
06/02/2022 08:38:14 - INFO - __main__ - Global step 300 Train loss 3.33 Classification-F1 0.20824278694057044 on epoch=21
06/02/2022 08:38:14 - INFO - __main__ - Saving model with best Classification-F1: 0.09828038959691619 -> 0.20824278694057044 on epoch=21, global_step=300
06/02/2022 08:38:15 - INFO - __main__ - Step 310 Global step 310 Train loss 3.00 on epoch=22
06/02/2022 08:38:16 - INFO - __main__ - Step 320 Global step 320 Train loss 3.00 on epoch=22
06/02/2022 08:38:17 - INFO - __main__ - Step 330 Global step 330 Train loss 2.74 on epoch=23
06/02/2022 08:38:19 - INFO - __main__ - Step 340 Global step 340 Train loss 2.73 on epoch=24
06/02/2022 08:38:20 - INFO - __main__ - Step 350 Global step 350 Train loss 2.57 on epoch=24
06/02/2022 08:38:24 - INFO - __main__ - Global step 350 Train loss 2.81 Classification-F1 0.23928148311338054 on epoch=24
06/02/2022 08:38:24 - INFO - __main__ - Saving model with best Classification-F1: 0.20824278694057044 -> 0.23928148311338054 on epoch=24, global_step=350
06/02/2022 08:38:25 - INFO - __main__ - Step 360 Global step 360 Train loss 2.62 on epoch=25
06/02/2022 08:38:27 - INFO - __main__ - Step 370 Global step 370 Train loss 2.49 on epoch=26
06/02/2022 08:38:28 - INFO - __main__ - Step 380 Global step 380 Train loss 2.40 on epoch=27
06/02/2022 08:38:29 - INFO - __main__ - Step 390 Global step 390 Train loss 2.27 on epoch=27
06/02/2022 08:38:31 - INFO - __main__ - Step 400 Global step 400 Train loss 2.13 on epoch=28
06/02/2022 08:38:34 - INFO - __main__ - Global step 400 Train loss 2.38 Classification-F1 0.18781844476644136 on epoch=28
06/02/2022 08:38:35 - INFO - __main__ - Step 410 Global step 410 Train loss 2.12 on epoch=29
06/02/2022 08:38:36 - INFO - __main__ - Step 420 Global step 420 Train loss 2.00 on epoch=29
06/02/2022 08:38:37 - INFO - __main__ - Step 430 Global step 430 Train loss 1.97 on epoch=30
06/02/2022 08:38:39 - INFO - __main__ - Step 440 Global step 440 Train loss 1.84 on epoch=31
06/02/2022 08:38:40 - INFO - __main__ - Step 450 Global step 450 Train loss 1.71 on epoch=32
06/02/2022 08:38:43 - INFO - __main__ - Global step 450 Train loss 1.93 Classification-F1 0.2508560720897093 on epoch=32
06/02/2022 08:38:43 - INFO - __main__ - Saving model with best Classification-F1: 0.23928148311338054 -> 0.2508560720897093 on epoch=32, global_step=450
06/02/2022 08:38:45 - INFO - __main__ - Step 460 Global step 460 Train loss 1.67 on epoch=32
06/02/2022 08:38:46 - INFO - __main__ - Step 470 Global step 470 Train loss 1.46 on epoch=33
06/02/2022 08:38:47 - INFO - __main__ - Step 480 Global step 480 Train loss 1.52 on epoch=34
06/02/2022 08:38:48 - INFO - __main__ - Step 490 Global step 490 Train loss 1.33 on epoch=34
06/02/2022 08:38:50 - INFO - __main__ - Step 500 Global step 500 Train loss 1.37 on epoch=35
06/02/2022 08:38:53 - INFO - __main__ - Global step 500 Train loss 1.47 Classification-F1 0.37628423987133475 on epoch=35
06/02/2022 08:38:53 - INFO - __main__ - Saving model with best Classification-F1: 0.2508560720897093 -> 0.37628423987133475 on epoch=35, global_step=500
06/02/2022 08:38:54 - INFO - __main__ - Step 510 Global step 510 Train loss 1.37 on epoch=36
06/02/2022 08:38:55 - INFO - __main__ - Step 520 Global step 520 Train loss 1.29 on epoch=37
06/02/2022 08:38:56 - INFO - __main__ - Step 530 Global step 530 Train loss 1.21 on epoch=37
06/02/2022 08:38:58 - INFO - __main__ - Step 540 Global step 540 Train loss 1.15 on epoch=38
06/02/2022 08:38:59 - INFO - __main__ - Step 550 Global step 550 Train loss 1.31 on epoch=39
06/02/2022 08:39:02 - INFO - __main__ - Global step 550 Train loss 1.26 Classification-F1 0.3765304346999319 on epoch=39
06/02/2022 08:39:02 - INFO - __main__ - Saving model with best Classification-F1: 0.37628423987133475 -> 0.3765304346999319 on epoch=39, global_step=550
06/02/2022 08:39:04 - INFO - __main__ - Step 560 Global step 560 Train loss 1.18 on epoch=39
06/02/2022 08:39:05 - INFO - __main__ - Step 570 Global step 570 Train loss 1.11 on epoch=40
06/02/2022 08:39:06 - INFO - __main__ - Step 580 Global step 580 Train loss 1.16 on epoch=41
06/02/2022 08:39:07 - INFO - __main__ - Step 590 Global step 590 Train loss 1.13 on epoch=42
06/02/2022 08:39:09 - INFO - __main__ - Step 600 Global step 600 Train loss 1.02 on epoch=42
06/02/2022 08:39:12 - INFO - __main__ - Global step 600 Train loss 1.12 Classification-F1 0.48496505174168214 on epoch=42
06/02/2022 08:39:12 - INFO - __main__ - Saving model with best Classification-F1: 0.3765304346999319 -> 0.48496505174168214 on epoch=42, global_step=600
06/02/2022 08:39:13 - INFO - __main__ - Step 610 Global step 610 Train loss 1.11 on epoch=43
06/02/2022 08:39:14 - INFO - __main__ - Step 620 Global step 620 Train loss 1.11 on epoch=44
06/02/2022 08:39:16 - INFO - __main__ - Step 630 Global step 630 Train loss 1.05 on epoch=44
06/02/2022 08:39:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.98 on epoch=45
06/02/2022 08:39:18 - INFO - __main__ - Step 650 Global step 650 Train loss 1.04 on epoch=46
06/02/2022 08:39:22 - INFO - __main__ - Global step 650 Train loss 1.06 Classification-F1 0.4735736028089852 on epoch=46
06/02/2022 08:39:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.93 on epoch=47
06/02/2022 08:39:24 - INFO - __main__ - Step 670 Global step 670 Train loss 1.03 on epoch=47
06/02/2022 08:39:25 - INFO - __main__ - Step 680 Global step 680 Train loss 0.96 on epoch=48
06/02/2022 08:39:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.92 on epoch=49
06/02/2022 08:39:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.96 on epoch=49
06/02/2022 08:39:32 - INFO - __main__ - Global step 700 Train loss 0.96 Classification-F1 0.6391330290749223 on epoch=49
06/02/2022 08:39:32 - INFO - __main__ - Saving model with best Classification-F1: 0.48496505174168214 -> 0.6391330290749223 on epoch=49, global_step=700
06/02/2022 08:39:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.88 on epoch=50
06/02/2022 08:39:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.93 on epoch=51
06/02/2022 08:39:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.90 on epoch=52
06/02/2022 08:39:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.90 on epoch=52
06/02/2022 08:39:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.88 on epoch=53
06/02/2022 08:39:41 - INFO - __main__ - Global step 750 Train loss 0.90 Classification-F1 0.4961997306160401 on epoch=53
06/02/2022 08:39:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.99 on epoch=54
06/02/2022 08:39:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.95 on epoch=54
06/02/2022 08:39:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.80 on epoch=55
06/02/2022 08:39:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.88 on epoch=56
06/02/2022 08:39:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.84 on epoch=57
06/02/2022 08:39:51 - INFO - __main__ - Global step 800 Train loss 0.89 Classification-F1 0.5779990148427038 on epoch=57
06/02/2022 08:39:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.76 on epoch=57
06/02/2022 08:39:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.65 on epoch=58
06/02/2022 08:39:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.92 on epoch=59
06/02/2022 08:39:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.71 on epoch=59
06/02/2022 08:39:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.74 on epoch=60
06/02/2022 08:40:01 - INFO - __main__ - Global step 850 Train loss 0.76 Classification-F1 0.5297981893712443 on epoch=60
06/02/2022 08:40:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.79 on epoch=61
06/02/2022 08:40:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.83 on epoch=62
06/02/2022 08:40:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.72 on epoch=62
06/02/2022 08:40:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.68 on epoch=63
06/02/2022 08:40:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.78 on epoch=64
06/02/2022 08:40:11 - INFO - __main__ - Global step 900 Train loss 0.76 Classification-F1 0.44908560896829547 on epoch=64
06/02/2022 08:40:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.67 on epoch=64
06/02/2022 08:40:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.64 on epoch=65
06/02/2022 08:40:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.70 on epoch=66
06/02/2022 08:40:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.67 on epoch=67
06/02/2022 08:40:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.63 on epoch=67
06/02/2022 08:40:22 - INFO - __main__ - Global step 950 Train loss 0.66 Classification-F1 0.4351245726245727 on epoch=67
06/02/2022 08:40:23 - INFO - __main__ - Step 960 Global step 960 Train loss 0.65 on epoch=68
06/02/2022 08:40:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.75 on epoch=69
06/02/2022 08:40:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.57 on epoch=69
06/02/2022 08:40:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.59 on epoch=70
06/02/2022 08:40:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.57 on epoch=71
06/02/2022 08:40:32 - INFO - __main__ - Global step 1000 Train loss 0.62 Classification-F1 0.4142474294486679 on epoch=71
06/02/2022 08:40:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.65 on epoch=72
06/02/2022 08:40:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.56 on epoch=72
06/02/2022 08:40:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.50 on epoch=73
06/02/2022 08:40:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.57 on epoch=74
06/02/2022 08:40:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.61 on epoch=74
06/02/2022 08:40:42 - INFO - __main__ - Global step 1050 Train loss 0.58 Classification-F1 0.5021912917448903 on epoch=74
06/02/2022 08:40:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.55 on epoch=75
06/02/2022 08:40:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.57 on epoch=76
06/02/2022 08:40:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.52 on epoch=77
06/02/2022 08:40:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.54 on epoch=77
06/02/2022 08:40:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.51 on epoch=78
06/02/2022 08:40:52 - INFO - __main__ - Global step 1100 Train loss 0.54 Classification-F1 0.576324689522892 on epoch=78
06/02/2022 08:40:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.78 on epoch=79
06/02/2022 08:40:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.50 on epoch=79
06/02/2022 08:40:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.43 on epoch=80
06/02/2022 08:40:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.51 on epoch=81
06/02/2022 08:40:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.60 on epoch=82
06/02/2022 08:41:02 - INFO - __main__ - Global step 1150 Train loss 0.57 Classification-F1 0.4387704169166814 on epoch=82
06/02/2022 08:41:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.49 on epoch=82
06/02/2022 08:41:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.53 on epoch=83
06/02/2022 08:41:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.49 on epoch=84
06/02/2022 08:41:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.42 on epoch=84
06/02/2022 08:41:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.44 on epoch=85
06/02/2022 08:41:12 - INFO - __main__ - Global step 1200 Train loss 0.47 Classification-F1 0.5880089361639322 on epoch=85
06/02/2022 08:41:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.42 on epoch=86
06/02/2022 08:41:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.52 on epoch=87
06/02/2022 08:41:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.45 on epoch=87
06/02/2022 08:41:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.46 on epoch=88
06/02/2022 08:41:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.45 on epoch=89
06/02/2022 08:41:22 - INFO - __main__ - Global step 1250 Train loss 0.46 Classification-F1 0.5121511819747956 on epoch=89
06/02/2022 08:41:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.44 on epoch=89
06/02/2022 08:41:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.37 on epoch=90
06/02/2022 08:41:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.45 on epoch=91
06/02/2022 08:41:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.59 on epoch=92
06/02/2022 08:41:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.59 on epoch=92
06/02/2022 08:41:32 - INFO - __main__ - Global step 1300 Train loss 0.49 Classification-F1 0.45837371376221303 on epoch=92
06/02/2022 08:41:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.42 on epoch=93
06/02/2022 08:41:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.42 on epoch=94
06/02/2022 08:41:35 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.43 on epoch=94
06/02/2022 08:41:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.39 on epoch=95
06/02/2022 08:41:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.38 on epoch=96
06/02/2022 08:41:42 - INFO - __main__ - Global step 1350 Train loss 0.41 Classification-F1 0.5451150066064299 on epoch=96
06/02/2022 08:41:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.45 on epoch=97
06/02/2022 08:41:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.47 on epoch=97
06/02/2022 08:41:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.34 on epoch=98
06/02/2022 08:41:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.42 on epoch=99
06/02/2022 08:41:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.47 on epoch=99
06/02/2022 08:41:51 - INFO - __main__ - Global step 1400 Train loss 0.43 Classification-F1 0.4543881412833026 on epoch=99
06/02/2022 08:41:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=100
06/02/2022 08:41:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.40 on epoch=101
06/02/2022 08:41:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.37 on epoch=102
06/02/2022 08:41:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.40 on epoch=102
06/02/2022 08:41:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.38 on epoch=103
06/02/2022 08:42:01 - INFO - __main__ - Global step 1450 Train loss 0.36 Classification-F1 0.5741858694812957 on epoch=103
06/02/2022 08:42:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.39 on epoch=104
06/02/2022 08:42:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.37 on epoch=104
06/02/2022 08:42:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.31 on epoch=105
06/02/2022 08:42:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.43 on epoch=106
06/02/2022 08:42:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.40 on epoch=107
06/02/2022 08:42:11 - INFO - __main__ - Global step 1500 Train loss 0.38 Classification-F1 0.5838041337872536 on epoch=107
06/02/2022 08:42:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.36 on epoch=107
06/02/2022 08:42:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.31 on epoch=108
06/02/2022 08:42:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.29 on epoch=109
06/02/2022 08:42:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.35 on epoch=109
06/02/2022 08:42:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.39 on epoch=110
06/02/2022 08:42:21 - INFO - __main__ - Global step 1550 Train loss 0.34 Classification-F1 0.8248156170524592 on epoch=110
06/02/2022 08:42:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6391330290749223 -> 0.8248156170524592 on epoch=110, global_step=1550
06/02/2022 08:42:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.44 on epoch=111
06/02/2022 08:42:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.40 on epoch=112
06/02/2022 08:42:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.36 on epoch=112
06/02/2022 08:42:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.31 on epoch=113
06/02/2022 08:42:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.31 on epoch=114
06/02/2022 08:42:31 - INFO - __main__ - Global step 1600 Train loss 0.36 Classification-F1 0.5338324219284949 on epoch=114
06/02/2022 08:42:33 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.37 on epoch=114
06/02/2022 08:42:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.30 on epoch=115
06/02/2022 08:42:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.32 on epoch=116
06/02/2022 08:42:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.35 on epoch=117
06/02/2022 08:42:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.27 on epoch=117
06/02/2022 08:42:41 - INFO - __main__ - Global step 1650 Train loss 0.32 Classification-F1 0.5794831077463656 on epoch=117
06/02/2022 08:42:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.23 on epoch=118
06/02/2022 08:42:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.32 on epoch=119
06/02/2022 08:42:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.24 on epoch=119
06/02/2022 08:42:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.24 on epoch=120
06/02/2022 08:42:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.21 on epoch=121
06/02/2022 08:42:51 - INFO - __main__ - Global step 1700 Train loss 0.25 Classification-F1 0.7632403230913449 on epoch=121
06/02/2022 08:42:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.26 on epoch=122
06/02/2022 08:42:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.31 on epoch=122
06/02/2022 08:42:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.22 on epoch=123
06/02/2022 08:42:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.23 on epoch=124
06/02/2022 08:42:58 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.26 on epoch=124
06/02/2022 08:43:01 - INFO - __main__ - Global step 1750 Train loss 0.25 Classification-F1 0.6422406562488272 on epoch=124
06/02/2022 08:43:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.22 on epoch=125
06/02/2022 08:43:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.25 on epoch=126
06/02/2022 08:43:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.33 on epoch=127
06/02/2022 08:43:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.25 on epoch=127
06/02/2022 08:43:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.22 on epoch=128
06/02/2022 08:43:12 - INFO - __main__ - Global step 1800 Train loss 0.25 Classification-F1 0.7549985308759931 on epoch=128
06/02/2022 08:43:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.30 on epoch=129
06/02/2022 08:43:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.29 on epoch=129
06/02/2022 08:43:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.24 on epoch=130
06/02/2022 08:43:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.30 on epoch=131
06/02/2022 08:43:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.24 on epoch=132
06/02/2022 08:43:22 - INFO - __main__ - Global step 1850 Train loss 0.27 Classification-F1 0.8317162818206463 on epoch=132
06/02/2022 08:43:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8248156170524592 -> 0.8317162818206463 on epoch=132, global_step=1850
06/02/2022 08:43:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.29 on epoch=132
06/02/2022 08:43:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.26 on epoch=133
06/02/2022 08:43:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.33 on epoch=134
06/02/2022 08:43:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.31 on epoch=134
06/02/2022 08:43:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.28 on epoch=135
06/02/2022 08:43:32 - INFO - __main__ - Global step 1900 Train loss 0.29 Classification-F1 0.8797919619678001 on epoch=135
06/02/2022 08:43:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8317162818206463 -> 0.8797919619678001 on epoch=135, global_step=1900
06/02/2022 08:43:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.25 on epoch=136
06/02/2022 08:43:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.21 on epoch=137
06/02/2022 08:43:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.29 on epoch=137
06/02/2022 08:43:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.23 on epoch=138
06/02/2022 08:43:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.25 on epoch=139
06/02/2022 08:43:43 - INFO - __main__ - Global step 1950 Train loss 0.24 Classification-F1 0.5588218261853704 on epoch=139
06/02/2022 08:43:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.18 on epoch=139
06/02/2022 08:43:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.26 on epoch=140
06/02/2022 08:43:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.24 on epoch=141
06/02/2022 08:43:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.24 on epoch=142
06/02/2022 08:43:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.24 on epoch=142
06/02/2022 08:43:53 - INFO - __main__ - Global step 2000 Train loss 0.23 Classification-F1 0.7608273791074943 on epoch=142
06/02/2022 08:43:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.25 on epoch=143
06/02/2022 08:43:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.30 on epoch=144
06/02/2022 08:43:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.22 on epoch=144
06/02/2022 08:43:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.25 on epoch=145
06/02/2022 08:43:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.30 on epoch=146
06/02/2022 08:44:03 - INFO - __main__ - Global step 2050 Train loss 0.26 Classification-F1 0.9012468148465047 on epoch=146
06/02/2022 08:44:03 - INFO - __main__ - Saving model with best Classification-F1: 0.8797919619678001 -> 0.9012468148465047 on epoch=146, global_step=2050
06/02/2022 08:44:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.22 on epoch=147
06/02/2022 08:44:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.20 on epoch=147
06/02/2022 08:44:06 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.30 on epoch=148
06/02/2022 08:44:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.24 on epoch=149
06/02/2022 08:44:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.24 on epoch=149
06/02/2022 08:44:12 - INFO - __main__ - Global step 2100 Train loss 0.24 Classification-F1 0.755555241039112 on epoch=149
06/02/2022 08:44:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.21 on epoch=150
06/02/2022 08:44:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.15 on epoch=151
06/02/2022 08:44:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.23 on epoch=152
06/02/2022 08:44:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.21 on epoch=152
06/02/2022 08:44:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.22 on epoch=153
06/02/2022 08:44:23 - INFO - __main__ - Global step 2150 Train loss 0.20 Classification-F1 0.8000076585391969 on epoch=153
06/02/2022 08:44:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.17 on epoch=154
06/02/2022 08:44:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.19 on epoch=154
06/02/2022 08:44:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.23 on epoch=155
06/02/2022 08:44:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.21 on epoch=156
06/02/2022 08:44:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.23 on epoch=157
06/02/2022 08:44:33 - INFO - __main__ - Global step 2200 Train loss 0.21 Classification-F1 0.783173406687838 on epoch=157
06/02/2022 08:44:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.18 on epoch=157
06/02/2022 08:44:35 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.16 on epoch=158
06/02/2022 08:44:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.20 on epoch=159
06/02/2022 08:44:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.17 on epoch=159
06/02/2022 08:44:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.14 on epoch=160
06/02/2022 08:44:43 - INFO - __main__ - Global step 2250 Train loss 0.17 Classification-F1 0.817990408284526 on epoch=160
06/02/2022 08:44:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.17 on epoch=161
06/02/2022 08:44:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.22 on epoch=162
06/02/2022 08:44:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.18 on epoch=162
06/02/2022 08:44:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.23 on epoch=163
06/02/2022 08:44:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.16 on epoch=164
06/02/2022 08:44:53 - INFO - __main__ - Global step 2300 Train loss 0.19 Classification-F1 0.7610345457831227 on epoch=164
06/02/2022 08:44:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.27 on epoch=164
06/02/2022 08:44:55 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.18 on epoch=165
06/02/2022 08:44:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.18 on epoch=166
06/02/2022 08:44:58 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.24 on epoch=167
06/02/2022 08:44:59 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.19 on epoch=167
06/02/2022 08:45:03 - INFO - __main__ - Global step 2350 Train loss 0.21 Classification-F1 0.7114265492293174 on epoch=167
06/02/2022 08:45:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.25 on epoch=168
06/02/2022 08:45:05 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.13 on epoch=169
06/02/2022 08:45:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.18 on epoch=169
06/02/2022 08:45:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.13 on epoch=170
06/02/2022 08:45:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.23 on epoch=171
06/02/2022 08:45:13 - INFO - __main__ - Global step 2400 Train loss 0.18 Classification-F1 0.6937455535373831 on epoch=171
06/02/2022 08:45:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.15 on epoch=172
06/02/2022 08:45:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.13 on epoch=172
06/02/2022 08:45:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.15 on epoch=173
06/02/2022 08:45:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=174
06/02/2022 08:45:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.17 on epoch=174
06/02/2022 08:45:23 - INFO - __main__ - Global step 2450 Train loss 0.15 Classification-F1 0.7399003275676101 on epoch=174
06/02/2022 08:45:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.21 on epoch=175
06/02/2022 08:45:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.15 on epoch=176
06/02/2022 08:45:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.18 on epoch=177
06/02/2022 08:45:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.18 on epoch=177
06/02/2022 08:45:29 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.13 on epoch=178
06/02/2022 08:45:33 - INFO - __main__ - Global step 2500 Train loss 0.17 Classification-F1 0.7309328275437775 on epoch=178
06/02/2022 08:45:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.19 on epoch=179
06/02/2022 08:45:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.18 on epoch=179
06/02/2022 08:45:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.11 on epoch=180
06/02/2022 08:45:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.13 on epoch=181
06/02/2022 08:45:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.24 on epoch=182
06/02/2022 08:45:43 - INFO - __main__ - Global step 2550 Train loss 0.17 Classification-F1 0.704784864599328 on epoch=182
06/02/2022 08:45:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.22 on epoch=182
06/02/2022 08:45:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.11 on epoch=183
06/02/2022 08:45:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.17 on epoch=184
06/02/2022 08:45:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.11 on epoch=184
06/02/2022 08:45:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.13 on epoch=185
06/02/2022 08:45:53 - INFO - __main__ - Global step 2600 Train loss 0.15 Classification-F1 0.8356878948925669 on epoch=185
06/02/2022 08:45:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.16 on epoch=186
06/02/2022 08:45:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.12 on epoch=187
06/02/2022 08:45:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=187
06/02/2022 08:45:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.13 on epoch=188
06/02/2022 08:45:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.13 on epoch=189
06/02/2022 08:46:03 - INFO - __main__ - Global step 2650 Train loss 0.13 Classification-F1 0.8259321323837453 on epoch=189
06/02/2022 08:46:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.15 on epoch=189
06/02/2022 08:46:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.12 on epoch=190
06/02/2022 08:46:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.12 on epoch=191
06/02/2022 08:46:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.14 on epoch=192
06/02/2022 08:46:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/02/2022 08:46:13 - INFO - __main__ - Global step 2700 Train loss 0.12 Classification-F1 0.7705209796528583 on epoch=192
06/02/2022 08:46:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.12 on epoch=193
06/02/2022 08:46:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.15 on epoch=194
06/02/2022 08:46:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.11 on epoch=194
06/02/2022 08:46:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.12 on epoch=195
06/02/2022 08:46:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=196
06/02/2022 08:46:23 - INFO - __main__ - Global step 2750 Train loss 0.12 Classification-F1 0.7926429236997303 on epoch=196
06/02/2022 08:46:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.15 on epoch=197
06/02/2022 08:46:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.19 on epoch=197
06/02/2022 08:46:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.16 on epoch=198
06/02/2022 08:46:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.12 on epoch=199
06/02/2022 08:46:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.12 on epoch=199
06/02/2022 08:46:33 - INFO - __main__ - Global step 2800 Train loss 0.15 Classification-F1 0.8862574553388017 on epoch=199
06/02/2022 08:46:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.12 on epoch=200
06/02/2022 08:46:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=201
06/02/2022 08:46:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=202
06/02/2022 08:46:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.12 on epoch=202
06/02/2022 08:46:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.12 on epoch=203
06/02/2022 08:46:43 - INFO - __main__ - Global step 2850 Train loss 0.12 Classification-F1 0.8578349912790141 on epoch=203
06/02/2022 08:46:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.10 on epoch=204
06/02/2022 08:46:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.12 on epoch=204
06/02/2022 08:46:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/02/2022 08:46:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.15 on epoch=206
06/02/2022 08:46:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.14 on epoch=207
06/02/2022 08:46:53 - INFO - __main__ - Global step 2900 Train loss 0.12 Classification-F1 0.7554558871446917 on epoch=207
06/02/2022 08:46:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.14 on epoch=207
06/02/2022 08:46:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.16 on epoch=208
06/02/2022 08:46:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=209
06/02/2022 08:46:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=209
06/02/2022 08:47:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.10 on epoch=210
06/02/2022 08:47:03 - INFO - __main__ - Global step 2950 Train loss 0.12 Classification-F1 0.8913508690105779 on epoch=210
06/02/2022 08:47:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.08 on epoch=211
06/02/2022 08:47:06 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.10 on epoch=212
06/02/2022 08:47:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.10 on epoch=212
06/02/2022 08:47:09 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
06/02/2022 08:47:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.10 on epoch=214
06/02/2022 08:47:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:47:11 - INFO - __main__ - Printing 3 examples
06/02/2022 08:47:11 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:47:11 - INFO - __main__ - ['Company']
06/02/2022 08:47:11 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:47:11 - INFO - __main__ - ['Company']
06/02/2022 08:47:11 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:47:11 - INFO - __main__ - ['Company']
06/02/2022 08:47:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:47:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:47:11 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:47:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:47:11 - INFO - __main__ - Printing 3 examples
06/02/2022 08:47:11 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:47:11 - INFO - __main__ - ['Company']
06/02/2022 08:47:11 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:47:11 - INFO - __main__ - ['Company']
06/02/2022 08:47:11 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:47:11 - INFO - __main__ - ['Company']
06/02/2022 08:47:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:47:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:47:12 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:47:13 - INFO - __main__ - Global step 3000 Train loss 0.09 Classification-F1 0.8638161253310438 on epoch=214
06/02/2022 08:47:13 - INFO - __main__ - save last model!
06/02/2022 08:47:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 08:47:14 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 08:47:14 - INFO - __main__ - Printing 3 examples
06/02/2022 08:47:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 08:47:14 - INFO - __main__ - ['Animal']
06/02/2022 08:47:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 08:47:14 - INFO - __main__ - ['Animal']
06/02/2022 08:47:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 08:47:14 - INFO - __main__ - ['Village']
06/02/2022 08:47:14 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:47:15 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:47:17 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:47:17 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:47:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:47:17 - INFO - __main__ - Starting training!
06/02/2022 08:47:19 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 08:48:27 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/02/2022 08:48:27 - INFO - __main__ - Classification-F1 on test data: 0.6417
06/02/2022 08:48:28 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9012468148465047, test_performance=0.6417061593726163
06/02/2022 08:48:28 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/02/2022 08:48:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:48:28 - INFO - __main__ - Printing 3 examples
06/02/2022 08:48:28 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/02/2022 08:48:28 - INFO - __main__ - ['Company']
06/02/2022 08:48:28 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/02/2022 08:48:28 - INFO - __main__ - ['Company']
06/02/2022 08:48:28 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/02/2022 08:48:28 - INFO - __main__ - ['Company']
06/02/2022 08:48:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:48:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:48:29 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:48:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:48:29 - INFO - __main__ - Printing 3 examples
06/02/2022 08:48:29 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/02/2022 08:48:29 - INFO - __main__ - ['Company']
06/02/2022 08:48:29 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/02/2022 08:48:29 - INFO - __main__ - ['Company']
06/02/2022 08:48:29 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/02/2022 08:48:29 - INFO - __main__ - ['Company']
06/02/2022 08:48:29 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:48:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:48:29 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:48:35 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:48:35 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:48:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:48:36 - INFO - __main__ - Starting training!
06/02/2022 08:48:37 - INFO - __main__ - Step 10 Global step 10 Train loss 6.69 on epoch=0
06/02/2022 08:48:38 - INFO - __main__ - Step 20 Global step 20 Train loss 5.76 on epoch=1
06/02/2022 08:48:40 - INFO - __main__ - Step 30 Global step 30 Train loss 5.30 on epoch=2
06/02/2022 08:48:41 - INFO - __main__ - Step 40 Global step 40 Train loss 4.69 on epoch=2
06/02/2022 08:48:42 - INFO - __main__ - Step 50 Global step 50 Train loss 4.57 on epoch=3
06/02/2022 08:49:03 - INFO - __main__ - Global step 50 Train loss 5.40 Classification-F1 0.003807710613993337 on epoch=3
06/02/2022 08:49:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.003807710613993337 on epoch=3, global_step=50
06/02/2022 08:49:04 - INFO - __main__ - Step 60 Global step 60 Train loss 4.13 on epoch=4
06/02/2022 08:49:05 - INFO - __main__ - Step 70 Global step 70 Train loss 3.82 on epoch=4
06/02/2022 08:49:06 - INFO - __main__ - Step 80 Global step 80 Train loss 3.49 on epoch=5
06/02/2022 08:49:08 - INFO - __main__ - Step 90 Global step 90 Train loss 3.37 on epoch=6
06/02/2022 08:49:09 - INFO - __main__ - Step 100 Global step 100 Train loss 3.20 on epoch=7
06/02/2022 08:49:18 - INFO - __main__ - Global step 100 Train loss 3.60 Classification-F1 0.034317389559956064 on epoch=7
06/02/2022 08:49:18 - INFO - __main__ - Saving model with best Classification-F1: 0.003807710613993337 -> 0.034317389559956064 on epoch=7, global_step=100
06/02/2022 08:49:19 - INFO - __main__ - Step 110 Global step 110 Train loss 2.89 on epoch=7
06/02/2022 08:49:20 - INFO - __main__ - Step 120 Global step 120 Train loss 2.82 on epoch=8
06/02/2022 08:49:22 - INFO - __main__ - Step 130 Global step 130 Train loss 2.68 on epoch=9
06/02/2022 08:49:23 - INFO - __main__ - Step 140 Global step 140 Train loss 2.53 on epoch=9
06/02/2022 08:49:24 - INFO - __main__ - Step 150 Global step 150 Train loss 2.32 on epoch=10
06/02/2022 08:49:30 - INFO - __main__ - Global step 150 Train loss 2.65 Classification-F1 0.16714648167716603 on epoch=10
06/02/2022 08:49:30 - INFO - __main__ - Saving model with best Classification-F1: 0.034317389559956064 -> 0.16714648167716603 on epoch=10, global_step=150
06/02/2022 08:49:31 - INFO - __main__ - Step 160 Global step 160 Train loss 2.32 on epoch=11
06/02/2022 08:49:32 - INFO - __main__ - Step 170 Global step 170 Train loss 2.22 on epoch=12
06/02/2022 08:49:33 - INFO - __main__ - Step 180 Global step 180 Train loss 2.15 on epoch=12
06/02/2022 08:49:35 - INFO - __main__ - Step 190 Global step 190 Train loss 2.09 on epoch=13
06/02/2022 08:49:36 - INFO - __main__ - Step 200 Global step 200 Train loss 2.13 on epoch=14
06/02/2022 08:49:40 - INFO - __main__ - Global step 200 Train loss 2.18 Classification-F1 0.20000380350406985 on epoch=14
06/02/2022 08:49:40 - INFO - __main__ - Saving model with best Classification-F1: 0.16714648167716603 -> 0.20000380350406985 on epoch=14, global_step=200
06/02/2022 08:49:41 - INFO - __main__ - Step 210 Global step 210 Train loss 1.97 on epoch=14
06/02/2022 08:49:43 - INFO - __main__ - Step 220 Global step 220 Train loss 1.85 on epoch=15
06/02/2022 08:49:44 - INFO - __main__ - Step 230 Global step 230 Train loss 1.96 on epoch=16
06/02/2022 08:49:45 - INFO - __main__ - Step 240 Global step 240 Train loss 1.77 on epoch=17
06/02/2022 08:49:47 - INFO - __main__ - Step 250 Global step 250 Train loss 1.78 on epoch=17
06/02/2022 08:49:50 - INFO - __main__ - Global step 250 Train loss 1.87 Classification-F1 0.22572084249717875 on epoch=17
06/02/2022 08:49:50 - INFO - __main__ - Saving model with best Classification-F1: 0.20000380350406985 -> 0.22572084249717875 on epoch=17, global_step=250
06/02/2022 08:49:51 - INFO - __main__ - Step 260 Global step 260 Train loss 1.85 on epoch=18
06/02/2022 08:49:52 - INFO - __main__ - Step 270 Global step 270 Train loss 1.63 on epoch=19
06/02/2022 08:49:54 - INFO - __main__ - Step 280 Global step 280 Train loss 1.56 on epoch=19
06/02/2022 08:49:55 - INFO - __main__ - Step 290 Global step 290 Train loss 1.56 on epoch=20
06/02/2022 08:49:56 - INFO - __main__ - Step 300 Global step 300 Train loss 1.64 on epoch=21
06/02/2022 08:50:00 - INFO - __main__ - Global step 300 Train loss 1.65 Classification-F1 0.23105170055907936 on epoch=21
06/02/2022 08:50:00 - INFO - __main__ - Saving model with best Classification-F1: 0.22572084249717875 -> 0.23105170055907936 on epoch=21, global_step=300
06/02/2022 08:50:01 - INFO - __main__ - Step 310 Global step 310 Train loss 1.54 on epoch=22
06/02/2022 08:50:02 - INFO - __main__ - Step 320 Global step 320 Train loss 1.55 on epoch=22
06/02/2022 08:50:03 - INFO - __main__ - Step 330 Global step 330 Train loss 1.41 on epoch=23
06/02/2022 08:50:05 - INFO - __main__ - Step 340 Global step 340 Train loss 1.35 on epoch=24
06/02/2022 08:50:06 - INFO - __main__ - Step 350 Global step 350 Train loss 1.25 on epoch=24
06/02/2022 08:50:10 - INFO - __main__ - Global step 350 Train loss 1.42 Classification-F1 0.30250079277663466 on epoch=24
06/02/2022 08:50:10 - INFO - __main__ - Saving model with best Classification-F1: 0.23105170055907936 -> 0.30250079277663466 on epoch=24, global_step=350
06/02/2022 08:50:11 - INFO - __main__ - Step 360 Global step 360 Train loss 1.25 on epoch=25
06/02/2022 08:50:12 - INFO - __main__ - Step 370 Global step 370 Train loss 1.12 on epoch=26
06/02/2022 08:50:14 - INFO - __main__ - Step 380 Global step 380 Train loss 1.06 on epoch=27
06/02/2022 08:50:15 - INFO - __main__ - Step 390 Global step 390 Train loss 1.22 on epoch=27
06/02/2022 08:50:16 - INFO - __main__ - Step 400 Global step 400 Train loss 1.09 on epoch=28
06/02/2022 08:50:23 - INFO - __main__ - Global step 400 Train loss 1.15 Classification-F1 0.26565305329524236 on epoch=28
06/02/2022 08:50:24 - INFO - __main__ - Step 410 Global step 410 Train loss 1.19 on epoch=29
06/02/2022 08:50:26 - INFO - __main__ - Step 420 Global step 420 Train loss 1.03 on epoch=29
06/02/2022 08:50:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.92 on epoch=30
06/02/2022 08:50:28 - INFO - __main__ - Step 440 Global step 440 Train loss 1.01 on epoch=31
06/02/2022 08:50:29 - INFO - __main__ - Step 450 Global step 450 Train loss 1.07 on epoch=32
06/02/2022 08:50:33 - INFO - __main__ - Global step 450 Train loss 1.04 Classification-F1 0.33652706819789846 on epoch=32
06/02/2022 08:50:33 - INFO - __main__ - Saving model with best Classification-F1: 0.30250079277663466 -> 0.33652706819789846 on epoch=32, global_step=450
06/02/2022 08:50:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.93 on epoch=32
06/02/2022 08:50:36 - INFO - __main__ - Step 470 Global step 470 Train loss 1.01 on epoch=33
06/02/2022 08:50:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.91 on epoch=34
06/02/2022 08:50:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.93 on epoch=34
06/02/2022 08:50:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.88 on epoch=35
06/02/2022 08:50:44 - INFO - __main__ - Global step 500 Train loss 0.93 Classification-F1 0.35278268472607655 on epoch=35
06/02/2022 08:50:44 - INFO - __main__ - Saving model with best Classification-F1: 0.33652706819789846 -> 0.35278268472607655 on epoch=35, global_step=500
06/02/2022 08:50:45 - INFO - __main__ - Step 510 Global step 510 Train loss 1.14 on epoch=36
06/02/2022 08:50:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.87 on epoch=37
06/02/2022 08:50:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.88 on epoch=37
06/02/2022 08:50:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.80 on epoch=38
06/02/2022 08:50:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.86 on epoch=39
06/02/2022 08:50:54 - INFO - __main__ - Global step 550 Train loss 0.91 Classification-F1 0.4009380050904482 on epoch=39
06/02/2022 08:50:54 - INFO - __main__ - Saving model with best Classification-F1: 0.35278268472607655 -> 0.4009380050904482 on epoch=39, global_step=550
06/02/2022 08:50:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.85 on epoch=39
06/02/2022 08:50:56 - INFO - __main__ - Step 570 Global step 570 Train loss 0.83 on epoch=40
06/02/2022 08:50:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.83 on epoch=41
06/02/2022 08:50:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.94 on epoch=42
06/02/2022 08:51:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.90 on epoch=42
06/02/2022 08:51:04 - INFO - __main__ - Global step 600 Train loss 0.87 Classification-F1 0.47851750267521553 on epoch=42
06/02/2022 08:51:04 - INFO - __main__ - Saving model with best Classification-F1: 0.4009380050904482 -> 0.47851750267521553 on epoch=42, global_step=600
06/02/2022 08:51:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.78 on epoch=43
06/02/2022 08:51:07 - INFO - __main__ - Step 620 Global step 620 Train loss 0.92 on epoch=44
06/02/2022 08:51:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.87 on epoch=44
06/02/2022 08:51:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.71 on epoch=45
06/02/2022 08:51:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.81 on epoch=46
06/02/2022 08:51:14 - INFO - __main__ - Global step 650 Train loss 0.82 Classification-F1 0.40862792417979765 on epoch=46
06/02/2022 08:51:15 - INFO - __main__ - Step 660 Global step 660 Train loss 0.83 on epoch=47
06/02/2022 08:51:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.73 on epoch=47
06/02/2022 08:51:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.74 on epoch=48
06/02/2022 08:51:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.90 on epoch=49
06/02/2022 08:51:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.78 on epoch=49
06/02/2022 08:51:24 - INFO - __main__ - Global step 700 Train loss 0.79 Classification-F1 0.5046053694267604 on epoch=49
06/02/2022 08:51:24 - INFO - __main__ - Saving model with best Classification-F1: 0.47851750267521553 -> 0.5046053694267604 on epoch=49, global_step=700
06/02/2022 08:51:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.67 on epoch=50
06/02/2022 08:51:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.75 on epoch=51
06/02/2022 08:51:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.71 on epoch=52
06/02/2022 08:51:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.76 on epoch=52
06/02/2022 08:51:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.79 on epoch=53
06/02/2022 08:51:34 - INFO - __main__ - Global step 750 Train loss 0.74 Classification-F1 0.4553519158787953 on epoch=53
06/02/2022 08:51:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.69 on epoch=54
06/02/2022 08:51:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.64 on epoch=54
06/02/2022 08:51:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.50 on epoch=55
06/02/2022 08:51:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.72 on epoch=56
06/02/2022 08:51:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.74 on epoch=57
06/02/2022 08:51:43 - INFO - __main__ - Global step 800 Train loss 0.66 Classification-F1 0.42094705437416435 on epoch=57
06/02/2022 08:51:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.63 on epoch=57
06/02/2022 08:51:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.55 on epoch=58
06/02/2022 08:51:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.81 on epoch=59
06/02/2022 08:51:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.65 on epoch=59
06/02/2022 08:51:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.66 on epoch=60
06/02/2022 08:51:53 - INFO - __main__ - Global step 850 Train loss 0.66 Classification-F1 0.4532782056134089 on epoch=60
06/02/2022 08:51:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.67 on epoch=61
06/02/2022 08:51:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.72 on epoch=62
06/02/2022 08:51:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.55 on epoch=62
06/02/2022 08:51:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.50 on epoch=63
06/02/2022 08:52:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.62 on epoch=64
06/02/2022 08:52:04 - INFO - __main__ - Global step 900 Train loss 0.61 Classification-F1 0.4846295978968333 on epoch=64
06/02/2022 08:52:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.60 on epoch=64
06/02/2022 08:52:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.62 on epoch=65
06/02/2022 08:52:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.60 on epoch=66
06/02/2022 08:52:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.65 on epoch=67
06/02/2022 08:52:10 - INFO - __main__ - Step 950 Global step 950 Train loss 0.61 on epoch=67
06/02/2022 08:52:14 - INFO - __main__ - Global step 950 Train loss 0.62 Classification-F1 0.5037926702183788 on epoch=67
06/02/2022 08:52:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.53 on epoch=68
06/02/2022 08:52:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.66 on epoch=69
06/02/2022 08:52:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.58 on epoch=69
06/02/2022 08:52:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.47 on epoch=70
06/02/2022 08:52:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.61 on epoch=71
06/02/2022 08:52:24 - INFO - __main__ - Global step 1000 Train loss 0.57 Classification-F1 0.5087193745846322 on epoch=71
06/02/2022 08:52:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5046053694267604 -> 0.5087193745846322 on epoch=71, global_step=1000
06/02/2022 08:52:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.64 on epoch=72
06/02/2022 08:52:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.60 on epoch=72
06/02/2022 08:52:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.54 on epoch=73
06/02/2022 08:52:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.56 on epoch=74
06/02/2022 08:52:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.52 on epoch=74
06/02/2022 08:52:34 - INFO - __main__ - Global step 1050 Train loss 0.57 Classification-F1 0.6120748635501397 on epoch=74
06/02/2022 08:52:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5087193745846322 -> 0.6120748635501397 on epoch=74, global_step=1050
06/02/2022 08:52:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.47 on epoch=75
06/02/2022 08:52:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.62 on epoch=76
06/02/2022 08:52:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.53 on epoch=77
06/02/2022 08:52:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.60 on epoch=77
06/02/2022 08:52:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.43 on epoch=78
06/02/2022 08:52:44 - INFO - __main__ - Global step 1100 Train loss 0.53 Classification-F1 0.5949519173770258 on epoch=78
06/02/2022 08:52:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.53 on epoch=79
06/02/2022 08:52:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.47 on epoch=79
06/02/2022 08:52:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.45 on epoch=80
06/02/2022 08:52:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.53 on epoch=81
06/02/2022 08:52:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.46 on epoch=82
06/02/2022 08:52:54 - INFO - __main__ - Global step 1150 Train loss 0.49 Classification-F1 0.6117807675914169 on epoch=82
06/02/2022 08:52:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.48 on epoch=82
06/02/2022 08:52:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.44 on epoch=83
06/02/2022 08:52:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.51 on epoch=84
06/02/2022 08:52:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.48 on epoch=84
06/02/2022 08:53:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.45 on epoch=85
06/02/2022 08:53:04 - INFO - __main__ - Global step 1200 Train loss 0.47 Classification-F1 0.5144220460707506 on epoch=85
06/02/2022 08:53:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.60 on epoch=86
06/02/2022 08:53:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.48 on epoch=87
06/02/2022 08:53:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.43 on epoch=87
06/02/2022 08:53:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.33 on epoch=88
06/02/2022 08:53:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.43 on epoch=89
06/02/2022 08:53:14 - INFO - __main__ - Global step 1250 Train loss 0.45 Classification-F1 0.6208799018667113 on epoch=89
06/02/2022 08:53:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6120748635501397 -> 0.6208799018667113 on epoch=89, global_step=1250
06/02/2022 08:53:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.48 on epoch=89
06/02/2022 08:53:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.38 on epoch=90
06/02/2022 08:53:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.45 on epoch=91
06/02/2022 08:53:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.39 on epoch=92
06/02/2022 08:53:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.39 on epoch=92
06/02/2022 08:53:24 - INFO - __main__ - Global step 1300 Train loss 0.42 Classification-F1 0.5938625932092204 on epoch=92
06/02/2022 08:53:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.35 on epoch=93
06/02/2022 08:53:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.44 on epoch=94
06/02/2022 08:53:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.38 on epoch=94
06/02/2022 08:53:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.42 on epoch=95
06/02/2022 08:53:30 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.39 on epoch=96
06/02/2022 08:53:34 - INFO - __main__ - Global step 1350 Train loss 0.40 Classification-F1 0.6681264735411674 on epoch=96
06/02/2022 08:53:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6208799018667113 -> 0.6681264735411674 on epoch=96, global_step=1350
06/02/2022 08:53:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.46 on epoch=97
06/02/2022 08:53:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.44 on epoch=97
06/02/2022 08:53:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.35 on epoch=98
06/02/2022 08:53:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.39 on epoch=99
06/02/2022 08:53:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.41 on epoch=99
06/02/2022 08:53:44 - INFO - __main__ - Global step 1400 Train loss 0.41 Classification-F1 0.7068121095398681 on epoch=99
06/02/2022 08:53:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6681264735411674 -> 0.7068121095398681 on epoch=99, global_step=1400
06/02/2022 08:53:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.39 on epoch=100
06/02/2022 08:53:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.38 on epoch=101
06/02/2022 08:53:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.42 on epoch=102
06/02/2022 08:53:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.37 on epoch=102
06/02/2022 08:53:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.33 on epoch=103
06/02/2022 08:53:54 - INFO - __main__ - Global step 1450 Train loss 0.38 Classification-F1 0.8144177876120776 on epoch=103
06/02/2022 08:53:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7068121095398681 -> 0.8144177876120776 on epoch=103, global_step=1450
06/02/2022 08:53:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.44 on epoch=104
06/02/2022 08:53:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.30 on epoch=104
06/02/2022 08:53:58 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.28 on epoch=105
06/02/2022 08:53:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.41 on epoch=106
06/02/2022 08:54:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.37 on epoch=107
06/02/2022 08:54:04 - INFO - __main__ - Global step 1500 Train loss 0.36 Classification-F1 0.6687486033707175 on epoch=107
06/02/2022 08:54:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.37 on epoch=107
06/02/2022 08:54:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.31 on epoch=108
06/02/2022 08:54:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.37 on epoch=109
06/02/2022 08:54:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.34 on epoch=109
06/02/2022 08:54:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.39 on epoch=110
06/02/2022 08:54:15 - INFO - __main__ - Global step 1550 Train loss 0.36 Classification-F1 0.7317251582051906 on epoch=110
06/02/2022 08:54:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.38 on epoch=111
06/02/2022 08:54:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.37 on epoch=112
06/02/2022 08:54:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.30 on epoch=112
06/02/2022 08:54:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.30 on epoch=113
06/02/2022 08:54:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.31 on epoch=114
06/02/2022 08:54:25 - INFO - __main__ - Global step 1600 Train loss 0.33 Classification-F1 0.7799446670635505 on epoch=114
06/02/2022 08:54:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.41 on epoch=114
06/02/2022 08:54:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.32 on epoch=115
06/02/2022 08:54:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.37 on epoch=116
06/02/2022 08:54:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.34 on epoch=117
06/02/2022 08:54:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.43 on epoch=117
06/02/2022 08:54:35 - INFO - __main__ - Global step 1650 Train loss 0.37 Classification-F1 0.6884401150915711 on epoch=117
06/02/2022 08:54:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.34 on epoch=118
06/02/2022 08:54:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.42 on epoch=119
06/02/2022 08:54:39 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.32 on epoch=119
06/02/2022 08:54:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.31 on epoch=120
06/02/2022 08:54:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.33 on epoch=121
06/02/2022 08:54:45 - INFO - __main__ - Global step 1700 Train loss 0.34 Classification-F1 0.6921842787174222 on epoch=121
06/02/2022 08:54:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.40 on epoch=122
06/02/2022 08:54:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.40 on epoch=122
06/02/2022 08:54:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.27 on epoch=123
06/02/2022 08:54:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.34 on epoch=124
06/02/2022 08:54:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.31 on epoch=124
06/02/2022 08:54:55 - INFO - __main__ - Global step 1750 Train loss 0.35 Classification-F1 0.7460503489868362 on epoch=124
06/02/2022 08:54:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.28 on epoch=125
06/02/2022 08:54:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.29 on epoch=126
06/02/2022 08:54:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.36 on epoch=127
06/02/2022 08:55:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.27 on epoch=127
06/02/2022 08:55:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.30 on epoch=128
06/02/2022 08:55:05 - INFO - __main__ - Global step 1800 Train loss 0.30 Classification-F1 0.7042904841644834 on epoch=128
06/02/2022 08:55:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.29 on epoch=129
06/02/2022 08:55:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.32 on epoch=129
06/02/2022 08:55:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.25 on epoch=130
06/02/2022 08:55:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.36 on epoch=131
06/02/2022 08:55:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.29 on epoch=132
06/02/2022 08:55:15 - INFO - __main__ - Global step 1850 Train loss 0.30 Classification-F1 0.7444372729581227 on epoch=132
06/02/2022 08:55:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.35 on epoch=132
06/02/2022 08:55:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.24 on epoch=133
06/02/2022 08:55:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.25 on epoch=134
06/02/2022 08:55:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.29 on epoch=134
06/02/2022 08:55:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.25 on epoch=135
06/02/2022 08:55:25 - INFO - __main__ - Global step 1900 Train loss 0.28 Classification-F1 0.7679897231394068 on epoch=135
06/02/2022 08:55:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.33 on epoch=136
06/02/2022 08:55:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.27 on epoch=137
06/02/2022 08:55:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.27 on epoch=137
06/02/2022 08:55:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.23 on epoch=138
06/02/2022 08:55:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.28 on epoch=139
06/02/2022 08:55:36 - INFO - __main__ - Global step 1950 Train loss 0.27 Classification-F1 0.7251630703691636 on epoch=139
06/02/2022 08:55:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.19 on epoch=139
06/02/2022 08:55:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.26 on epoch=140
06/02/2022 08:55:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.27 on epoch=141
06/02/2022 08:55:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.34 on epoch=142
06/02/2022 08:55:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.33 on epoch=142
06/02/2022 08:55:46 - INFO - __main__ - Global step 2000 Train loss 0.28 Classification-F1 0.6234159160444792 on epoch=142
06/02/2022 08:55:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.24 on epoch=143
06/02/2022 08:55:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.32 on epoch=144
06/02/2022 08:55:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.28 on epoch=144
06/02/2022 08:55:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.26 on epoch=145
06/02/2022 08:55:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.29 on epoch=146
06/02/2022 08:55:56 - INFO - __main__ - Global step 2050 Train loss 0.28 Classification-F1 0.7490243071348663 on epoch=146
06/02/2022 08:55:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.26 on epoch=147
06/02/2022 08:55:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.22 on epoch=147
06/02/2022 08:56:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.17 on epoch=148
06/02/2022 08:56:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.29 on epoch=149
06/02/2022 08:56:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.30 on epoch=149
06/02/2022 08:56:06 - INFO - __main__ - Global step 2100 Train loss 0.25 Classification-F1 0.781931983040854 on epoch=149
06/02/2022 08:56:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.16 on epoch=150
06/02/2022 08:56:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.21 on epoch=151
06/02/2022 08:56:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.21 on epoch=152
06/02/2022 08:56:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.24 on epoch=152
06/02/2022 08:56:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.21 on epoch=153
06/02/2022 08:56:16 - INFO - __main__ - Global step 2150 Train loss 0.21 Classification-F1 0.7909414610019448 on epoch=153
06/02/2022 08:56:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.26 on epoch=154
06/02/2022 08:56:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.24 on epoch=154
06/02/2022 08:56:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.23 on epoch=155
06/02/2022 08:56:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.29 on epoch=156
06/02/2022 08:56:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.28 on epoch=157
06/02/2022 08:56:26 - INFO - __main__ - Global step 2200 Train loss 0.26 Classification-F1 0.7338251674543562 on epoch=157
06/02/2022 08:56:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.31 on epoch=157
06/02/2022 08:56:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.19 on epoch=158
06/02/2022 08:56:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.22 on epoch=159
06/02/2022 08:56:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.22 on epoch=159
06/02/2022 08:56:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.17 on epoch=160
06/02/2022 08:56:36 - INFO - __main__ - Global step 2250 Train loss 0.23 Classification-F1 0.7812141208983181 on epoch=160
06/02/2022 08:56:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.31 on epoch=161
06/02/2022 08:56:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.21 on epoch=162
06/02/2022 08:56:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.16 on epoch=162
06/02/2022 08:56:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.23 on epoch=163
06/02/2022 08:56:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.25 on epoch=164
06/02/2022 08:56:46 - INFO - __main__ - Global step 2300 Train loss 0.23 Classification-F1 0.7720775113564488 on epoch=164
06/02/2022 08:56:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.22 on epoch=164
06/02/2022 08:56:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.19 on epoch=165
06/02/2022 08:56:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.14 on epoch=166
06/02/2022 08:56:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.22 on epoch=167
06/02/2022 08:56:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.25 on epoch=167
06/02/2022 08:56:56 - INFO - __main__ - Global step 2350 Train loss 0.20 Classification-F1 0.7115649616262684 on epoch=167
06/02/2022 08:56:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.15 on epoch=168
06/02/2022 08:56:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.20 on epoch=169
06/02/2022 08:56:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.25 on epoch=169
06/02/2022 08:57:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.14 on epoch=170
06/02/2022 08:57:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.26 on epoch=171
06/02/2022 08:57:06 - INFO - __main__ - Global step 2400 Train loss 0.20 Classification-F1 0.6625682956238145 on epoch=171
06/02/2022 08:57:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.16 on epoch=172
06/02/2022 08:57:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.21 on epoch=172
06/02/2022 08:57:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.21 on epoch=173
06/02/2022 08:57:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.23 on epoch=174
06/02/2022 08:57:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.24 on epoch=174
06/02/2022 08:57:16 - INFO - __main__ - Global step 2450 Train loss 0.21 Classification-F1 0.7976649170787572 on epoch=174
06/02/2022 08:57:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.19 on epoch=175
06/02/2022 08:57:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.20 on epoch=176
06/02/2022 08:57:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.12 on epoch=177
06/02/2022 08:57:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.24 on epoch=177
06/02/2022 08:57:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.14 on epoch=178
06/02/2022 08:57:26 - INFO - __main__ - Global step 2500 Train loss 0.18 Classification-F1 0.7650029166800012 on epoch=178
06/02/2022 08:57:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.18 on epoch=179
06/02/2022 08:57:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.12 on epoch=179
06/02/2022 08:57:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.14 on epoch=180
06/02/2022 08:57:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.23 on epoch=181
06/02/2022 08:57:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.21 on epoch=182
06/02/2022 08:57:36 - INFO - __main__ - Global step 2550 Train loss 0.18 Classification-F1 0.7969023840587731 on epoch=182
06/02/2022 08:57:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.17 on epoch=182
06/02/2022 08:57:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=183
06/02/2022 08:57:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.13 on epoch=184
06/02/2022 08:57:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.21 on epoch=184
06/02/2022 08:57:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.18 on epoch=185
06/02/2022 08:57:46 - INFO - __main__ - Global step 2600 Train loss 0.16 Classification-F1 0.749308931906089 on epoch=185
06/02/2022 08:57:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.17 on epoch=186
06/02/2022 08:57:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.12 on epoch=187
06/02/2022 08:57:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.12 on epoch=187
06/02/2022 08:57:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.17 on epoch=188
06/02/2022 08:57:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.13 on epoch=189
06/02/2022 08:57:56 - INFO - __main__ - Global step 2650 Train loss 0.14 Classification-F1 0.7988695276497696 on epoch=189
06/02/2022 08:57:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.12 on epoch=189
06/02/2022 08:57:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=190
06/02/2022 08:58:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.25 on epoch=191
06/02/2022 08:58:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.20 on epoch=192
06/02/2022 08:58:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.13 on epoch=192
06/02/2022 08:58:06 - INFO - __main__ - Global step 2700 Train loss 0.16 Classification-F1 0.7669625965181587 on epoch=192
06/02/2022 08:58:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.17 on epoch=193
06/02/2022 08:58:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.17 on epoch=194
06/02/2022 08:58:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.13 on epoch=194
06/02/2022 08:58:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.16 on epoch=195
06/02/2022 08:58:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.18 on epoch=196
06/02/2022 08:58:16 - INFO - __main__ - Global step 2750 Train loss 0.16 Classification-F1 0.7653409718400231 on epoch=196
06/02/2022 08:58:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.15 on epoch=197
06/02/2022 08:58:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.16 on epoch=197
06/02/2022 08:58:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.21 on epoch=198
06/02/2022 08:58:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.34 on epoch=199
06/02/2022 08:58:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.22 on epoch=199
06/02/2022 08:58:26 - INFO - __main__ - Global step 2800 Train loss 0.22 Classification-F1 0.6812453148329011 on epoch=199
06/02/2022 08:58:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.19 on epoch=200
06/02/2022 08:58:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.18 on epoch=201
06/02/2022 08:58:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.14 on epoch=202
06/02/2022 08:58:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.13 on epoch=202
06/02/2022 08:58:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.18 on epoch=203
06/02/2022 08:58:36 - INFO - __main__ - Global step 2850 Train loss 0.16 Classification-F1 0.7949233670741024 on epoch=203
06/02/2022 08:58:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.21 on epoch=204
06/02/2022 08:58:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.17 on epoch=204
06/02/2022 08:58:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.12 on epoch=205
06/02/2022 08:58:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.13 on epoch=206
06/02/2022 08:58:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.15 on epoch=207
06/02/2022 08:58:46 - INFO - __main__ - Global step 2900 Train loss 0.16 Classification-F1 0.7417510195959243 on epoch=207
06/02/2022 08:58:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.12 on epoch=207
06/02/2022 08:58:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=208
06/02/2022 08:58:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.13 on epoch=209
06/02/2022 08:58:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.13 on epoch=209
06/02/2022 08:58:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=210
06/02/2022 08:58:56 - INFO - __main__ - Global step 2950 Train loss 0.12 Classification-F1 0.8050768807153312 on epoch=210
06/02/2022 08:58:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.15 on epoch=211
06/02/2022 08:58:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.17 on epoch=212
06/02/2022 08:58:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.16 on epoch=212
06/02/2022 08:59:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.12 on epoch=213
06/02/2022 08:59:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.14 on epoch=214
06/02/2022 08:59:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:59:03 - INFO - __main__ - Printing 3 examples
06/02/2022 08:59:03 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 08:59:03 - INFO - __main__ - ['Film']
06/02/2022 08:59:03 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 08:59:03 - INFO - __main__ - ['Film']
06/02/2022 08:59:03 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 08:59:03 - INFO - __main__ - ['Film']
06/02/2022 08:59:03 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:59:03 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:59:03 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 08:59:03 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 08:59:03 - INFO - __main__ - Printing 3 examples
06/02/2022 08:59:03 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 08:59:03 - INFO - __main__ - ['Film']
06/02/2022 08:59:03 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 08:59:03 - INFO - __main__ - ['Film']
06/02/2022 08:59:03 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 08:59:03 - INFO - __main__ - ['Film']
06/02/2022 08:59:03 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:59:04 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:59:04 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 08:59:06 - INFO - __main__ - Global step 3000 Train loss 0.15 Classification-F1 0.7794415420126996 on epoch=214
06/02/2022 08:59:06 - INFO - __main__ - save last model!
06/02/2022 08:59:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 08:59:06 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 08:59:06 - INFO - __main__ - Printing 3 examples
06/02/2022 08:59:06 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 08:59:06 - INFO - __main__ - ['Animal']
06/02/2022 08:59:06 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 08:59:06 - INFO - __main__ - ['Animal']
06/02/2022 08:59:06 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 08:59:06 - INFO - __main__ - ['Village']
06/02/2022 08:59:06 - INFO - __main__ - Tokenizing Input ...
06/02/2022 08:59:08 - INFO - __main__ - Tokenizing Output ...
06/02/2022 08:59:10 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 08:59:10 - INFO - __main__ - task name: dbpedia_14
06/02/2022 08:59:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 08:59:11 - INFO - __main__ - Starting training!
06/02/2022 08:59:11 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 09:00:23 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/02/2022 09:00:23 - INFO - __main__ - Classification-F1 on test data: 0.5205
06/02/2022 09:00:23 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.8144177876120776, test_performance=0.5204562235737535
06/02/2022 09:00:23 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/02/2022 09:00:24 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:00:24 - INFO - __main__ - Printing 3 examples
06/02/2022 09:00:24 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 09:00:24 - INFO - __main__ - ['Film']
06/02/2022 09:00:24 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 09:00:24 - INFO - __main__ - ['Film']
06/02/2022 09:00:24 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 09:00:24 - INFO - __main__ - ['Film']
06/02/2022 09:00:24 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:00:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:00:25 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:00:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:00:25 - INFO - __main__ - Printing 3 examples
06/02/2022 09:00:25 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 09:00:25 - INFO - __main__ - ['Film']
06/02/2022 09:00:25 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 09:00:25 - INFO - __main__ - ['Film']
06/02/2022 09:00:25 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 09:00:25 - INFO - __main__ - ['Film']
06/02/2022 09:00:25 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:00:25 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:00:25 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:00:31 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 09:00:31 - INFO - __main__ - task name: dbpedia_14
06/02/2022 09:00:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 09:00:32 - INFO - __main__ - Starting training!
06/02/2022 09:00:33 - INFO - __main__ - Step 10 Global step 10 Train loss 6.65 on epoch=0
06/02/2022 09:00:34 - INFO - __main__ - Step 20 Global step 20 Train loss 5.11 on epoch=1
06/02/2022 09:00:36 - INFO - __main__ - Step 30 Global step 30 Train loss 4.43 on epoch=2
06/02/2022 09:00:37 - INFO - __main__ - Step 40 Global step 40 Train loss 3.35 on epoch=2
06/02/2022 09:00:38 - INFO - __main__ - Step 50 Global step 50 Train loss 2.97 on epoch=3
06/02/2022 09:00:45 - INFO - __main__ - Global step 50 Train loss 4.50 Classification-F1 0.11918336933883467 on epoch=3
06/02/2022 09:00:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11918336933883467 on epoch=3, global_step=50
06/02/2022 09:00:46 - INFO - __main__ - Step 60 Global step 60 Train loss 2.45 on epoch=4
06/02/2022 09:00:47 - INFO - __main__ - Step 70 Global step 70 Train loss 2.15 on epoch=4
06/02/2022 09:00:48 - INFO - __main__ - Step 80 Global step 80 Train loss 2.04 on epoch=5
06/02/2022 09:00:50 - INFO - __main__ - Step 90 Global step 90 Train loss 1.68 on epoch=6
06/02/2022 09:00:51 - INFO - __main__ - Step 100 Global step 100 Train loss 1.61 on epoch=7
06/02/2022 09:00:56 - INFO - __main__ - Global step 100 Train loss 1.99 Classification-F1 0.19892744386626476 on epoch=7
06/02/2022 09:00:56 - INFO - __main__ - Saving model with best Classification-F1: 0.11918336933883467 -> 0.19892744386626476 on epoch=7, global_step=100
06/02/2022 09:00:57 - INFO - __main__ - Step 110 Global step 110 Train loss 1.35 on epoch=7
06/02/2022 09:00:58 - INFO - __main__ - Step 120 Global step 120 Train loss 1.36 on epoch=8
06/02/2022 09:01:00 - INFO - __main__ - Step 130 Global step 130 Train loss 1.17 on epoch=9
06/02/2022 09:01:01 - INFO - __main__ - Step 140 Global step 140 Train loss 1.29 on epoch=9
06/02/2022 09:01:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.15 on epoch=10
06/02/2022 09:01:06 - INFO - __main__ - Global step 150 Train loss 1.26 Classification-F1 0.3782773034858686 on epoch=10
06/02/2022 09:01:06 - INFO - __main__ - Saving model with best Classification-F1: 0.19892744386626476 -> 0.3782773034858686 on epoch=10, global_step=150
06/02/2022 09:01:07 - INFO - __main__ - Step 160 Global step 160 Train loss 1.08 on epoch=11
06/02/2022 09:01:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.99 on epoch=12
06/02/2022 09:01:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=12
06/02/2022 09:01:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.95 on epoch=13
06/02/2022 09:01:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.94 on epoch=14
06/02/2022 09:01:15 - INFO - __main__ - Global step 200 Train loss 0.98 Classification-F1 0.3912726393440581 on epoch=14
06/02/2022 09:01:15 - INFO - __main__ - Saving model with best Classification-F1: 0.3782773034858686 -> 0.3912726393440581 on epoch=14, global_step=200
06/02/2022 09:01:16 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=14
06/02/2022 09:01:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=15
06/02/2022 09:01:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=16
06/02/2022 09:01:20 - INFO - __main__ - Step 240 Global step 240 Train loss 2.23 on epoch=17
06/02/2022 09:01:21 - INFO - __main__ - Step 250 Global step 250 Train loss 3.82 on epoch=17
06/02/2022 09:01:58 - INFO - __main__ - Global step 250 Train loss 1.69 Classification-F1 0.006305532965874522 on epoch=17
06/02/2022 09:01:59 - INFO - __main__ - Step 260 Global step 260 Train loss 5.20 on epoch=18
06/02/2022 09:02:00 - INFO - __main__ - Step 270 Global step 270 Train loss 1.55 on epoch=19
06/02/2022 09:02:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.87 on epoch=19
06/02/2022 09:02:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.81 on epoch=20
06/02/2022 09:02:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.72 on epoch=21
06/02/2022 09:02:07 - INFO - __main__ - Global step 300 Train loss 1.83 Classification-F1 0.4529688875593879 on epoch=21
06/02/2022 09:02:07 - INFO - __main__ - Saving model with best Classification-F1: 0.3912726393440581 -> 0.4529688875593879 on epoch=21, global_step=300
06/02/2022 09:02:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=22
06/02/2022 09:02:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.63 on epoch=22
06/02/2022 09:02:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.69 on epoch=23
06/02/2022 09:02:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.71 on epoch=24
06/02/2022 09:02:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.70 on epoch=24
06/02/2022 09:02:17 - INFO - __main__ - Global step 350 Train loss 0.70 Classification-F1 0.508717590082628 on epoch=24
06/02/2022 09:02:17 - INFO - __main__ - Saving model with best Classification-F1: 0.4529688875593879 -> 0.508717590082628 on epoch=24, global_step=350
06/02/2022 09:02:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.75 on epoch=25
06/02/2022 09:02:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.64 on epoch=26
06/02/2022 09:02:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.67 on epoch=27
06/02/2022 09:02:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.71 on epoch=27
06/02/2022 09:02:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=28
06/02/2022 09:02:27 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.5735255221032423 on epoch=28
06/02/2022 09:02:27 - INFO - __main__ - Saving model with best Classification-F1: 0.508717590082628 -> 0.5735255221032423 on epoch=28, global_step=400
06/02/2022 09:02:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.61 on epoch=29
06/02/2022 09:02:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.65 on epoch=29
06/02/2022 09:02:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.70 on epoch=30
06/02/2022 09:02:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.65 on epoch=31
06/02/2022 09:02:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.77 on epoch=32
06/02/2022 09:02:36 - INFO - __main__ - Global step 450 Train loss 0.68 Classification-F1 0.6088457805750597 on epoch=32
06/02/2022 09:02:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5735255221032423 -> 0.6088457805750597 on epoch=32, global_step=450
06/02/2022 09:02:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.63 on epoch=32
06/02/2022 09:02:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.66 on epoch=33
06/02/2022 09:02:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.65 on epoch=34
06/02/2022 09:02:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.64 on epoch=34
06/02/2022 09:02:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.64 on epoch=35
06/02/2022 09:02:46 - INFO - __main__ - Global step 500 Train loss 0.65 Classification-F1 0.6031889742730988 on epoch=35
06/02/2022 09:02:47 - INFO - __main__ - Step 510 Global step 510 Train loss 0.72 on epoch=36
06/02/2022 09:02:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.69 on epoch=37
06/02/2022 09:02:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.67 on epoch=37
06/02/2022 09:02:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.56 on epoch=38
06/02/2022 09:02:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.64 on epoch=39
06/02/2022 09:02:56 - INFO - __main__ - Global step 550 Train loss 0.65 Classification-F1 0.5537399290899034 on epoch=39
06/02/2022 09:02:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.61 on epoch=39
06/02/2022 09:02:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=40
06/02/2022 09:02:59 - INFO - __main__ - Step 580 Global step 580 Train loss 0.68 on epoch=41
06/02/2022 09:03:01 - INFO - __main__ - Step 590 Global step 590 Train loss 0.60 on epoch=42
06/02/2022 09:03:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.52 on epoch=42
06/02/2022 09:03:06 - INFO - __main__ - Global step 600 Train loss 0.59 Classification-F1 0.5947230543135035 on epoch=42
06/02/2022 09:03:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.59 on epoch=43
06/02/2022 09:03:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.60 on epoch=44
06/02/2022 09:03:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.56 on epoch=44
06/02/2022 09:03:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.57 on epoch=45
06/02/2022 09:03:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.51 on epoch=46
06/02/2022 09:03:16 - INFO - __main__ - Global step 650 Train loss 0.57 Classification-F1 0.5631822684835018 on epoch=46
06/02/2022 09:03:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.48 on epoch=47
06/02/2022 09:03:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.52 on epoch=47
06/02/2022 09:03:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.64 on epoch=48
06/02/2022 09:03:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.59 on epoch=49
06/02/2022 09:03:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.56 on epoch=49
06/02/2022 09:03:25 - INFO - __main__ - Global step 700 Train loss 0.56 Classification-F1 0.6565119398792032 on epoch=49
06/02/2022 09:03:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6088457805750597 -> 0.6565119398792032 on epoch=49, global_step=700
06/02/2022 09:03:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.55 on epoch=50
06/02/2022 09:03:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.50 on epoch=51
06/02/2022 09:03:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.50 on epoch=52
06/02/2022 09:03:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.54 on epoch=52
06/02/2022 09:03:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.64 on epoch=53
06/02/2022 09:03:36 - INFO - __main__ - Global step 750 Train loss 0.55 Classification-F1 0.6336721905478857 on epoch=53
06/02/2022 09:03:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.56 on epoch=54
06/02/2022 09:03:38 - INFO - __main__ - Step 770 Global step 770 Train loss 0.57 on epoch=54
06/02/2022 09:03:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.58 on epoch=55
06/02/2022 09:03:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.60 on epoch=56
06/02/2022 09:03:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.50 on epoch=57
06/02/2022 09:03:46 - INFO - __main__ - Global step 800 Train loss 0.56 Classification-F1 0.7409224782674297 on epoch=57
06/02/2022 09:03:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6565119398792032 -> 0.7409224782674297 on epoch=57, global_step=800
06/02/2022 09:03:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.54 on epoch=57
06/02/2022 09:03:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.47 on epoch=58
06/02/2022 09:03:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.46 on epoch=59
06/02/2022 09:03:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.54 on epoch=59
06/02/2022 09:03:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.57 on epoch=60
06/02/2022 09:03:56 - INFO - __main__ - Global step 850 Train loss 0.52 Classification-F1 0.7760483195625355 on epoch=60
06/02/2022 09:03:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7409224782674297 -> 0.7760483195625355 on epoch=60, global_step=850
06/02/2022 09:03:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.62 on epoch=61
06/02/2022 09:03:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.46 on epoch=62
06/02/2022 09:04:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.48 on epoch=62
06/02/2022 09:04:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.49 on epoch=63
06/02/2022 09:04:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.40 on epoch=64
06/02/2022 09:04:06 - INFO - __main__ - Global step 900 Train loss 0.49 Classification-F1 0.6928882452197477 on epoch=64
06/02/2022 09:04:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.47 on epoch=64
06/02/2022 09:04:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.45 on epoch=65
06/02/2022 09:04:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.40 on epoch=66
06/02/2022 09:04:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.51 on epoch=67
06/02/2022 09:04:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.42 on epoch=67
06/02/2022 09:04:16 - INFO - __main__ - Global step 950 Train loss 0.45 Classification-F1 0.7736297510206427 on epoch=67
06/02/2022 09:04:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.53 on epoch=68
06/02/2022 09:04:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.50 on epoch=69
06/02/2022 09:04:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.39 on epoch=69
06/02/2022 09:04:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.37 on epoch=70
06/02/2022 09:04:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.48 on epoch=71
06/02/2022 09:04:25 - INFO - __main__ - Global step 1000 Train loss 0.45 Classification-F1 0.6789721213499319 on epoch=71
06/02/2022 09:04:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.44 on epoch=72
06/02/2022 09:04:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.31 on epoch=72
06/02/2022 09:04:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.44 on epoch=73
06/02/2022 09:04:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.38 on epoch=74
06/02/2022 09:04:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.38 on epoch=74
06/02/2022 09:04:35 - INFO - __main__ - Global step 1050 Train loss 0.39 Classification-F1 0.7984219059322044 on epoch=74
06/02/2022 09:04:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7760483195625355 -> 0.7984219059322044 on epoch=74, global_step=1050
06/02/2022 09:04:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.44 on epoch=75
06/02/2022 09:04:38 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.45 on epoch=76
06/02/2022 09:04:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.40 on epoch=77
06/02/2022 09:04:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.28 on epoch=77
06/02/2022 09:04:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.33 on epoch=78
06/02/2022 09:04:45 - INFO - __main__ - Global step 1100 Train loss 0.38 Classification-F1 0.6637042266759967 on epoch=78
06/02/2022 09:04:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.42 on epoch=79
06/02/2022 09:04:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.33 on epoch=79
06/02/2022 09:04:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.37 on epoch=80
06/02/2022 09:04:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.40 on epoch=81
06/02/2022 09:04:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.35 on epoch=82
06/02/2022 09:04:56 - INFO - __main__ - Global step 1150 Train loss 0.37 Classification-F1 0.7841947327126939 on epoch=82
06/02/2022 09:04:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.32 on epoch=82
06/02/2022 09:04:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.31 on epoch=83
06/02/2022 09:04:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.43 on epoch=84
06/02/2022 09:05:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.31 on epoch=84
06/02/2022 09:05:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.30 on epoch=85
06/02/2022 09:05:06 - INFO - __main__ - Global step 1200 Train loss 0.33 Classification-F1 0.766628424993878 on epoch=85
06/02/2022 09:05:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.29 on epoch=86
06/02/2022 09:05:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.26 on epoch=87
06/02/2022 09:05:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.24 on epoch=87
06/02/2022 09:05:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.31 on epoch=88
06/02/2022 09:05:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.33 on epoch=89
06/02/2022 09:05:16 - INFO - __main__ - Global step 1250 Train loss 0.29 Classification-F1 0.8403259146947352 on epoch=89
06/02/2022 09:05:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7984219059322044 -> 0.8403259146947352 on epoch=89, global_step=1250
06/02/2022 09:05:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.27 on epoch=89
06/02/2022 09:05:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.27 on epoch=90
06/02/2022 09:05:19 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.28 on epoch=91
06/02/2022 09:05:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.26 on epoch=92
06/02/2022 09:05:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.33 on epoch=92
06/02/2022 09:05:26 - INFO - __main__ - Global step 1300 Train loss 0.28 Classification-F1 0.808850155221123 on epoch=92
06/02/2022 09:05:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.23 on epoch=93
06/02/2022 09:05:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=94
06/02/2022 09:05:29 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.30 on epoch=94
06/02/2022 09:05:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.24 on epoch=95
06/02/2022 09:05:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.26 on epoch=96
06/02/2022 09:05:36 - INFO - __main__ - Global step 1350 Train loss 0.25 Classification-F1 0.7600385732568242 on epoch=96
06/02/2022 09:05:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=97
06/02/2022 09:05:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.23 on epoch=97
06/02/2022 09:05:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.26 on epoch=98
06/02/2022 09:05:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.31 on epoch=99
06/02/2022 09:05:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.19 on epoch=99
06/02/2022 09:05:46 - INFO - __main__ - Global step 1400 Train loss 0.25 Classification-F1 0.8533132652259454 on epoch=99
06/02/2022 09:05:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8403259146947352 -> 0.8533132652259454 on epoch=99, global_step=1400
06/02/2022 09:05:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=100
06/02/2022 09:05:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=101
06/02/2022 09:05:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.27 on epoch=102
06/02/2022 09:05:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.20 on epoch=102
06/02/2022 09:05:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.23 on epoch=103
06/02/2022 09:05:56 - INFO - __main__ - Global step 1450 Train loss 0.23 Classification-F1 0.8930938416422286 on epoch=103
06/02/2022 09:05:56 - INFO - __main__ - Saving model with best Classification-F1: 0.8533132652259454 -> 0.8930938416422286 on epoch=103, global_step=1450
06/02/2022 09:05:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.22 on epoch=104
06/02/2022 09:05:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=104
06/02/2022 09:06:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.26 on epoch=105
06/02/2022 09:06:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.26 on epoch=106
06/02/2022 09:06:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.18 on epoch=107
06/02/2022 09:06:06 - INFO - __main__ - Global step 1500 Train loss 0.22 Classification-F1 0.6869046649288584 on epoch=107
06/02/2022 09:06:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.14 on epoch=107
06/02/2022 09:06:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=108
06/02/2022 09:06:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.21 on epoch=109
06/02/2022 09:06:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.20 on epoch=109
06/02/2022 09:06:13 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.16 on epoch=110
06/02/2022 09:06:16 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.7760258245287266 on epoch=110
06/02/2022 09:06:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.24 on epoch=111
06/02/2022 09:06:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=112
06/02/2022 09:06:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=112
06/02/2022 09:06:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.19 on epoch=113
06/02/2022 09:06:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=114
06/02/2022 09:06:26 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.7649324957288668 on epoch=114
06/02/2022 09:06:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=114
06/02/2022 09:06:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.21 on epoch=115
06/02/2022 09:06:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.20 on epoch=116
06/02/2022 09:06:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.20 on epoch=117
06/02/2022 09:06:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=117
06/02/2022 09:06:36 - INFO - __main__ - Global step 1650 Train loss 0.18 Classification-F1 0.8160853141166234 on epoch=117
06/02/2022 09:06:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=118
06/02/2022 09:06:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.23 on epoch=119
06/02/2022 09:06:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.15 on epoch=119
06/02/2022 09:06:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=120
06/02/2022 09:06:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.17 on epoch=121
06/02/2022 09:06:46 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.8187642742923733 on epoch=121
06/02/2022 09:06:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.20 on epoch=122
06/02/2022 09:06:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
06/02/2022 09:06:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=123
06/02/2022 09:06:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=124
06/02/2022 09:06:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=124
06/02/2022 09:06:56 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.7304105784814197 on epoch=124
06/02/2022 09:06:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.13 on epoch=125
06/02/2022 09:06:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/02/2022 09:07:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.14 on epoch=127
06/02/2022 09:07:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
06/02/2022 09:07:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=128
06/02/2022 09:07:06 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.8207933085257564 on epoch=128
06/02/2022 09:07:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.19 on epoch=129
06/02/2022 09:07:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
06/02/2022 09:07:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=130
06/02/2022 09:07:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=131
06/02/2022 09:07:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/02/2022 09:07:16 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.8651842765758696 on epoch=132
06/02/2022 09:07:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
06/02/2022 09:07:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/02/2022 09:07:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=134
06/02/2022 09:07:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.15 on epoch=134
06/02/2022 09:07:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.14 on epoch=135
06/02/2022 09:07:26 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.8117016789589184 on epoch=135
06/02/2022 09:07:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=136
06/02/2022 09:07:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=137
06/02/2022 09:07:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.18 on epoch=137
06/02/2022 09:07:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=138
06/02/2022 09:07:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.13 on epoch=139
06/02/2022 09:07:36 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.8891132617809316 on epoch=139
06/02/2022 09:07:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.15 on epoch=139
06/02/2022 09:07:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=140
06/02/2022 09:07:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.11 on epoch=141
06/02/2022 09:07:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=142
06/02/2022 09:07:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=142
06/02/2022 09:07:46 - INFO - __main__ - Global step 2000 Train loss 0.12 Classification-F1 0.7360159963931766 on epoch=142
06/02/2022 09:07:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=143
06/02/2022 09:07:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.17 on epoch=144
06/02/2022 09:07:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=144
06/02/2022 09:07:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=145
06/02/2022 09:07:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
06/02/2022 09:07:56 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.8293763829268455 on epoch=146
06/02/2022 09:07:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/02/2022 09:07:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=147
06/02/2022 09:07:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/02/2022 09:08:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/02/2022 09:08:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/02/2022 09:08:05 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.8253572250014376 on epoch=149
06/02/2022 09:08:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/02/2022 09:08:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
06/02/2022 09:08:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.11 on epoch=152
06/02/2022 09:08:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=152
06/02/2022 09:08:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=153
06/02/2022 09:08:15 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.8186090361888119 on epoch=153
06/02/2022 09:08:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.23 on epoch=154
06/02/2022 09:08:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=154
06/02/2022 09:08:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=155
06/02/2022 09:08:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=156
06/02/2022 09:08:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=157
06/02/2022 09:08:25 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.889184343977251 on epoch=157
06/02/2022 09:08:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/02/2022 09:08:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=158
06/02/2022 09:08:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=159
06/02/2022 09:08:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=159
06/02/2022 09:08:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 09:08:35 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.8097823586912771 on epoch=160
06/02/2022 09:08:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/02/2022 09:08:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=162
06/02/2022 09:08:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=162
06/02/2022 09:08:40 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=163
06/02/2022 09:08:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=164
06/02/2022 09:08:45 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.8708458009501653 on epoch=164
06/02/2022 09:08:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=164
06/02/2022 09:08:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/02/2022 09:08:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=166
06/02/2022 09:08:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/02/2022 09:08:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/02/2022 09:08:55 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.8908711950078173 on epoch=167
06/02/2022 09:08:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.09 on epoch=168
06/02/2022 09:08:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.19 on epoch=169
06/02/2022 09:08:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.13 on epoch=169
06/02/2022 09:09:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=170
06/02/2022 09:09:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.10 on epoch=171
06/02/2022 09:09:04 - INFO - __main__ - Global step 2400 Train loss 0.12 Classification-F1 0.9690379377557475 on epoch=171
06/02/2022 09:09:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8930938416422286 -> 0.9690379377557475 on epoch=171, global_step=2400
06/02/2022 09:09:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/02/2022 09:09:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=172
06/02/2022 09:09:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=173
06/02/2022 09:09:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.13 on epoch=174
06/02/2022 09:09:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.15 on epoch=174
06/02/2022 09:09:14 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.8907625454874032 on epoch=174
06/02/2022 09:09:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=175
06/02/2022 09:09:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=176
06/02/2022 09:09:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=177
06/02/2022 09:09:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=177
06/02/2022 09:09:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=178
06/02/2022 09:09:24 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.9550949998767836 on epoch=178
06/02/2022 09:09:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=179
06/02/2022 09:09:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/02/2022 09:09:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=180
06/02/2022 09:09:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
06/02/2022 09:09:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/02/2022 09:09:34 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.9598306184643945 on epoch=182
06/02/2022 09:09:36 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
06/02/2022 09:09:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=183
06/02/2022 09:09:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/02/2022 09:09:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=184
06/02/2022 09:09:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/02/2022 09:09:44 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.9600272000295721 on epoch=185
06/02/2022 09:09:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=186
06/02/2022 09:09:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=187
06/02/2022 09:09:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=187
06/02/2022 09:09:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/02/2022 09:09:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=189
06/02/2022 09:09:54 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.9601050024115219 on epoch=189
06/02/2022 09:09:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.11 on epoch=189
06/02/2022 09:09:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/02/2022 09:09:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=191
06/02/2022 09:09:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=192
06/02/2022 09:10:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.10 on epoch=192
06/02/2022 09:10:04 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.8933036476126837 on epoch=192
06/02/2022 09:10:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=193
06/02/2022 09:10:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/02/2022 09:10:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.13 on epoch=194
06/02/2022 09:10:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/02/2022 09:10:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/02/2022 09:10:14 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.9642149161717474 on epoch=196
06/02/2022 09:10:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.10 on epoch=197
06/02/2022 09:10:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=197
06/02/2022 09:10:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
06/02/2022 09:10:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
06/02/2022 09:10:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/02/2022 09:10:24 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.9553356826601609 on epoch=199
06/02/2022 09:10:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/02/2022 09:10:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/02/2022 09:10:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/02/2022 09:10:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/02/2022 09:10:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=203
06/02/2022 09:10:33 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.9688292179041706 on epoch=203
06/02/2022 09:10:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/02/2022 09:10:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/02/2022 09:10:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/02/2022 09:10:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/02/2022 09:10:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/02/2022 09:10:43 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.9508824057482231 on epoch=207
06/02/2022 09:10:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/02/2022 09:10:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/02/2022 09:10:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/02/2022 09:10:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/02/2022 09:10:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
06/02/2022 09:10:53 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.9553291331195235 on epoch=210
06/02/2022 09:10:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/02/2022 09:10:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 09:10:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/02/2022 09:10:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/02/2022 09:11:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=214
06/02/2022 09:11:01 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:11:01 - INFO - __main__ - Printing 3 examples
06/02/2022 09:11:01 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 09:11:01 - INFO - __main__ - ['Film']
06/02/2022 09:11:01 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 09:11:01 - INFO - __main__ - ['Film']
06/02/2022 09:11:01 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 09:11:01 - INFO - __main__ - ['Film']
06/02/2022 09:11:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:11:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:11:01 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:11:01 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:11:01 - INFO - __main__ - Printing 3 examples
06/02/2022 09:11:01 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 09:11:01 - INFO - __main__ - ['Film']
06/02/2022 09:11:01 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 09:11:01 - INFO - __main__ - ['Film']
06/02/2022 09:11:01 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 09:11:01 - INFO - __main__ - ['Film']
06/02/2022 09:11:01 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:11:01 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:11:01 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:11:03 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.956107570105266 on epoch=214
06/02/2022 09:11:03 - INFO - __main__ - save last model!
06/02/2022 09:11:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 09:11:03 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 09:11:03 - INFO - __main__ - Printing 3 examples
06/02/2022 09:11:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 09:11:03 - INFO - __main__ - ['Animal']
06/02/2022 09:11:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 09:11:03 - INFO - __main__ - ['Animal']
06/02/2022 09:11:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 09:11:03 - INFO - __main__ - ['Village']
06/02/2022 09:11:03 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:11:05 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:11:07 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 09:11:07 - INFO - __main__ - task name: dbpedia_14
06/02/2022 09:11:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 09:11:08 - INFO - __main__ - Starting training!
06/02/2022 09:11:09 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 09:12:21 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/02/2022 09:12:21 - INFO - __main__ - Classification-F1 on test data: 0.5771
06/02/2022 09:12:21 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9690379377557475, test_performance=0.5771438395677329
06/02/2022 09:12:21 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/02/2022 09:12:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:12:22 - INFO - __main__ - Printing 3 examples
06/02/2022 09:12:22 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 09:12:22 - INFO - __main__ - ['Film']
06/02/2022 09:12:22 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 09:12:22 - INFO - __main__ - ['Film']
06/02/2022 09:12:22 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 09:12:22 - INFO - __main__ - ['Film']
06/02/2022 09:12:22 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:12:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:12:23 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:12:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:12:23 - INFO - __main__ - Printing 3 examples
06/02/2022 09:12:23 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 09:12:23 - INFO - __main__ - ['Film']
06/02/2022 09:12:23 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 09:12:23 - INFO - __main__ - ['Film']
06/02/2022 09:12:23 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 09:12:23 - INFO - __main__ - ['Film']
06/02/2022 09:12:23 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:12:23 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:12:23 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:12:29 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 09:12:29 - INFO - __main__ - task name: dbpedia_14
06/02/2022 09:12:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 09:12:30 - INFO - __main__ - Starting training!
06/02/2022 09:12:31 - INFO - __main__ - Step 10 Global step 10 Train loss 6.76 on epoch=0
06/02/2022 09:12:33 - INFO - __main__ - Step 20 Global step 20 Train loss 5.86 on epoch=1
06/02/2022 09:12:35 - INFO - __main__ - Step 30 Global step 30 Train loss 6.93 on epoch=2
06/02/2022 09:12:36 - INFO - __main__ - Step 40 Global step 40 Train loss 7.32 on epoch=2
06/02/2022 09:12:37 - INFO - __main__ - Step 50 Global step 50 Train loss 5.80 on epoch=3
06/02/2022 09:13:36 - INFO - __main__ - Global step 50 Train loss 6.54 Classification-F1 0.0 on epoch=3
06/02/2022 09:13:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 09:13:38 - INFO - __main__ - Step 60 Global step 60 Train loss 5.50 on epoch=4
06/02/2022 09:13:39 - INFO - __main__ - Step 70 Global step 70 Train loss 5.19 on epoch=4
06/02/2022 09:13:40 - INFO - __main__ - Step 80 Global step 80 Train loss 5.38 on epoch=5
06/02/2022 09:13:42 - INFO - __main__ - Step 90 Global step 90 Train loss 4.90 on epoch=6
06/02/2022 09:13:43 - INFO - __main__ - Step 100 Global step 100 Train loss 4.91 on epoch=7
06/02/2022 09:14:13 - INFO - __main__ - Global step 100 Train loss 5.18 Classification-F1 0.0 on epoch=7
06/02/2022 09:14:14 - INFO - __main__ - Step 110 Global step 110 Train loss 4.62 on epoch=7
06/02/2022 09:14:16 - INFO - __main__ - Step 120 Global step 120 Train loss 4.23 on epoch=8
06/02/2022 09:14:17 - INFO - __main__ - Step 130 Global step 130 Train loss 3.92 on epoch=9
06/02/2022 09:14:19 - INFO - __main__ - Step 140 Global step 140 Train loss 3.78 on epoch=9
06/02/2022 09:14:20 - INFO - __main__ - Step 150 Global step 150 Train loss 3.65 on epoch=10
06/02/2022 09:14:26 - INFO - __main__ - Global step 150 Train loss 4.04 Classification-F1 0.058321207459384565 on epoch=10
06/02/2022 09:14:26 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.058321207459384565 on epoch=10, global_step=150
06/02/2022 09:14:27 - INFO - __main__ - Step 160 Global step 160 Train loss 3.24 on epoch=11
06/02/2022 09:14:29 - INFO - __main__ - Step 170 Global step 170 Train loss 3.39 on epoch=12
06/02/2022 09:14:30 - INFO - __main__ - Step 180 Global step 180 Train loss 3.01 on epoch=12
06/02/2022 09:14:31 - INFO - __main__ - Step 190 Global step 190 Train loss 2.82 on epoch=13
06/02/2022 09:14:32 - INFO - __main__ - Step 200 Global step 200 Train loss 2.74 on epoch=14
06/02/2022 09:14:36 - INFO - __main__ - Global step 200 Train loss 3.04 Classification-F1 0.15428266600573745 on epoch=14
06/02/2022 09:14:36 - INFO - __main__ - Saving model with best Classification-F1: 0.058321207459384565 -> 0.15428266600573745 on epoch=14, global_step=200
06/02/2022 09:14:37 - INFO - __main__ - Step 210 Global step 210 Train loss 2.72 on epoch=14
06/02/2022 09:14:38 - INFO - __main__ - Step 220 Global step 220 Train loss 2.56 on epoch=15
06/02/2022 09:14:40 - INFO - __main__ - Step 230 Global step 230 Train loss 2.33 on epoch=16
06/02/2022 09:14:41 - INFO - __main__ - Step 240 Global step 240 Train loss 2.35 on epoch=17
06/02/2022 09:14:42 - INFO - __main__ - Step 250 Global step 250 Train loss 2.07 on epoch=17
06/02/2022 09:14:45 - INFO - __main__ - Global step 250 Train loss 2.41 Classification-F1 0.17114766710798393 on epoch=17
06/02/2022 09:14:45 - INFO - __main__ - Saving model with best Classification-F1: 0.15428266600573745 -> 0.17114766710798393 on epoch=17, global_step=250
06/02/2022 09:14:47 - INFO - __main__ - Step 260 Global step 260 Train loss 2.13 on epoch=18
06/02/2022 09:14:48 - INFO - __main__ - Step 270 Global step 270 Train loss 1.93 on epoch=19
06/02/2022 09:14:49 - INFO - __main__ - Step 280 Global step 280 Train loss 2.04 on epoch=19
06/02/2022 09:14:51 - INFO - __main__ - Step 290 Global step 290 Train loss 1.81 on epoch=20
06/02/2022 09:14:52 - INFO - __main__ - Step 300 Global step 300 Train loss 1.78 on epoch=21
06/02/2022 09:14:57 - INFO - __main__ - Global step 300 Train loss 1.94 Classification-F1 0.22079984605951314 on epoch=21
06/02/2022 09:14:57 - INFO - __main__ - Saving model with best Classification-F1: 0.17114766710798393 -> 0.22079984605951314 on epoch=21, global_step=300
06/02/2022 09:14:58 - INFO - __main__ - Step 310 Global step 310 Train loss 1.87 on epoch=22
06/02/2022 09:14:59 - INFO - __main__ - Step 320 Global step 320 Train loss 1.62 on epoch=22
06/02/2022 09:15:01 - INFO - __main__ - Step 330 Global step 330 Train loss 1.76 on epoch=23
06/02/2022 09:15:02 - INFO - __main__ - Step 340 Global step 340 Train loss 1.74 on epoch=24
06/02/2022 09:15:03 - INFO - __main__ - Step 350 Global step 350 Train loss 1.65 on epoch=24
06/02/2022 09:15:07 - INFO - __main__ - Global step 350 Train loss 1.73 Classification-F1 0.2517927207277262 on epoch=24
06/02/2022 09:15:07 - INFO - __main__ - Saving model with best Classification-F1: 0.22079984605951314 -> 0.2517927207277262 on epoch=24, global_step=350
06/02/2022 09:15:08 - INFO - __main__ - Step 360 Global step 360 Train loss 1.64 on epoch=25
06/02/2022 09:15:09 - INFO - __main__ - Step 370 Global step 370 Train loss 1.47 on epoch=26
06/02/2022 09:15:11 - INFO - __main__ - Step 380 Global step 380 Train loss 1.43 on epoch=27
06/02/2022 09:15:12 - INFO - __main__ - Step 390 Global step 390 Train loss 1.51 on epoch=27
06/02/2022 09:15:13 - INFO - __main__ - Step 400 Global step 400 Train loss 1.39 on epoch=28
06/02/2022 09:15:17 - INFO - __main__ - Global step 400 Train loss 1.49 Classification-F1 0.29293392958600994 on epoch=28
06/02/2022 09:15:17 - INFO - __main__ - Saving model with best Classification-F1: 0.2517927207277262 -> 0.29293392958600994 on epoch=28, global_step=400
06/02/2022 09:15:19 - INFO - __main__ - Step 410 Global step 410 Train loss 1.37 on epoch=29
06/02/2022 09:15:20 - INFO - __main__ - Step 420 Global step 420 Train loss 1.32 on epoch=29
06/02/2022 09:15:21 - INFO - __main__ - Step 430 Global step 430 Train loss 1.35 on epoch=30
06/02/2022 09:15:23 - INFO - __main__ - Step 440 Global step 440 Train loss 1.31 on epoch=31
06/02/2022 09:15:24 - INFO - __main__ - Step 450 Global step 450 Train loss 1.17 on epoch=32
06/02/2022 09:15:28 - INFO - __main__ - Global step 450 Train loss 1.30 Classification-F1 0.3539398402959831 on epoch=32
06/02/2022 09:15:28 - INFO - __main__ - Saving model with best Classification-F1: 0.29293392958600994 -> 0.3539398402959831 on epoch=32, global_step=450
06/02/2022 09:15:29 - INFO - __main__ - Step 460 Global step 460 Train loss 1.37 on epoch=32
06/02/2022 09:15:30 - INFO - __main__ - Step 470 Global step 470 Train loss 1.27 on epoch=33
06/02/2022 09:15:32 - INFO - __main__ - Step 480 Global step 480 Train loss 1.29 on epoch=34
06/02/2022 09:15:33 - INFO - __main__ - Step 490 Global step 490 Train loss 1.13 on epoch=34
06/02/2022 09:15:34 - INFO - __main__ - Step 500 Global step 500 Train loss 1.17 on epoch=35
06/02/2022 09:15:38 - INFO - __main__ - Global step 500 Train loss 1.25 Classification-F1 0.35732755078943823 on epoch=35
06/02/2022 09:15:38 - INFO - __main__ - Saving model with best Classification-F1: 0.3539398402959831 -> 0.35732755078943823 on epoch=35, global_step=500
06/02/2022 09:15:39 - INFO - __main__ - Step 510 Global step 510 Train loss 1.08 on epoch=36
06/02/2022 09:15:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.98 on epoch=37
06/02/2022 09:15:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.99 on epoch=37
06/02/2022 09:15:43 - INFO - __main__ - Step 540 Global step 540 Train loss 1.06 on epoch=38
06/02/2022 09:15:45 - INFO - __main__ - Step 550 Global step 550 Train loss 1.02 on epoch=39
06/02/2022 09:15:49 - INFO - __main__ - Global step 550 Train loss 1.03 Classification-F1 0.355931303161854 on epoch=39
06/02/2022 09:15:51 - INFO - __main__ - Step 560 Global step 560 Train loss 1.02 on epoch=39
06/02/2022 09:15:52 - INFO - __main__ - Step 570 Global step 570 Train loss 1.11 on epoch=40
06/02/2022 09:15:53 - INFO - __main__ - Step 580 Global step 580 Train loss 1.09 on epoch=41
06/02/2022 09:15:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.95 on epoch=42
06/02/2022 09:15:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.98 on epoch=42
06/02/2022 09:16:00 - INFO - __main__ - Global step 600 Train loss 1.03 Classification-F1 0.35563106938491357 on epoch=42
06/02/2022 09:16:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.95 on epoch=43
06/02/2022 09:16:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.89 on epoch=44
06/02/2022 09:16:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.85 on epoch=44
06/02/2022 09:16:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.90 on epoch=45
06/02/2022 09:16:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.89 on epoch=46
06/02/2022 09:16:10 - INFO - __main__ - Global step 650 Train loss 0.90 Classification-F1 0.3769572097697098 on epoch=46
06/02/2022 09:16:10 - INFO - __main__ - Saving model with best Classification-F1: 0.35732755078943823 -> 0.3769572097697098 on epoch=46, global_step=650
06/02/2022 09:16:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.83 on epoch=47
06/02/2022 09:16:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.79 on epoch=47
06/02/2022 09:16:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.82 on epoch=48
06/02/2022 09:16:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.76 on epoch=49
06/02/2022 09:16:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.70 on epoch=49
06/02/2022 09:16:20 - INFO - __main__ - Global step 700 Train loss 0.78 Classification-F1 0.36827257064478364 on epoch=49
06/02/2022 09:16:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.81 on epoch=50
06/02/2022 09:16:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.73 on epoch=51
06/02/2022 09:16:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.68 on epoch=52
06/02/2022 09:16:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.72 on epoch=52
06/02/2022 09:16:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.75 on epoch=53
06/02/2022 09:16:29 - INFO - __main__ - Global step 750 Train loss 0.74 Classification-F1 0.47668408711171867 on epoch=53
06/02/2022 09:16:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3769572097697098 -> 0.47668408711171867 on epoch=53, global_step=750
06/02/2022 09:16:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.68 on epoch=54
06/02/2022 09:16:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.71 on epoch=54
06/02/2022 09:16:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.71 on epoch=55
06/02/2022 09:16:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.56 on epoch=56
06/02/2022 09:16:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.92 on epoch=57
06/02/2022 09:16:40 - INFO - __main__ - Global step 800 Train loss 0.71 Classification-F1 0.4839969420590206 on epoch=57
06/02/2022 09:16:40 - INFO - __main__ - Saving model with best Classification-F1: 0.47668408711171867 -> 0.4839969420590206 on epoch=57, global_step=800
06/02/2022 09:16:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.64 on epoch=57
06/02/2022 09:16:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.65 on epoch=58
06/02/2022 09:16:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.52 on epoch=59
06/02/2022 09:16:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.55 on epoch=59
06/02/2022 09:16:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.63 on epoch=60
06/02/2022 09:16:50 - INFO - __main__ - Global step 850 Train loss 0.60 Classification-F1 0.48955630345554857 on epoch=60
06/02/2022 09:16:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4839969420590206 -> 0.48955630345554857 on epoch=60, global_step=850
06/02/2022 09:16:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.50 on epoch=61
06/02/2022 09:16:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.53 on epoch=62
06/02/2022 09:16:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.47 on epoch=62
06/02/2022 09:16:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.61 on epoch=63
06/02/2022 09:16:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.75 on epoch=64
06/02/2022 09:17:00 - INFO - __main__ - Global step 900 Train loss 0.57 Classification-F1 0.6362947755737131 on epoch=64
06/02/2022 09:17:00 - INFO - __main__ - Saving model with best Classification-F1: 0.48955630345554857 -> 0.6362947755737131 on epoch=64, global_step=900
06/02/2022 09:17:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.44 on epoch=64
06/02/2022 09:17:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.41 on epoch=65
06/02/2022 09:17:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.59 on epoch=66
06/02/2022 09:17:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.49 on epoch=67
06/02/2022 09:17:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.49 on epoch=67
06/02/2022 09:17:10 - INFO - __main__ - Global step 950 Train loss 0.48 Classification-F1 0.7549197906011806 on epoch=67
06/02/2022 09:17:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6362947755737131 -> 0.7549197906011806 on epoch=67, global_step=950
06/02/2022 09:17:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.50 on epoch=68
06/02/2022 09:17:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.43 on epoch=69
06/02/2022 09:17:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.41 on epoch=69
06/02/2022 09:17:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.45 on epoch=70
06/02/2022 09:17:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.37 on epoch=71
06/02/2022 09:17:19 - INFO - __main__ - Global step 1000 Train loss 0.43 Classification-F1 0.6647893833862974 on epoch=71
06/02/2022 09:17:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.52 on epoch=72
06/02/2022 09:17:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.35 on epoch=72
06/02/2022 09:17:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.38 on epoch=73
06/02/2022 09:17:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.46 on epoch=74
06/02/2022 09:17:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.49 on epoch=74
06/02/2022 09:17:29 - INFO - __main__ - Global step 1050 Train loss 0.44 Classification-F1 0.5299347437580949 on epoch=74
06/02/2022 09:17:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.36 on epoch=75
06/02/2022 09:17:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.34 on epoch=76
06/02/2022 09:17:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.38 on epoch=77
06/02/2022 09:17:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=77
06/02/2022 09:17:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.33 on epoch=78
06/02/2022 09:17:39 - INFO - __main__ - Global step 1100 Train loss 0.34 Classification-F1 0.6236550730536327 on epoch=78
06/02/2022 09:17:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.34 on epoch=79
06/02/2022 09:17:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.34 on epoch=79
06/02/2022 09:17:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.36 on epoch=80
06/02/2022 09:17:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.33 on epoch=81
06/02/2022 09:17:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.40 on epoch=82
06/02/2022 09:17:49 - INFO - __main__ - Global step 1150 Train loss 0.36 Classification-F1 0.43558066884468843 on epoch=82
06/02/2022 09:17:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.26 on epoch=82
06/02/2022 09:17:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.34 on epoch=83
06/02/2022 09:17:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.34 on epoch=84
06/02/2022 09:17:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.28 on epoch=84
06/02/2022 09:17:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.28 on epoch=85
06/02/2022 09:17:58 - INFO - __main__ - Global step 1200 Train loss 0.30 Classification-F1 0.5089834575027564 on epoch=85
06/02/2022 09:18:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.45 on epoch=86
06/02/2022 09:18:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.35 on epoch=87
06/02/2022 09:18:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=87
06/02/2022 09:18:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.29 on epoch=88
06/02/2022 09:18:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.27 on epoch=89
06/02/2022 09:18:08 - INFO - __main__ - Global step 1250 Train loss 0.31 Classification-F1 0.6579781992338601 on epoch=89
06/02/2022 09:18:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.25 on epoch=89
06/02/2022 09:18:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.25 on epoch=90
06/02/2022 09:18:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.22 on epoch=91
06/02/2022 09:18:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.23 on epoch=92
06/02/2022 09:18:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.33 on epoch=92
06/02/2022 09:18:18 - INFO - __main__ - Global step 1300 Train loss 0.26 Classification-F1 0.715637917980303 on epoch=92
06/02/2022 09:18:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=93
06/02/2022 09:18:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.26 on epoch=94
06/02/2022 09:18:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=94
06/02/2022 09:18:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=95
06/02/2022 09:18:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=96
06/02/2022 09:18:28 - INFO - __main__ - Global step 1350 Train loss 0.22 Classification-F1 0.5689454069280919 on epoch=96
06/02/2022 09:18:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
06/02/2022 09:18:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.21 on epoch=97
06/02/2022 09:18:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.20 on epoch=98
06/02/2022 09:18:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=99
06/02/2022 09:18:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=99
06/02/2022 09:18:38 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.7269720750645549 on epoch=99
06/02/2022 09:18:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
06/02/2022 09:18:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=101
06/02/2022 09:18:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.21 on epoch=102
06/02/2022 09:18:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=102
06/02/2022 09:18:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=103
06/02/2022 09:18:48 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.6135041859764395 on epoch=103
06/02/2022 09:18:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.23 on epoch=104
06/02/2022 09:18:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=104
06/02/2022 09:18:51 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
06/02/2022 09:18:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.24 on epoch=106
06/02/2022 09:18:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.19 on epoch=107
06/02/2022 09:18:57 - INFO - __main__ - Global step 1500 Train loss 0.19 Classification-F1 0.6956128077270591 on epoch=107
06/02/2022 09:18:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=107
06/02/2022 09:19:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=108
06/02/2022 09:19:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=109
06/02/2022 09:19:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.16 on epoch=109
06/02/2022 09:19:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=110
06/02/2022 09:19:07 - INFO - __main__ - Global step 1550 Train loss 0.15 Classification-F1 0.6712570840917035 on epoch=110
06/02/2022 09:19:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=111
06/02/2022 09:19:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
06/02/2022 09:19:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/02/2022 09:19:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.15 on epoch=113
06/02/2022 09:19:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=114
06/02/2022 09:19:17 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.7455545198207297 on epoch=114
06/02/2022 09:19:19 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=114
06/02/2022 09:19:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=115
06/02/2022 09:19:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=116
06/02/2022 09:19:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=117
06/02/2022 09:19:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/02/2022 09:19:27 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.7643043264535326 on epoch=117
06/02/2022 09:19:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7549197906011806 -> 0.7643043264535326 on epoch=117, global_step=1650
06/02/2022 09:19:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.16 on epoch=118
06/02/2022 09:19:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=119
06/02/2022 09:19:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=119
06/02/2022 09:19:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=120
06/02/2022 09:19:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=121
06/02/2022 09:19:37 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.8010988462690825 on epoch=121
06/02/2022 09:19:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7643043264535326 -> 0.8010988462690825 on epoch=121, global_step=1700
06/02/2022 09:19:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=122
06/02/2022 09:19:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/02/2022 09:19:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=123
06/02/2022 09:19:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/02/2022 09:19:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=124
06/02/2022 09:19:47 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.8801983590718236 on epoch=124
06/02/2022 09:19:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8010988462690825 -> 0.8801983590718236 on epoch=124, global_step=1750
06/02/2022 09:19:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=125
06/02/2022 09:19:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
06/02/2022 09:19:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/02/2022 09:19:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=127
06/02/2022 09:19:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=128
06/02/2022 09:19:57 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.6453280877300251 on epoch=128
06/02/2022 09:19:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/02/2022 09:19:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/02/2022 09:20:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/02/2022 09:20:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/02/2022 09:20:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/02/2022 09:20:07 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6970388705788242 on epoch=132
06/02/2022 09:20:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
06/02/2022 09:20:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/02/2022 09:20:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/02/2022 09:20:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=134
06/02/2022 09:20:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
06/02/2022 09:20:16 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.6789080055736635 on epoch=135
06/02/2022 09:20:18 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/02/2022 09:20:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=137
06/02/2022 09:20:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=137
06/02/2022 09:20:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/02/2022 09:20:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/02/2022 09:20:26 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.8935480037567325 on epoch=139
06/02/2022 09:20:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8801983590718236 -> 0.8935480037567325 on epoch=139, global_step=1950
06/02/2022 09:20:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/02/2022 09:20:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=140
06/02/2022 09:20:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=141
06/02/2022 09:20:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=142
06/02/2022 09:20:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/02/2022 09:20:36 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7727738231742585 on epoch=142
06/02/2022 09:20:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/02/2022 09:20:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
06/02/2022 09:20:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=144
06/02/2022 09:20:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.12 on epoch=145
06/02/2022 09:20:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/02/2022 09:20:46 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.792277864613957 on epoch=146
06/02/2022 09:20:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=147
06/02/2022 09:20:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/02/2022 09:20:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/02/2022 09:20:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
06/02/2022 09:20:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=149
06/02/2022 09:20:56 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7632017237776809 on epoch=149
06/02/2022 09:20:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/02/2022 09:20:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
06/02/2022 09:21:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=152
06/02/2022 09:21:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/02/2022 09:21:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=153
06/02/2022 09:21:06 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8287523434138546 on epoch=153
06/02/2022 09:21:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=154
06/02/2022 09:21:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/02/2022 09:21:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/02/2022 09:21:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/02/2022 09:21:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/02/2022 09:21:15 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8967158163363097 on epoch=157
06/02/2022 09:21:16 - INFO - __main__ - Saving model with best Classification-F1: 0.8935480037567325 -> 0.8967158163363097 on epoch=157, global_step=2200
06/02/2022 09:21:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/02/2022 09:21:18 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/02/2022 09:21:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=159
06/02/2022 09:21:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=159
06/02/2022 09:21:22 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=160
06/02/2022 09:21:26 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.96408399870212 on epoch=160
06/02/2022 09:21:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8967158163363097 -> 0.96408399870212 on epoch=160, global_step=2250
06/02/2022 09:21:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/02/2022 09:21:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/02/2022 09:21:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=162
06/02/2022 09:21:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/02/2022 09:21:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/02/2022 09:21:35 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.9634916723287557 on epoch=164
06/02/2022 09:21:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/02/2022 09:21:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/02/2022 09:21:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/02/2022 09:21:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
06/02/2022 09:21:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=167
06/02/2022 09:21:45 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7810385593104089 on epoch=167
06/02/2022 09:21:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/02/2022 09:21:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=169
06/02/2022 09:21:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/02/2022 09:21:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=170
06/02/2022 09:21:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/02/2022 09:21:55 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8898170669375602 on epoch=171
06/02/2022 09:21:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/02/2022 09:21:58 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/02/2022 09:21:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/02/2022 09:22:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/02/2022 09:22:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/02/2022 09:22:05 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8954276842701889 on epoch=174
06/02/2022 09:22:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/02/2022 09:22:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/02/2022 09:22:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/02/2022 09:22:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/02/2022 09:22:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=178
06/02/2022 09:22:15 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8977964176873097 on epoch=178
06/02/2022 09:22:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/02/2022 09:22:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/02/2022 09:22:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/02/2022 09:22:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
06/02/2022 09:22:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/02/2022 09:22:25 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9501207374445381 on epoch=182
06/02/2022 09:22:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
06/02/2022 09:22:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/02/2022 09:22:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/02/2022 09:22:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=184
06/02/2022 09:22:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=185
06/02/2022 09:22:35 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9596770086333655 on epoch=185
06/02/2022 09:22:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/02/2022 09:22:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.10 on epoch=187
06/02/2022 09:22:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/02/2022 09:22:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/02/2022 09:22:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/02/2022 09:22:45 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.954528086894582 on epoch=189
06/02/2022 09:22:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=189
06/02/2022 09:22:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/02/2022 09:22:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/02/2022 09:22:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/02/2022 09:22:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=192
06/02/2022 09:22:55 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9594064706477189 on epoch=192
06/02/2022 09:22:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/02/2022 09:22:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=194
06/02/2022 09:22:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=194
06/02/2022 09:23:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/02/2022 09:23:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/02/2022 09:23:04 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.8512638092260365 on epoch=196
06/02/2022 09:23:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/02/2022 09:23:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/02/2022 09:23:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/02/2022 09:23:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
06/02/2022 09:23:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=199
06/02/2022 09:23:14 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9730082062150373 on epoch=199
06/02/2022 09:23:14 - INFO - __main__ - Saving model with best Classification-F1: 0.96408399870212 -> 0.9730082062150373 on epoch=199, global_step=2800
06/02/2022 09:23:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/02/2022 09:23:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/02/2022 09:23:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/02/2022 09:23:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/02/2022 09:23:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/02/2022 09:23:24 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9685132704108036 on epoch=203
06/02/2022 09:23:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/02/2022 09:23:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
06/02/2022 09:23:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/02/2022 09:23:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/02/2022 09:23:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/02/2022 09:23:34 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9774768558449773 on epoch=207
06/02/2022 09:23:34 - INFO - __main__ - Saving model with best Classification-F1: 0.9730082062150373 -> 0.9774768558449773 on epoch=207, global_step=2900
06/02/2022 09:23:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/02/2022 09:23:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/02/2022 09:23:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/02/2022 09:23:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/02/2022 09:23:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/02/2022 09:23:44 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9732519400722166 on epoch=210
06/02/2022 09:23:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/02/2022 09:23:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/02/2022 09:23:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/02/2022 09:23:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=213
06/02/2022 09:23:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/02/2022 09:23:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:23:51 - INFO - __main__ - Printing 3 examples
06/02/2022 09:23:51 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 09:23:51 - INFO - __main__ - ['Film']
06/02/2022 09:23:51 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 09:23:51 - INFO - __main__ - ['Film']
06/02/2022 09:23:51 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 09:23:51 - INFO - __main__ - ['Film']
06/02/2022 09:23:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:23:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:23:51 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:23:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:23:51 - INFO - __main__ - Printing 3 examples
06/02/2022 09:23:51 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 09:23:51 - INFO - __main__ - ['Film']
06/02/2022 09:23:51 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 09:23:51 - INFO - __main__ - ['Film']
06/02/2022 09:23:51 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 09:23:51 - INFO - __main__ - ['Film']
06/02/2022 09:23:51 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:23:51 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:23:52 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:23:54 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9020594190755482 on epoch=214
06/02/2022 09:23:54 - INFO - __main__ - save last model!
06/02/2022 09:23:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 09:23:54 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 09:23:54 - INFO - __main__ - Printing 3 examples
06/02/2022 09:23:54 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 09:23:54 - INFO - __main__ - ['Animal']
06/02/2022 09:23:54 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 09:23:54 - INFO - __main__ - ['Animal']
06/02/2022 09:23:54 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 09:23:54 - INFO - __main__ - ['Village']
06/02/2022 09:23:54 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:23:56 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:23:57 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 09:23:57 - INFO - __main__ - task name: dbpedia_14
06/02/2022 09:23:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 09:23:57 - INFO - __main__ - Starting training!
06/02/2022 09:23:59 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 09:25:10 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/02/2022 09:25:10 - INFO - __main__ - Classification-F1 on test data: 0.5846
06/02/2022 09:25:10 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9774768558449773, test_performance=0.5845524425848574
06/02/2022 09:25:10 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/02/2022 09:25:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:25:11 - INFO - __main__ - Printing 3 examples
06/02/2022 09:25:11 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 09:25:11 - INFO - __main__ - ['Film']
06/02/2022 09:25:11 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 09:25:11 - INFO - __main__ - ['Film']
06/02/2022 09:25:11 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 09:25:11 - INFO - __main__ - ['Film']
06/02/2022 09:25:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:25:11 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:25:11 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:25:11 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:25:11 - INFO - __main__ - Printing 3 examples
06/02/2022 09:25:11 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 09:25:11 - INFO - __main__ - ['Film']
06/02/2022 09:25:11 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 09:25:11 - INFO - __main__ - ['Film']
06/02/2022 09:25:11 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 09:25:11 - INFO - __main__ - ['Film']
06/02/2022 09:25:11 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:25:12 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:25:12 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:25:17 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 09:25:17 - INFO - __main__ - task name: dbpedia_14
06/02/2022 09:25:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 09:25:17 - INFO - __main__ - Starting training!
06/02/2022 09:25:19 - INFO - __main__ - Step 10 Global step 10 Train loss 6.88 on epoch=0
06/02/2022 09:25:20 - INFO - __main__ - Step 20 Global step 20 Train loss 5.56 on epoch=1
06/02/2022 09:25:22 - INFO - __main__ - Step 30 Global step 30 Train loss 5.09 on epoch=2
06/02/2022 09:25:23 - INFO - __main__ - Step 40 Global step 40 Train loss 4.73 on epoch=2
06/02/2022 09:25:24 - INFO - __main__ - Step 50 Global step 50 Train loss 4.37 on epoch=3
06/02/2022 09:25:37 - INFO - __main__ - Global step 50 Train loss 5.33 Classification-F1 0.010444581873153301 on epoch=3
06/02/2022 09:25:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.010444581873153301 on epoch=3, global_step=50
06/02/2022 09:25:38 - INFO - __main__ - Step 60 Global step 60 Train loss 3.76 on epoch=4
06/02/2022 09:25:39 - INFO - __main__ - Step 70 Global step 70 Train loss 3.55 on epoch=4
06/02/2022 09:25:41 - INFO - __main__ - Step 80 Global step 80 Train loss 3.20 on epoch=5
06/02/2022 09:25:42 - INFO - __main__ - Step 90 Global step 90 Train loss 2.75 on epoch=6
06/02/2022 09:25:43 - INFO - __main__ - Step 100 Global step 100 Train loss 2.68 on epoch=7
06/02/2022 09:25:47 - INFO - __main__ - Global step 100 Train loss 3.19 Classification-F1 0.17969835918958796 on epoch=7
06/02/2022 09:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.010444581873153301 -> 0.17969835918958796 on epoch=7, global_step=100
06/02/2022 09:25:48 - INFO - __main__ - Step 110 Global step 110 Train loss 2.41 on epoch=7
06/02/2022 09:25:49 - INFO - __main__ - Step 120 Global step 120 Train loss 2.23 on epoch=8
06/02/2022 09:25:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.96 on epoch=9
06/02/2022 09:25:52 - INFO - __main__ - Step 140 Global step 140 Train loss 2.09 on epoch=9
06/02/2022 09:25:53 - INFO - __main__ - Step 150 Global step 150 Train loss 1.86 on epoch=10
06/02/2022 09:25:57 - INFO - __main__ - Global step 150 Train loss 2.11 Classification-F1 0.2695740433221901 on epoch=10
06/02/2022 09:25:57 - INFO - __main__ - Saving model with best Classification-F1: 0.17969835918958796 -> 0.2695740433221901 on epoch=10, global_step=150
06/02/2022 09:25:58 - INFO - __main__ - Step 160 Global step 160 Train loss 1.75 on epoch=11
06/02/2022 09:25:59 - INFO - __main__ - Step 170 Global step 170 Train loss 1.54 on epoch=12
06/02/2022 09:26:01 - INFO - __main__ - Step 180 Global step 180 Train loss 1.27 on epoch=12
06/02/2022 09:26:02 - INFO - __main__ - Step 190 Global step 190 Train loss 1.19 on epoch=13
06/02/2022 09:26:03 - INFO - __main__ - Step 200 Global step 200 Train loss 1.37 on epoch=14
06/02/2022 09:26:06 - INFO - __main__ - Global step 200 Train loss 1.43 Classification-F1 0.3067607522036277 on epoch=14
06/02/2022 09:26:06 - INFO - __main__ - Saving model with best Classification-F1: 0.2695740433221901 -> 0.3067607522036277 on epoch=14, global_step=200
06/02/2022 09:26:07 - INFO - __main__ - Step 210 Global step 210 Train loss 1.15 on epoch=14
06/02/2022 09:26:09 - INFO - __main__ - Step 220 Global step 220 Train loss 1.07 on epoch=15
06/02/2022 09:26:10 - INFO - __main__ - Step 230 Global step 230 Train loss 1.04 on epoch=16
06/02/2022 09:26:11 - INFO - __main__ - Step 240 Global step 240 Train loss 1.08 on epoch=17
06/02/2022 09:26:13 - INFO - __main__ - Step 250 Global step 250 Train loss 1.08 on epoch=17
06/02/2022 09:26:16 - INFO - __main__ - Global step 250 Train loss 1.09 Classification-F1 0.3717006970440008 on epoch=17
06/02/2022 09:26:16 - INFO - __main__ - Saving model with best Classification-F1: 0.3067607522036277 -> 0.3717006970440008 on epoch=17, global_step=250
06/02/2022 09:26:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.89 on epoch=18
06/02/2022 09:26:18 - INFO - __main__ - Step 270 Global step 270 Train loss 1.06 on epoch=19
06/02/2022 09:26:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.86 on epoch=19
06/02/2022 09:26:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.77 on epoch=20
06/02/2022 09:26:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.87 on epoch=21
06/02/2022 09:26:25 - INFO - __main__ - Global step 300 Train loss 0.89 Classification-F1 0.5068564645770528 on epoch=21
06/02/2022 09:26:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3717006970440008 -> 0.5068564645770528 on epoch=21, global_step=300
06/02/2022 09:26:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.74 on epoch=22
06/02/2022 09:26:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.82 on epoch=22
06/02/2022 09:26:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.82 on epoch=23
06/02/2022 09:26:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.87 on epoch=24
06/02/2022 09:26:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.78 on epoch=24
06/02/2022 09:26:35 - INFO - __main__ - Global step 350 Train loss 0.81 Classification-F1 0.6025854183980861 on epoch=24
06/02/2022 09:26:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5068564645770528 -> 0.6025854183980861 on epoch=24, global_step=350
06/02/2022 09:26:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.69 on epoch=25
06/02/2022 09:26:38 - INFO - __main__ - Step 370 Global step 370 Train loss 0.76 on epoch=26
06/02/2022 09:26:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.69 on epoch=27
06/02/2022 09:26:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.71 on epoch=27
06/02/2022 09:26:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.77 on epoch=28
06/02/2022 09:26:45 - INFO - __main__ - Global step 400 Train loss 0.73 Classification-F1 0.6821156079868165 on epoch=28
06/02/2022 09:26:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6025854183980861 -> 0.6821156079868165 on epoch=28, global_step=400
06/02/2022 09:26:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.60 on epoch=29
06/02/2022 09:26:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.71 on epoch=29
06/02/2022 09:26:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.71 on epoch=30
06/02/2022 09:26:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.60 on epoch=31
06/02/2022 09:26:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.71 on epoch=32
06/02/2022 09:26:55 - INFO - __main__ - Global step 450 Train loss 0.67 Classification-F1 0.5873918642963972 on epoch=32
06/02/2022 09:26:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.59 on epoch=32
06/02/2022 09:26:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.72 on epoch=33
06/02/2022 09:26:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.66 on epoch=34
06/02/2022 09:27:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.64 on epoch=34
06/02/2022 09:27:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.55 on epoch=35
06/02/2022 09:27:05 - INFO - __main__ - Global step 500 Train loss 0.63 Classification-F1 0.6664510032372974 on epoch=35
06/02/2022 09:27:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.62 on epoch=36
06/02/2022 09:27:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=37
06/02/2022 09:27:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.53 on epoch=37
06/02/2022 09:27:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.53 on epoch=38
06/02/2022 09:27:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.53 on epoch=39
06/02/2022 09:27:16 - INFO - __main__ - Global step 550 Train loss 0.54 Classification-F1 0.6226812712388432 on epoch=39
06/02/2022 09:27:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=39
06/02/2022 09:27:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.64 on epoch=40
06/02/2022 09:27:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.53 on epoch=41
06/02/2022 09:27:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.51 on epoch=42
06/02/2022 09:27:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.51 on epoch=42
06/02/2022 09:27:26 - INFO - __main__ - Global step 600 Train loss 0.53 Classification-F1 0.6362613150357773 on epoch=42
06/02/2022 09:27:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.50 on epoch=43
06/02/2022 09:27:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.59 on epoch=44
06/02/2022 09:27:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.50 on epoch=44
06/02/2022 09:27:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.55 on epoch=45
06/02/2022 09:27:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.50 on epoch=46
06/02/2022 09:27:36 - INFO - __main__ - Global step 650 Train loss 0.53 Classification-F1 0.7696893588658295 on epoch=46
06/02/2022 09:27:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6821156079868165 -> 0.7696893588658295 on epoch=46, global_step=650
06/02/2022 09:27:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=47
06/02/2022 09:27:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.48 on epoch=47
06/02/2022 09:27:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.52 on epoch=48
06/02/2022 09:27:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.56 on epoch=49
06/02/2022 09:27:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.45 on epoch=49
06/02/2022 09:27:46 - INFO - __main__ - Global step 700 Train loss 0.49 Classification-F1 0.82169024722966 on epoch=49
06/02/2022 09:27:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7696893588658295 -> 0.82169024722966 on epoch=49, global_step=700
06/02/2022 09:27:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.41 on epoch=50
06/02/2022 09:27:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.41 on epoch=51
06/02/2022 09:27:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.45 on epoch=52
06/02/2022 09:27:51 - INFO - __main__ - Step 740 Global step 740 Train loss 0.41 on epoch=52
06/02/2022 09:27:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.46 on epoch=53
06/02/2022 09:27:56 - INFO - __main__ - Global step 750 Train loss 0.43 Classification-F1 0.748427383389171 on epoch=53
06/02/2022 09:27:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.40 on epoch=54
06/02/2022 09:27:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.41 on epoch=54
06/02/2022 09:28:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=55
06/02/2022 09:28:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.36 on epoch=56
06/02/2022 09:28:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.45 on epoch=57
06/02/2022 09:28:05 - INFO - __main__ - Global step 800 Train loss 0.41 Classification-F1 0.7885672491163224 on epoch=57
06/02/2022 09:28:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=57
06/02/2022 09:28:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.47 on epoch=58
06/02/2022 09:28:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.44 on epoch=59
06/02/2022 09:28:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.43 on epoch=59
06/02/2022 09:28:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.37 on epoch=60
06/02/2022 09:28:15 - INFO - __main__ - Global step 850 Train loss 0.42 Classification-F1 0.8325503665839801 on epoch=60
06/02/2022 09:28:15 - INFO - __main__ - Saving model with best Classification-F1: 0.82169024722966 -> 0.8325503665839801 on epoch=60, global_step=850
06/02/2022 09:28:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.39 on epoch=61
06/02/2022 09:28:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.37 on epoch=62
06/02/2022 09:28:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=62
06/02/2022 09:28:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=63
06/02/2022 09:28:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.39 on epoch=64
06/02/2022 09:28:25 - INFO - __main__ - Global step 900 Train loss 0.35 Classification-F1 0.7597307741738 on epoch=64
06/02/2022 09:28:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.40 on epoch=64
06/02/2022 09:28:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.39 on epoch=65
06/02/2022 09:28:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.41 on epoch=66
06/02/2022 09:28:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.36 on epoch=67
06/02/2022 09:28:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=67
06/02/2022 09:28:34 - INFO - __main__ - Global step 950 Train loss 0.37 Classification-F1 0.8358059311479275 on epoch=67
06/02/2022 09:28:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8325503665839801 -> 0.8358059311479275 on epoch=67, global_step=950
06/02/2022 09:28:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.39 on epoch=68
06/02/2022 09:28:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.39 on epoch=69
06/02/2022 09:28:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.32 on epoch=69
06/02/2022 09:28:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.33 on epoch=70
06/02/2022 09:28:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.38 on epoch=71
06/02/2022 09:28:44 - INFO - __main__ - Global step 1000 Train loss 0.36 Classification-F1 0.8468267173387709 on epoch=71
06/02/2022 09:28:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8358059311479275 -> 0.8468267173387709 on epoch=71, global_step=1000
06/02/2022 09:28:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.38 on epoch=72
06/02/2022 09:28:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=72
06/02/2022 09:28:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.34 on epoch=73
06/02/2022 09:28:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.31 on epoch=74
06/02/2022 09:28:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.28 on epoch=74
06/02/2022 09:28:54 - INFO - __main__ - Global step 1050 Train loss 0.31 Classification-F1 0.7068039158521532 on epoch=74
06/02/2022 09:28:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.29 on epoch=75
06/02/2022 09:28:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.38 on epoch=76
06/02/2022 09:28:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.26 on epoch=77
06/02/2022 09:28:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.31 on epoch=77
06/02/2022 09:29:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=78
06/02/2022 09:29:03 - INFO - __main__ - Global step 1100 Train loss 0.31 Classification-F1 0.7161454888835588 on epoch=78
06/02/2022 09:29:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.33 on epoch=79
06/02/2022 09:29:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.38 on epoch=79
06/02/2022 09:29:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.31 on epoch=80
06/02/2022 09:29:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.34 on epoch=81
06/02/2022 09:29:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=82
06/02/2022 09:29:13 - INFO - __main__ - Global step 1150 Train loss 0.32 Classification-F1 0.6192784103593774 on epoch=82
06/02/2022 09:29:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.22 on epoch=82
06/02/2022 09:29:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.28 on epoch=83
06/02/2022 09:29:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.26 on epoch=84
06/02/2022 09:29:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.25 on epoch=84
06/02/2022 09:29:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.22 on epoch=85
06/02/2022 09:29:22 - INFO - __main__ - Global step 1200 Train loss 0.25 Classification-F1 0.7137156140067356 on epoch=85
06/02/2022 09:29:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.29 on epoch=86
06/02/2022 09:29:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=87
06/02/2022 09:29:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=87
06/02/2022 09:29:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=88
06/02/2022 09:29:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.28 on epoch=89
06/02/2022 09:29:32 - INFO - __main__ - Global step 1250 Train loss 0.25 Classification-F1 0.7785364320528398 on epoch=89
06/02/2022 09:29:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.31 on epoch=89
06/02/2022 09:29:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.30 on epoch=90
06/02/2022 09:29:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.25 on epoch=91
06/02/2022 09:29:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.29 on epoch=92
06/02/2022 09:29:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.23 on epoch=92
06/02/2022 09:29:41 - INFO - __main__ - Global step 1300 Train loss 0.28 Classification-F1 0.7020388241200729 on epoch=92
06/02/2022 09:29:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=93
06/02/2022 09:29:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=94
06/02/2022 09:29:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.26 on epoch=94
06/02/2022 09:29:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=95
06/02/2022 09:29:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.28 on epoch=96
06/02/2022 09:29:51 - INFO - __main__ - Global step 1350 Train loss 0.24 Classification-F1 0.8355681695830881 on epoch=96
06/02/2022 09:29:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=97
06/02/2022 09:29:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.21 on epoch=97
06/02/2022 09:29:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=98
06/02/2022 09:29:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.32 on epoch=99
06/02/2022 09:29:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=99
06/02/2022 09:30:01 - INFO - __main__ - Global step 1400 Train loss 0.23 Classification-F1 0.7496455723255415 on epoch=99
06/02/2022 09:30:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=100
06/02/2022 09:30:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.22 on epoch=101
06/02/2022 09:30:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.28 on epoch=102
06/02/2022 09:30:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.20 on epoch=102
06/02/2022 09:30:07 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.23 on epoch=103
06/02/2022 09:30:10 - INFO - __main__ - Global step 1450 Train loss 0.22 Classification-F1 0.8680274968956176 on epoch=103
06/02/2022 09:30:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8468267173387709 -> 0.8680274968956176 on epoch=103, global_step=1450
06/02/2022 09:30:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.31 on epoch=104
06/02/2022 09:30:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=104
06/02/2022 09:30:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.20 on epoch=105
06/02/2022 09:30:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.21 on epoch=106
06/02/2022 09:30:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.22 on epoch=107
06/02/2022 09:30:20 - INFO - __main__ - Global step 1500 Train loss 0.23 Classification-F1 0.7440027244444801 on epoch=107
06/02/2022 09:30:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.21 on epoch=107
06/02/2022 09:30:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.24 on epoch=108
06/02/2022 09:30:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.18 on epoch=109
06/02/2022 09:30:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.19 on epoch=109
06/02/2022 09:30:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.26 on epoch=110
06/02/2022 09:30:30 - INFO - __main__ - Global step 1550 Train loss 0.21 Classification-F1 0.816912718807144 on epoch=110
06/02/2022 09:30:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.21 on epoch=111
06/02/2022 09:30:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.17 on epoch=112
06/02/2022 09:30:33 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.13 on epoch=112
06/02/2022 09:30:35 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.25 on epoch=113
06/02/2022 09:30:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=114
06/02/2022 09:30:39 - INFO - __main__ - Global step 1600 Train loss 0.19 Classification-F1 0.880040121684272 on epoch=114
06/02/2022 09:30:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8680274968956176 -> 0.880040121684272 on epoch=114, global_step=1600
06/02/2022 09:30:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.27 on epoch=114
06/02/2022 09:30:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.22 on epoch=115
06/02/2022 09:30:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.16 on epoch=116
06/02/2022 09:30:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.20 on epoch=117
06/02/2022 09:30:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.13 on epoch=117
06/02/2022 09:30:49 - INFO - __main__ - Global step 1650 Train loss 0.20 Classification-F1 0.6533591515325454 on epoch=117
06/02/2022 09:30:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.20 on epoch=118
06/02/2022 09:30:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=119
06/02/2022 09:30:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.15 on epoch=119
06/02/2022 09:30:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=120
06/02/2022 09:30:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.20 on epoch=121
06/02/2022 09:30:59 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.6742448341086362 on epoch=121
06/02/2022 09:31:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.17 on epoch=122
06/02/2022 09:31:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.19 on epoch=122
06/02/2022 09:31:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=123
06/02/2022 09:31:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.17 on epoch=124
06/02/2022 09:31:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.30 on epoch=124
06/02/2022 09:31:08 - INFO - __main__ - Global step 1750 Train loss 0.20 Classification-F1 0.7492276670736152 on epoch=124
06/02/2022 09:31:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.21 on epoch=125
06/02/2022 09:31:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.21 on epoch=126
06/02/2022 09:31:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.34 on epoch=127
06/02/2022 09:31:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.25 on epoch=127
06/02/2022 09:31:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=128
06/02/2022 09:31:19 - INFO - __main__ - Global step 1800 Train loss 0.23 Classification-F1 0.8504804746170971 on epoch=128
06/02/2022 09:31:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=129
06/02/2022 09:31:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=129
06/02/2022 09:31:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=130
06/02/2022 09:31:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.20 on epoch=131
06/02/2022 09:31:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.16 on epoch=132
06/02/2022 09:31:29 - INFO - __main__ - Global step 1850 Train loss 0.15 Classification-F1 0.7517648617674338 on epoch=132
06/02/2022 09:31:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.16 on epoch=132
06/02/2022 09:31:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.15 on epoch=133
06/02/2022 09:31:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.16 on epoch=134
06/02/2022 09:31:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=134
06/02/2022 09:31:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=135
06/02/2022 09:31:38 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.7264811452639335 on epoch=135
06/02/2022 09:31:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=136
06/02/2022 09:31:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.18 on epoch=137
06/02/2022 09:31:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=137
06/02/2022 09:31:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.21 on epoch=138
06/02/2022 09:31:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.14 on epoch=139
06/02/2022 09:31:48 - INFO - __main__ - Global step 1950 Train loss 0.16 Classification-F1 0.5806647270345088 on epoch=139
06/02/2022 09:31:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=139
06/02/2022 09:31:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.16 on epoch=140
06/02/2022 09:31:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.11 on epoch=141
06/02/2022 09:31:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.13 on epoch=142
06/02/2022 09:31:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=142
06/02/2022 09:31:58 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.6164136119257086 on epoch=142
06/02/2022 09:31:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.17 on epoch=143
06/02/2022 09:32:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.14 on epoch=144
06/02/2022 09:32:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.19 on epoch=144
06/02/2022 09:32:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=145
06/02/2022 09:32:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=146
06/02/2022 09:32:08 - INFO - __main__ - Global step 2050 Train loss 0.15 Classification-F1 0.651306749065288 on epoch=146
06/02/2022 09:32:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=147
06/02/2022 09:32:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=147
06/02/2022 09:32:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.14 on epoch=148
06/02/2022 09:32:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.13 on epoch=149
06/02/2022 09:32:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=149
06/02/2022 09:32:18 - INFO - __main__ - Global step 2100 Train loss 0.13 Classification-F1 0.6697786941001198 on epoch=149
06/02/2022 09:32:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=150
06/02/2022 09:32:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=151
06/02/2022 09:32:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.12 on epoch=152
06/02/2022 09:32:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.16 on epoch=152
06/02/2022 09:32:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.12 on epoch=153
06/02/2022 09:32:28 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.7481814461164835 on epoch=153
06/02/2022 09:32:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.09 on epoch=154
06/02/2022 09:32:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=154
06/02/2022 09:32:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.16 on epoch=155
06/02/2022 09:32:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=156
06/02/2022 09:32:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.15 on epoch=157
06/02/2022 09:32:38 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.6777039128715283 on epoch=157
06/02/2022 09:32:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.15 on epoch=157
06/02/2022 09:32:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.28 on epoch=158
06/02/2022 09:32:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=159
06/02/2022 09:32:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.13 on epoch=159
06/02/2022 09:32:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.10 on epoch=160
06/02/2022 09:32:48 - INFO - __main__ - Global step 2250 Train loss 0.15 Classification-F1 0.7696928141620629 on epoch=160
06/02/2022 09:32:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=161
06/02/2022 09:32:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=162
06/02/2022 09:32:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=162
06/02/2022 09:32:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=163
06/02/2022 09:32:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=164
06/02/2022 09:32:58 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.6592999435896858 on epoch=164
06/02/2022 09:32:59 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=164
06/02/2022 09:33:00 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.10 on epoch=165
06/02/2022 09:33:02 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=166
06/02/2022 09:33:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.19 on epoch=167
06/02/2022 09:33:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.12 on epoch=167
06/02/2022 09:33:08 - INFO - __main__ - Global step 2350 Train loss 0.12 Classification-F1 0.8118430510033926 on epoch=167
06/02/2022 09:33:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=168
06/02/2022 09:33:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.12 on epoch=169
06/02/2022 09:33:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=169
06/02/2022 09:33:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=170
06/02/2022 09:33:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=171
06/02/2022 09:33:17 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.6536290230128974 on epoch=171
06/02/2022 09:33:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.13 on epoch=172
06/02/2022 09:33:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=172
06/02/2022 09:33:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=173
06/02/2022 09:33:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=174
06/02/2022 09:33:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=174
06/02/2022 09:33:27 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.6315993915701795 on epoch=174
06/02/2022 09:33:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/02/2022 09:33:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.14 on epoch=176
06/02/2022 09:33:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=177
06/02/2022 09:33:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=177
06/02/2022 09:33:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=178
06/02/2022 09:33:37 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.7958432268888236 on epoch=178
06/02/2022 09:33:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=179
06/02/2022 09:33:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=179
06/02/2022 09:33:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=180
06/02/2022 09:33:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.12 on epoch=181
06/02/2022 09:33:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/02/2022 09:33:48 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.8192217012366955 on epoch=182
06/02/2022 09:33:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=182
06/02/2022 09:33:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=183
06/02/2022 09:33:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/02/2022 09:33:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.11 on epoch=184
06/02/2022 09:33:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=185
06/02/2022 09:33:58 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.7946594681266682 on epoch=185
06/02/2022 09:33:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=186
06/02/2022 09:34:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/02/2022 09:34:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.12 on epoch=187
06/02/2022 09:34:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=188
06/02/2022 09:34:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=189
06/02/2022 09:34:08 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.7292496666310707 on epoch=189
06/02/2022 09:34:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=189
06/02/2022 09:34:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=190
06/02/2022 09:34:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=191
06/02/2022 09:34:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=192
06/02/2022 09:34:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=192
06/02/2022 09:34:18 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.7201496958162498 on epoch=192
06/02/2022 09:34:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.13 on epoch=193
06/02/2022 09:34:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=194
06/02/2022 09:34:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=194
06/02/2022 09:34:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=195
06/02/2022 09:34:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=196
06/02/2022 09:34:29 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.9551828677168108 on epoch=196
06/02/2022 09:34:29 - INFO - __main__ - Saving model with best Classification-F1: 0.880040121684272 -> 0.9551828677168108 on epoch=196, global_step=2750
06/02/2022 09:34:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=197
06/02/2022 09:34:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/02/2022 09:34:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=198
06/02/2022 09:34:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=199
06/02/2022 09:34:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=199
06/02/2022 09:34:39 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.6569128065360381 on epoch=199
06/02/2022 09:34:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=200
06/02/2022 09:34:41 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=201
06/02/2022 09:34:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/02/2022 09:34:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=202
06/02/2022 09:34:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.10 on epoch=203
06/02/2022 09:34:49 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.722539049823114 on epoch=203
06/02/2022 09:34:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/02/2022 09:34:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.10 on epoch=204
06/02/2022 09:34:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/02/2022 09:34:54 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=206
06/02/2022 09:34:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=207
06/02/2022 09:34:59 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.6853323798032244 on epoch=207
06/02/2022 09:35:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/02/2022 09:35:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/02/2022 09:35:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=209
06/02/2022 09:35:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/02/2022 09:35:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=210
06/02/2022 09:35:09 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.9595241936900152 on epoch=210
06/02/2022 09:35:10 - INFO - __main__ - Saving model with best Classification-F1: 0.9551828677168108 -> 0.9595241936900152 on epoch=210, global_step=2950
06/02/2022 09:35:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/02/2022 09:35:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=212
06/02/2022 09:35:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/02/2022 09:35:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=213
06/02/2022 09:35:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=214
06/02/2022 09:35:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:35:17 - INFO - __main__ - Printing 3 examples
06/02/2022 09:35:17 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 09:35:17 - INFO - __main__ - ['Film']
06/02/2022 09:35:17 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 09:35:17 - INFO - __main__ - ['Film']
06/02/2022 09:35:17 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 09:35:17 - INFO - __main__ - ['Film']
06/02/2022 09:35:17 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:35:17 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:35:17 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:35:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:35:17 - INFO - __main__ - Printing 3 examples
06/02/2022 09:35:17 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 09:35:17 - INFO - __main__ - ['Film']
06/02/2022 09:35:17 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 09:35:17 - INFO - __main__ - ['Film']
06/02/2022 09:35:17 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 09:35:17 - INFO - __main__ - ['Film']
06/02/2022 09:35:17 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:35:17 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:35:18 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:35:20 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.9460630907737754 on epoch=214
06/02/2022 09:35:20 - INFO - __main__ - save last model!
06/02/2022 09:35:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 09:35:20 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 09:35:20 - INFO - __main__ - Printing 3 examples
06/02/2022 09:35:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 09:35:20 - INFO - __main__ - ['Animal']
06/02/2022 09:35:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 09:35:20 - INFO - __main__ - ['Animal']
06/02/2022 09:35:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 09:35:20 - INFO - __main__ - ['Village']
06/02/2022 09:35:20 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:35:22 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:35:24 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 09:35:24 - INFO - __main__ - task name: dbpedia_14
06/02/2022 09:35:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 09:35:24 - INFO - __main__ - Starting training!
06/02/2022 09:35:25 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 09:36:40 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/02/2022 09:36:40 - INFO - __main__ - Classification-F1 on test data: 0.4676
06/02/2022 09:36:40 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9595241936900152, test_performance=0.4676497691745784
06/02/2022 09:36:40 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/02/2022 09:36:41 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:36:41 - INFO - __main__ - Printing 3 examples
06/02/2022 09:36:41 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
06/02/2022 09:36:41 - INFO - __main__ - ['Film']
06/02/2022 09:36:41 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/02/2022 09:36:41 - INFO - __main__ - ['Film']
06/02/2022 09:36:41 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/02/2022 09:36:41 - INFO - __main__ - ['Film']
06/02/2022 09:36:41 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:36:41 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:36:42 - INFO - __main__ - Loaded 224 examples from train data
06/02/2022 09:36:42 - INFO - __main__ - Start tokenizing ... 224 instances
06/02/2022 09:36:42 - INFO - __main__ - Printing 3 examples
06/02/2022 09:36:42 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/02/2022 09:36:42 - INFO - __main__ - ['Film']
06/02/2022 09:36:42 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
06/02/2022 09:36:42 - INFO - __main__ - ['Film']
06/02/2022 09:36:42 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/02/2022 09:36:42 - INFO - __main__ - ['Film']
06/02/2022 09:36:42 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:36:42 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:36:42 - INFO - __main__ - Loaded 224 examples from dev data
06/02/2022 09:36:47 - INFO - __main__ - try to initialize prompt embeddings
06/02/2022 09:36:47 - INFO - __main__ - task name: dbpedia_14
06/02/2022 09:36:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
06/02/2022 09:36:48 - INFO - __main__ - Starting training!
06/02/2022 09:36:49 - INFO - __main__ - Step 10 Global step 10 Train loss 7.11 on epoch=0
06/02/2022 09:36:50 - INFO - __main__ - Step 20 Global step 20 Train loss 6.15 on epoch=1
06/02/2022 09:36:52 - INFO - __main__ - Step 30 Global step 30 Train loss 5.63 on epoch=2
06/02/2022 09:36:53 - INFO - __main__ - Step 40 Global step 40 Train loss 5.51 on epoch=2
06/02/2022 09:36:54 - INFO - __main__ - Step 50 Global step 50 Train loss 5.09 on epoch=3
06/02/2022 09:37:35 - INFO - __main__ - Global step 50 Train loss 5.90 Classification-F1 0.0 on epoch=3
06/02/2022 09:37:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
06/02/2022 09:37:36 - INFO - __main__ - Step 60 Global step 60 Train loss 4.82 on epoch=4
06/02/2022 09:37:38 - INFO - __main__ - Step 70 Global step 70 Train loss 4.67 on epoch=4
06/02/2022 09:37:39 - INFO - __main__ - Step 80 Global step 80 Train loss 4.30 on epoch=5
06/02/2022 09:37:40 - INFO - __main__ - Step 90 Global step 90 Train loss 3.88 on epoch=6
06/02/2022 09:37:41 - INFO - __main__ - Step 100 Global step 100 Train loss 3.69 on epoch=7
06/02/2022 09:37:45 - INFO - __main__ - Global step 100 Train loss 4.27 Classification-F1 0.02922077922077922 on epoch=7
06/02/2022 09:37:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.02922077922077922 on epoch=7, global_step=100
06/02/2022 09:37:47 - INFO - __main__ - Step 110 Global step 110 Train loss 3.52 on epoch=7
06/02/2022 09:37:48 - INFO - __main__ - Step 120 Global step 120 Train loss 3.27 on epoch=8
06/02/2022 09:37:49 - INFO - __main__ - Step 130 Global step 130 Train loss 3.23 on epoch=9
06/02/2022 09:37:50 - INFO - __main__ - Step 140 Global step 140 Train loss 3.06 on epoch=9
06/02/2022 09:37:52 - INFO - __main__ - Step 150 Global step 150 Train loss 2.91 on epoch=10
06/02/2022 09:37:54 - INFO - __main__ - Global step 150 Train loss 3.20 Classification-F1 0.10174007725831863 on epoch=10
06/02/2022 09:37:54 - INFO - __main__ - Saving model with best Classification-F1: 0.02922077922077922 -> 0.10174007725831863 on epoch=10, global_step=150
06/02/2022 09:37:55 - INFO - __main__ - Step 160 Global step 160 Train loss 2.50 on epoch=11
06/02/2022 09:37:57 - INFO - __main__ - Step 170 Global step 170 Train loss 2.93 on epoch=12
06/02/2022 09:37:58 - INFO - __main__ - Step 180 Global step 180 Train loss 2.62 on epoch=12
06/02/2022 09:37:59 - INFO - __main__ - Step 190 Global step 190 Train loss 2.47 on epoch=13
06/02/2022 09:38:00 - INFO - __main__ - Step 200 Global step 200 Train loss 2.43 on epoch=14
06/02/2022 09:38:04 - INFO - __main__ - Global step 200 Train loss 2.59 Classification-F1 0.1406881363184675 on epoch=14
06/02/2022 09:38:04 - INFO - __main__ - Saving model with best Classification-F1: 0.10174007725831863 -> 0.1406881363184675 on epoch=14, global_step=200
06/02/2022 09:38:05 - INFO - __main__ - Step 210 Global step 210 Train loss 2.33 on epoch=14
06/02/2022 09:38:06 - INFO - __main__ - Step 220 Global step 220 Train loss 2.24 on epoch=15
06/02/2022 09:38:07 - INFO - __main__ - Step 230 Global step 230 Train loss 2.06 on epoch=16
06/02/2022 09:38:09 - INFO - __main__ - Step 240 Global step 240 Train loss 2.11 on epoch=17
06/02/2022 09:38:10 - INFO - __main__ - Step 250 Global step 250 Train loss 1.98 on epoch=17
06/02/2022 09:38:13 - INFO - __main__ - Global step 250 Train loss 2.15 Classification-F1 0.19866802631337752 on epoch=17
06/02/2022 09:38:13 - INFO - __main__ - Saving model with best Classification-F1: 0.1406881363184675 -> 0.19866802631337752 on epoch=17, global_step=250
06/02/2022 09:38:14 - INFO - __main__ - Step 260 Global step 260 Train loss 2.02 on epoch=18
06/02/2022 09:38:16 - INFO - __main__ - Step 270 Global step 270 Train loss 1.94 on epoch=19
06/02/2022 09:38:17 - INFO - __main__ - Step 280 Global step 280 Train loss 1.68 on epoch=19
06/02/2022 09:38:18 - INFO - __main__ - Step 290 Global step 290 Train loss 2.03 on epoch=20
06/02/2022 09:38:19 - INFO - __main__ - Step 300 Global step 300 Train loss 1.64 on epoch=21
06/02/2022 09:38:22 - INFO - __main__ - Global step 300 Train loss 1.86 Classification-F1 0.20833119302825337 on epoch=21
06/02/2022 09:38:22 - INFO - __main__ - Saving model with best Classification-F1: 0.19866802631337752 -> 0.20833119302825337 on epoch=21, global_step=300
06/02/2022 09:38:23 - INFO - __main__ - Step 310 Global step 310 Train loss 1.70 on epoch=22
06/02/2022 09:38:25 - INFO - __main__ - Step 320 Global step 320 Train loss 1.64 on epoch=22
06/02/2022 09:38:26 - INFO - __main__ - Step 330 Global step 330 Train loss 1.80 on epoch=23
06/02/2022 09:38:27 - INFO - __main__ - Step 340 Global step 340 Train loss 1.57 on epoch=24
06/02/2022 09:38:28 - INFO - __main__ - Step 350 Global step 350 Train loss 1.40 on epoch=24
06/02/2022 09:38:31 - INFO - __main__ - Global step 350 Train loss 1.62 Classification-F1 0.26764076265745984 on epoch=24
06/02/2022 09:38:31 - INFO - __main__ - Saving model with best Classification-F1: 0.20833119302825337 -> 0.26764076265745984 on epoch=24, global_step=350
06/02/2022 09:38:32 - INFO - __main__ - Step 360 Global step 360 Train loss 1.49 on epoch=25
06/02/2022 09:38:34 - INFO - __main__ - Step 370 Global step 370 Train loss 1.46 on epoch=26
06/02/2022 09:38:35 - INFO - __main__ - Step 380 Global step 380 Train loss 1.46 on epoch=27
06/02/2022 09:38:36 - INFO - __main__ - Step 390 Global step 390 Train loss 1.34 on epoch=27
06/02/2022 09:38:37 - INFO - __main__ - Step 400 Global step 400 Train loss 1.26 on epoch=28
06/02/2022 09:38:40 - INFO - __main__ - Global step 400 Train loss 1.40 Classification-F1 0.29334594759876714 on epoch=28
06/02/2022 09:38:40 - INFO - __main__ - Saving model with best Classification-F1: 0.26764076265745984 -> 0.29334594759876714 on epoch=28, global_step=400
06/02/2022 09:38:42 - INFO - __main__ - Step 410 Global step 410 Train loss 1.36 on epoch=29
06/02/2022 09:38:43 - INFO - __main__ - Step 420 Global step 420 Train loss 1.16 on epoch=29
06/02/2022 09:38:44 - INFO - __main__ - Step 430 Global step 430 Train loss 1.24 on epoch=30
06/02/2022 09:38:45 - INFO - __main__ - Step 440 Global step 440 Train loss 1.24 on epoch=31
06/02/2022 09:38:47 - INFO - __main__ - Step 450 Global step 450 Train loss 1.12 on epoch=32
06/02/2022 09:38:50 - INFO - __main__ - Global step 450 Train loss 1.22 Classification-F1 0.2957087819273263 on epoch=32
06/02/2022 09:38:50 - INFO - __main__ - Saving model with best Classification-F1: 0.29334594759876714 -> 0.2957087819273263 on epoch=32, global_step=450
06/02/2022 09:38:51 - INFO - __main__ - Step 460 Global step 460 Train loss 1.06 on epoch=32
06/02/2022 09:38:52 - INFO - __main__ - Step 470 Global step 470 Train loss 1.05 on epoch=33
06/02/2022 09:38:54 - INFO - __main__ - Step 480 Global step 480 Train loss 1.07 on epoch=34
06/02/2022 09:38:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.96 on epoch=34
06/02/2022 09:38:56 - INFO - __main__ - Step 500 Global step 500 Train loss 1.09 on epoch=35
06/02/2022 09:38:59 - INFO - __main__ - Global step 500 Train loss 1.05 Classification-F1 0.3465851451124702 on epoch=35
06/02/2022 09:38:59 - INFO - __main__ - Saving model with best Classification-F1: 0.2957087819273263 -> 0.3465851451124702 on epoch=35, global_step=500
06/02/2022 09:39:01 - INFO - __main__ - Step 510 Global step 510 Train loss 1.03 on epoch=36
06/02/2022 09:39:02 - INFO - __main__ - Step 520 Global step 520 Train loss 0.97 on epoch=37
06/02/2022 09:39:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.84 on epoch=37
06/02/2022 09:39:05 - INFO - __main__ - Step 540 Global step 540 Train loss 1.00 on epoch=38
06/02/2022 09:39:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.82 on epoch=39
06/02/2022 09:39:09 - INFO - __main__ - Global step 550 Train loss 0.93 Classification-F1 0.2740869494459594 on epoch=39
06/02/2022 09:39:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.99 on epoch=39
06/02/2022 09:39:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.85 on epoch=40
06/02/2022 09:39:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.86 on epoch=41
06/02/2022 09:39:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.76 on epoch=42
06/02/2022 09:39:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.82 on epoch=42
06/02/2022 09:39:19 - INFO - __main__ - Global step 600 Train loss 0.86 Classification-F1 0.35199775436734926 on epoch=42
06/02/2022 09:39:19 - INFO - __main__ - Saving model with best Classification-F1: 0.3465851451124702 -> 0.35199775436734926 on epoch=42, global_step=600
06/02/2022 09:39:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.80 on epoch=43
06/02/2022 09:39:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.81 on epoch=44
06/02/2022 09:39:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.83 on epoch=44
06/02/2022 09:39:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.73 on epoch=45
06/02/2022 09:39:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.80 on epoch=46
06/02/2022 09:39:28 - INFO - __main__ - Global step 650 Train loss 0.80 Classification-F1 0.379602992556822 on epoch=46
06/02/2022 09:39:28 - INFO - __main__ - Saving model with best Classification-F1: 0.35199775436734926 -> 0.379602992556822 on epoch=46, global_step=650
06/02/2022 09:39:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.61 on epoch=47
06/02/2022 09:39:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.73 on epoch=47
06/02/2022 09:39:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.69 on epoch=48
06/02/2022 09:39:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.75 on epoch=49
06/02/2022 09:39:35 - INFO - __main__ - Step 700 Global step 700 Train loss 0.76 on epoch=49
06/02/2022 09:39:38 - INFO - __main__ - Global step 700 Train loss 0.71 Classification-F1 0.4744595982445661 on epoch=49
06/02/2022 09:39:38 - INFO - __main__ - Saving model with best Classification-F1: 0.379602992556822 -> 0.4744595982445661 on epoch=49, global_step=700
06/02/2022 09:39:39 - INFO - __main__ - Step 710 Global step 710 Train loss 0.62 on epoch=50
06/02/2022 09:39:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.68 on epoch=51
06/02/2022 09:39:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.76 on epoch=52
06/02/2022 09:39:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.63 on epoch=52
06/02/2022 09:39:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.71 on epoch=53
06/02/2022 09:39:47 - INFO - __main__ - Global step 750 Train loss 0.68 Classification-F1 0.4869013140880149 on epoch=53
06/02/2022 09:39:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4744595982445661 -> 0.4869013140880149 on epoch=53, global_step=750
06/02/2022 09:39:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.62 on epoch=54
06/02/2022 09:39:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.66 on epoch=54
06/02/2022 09:39:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.62 on epoch=55
06/02/2022 09:39:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.70 on epoch=56
06/02/2022 09:39:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.58 on epoch=57
06/02/2022 09:39:57 - INFO - __main__ - Global step 800 Train loss 0.63 Classification-F1 0.5105114737044292 on epoch=57
06/02/2022 09:39:57 - INFO - __main__ - Saving model with best Classification-F1: 0.4869013140880149 -> 0.5105114737044292 on epoch=57, global_step=800
06/02/2022 09:39:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.55 on epoch=57
06/02/2022 09:40:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.58 on epoch=58
06/02/2022 09:40:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.62 on epoch=59
06/02/2022 09:40:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.55 on epoch=59
06/02/2022 09:40:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.58 on epoch=60
06/02/2022 09:40:06 - INFO - __main__ - Global step 850 Train loss 0.58 Classification-F1 0.5829864532783384 on epoch=60
06/02/2022 09:40:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5105114737044292 -> 0.5829864532783384 on epoch=60, global_step=850
06/02/2022 09:40:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.53 on epoch=61
06/02/2022 09:40:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.55 on epoch=62
06/02/2022 09:40:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.52 on epoch=62
06/02/2022 09:40:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.57 on epoch=63
06/02/2022 09:40:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.61 on epoch=64
06/02/2022 09:40:16 - INFO - __main__ - Global step 900 Train loss 0.55 Classification-F1 0.4574409235895908 on epoch=64
06/02/2022 09:40:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.59 on epoch=64
06/02/2022 09:40:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.56 on epoch=65
06/02/2022 09:40:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.61 on epoch=66
06/02/2022 09:40:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.54 on epoch=67
06/02/2022 09:40:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.53 on epoch=67
06/02/2022 09:40:25 - INFO - __main__ - Global step 950 Train loss 0.57 Classification-F1 0.5591600937892064 on epoch=67
06/02/2022 09:40:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.60 on epoch=68
06/02/2022 09:40:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.51 on epoch=69
06/02/2022 09:40:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.47 on epoch=69
06/02/2022 09:40:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.49 on epoch=70
06/02/2022 09:40:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.48 on epoch=71
06/02/2022 09:40:35 - INFO - __main__ - Global step 1000 Train loss 0.51 Classification-F1 0.6741426471308531 on epoch=71
06/02/2022 09:40:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5829864532783384 -> 0.6741426471308531 on epoch=71, global_step=1000
06/02/2022 09:40:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.52 on epoch=72
06/02/2022 09:40:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.48 on epoch=72
06/02/2022 09:40:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.48 on epoch=73
06/02/2022 09:40:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.50 on epoch=74
06/02/2022 09:40:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.48 on epoch=74
06/02/2022 09:40:45 - INFO - __main__ - Global step 1050 Train loss 0.49 Classification-F1 0.7696634013692838 on epoch=74
06/02/2022 09:40:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6741426471308531 -> 0.7696634013692838 on epoch=74, global_step=1050
06/02/2022 09:40:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.46 on epoch=75
06/02/2022 09:40:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.51 on epoch=76
06/02/2022 09:40:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.51 on epoch=77
06/02/2022 09:40:51 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.44 on epoch=77
06/02/2022 09:40:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.43 on epoch=78
06/02/2022 09:40:56 - INFO - __main__ - Global step 1100 Train loss 0.47 Classification-F1 0.7588896702640835 on epoch=78
06/02/2022 09:40:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.44 on epoch=79
06/02/2022 09:40:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.36 on epoch=79
06/02/2022 09:40:59 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.49 on epoch=80
06/02/2022 09:41:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.50 on epoch=81
06/02/2022 09:41:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.45 on epoch=82
06/02/2022 09:41:05 - INFO - __main__ - Global step 1150 Train loss 0.45 Classification-F1 0.536340362815469 on epoch=82
06/02/2022 09:41:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.44 on epoch=82
06/02/2022 09:41:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.47 on epoch=83
06/02/2022 09:41:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.43 on epoch=84
06/02/2022 09:41:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.44 on epoch=84
06/02/2022 09:41:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.40 on epoch=85
06/02/2022 09:41:15 - INFO - __main__ - Global step 1200 Train loss 0.43 Classification-F1 0.7145804259533587 on epoch=85
06/02/2022 09:41:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.36 on epoch=86
06/02/2022 09:41:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.48 on epoch=87
06/02/2022 09:41:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.41 on epoch=87
06/02/2022 09:41:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.47 on epoch=88
06/02/2022 09:41:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.45 on epoch=89
06/02/2022 09:41:25 - INFO - __main__ - Global step 1250 Train loss 0.43 Classification-F1 0.6756573146446458 on epoch=89
06/02/2022 09:41:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.29 on epoch=89
06/02/2022 09:41:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.49 on epoch=90
06/02/2022 09:41:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.39 on epoch=91
06/02/2022 09:41:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.40 on epoch=92
06/02/2022 09:41:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.39 on epoch=92
06/02/2022 09:41:35 - INFO - __main__ - Global step 1300 Train loss 0.39 Classification-F1 0.6944476998041923 on epoch=92
06/02/2022 09:41:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.38 on epoch=93
06/02/2022 09:41:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.32 on epoch=94
06/02/2022 09:41:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.34 on epoch=94
06/02/2022 09:41:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.34 on epoch=95
06/02/2022 09:41:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.46 on epoch=96
06/02/2022 09:41:45 - INFO - __main__ - Global step 1350 Train loss 0.37 Classification-F1 0.6031927923364164 on epoch=96
06/02/2022 09:41:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.36 on epoch=97
06/02/2022 09:41:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.34 on epoch=97
06/02/2022 09:41:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.38 on epoch=98
06/02/2022 09:41:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.42 on epoch=99
06/02/2022 09:41:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.37 on epoch=99
06/02/2022 09:41:55 - INFO - __main__ - Global step 1400 Train loss 0.38 Classification-F1 0.5862604556322366 on epoch=99
06/02/2022 09:41:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.41 on epoch=100
06/02/2022 09:41:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.44 on epoch=101
06/02/2022 09:41:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.39 on epoch=102
06/02/2022 09:42:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.32 on epoch=102
06/02/2022 09:42:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.33 on epoch=103
06/02/2022 09:42:06 - INFO - __main__ - Global step 1450 Train loss 0.38 Classification-F1 0.45824999943128775 on epoch=103
06/02/2022 09:42:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.38 on epoch=104
06/02/2022 09:42:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.39 on epoch=104
06/02/2022 09:42:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.34 on epoch=105
06/02/2022 09:42:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.38 on epoch=106
06/02/2022 09:42:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.41 on epoch=107
06/02/2022 09:42:16 - INFO - __main__ - Global step 1500 Train loss 0.38 Classification-F1 0.6097818544982537 on epoch=107
06/02/2022 09:42:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.29 on epoch=107
06/02/2022 09:42:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.32 on epoch=108
06/02/2022 09:42:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.40 on epoch=109
06/02/2022 09:42:21 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.28 on epoch=109
06/02/2022 09:42:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.30 on epoch=110
06/02/2022 09:42:26 - INFO - __main__ - Global step 1550 Train loss 0.32 Classification-F1 0.6754772588508733 on epoch=110
06/02/2022 09:42:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.49 on epoch=111
06/02/2022 09:42:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.29 on epoch=112
06/02/2022 09:42:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.23 on epoch=112
06/02/2022 09:42:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.33 on epoch=113
06/02/2022 09:42:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.34 on epoch=114
06/02/2022 09:42:36 - INFO - __main__ - Global step 1600 Train loss 0.34 Classification-F1 0.7451639037894653 on epoch=114
06/02/2022 09:42:38 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.41 on epoch=114
06/02/2022 09:42:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.31 on epoch=115
06/02/2022 09:42:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.23 on epoch=116
06/02/2022 09:42:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.32 on epoch=117
06/02/2022 09:42:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.27 on epoch=117
06/02/2022 09:42:47 - INFO - __main__ - Global step 1650 Train loss 0.31 Classification-F1 0.6371688198124132 on epoch=117
06/02/2022 09:42:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.27 on epoch=118
06/02/2022 09:42:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.25 on epoch=119
06/02/2022 09:42:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.30 on epoch=119
06/02/2022 09:42:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.21 on epoch=120
06/02/2022 09:42:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.28 on epoch=121
06/02/2022 09:42:57 - INFO - __main__ - Global step 1700 Train loss 0.26 Classification-F1 0.8063436205371688 on epoch=121
06/02/2022 09:42:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7696634013692838 -> 0.8063436205371688 on epoch=121, global_step=1700
06/02/2022 09:42:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.32 on epoch=122
06/02/2022 09:42:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.29 on epoch=122
06/02/2022 09:43:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.25 on epoch=123
06/02/2022 09:43:02 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.34 on epoch=124
06/02/2022 09:43:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.31 on epoch=124
06/02/2022 09:43:07 - INFO - __main__ - Global step 1750 Train loss 0.30 Classification-F1 0.6306152890809126 on epoch=124
06/02/2022 09:43:08 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.28 on epoch=125
06/02/2022 09:43:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.24 on epoch=126
06/02/2022 09:43:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.30 on epoch=127
06/02/2022 09:43:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.21 on epoch=127
06/02/2022 09:43:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.31 on epoch=128
06/02/2022 09:43:17 - INFO - __main__ - Global step 1800 Train loss 0.27 Classification-F1 0.675824775621845 on epoch=128
06/02/2022 09:43:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.37 on epoch=129
06/02/2022 09:43:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.32 on epoch=129
06/02/2022 09:43:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.23 on epoch=130
06/02/2022 09:43:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.23 on epoch=131
06/02/2022 09:43:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.39 on epoch=132
06/02/2022 09:43:28 - INFO - __main__ - Global step 1850 Train loss 0.31 Classification-F1 0.7830026576246334 on epoch=132
06/02/2022 09:43:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.23 on epoch=132
06/02/2022 09:43:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.22 on epoch=133
06/02/2022 09:43:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.25 on epoch=134
06/02/2022 09:43:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.23 on epoch=134
06/02/2022 09:43:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.23 on epoch=135
06/02/2022 09:43:37 - INFO - __main__ - Global step 1900 Train loss 0.23 Classification-F1 0.6763937719108496 on epoch=135
06/02/2022 09:43:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.19 on epoch=136
06/02/2022 09:43:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.30 on epoch=137
06/02/2022 09:43:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.21 on epoch=137
06/02/2022 09:43:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.17 on epoch=138
06/02/2022 09:43:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.21 on epoch=139
06/02/2022 09:43:47 - INFO - __main__ - Global step 1950 Train loss 0.22 Classification-F1 0.5479824242276805 on epoch=139
06/02/2022 09:43:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.22 on epoch=139
06/02/2022 09:43:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.17 on epoch=140
06/02/2022 09:43:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.26 on epoch=141
06/02/2022 09:43:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.15 on epoch=142
06/02/2022 09:43:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=142
06/02/2022 09:43:58 - INFO - __main__ - Global step 2000 Train loss 0.20 Classification-F1 0.6675882008208024 on epoch=142
06/02/2022 09:43:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.18 on epoch=143
06/02/2022 09:44:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.19 on epoch=144
06/02/2022 09:44:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.23 on epoch=144
06/02/2022 09:44:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.27 on epoch=145
06/02/2022 09:44:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.23 on epoch=146
06/02/2022 09:44:08 - INFO - __main__ - Global step 2050 Train loss 0.22 Classification-F1 0.5787078697183061 on epoch=146
06/02/2022 09:44:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.24 on epoch=147
06/02/2022 09:44:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.13 on epoch=147
06/02/2022 09:44:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.23 on epoch=148
06/02/2022 09:44:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.21 on epoch=149
06/02/2022 09:44:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.18 on epoch=149
06/02/2022 09:44:19 - INFO - __main__ - Global step 2100 Train loss 0.20 Classification-F1 0.7794228301804482 on epoch=149
06/02/2022 09:44:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.16 on epoch=150
06/02/2022 09:44:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.25 on epoch=151
06/02/2022 09:44:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.20 on epoch=152
06/02/2022 09:44:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.15 on epoch=152
06/02/2022 09:44:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.16 on epoch=153
06/02/2022 09:44:29 - INFO - __main__ - Global step 2150 Train loss 0.18 Classification-F1 0.8414581805962855 on epoch=153
06/02/2022 09:44:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8063436205371688 -> 0.8414581805962855 on epoch=153, global_step=2150
06/02/2022 09:44:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=154
06/02/2022 09:44:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.21 on epoch=154
06/02/2022 09:44:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.15 on epoch=155
06/02/2022 09:44:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=156
06/02/2022 09:44:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.13 on epoch=157
06/02/2022 09:44:40 - INFO - __main__ - Global step 2200 Train loss 0.14 Classification-F1 0.7420788681317355 on epoch=157
06/02/2022 09:44:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=157
06/02/2022 09:44:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.18 on epoch=158
06/02/2022 09:44:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.17 on epoch=159
06/02/2022 09:44:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.15 on epoch=159
06/02/2022 09:44:46 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.15 on epoch=160
06/02/2022 09:44:50 - INFO - __main__ - Global step 2250 Train loss 0.15 Classification-F1 0.7832244531951723 on epoch=160
06/02/2022 09:44:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.16 on epoch=161
06/02/2022 09:44:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.16 on epoch=162
06/02/2022 09:44:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=162
06/02/2022 09:44:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.18 on epoch=163
06/02/2022 09:44:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.24 on epoch=164
06/02/2022 09:45:00 - INFO - __main__ - Global step 2300 Train loss 0.17 Classification-F1 0.7636409842529388 on epoch=164
06/02/2022 09:45:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.24 on epoch=164
06/02/2022 09:45:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.15 on epoch=165
06/02/2022 09:45:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.14 on epoch=166
06/02/2022 09:45:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.22 on epoch=167
06/02/2022 09:45:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.13 on epoch=167
06/02/2022 09:45:11 - INFO - __main__ - Global step 2350 Train loss 0.17 Classification-F1 0.7658391266536708 on epoch=167
06/02/2022 09:45:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.15 on epoch=168
06/02/2022 09:45:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.15 on epoch=169
06/02/2022 09:45:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.15 on epoch=169
06/02/2022 09:45:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.17 on epoch=170
06/02/2022 09:45:17 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.16 on epoch=171
06/02/2022 09:45:21 - INFO - __main__ - Global step 2400 Train loss 0.16 Classification-F1 0.7689327616454577 on epoch=171
06/02/2022 09:45:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.15 on epoch=172
06/02/2022 09:45:24 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.13 on epoch=172
06/02/2022 09:45:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.12 on epoch=173
06/02/2022 09:45:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.14 on epoch=174
06/02/2022 09:45:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.21 on epoch=174
06/02/2022 09:45:32 - INFO - __main__ - Global step 2450 Train loss 0.15 Classification-F1 0.7714327268556594 on epoch=174
06/02/2022 09:45:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.13 on epoch=175
06/02/2022 09:45:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/02/2022 09:45:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.14 on epoch=177
06/02/2022 09:45:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.15 on epoch=177
06/02/2022 09:45:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.21 on epoch=178
06/02/2022 09:45:43 - INFO - __main__ - Global step 2500 Train loss 0.14 Classification-F1 0.8358260212076033 on epoch=178
06/02/2022 09:45:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.15 on epoch=179
06/02/2022 09:45:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.16 on epoch=179
06/02/2022 09:45:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.14 on epoch=180
06/02/2022 09:45:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.11 on epoch=181
06/02/2022 09:45:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.14 on epoch=182
06/02/2022 09:45:53 - INFO - __main__ - Global step 2550 Train loss 0.14 Classification-F1 0.8890198728450381 on epoch=182
06/02/2022 09:45:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8414581805962855 -> 0.8890198728450381 on epoch=182, global_step=2550
06/02/2022 09:45:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=182
06/02/2022 09:45:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.11 on epoch=183
06/02/2022 09:45:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.14 on epoch=184
06/02/2022 09:45:58 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.09 on epoch=184
06/02/2022 09:46:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.11 on epoch=185
06/02/2022 09:46:04 - INFO - __main__ - Global step 2600 Train loss 0.11 Classification-F1 0.9597084536109923 on epoch=185
06/02/2022 09:46:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8890198728450381 -> 0.9597084536109923 on epoch=185, global_step=2600
06/02/2022 09:46:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=186
06/02/2022 09:46:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=187
06/02/2022 09:46:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.13 on epoch=187
06/02/2022 09:46:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=188
06/02/2022 09:46:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.15 on epoch=189
06/02/2022 09:46:14 - INFO - __main__ - Global step 2650 Train loss 0.11 Classification-F1 0.9732891397028022 on epoch=189
06/02/2022 09:46:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9597084536109923 -> 0.9732891397028022 on epoch=189, global_step=2650
06/02/2022 09:46:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.14 on epoch=189
06/02/2022 09:46:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=190
06/02/2022 09:46:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.12 on epoch=191
06/02/2022 09:46:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.10 on epoch=192
06/02/2022 09:46:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.13 on epoch=192
06/02/2022 09:46:25 - INFO - __main__ - Global step 2700 Train loss 0.12 Classification-F1 0.9731661799617208 on epoch=192
06/02/2022 09:46:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=193
06/02/2022 09:46:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.13 on epoch=194
06/02/2022 09:46:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=194
06/02/2022 09:46:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.11 on epoch=195
06/02/2022 09:46:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.11 on epoch=196
06/02/2022 09:46:35 - INFO - __main__ - Global step 2750 Train loss 0.10 Classification-F1 0.7777153340204462 on epoch=196
06/02/2022 09:46:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.15 on epoch=197
06/02/2022 09:46:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=197
06/02/2022 09:46:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=198
06/02/2022 09:46:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.15 on epoch=199
06/02/2022 09:46:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.09 on epoch=199
06/02/2022 09:46:46 - INFO - __main__ - Global step 2800 Train loss 0.11 Classification-F1 0.8381356151754634 on epoch=199
06/02/2022 09:46:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.16 on epoch=200
06/02/2022 09:46:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=201
06/02/2022 09:46:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=202
06/02/2022 09:46:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=202
06/02/2022 09:46:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=203
06/02/2022 09:46:56 - INFO - __main__ - Global step 2850 Train loss 0.10 Classification-F1 0.770097286658893 on epoch=203
06/02/2022 09:46:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/02/2022 09:46:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
06/02/2022 09:47:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/02/2022 09:47:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=206
06/02/2022 09:47:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.18 on epoch=207
06/02/2022 09:47:07 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.7730545941368424 on epoch=207
06/02/2022 09:47:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.10 on epoch=207
06/02/2022 09:47:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.13 on epoch=208
06/02/2022 09:47:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.12 on epoch=209
06/02/2022 09:47:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.10 on epoch=209
06/02/2022 09:47:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=210
06/02/2022 09:47:17 - INFO - __main__ - Global step 2950 Train loss 0.11 Classification-F1 0.8434175490716562 on epoch=210
06/02/2022 09:47:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.12 on epoch=211
06/02/2022 09:47:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=212
06/02/2022 09:47:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.10 on epoch=212
06/02/2022 09:47:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=213
06/02/2022 09:47:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.18 on epoch=214
06/02/2022 09:47:27 - INFO - __main__ - Global step 3000 Train loss 0.11 Classification-F1 0.8933898032870748 on epoch=214
06/02/2022 09:47:27 - INFO - __main__ - save last model!
06/02/2022 09:47:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 09:47:28 - INFO - __main__ - Start tokenizing ... 3500 instances
06/02/2022 09:47:28 - INFO - __main__ - Printing 3 examples
06/02/2022 09:47:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
06/02/2022 09:47:28 - INFO - __main__ - ['Animal']
06/02/2022 09:47:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/02/2022 09:47:28 - INFO - __main__ - ['Animal']
06/02/2022 09:47:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
06/02/2022 09:47:28 - INFO - __main__ - ['Village']
06/02/2022 09:47:28 - INFO - __main__ - Tokenizing Input ...
06/02/2022 09:47:29 - INFO - __main__ - Tokenizing Output ...
06/02/2022 09:47:33 - INFO - __main__ - Loaded 3500 examples from test data
06/02/2022 09:48:48 - INFO - __main__ - Saved prediction in models/T5-base-cls2cls/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/02/2022 09:48:48 - INFO - __main__ - Classification-F1 on test data: 0.6064
06/02/2022 09:48:49 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.9732891397028022, test_performance=0.6063773485171188
