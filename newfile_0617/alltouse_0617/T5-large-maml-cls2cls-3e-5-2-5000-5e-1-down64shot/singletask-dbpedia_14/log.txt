05/21/2022 21:22:13 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:22:13 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14
05/21/2022 21:22:13 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 21:22:13 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14
05/21/2022 21:22:15 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:22:15 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:22:15 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:22:15 - INFO - __main__ - Using 2 gpus
05/21/2022 21:22:15 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
05/21/2022 21:22:15 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:22:15 - INFO - __main__ - Using 2 gpus
05/21/2022 21:22:15 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
05/21/2022 21:22:20 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.5, bsz=8 ...
06/09/2022 10:29:35 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/09/2022 10:29:35 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14
06/09/2022 10:29:35 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/09/2022 10:29:35 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14
06/09/2022 10:29:37 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/09/2022 10:29:37 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/09/2022 10:29:37 - INFO - __main__ - args.device: cuda:1
06/09/2022 10:29:37 - INFO - __main__ - args.device: cuda:0
06/09/2022 10:29:37 - INFO - __main__ - Using 2 gpus
06/09/2022 10:29:37 - INFO - __main__ - Using 2 gpus
06/09/2022 10:29:37 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
06/09/2022 10:29:37 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
06/13/2022 02:06:17 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/13/2022 02:06:17 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14
06/13/2022 02:06:17 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/13/2022 02:06:17 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14
06/13/2022 02:06:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/13/2022 02:06:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/13/2022 02:06:19 - INFO - __main__ - args.device: cuda:0
06/13/2022 02:06:19 - INFO - __main__ - args.device: cuda:1
06/13/2022 02:06:19 - INFO - __main__ - Using 2 gpus
06/13/2022 02:06:19 - INFO - __main__ - Using 2 gpus
06/13/2022 02:06:19 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
06/13/2022 02:06:19 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
06/13/2022 02:06:23 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.5, bsz=8 ...
06/13/2022 02:06:24 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:06:24 - INFO - __main__ - Printing 3 examples
06/13/2022 02:06:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 02:06:24 - INFO - __main__ - ['Animal']
06/13/2022 02:06:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 02:06:24 - INFO - __main__ - ['Animal']
06/13/2022 02:06:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 02:06:24 - INFO - __main__ - ['Animal']
06/13/2022 02:06:24 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:06:24 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:06:24 - INFO - __main__ - Printing 3 examples
06/13/2022 02:06:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 02:06:24 - INFO - __main__ - ['Animal']
06/13/2022 02:06:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 02:06:24 - INFO - __main__ - ['Animal']
06/13/2022 02:06:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 02:06:24 - INFO - __main__ - ['Animal']
06/13/2022 02:06:24 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:06:25 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:06:25 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:06:26 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 02:06:26 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:06:26 - INFO - __main__ - Printing 3 examples
06/13/2022 02:06:26 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 02:06:26 - INFO - __main__ - ['Animal']
06/13/2022 02:06:26 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 02:06:26 - INFO - __main__ - ['Animal']
06/13/2022 02:06:26 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 02:06:26 - INFO - __main__ - ['Animal']
06/13/2022 02:06:26 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:06:26 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 02:06:26 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:06:26 - INFO - __main__ - Printing 3 examples
06/13/2022 02:06:26 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 02:06:26 - INFO - __main__ - ['Animal']
06/13/2022 02:06:26 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 02:06:26 - INFO - __main__ - ['Animal']
06/13/2022 02:06:26 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 02:06:26 - INFO - __main__ - ['Animal']
06/13/2022 02:06:26 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:06:26 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:06:26 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:06:27 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 02:06:27 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 02:06:45 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 02:06:45 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 02:06:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 02:06:46 - INFO - __main__ - Starting training!
06/13/2022 02:06:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 02:06:51 - INFO - __main__ - Starting training!
06/13/2022 02:06:55 - INFO - __main__ - Step 10 Global step 10 Train loss 4.41 on epoch=0
06/13/2022 02:06:58 - INFO - __main__ - Step 20 Global step 20 Train loss 2.42 on epoch=0
06/13/2022 02:07:00 - INFO - __main__ - Step 30 Global step 30 Train loss 1.80 on epoch=0
06/13/2022 02:07:03 - INFO - __main__ - Step 40 Global step 40 Train loss 1.56 on epoch=0
06/13/2022 02:07:05 - INFO - __main__ - Step 50 Global step 50 Train loss 1.37 on epoch=0
06/13/2022 02:07:28 - INFO - __main__ - Global step 50 Train loss 2.31 Classification-F1 0.185875066963679 on epoch=0
06/13/2022 02:07:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.185875066963679 on epoch=0, global_step=50
06/13/2022 02:07:31 - INFO - __main__ - Step 60 Global step 60 Train loss 1.10 on epoch=1
06/13/2022 02:07:33 - INFO - __main__ - Step 70 Global step 70 Train loss 0.81 on epoch=1
06/13/2022 02:07:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.82 on epoch=1
06/13/2022 02:07:38 - INFO - __main__ - Step 90 Global step 90 Train loss 0.70 on epoch=1
06/13/2022 02:07:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.74 on epoch=1
06/13/2022 02:08:07 - INFO - __main__ - Global step 100 Train loss 0.83 Classification-F1 0.4680721962474033 on epoch=1
06/13/2022 02:08:07 - INFO - __main__ - Saving model with best Classification-F1: 0.185875066963679 -> 0.4680721962474033 on epoch=1, global_step=100
06/13/2022 02:08:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.70 on epoch=1
06/13/2022 02:08:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=2
06/13/2022 02:08:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.56 on epoch=2
06/13/2022 02:08:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=2
06/13/2022 02:08:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.57 on epoch=2
06/13/2022 02:08:48 - INFO - __main__ - Global step 150 Train loss 0.58 Classification-F1 0.5863520971266919 on epoch=2
06/13/2022 02:08:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4680721962474033 -> 0.5863520971266919 on epoch=2, global_step=150
06/13/2022 02:08:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=2
06/13/2022 02:08:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=3
06/13/2022 02:08:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=3
06/13/2022 02:08:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=3
06/13/2022 02:09:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=3
06/13/2022 02:09:29 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.6656252448629204 on epoch=3
06/13/2022 02:09:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5863520971266919 -> 0.6656252448629204 on epoch=3, global_step=200
06/13/2022 02:09:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.43 on epoch=3
06/13/2022 02:09:34 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=3
06/13/2022 02:09:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=4
06/13/2022 02:09:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.37 on epoch=4
06/13/2022 02:09:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=4
06/13/2022 02:10:10 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.5663391435820793 on epoch=4
06/13/2022 02:10:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=4
06/13/2022 02:10:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=4
06/13/2022 02:10:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=4
06/13/2022 02:10:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=5
06/13/2022 02:10:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=5
06/13/2022 02:10:55 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.77806452045943 on epoch=5
06/13/2022 02:10:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6656252448629204 -> 0.77806452045943 on epoch=5, global_step=300
06/13/2022 02:10:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=5
06/13/2022 02:11:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=5
06/13/2022 02:11:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=5
06/13/2022 02:11:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=6
06/13/2022 02:11:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=6
06/13/2022 02:11:36 - INFO - __main__ - Global step 350 Train loss 0.25 Classification-F1 0.5981911320150395 on epoch=6
06/13/2022 02:11:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=6
06/13/2022 02:11:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=6
06/13/2022 02:11:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=6
06/13/2022 02:11:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=6
06/13/2022 02:11:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=7
06/13/2022 02:12:21 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.5922858481735401 on epoch=7
06/13/2022 02:12:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=7
06/13/2022 02:12:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=7
06/13/2022 02:12:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=7
06/13/2022 02:12:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=7
06/13/2022 02:12:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=8
06/13/2022 02:13:01 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.6758606943625884 on epoch=8
06/13/2022 02:13:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=8
06/13/2022 02:13:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=8
06/13/2022 02:13:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=8
06/13/2022 02:13:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=8
06/13/2022 02:13:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=8
06/13/2022 02:13:44 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.6940715735175833 on epoch=8
06/13/2022 02:13:47 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=9
06/13/2022 02:13:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.10 on epoch=9
06/13/2022 02:13:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=9
06/13/2022 02:13:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=9
06/13/2022 02:13:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=9
06/13/2022 02:14:28 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.8427511516518038 on epoch=9
06/13/2022 02:14:28 - INFO - __main__ - Saving model with best Classification-F1: 0.77806452045943 -> 0.8427511516518038 on epoch=9, global_step=550
06/13/2022 02:14:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=9
06/13/2022 02:14:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=10
06/13/2022 02:14:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=10
06/13/2022 02:14:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=10
06/13/2022 02:14:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=10
06/13/2022 02:15:11 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.7924980345877602 on epoch=10
06/13/2022 02:15:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.41 on epoch=10
06/13/2022 02:15:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=11
06/13/2022 02:15:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=11
06/13/2022 02:15:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=11
06/13/2022 02:15:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=11
06/13/2022 02:15:53 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.7387147334480784 on epoch=11
06/13/2022 02:15:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=11
06/13/2022 02:15:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=11
06/13/2022 02:16:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=12
06/13/2022 02:16:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=12
06/13/2022 02:16:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=12
06/13/2022 02:16:35 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.91193845030489 on epoch=12
06/13/2022 02:16:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8427511516518038 -> 0.91193845030489 on epoch=12, global_step=700
06/13/2022 02:16:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=12
06/13/2022 02:16:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.34 on epoch=12
06/13/2022 02:16:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=13
06/13/2022 02:16:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=13
06/13/2022 02:16:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=13
06/13/2022 02:17:15 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.9079045926708356 on epoch=13
06/13/2022 02:17:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=13
06/13/2022 02:17:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=13
06/13/2022 02:17:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.30 on epoch=13
06/13/2022 02:17:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=14
06/13/2022 02:17:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=14
06/13/2022 02:17:55 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.7675380302655187 on epoch=14
06/13/2022 02:17:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=14
06/13/2022 02:18:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=14
06/13/2022 02:18:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=14
06/13/2022 02:18:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=14
06/13/2022 02:18:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=15
06/13/2022 02:18:36 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.8973318814890353 on epoch=15
06/13/2022 02:18:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=15
06/13/2022 02:18:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=15
06/13/2022 02:18:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=15
06/13/2022 02:18:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=15
06/13/2022 02:18:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=16
06/13/2022 02:19:15 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.6969174227819867 on epoch=16
06/13/2022 02:19:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=16
06/13/2022 02:19:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=16
06/13/2022 02:19:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=16
06/13/2022 02:19:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=16
06/13/2022 02:19:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=16
06/13/2022 02:19:54 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.8544247661202251 on epoch=16
06/13/2022 02:19:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=17
06/13/2022 02:19:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=17
06/13/2022 02:20:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=17
06/13/2022 02:20:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=17
06/13/2022 02:20:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=17
06/13/2022 02:20:31 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.8976099748589748 on epoch=17
06/13/2022 02:20:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=18
06/13/2022 02:20:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=18
06/13/2022 02:20:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=18
06/13/2022 02:20:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=18
06/13/2022 02:20:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=18
06/13/2022 02:21:09 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.8509527155952124 on epoch=18
06/13/2022 02:21:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=18
06/13/2022 02:21:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=19
06/13/2022 02:21:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=19
06/13/2022 02:21:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=19
06/13/2022 02:21:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=19
06/13/2022 02:21:47 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.9765633021000945 on epoch=19
06/13/2022 02:21:47 - INFO - __main__ - Saving model with best Classification-F1: 0.91193845030489 -> 0.9765633021000945 on epoch=19, global_step=1100
06/13/2022 02:21:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.32 on epoch=19
06/13/2022 02:21:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=19
06/13/2022 02:21:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=20
06/13/2022 02:21:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=20
06/13/2022 02:21:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=20
06/13/2022 02:22:23 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7900766262373838 on epoch=20
06/13/2022 02:22:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=20
06/13/2022 02:22:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=20
06/13/2022 02:22:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=21
06/13/2022 02:22:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=21
06/13/2022 02:22:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
06/13/2022 02:23:01 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.8527861172711715 on epoch=21
06/13/2022 02:23:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=21
06/13/2022 02:23:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
06/13/2022 02:23:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.35 on epoch=21
06/13/2022 02:23:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=22
06/13/2022 02:23:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=22
06/13/2022 02:23:38 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.9130098831477853 on epoch=22
06/13/2022 02:23:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=22
06/13/2022 02:23:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=22
06/13/2022 02:23:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
06/13/2022 02:23:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=23
06/13/2022 02:23:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
06/13/2022 02:24:16 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9112769598611979 on epoch=23
06/13/2022 02:24:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=23
06/13/2022 02:24:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=23
06/13/2022 02:24:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=23
06/13/2022 02:24:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
06/13/2022 02:24:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=24
06/13/2022 02:24:52 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8455476974256477 on epoch=24
06/13/2022 02:24:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=24
06/13/2022 02:24:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=24
06/13/2022 02:24:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=24
06/13/2022 02:25:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=24
06/13/2022 02:25:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
06/13/2022 02:25:28 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7936923953279331 on epoch=24
06/13/2022 02:25:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=25
06/13/2022 02:25:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=25
06/13/2022 02:25:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=25
06/13/2022 02:25:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=25
06/13/2022 02:25:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=25
06/13/2022 02:26:04 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7527898002185807 on epoch=25
06/13/2022 02:26:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=26
06/13/2022 02:26:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=26
06/13/2022 02:26:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=26
06/13/2022 02:26:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
06/13/2022 02:26:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=26
06/13/2022 02:26:41 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.893565125993979 on epoch=26
06/13/2022 02:26:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=26
06/13/2022 02:26:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=27
06/13/2022 02:26:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=27
06/13/2022 02:26:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=27
06/13/2022 02:26:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=27
06/13/2022 02:27:16 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7957146674755203 on epoch=27
06/13/2022 02:27:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=27
06/13/2022 02:27:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
06/13/2022 02:27:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
06/13/2022 02:27:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
06/13/2022 02:27:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=28
06/13/2022 02:27:52 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7081065099781115 on epoch=28
06/13/2022 02:27:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=28
06/13/2022 02:27:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
06/13/2022 02:27:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
06/13/2022 02:28:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=29
06/13/2022 02:28:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=29
06/13/2022 02:28:28 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.47535498517475816 on epoch=29
06/13/2022 02:28:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=29
06/13/2022 02:28:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=29
06/13/2022 02:28:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
06/13/2022 02:28:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=30
06/13/2022 02:28:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=30
06/13/2022 02:29:04 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7812526582826418 on epoch=30
06/13/2022 02:29:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
06/13/2022 02:29:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=30
06/13/2022 02:29:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.34 on epoch=30
06/13/2022 02:29:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
06/13/2022 02:29:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=31
06/13/2022 02:29:40 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.5892309147357991 on epoch=31
06/13/2022 02:29:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
06/13/2022 02:29:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
06/13/2022 02:29:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=31
06/13/2022 02:29:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.31 on epoch=31
06/13/2022 02:29:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=32
06/13/2022 02:30:15 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.5751853274334546 on epoch=32
06/13/2022 02:30:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
06/13/2022 02:30:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
06/13/2022 02:30:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=32
06/13/2022 02:30:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
06/13/2022 02:30:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=33
06/13/2022 02:30:51 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7740927637402024 on epoch=33
06/13/2022 02:30:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
06/13/2022 02:30:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
06/13/2022 02:30:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
06/13/2022 02:31:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=33
06/13/2022 02:31:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=33
06/13/2022 02:31:26 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7646107042308775 on epoch=33
06/13/2022 02:31:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=34
06/13/2022 02:31:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
06/13/2022 02:31:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
06/13/2022 02:31:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=34
06/13/2022 02:31:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=34
06/13/2022 02:32:02 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7648272194191932 on epoch=34
06/13/2022 02:32:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
06/13/2022 02:32:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=35
06/13/2022 02:32:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=35
06/13/2022 02:32:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=35
06/13/2022 02:32:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
06/13/2022 02:32:40 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.9517117435003432 on epoch=35
06/13/2022 02:32:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.32 on epoch=35
06/13/2022 02:32:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
06/13/2022 02:32:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
06/13/2022 02:32:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
06/13/2022 02:32:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
06/13/2022 02:33:15 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.8394585428924202 on epoch=36
06/13/2022 02:33:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
06/13/2022 02:33:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
06/13/2022 02:33:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
06/13/2022 02:33:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=37
06/13/2022 02:33:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=37
06/13/2022 02:33:50 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9098508888721077 on epoch=37
06/13/2022 02:33:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
06/13/2022 02:33:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.28 on epoch=37
06/13/2022 02:33:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
06/13/2022 02:34:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=38
06/13/2022 02:34:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
06/13/2022 02:34:27 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.960064544088934 on epoch=38
06/13/2022 02:34:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.13 on epoch=38
06/13/2022 02:34:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=38
06/13/2022 02:34:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.23 on epoch=38
06/13/2022 02:34:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
06/13/2022 02:34:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=39
06/13/2022 02:35:05 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.9035778078428922 on epoch=39
06/13/2022 02:35:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
06/13/2022 02:35:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=39
06/13/2022 02:35:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.28 on epoch=39
06/13/2022 02:35:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=39
06/13/2022 02:35:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=40
06/13/2022 02:35:41 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.900997704797539 on epoch=40
06/13/2022 02:35:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=40
06/13/2022 02:35:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
06/13/2022 02:35:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
06/13/2022 02:35:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.30 on epoch=40
06/13/2022 02:35:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
06/13/2022 02:36:16 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.7094358833145444 on epoch=41
06/13/2022 02:36:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
06/13/2022 02:36:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
06/13/2022 02:36:24 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
06/13/2022 02:36:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
06/13/2022 02:36:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.28 on epoch=41
06/13/2022 02:36:51 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.49142609580219027 on epoch=41
06/13/2022 02:36:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.09 on epoch=42
06/13/2022 02:36:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
06/13/2022 02:36:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
06/13/2022 02:37:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=42
06/13/2022 02:37:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
06/13/2022 02:37:28 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8529068171117493 on epoch=42
06/13/2022 02:37:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
06/13/2022 02:37:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
06/13/2022 02:37:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=43
06/13/2022 02:37:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
06/13/2022 02:37:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
06/13/2022 02:38:04 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8503364384971528 on epoch=43
06/13/2022 02:38:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=43
06/13/2022 02:38:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
06/13/2022 02:38:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=44
06/13/2022 02:38:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 02:38:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
06/13/2022 02:38:39 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7454388000276846 on epoch=44
06/13/2022 02:38:41 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
06/13/2022 02:38:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
06/13/2022 02:38:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=45
06/13/2022 02:38:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=45
06/13/2022 02:38:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=45
06/13/2022 02:39:15 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7981567370140616 on epoch=45
06/13/2022 02:39:17 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
06/13/2022 02:39:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
06/13/2022 02:39:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 02:39:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
06/13/2022 02:39:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=46
06/13/2022 02:39:51 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8483917190677408 on epoch=46
06/13/2022 02:39:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=46
06/13/2022 02:39:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
06/13/2022 02:39:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
06/13/2022 02:40:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
06/13/2022 02:40:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
06/13/2022 02:40:27 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7774866664834074 on epoch=47
06/13/2022 02:40:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
06/13/2022 02:40:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
06/13/2022 02:40:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.33 on epoch=47
06/13/2022 02:40:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
06/13/2022 02:40:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
06/13/2022 02:41:03 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.7492476664969732 on epoch=48
06/13/2022 02:41:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=48
06/13/2022 02:41:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
06/13/2022 02:41:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=48
06/13/2022 02:41:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
06/13/2022 02:41:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
06/13/2022 02:41:38 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8383250597938645 on epoch=49
06/13/2022 02:41:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=49
06/13/2022 02:41:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
06/13/2022 02:41:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
06/13/2022 02:41:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
06/13/2022 02:41:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
06/13/2022 02:42:14 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.854354146968693 on epoch=49
06/13/2022 02:42:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
06/13/2022 02:42:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
06/13/2022 02:42:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
06/13/2022 02:42:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=50
06/13/2022 02:42:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.25 on epoch=50
06/13/2022 02:42:49 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.5323492260924791 on epoch=50
06/13/2022 02:42:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
06/13/2022 02:42:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
06/13/2022 02:42:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=51
06/13/2022 02:42:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
06/13/2022 02:43:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
06/13/2022 02:43:25 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7565823394662032 on epoch=51
06/13/2022 02:43:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=51
06/13/2022 02:43:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
06/13/2022 02:43:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
06/13/2022 02:43:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
06/13/2022 02:43:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
06/13/2022 02:44:02 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9145205173993245 on epoch=52
06/13/2022 02:44:04 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.29 on epoch=52
06/13/2022 02:44:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
06/13/2022 02:44:09 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
06/13/2022 02:44:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
06/13/2022 02:44:14 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=53
06/13/2022 02:44:16 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:44:16 - INFO - __main__ - Printing 3 examples
06/13/2022 02:44:16 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 02:44:16 - INFO - __main__ - ['Animal']
06/13/2022 02:44:16 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 02:44:16 - INFO - __main__ - ['Animal']
06/13/2022 02:44:16 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 02:44:16 - INFO - __main__ - ['Animal']
06/13/2022 02:44:16 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:44:16 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:44:17 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 02:44:17 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:44:17 - INFO - __main__ - Printing 3 examples
06/13/2022 02:44:17 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 02:44:17 - INFO - __main__ - ['Animal']
06/13/2022 02:44:17 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 02:44:17 - INFO - __main__ - ['Animal']
06/13/2022 02:44:17 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 02:44:17 - INFO - __main__ - ['Animal']
06/13/2022 02:44:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:44:18 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:44:19 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 02:44:34 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 02:44:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 02:44:35 - INFO - __main__ - Starting training!
06/13/2022 02:44:38 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.9160867341745844 on epoch=53
06/13/2022 02:44:38 - INFO - __main__ - save last model!
06/13/2022 02:44:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 02:44:38 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 02:44:38 - INFO - __main__ - Printing 3 examples
06/13/2022 02:44:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 02:44:38 - INFO - __main__ - ['Animal']
06/13/2022 02:44:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 02:44:38 - INFO - __main__ - ['Animal']
06/13/2022 02:44:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 02:44:38 - INFO - __main__ - ['Village']
06/13/2022 02:44:38 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:44:40 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:44:43 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 02:46:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.5_8_predictions.txt
06/13/2022 02:46:49 - INFO - __main__ - Classification-F1 on test data: 0.7239
06/13/2022 02:46:49 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.5, bsz=8, dev_performance=0.9765633021000945, test_performance=0.7238867222621256
06/13/2022 02:46:49 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.4, bsz=8 ...
06/13/2022 02:46:50 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:46:50 - INFO - __main__ - Printing 3 examples
06/13/2022 02:46:50 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 02:46:50 - INFO - __main__ - ['Animal']
06/13/2022 02:46:50 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 02:46:50 - INFO - __main__ - ['Animal']
06/13/2022 02:46:50 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 02:46:50 - INFO - __main__ - ['Animal']
06/13/2022 02:46:50 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:46:51 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:46:52 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 02:46:52 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 02:46:52 - INFO - __main__ - Printing 3 examples
06/13/2022 02:46:52 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 02:46:52 - INFO - __main__ - ['Animal']
06/13/2022 02:46:52 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 02:46:52 - INFO - __main__ - ['Animal']
06/13/2022 02:46:52 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 02:46:52 - INFO - __main__ - ['Animal']
06/13/2022 02:46:52 - INFO - __main__ - Tokenizing Input ...
06/13/2022 02:46:52 - INFO - __main__ - Tokenizing Output ...
06/13/2022 02:46:53 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 02:47:09 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 02:47:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 02:47:10 - INFO - __main__ - Starting training!
06/13/2022 02:47:13 - INFO - __main__ - Step 10 Global step 10 Train loss 4.64 on epoch=0
06/13/2022 02:47:16 - INFO - __main__ - Step 20 Global step 20 Train loss 2.72 on epoch=0
06/13/2022 02:47:18 - INFO - __main__ - Step 30 Global step 30 Train loss 2.17 on epoch=0
06/13/2022 02:47:21 - INFO - __main__ - Step 40 Global step 40 Train loss 1.76 on epoch=0
06/13/2022 02:47:23 - INFO - __main__ - Step 50 Global step 50 Train loss 1.45 on epoch=0
06/13/2022 02:47:47 - INFO - __main__ - Global step 50 Train loss 2.55 Classification-F1 0.13396558518248994 on epoch=0
06/13/2022 02:47:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13396558518248994 on epoch=0, global_step=50
06/13/2022 02:47:49 - INFO - __main__ - Step 60 Global step 60 Train loss 1.10 on epoch=1
06/13/2022 02:47:52 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=1
06/13/2022 02:47:54 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=1
06/13/2022 02:47:57 - INFO - __main__ - Step 90 Global step 90 Train loss 0.85 on epoch=1
06/13/2022 02:47:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.79 on epoch=1
06/13/2022 02:48:25 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.3381502533825832 on epoch=1
06/13/2022 02:48:25 - INFO - __main__ - Saving model with best Classification-F1: 0.13396558518248994 -> 0.3381502533825832 on epoch=1, global_step=100
06/13/2022 02:48:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=1
06/13/2022 02:48:30 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=2
06/13/2022 02:48:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=2
06/13/2022 02:48:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.51 on epoch=2
06/13/2022 02:48:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.53 on epoch=2
06/13/2022 02:49:04 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.4566836810504051 on epoch=2
06/13/2022 02:49:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3381502533825832 -> 0.4566836810504051 on epoch=2, global_step=150
06/13/2022 02:49:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.55 on epoch=2
06/13/2022 02:49:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.56 on epoch=3
06/13/2022 02:49:12 - INFO - __main__ - Step 180 Global step 180 Train loss 0.47 on epoch=3
06/13/2022 02:49:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=3
06/13/2022 02:49:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.43 on epoch=3
06/13/2022 02:49:49 - INFO - __main__ - Global step 200 Train loss 0.50 Classification-F1 0.539239184076845 on epoch=3
06/13/2022 02:49:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4566836810504051 -> 0.539239184076845 on epoch=3, global_step=200
06/13/2022 02:49:51 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=3
06/13/2022 02:49:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.43 on epoch=3
06/13/2022 02:49:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=4
06/13/2022 02:49:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.44 on epoch=4
06/13/2022 02:50:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=4
06/13/2022 02:50:31 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.5712392610051298 on epoch=4
06/13/2022 02:50:31 - INFO - __main__ - Saving model with best Classification-F1: 0.539239184076845 -> 0.5712392610051298 on epoch=4, global_step=250
06/13/2022 02:50:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=4
06/13/2022 02:50:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=4
06/13/2022 02:50:38 - INFO - __main__ - Step 280 Global step 280 Train loss 0.32 on epoch=4
06/13/2022 02:50:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.24 on epoch=5
06/13/2022 02:50:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=5
06/13/2022 02:51:15 - INFO - __main__ - Global step 300 Train loss 0.36 Classification-F1 0.5772717984888153 on epoch=5
06/13/2022 02:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5712392610051298 -> 0.5772717984888153 on epoch=5, global_step=300
06/13/2022 02:51:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=5
06/13/2022 02:51:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=5
06/13/2022 02:51:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.57 on epoch=5
06/13/2022 02:51:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=6
06/13/2022 02:51:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=6
06/13/2022 02:51:58 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.5704587457231329 on epoch=6
06/13/2022 02:52:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=6
06/13/2022 02:52:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=6
06/13/2022 02:52:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=6
06/13/2022 02:52:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.45 on epoch=6
06/13/2022 02:52:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=7
06/13/2022 02:52:42 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.666166554359764 on epoch=7
06/13/2022 02:52:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5772717984888153 -> 0.666166554359764 on epoch=7, global_step=400
06/13/2022 02:52:44 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=7
06/13/2022 02:52:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=7
06/13/2022 02:52:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=7
06/13/2022 02:52:52 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=7
06/13/2022 02:52:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=8
06/13/2022 02:53:24 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.6628549648579563 on epoch=8
06/13/2022 02:53:27 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=8
06/13/2022 02:53:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=8
06/13/2022 02:53:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=8
06/13/2022 02:53:34 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=8
06/13/2022 02:53:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=8
06/13/2022 02:54:07 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.6902066136330951 on epoch=8
06/13/2022 02:54:07 - INFO - __main__ - Saving model with best Classification-F1: 0.666166554359764 -> 0.6902066136330951 on epoch=8, global_step=500
06/13/2022 02:54:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=9
06/13/2022 02:54:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=9
06/13/2022 02:54:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=9
06/13/2022 02:54:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=9
06/13/2022 02:54:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.36 on epoch=9
06/13/2022 02:54:50 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.6362564610236161 on epoch=9
06/13/2022 02:54:53 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=9
06/13/2022 02:54:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=10
06/13/2022 02:54:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=10
06/13/2022 02:55:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=10
06/13/2022 02:55:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=10
06/13/2022 02:55:34 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.7375228851132983 on epoch=10
06/13/2022 02:55:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6902066136330951 -> 0.7375228851132983 on epoch=10, global_step=600
06/13/2022 02:55:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.39 on epoch=10
06/13/2022 02:55:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=11
06/13/2022 02:55:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=11
06/13/2022 02:55:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
06/13/2022 02:55:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=11
06/13/2022 02:56:19 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7361849886571867 on epoch=11
06/13/2022 02:56:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=11
06/13/2022 02:56:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=11
06/13/2022 02:56:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=12
06/13/2022 02:56:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=12
06/13/2022 02:56:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=12
06/13/2022 02:57:04 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.8331726789738165 on epoch=12
06/13/2022 02:57:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7375228851132983 -> 0.8331726789738165 on epoch=12, global_step=700
06/13/2022 02:57:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=12
06/13/2022 02:57:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=12
06/13/2022 02:57:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=13
06/13/2022 02:57:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=13
06/13/2022 02:57:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=13
06/13/2022 02:57:43 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6687514207877414 on epoch=13
06/13/2022 02:57:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=13
06/13/2022 02:57:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=13
06/13/2022 02:57:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=13
06/13/2022 02:57:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=14
06/13/2022 02:57:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=14
06/13/2022 02:58:24 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.8563897626072097 on epoch=14
06/13/2022 02:58:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8331726789738165 -> 0.8563897626072097 on epoch=14, global_step=800
06/13/2022 02:58:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=14
06/13/2022 02:58:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=14
06/13/2022 02:58:31 - INFO - __main__ - Step 830 Global step 830 Train loss 0.38 on epoch=14
06/13/2022 02:58:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=14
06/13/2022 02:58:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=15
06/13/2022 02:59:07 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.7589333878242216 on epoch=15
06/13/2022 02:59:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=15
06/13/2022 02:59:13 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=15
06/13/2022 02:59:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=15
06/13/2022 02:59:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=15
06/13/2022 02:59:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=16
06/13/2022 02:59:49 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.5559480451381201 on epoch=16
06/13/2022 02:59:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=16
06/13/2022 02:59:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=16
06/13/2022 02:59:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=16
06/13/2022 02:59:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=16
06/13/2022 03:00:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=16
06/13/2022 03:00:31 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.8004229794037748 on epoch=16
06/13/2022 03:00:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=17
06/13/2022 03:00:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=17
06/13/2022 03:00:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=17
06/13/2022 03:00:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=17
06/13/2022 03:00:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=17
06/13/2022 03:01:13 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.8001586409032552 on epoch=17
06/13/2022 03:01:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=18
06/13/2022 03:01:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=18
06/13/2022 03:01:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=18
06/13/2022 03:01:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=18
06/13/2022 03:01:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=18
06/13/2022 03:01:51 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.8378222555803967 on epoch=18
06/13/2022 03:01:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
06/13/2022 03:01:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=19
06/13/2022 03:01:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=19
06/13/2022 03:02:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=19
06/13/2022 03:02:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=19
06/13/2022 03:02:32 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.849394293269008 on epoch=19
06/13/2022 03:02:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=19
06/13/2022 03:02:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=19
06/13/2022 03:02:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
06/13/2022 03:02:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=20
06/13/2022 03:02:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=20
06/13/2022 03:03:12 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.8531268312478513 on epoch=20
06/13/2022 03:03:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=20
06/13/2022 03:03:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=20
06/13/2022 03:03:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=21
06/13/2022 03:03:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=21
06/13/2022 03:03:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=21
06/13/2022 03:03:53 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.9776296473411981 on epoch=21
06/13/2022 03:03:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8563897626072097 -> 0.9776296473411981 on epoch=21, global_step=1200
06/13/2022 03:03:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=21
06/13/2022 03:03:58 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=21
06/13/2022 03:04:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.27 on epoch=21
06/13/2022 03:04:03 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=22
06/13/2022 03:04:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=22
06/13/2022 03:04:35 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.7466768662412818 on epoch=22
06/13/2022 03:04:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=22
06/13/2022 03:04:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=22
06/13/2022 03:04:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=22
06/13/2022 03:04:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=23
06/13/2022 03:04:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=23
06/13/2022 03:05:14 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7448999704354744 on epoch=23
06/13/2022 03:05:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=23
06/13/2022 03:05:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=23
06/13/2022 03:05:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=23
06/13/2022 03:05:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=23
06/13/2022 03:05:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
06/13/2022 03:05:50 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.6578483977368083 on epoch=24
06/13/2022 03:05:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=24
06/13/2022 03:05:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=24
06/13/2022 03:05:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=24
06/13/2022 03:06:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=24
06/13/2022 03:06:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=24
06/13/2022 03:06:29 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9002151745286767 on epoch=24
06/13/2022 03:06:32 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=25
06/13/2022 03:06:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=25
06/13/2022 03:06:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=25
06/13/2022 03:06:39 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=25
06/13/2022 03:06:42 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.35 on epoch=25
06/13/2022 03:07:05 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.7455696259055044 on epoch=25
06/13/2022 03:07:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
06/13/2022 03:07:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
06/13/2022 03:07:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
06/13/2022 03:07:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=26
06/13/2022 03:07:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=26
06/13/2022 03:07:42 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.8191085336713773 on epoch=26
06/13/2022 03:07:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=26
06/13/2022 03:07:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=27
06/13/2022 03:07:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
06/13/2022 03:07:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=27
06/13/2022 03:07:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
06/13/2022 03:08:18 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.8499734413000173 on epoch=27
06/13/2022 03:08:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.38 on epoch=27
06/13/2022 03:08:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
06/13/2022 03:08:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
06/13/2022 03:08:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=28
06/13/2022 03:08:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
06/13/2022 03:08:54 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.8501668186033836 on epoch=28
06/13/2022 03:08:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=28
06/13/2022 03:08:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=28
06/13/2022 03:09:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=29
06/13/2022 03:09:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=29
06/13/2022 03:09:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=29
06/13/2022 03:09:30 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9145198147366248 on epoch=29
06/13/2022 03:09:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
06/13/2022 03:09:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.35 on epoch=29
06/13/2022 03:09:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
06/13/2022 03:09:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=30
06/13/2022 03:09:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=30
06/13/2022 03:10:07 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.7981901398292858 on epoch=30
06/13/2022 03:10:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=30
06/13/2022 03:10:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
06/13/2022 03:10:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=30
06/13/2022 03:10:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=31
06/13/2022 03:10:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=31
06/13/2022 03:10:45 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.7558304697677085 on epoch=31
06/13/2022 03:10:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
06/13/2022 03:10:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=31
06/13/2022 03:10:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=31
06/13/2022 03:10:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.32 on epoch=31
06/13/2022 03:10:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=32
06/13/2022 03:11:21 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.6142889338920279 on epoch=32
06/13/2022 03:11:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
06/13/2022 03:11:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=32
06/13/2022 03:11:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
06/13/2022 03:11:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.32 on epoch=32
06/13/2022 03:11:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=33
06/13/2022 03:11:57 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.7033405834104096 on epoch=33
06/13/2022 03:11:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
06/13/2022 03:12:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=33
06/13/2022 03:12:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=33
06/13/2022 03:12:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=33
06/13/2022 03:12:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=33
06/13/2022 03:12:32 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.672835104335966 on epoch=33
06/13/2022 03:12:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=34
06/13/2022 03:12:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=34
06/13/2022 03:12:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
06/13/2022 03:12:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
06/13/2022 03:12:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.28 on epoch=34
06/13/2022 03:13:08 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.7926632518579566 on epoch=34
06/13/2022 03:13:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=34
06/13/2022 03:13:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
06/13/2022 03:13:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
06/13/2022 03:13:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=35
06/13/2022 03:13:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
06/13/2022 03:13:45 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9787618439320858 on epoch=35
06/13/2022 03:13:45 - INFO - __main__ - Saving model with best Classification-F1: 0.9776296473411981 -> 0.9787618439320858 on epoch=35, global_step=2000
06/13/2022 03:13:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
06/13/2022 03:13:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
06/13/2022 03:13:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=36
06/13/2022 03:13:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=36
06/13/2022 03:13:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
06/13/2022 03:14:22 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.978731389834975 on epoch=36
06/13/2022 03:14:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=36
06/13/2022 03:14:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
06/13/2022 03:14:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
06/13/2022 03:14:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=37
06/13/2022 03:14:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
06/13/2022 03:14:57 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9086137685262368 on epoch=37
06/13/2022 03:15:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=37
06/13/2022 03:15:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=37
06/13/2022 03:15:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
06/13/2022 03:15:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
06/13/2022 03:15:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=38
06/13/2022 03:15:33 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8533811108053064 on epoch=38
06/13/2022 03:15:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=38
06/13/2022 03:15:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=38
06/13/2022 03:15:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=38
06/13/2022 03:15:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
06/13/2022 03:15:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=39
06/13/2022 03:16:09 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9122688182452631 on epoch=39
06/13/2022 03:16:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
06/13/2022 03:16:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=39
06/13/2022 03:16:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
06/13/2022 03:16:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
06/13/2022 03:16:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=40
06/13/2022 03:16:44 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9151215765177956 on epoch=40
06/13/2022 03:16:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=40
06/13/2022 03:16:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
06/13/2022 03:16:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
06/13/2022 03:16:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
06/13/2022 03:16:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 03:17:20 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9109756244014597 on epoch=41
06/13/2022 03:17:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=41
06/13/2022 03:17:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=41
06/13/2022 03:17:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=41
06/13/2022 03:17:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=41
06/13/2022 03:17:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
06/13/2022 03:17:56 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8492347893717169 on epoch=41
06/13/2022 03:17:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=42
06/13/2022 03:18:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
06/13/2022 03:18:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 03:18:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
06/13/2022 03:18:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
06/13/2022 03:18:32 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9113868269551985 on epoch=42
06/13/2022 03:18:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
06/13/2022 03:18:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
06/13/2022 03:18:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 03:18:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
06/13/2022 03:18:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=43
06/13/2022 03:19:07 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6325373126613617 on epoch=43
06/13/2022 03:19:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
06/13/2022 03:19:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=44
06/13/2022 03:19:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=44
06/13/2022 03:19:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 03:19:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
06/13/2022 03:19:42 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.748537751049881 on epoch=44
06/13/2022 03:19:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
06/13/2022 03:19:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
06/13/2022 03:19:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 03:19:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=45
06/13/2022 03:19:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
06/13/2022 03:20:16 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8496676545302584 on epoch=45
06/13/2022 03:20:19 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=45
06/13/2022 03:20:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=45
06/13/2022 03:20:24 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
06/13/2022 03:20:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
06/13/2022 03:20:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
06/13/2022 03:20:52 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8046726542208065 on epoch=46
06/13/2022 03:20:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
06/13/2022 03:20:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
06/13/2022 03:20:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.33 on epoch=46
06/13/2022 03:21:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=47
06/13/2022 03:21:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
06/13/2022 03:21:26 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.7199373120738547 on epoch=47
06/13/2022 03:21:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 03:21:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
06/13/2022 03:21:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.25 on epoch=47
06/13/2022 03:21:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
06/13/2022 03:21:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
06/13/2022 03:22:01 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6468852545946951 on epoch=48
06/13/2022 03:22:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
06/13/2022 03:22:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=48
06/13/2022 03:22:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
06/13/2022 03:22:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
06/13/2022 03:22:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
06/13/2022 03:22:37 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9098240225692192 on epoch=49
06/13/2022 03:22:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=49
06/13/2022 03:22:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
06/13/2022 03:22:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=49
06/13/2022 03:22:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
06/13/2022 03:22:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 03:23:12 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8056451716310212 on epoch=49
06/13/2022 03:23:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=50
06/13/2022 03:23:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
06/13/2022 03:23:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
06/13/2022 03:23:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
06/13/2022 03:23:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=50
06/13/2022 03:23:47 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7116629094540508 on epoch=50
06/13/2022 03:23:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=51
06/13/2022 03:23:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
06/13/2022 03:23:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
06/13/2022 03:23:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
06/13/2022 03:24:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
06/13/2022 03:24:22 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7849757126811555 on epoch=51
06/13/2022 03:24:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
06/13/2022 03:24:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
06/13/2022 03:24:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=52
06/13/2022 03:24:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=52
06/13/2022 03:24:35 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
06/13/2022 03:24:58 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8000310027076342 on epoch=52
06/13/2022 03:25:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=52
06/13/2022 03:25:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
06/13/2022 03:25:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=53
06/13/2022 03:25:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
06/13/2022 03:25:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=53
06/13/2022 03:25:12 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 03:25:12 - INFO - __main__ - Printing 3 examples
06/13/2022 03:25:12 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 03:25:12 - INFO - __main__ - ['Animal']
06/13/2022 03:25:12 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 03:25:12 - INFO - __main__ - ['Animal']
06/13/2022 03:25:12 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 03:25:12 - INFO - __main__ - ['Animal']
06/13/2022 03:25:12 - INFO - __main__ - Tokenizing Input ...
06/13/2022 03:25:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 03:25:13 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 03:25:13 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 03:25:13 - INFO - __main__ - Printing 3 examples
06/13/2022 03:25:13 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 03:25:13 - INFO - __main__ - ['Animal']
06/13/2022 03:25:13 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 03:25:13 - INFO - __main__ - ['Animal']
06/13/2022 03:25:13 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 03:25:13 - INFO - __main__ - ['Animal']
06/13/2022 03:25:13 - INFO - __main__ - Tokenizing Input ...
06/13/2022 03:25:14 - INFO - __main__ - Tokenizing Output ...
06/13/2022 03:25:15 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 03:25:30 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 03:25:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 03:25:31 - INFO - __main__ - Starting training!
06/13/2022 03:25:34 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.9124230597769044 on epoch=53
06/13/2022 03:25:34 - INFO - __main__ - save last model!
06/13/2022 03:25:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 03:25:35 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 03:25:35 - INFO - __main__ - Printing 3 examples
06/13/2022 03:25:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 03:25:35 - INFO - __main__ - ['Animal']
06/13/2022 03:25:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 03:25:35 - INFO - __main__ - ['Animal']
06/13/2022 03:25:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 03:25:35 - INFO - __main__ - ['Village']
06/13/2022 03:25:35 - INFO - __main__ - Tokenizing Input ...
06/13/2022 03:25:36 - INFO - __main__ - Tokenizing Output ...
06/13/2022 03:25:40 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 03:27:47 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.4_8_predictions.txt
06/13/2022 03:27:47 - INFO - __main__ - Classification-F1 on test data: 0.7608
06/13/2022 03:27:47 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.4, bsz=8, dev_performance=0.9787618439320858, test_performance=0.7608159618095071
06/13/2022 03:27:47 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.3, bsz=8 ...
06/13/2022 03:27:48 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 03:27:48 - INFO - __main__ - Printing 3 examples
06/13/2022 03:27:48 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 03:27:48 - INFO - __main__ - ['Animal']
06/13/2022 03:27:48 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 03:27:48 - INFO - __main__ - ['Animal']
06/13/2022 03:27:48 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 03:27:48 - INFO - __main__ - ['Animal']
06/13/2022 03:27:48 - INFO - __main__ - Tokenizing Input ...
06/13/2022 03:27:49 - INFO - __main__ - Tokenizing Output ...
06/13/2022 03:27:50 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 03:27:50 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 03:27:50 - INFO - __main__ - Printing 3 examples
06/13/2022 03:27:50 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 03:27:50 - INFO - __main__ - ['Animal']
06/13/2022 03:27:50 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 03:27:50 - INFO - __main__ - ['Animal']
06/13/2022 03:27:50 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 03:27:50 - INFO - __main__ - ['Animal']
06/13/2022 03:27:50 - INFO - __main__ - Tokenizing Input ...
06/13/2022 03:27:50 - INFO - __main__ - Tokenizing Output ...
06/13/2022 03:27:51 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 03:28:06 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 03:28:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 03:28:07 - INFO - __main__ - Starting training!
06/13/2022 03:28:11 - INFO - __main__ - Step 10 Global step 10 Train loss 4.96 on epoch=0
06/13/2022 03:28:13 - INFO - __main__ - Step 20 Global step 20 Train loss 3.45 on epoch=0
06/13/2022 03:28:16 - INFO - __main__ - Step 30 Global step 30 Train loss 2.91 on epoch=0
06/13/2022 03:28:18 - INFO - __main__ - Step 40 Global step 40 Train loss 2.83 on epoch=0
06/13/2022 03:28:21 - INFO - __main__ - Step 50 Global step 50 Train loss 2.67 on epoch=0
06/13/2022 03:28:41 - INFO - __main__ - Global step 50 Train loss 3.36 Classification-F1 0.032797944615423034 on epoch=0
06/13/2022 03:28:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.032797944615423034 on epoch=0, global_step=50
06/13/2022 03:28:44 - INFO - __main__ - Step 60 Global step 60 Train loss 2.59 on epoch=1
06/13/2022 03:28:46 - INFO - __main__ - Step 70 Global step 70 Train loss 2.14 on epoch=1
06/13/2022 03:28:49 - INFO - __main__ - Step 80 Global step 80 Train loss 1.81 on epoch=1
06/13/2022 03:28:51 - INFO - __main__ - Step 90 Global step 90 Train loss 1.74 on epoch=1
06/13/2022 03:28:54 - INFO - __main__ - Step 100 Global step 100 Train loss 1.65 on epoch=1
06/13/2022 03:29:15 - INFO - __main__ - Global step 100 Train loss 1.98 Classification-F1 0.08175526473555013 on epoch=1
06/13/2022 03:29:16 - INFO - __main__ - Saving model with best Classification-F1: 0.032797944615423034 -> 0.08175526473555013 on epoch=1, global_step=100
06/13/2022 03:29:18 - INFO - __main__ - Step 110 Global step 110 Train loss 1.39 on epoch=1
06/13/2022 03:29:20 - INFO - __main__ - Step 120 Global step 120 Train loss 1.42 on epoch=2
06/13/2022 03:29:23 - INFO - __main__ - Step 130 Global step 130 Train loss 1.18 on epoch=2
06/13/2022 03:29:26 - INFO - __main__ - Step 140 Global step 140 Train loss 1.01 on epoch=2
06/13/2022 03:29:28 - INFO - __main__ - Step 150 Global step 150 Train loss 1.11 on epoch=2
06/13/2022 03:29:56 - INFO - __main__ - Global step 150 Train loss 1.22 Classification-F1 0.2538483464824745 on epoch=2
06/13/2022 03:29:56 - INFO - __main__ - Saving model with best Classification-F1: 0.08175526473555013 -> 0.2538483464824745 on epoch=2, global_step=150
06/13/2022 03:29:59 - INFO - __main__ - Step 160 Global step 160 Train loss 1.07 on epoch=2
06/13/2022 03:30:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.81 on epoch=3
06/13/2022 03:30:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=3
06/13/2022 03:30:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=3
06/13/2022 03:30:09 - INFO - __main__ - Step 200 Global step 200 Train loss 0.76 on epoch=3
06/13/2022 03:30:34 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.3613947553962214 on epoch=3
06/13/2022 03:30:34 - INFO - __main__ - Saving model with best Classification-F1: 0.2538483464824745 -> 0.3613947553962214 on epoch=3, global_step=200
06/13/2022 03:30:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=3
06/13/2022 03:30:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.98 on epoch=3
06/13/2022 03:30:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.70 on epoch=4
06/13/2022 03:30:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=4
06/13/2022 03:30:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=4
06/13/2022 03:31:13 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.4099360934464476 on epoch=4
06/13/2022 03:31:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3613947553962214 -> 0.4099360934464476 on epoch=4, global_step=250
06/13/2022 03:31:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=4
06/13/2022 03:31:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=4
06/13/2022 03:31:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=4
06/13/2022 03:31:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=5
06/13/2022 03:31:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=5
06/13/2022 03:31:54 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.511595893503322 on epoch=5
06/13/2022 03:31:54 - INFO - __main__ - Saving model with best Classification-F1: 0.4099360934464476 -> 0.511595893503322 on epoch=5, global_step=300
06/13/2022 03:31:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=5
06/13/2022 03:31:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=5
06/13/2022 03:32:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.79 on epoch=5
06/13/2022 03:32:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=6
06/13/2022 03:32:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=6
06/13/2022 03:32:37 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.49774875953641273 on epoch=6
06/13/2022 03:32:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=6
06/13/2022 03:32:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=6
06/13/2022 03:32:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.48 on epoch=6
06/13/2022 03:32:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=6
06/13/2022 03:32:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=7
06/13/2022 03:33:18 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.5371939326614701 on epoch=7
06/13/2022 03:33:18 - INFO - __main__ - Saving model with best Classification-F1: 0.511595893503322 -> 0.5371939326614701 on epoch=7, global_step=400
06/13/2022 03:33:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=7
06/13/2022 03:33:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=7
06/13/2022 03:33:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=7
06/13/2022 03:33:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=7
06/13/2022 03:33:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=8
06/13/2022 03:34:00 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.6720612857562428 on epoch=8
06/13/2022 03:34:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5371939326614701 -> 0.6720612857562428 on epoch=8, global_step=450
06/13/2022 03:34:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=8
06/13/2022 03:34:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=8
06/13/2022 03:34:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=8
06/13/2022 03:34:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=8
06/13/2022 03:34:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.49 on epoch=8
06/13/2022 03:34:42 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.5941768725004136 on epoch=8
06/13/2022 03:34:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=9
06/13/2022 03:34:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=9
06/13/2022 03:34:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=9
06/13/2022 03:34:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=9
06/13/2022 03:34:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=9
06/13/2022 03:35:24 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.6105854646583706 on epoch=9
06/13/2022 03:35:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=9
06/13/2022 03:35:29 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=10
06/13/2022 03:35:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=10
06/13/2022 03:35:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=10
06/13/2022 03:35:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=10
06/13/2022 03:36:06 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.7328919760673509 on epoch=10
06/13/2022 03:36:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6720612857562428 -> 0.7328919760673509 on epoch=10, global_step=600
06/13/2022 03:36:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.43 on epoch=10
06/13/2022 03:36:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=11
06/13/2022 03:36:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=11
06/13/2022 03:36:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=11
06/13/2022 03:36:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=11
06/13/2022 03:36:48 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6512406759950427 on epoch=11
06/13/2022 03:36:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=11
06/13/2022 03:36:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=11
06/13/2022 03:36:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=12
06/13/2022 03:36:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=12
06/13/2022 03:37:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=12
06/13/2022 03:37:33 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.8389129600966461 on epoch=12
06/13/2022 03:37:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7328919760673509 -> 0.8389129600966461 on epoch=12, global_step=700
06/13/2022 03:37:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=12
06/13/2022 03:37:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=12
06/13/2022 03:37:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=13
06/13/2022 03:37:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=13
06/13/2022 03:37:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=13
06/13/2022 03:38:19 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.61918953475853 on epoch=13
06/13/2022 03:38:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=13
06/13/2022 03:38:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=13
06/13/2022 03:38:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.44 on epoch=13
06/13/2022 03:38:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=14
06/13/2022 03:38:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=14
06/13/2022 03:39:03 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.7592309799639104 on epoch=14
06/13/2022 03:39:05 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=14
06/13/2022 03:39:08 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=14
06/13/2022 03:39:10 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=14
06/13/2022 03:39:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=14
06/13/2022 03:39:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=15
06/13/2022 03:39:48 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.5817964893267096 on epoch=15
06/13/2022 03:39:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=15
06/13/2022 03:39:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=15
06/13/2022 03:39:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=15
06/13/2022 03:39:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.41 on epoch=15
06/13/2022 03:40:01 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=16
06/13/2022 03:40:30 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.6031799484774469 on epoch=16
06/13/2022 03:40:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=16
06/13/2022 03:40:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=16
06/13/2022 03:40:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=16
06/13/2022 03:40:40 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=16
06/13/2022 03:40:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=16
06/13/2022 03:41:15 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.6516640032180655 on epoch=16
06/13/2022 03:41:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=17
06/13/2022 03:41:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=17
06/13/2022 03:41:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=17
06/13/2022 03:41:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=17
06/13/2022 03:41:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.33 on epoch=17
06/13/2022 03:41:58 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6716554874772582 on epoch=17
06/13/2022 03:42:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=18
06/13/2022 03:42:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=18
06/13/2022 03:42:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=18
06/13/2022 03:42:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=18
06/13/2022 03:42:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=18
06/13/2022 03:42:43 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.8917822490043328 on epoch=18
06/13/2022 03:42:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8389129600966461 -> 0.8917822490043328 on epoch=18, global_step=1050
06/13/2022 03:42:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.32 on epoch=18
06/13/2022 03:42:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=19
06/13/2022 03:42:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=19
06/13/2022 03:42:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=19
06/13/2022 03:42:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=19
06/13/2022 03:43:27 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.84651256676055 on epoch=19
06/13/2022 03:43:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=19
06/13/2022 03:43:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=19
06/13/2022 03:43:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=20
06/13/2022 03:43:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=20
06/13/2022 03:43:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=20
06/13/2022 03:44:12 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7310486783749104 on epoch=20
06/13/2022 03:44:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=20
06/13/2022 03:44:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=20
06/13/2022 03:44:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=21
06/13/2022 03:44:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=21
06/13/2022 03:44:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=21
06/13/2022 03:44:55 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.7150955106440762 on epoch=21
06/13/2022 03:44:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=21
06/13/2022 03:45:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=21
06/13/2022 03:45:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.42 on epoch=21
06/13/2022 03:45:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=22
06/13/2022 03:45:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=22
06/13/2022 03:45:38 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.5635089088325236 on epoch=22
06/13/2022 03:45:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=22
06/13/2022 03:45:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=22
06/13/2022 03:45:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=22
06/13/2022 03:45:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
06/13/2022 03:45:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
06/13/2022 03:46:20 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.6859787392284932 on epoch=23
06/13/2022 03:46:22 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=23
06/13/2022 03:46:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=23
06/13/2022 03:46:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=23
06/13/2022 03:46:30 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=23
06/13/2022 03:46:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=24
06/13/2022 03:47:01 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7166240030786161 on epoch=24
06/13/2022 03:47:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=24
06/13/2022 03:47:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=24
06/13/2022 03:47:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=24
06/13/2022 03:47:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=24
06/13/2022 03:47:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=24
06/13/2022 03:47:41 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.7069395054695378 on epoch=24
06/13/2022 03:47:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=25
06/13/2022 03:47:47 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=25
06/13/2022 03:47:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
06/13/2022 03:47:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=25
06/13/2022 03:47:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.37 on epoch=25
06/13/2022 03:48:22 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.7806799006421081 on epoch=25
06/13/2022 03:48:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
06/13/2022 03:48:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=26
06/13/2022 03:48:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
06/13/2022 03:48:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
06/13/2022 03:48:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=26
06/13/2022 03:49:01 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6621697905292715 on epoch=26
06/13/2022 03:49:03 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.36 on epoch=26
06/13/2022 03:49:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=27
06/13/2022 03:49:08 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=27
06/13/2022 03:49:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=27
06/13/2022 03:49:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=27
06/13/2022 03:49:40 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.79575020711396 on epoch=27
06/13/2022 03:49:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.30 on epoch=27
06/13/2022 03:49:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=28
06/13/2022 03:49:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=28
06/13/2022 03:49:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=28
06/13/2022 03:49:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
06/13/2022 03:50:20 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.8538504413035692 on epoch=28
06/13/2022 03:50:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=28
06/13/2022 03:50:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.39 on epoch=28
06/13/2022 03:50:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
06/13/2022 03:50:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
06/13/2022 03:50:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
06/13/2022 03:50:59 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.5346160693237456 on epoch=29
06/13/2022 03:51:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=29
06/13/2022 03:51:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.29 on epoch=29
06/13/2022 03:51:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
06/13/2022 03:51:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=30
06/13/2022 03:51:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=30
06/13/2022 03:51:40 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.6149918446532776 on epoch=30
06/13/2022 03:51:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=30
06/13/2022 03:51:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=30
06/13/2022 03:51:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.33 on epoch=30
06/13/2022 03:51:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=31
06/13/2022 03:51:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=31
06/13/2022 03:52:18 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.6674362201394523 on epoch=31
06/13/2022 03:52:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
06/13/2022 03:52:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
06/13/2022 03:52:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=31
06/13/2022 03:52:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.32 on epoch=31
06/13/2022 03:52:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=32
06/13/2022 03:52:57 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.4699470421027986 on epoch=32
06/13/2022 03:52:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
06/13/2022 03:53:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=32
06/13/2022 03:53:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=32
06/13/2022 03:53:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.30 on epoch=32
06/13/2022 03:53:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=33
06/13/2022 03:53:33 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.6815977342720988 on epoch=33
06/13/2022 03:53:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
06/13/2022 03:53:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=33
06/13/2022 03:53:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=33
06/13/2022 03:53:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=33
06/13/2022 03:53:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.38 on epoch=33
06/13/2022 03:54:09 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.5068104066667789 on epoch=33
06/13/2022 03:54:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
06/13/2022 03:54:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=34
06/13/2022 03:54:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
06/13/2022 03:54:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=34
06/13/2022 03:54:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=34
06/13/2022 03:54:46 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7688170306349928 on epoch=34
06/13/2022 03:54:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=34
06/13/2022 03:54:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=35
06/13/2022 03:54:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=35
06/13/2022 03:54:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=35
06/13/2022 03:54:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=35
06/13/2022 03:55:25 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7991152592312919 on epoch=35
06/13/2022 03:55:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.34 on epoch=35
06/13/2022 03:55:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=36
06/13/2022 03:55:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
06/13/2022 03:55:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=36
06/13/2022 03:55:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
06/13/2022 03:56:02 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.5360312530268441 on epoch=36
06/13/2022 03:56:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
06/13/2022 03:56:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=36
06/13/2022 03:56:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
06/13/2022 03:56:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=37
06/13/2022 03:56:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=37
06/13/2022 03:56:42 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.5547800676610067 on epoch=37
06/13/2022 03:56:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
06/13/2022 03:56:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=37
06/13/2022 03:56:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=38
06/13/2022 03:56:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=38
06/13/2022 03:56:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
06/13/2022 03:57:22 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6995986515793021 on epoch=38
06/13/2022 03:57:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
06/13/2022 03:57:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=38
06/13/2022 03:57:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=38
06/13/2022 03:57:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
06/13/2022 03:57:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
06/13/2022 03:57:58 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7899246578862059 on epoch=39
06/13/2022 03:58:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
06/13/2022 03:58:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
06/13/2022 03:58:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.31 on epoch=39
06/13/2022 03:58:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=39
06/13/2022 03:58:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=40
06/13/2022 03:58:36 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.6943656085032331 on epoch=40
06/13/2022 03:58:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 03:58:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
06/13/2022 03:58:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
06/13/2022 03:58:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.26 on epoch=40
06/13/2022 03:58:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=41
06/13/2022 03:59:11 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.6880599381319051 on epoch=41
06/13/2022 03:59:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=41
06/13/2022 03:59:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
06/13/2022 03:59:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=41
06/13/2022 03:59:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 03:59:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.27 on epoch=41
06/13/2022 03:59:47 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7567548573277169 on epoch=41
06/13/2022 03:59:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=42
06/13/2022 03:59:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
06/13/2022 03:59:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=42
06/13/2022 03:59:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
06/13/2022 04:00:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.30 on epoch=42
06/13/2022 04:00:24 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.7536256928942977 on epoch=42
06/13/2022 04:00:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
06/13/2022 04:00:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
06/13/2022 04:00:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
06/13/2022 04:00:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=43
06/13/2022 04:00:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
06/13/2022 04:01:00 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.5723099313983913 on epoch=43
06/13/2022 04:01:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
06/13/2022 04:01:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
06/13/2022 04:01:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
06/13/2022 04:01:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 04:01:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
06/13/2022 04:01:37 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8294531500823519 on epoch=44
06/13/2022 04:01:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.29 on epoch=44
06/13/2022 04:01:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
06/13/2022 04:01:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 04:01:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=45
06/13/2022 04:01:49 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=45
06/13/2022 04:02:13 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.638931761380429 on epoch=45
06/13/2022 04:02:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
06/13/2022 04:02:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.29 on epoch=45
06/13/2022 04:02:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
06/13/2022 04:02:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
06/13/2022 04:02:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
06/13/2022 04:02:50 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.712337968360983 on epoch=46
06/13/2022 04:02:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=46
06/13/2022 04:02:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
06/13/2022 04:02:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.30 on epoch=46
06/13/2022 04:03:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
06/13/2022 04:03:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=47
06/13/2022 04:03:26 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.5843681988048175 on epoch=47
06/13/2022 04:03:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
06/13/2022 04:03:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=47
06/13/2022 04:03:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.27 on epoch=47
06/13/2022 04:03:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
06/13/2022 04:03:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
06/13/2022 04:04:01 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.534321194588308 on epoch=48
06/13/2022 04:04:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=48
06/13/2022 04:04:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
06/13/2022 04:04:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
06/13/2022 04:04:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.22 on epoch=48
06/13/2022 04:04:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
06/13/2022 04:04:37 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.5241050714076675 on epoch=49
06/13/2022 04:04:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
06/13/2022 04:04:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
06/13/2022 04:04:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
06/13/2022 04:04:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
06/13/2022 04:04:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
06/13/2022 04:05:13 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5186167455486902 on epoch=49
06/13/2022 04:05:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
06/13/2022 04:05:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
06/13/2022 04:05:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
06/13/2022 04:05:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
06/13/2022 04:05:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.31 on epoch=50
06/13/2022 04:05:49 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.510067861917164 on epoch=50
06/13/2022 04:05:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
06/13/2022 04:05:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
06/13/2022 04:05:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
06/13/2022 04:06:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=51
06/13/2022 04:06:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
06/13/2022 04:06:26 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.49966369309921493 on epoch=51
06/13/2022 04:06:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
06/13/2022 04:06:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=52
06/13/2022 04:06:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
06/13/2022 04:06:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
06/13/2022 04:06:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=52
06/13/2022 04:07:03 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6767571669367289 on epoch=52
06/13/2022 04:07:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.31 on epoch=52
06/13/2022 04:07:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=53
06/13/2022 04:07:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
06/13/2022 04:07:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
06/13/2022 04:07:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 04:07:17 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:07:17 - INFO - __main__ - Printing 3 examples
06/13/2022 04:07:17 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 04:07:17 - INFO - __main__ - ['Animal']
06/13/2022 04:07:17 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 04:07:17 - INFO - __main__ - ['Animal']
06/13/2022 04:07:17 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 04:07:17 - INFO - __main__ - ['Animal']
06/13/2022 04:07:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:07:18 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:07:19 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 04:07:19 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:07:19 - INFO - __main__ - Printing 3 examples
06/13/2022 04:07:19 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 04:07:19 - INFO - __main__ - ['Animal']
06/13/2022 04:07:19 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 04:07:19 - INFO - __main__ - ['Animal']
06/13/2022 04:07:19 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 04:07:19 - INFO - __main__ - ['Animal']
06/13/2022 04:07:19 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:07:19 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:07:20 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 04:07:39 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 04:07:39 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.4904088439183376 on epoch=53
06/13/2022 04:07:39 - INFO - __main__ - save last model!
06/13/2022 04:07:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 04:07:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 04:07:39 - INFO - __main__ - Printing 3 examples
06/13/2022 04:07:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 04:07:39 - INFO - __main__ - ['Animal']
06/13/2022 04:07:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 04:07:39 - INFO - __main__ - ['Animal']
06/13/2022 04:07:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 04:07:39 - INFO - __main__ - ['Village']
06/13/2022 04:07:39 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:07:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 04:07:40 - INFO - __main__ - Starting training!
06/13/2022 04:07:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:07:45 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 04:09:41 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.3_8_predictions.txt
06/13/2022 04:09:41 - INFO - __main__ - Classification-F1 on test data: 0.3663
06/13/2022 04:09:42 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.3, bsz=8, dev_performance=0.8917822490043328, test_performance=0.36630690045177267
06/13/2022 04:09:42 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.2, bsz=8 ...
06/13/2022 04:09:43 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:09:43 - INFO - __main__ - Printing 3 examples
06/13/2022 04:09:43 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/13/2022 04:09:43 - INFO - __main__ - ['Animal']
06/13/2022 04:09:43 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/13/2022 04:09:43 - INFO - __main__ - ['Animal']
06/13/2022 04:09:43 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/13/2022 04:09:43 - INFO - __main__ - ['Animal']
06/13/2022 04:09:43 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:09:43 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:09:44 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 04:09:44 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:09:44 - INFO - __main__ - Printing 3 examples
06/13/2022 04:09:44 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
06/13/2022 04:09:44 - INFO - __main__ - ['Animal']
06/13/2022 04:09:44 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
06/13/2022 04:09:44 - INFO - __main__ - ['Animal']
06/13/2022 04:09:44 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
06/13/2022 04:09:44 - INFO - __main__ - ['Animal']
06/13/2022 04:09:44 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:09:45 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:09:45 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 04:10:01 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 04:10:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 04:10:01 - INFO - __main__ - Starting training!
06/13/2022 04:10:05 - INFO - __main__ - Step 10 Global step 10 Train loss 5.45 on epoch=0
06/13/2022 04:10:07 - INFO - __main__ - Step 20 Global step 20 Train loss 3.71 on epoch=0
06/13/2022 04:10:10 - INFO - __main__ - Step 30 Global step 30 Train loss 3.00 on epoch=0
06/13/2022 04:10:13 - INFO - __main__ - Step 40 Global step 40 Train loss 2.69 on epoch=0
06/13/2022 04:10:15 - INFO - __main__ - Step 50 Global step 50 Train loss 2.25 on epoch=0
06/13/2022 04:10:36 - INFO - __main__ - Global step 50 Train loss 3.42 Classification-F1 0.05651155737492845 on epoch=0
06/13/2022 04:10:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05651155737492845 on epoch=0, global_step=50
06/13/2022 04:10:39 - INFO - __main__ - Step 60 Global step 60 Train loss 1.80 on epoch=1
06/13/2022 04:10:41 - INFO - __main__ - Step 70 Global step 70 Train loss 1.41 on epoch=1
06/13/2022 04:10:44 - INFO - __main__ - Step 80 Global step 80 Train loss 1.36 on epoch=1
06/13/2022 04:10:46 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=1
06/13/2022 04:10:49 - INFO - __main__ - Step 100 Global step 100 Train loss 1.08 on epoch=1
06/13/2022 04:11:14 - INFO - __main__ - Global step 100 Train loss 1.38 Classification-F1 0.33556259325239063 on epoch=1
06/13/2022 04:11:14 - INFO - __main__ - Saving model with best Classification-F1: 0.05651155737492845 -> 0.33556259325239063 on epoch=1, global_step=100
06/13/2022 04:11:17 - INFO - __main__ - Step 110 Global step 110 Train loss 1.16 on epoch=1
06/13/2022 04:11:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=2
06/13/2022 04:11:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=2
06/13/2022 04:11:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=2
06/13/2022 04:11:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.69 on epoch=2
06/13/2022 04:11:53 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.49612838700269873 on epoch=2
06/13/2022 04:11:53 - INFO - __main__ - Saving model with best Classification-F1: 0.33556259325239063 -> 0.49612838700269873 on epoch=2, global_step=150
06/13/2022 04:11:56 - INFO - __main__ - Step 160 Global step 160 Train loss 0.90 on epoch=2
06/13/2022 04:11:58 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=3
06/13/2022 04:12:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.59 on epoch=3
06/13/2022 04:12:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=3
06/13/2022 04:12:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.64 on epoch=3
06/13/2022 04:12:31 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.5607751803897573 on epoch=3
06/13/2022 04:12:31 - INFO - __main__ - Saving model with best Classification-F1: 0.49612838700269873 -> 0.5607751803897573 on epoch=3, global_step=200
06/13/2022 04:12:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=3
06/13/2022 04:12:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=3
06/13/2022 04:12:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=4
06/13/2022 04:12:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=4
06/13/2022 04:12:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=4
06/13/2022 04:13:11 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.59736310813009 on epoch=4
06/13/2022 04:13:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5607751803897573 -> 0.59736310813009 on epoch=4, global_step=250
06/13/2022 04:13:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=4
06/13/2022 04:13:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=4
06/13/2022 04:13:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=4
06/13/2022 04:13:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=5
06/13/2022 04:13:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=5
06/13/2022 04:13:51 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.5748111291247879 on epoch=5
06/13/2022 04:13:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=5
06/13/2022 04:13:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=5
06/13/2022 04:13:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.48 on epoch=5
06/13/2022 04:14:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=6
06/13/2022 04:14:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=6
06/13/2022 04:14:30 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.5936029394969655 on epoch=6
06/13/2022 04:14:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.36 on epoch=6
06/13/2022 04:14:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=6
06/13/2022 04:14:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=6
06/13/2022 04:14:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.59 on epoch=6
06/13/2022 04:14:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=7
06/13/2022 04:15:08 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.6241449192441051 on epoch=7
06/13/2022 04:15:08 - INFO - __main__ - Saving model with best Classification-F1: 0.59736310813009 -> 0.6241449192441051 on epoch=7, global_step=400
06/13/2022 04:15:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=7
06/13/2022 04:15:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=7
06/13/2022 04:15:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=7
06/13/2022 04:15:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=7
06/13/2022 04:15:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=8
06/13/2022 04:15:50 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.6490854761113158 on epoch=8
06/13/2022 04:15:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6241449192441051 -> 0.6490854761113158 on epoch=8, global_step=450
06/13/2022 04:15:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=8
06/13/2022 04:15:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=8
06/13/2022 04:15:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=8
06/13/2022 04:16:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=8
06/13/2022 04:16:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.51 on epoch=8
06/13/2022 04:16:32 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.7824805853579541 on epoch=8
06/13/2022 04:16:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6490854761113158 -> 0.7824805853579541 on epoch=8, global_step=500
06/13/2022 04:16:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=9
06/13/2022 04:16:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=9
06/13/2022 04:16:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=9
06/13/2022 04:16:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=9
06/13/2022 04:16:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.49 on epoch=9
06/13/2022 04:17:12 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.7120959782881425 on epoch=9
06/13/2022 04:17:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=9
06/13/2022 04:17:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=10
06/13/2022 04:17:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=10
06/13/2022 04:17:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=10
06/13/2022 04:17:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=10
06/13/2022 04:17:54 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6987606379278851 on epoch=10
06/13/2022 04:17:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=10
06/13/2022 04:17:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=11
06/13/2022 04:18:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=11
06/13/2022 04:18:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=11
06/13/2022 04:18:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=11
06/13/2022 04:18:34 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.7266228062339876 on epoch=11
06/13/2022 04:18:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=11
06/13/2022 04:18:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=11
06/13/2022 04:18:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=12
06/13/2022 04:18:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=12
06/13/2022 04:18:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=12
06/13/2022 04:19:14 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.7928778304846427 on epoch=12
06/13/2022 04:19:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7824805853579541 -> 0.7928778304846427 on epoch=12, global_step=700
06/13/2022 04:19:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=12
06/13/2022 04:19:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.49 on epoch=12
06/13/2022 04:19:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=13
06/13/2022 04:19:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=13
06/13/2022 04:19:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=13
06/13/2022 04:19:55 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.7105418523959119 on epoch=13
06/13/2022 04:19:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=13
06/13/2022 04:20:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=13
06/13/2022 04:20:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=13
06/13/2022 04:20:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=14
06/13/2022 04:20:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=14
06/13/2022 04:20:35 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.7921776686616168 on epoch=14
06/13/2022 04:20:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=14
06/13/2022 04:20:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=14
06/13/2022 04:20:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=14
06/13/2022 04:20:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=14
06/13/2022 04:20:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=15
06/13/2022 04:21:15 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.7160783212251541 on epoch=15
06/13/2022 04:21:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=15
06/13/2022 04:21:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=15
06/13/2022 04:21:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=15
06/13/2022 04:21:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=15
06/13/2022 04:21:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=16
06/13/2022 04:21:53 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.9119451160857308 on epoch=16
06/13/2022 04:21:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7928778304846427 -> 0.9119451160857308 on epoch=16, global_step=900
06/13/2022 04:21:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=16
06/13/2022 04:21:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=16
06/13/2022 04:22:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=16
06/13/2022 04:22:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=16
06/13/2022 04:22:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=16
06/13/2022 04:22:34 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.8514803095364241 on epoch=16
06/13/2022 04:22:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=17
06/13/2022 04:22:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=17
06/13/2022 04:22:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=17
06/13/2022 04:22:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=17
06/13/2022 04:22:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.41 on epoch=17
06/13/2022 04:23:14 - INFO - __main__ - Global step 1000 Train loss 0.20 Classification-F1 0.7903062018084606 on epoch=17
06/13/2022 04:23:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=18
06/13/2022 04:23:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=18
06/13/2022 04:23:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=18
06/13/2022 04:23:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=18
06/13/2022 04:23:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=18
06/13/2022 04:23:53 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.9047351507053814 on epoch=18
06/13/2022 04:23:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.40 on epoch=18
06/13/2022 04:23:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=19
06/13/2022 04:24:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=19
06/13/2022 04:24:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=19
06/13/2022 04:24:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=19
06/13/2022 04:24:32 - INFO - __main__ - Global step 1100 Train loss 0.18 Classification-F1 0.8466728337929055 on epoch=19
06/13/2022 04:24:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.38 on epoch=19
06/13/2022 04:24:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=19
06/13/2022 04:24:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=20
06/13/2022 04:24:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=20
06/13/2022 04:24:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=20
06/13/2022 04:25:12 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.9079057993017337 on epoch=20
06/13/2022 04:25:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=20
06/13/2022 04:25:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.31 on epoch=20
06/13/2022 04:25:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=21
06/13/2022 04:25:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=21
06/13/2022 04:25:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=21
06/13/2022 04:25:51 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.9078744749954673 on epoch=21
06/13/2022 04:25:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=21
06/13/2022 04:25:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=21
06/13/2022 04:25:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.40 on epoch=21
06/13/2022 04:26:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=22
06/13/2022 04:26:04 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=22
06/13/2022 04:26:30 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.9139380479361474 on epoch=22
06/13/2022 04:26:30 - INFO - __main__ - Saving model with best Classification-F1: 0.9119451160857308 -> 0.9139380479361474 on epoch=22, global_step=1250
06/13/2022 04:26:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=22
06/13/2022 04:26:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=22
06/13/2022 04:26:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.39 on epoch=22
06/13/2022 04:26:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
06/13/2022 04:26:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=23
06/13/2022 04:27:09 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.8563464117383355 on epoch=23
06/13/2022 04:27:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=23
06/13/2022 04:27:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=23
06/13/2022 04:27:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=23
06/13/2022 04:27:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=23
06/13/2022 04:27:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=24
06/13/2022 04:27:47 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.9799361410707054 on epoch=24
06/13/2022 04:27:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9139380479361474 -> 0.9799361410707054 on epoch=24, global_step=1350
06/13/2022 04:27:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=24
06/13/2022 04:27:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=24
06/13/2022 04:27:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=24
06/13/2022 04:27:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.34 on epoch=24
06/13/2022 04:28:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=24
06/13/2022 04:28:25 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.8574320695117768 on epoch=24
06/13/2022 04:28:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=25
06/13/2022 04:28:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=25
06/13/2022 04:28:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
06/13/2022 04:28:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=25
06/13/2022 04:28:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.35 on epoch=25
06/13/2022 04:29:03 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.9140861923399461 on epoch=25
06/13/2022 04:29:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=26
06/13/2022 04:29:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=26
06/13/2022 04:29:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=26
06/13/2022 04:29:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=26
06/13/2022 04:29:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
06/13/2022 04:29:42 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.9788311058510629 on epoch=26
06/13/2022 04:29:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.31 on epoch=26
06/13/2022 04:29:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=27
06/13/2022 04:29:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
06/13/2022 04:29:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=27
06/13/2022 04:29:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=27
06/13/2022 04:30:20 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.9130540627985958 on epoch=27
06/13/2022 04:30:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=27
06/13/2022 04:30:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=28
06/13/2022 04:30:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=28
06/13/2022 04:30:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=28
06/13/2022 04:30:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=28
06/13/2022 04:30:57 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.9161358599482065 on epoch=28
06/13/2022 04:31:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=28
06/13/2022 04:31:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.44 on epoch=28
06/13/2022 04:31:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=29
06/13/2022 04:31:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=29
06/13/2022 04:31:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
06/13/2022 04:31:35 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.9078230740627854 on epoch=29
06/13/2022 04:31:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
06/13/2022 04:31:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.34 on epoch=29
06/13/2022 04:31:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=29
06/13/2022 04:31:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
06/13/2022 04:31:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=30
06/13/2022 04:32:14 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.9108427302289002 on epoch=30
06/13/2022 04:32:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=30
06/13/2022 04:32:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=30
06/13/2022 04:32:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=30
06/13/2022 04:32:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=31
06/13/2022 04:32:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=31
06/13/2022 04:32:52 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.9114937916574303 on epoch=31
06/13/2022 04:32:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=31
06/13/2022 04:32:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=31
06/13/2022 04:33:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
06/13/2022 04:33:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.34 on epoch=31
06/13/2022 04:33:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=32
06/13/2022 04:33:29 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.8045380113676807 on epoch=32
06/13/2022 04:33:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=32
06/13/2022 04:33:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
06/13/2022 04:33:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=32
06/13/2022 04:33:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.39 on epoch=32
06/13/2022 04:33:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=33
06/13/2022 04:34:05 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.7035038192688221 on epoch=33
06/13/2022 04:34:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=33
06/13/2022 04:34:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
06/13/2022 04:34:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=33
06/13/2022 04:34:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=33
06/13/2022 04:34:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.31 on epoch=33
06/13/2022 04:34:43 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.7529416278509209 on epoch=33
06/13/2022 04:34:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=34
06/13/2022 04:34:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=34
06/13/2022 04:34:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
06/13/2022 04:34:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=34
06/13/2022 04:34:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.33 on epoch=34
06/13/2022 04:35:20 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.855915461278171 on epoch=34
06/13/2022 04:35:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=34
06/13/2022 04:35:26 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
06/13/2022 04:35:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
06/13/2022 04:35:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=35
06/13/2022 04:35:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=35
06/13/2022 04:35:59 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.8045964233024756 on epoch=35
06/13/2022 04:36:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.32 on epoch=35
06/13/2022 04:36:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=36
06/13/2022 04:36:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=36
06/13/2022 04:36:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
06/13/2022 04:36:12 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=36
06/13/2022 04:36:37 - INFO - __main__ - Global step 2050 Train loss 0.14 Classification-F1 0.8564319090127379 on epoch=36
06/13/2022 04:36:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
06/13/2022 04:36:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
06/13/2022 04:36:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
06/13/2022 04:36:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
06/13/2022 04:36:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=37
06/13/2022 04:37:14 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.9139722469759959 on epoch=37
06/13/2022 04:37:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=37
06/13/2022 04:37:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=37
06/13/2022 04:37:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=38
06/13/2022 04:37:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
06/13/2022 04:37:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=38
06/13/2022 04:37:52 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.9119083931189002 on epoch=38
06/13/2022 04:37:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=38
06/13/2022 04:37:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=38
06/13/2022 04:38:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=38
06/13/2022 04:38:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=39
06/13/2022 04:38:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=39
06/13/2022 04:38:29 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.9788805085746844 on epoch=39
06/13/2022 04:38:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
06/13/2022 04:38:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
06/13/2022 04:38:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.36 on epoch=39
06/13/2022 04:38:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=39
06/13/2022 04:38:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=40
06/13/2022 04:39:06 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.8037205969782615 on epoch=40
06/13/2022 04:39:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=40
06/13/2022 04:39:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=40
06/13/2022 04:39:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=40
06/13/2022 04:39:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.32 on epoch=40
06/13/2022 04:39:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 04:39:43 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.8515635872977978 on epoch=41
06/13/2022 04:39:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=41
06/13/2022 04:39:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=41
06/13/2022 04:39:50 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=41
06/13/2022 04:39:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=41
06/13/2022 04:39:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.27 on epoch=41
06/13/2022 04:40:19 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.9107944599059462 on epoch=41
06/13/2022 04:40:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=42
06/13/2022 04:40:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
06/13/2022 04:40:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=42
06/13/2022 04:40:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=42
06/13/2022 04:40:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=42
06/13/2022 04:40:56 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.8028416165476989 on epoch=42
06/13/2022 04:40:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
06/13/2022 04:41:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=43
06/13/2022 04:41:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 04:41:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=43
06/13/2022 04:41:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=43
06/13/2022 04:41:32 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.7522290808720367 on epoch=43
06/13/2022 04:41:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.30 on epoch=43
06/13/2022 04:41:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=44
06/13/2022 04:41:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=44
06/13/2022 04:41:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 04:41:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
06/13/2022 04:42:09 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.914017344751993 on epoch=44
06/13/2022 04:42:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.32 on epoch=44
06/13/2022 04:42:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=44
06/13/2022 04:42:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
06/13/2022 04:42:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 04:42:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=45
06/13/2022 04:42:45 - INFO - __main__ - Global step 2550 Train loss 0.12 Classification-F1 0.912938752630751 on epoch=45
06/13/2022 04:42:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=45
06/13/2022 04:42:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=45
06/13/2022 04:42:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=46
06/13/2022 04:42:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
06/13/2022 04:42:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=46
06/13/2022 04:43:22 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.8525774923246907 on epoch=46
06/13/2022 04:43:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=46
06/13/2022 04:43:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=46
06/13/2022 04:43:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.22 on epoch=46
06/13/2022 04:43:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=47
06/13/2022 04:43:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
06/13/2022 04:43:59 - INFO - __main__ - Global step 2650 Train loss 0.08 Classification-F1 0.9150804787222111 on epoch=47
06/13/2022 04:44:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=47
06/13/2022 04:44:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.09 on epoch=47
06/13/2022 04:44:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=47
06/13/2022 04:44:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=48
06/13/2022 04:44:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
06/13/2022 04:44:35 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.9753753919460834 on epoch=48
06/13/2022 04:44:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=48
06/13/2022 04:44:40 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
06/13/2022 04:44:43 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
06/13/2022 04:44:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
06/13/2022 04:44:48 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
06/13/2022 04:45:11 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9047490778207663 on epoch=49
06/13/2022 04:45:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
06/13/2022 04:45:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
06/13/2022 04:45:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
06/13/2022 04:45:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
06/13/2022 04:45:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=49
06/13/2022 04:45:48 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8559481149184522 on epoch=49
06/13/2022 04:45:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=50
06/13/2022 04:45:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
06/13/2022 04:45:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=50
06/13/2022 04:45:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=50
06/13/2022 04:46:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.27 on epoch=50
06/13/2022 04:46:24 - INFO - __main__ - Global step 2850 Train loss 0.10 Classification-F1 0.790705041558217 on epoch=50
06/13/2022 04:46:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 04:46:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
06/13/2022 04:46:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
06/13/2022 04:46:34 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
06/13/2022 04:46:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
06/13/2022 04:47:01 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9112212742920481 on epoch=51
06/13/2022 04:47:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.31 on epoch=51
06/13/2022 04:47:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=52
06/13/2022 04:47:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
06/13/2022 04:47:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=52
06/13/2022 04:47:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 04:47:37 - INFO - __main__ - Global step 2950 Train loss 0.09 Classification-F1 0.9096579574684935 on epoch=52
06/13/2022 04:47:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.25 on epoch=52
06/13/2022 04:47:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=53
06/13/2022 04:47:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
06/13/2022 04:47:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
06/13/2022 04:47:50 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=53
06/13/2022 04:47:52 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:47:52 - INFO - __main__ - Printing 3 examples
06/13/2022 04:47:52 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 04:47:52 - INFO - __main__ - ['Animal']
06/13/2022 04:47:52 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 04:47:52 - INFO - __main__ - ['Animal']
06/13/2022 04:47:52 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 04:47:52 - INFO - __main__ - ['Animal']
06/13/2022 04:47:52 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:47:52 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:47:53 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 04:47:53 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:47:53 - INFO - __main__ - Printing 3 examples
06/13/2022 04:47:53 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 04:47:53 - INFO - __main__ - ['Animal']
06/13/2022 04:47:53 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 04:47:53 - INFO - __main__ - ['Animal']
06/13/2022 04:47:53 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 04:47:53 - INFO - __main__ - ['Animal']
06/13/2022 04:47:53 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:47:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:47:54 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 04:48:13 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 04:48:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 04:48:13 - INFO - __main__ - Starting training!
06/13/2022 04:48:15 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.9091687112366512 on epoch=53
06/13/2022 04:48:15 - INFO - __main__ - save last model!
06/13/2022 04:48:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 04:48:15 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 04:48:15 - INFO - __main__ - Printing 3 examples
06/13/2022 04:48:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 04:48:15 - INFO - __main__ - ['Animal']
06/13/2022 04:48:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 04:48:15 - INFO - __main__ - ['Animal']
06/13/2022 04:48:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 04:48:15 - INFO - __main__ - ['Village']
06/13/2022 04:48:15 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:48:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:48:20 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 04:50:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.2_8_predictions.txt
06/13/2022 04:50:26 - INFO - __main__ - Classification-F1 on test data: 0.7585
06/13/2022 04:50:27 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.2, bsz=8, dev_performance=0.9799361410707054, test_performance=0.7584937770957318
06/13/2022 04:50:27 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.5, bsz=8 ...
06/13/2022 04:50:28 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:50:28 - INFO - __main__ - Printing 3 examples
06/13/2022 04:50:28 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 04:50:28 - INFO - __main__ - ['Animal']
06/13/2022 04:50:28 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 04:50:28 - INFO - __main__ - ['Animal']
06/13/2022 04:50:28 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 04:50:28 - INFO - __main__ - ['Animal']
06/13/2022 04:50:28 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:50:28 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:50:29 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 04:50:29 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 04:50:29 - INFO - __main__ - Printing 3 examples
06/13/2022 04:50:29 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 04:50:29 - INFO - __main__ - ['Animal']
06/13/2022 04:50:29 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 04:50:29 - INFO - __main__ - ['Animal']
06/13/2022 04:50:29 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 04:50:29 - INFO - __main__ - ['Animal']
06/13/2022 04:50:29 - INFO - __main__ - Tokenizing Input ...
06/13/2022 04:50:30 - INFO - __main__ - Tokenizing Output ...
06/13/2022 04:50:30 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 04:50:46 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 04:50:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 04:50:46 - INFO - __main__ - Starting training!
06/13/2022 04:50:50 - INFO - __main__ - Step 10 Global step 10 Train loss 4.23 on epoch=0
06/13/2022 04:50:53 - INFO - __main__ - Step 20 Global step 20 Train loss 3.12 on epoch=0
06/13/2022 04:50:55 - INFO - __main__ - Step 30 Global step 30 Train loss 2.00 on epoch=0
06/13/2022 04:50:58 - INFO - __main__ - Step 40 Global step 40 Train loss 1.37 on epoch=0
06/13/2022 04:51:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.16 on epoch=0
06/13/2022 04:51:27 - INFO - __main__ - Global step 50 Train loss 2.37 Classification-F1 0.2692391897112244 on epoch=0
06/13/2022 04:51:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2692391897112244 on epoch=0, global_step=50
06/13/2022 04:51:30 - INFO - __main__ - Step 60 Global step 60 Train loss 0.94 on epoch=1
06/13/2022 04:51:32 - INFO - __main__ - Step 70 Global step 70 Train loss 0.87 on epoch=1
06/13/2022 04:51:35 - INFO - __main__ - Step 80 Global step 80 Train loss 0.81 on epoch=1
06/13/2022 04:51:37 - INFO - __main__ - Step 90 Global step 90 Train loss 0.81 on epoch=1
06/13/2022 04:51:40 - INFO - __main__ - Step 100 Global step 100 Train loss 0.62 on epoch=1
06/13/2022 04:52:06 - INFO - __main__ - Global step 100 Train loss 0.81 Classification-F1 0.41648905594034047 on epoch=1
06/13/2022 04:52:06 - INFO - __main__ - Saving model with best Classification-F1: 0.2692391897112244 -> 0.41648905594034047 on epoch=1, global_step=100
06/13/2022 04:52:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.54 on epoch=1
06/13/2022 04:52:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.50 on epoch=2
06/13/2022 04:52:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.67 on epoch=2
06/13/2022 04:52:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=2
06/13/2022 04:52:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.47 on epoch=2
06/13/2022 04:52:48 - INFO - __main__ - Global step 150 Train loss 0.55 Classification-F1 0.408471527628674 on epoch=2
06/13/2022 04:52:50 - INFO - __main__ - Step 160 Global step 160 Train loss 0.47 on epoch=2
06/13/2022 04:52:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.40 on epoch=3
06/13/2022 04:52:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=3
06/13/2022 04:52:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=3
06/13/2022 04:53:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.36 on epoch=3
06/13/2022 04:53:29 - INFO - __main__ - Global step 200 Train loss 0.45 Classification-F1 0.5447855607091132 on epoch=3
06/13/2022 04:53:30 - INFO - __main__ - Saving model with best Classification-F1: 0.41648905594034047 -> 0.5447855607091132 on epoch=3, global_step=200
06/13/2022 04:53:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=3
06/13/2022 04:53:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.26 on epoch=3
06/13/2022 04:53:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.30 on epoch=4
06/13/2022 04:53:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.30 on epoch=4
06/13/2022 04:53:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=4
06/13/2022 04:54:12 - INFO - __main__ - Global step 250 Train loss 0.30 Classification-F1 0.6416354601528683 on epoch=4
06/13/2022 04:54:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5447855607091132 -> 0.6416354601528683 on epoch=4, global_step=250
06/13/2022 04:54:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=4
06/13/2022 04:54:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.28 on epoch=4
06/13/2022 04:54:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=4
06/13/2022 04:54:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=5
06/13/2022 04:54:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=5
06/13/2022 04:54:52 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.46286143974056204 on epoch=5
06/13/2022 04:54:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=5
06/13/2022 04:54:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.15 on epoch=5
06/13/2022 04:54:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.19 on epoch=5
06/13/2022 04:55:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=6
06/13/2022 04:55:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.22 on epoch=6
06/13/2022 04:55:35 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.47184093281225314 on epoch=6
06/13/2022 04:55:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=6
06/13/2022 04:55:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=6
06/13/2022 04:55:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=6
06/13/2022 04:55:45 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=6
06/13/2022 04:55:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.11 on epoch=7
06/13/2022 04:56:12 - INFO - __main__ - Global step 400 Train loss 0.16 Classification-F1 0.4196367056272023 on epoch=7
06/13/2022 04:56:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=7
06/13/2022 04:56:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=7
06/13/2022 04:56:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=7
06/13/2022 04:56:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=7
06/13/2022 04:56:25 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=8
06/13/2022 04:56:50 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.7366038078664889 on epoch=8
06/13/2022 04:56:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6416354601528683 -> 0.7366038078664889 on epoch=8, global_step=450
06/13/2022 04:56:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=8
06/13/2022 04:56:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=8
06/13/2022 04:56:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.13 on epoch=8
06/13/2022 04:57:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=8
06/13/2022 04:57:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=8
06/13/2022 04:57:29 - INFO - __main__ - Global step 500 Train loss 0.15 Classification-F1 0.8593395450414569 on epoch=8
06/13/2022 04:57:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7366038078664889 -> 0.8593395450414569 on epoch=8, global_step=500
06/13/2022 04:57:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.08 on epoch=9
06/13/2022 04:57:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=9
06/13/2022 04:57:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=9
06/13/2022 04:57:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=9
06/13/2022 04:57:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=9
06/13/2022 04:58:06 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.3927338281453044 on epoch=9
06/13/2022 04:58:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=9
06/13/2022 04:58:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=10
06/13/2022 04:58:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=10
06/13/2022 04:58:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=10
06/13/2022 04:58:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=10
06/13/2022 04:58:44 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.4849076724579841 on epoch=10
06/13/2022 04:58:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=10
06/13/2022 04:58:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=11
06/13/2022 04:58:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=11
06/13/2022 04:58:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=11
06/13/2022 04:58:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=11
06/13/2022 04:59:21 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.7067815933151679 on epoch=11
06/13/2022 04:59:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=11
06/13/2022 04:59:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=11
06/13/2022 04:59:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=12
06/13/2022 04:59:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=12
06/13/2022 04:59:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=12
06/13/2022 04:59:56 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.44342158372820467 on epoch=12
06/13/2022 04:59:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=12
06/13/2022 05:00:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=12
06/13/2022 05:00:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=13
06/13/2022 05:00:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=13
06/13/2022 05:00:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=13
06/13/2022 05:00:31 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.42346438669157643 on epoch=13
06/13/2022 05:00:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=13
06/13/2022 05:00:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=13
06/13/2022 05:00:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=13
06/13/2022 05:00:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=14
06/13/2022 05:00:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=14
06/13/2022 05:01:09 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.522166314197073 on epoch=14
06/13/2022 05:01:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=14
06/13/2022 05:01:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=14
06/13/2022 05:01:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=14
06/13/2022 05:01:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=14
06/13/2022 05:01:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=15
06/13/2022 05:01:46 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7064191018321646 on epoch=15
06/13/2022 05:01:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=15
06/13/2022 05:01:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=15
06/13/2022 05:01:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=15
06/13/2022 05:01:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=15
06/13/2022 05:01:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=16
06/13/2022 05:02:23 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6585941224672883 on epoch=16
06/13/2022 05:02:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=16
06/13/2022 05:02:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
06/13/2022 05:02:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=16
06/13/2022 05:02:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=16
06/13/2022 05:02:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=16
06/13/2022 05:03:00 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.5678474893462422 on epoch=16
06/13/2022 05:03:02 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=17
06/13/2022 05:03:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=17
06/13/2022 05:03:07 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=17
06/13/2022 05:03:10 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=17
06/13/2022 05:03:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=17
06/13/2022 05:03:37 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7016809883166676 on epoch=17
06/13/2022 05:03:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=18
06/13/2022 05:03:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=18
06/13/2022 05:03:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=18
06/13/2022 05:03:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=18
06/13/2022 05:03:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=18
06/13/2022 05:04:16 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6766527682218627 on epoch=18
06/13/2022 05:04:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
06/13/2022 05:04:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=19
06/13/2022 05:04:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=19
06/13/2022 05:04:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=19
06/13/2022 05:04:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=19
06/13/2022 05:04:53 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.5614852697938651 on epoch=19
06/13/2022 05:04:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=19
06/13/2022 05:04:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=19
06/13/2022 05:05:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=20
06/13/2022 05:05:03 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=20
06/13/2022 05:05:06 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=20
06/13/2022 05:05:30 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.6113341526885858 on epoch=20
06/13/2022 05:05:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=20
06/13/2022 05:05:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=20
06/13/2022 05:05:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=21
06/13/2022 05:05:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=21
06/13/2022 05:05:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=21
06/13/2022 05:06:09 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.44313601421567367 on epoch=21
06/13/2022 05:06:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=21
06/13/2022 05:06:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=21
06/13/2022 05:06:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=21
06/13/2022 05:06:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=22
06/13/2022 05:06:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=22
06/13/2022 05:06:49 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6663008337823285 on epoch=22
06/13/2022 05:06:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=22
06/13/2022 05:06:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=22
06/13/2022 05:06:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
06/13/2022 05:06:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=23
06/13/2022 05:07:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
06/13/2022 05:07:26 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6588392744312352 on epoch=23
06/13/2022 05:07:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=23
06/13/2022 05:07:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=23
06/13/2022 05:07:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=23
06/13/2022 05:07:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=23
06/13/2022 05:07:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
06/13/2022 05:08:03 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8083292016382567 on epoch=24
06/13/2022 05:08:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=24
06/13/2022 05:08:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
06/13/2022 05:08:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=24
06/13/2022 05:08:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
06/13/2022 05:08:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=24
06/13/2022 05:08:41 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.854476500263509 on epoch=24
06/13/2022 05:08:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=25
06/13/2022 05:08:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=25
06/13/2022 05:08:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=25
06/13/2022 05:08:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=25
06/13/2022 05:08:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=25
06/13/2022 05:09:17 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.5701161391333643 on epoch=25
06/13/2022 05:09:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
06/13/2022 05:09:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=26
06/13/2022 05:09:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=26
06/13/2022 05:09:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=26
06/13/2022 05:09:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=26
06/13/2022 05:09:55 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7079848836952349 on epoch=26
06/13/2022 05:09:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=26
06/13/2022 05:10:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
06/13/2022 05:10:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
06/13/2022 05:10:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
06/13/2022 05:10:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=27
06/13/2022 05:10:31 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7535878029411479 on epoch=27
06/13/2022 05:10:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=27
06/13/2022 05:10:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=28
06/13/2022 05:10:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
06/13/2022 05:10:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
06/13/2022 05:10:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=28
06/13/2022 05:11:08 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.751930202229611 on epoch=28
06/13/2022 05:11:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=28
06/13/2022 05:11:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
06/13/2022 05:11:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
06/13/2022 05:11:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=29
06/13/2022 05:11:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=29
06/13/2022 05:11:44 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6113176225203842 on epoch=29
06/13/2022 05:11:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
06/13/2022 05:11:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=29
06/13/2022 05:11:52 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=29
06/13/2022 05:11:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=30
06/13/2022 05:11:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=30
06/13/2022 05:12:21 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6704867659916667 on epoch=30
06/13/2022 05:12:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=30
06/13/2022 05:12:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=30
06/13/2022 05:12:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=30
06/13/2022 05:12:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
06/13/2022 05:12:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=31
06/13/2022 05:12:58 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7996868154498683 on epoch=31
06/13/2022 05:13:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
06/13/2022 05:13:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
06/13/2022 05:13:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
06/13/2022 05:13:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
06/13/2022 05:13:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
06/13/2022 05:13:34 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.6552774224296479 on epoch=32
06/13/2022 05:13:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=32
06/13/2022 05:13:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
06/13/2022 05:13:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=32
06/13/2022 05:13:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
06/13/2022 05:13:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=33
06/13/2022 05:14:10 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.613668032597598 on epoch=33
06/13/2022 05:14:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
06/13/2022 05:14:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=33
06/13/2022 05:14:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=33
06/13/2022 05:14:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=33
06/13/2022 05:14:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=33
06/13/2022 05:14:47 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6802577243028172 on epoch=33
06/13/2022 05:14:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
06/13/2022 05:14:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
06/13/2022 05:14:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
06/13/2022 05:14:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
06/13/2022 05:15:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
06/13/2022 05:15:22 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6643332887699189 on epoch=34
06/13/2022 05:15:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
06/13/2022 05:15:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
06/13/2022 05:15:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
06/13/2022 05:15:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
06/13/2022 05:15:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=35
06/13/2022 05:16:00 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.756027234549724 on epoch=35
06/13/2022 05:16:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=35
06/13/2022 05:16:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
06/13/2022 05:16:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=36
06/13/2022 05:16:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=36
06/13/2022 05:16:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=36
06/13/2022 05:16:37 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7539922714172895 on epoch=36
06/13/2022 05:16:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=36
06/13/2022 05:16:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=36
06/13/2022 05:16:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=37
06/13/2022 05:16:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
06/13/2022 05:16:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=37
06/13/2022 05:17:14 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6468279372636807 on epoch=37
06/13/2022 05:17:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
06/13/2022 05:17:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=37
06/13/2022 05:17:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
06/13/2022 05:17:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
06/13/2022 05:17:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=38
06/13/2022 05:17:50 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.810123378101493 on epoch=38
06/13/2022 05:17:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
06/13/2022 05:17:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
06/13/2022 05:17:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=38
06/13/2022 05:18:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=39
06/13/2022 05:18:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=39
06/13/2022 05:18:27 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6648938918615711 on epoch=39
06/13/2022 05:18:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
06/13/2022 05:18:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
06/13/2022 05:18:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=39
06/13/2022 05:18:37 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=39
06/13/2022 05:18:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=40
06/13/2022 05:19:04 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.762024526248684 on epoch=40
06/13/2022 05:19:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=40
06/13/2022 05:19:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
06/13/2022 05:19:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=40
06/13/2022 05:19:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
06/13/2022 05:19:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 05:19:40 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7979726666488945 on epoch=41
06/13/2022 05:19:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=41
06/13/2022 05:19:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
06/13/2022 05:19:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
06/13/2022 05:19:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 05:19:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
06/13/2022 05:20:16 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7219338294901805 on epoch=41
06/13/2022 05:20:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
06/13/2022 05:20:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=42
06/13/2022 05:20:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
06/13/2022 05:20:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
06/13/2022 05:20:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=42
06/13/2022 05:20:52 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8101756923030364 on epoch=42
06/13/2022 05:20:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
06/13/2022 05:20:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
06/13/2022 05:21:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
06/13/2022 05:21:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
06/13/2022 05:21:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
06/13/2022 05:21:28 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7470761578672526 on epoch=43
06/13/2022 05:21:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
06/13/2022 05:21:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=44
06/13/2022 05:21:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=44
06/13/2022 05:21:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 05:21:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=44
06/13/2022 05:22:04 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8602944173133742 on epoch=44
06/13/2022 05:22:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8593395450414569 -> 0.8602944173133742 on epoch=44, global_step=2500
06/13/2022 05:22:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
06/13/2022 05:22:09 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
06/13/2022 05:22:12 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
06/13/2022 05:22:14 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 05:22:17 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
06/13/2022 05:22:40 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8612959192726692 on epoch=45
06/13/2022 05:22:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8602944173133742 -> 0.8612959192726692 on epoch=45, global_step=2550
06/13/2022 05:22:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
06/13/2022 05:22:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=45
06/13/2022 05:22:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 05:22:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=46
06/13/2022 05:22:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
06/13/2022 05:23:16 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7673317871454202 on epoch=46
06/13/2022 05:23:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=46
06/13/2022 05:23:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=46
06/13/2022 05:23:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
06/13/2022 05:23:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
06/13/2022 05:23:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
06/13/2022 05:23:53 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7623457383740353 on epoch=47
06/13/2022 05:23:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
06/13/2022 05:23:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=47
06/13/2022 05:24:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
06/13/2022 05:24:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
06/13/2022 05:24:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
06/13/2022 05:24:29 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8115221329635437 on epoch=48
06/13/2022 05:24:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=48
06/13/2022 05:24:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
06/13/2022 05:24:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
06/13/2022 05:24:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
06/13/2022 05:24:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
06/13/2022 05:25:05 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.808797045853809 on epoch=49
06/13/2022 05:25:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
06/13/2022 05:25:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
06/13/2022 05:25:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
06/13/2022 05:25:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=49
06/13/2022 05:25:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 05:25:43 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8091896250799955 on epoch=49
06/13/2022 05:25:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=50
06/13/2022 05:25:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=50
06/13/2022 05:25:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=50
06/13/2022 05:25:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=50
06/13/2022 05:25:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=50
06/13/2022 05:26:20 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7546851423389662 on epoch=50
06/13/2022 05:26:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=51
06/13/2022 05:26:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=51
06/13/2022 05:26:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
06/13/2022 05:26:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
06/13/2022 05:26:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 05:26:56 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.617620952560363 on epoch=51
06/13/2022 05:26:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
06/13/2022 05:27:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
06/13/2022 05:27:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=52
06/13/2022 05:27:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
06/13/2022 05:27:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 05:27:31 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5920599306813661 on epoch=52
06/13/2022 05:27:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
06/13/2022 05:27:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
06/13/2022 05:27:39 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
06/13/2022 05:27:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
06/13/2022 05:27:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 05:27:46 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 05:27:46 - INFO - __main__ - Printing 3 examples
06/13/2022 05:27:46 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 05:27:46 - INFO - __main__ - ['Animal']
06/13/2022 05:27:46 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 05:27:46 - INFO - __main__ - ['Animal']
06/13/2022 05:27:46 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 05:27:46 - INFO - __main__ - ['Animal']
06/13/2022 05:27:46 - INFO - __main__ - Tokenizing Input ...
06/13/2022 05:27:46 - INFO - __main__ - Tokenizing Output ...
06/13/2022 05:27:47 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 05:27:47 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 05:27:47 - INFO - __main__ - Printing 3 examples
06/13/2022 05:27:47 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 05:27:47 - INFO - __main__ - ['Animal']
06/13/2022 05:27:47 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 05:27:47 - INFO - __main__ - ['Animal']
06/13/2022 05:27:47 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 05:27:47 - INFO - __main__ - ['Animal']
06/13/2022 05:27:47 - INFO - __main__ - Tokenizing Input ...
06/13/2022 05:27:48 - INFO - __main__ - Tokenizing Output ...
06/13/2022 05:27:49 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 05:28:07 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6511814469347099 on epoch=53
06/13/2022 05:28:07 - INFO - __main__ - save last model!
06/13/2022 05:28:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 05:28:07 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 05:28:07 - INFO - __main__ - Printing 3 examples
06/13/2022 05:28:07 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 05:28:07 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 05:28:07 - INFO - __main__ - ['Animal']
06/13/2022 05:28:07 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 05:28:07 - INFO - __main__ - ['Animal']
06/13/2022 05:28:07 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 05:28:07 - INFO - __main__ - ['Village']
06/13/2022 05:28:07 - INFO - __main__ - Tokenizing Input ...
06/13/2022 05:28:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 05:28:08 - INFO - __main__ - Starting training!
06/13/2022 05:28:09 - INFO - __main__ - Tokenizing Output ...
06/13/2022 05:28:12 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 05:30:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.5_8_predictions.txt
06/13/2022 05:30:15 - INFO - __main__ - Classification-F1 on test data: 0.6195
06/13/2022 05:30:16 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.5, bsz=8, dev_performance=0.8612959192726692, test_performance=0.6194950247027511
06/13/2022 05:30:16 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.4, bsz=8 ...
06/13/2022 05:30:17 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 05:30:17 - INFO - __main__ - Printing 3 examples
06/13/2022 05:30:17 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 05:30:17 - INFO - __main__ - ['Animal']
06/13/2022 05:30:17 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 05:30:17 - INFO - __main__ - ['Animal']
06/13/2022 05:30:17 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 05:30:17 - INFO - __main__ - ['Animal']
06/13/2022 05:30:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 05:30:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 05:30:18 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 05:30:18 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 05:30:18 - INFO - __main__ - Printing 3 examples
06/13/2022 05:30:18 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 05:30:18 - INFO - __main__ - ['Animal']
06/13/2022 05:30:18 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 05:30:18 - INFO - __main__ - ['Animal']
06/13/2022 05:30:18 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 05:30:18 - INFO - __main__ - ['Animal']
06/13/2022 05:30:18 - INFO - __main__ - Tokenizing Input ...
06/13/2022 05:30:19 - INFO - __main__ - Tokenizing Output ...
06/13/2022 05:30:19 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 05:30:35 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 05:30:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 05:30:35 - INFO - __main__ - Starting training!
06/13/2022 05:30:39 - INFO - __main__ - Step 10 Global step 10 Train loss 4.57 on epoch=0
06/13/2022 05:30:41 - INFO - __main__ - Step 20 Global step 20 Train loss 4.09 on epoch=0
06/13/2022 05:30:44 - INFO - __main__ - Step 30 Global step 30 Train loss 2.81 on epoch=0
06/13/2022 05:30:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.88 on epoch=0
06/13/2022 05:30:49 - INFO - __main__ - Step 50 Global step 50 Train loss 1.59 on epoch=0
06/13/2022 05:31:14 - INFO - __main__ - Global step 50 Train loss 2.99 Classification-F1 0.0988334944971961 on epoch=0
06/13/2022 05:31:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0988334944971961 on epoch=0, global_step=50
06/13/2022 05:31:17 - INFO - __main__ - Step 60 Global step 60 Train loss 1.16 on epoch=1
06/13/2022 05:31:19 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=1
06/13/2022 05:31:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=1
06/13/2022 05:31:25 - INFO - __main__ - Step 90 Global step 90 Train loss 0.88 on epoch=1
06/13/2022 05:31:27 - INFO - __main__ - Step 100 Global step 100 Train loss 0.71 on epoch=1
06/13/2022 05:31:55 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.21517096813317926 on epoch=1
06/13/2022 05:31:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0988334944971961 -> 0.21517096813317926 on epoch=1, global_step=100
06/13/2022 05:31:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.73 on epoch=1
06/13/2022 05:32:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=2
06/13/2022 05:32:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.64 on epoch=2
06/13/2022 05:32:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=2
06/13/2022 05:32:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=2
06/13/2022 05:32:36 - INFO - __main__ - Global step 150 Train loss 0.61 Classification-F1 0.451298252557617 on epoch=2
06/13/2022 05:32:36 - INFO - __main__ - Saving model with best Classification-F1: 0.21517096813317926 -> 0.451298252557617 on epoch=2, global_step=150
06/13/2022 05:32:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=2
06/13/2022 05:32:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=3
06/13/2022 05:32:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.42 on epoch=3
06/13/2022 05:32:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=3
06/13/2022 05:32:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=3
06/13/2022 05:33:20 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.6209421796763969 on epoch=3
06/13/2022 05:33:20 - INFO - __main__ - Saving model with best Classification-F1: 0.451298252557617 -> 0.6209421796763969 on epoch=3, global_step=200
06/13/2022 05:33:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=3
06/13/2022 05:33:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.47 on epoch=3
06/13/2022 05:33:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=4
06/13/2022 05:33:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=4
06/13/2022 05:33:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=4
06/13/2022 05:34:04 - INFO - __main__ - Global step 250 Train loss 0.40 Classification-F1 0.44639741167114066 on epoch=4
06/13/2022 05:34:07 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=4
06/13/2022 05:34:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=4
06/13/2022 05:34:12 - INFO - __main__ - Step 280 Global step 280 Train loss 0.26 on epoch=4
06/13/2022 05:34:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=5
06/13/2022 05:34:17 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=5
06/13/2022 05:34:49 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.4977667987667562 on epoch=5
06/13/2022 05:34:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=5
06/13/2022 05:34:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=5
06/13/2022 05:34:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.24 on epoch=5
06/13/2022 05:34:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.21 on epoch=6
06/13/2022 05:35:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=6
06/13/2022 05:35:33 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.7391928579135754 on epoch=6
06/13/2022 05:35:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6209421796763969 -> 0.7391928579135754 on epoch=6, global_step=350
06/13/2022 05:35:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.27 on epoch=6
06/13/2022 05:35:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=6
06/13/2022 05:35:41 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=6
06/13/2022 05:35:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=6
06/13/2022 05:35:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=7
06/13/2022 05:36:17 - INFO - __main__ - Global step 400 Train loss 0.27 Classification-F1 0.8229629341544242 on epoch=7
06/13/2022 05:36:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7391928579135754 -> 0.8229629341544242 on epoch=7, global_step=400
06/13/2022 05:36:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=7
06/13/2022 05:36:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=7
06/13/2022 05:36:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=7
06/13/2022 05:36:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=7
06/13/2022 05:36:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=8
06/13/2022 05:36:58 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.6545274319003188 on epoch=8
06/13/2022 05:37:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=8
06/13/2022 05:37:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=8
06/13/2022 05:37:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=8
06/13/2022 05:37:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=8
06/13/2022 05:37:10 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=8
06/13/2022 05:37:41 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.5846523814069223 on epoch=8
06/13/2022 05:37:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=9
06/13/2022 05:37:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=9
06/13/2022 05:37:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=9
06/13/2022 05:37:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=9
06/13/2022 05:37:53 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=9
06/13/2022 05:38:20 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.5489543528458848 on epoch=9
06/13/2022 05:38:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=9
06/13/2022 05:38:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=10
06/13/2022 05:38:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=10
06/13/2022 05:38:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=10
06/13/2022 05:38:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=10
06/13/2022 05:39:04 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.7223676475460317 on epoch=10
06/13/2022 05:39:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=10
06/13/2022 05:39:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=11
06/13/2022 05:39:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=11
06/13/2022 05:39:15 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=11
06/13/2022 05:39:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=11
06/13/2022 05:39:49 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7575171762832933 on epoch=11
06/13/2022 05:39:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=11
06/13/2022 05:39:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=11
06/13/2022 05:39:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=12
06/13/2022 05:39:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=12
06/13/2022 05:40:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=12
06/13/2022 05:40:31 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.803673060062807 on epoch=12
06/13/2022 05:40:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=12
06/13/2022 05:40:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=12
06/13/2022 05:40:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=13
06/13/2022 05:40:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=13
06/13/2022 05:40:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=13
06/13/2022 05:41:11 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.759414129619417 on epoch=13
06/13/2022 05:41:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=13
06/13/2022 05:41:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=13
06/13/2022 05:41:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=13
06/13/2022 05:41:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=14
06/13/2022 05:41:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=14
06/13/2022 05:41:54 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.6443552447011981 on epoch=14
06/13/2022 05:41:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=14
06/13/2022 05:41:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=14
06/13/2022 05:42:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=14
06/13/2022 05:42:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=14
06/13/2022 05:42:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=15
06/13/2022 05:42:33 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.804670642861882 on epoch=15
06/13/2022 05:42:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=15
06/13/2022 05:42:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=15
06/13/2022 05:42:41 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=15
06/13/2022 05:42:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=15
06/13/2022 05:42:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=16
06/13/2022 05:43:11 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.8036374452696522 on epoch=16
06/13/2022 05:43:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=16
06/13/2022 05:43:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=16
06/13/2022 05:43:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=16
06/13/2022 05:43:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=16
06/13/2022 05:43:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=16
06/13/2022 05:43:48 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8009806263705029 on epoch=16
06/13/2022 05:43:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=17
06/13/2022 05:43:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=17
06/13/2022 05:43:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=17
06/13/2022 05:43:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=17
06/13/2022 05:44:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=17
06/13/2022 05:44:27 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.687007619927712 on epoch=17
06/13/2022 05:44:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=18
06/13/2022 05:44:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=18
06/13/2022 05:44:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=18
06/13/2022 05:44:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=18
06/13/2022 05:44:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=18
06/13/2022 05:45:05 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.8622485615966721 on epoch=18
06/13/2022 05:45:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8229629341544242 -> 0.8622485615966721 on epoch=18, global_step=1050
06/13/2022 05:45:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=18
06/13/2022 05:45:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=19
06/13/2022 05:45:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=19
06/13/2022 05:45:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=19
06/13/2022 05:45:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=19
06/13/2022 05:45:42 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.8563931191715598 on epoch=19
06/13/2022 05:45:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=19
06/13/2022 05:45:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=19
06/13/2022 05:45:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
06/13/2022 05:45:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=20
06/13/2022 05:45:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=20
06/13/2022 05:46:20 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8583945127013584 on epoch=20
06/13/2022 05:46:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=20
06/13/2022 05:46:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=20
06/13/2022 05:46:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=21
06/13/2022 05:46:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=21
06/13/2022 05:46:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=21
06/13/2022 05:46:59 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8602701605632038 on epoch=21
06/13/2022 05:47:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=21
06/13/2022 05:47:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=21
06/13/2022 05:47:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=21
06/13/2022 05:47:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
06/13/2022 05:47:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=22
06/13/2022 05:47:37 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.8564287223128715 on epoch=22
06/13/2022 05:47:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=22
06/13/2022 05:47:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=22
06/13/2022 05:47:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
06/13/2022 05:47:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=23
06/13/2022 05:47:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=23
06/13/2022 05:48:14 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7647147479667431 on epoch=23
06/13/2022 05:48:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=23
06/13/2022 05:48:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=23
06/13/2022 05:48:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=23
06/13/2022 05:48:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=23
06/13/2022 05:48:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=24
06/13/2022 05:48:51 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7597682329402029 on epoch=24
06/13/2022 05:48:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=24
06/13/2022 05:48:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=24
06/13/2022 05:48:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
06/13/2022 05:49:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=24
06/13/2022 05:49:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=24
06/13/2022 05:49:27 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7425923859484185 on epoch=24
06/13/2022 05:49:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=25
06/13/2022 05:49:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=25
06/13/2022 05:49:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=25
06/13/2022 05:49:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
06/13/2022 05:49:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=25
06/13/2022 05:50:04 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7633990760045711 on epoch=25
06/13/2022 05:50:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
06/13/2022 05:50:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
06/13/2022 05:50:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=26
06/13/2022 05:50:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
06/13/2022 05:50:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=26
06/13/2022 05:50:41 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6870406507696091 on epoch=26
06/13/2022 05:50:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=26
06/13/2022 05:50:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=27
06/13/2022 05:50:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=27
06/13/2022 05:50:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=27
06/13/2022 05:50:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=27
06/13/2022 05:51:18 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.717564846503104 on epoch=27
06/13/2022 05:51:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=27
06/13/2022 05:51:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=28
06/13/2022 05:51:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=28
06/13/2022 05:51:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=28
06/13/2022 05:51:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=28
06/13/2022 05:51:54 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.678517091701204 on epoch=28
06/13/2022 05:51:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=28
06/13/2022 05:51:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=28
06/13/2022 05:52:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
06/13/2022 05:52:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=29
06/13/2022 05:52:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=29
06/13/2022 05:52:30 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6784585553179729 on epoch=29
06/13/2022 05:52:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=29
06/13/2022 05:52:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=29
06/13/2022 05:52:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=29
06/13/2022 05:52:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=30
06/13/2022 05:52:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=30
06/13/2022 05:53:07 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7608240614539065 on epoch=30
06/13/2022 05:53:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=30
06/13/2022 05:53:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=30
06/13/2022 05:53:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=30
06/13/2022 05:53:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=31
06/13/2022 05:53:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
06/13/2022 05:53:44 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8092326924679325 on epoch=31
06/13/2022 05:53:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=31
06/13/2022 05:53:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=31
06/13/2022 05:53:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=31
06/13/2022 05:53:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
06/13/2022 05:53:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=32
06/13/2022 05:54:21 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8060334155457843 on epoch=32
06/13/2022 05:54:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=32
06/13/2022 05:54:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=32
06/13/2022 05:54:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
06/13/2022 05:54:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
06/13/2022 05:54:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
06/13/2022 05:54:57 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.6445244863585453 on epoch=33
06/13/2022 05:54:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=33
06/13/2022 05:55:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
06/13/2022 05:55:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=33
06/13/2022 05:55:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=33
06/13/2022 05:55:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
06/13/2022 05:55:33 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7014008861939622 on epoch=33
06/13/2022 05:55:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
06/13/2022 05:55:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
06/13/2022 05:55:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
06/13/2022 05:55:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
06/13/2022 05:55:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
06/13/2022 05:56:08 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7464169070029933 on epoch=34
06/13/2022 05:56:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
06/13/2022 05:56:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
06/13/2022 05:56:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
06/13/2022 05:56:18 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=35
06/13/2022 05:56:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
06/13/2022 05:56:43 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6410674438526636 on epoch=35
06/13/2022 05:56:46 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=35
06/13/2022 05:56:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=36
06/13/2022 05:56:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
06/13/2022 05:56:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
06/13/2022 05:56:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=36
06/13/2022 05:57:20 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6500395419932959 on epoch=36
06/13/2022 05:57:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
06/13/2022 05:57:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=36
06/13/2022 05:57:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
06/13/2022 05:57:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=37
06/13/2022 05:57:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=37
06/13/2022 05:57:56 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7128146837125415 on epoch=37
06/13/2022 05:57:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=37
06/13/2022 05:58:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
06/13/2022 05:58:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=38
06/13/2022 05:58:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=38
06/13/2022 05:58:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=38
06/13/2022 05:58:33 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7199335461580043 on epoch=38
06/13/2022 05:58:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=38
06/13/2022 05:58:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
06/13/2022 05:58:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
06/13/2022 05:58:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=39
06/13/2022 05:58:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=39
06/13/2022 05:59:08 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7201777192048293 on epoch=39
06/13/2022 05:59:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
06/13/2022 05:59:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
06/13/2022 05:59:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
06/13/2022 05:59:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=39
06/13/2022 05:59:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
06/13/2022 05:59:44 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7231830338800839 on epoch=40
06/13/2022 05:59:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=40
06/13/2022 05:59:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
06/13/2022 05:59:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
06/13/2022 05:59:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
06/13/2022 05:59:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 06:00:20 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8033448328317344 on epoch=41
06/13/2022 06:00:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
06/13/2022 06:00:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=41
06/13/2022 06:00:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=41
06/13/2022 06:00:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 06:00:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
06/13/2022 06:00:55 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.763259320406803 on epoch=41
06/13/2022 06:00:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=42
06/13/2022 06:01:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
06/13/2022 06:01:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 06:01:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
06/13/2022 06:01:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
06/13/2022 06:01:30 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7596733232224291 on epoch=42
06/13/2022 06:01:33 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
06/13/2022 06:01:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=43
06/13/2022 06:01:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 06:01:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=43
06/13/2022 06:01:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
06/13/2022 06:02:07 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8593193199247064 on epoch=43
06/13/2022 06:02:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=43
06/13/2022 06:02:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
06/13/2022 06:02:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
06/13/2022 06:02:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 06:02:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
06/13/2022 06:02:44 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7182092400198328 on epoch=44
06/13/2022 06:02:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
06/13/2022 06:02:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
06/13/2022 06:02:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
06/13/2022 06:02:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 06:02:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=45
06/13/2022 06:03:21 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8562741577794353 on epoch=45
06/13/2022 06:03:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=45
06/13/2022 06:03:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
06/13/2022 06:03:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=46
06/13/2022 06:03:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=46
06/13/2022 06:03:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
06/13/2022 06:03:58 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8073129899339699 on epoch=46
06/13/2022 06:04:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=46
06/13/2022 06:04:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
06/13/2022 06:04:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
06/13/2022 06:04:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=47
06/13/2022 06:04:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
06/13/2022 06:04:34 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6076055806052996 on epoch=47
06/13/2022 06:04:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 06:04:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=47
06/13/2022 06:04:41 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
06/13/2022 06:04:44 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
06/13/2022 06:04:46 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
06/13/2022 06:05:10 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7633342431366585 on epoch=48
06/13/2022 06:05:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=48
06/13/2022 06:05:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
06/13/2022 06:05:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
06/13/2022 06:05:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
06/13/2022 06:05:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
06/13/2022 06:05:46 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8101422259145746 on epoch=49
06/13/2022 06:05:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
06/13/2022 06:05:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
06/13/2022 06:05:54 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=49
06/13/2022 06:05:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
06/13/2022 06:05:59 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
06/13/2022 06:06:21 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7213847254782803 on epoch=49
06/13/2022 06:06:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
06/13/2022 06:06:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
06/13/2022 06:06:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=50
06/13/2022 06:06:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
06/13/2022 06:06:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
06/13/2022 06:06:57 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.568578104645409 on epoch=50
06/13/2022 06:07:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
06/13/2022 06:07:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
06/13/2022 06:07:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
06/13/2022 06:07:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=51
06/13/2022 06:07:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 06:07:33 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.6171732262088869 on epoch=51
06/13/2022 06:07:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
06/13/2022 06:07:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=52
06/13/2022 06:07:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
06/13/2022 06:07:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
06/13/2022 06:07:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
06/13/2022 06:08:08 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.677732167107284 on epoch=52
06/13/2022 06:08:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
06/13/2022 06:08:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
06/13/2022 06:08:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.08 on epoch=53
06/13/2022 06:08:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
06/13/2022 06:08:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 06:08:23 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:08:23 - INFO - __main__ - Printing 3 examples
06/13/2022 06:08:23 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 06:08:23 - INFO - __main__ - ['Animal']
06/13/2022 06:08:23 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 06:08:23 - INFO - __main__ - ['Animal']
06/13/2022 06:08:23 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 06:08:23 - INFO - __main__ - ['Animal']
06/13/2022 06:08:23 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:08:23 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:08:24 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 06:08:24 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:08:24 - INFO - __main__ - Printing 3 examples
06/13/2022 06:08:24 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 06:08:24 - INFO - __main__ - ['Animal']
06/13/2022 06:08:24 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 06:08:24 - INFO - __main__ - ['Animal']
06/13/2022 06:08:24 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 06:08:24 - INFO - __main__ - ['Animal']
06/13/2022 06:08:24 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:08:25 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:08:26 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 06:08:41 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 06:08:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 06:08:42 - INFO - __main__ - Starting training!
06/13/2022 06:08:44 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6518722188584218 on epoch=53
06/13/2022 06:08:44 - INFO - __main__ - save last model!
06/13/2022 06:08:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 06:08:44 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 06:08:44 - INFO - __main__ - Printing 3 examples
06/13/2022 06:08:44 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 06:08:44 - INFO - __main__ - ['Animal']
06/13/2022 06:08:44 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 06:08:44 - INFO - __main__ - ['Animal']
06/13/2022 06:08:44 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 06:08:44 - INFO - __main__ - ['Village']
06/13/2022 06:08:44 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:08:46 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:08:50 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 06:10:54 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.4_8_predictions.txt
06/13/2022 06:10:54 - INFO - __main__ - Classification-F1 on test data: 0.5689
06/13/2022 06:10:55 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.4, bsz=8, dev_performance=0.8622485615966721, test_performance=0.5688600317691012
06/13/2022 06:10:55 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.3, bsz=8 ...
06/13/2022 06:10:56 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:10:56 - INFO - __main__ - Printing 3 examples
06/13/2022 06:10:56 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 06:10:56 - INFO - __main__ - ['Animal']
06/13/2022 06:10:56 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 06:10:56 - INFO - __main__ - ['Animal']
06/13/2022 06:10:56 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 06:10:56 - INFO - __main__ - ['Animal']
06/13/2022 06:10:56 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:10:56 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:10:57 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 06:10:57 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:10:57 - INFO - __main__ - Printing 3 examples
06/13/2022 06:10:57 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 06:10:57 - INFO - __main__ - ['Animal']
06/13/2022 06:10:57 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 06:10:57 - INFO - __main__ - ['Animal']
06/13/2022 06:10:57 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 06:10:57 - INFO - __main__ - ['Animal']
06/13/2022 06:10:57 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:10:57 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:10:58 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 06:11:14 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 06:11:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 06:11:14 - INFO - __main__ - Starting training!
06/13/2022 06:11:18 - INFO - __main__ - Step 10 Global step 10 Train loss 4.86 on epoch=0
06/13/2022 06:11:20 - INFO - __main__ - Step 20 Global step 20 Train loss 3.32 on epoch=0
06/13/2022 06:11:23 - INFO - __main__ - Step 30 Global step 30 Train loss 2.61 on epoch=0
06/13/2022 06:11:25 - INFO - __main__ - Step 40 Global step 40 Train loss 1.96 on epoch=0
06/13/2022 06:11:28 - INFO - __main__ - Step 50 Global step 50 Train loss 1.59 on epoch=0
06/13/2022 06:11:55 - INFO - __main__ - Global step 50 Train loss 2.87 Classification-F1 0.11907309354728196 on epoch=0
06/13/2022 06:11:55 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11907309354728196 on epoch=0, global_step=50
06/13/2022 06:11:57 - INFO - __main__ - Step 60 Global step 60 Train loss 1.18 on epoch=1
06/13/2022 06:12:00 - INFO - __main__ - Step 70 Global step 70 Train loss 1.02 on epoch=1
06/13/2022 06:12:02 - INFO - __main__ - Step 80 Global step 80 Train loss 1.06 on epoch=1
06/13/2022 06:12:05 - INFO - __main__ - Step 90 Global step 90 Train loss 0.83 on epoch=1
06/13/2022 06:12:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.73 on epoch=1
06/13/2022 06:12:31 - INFO - __main__ - Global step 100 Train loss 0.96 Classification-F1 0.2864617817341818 on epoch=1
06/13/2022 06:12:31 - INFO - __main__ - Saving model with best Classification-F1: 0.11907309354728196 -> 0.2864617817341818 on epoch=1, global_step=100
06/13/2022 06:12:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.89 on epoch=1
06/13/2022 06:12:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.70 on epoch=2
06/13/2022 06:12:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.71 on epoch=2
06/13/2022 06:12:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=2
06/13/2022 06:12:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.65 on epoch=2
06/13/2022 06:13:11 - INFO - __main__ - Global step 150 Train loss 0.71 Classification-F1 0.4634186590549305 on epoch=2
06/13/2022 06:13:11 - INFO - __main__ - Saving model with best Classification-F1: 0.2864617817341818 -> 0.4634186590549305 on epoch=2, global_step=150
06/13/2022 06:13:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.61 on epoch=2
06/13/2022 06:13:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.45 on epoch=3
06/13/2022 06:13:19 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=3
06/13/2022 06:13:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=3
06/13/2022 06:13:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=3
06/13/2022 06:13:53 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.4669120880231721 on epoch=3
06/13/2022 06:13:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4634186590549305 -> 0.4669120880231721 on epoch=3, global_step=200
06/13/2022 06:13:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.47 on epoch=3
06/13/2022 06:13:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.42 on epoch=3
06/13/2022 06:14:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=4
06/13/2022 06:14:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=4
06/13/2022 06:14:05 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=4
06/13/2022 06:14:33 - INFO - __main__ - Global step 250 Train loss 0.43 Classification-F1 0.5388792478878811 on epoch=4
06/13/2022 06:14:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4669120880231721 -> 0.5388792478878811 on epoch=4, global_step=250
06/13/2022 06:14:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=4
06/13/2022 06:14:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.27 on epoch=4
06/13/2022 06:14:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=4
06/13/2022 06:14:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=5
06/13/2022 06:14:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.50 on epoch=5
06/13/2022 06:15:14 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.5041492512850071 on epoch=5
06/13/2022 06:15:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.35 on epoch=5
06/13/2022 06:15:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.34 on epoch=5
06/13/2022 06:15:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=5
06/13/2022 06:15:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=6
06/13/2022 06:15:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=6
06/13/2022 06:15:56 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.5557920460038129 on epoch=6
06/13/2022 06:15:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5388792478878811 -> 0.5557920460038129 on epoch=6, global_step=350
06/13/2022 06:15:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=6
06/13/2022 06:16:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=6
06/13/2022 06:16:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=6
06/13/2022 06:16:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=6
06/13/2022 06:16:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=7
06/13/2022 06:16:36 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.5190147425841157 on epoch=7
06/13/2022 06:16:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=7
06/13/2022 06:16:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=7
06/13/2022 06:16:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=7
06/13/2022 06:16:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=7
06/13/2022 06:16:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=8
06/13/2022 06:17:18 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.5688322942263787 on epoch=8
06/13/2022 06:17:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5557920460038129 -> 0.5688322942263787 on epoch=8, global_step=450
06/13/2022 06:17:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=8
06/13/2022 06:17:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=8
06/13/2022 06:17:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=8
06/13/2022 06:17:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=8
06/13/2022 06:17:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=8
06/13/2022 06:18:01 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6478321081600353 on epoch=8
06/13/2022 06:18:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5688322942263787 -> 0.6478321081600353 on epoch=8, global_step=500
06/13/2022 06:18:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=9
06/13/2022 06:18:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=9
06/13/2022 06:18:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=9
06/13/2022 06:18:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=9
06/13/2022 06:18:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=9
06/13/2022 06:18:42 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.5746786523586201 on epoch=9
06/13/2022 06:18:45 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=9
06/13/2022 06:18:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=10
06/13/2022 06:18:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=10
06/13/2022 06:18:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=10
06/13/2022 06:18:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=10
06/13/2022 06:19:25 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.6683606994262703 on epoch=10
06/13/2022 06:19:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6478321081600353 -> 0.6683606994262703 on epoch=10, global_step=600
06/13/2022 06:19:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=10
06/13/2022 06:19:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=11
06/13/2022 06:19:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=11
06/13/2022 06:19:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=11
06/13/2022 06:19:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=11
06/13/2022 06:20:07 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.5849086489885486 on epoch=11
06/13/2022 06:20:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=11
06/13/2022 06:20:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=11
06/13/2022 06:20:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=12
06/13/2022 06:20:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=12
06/13/2022 06:20:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=12
06/13/2022 06:20:49 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6914245278541354 on epoch=12
06/13/2022 06:20:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6683606994262703 -> 0.6914245278541354 on epoch=12, global_step=700
06/13/2022 06:20:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=12
06/13/2022 06:20:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=12
06/13/2022 06:20:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=13
06/13/2022 06:20:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=13
06/13/2022 06:21:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=13
06/13/2022 06:21:31 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.7546942310957174 on epoch=13
06/13/2022 06:21:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6914245278541354 -> 0.7546942310957174 on epoch=13, global_step=750
06/13/2022 06:21:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=13
06/13/2022 06:21:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=13
06/13/2022 06:21:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=13
06/13/2022 06:21:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=14
06/13/2022 06:21:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=14
06/13/2022 06:22:16 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.8934287196745465 on epoch=14
06/13/2022 06:22:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7546942310957174 -> 0.8934287196745465 on epoch=14, global_step=800
06/13/2022 06:22:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=14
06/13/2022 06:22:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=14
06/13/2022 06:22:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=14
06/13/2022 06:22:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=14
06/13/2022 06:22:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=15
06/13/2022 06:22:58 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7579052110492923 on epoch=15
06/13/2022 06:23:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=15
06/13/2022 06:23:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=15
06/13/2022 06:23:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=15
06/13/2022 06:23:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=15
06/13/2022 06:23:10 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=16
06/13/2022 06:23:37 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.722808518872941 on epoch=16
06/13/2022 06:23:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=16
06/13/2022 06:23:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
06/13/2022 06:23:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=16
06/13/2022 06:23:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=16
06/13/2022 06:23:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=16
06/13/2022 06:24:17 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.8211831865545898 on epoch=16
06/13/2022 06:24:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=17
06/13/2022 06:24:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=17
06/13/2022 06:24:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=17
06/13/2022 06:24:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=17
06/13/2022 06:24:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=17
06/13/2022 06:24:56 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.805995461108414 on epoch=17
06/13/2022 06:24:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=18
06/13/2022 06:25:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=18
06/13/2022 06:25:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=18
06/13/2022 06:25:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=18
06/13/2022 06:25:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=18
06/13/2022 06:25:35 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7513617423981779 on epoch=18
06/13/2022 06:25:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=18
06/13/2022 06:25:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=19
06/13/2022 06:25:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=19
06/13/2022 06:25:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=19
06/13/2022 06:25:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=19
06/13/2022 06:26:12 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.853473182679547 on epoch=19
06/13/2022 06:26:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=19
06/13/2022 06:26:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=19
06/13/2022 06:26:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=20
06/13/2022 06:26:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=20
06/13/2022 06:26:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=20
06/13/2022 06:26:50 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.8533888549001116 on epoch=20
06/13/2022 06:26:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=20
06/13/2022 06:26:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=20
06/13/2022 06:26:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=21
06/13/2022 06:27:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=21
06/13/2022 06:27:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=21
06/13/2022 06:27:27 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8069995874921131 on epoch=21
06/13/2022 06:27:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=21
06/13/2022 06:27:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=21
06/13/2022 06:27:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=21
06/13/2022 06:27:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=22
06/13/2022 06:27:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=22
06/13/2022 06:28:06 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.8000115249162266 on epoch=22
06/13/2022 06:28:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=22
06/13/2022 06:28:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=22
06/13/2022 06:28:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
06/13/2022 06:28:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=23
06/13/2022 06:28:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.18 on epoch=23
06/13/2022 06:28:44 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.686441564512049 on epoch=23
06/13/2022 06:28:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=23
06/13/2022 06:28:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=23
06/13/2022 06:28:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=23
06/13/2022 06:28:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=23
06/13/2022 06:28:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=24
06/13/2022 06:29:21 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7632953032348699 on epoch=24
06/13/2022 06:29:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=24
06/13/2022 06:29:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
06/13/2022 06:29:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
06/13/2022 06:29:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=24
06/13/2022 06:29:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=24
06/13/2022 06:29:58 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8583253095032082 on epoch=24
06/13/2022 06:30:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=25
06/13/2022 06:30:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=25
06/13/2022 06:30:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
06/13/2022 06:30:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=25
06/13/2022 06:30:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=25
06/13/2022 06:30:36 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8592864317051021 on epoch=25
06/13/2022 06:30:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=26
06/13/2022 06:30:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=26
06/13/2022 06:30:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=26
06/13/2022 06:30:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
06/13/2022 06:30:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=26
06/13/2022 06:31:13 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8032803959014514 on epoch=26
06/13/2022 06:31:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=26
06/13/2022 06:31:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=27
06/13/2022 06:31:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=27
06/13/2022 06:31:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
06/13/2022 06:31:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
06/13/2022 06:31:53 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.9118657000317497 on epoch=27
06/13/2022 06:31:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8934287196745465 -> 0.9118657000317497 on epoch=27, global_step=1550
06/13/2022 06:31:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
06/13/2022 06:31:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=28
06/13/2022 06:32:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
06/13/2022 06:32:03 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
06/13/2022 06:32:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=28
06/13/2022 06:32:32 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7113233926677219 on epoch=28
06/13/2022 06:32:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=28
06/13/2022 06:32:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
06/13/2022 06:32:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
06/13/2022 06:32:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=29
06/13/2022 06:32:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
06/13/2022 06:33:09 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7010550583363785 on epoch=29
06/13/2022 06:33:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
06/13/2022 06:33:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=29
06/13/2022 06:33:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
06/13/2022 06:33:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=30
06/13/2022 06:33:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
06/13/2022 06:33:49 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7167780760773481 on epoch=30
06/13/2022 06:33:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
06/13/2022 06:33:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=30
06/13/2022 06:33:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=30
06/13/2022 06:33:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=31
06/13/2022 06:34:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=31
06/13/2022 06:34:26 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6458989134539974 on epoch=31
06/13/2022 06:34:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=31
06/13/2022 06:34:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
06/13/2022 06:34:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
06/13/2022 06:34:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=31
06/13/2022 06:34:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=32
06/13/2022 06:35:03 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6444206317008169 on epoch=32
06/13/2022 06:35:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=32
06/13/2022 06:35:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=32
06/13/2022 06:35:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=32
06/13/2022 06:35:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
06/13/2022 06:35:16 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
06/13/2022 06:35:40 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7592017841763776 on epoch=33
06/13/2022 06:35:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=33
06/13/2022 06:35:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=33
06/13/2022 06:35:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
06/13/2022 06:35:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=33
06/13/2022 06:35:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
06/13/2022 06:36:16 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.7122096778937818 on epoch=33
06/13/2022 06:36:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=34
06/13/2022 06:36:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.14 on epoch=34
06/13/2022 06:36:24 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
06/13/2022 06:36:26 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
06/13/2022 06:36:29 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=34
06/13/2022 06:36:53 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6833760741337065 on epoch=34
06/13/2022 06:36:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
06/13/2022 06:36:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
06/13/2022 06:37:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=35
06/13/2022 06:37:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
06/13/2022 06:37:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=35
06/13/2022 06:37:29 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6442949583331643 on epoch=35
06/13/2022 06:37:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
06/13/2022 06:37:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
06/13/2022 06:37:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
06/13/2022 06:37:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=36
06/13/2022 06:37:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
06/13/2022 06:38:06 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7138642243606641 on epoch=36
06/13/2022 06:38:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=36
06/13/2022 06:38:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=36
06/13/2022 06:38:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=37
06/13/2022 06:38:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=37
06/13/2022 06:38:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
06/13/2022 06:38:43 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7222098205440086 on epoch=37
06/13/2022 06:38:45 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
06/13/2022 06:38:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
06/13/2022 06:38:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
06/13/2022 06:38:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=38
06/13/2022 06:38:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
06/13/2022 06:39:21 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7196584794148364 on epoch=38
06/13/2022 06:39:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
06/13/2022 06:39:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=38
06/13/2022 06:39:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
06/13/2022 06:39:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
06/13/2022 06:39:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=39
06/13/2022 06:39:58 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.6427421134173855 on epoch=39
06/13/2022 06:40:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=39
06/13/2022 06:40:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=39
06/13/2022 06:40:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
06/13/2022 06:40:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
06/13/2022 06:40:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
06/13/2022 06:40:35 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7121205865504314 on epoch=40
06/13/2022 06:40:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 06:40:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
06/13/2022 06:40:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=40
06/13/2022 06:40:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
06/13/2022 06:40:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
06/13/2022 06:41:10 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7583929316264096 on epoch=41
06/13/2022 06:41:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
06/13/2022 06:41:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=41
06/13/2022 06:41:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
06/13/2022 06:41:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 06:41:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
06/13/2022 06:41:46 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7587561189903297 on epoch=41
06/13/2022 06:41:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
06/13/2022 06:41:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=42
06/13/2022 06:41:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 06:41:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
06/13/2022 06:41:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
06/13/2022 06:42:22 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.756933117550227 on epoch=42
06/13/2022 06:42:24 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
06/13/2022 06:42:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=43
06/13/2022 06:42:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=43
06/13/2022 06:42:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
06/13/2022 06:42:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
06/13/2022 06:42:58 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8105282254850207 on epoch=43
06/13/2022 06:43:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=43
06/13/2022 06:43:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
06/13/2022 06:43:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=44
06/13/2022 06:43:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=44
06/13/2022 06:43:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
06/13/2022 06:43:34 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7632793940846088 on epoch=44
06/13/2022 06:43:37 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=44
06/13/2022 06:43:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
06/13/2022 06:43:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=45
06/13/2022 06:43:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 06:43:47 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
06/13/2022 06:44:11 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8090196066635789 on epoch=45
06/13/2022 06:44:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
06/13/2022 06:44:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
06/13/2022 06:44:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 06:44:21 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=46
06/13/2022 06:44:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
06/13/2022 06:44:48 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7185913727349162 on epoch=46
06/13/2022 06:44:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
06/13/2022 06:44:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
06/13/2022 06:44:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=46
06/13/2022 06:44:58 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
06/13/2022 06:45:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
06/13/2022 06:45:25 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8078209680718091 on epoch=47
06/13/2022 06:45:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 06:45:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
06/13/2022 06:45:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
06/13/2022 06:45:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
06/13/2022 06:45:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
06/13/2022 06:46:01 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8057543605948227 on epoch=48
06/13/2022 06:46:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
06/13/2022 06:46:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
06/13/2022 06:46:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
06/13/2022 06:46:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
06/13/2022 06:46:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
06/13/2022 06:46:39 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8115065736120299 on epoch=49
06/13/2022 06:46:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=49
06/13/2022 06:46:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
06/13/2022 06:46:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
06/13/2022 06:46:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=49
06/13/2022 06:46:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
06/13/2022 06:47:14 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8114612340048137 on epoch=49
06/13/2022 06:47:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=50
06/13/2022 06:47:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=50
06/13/2022 06:47:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
06/13/2022 06:47:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
06/13/2022 06:47:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
06/13/2022 06:47:50 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8092269786806247 on epoch=50
06/13/2022 06:47:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 06:47:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
06/13/2022 06:47:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
06/13/2022 06:48:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
06/13/2022 06:48:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 06:48:27 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8622649739675039 on epoch=51
06/13/2022 06:48:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
06/13/2022 06:48:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=52
06/13/2022 06:48:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.12 on epoch=52
06/13/2022 06:48:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
06/13/2022 06:48:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 06:49:02 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.8612881673573927 on epoch=52
06/13/2022 06:49:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=52
06/13/2022 06:49:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
06/13/2022 06:49:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
06/13/2022 06:49:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
06/13/2022 06:49:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=53
06/13/2022 06:49:16 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:49:16 - INFO - __main__ - Printing 3 examples
06/13/2022 06:49:16 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 06:49:16 - INFO - __main__ - ['Animal']
06/13/2022 06:49:16 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 06:49:16 - INFO - __main__ - ['Animal']
06/13/2022 06:49:16 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 06:49:16 - INFO - __main__ - ['Animal']
06/13/2022 06:49:16 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:49:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:49:18 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 06:49:18 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:49:18 - INFO - __main__ - Printing 3 examples
06/13/2022 06:49:18 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 06:49:18 - INFO - __main__ - ['Animal']
06/13/2022 06:49:18 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 06:49:18 - INFO - __main__ - ['Animal']
06/13/2022 06:49:18 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 06:49:18 - INFO - __main__ - ['Animal']
06/13/2022 06:49:18 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:49:18 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:49:19 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 06:49:34 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 06:49:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 06:49:35 - INFO - __main__ - Starting training!
06/13/2022 06:49:39 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8573657260985521 on epoch=53
06/13/2022 06:49:39 - INFO - __main__ - save last model!
06/13/2022 06:49:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 06:49:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 06:49:39 - INFO - __main__ - Printing 3 examples
06/13/2022 06:49:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 06:49:39 - INFO - __main__ - ['Animal']
06/13/2022 06:49:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 06:49:39 - INFO - __main__ - ['Animal']
06/13/2022 06:49:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 06:49:39 - INFO - __main__ - ['Village']
06/13/2022 06:49:39 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:49:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:49:44 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 06:51:58 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.3_8_predictions.txt
06/13/2022 06:51:58 - INFO - __main__ - Classification-F1 on test data: 0.7249
06/13/2022 06:51:59 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.3, bsz=8, dev_performance=0.9118657000317497, test_performance=0.7248617843993767
06/13/2022 06:51:59 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.2, bsz=8 ...
06/13/2022 06:51:59 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:51:59 - INFO - __main__ - Printing 3 examples
06/13/2022 06:51:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/13/2022 06:51:59 - INFO - __main__ - ['Animal']
06/13/2022 06:51:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/13/2022 06:51:59 - INFO - __main__ - ['Animal']
06/13/2022 06:51:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/13/2022 06:51:59 - INFO - __main__ - ['Animal']
06/13/2022 06:51:59 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:52:00 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:52:01 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 06:52:01 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 06:52:01 - INFO - __main__ - Printing 3 examples
06/13/2022 06:52:01 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
06/13/2022 06:52:01 - INFO - __main__ - ['Animal']
06/13/2022 06:52:01 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
06/13/2022 06:52:01 - INFO - __main__ - ['Animal']
06/13/2022 06:52:01 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
06/13/2022 06:52:01 - INFO - __main__ - ['Animal']
06/13/2022 06:52:01 - INFO - __main__ - Tokenizing Input ...
06/13/2022 06:52:01 - INFO - __main__ - Tokenizing Output ...
06/13/2022 06:52:02 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 06:52:18 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 06:52:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 06:52:18 - INFO - __main__ - Starting training!
06/13/2022 06:52:22 - INFO - __main__ - Step 10 Global step 10 Train loss 4.92 on epoch=0
06/13/2022 06:52:24 - INFO - __main__ - Step 20 Global step 20 Train loss 3.94 on epoch=0
06/13/2022 06:52:27 - INFO - __main__ - Step 30 Global step 30 Train loss 3.13 on epoch=0
06/13/2022 06:52:29 - INFO - __main__ - Step 40 Global step 40 Train loss 2.42 on epoch=0
06/13/2022 06:52:32 - INFO - __main__ - Step 50 Global step 50 Train loss 2.25 on epoch=0
06/13/2022 06:52:53 - INFO - __main__ - Global step 50 Train loss 3.33 Classification-F1 0.0465378419510803 on epoch=0
06/13/2022 06:52:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0465378419510803 on epoch=0, global_step=50
06/13/2022 06:52:56 - INFO - __main__ - Step 60 Global step 60 Train loss 1.67 on epoch=1
06/13/2022 06:52:58 - INFO - __main__ - Step 70 Global step 70 Train loss 1.55 on epoch=1
06/13/2022 06:53:01 - INFO - __main__ - Step 80 Global step 80 Train loss 1.41 on epoch=1
06/13/2022 06:53:03 - INFO - __main__ - Step 90 Global step 90 Train loss 1.29 on epoch=1
06/13/2022 06:53:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=1
06/13/2022 06:53:29 - INFO - __main__ - Global step 100 Train loss 1.38 Classification-F1 0.22394758468807105 on epoch=1
06/13/2022 06:53:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0465378419510803 -> 0.22394758468807105 on epoch=1, global_step=100
06/13/2022 06:53:32 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=1
06/13/2022 06:53:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=2
06/13/2022 06:53:37 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=2
06/13/2022 06:53:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=2
06/13/2022 06:53:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=2
06/13/2022 06:54:08 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.34184169646086304 on epoch=2
06/13/2022 06:54:08 - INFO - __main__ - Saving model with best Classification-F1: 0.22394758468807105 -> 0.34184169646086304 on epoch=2, global_step=150
06/13/2022 06:54:10 - INFO - __main__ - Step 160 Global step 160 Train loss 0.70 on epoch=2
06/13/2022 06:54:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.74 on epoch=3
06/13/2022 06:54:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=3
06/13/2022 06:54:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=3
06/13/2022 06:54:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.71 on epoch=3
06/13/2022 06:54:47 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.4784746197654326 on epoch=3
06/13/2022 06:54:47 - INFO - __main__ - Saving model with best Classification-F1: 0.34184169646086304 -> 0.4784746197654326 on epoch=3, global_step=200
06/13/2022 06:54:50 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=3
06/13/2022 06:54:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=3
06/13/2022 06:54:55 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=4
06/13/2022 06:54:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=4
06/13/2022 06:55:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.59 on epoch=4
06/13/2022 06:55:27 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.4825765432644302 on epoch=4
06/13/2022 06:55:27 - INFO - __main__ - Saving model with best Classification-F1: 0.4784746197654326 -> 0.4825765432644302 on epoch=4, global_step=250
06/13/2022 06:55:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=4
06/13/2022 06:55:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=4
06/13/2022 06:55:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=4
06/13/2022 06:55:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=5
06/13/2022 06:55:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=5
06/13/2022 06:56:04 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.46348961642842085 on epoch=5
06/13/2022 06:56:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=5
06/13/2022 06:56:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=5
06/13/2022 06:56:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=5
06/13/2022 06:56:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=6
06/13/2022 06:56:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=6
06/13/2022 06:56:43 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.557506007767646 on epoch=6
06/13/2022 06:56:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4825765432644302 -> 0.557506007767646 on epoch=6, global_step=350
06/13/2022 06:56:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=6
06/13/2022 06:56:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=6
06/13/2022 06:56:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=6
06/13/2022 06:56:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=6
06/13/2022 06:56:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=7
06/13/2022 06:57:25 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.4094212778533105 on epoch=7
06/13/2022 06:57:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=7
06/13/2022 06:57:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=7
06/13/2022 06:57:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=7
06/13/2022 06:57:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=7
06/13/2022 06:57:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=8
06/13/2022 06:58:04 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.45413633638060497 on epoch=8
06/13/2022 06:58:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=8
06/13/2022 06:58:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=8
06/13/2022 06:58:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=8
06/13/2022 06:58:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=8
06/13/2022 06:58:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=8
06/13/2022 06:58:46 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.601948865339681 on epoch=8
06/13/2022 06:58:46 - INFO - __main__ - Saving model with best Classification-F1: 0.557506007767646 -> 0.601948865339681 on epoch=8, global_step=500
06/13/2022 06:58:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=9
06/13/2022 06:58:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=9
06/13/2022 06:58:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=9
06/13/2022 06:58:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.34 on epoch=9
06/13/2022 06:58:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=9
06/13/2022 06:59:25 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.6157578635028522 on epoch=9
06/13/2022 06:59:25 - INFO - __main__ - Saving model with best Classification-F1: 0.601948865339681 -> 0.6157578635028522 on epoch=9, global_step=550
06/13/2022 06:59:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=9
06/13/2022 06:59:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=10
06/13/2022 06:59:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=10
06/13/2022 06:59:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=10
06/13/2022 06:59:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=10
06/13/2022 07:00:08 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.5890609703673624 on epoch=10
06/13/2022 07:00:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=10
06/13/2022 07:00:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=11
06/13/2022 07:00:16 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=11
06/13/2022 07:00:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=11
06/13/2022 07:00:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=11
06/13/2022 07:00:52 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6572235192027476 on epoch=11
06/13/2022 07:00:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6157578635028522 -> 0.6572235192027476 on epoch=11, global_step=650
06/13/2022 07:00:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=11
06/13/2022 07:00:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=11
06/13/2022 07:00:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=12
06/13/2022 07:01:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=12
06/13/2022 07:01:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=12
06/13/2022 07:01:34 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6646252885042534 on epoch=12
06/13/2022 07:01:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6572235192027476 -> 0.6646252885042534 on epoch=12, global_step=700
06/13/2022 07:01:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=12
06/13/2022 07:01:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=12
06/13/2022 07:01:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=13
06/13/2022 07:01:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=13
06/13/2022 07:01:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=13
06/13/2022 07:02:17 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.6000630360567095 on epoch=13
06/13/2022 07:02:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=13
06/13/2022 07:02:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=13
06/13/2022 07:02:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=13
06/13/2022 07:02:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=14
06/13/2022 07:02:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=14
06/13/2022 07:02:59 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.6077082157857361 on epoch=14
06/13/2022 07:03:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=14
06/13/2022 07:03:04 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=14
06/13/2022 07:03:07 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=14
06/13/2022 07:03:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=14
06/13/2022 07:03:12 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=15
06/13/2022 07:03:41 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.6206655768148569 on epoch=15
06/13/2022 07:03:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.32 on epoch=15
06/13/2022 07:03:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=15
06/13/2022 07:03:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=15
06/13/2022 07:03:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=15
06/13/2022 07:03:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=16
06/13/2022 07:04:23 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.5768724134738517 on epoch=16
06/13/2022 07:04:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=16
06/13/2022 07:04:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=16
06/13/2022 07:04:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=16
06/13/2022 07:04:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=16
06/13/2022 07:04:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
06/13/2022 07:05:02 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.5955659876615217 on epoch=16
06/13/2022 07:05:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=17
06/13/2022 07:05:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=17
06/13/2022 07:05:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=17
06/13/2022 07:05:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=17
06/13/2022 07:05:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=17
06/13/2022 07:05:42 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.570172121630135 on epoch=17
06/13/2022 07:05:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=18
06/13/2022 07:05:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=18
06/13/2022 07:05:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=18
06/13/2022 07:05:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=18
06/13/2022 07:05:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=18
06/13/2022 07:06:25 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.6793714897655738 on epoch=18
06/13/2022 07:06:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6646252885042534 -> 0.6793714897655738 on epoch=18, global_step=1050
06/13/2022 07:06:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=18
06/13/2022 07:06:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=19
06/13/2022 07:06:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=19
06/13/2022 07:06:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=19
06/13/2022 07:06:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=19
06/13/2022 07:07:03 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.6458985985035919 on epoch=19
06/13/2022 07:07:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=19
06/13/2022 07:07:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=19
06/13/2022 07:07:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=20
06/13/2022 07:07:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=20
06/13/2022 07:07:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=20
06/13/2022 07:07:44 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.6474318304925143 on epoch=20
06/13/2022 07:07:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=20
06/13/2022 07:07:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=20
06/13/2022 07:07:51 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=21
06/13/2022 07:07:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=21
06/13/2022 07:07:56 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=21
06/13/2022 07:08:26 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.8022745226882888 on epoch=21
06/13/2022 07:08:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6793714897655738 -> 0.8022745226882888 on epoch=21, global_step=1200
06/13/2022 07:08:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=21
06/13/2022 07:08:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=21
06/13/2022 07:08:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=21
06/13/2022 07:08:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=22
06/13/2022 07:08:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.21 on epoch=22
06/13/2022 07:09:10 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.7994243133598316 on epoch=22
06/13/2022 07:09:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=22
06/13/2022 07:09:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=22
06/13/2022 07:09:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=22
06/13/2022 07:09:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=23
06/13/2022 07:09:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=23
06/13/2022 07:09:50 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.6753192209607295 on epoch=23
06/13/2022 07:09:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=23
06/13/2022 07:09:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=23
06/13/2022 07:09:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=23
06/13/2022 07:10:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=23
06/13/2022 07:10:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
06/13/2022 07:10:30 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.6329742158894448 on epoch=24
06/13/2022 07:10:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=24
06/13/2022 07:10:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=24
06/13/2022 07:10:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
06/13/2022 07:10:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=24
06/13/2022 07:10:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=24
06/13/2022 07:11:10 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.600220676625992 on epoch=24
06/13/2022 07:11:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=25
06/13/2022 07:11:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=25
06/13/2022 07:11:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=25
06/13/2022 07:11:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=25
06/13/2022 07:11:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=25
06/13/2022 07:11:51 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6744728768107374 on epoch=25
06/13/2022 07:11:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=26
06/13/2022 07:11:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=26
06/13/2022 07:11:59 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
06/13/2022 07:12:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=26
06/13/2022 07:12:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=26
06/13/2022 07:12:31 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7598311079036439 on epoch=26
06/13/2022 07:12:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=26
06/13/2022 07:12:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=27
06/13/2022 07:12:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=27
06/13/2022 07:12:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=27
06/13/2022 07:12:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=27
06/13/2022 07:13:12 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.758328049155022 on epoch=27
06/13/2022 07:13:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=27
06/13/2022 07:13:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
06/13/2022 07:13:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=28
06/13/2022 07:13:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=28
06/13/2022 07:13:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
06/13/2022 07:13:53 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7201981887224503 on epoch=28
06/13/2022 07:13:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=28
06/13/2022 07:13:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=28
06/13/2022 07:14:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
06/13/2022 07:14:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=29
06/13/2022 07:14:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=29
06/13/2022 07:14:33 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.8603029694309625 on epoch=29
06/13/2022 07:14:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8022745226882888 -> 0.8603029694309625 on epoch=29, global_step=1650
06/13/2022 07:14:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=29
06/13/2022 07:14:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=29
06/13/2022 07:14:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=29
06/13/2022 07:14:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=30
06/13/2022 07:14:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=30
06/13/2022 07:15:13 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.8593562027703268 on epoch=30
06/13/2022 07:15:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
06/13/2022 07:15:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=30
06/13/2022 07:15:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=30
06/13/2022 07:15:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=31
06/13/2022 07:15:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=31
06/13/2022 07:15:53 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.6773140315393269 on epoch=31
06/13/2022 07:15:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=31
06/13/2022 07:15:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=31
06/13/2022 07:16:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=31
06/13/2022 07:16:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=31
06/13/2022 07:16:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=32
06/13/2022 07:16:30 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6491079045775983 on epoch=32
06/13/2022 07:16:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=32
06/13/2022 07:16:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
06/13/2022 07:16:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=32
06/13/2022 07:16:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=32
06/13/2022 07:16:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=33
06/13/2022 07:17:09 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.6452440578605986 on epoch=33
06/13/2022 07:17:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.14 on epoch=33
06/13/2022 07:17:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=33
06/13/2022 07:17:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=33
06/13/2022 07:17:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=33
06/13/2022 07:17:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=33
06/13/2022 07:17:47 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7603351352545253 on epoch=33
06/13/2022 07:17:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
06/13/2022 07:17:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=34
06/13/2022 07:17:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=34
06/13/2022 07:17:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=34
06/13/2022 07:18:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
06/13/2022 07:18:27 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.6087454905440937 on epoch=34
06/13/2022 07:18:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=34
06/13/2022 07:18:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=35
06/13/2022 07:18:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=35
06/13/2022 07:18:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=35
06/13/2022 07:18:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
06/13/2022 07:19:07 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.6879379413499168 on epoch=35
06/13/2022 07:19:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
06/13/2022 07:19:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
06/13/2022 07:19:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.16 on epoch=36
06/13/2022 07:19:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=36
06/13/2022 07:19:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
06/13/2022 07:19:47 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7633733751795089 on epoch=36
06/13/2022 07:19:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
06/13/2022 07:19:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=36
06/13/2022 07:19:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
06/13/2022 07:19:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=37
06/13/2022 07:19:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
06/13/2022 07:20:27 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7601724969036726 on epoch=37
06/13/2022 07:20:30 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
06/13/2022 07:20:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
06/13/2022 07:20:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
06/13/2022 07:20:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=38
06/13/2022 07:20:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=38
06/13/2022 07:21:06 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6479462640912143 on epoch=38
06/13/2022 07:21:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=38
06/13/2022 07:21:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=38
06/13/2022 07:21:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=38
06/13/2022 07:21:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.14 on epoch=39
06/13/2022 07:21:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=39
06/13/2022 07:21:46 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7223399006672846 on epoch=39
06/13/2022 07:21:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
06/13/2022 07:21:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
06/13/2022 07:21:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=39
06/13/2022 07:21:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=39
06/13/2022 07:21:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=40
06/13/2022 07:22:25 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7214504472908921 on epoch=40
06/13/2022 07:22:28 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=40
06/13/2022 07:22:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
06/13/2022 07:22:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
06/13/2022 07:22:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
06/13/2022 07:22:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
06/13/2022 07:23:03 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7631573564658738 on epoch=41
06/13/2022 07:23:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=41
06/13/2022 07:23:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=41
06/13/2022 07:23:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
06/13/2022 07:23:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=41
06/13/2022 07:23:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
06/13/2022 07:23:41 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7187154661227168 on epoch=41
06/13/2022 07:23:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=42
06/13/2022 07:23:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=42
06/13/2022 07:23:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=42
06/13/2022 07:23:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
06/13/2022 07:23:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=42
06/13/2022 07:24:20 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.649721675027253 on epoch=42
06/13/2022 07:24:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
06/13/2022 07:24:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=43
06/13/2022 07:24:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 07:24:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=43
06/13/2022 07:24:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
06/13/2022 07:24:58 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7599531921507134 on epoch=43
06/13/2022 07:25:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=43
06/13/2022 07:25:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
06/13/2022 07:25:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=44
06/13/2022 07:25:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=44
06/13/2022 07:25:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
06/13/2022 07:25:36 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6412330756117494 on epoch=44
06/13/2022 07:25:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
06/13/2022 07:25:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=44
06/13/2022 07:25:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
06/13/2022 07:25:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
06/13/2022 07:25:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
06/13/2022 07:26:13 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6446983477591586 on epoch=45
06/13/2022 07:26:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
06/13/2022 07:26:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=45
06/13/2022 07:26:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=46
06/13/2022 07:26:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=46
06/13/2022 07:26:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
06/13/2022 07:26:50 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6852999240544528 on epoch=46
06/13/2022 07:26:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
06/13/2022 07:26:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
06/13/2022 07:26:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
06/13/2022 07:27:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
06/13/2022 07:27:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=47
06/13/2022 07:27:27 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6161159337703863 on epoch=47
06/13/2022 07:27:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
06/13/2022 07:27:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
06/13/2022 07:27:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
06/13/2022 07:27:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
06/13/2022 07:27:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.14 on epoch=48
06/13/2022 07:28:05 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.638329549282123 on epoch=48
06/13/2022 07:28:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=48
06/13/2022 07:28:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
06/13/2022 07:28:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
06/13/2022 07:28:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
06/13/2022 07:28:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
06/13/2022 07:28:42 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6837787853807263 on epoch=49
06/13/2022 07:28:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=49
06/13/2022 07:28:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
06/13/2022 07:28:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=49
06/13/2022 07:28:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=49
06/13/2022 07:28:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 07:29:20 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6387868538131759 on epoch=49
06/13/2022 07:29:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=50
06/13/2022 07:29:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
06/13/2022 07:29:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
06/13/2022 07:29:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
06/13/2022 07:29:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=50
06/13/2022 07:29:57 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7231797154300436 on epoch=50
06/13/2022 07:30:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 07:30:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=51
06/13/2022 07:30:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
06/13/2022 07:30:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
06/13/2022 07:30:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
06/13/2022 07:30:36 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.762126104991426 on epoch=51
06/13/2022 07:30:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.08 on epoch=51
06/13/2022 07:30:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=52
06/13/2022 07:30:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=52
06/13/2022 07:30:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
06/13/2022 07:30:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 07:31:13 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7642498639574495 on epoch=52
06/13/2022 07:31:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=52
06/13/2022 07:31:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
06/13/2022 07:31:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=53
06/13/2022 07:31:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
06/13/2022 07:31:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=53
06/13/2022 07:31:28 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 07:31:28 - INFO - __main__ - Printing 3 examples
06/13/2022 07:31:28 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 07:31:28 - INFO - __main__ - ['Plant']
06/13/2022 07:31:28 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 07:31:28 - INFO - __main__ - ['Plant']
06/13/2022 07:31:28 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 07:31:28 - INFO - __main__ - ['Plant']
06/13/2022 07:31:28 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:31:28 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:31:29 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 07:31:29 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 07:31:29 - INFO - __main__ - Printing 3 examples
06/13/2022 07:31:29 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 07:31:29 - INFO - __main__ - ['Plant']
06/13/2022 07:31:29 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 07:31:29 - INFO - __main__ - ['Plant']
06/13/2022 07:31:29 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 07:31:29 - INFO - __main__ - ['Plant']
06/13/2022 07:31:29 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:31:29 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:31:30 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 07:31:49 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:31:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:31:50 - INFO - __main__ - Starting training!
06/13/2022 07:31:52 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6529840975227253 on epoch=53
06/13/2022 07:31:52 - INFO - __main__ - save last model!
06/13/2022 07:31:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 07:31:52 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 07:31:52 - INFO - __main__ - Printing 3 examples
06/13/2022 07:31:52 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 07:31:52 - INFO - __main__ - ['Animal']
06/13/2022 07:31:52 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 07:31:52 - INFO - __main__ - ['Animal']
06/13/2022 07:31:52 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 07:31:52 - INFO - __main__ - ['Village']
06/13/2022 07:31:52 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:31:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:31:57 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 07:34:07 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.2_8_predictions.txt
06/13/2022 07:34:07 - INFO - __main__ - Classification-F1 on test data: 0.7233
06/13/2022 07:34:08 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.2, bsz=8, dev_performance=0.8603029694309625, test_performance=0.7232850035146522
06/13/2022 07:34:08 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.5, bsz=8 ...
06/13/2022 07:34:09 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 07:34:09 - INFO - __main__ - Printing 3 examples
06/13/2022 07:34:09 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 07:34:09 - INFO - __main__ - ['Plant']
06/13/2022 07:34:09 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 07:34:09 - INFO - __main__ - ['Plant']
06/13/2022 07:34:09 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 07:34:09 - INFO - __main__ - ['Plant']
06/13/2022 07:34:09 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:34:09 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:34:10 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 07:34:10 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 07:34:10 - INFO - __main__ - Printing 3 examples
06/13/2022 07:34:10 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 07:34:10 - INFO - __main__ - ['Plant']
06/13/2022 07:34:10 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 07:34:10 - INFO - __main__ - ['Plant']
06/13/2022 07:34:10 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 07:34:10 - INFO - __main__ - ['Plant']
06/13/2022 07:34:10 - INFO - __main__ - Tokenizing Input ...
06/13/2022 07:34:11 - INFO - __main__ - Tokenizing Output ...
06/13/2022 07:34:11 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 07:34:30 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 07:34:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 07:34:31 - INFO - __main__ - Starting training!
06/13/2022 07:34:35 - INFO - __main__ - Step 10 Global step 10 Train loss 4.45 on epoch=0
06/13/2022 07:34:37 - INFO - __main__ - Step 20 Global step 20 Train loss 2.58 on epoch=0
06/13/2022 07:34:40 - INFO - __main__ - Step 30 Global step 30 Train loss 1.80 on epoch=0
06/13/2022 07:34:43 - INFO - __main__ - Step 40 Global step 40 Train loss 1.21 on epoch=0
06/13/2022 07:34:45 - INFO - __main__ - Step 50 Global step 50 Train loss 1.18 on epoch=0
06/13/2022 07:35:10 - INFO - __main__ - Global step 50 Train loss 2.25 Classification-F1 0.2678825103166494 on epoch=0
06/13/2022 07:35:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2678825103166494 on epoch=0, global_step=50
06/13/2022 07:35:13 - INFO - __main__ - Step 60 Global step 60 Train loss 0.71 on epoch=1
06/13/2022 07:35:15 - INFO - __main__ - Step 70 Global step 70 Train loss 0.85 on epoch=1
06/13/2022 07:35:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.82 on epoch=1
06/13/2022 07:35:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=1
06/13/2022 07:35:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.68 on epoch=1
06/13/2022 07:35:48 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.5230594928779169 on epoch=1
06/13/2022 07:35:48 - INFO - __main__ - Saving model with best Classification-F1: 0.2678825103166494 -> 0.5230594928779169 on epoch=1, global_step=100
06/13/2022 07:35:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.60 on epoch=1
06/13/2022 07:35:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.43 on epoch=2
06/13/2022 07:35:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.53 on epoch=2
06/13/2022 07:35:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.52 on epoch=2
06/13/2022 07:36:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.39 on epoch=2
06/13/2022 07:36:26 - INFO - __main__ - Global step 150 Train loss 0.49 Classification-F1 0.5041884592775495 on epoch=2
06/13/2022 07:36:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.43 on epoch=2
06/13/2022 07:36:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.41 on epoch=3
06/13/2022 07:36:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.44 on epoch=3
06/13/2022 07:36:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.33 on epoch=3
06/13/2022 07:36:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.31 on epoch=3
06/13/2022 07:37:06 - INFO - __main__ - Global step 200 Train loss 0.38 Classification-F1 0.759726426669721 on epoch=3
06/13/2022 07:37:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5230594928779169 -> 0.759726426669721 on epoch=3, global_step=200
06/13/2022 07:37:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.30 on epoch=3
06/13/2022 07:37:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.39 on epoch=3
06/13/2022 07:37:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.29 on epoch=4
06/13/2022 07:37:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.29 on epoch=4
06/13/2022 07:37:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.28 on epoch=4
06/13/2022 07:37:47 - INFO - __main__ - Global step 250 Train loss 0.31 Classification-F1 0.5798098223088554 on epoch=4
06/13/2022 07:37:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.26 on epoch=4
06/13/2022 07:37:52 - INFO - __main__ - Step 270 Global step 270 Train loss 0.25 on epoch=4
06/13/2022 07:37:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=4
06/13/2022 07:37:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.19 on epoch=5
06/13/2022 07:38:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=5
06/13/2022 07:38:28 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.5511638169118074 on epoch=5
06/13/2022 07:38:31 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=5
06/13/2022 07:38:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=5
06/13/2022 07:38:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=5
06/13/2022 07:38:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=6
06/13/2022 07:38:41 - INFO - __main__ - Step 350 Global step 350 Train loss 0.16 on epoch=6
06/13/2022 07:39:12 - INFO - __main__ - Global step 350 Train loss 0.19 Classification-F1 0.5218566542085409 on epoch=6
06/13/2022 07:39:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.27 on epoch=6
06/13/2022 07:39:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.14 on epoch=6
06/13/2022 07:39:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.17 on epoch=6
06/13/2022 07:39:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=6
06/13/2022 07:39:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.15 on epoch=7
06/13/2022 07:39:52 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6149596162564056 on epoch=7
06/13/2022 07:39:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=7
06/13/2022 07:39:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=7
06/13/2022 07:39:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.14 on epoch=7
06/13/2022 07:40:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=7
06/13/2022 07:40:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=8
06/13/2022 07:40:38 - INFO - __main__ - Global step 450 Train loss 0.14 Classification-F1 0.6251154177813018 on epoch=8
06/13/2022 07:40:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.09 on epoch=8
06/13/2022 07:40:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=8
06/13/2022 07:40:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.12 on epoch=8
06/13/2022 07:40:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=8
06/13/2022 07:40:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=8
06/13/2022 07:41:24 - INFO - __main__ - Global step 500 Train loss 0.13 Classification-F1 0.7156690173425847 on epoch=8
06/13/2022 07:41:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=9
06/13/2022 07:41:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=9
06/13/2022 07:41:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=9
06/13/2022 07:41:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=9
06/13/2022 07:41:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=9
06/13/2022 07:42:08 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.703139490872253 on epoch=9
06/13/2022 07:42:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=9
06/13/2022 07:42:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=10
06/13/2022 07:42:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=10
06/13/2022 07:42:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=10
06/13/2022 07:42:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=10
06/13/2022 07:42:49 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.739029843381631 on epoch=10
06/13/2022 07:42:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=10
06/13/2022 07:42:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=11
06/13/2022 07:42:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=11
06/13/2022 07:43:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=11
06/13/2022 07:43:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=11
06/13/2022 07:43:30 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.568267271666549 on epoch=11
06/13/2022 07:43:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=11
06/13/2022 07:43:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=11
06/13/2022 07:43:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=12
06/13/2022 07:43:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=12
06/13/2022 07:43:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=12
06/13/2022 07:44:10 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7983704685860145 on epoch=12
06/13/2022 07:44:10 - INFO - __main__ - Saving model with best Classification-F1: 0.759726426669721 -> 0.7983704685860145 on epoch=12, global_step=700
06/13/2022 07:44:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=12
06/13/2022 07:44:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=12
06/13/2022 07:44:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=13
06/13/2022 07:44:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=13
06/13/2022 07:44:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=13
06/13/2022 07:44:49 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.8000717030919469 on epoch=13
06/13/2022 07:44:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7983704685860145 -> 0.8000717030919469 on epoch=13, global_step=750
06/13/2022 07:44:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=13
06/13/2022 07:44:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=13
06/13/2022 07:44:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=13
06/13/2022 07:44:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=14
06/13/2022 07:45:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=14
06/13/2022 07:45:27 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.7815455061033014 on epoch=14
06/13/2022 07:45:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=14
06/13/2022 07:45:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=14
06/13/2022 07:45:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=14
06/13/2022 07:45:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=14
06/13/2022 07:45:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=15
06/13/2022 07:46:07 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6203077658229377 on epoch=15
06/13/2022 07:46:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=15
06/13/2022 07:46:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=15
06/13/2022 07:46:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=15
06/13/2022 07:46:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=15
06/13/2022 07:46:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=16
06/13/2022 07:46:46 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.7210022459547138 on epoch=16
06/13/2022 07:46:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=16
06/13/2022 07:46:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=16
06/13/2022 07:46:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=16
06/13/2022 07:46:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=16
06/13/2022 07:46:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=16
06/13/2022 07:47:25 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.6774821638279211 on epoch=16
06/13/2022 07:47:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=17
06/13/2022 07:47:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=17
06/13/2022 07:47:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=17
06/13/2022 07:47:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=17
06/13/2022 07:47:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=17
06/13/2022 07:48:02 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.5569424969250782 on epoch=17
06/13/2022 07:48:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=18
06/13/2022 07:48:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=18
06/13/2022 07:48:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=18
06/13/2022 07:48:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=18
06/13/2022 07:48:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=18
06/13/2022 07:48:41 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.6685970980587921 on epoch=18
06/13/2022 07:48:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=18
06/13/2022 07:48:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=19
06/13/2022 07:48:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=19
06/13/2022 07:48:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=19
06/13/2022 07:48:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=19
06/13/2022 07:49:22 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.863290947549006 on epoch=19
06/13/2022 07:49:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8000717030919469 -> 0.863290947549006 on epoch=19, global_step=1100
06/13/2022 07:49:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=19
06/13/2022 07:49:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=19
06/13/2022 07:49:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=20
06/13/2022 07:49:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=20
06/13/2022 07:49:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=20
06/13/2022 07:50:02 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8129191320518929 on epoch=20
06/13/2022 07:50:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=20
06/13/2022 07:50:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=20
06/13/2022 07:50:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=21
06/13/2022 07:50:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=21
06/13/2022 07:50:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=21
06/13/2022 07:50:41 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7584777287349856 on epoch=21
06/13/2022 07:50:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=21
06/13/2022 07:50:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
06/13/2022 07:50:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=21
06/13/2022 07:50:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=22
06/13/2022 07:50:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=22
06/13/2022 07:51:21 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.836364287785445 on epoch=22
06/13/2022 07:51:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=22
06/13/2022 07:51:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=22
06/13/2022 07:51:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
06/13/2022 07:51:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=23
06/13/2022 07:51:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=23
06/13/2022 07:52:01 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.6965705772185572 on epoch=23
06/13/2022 07:52:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=23
06/13/2022 07:52:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=23
06/13/2022 07:52:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=23
06/13/2022 07:52:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
06/13/2022 07:52:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=24
06/13/2022 07:52:41 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6136375276682634 on epoch=24
06/13/2022 07:52:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=24
06/13/2022 07:52:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=24
06/13/2022 07:52:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=24
06/13/2022 07:52:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=24
06/13/2022 07:52:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=24
06/13/2022 07:53:21 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.7491122484685744 on epoch=24
06/13/2022 07:53:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=25
06/13/2022 07:53:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=25
06/13/2022 07:53:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=25
06/13/2022 07:53:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=25
06/13/2022 07:53:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=25
06/13/2022 07:53:59 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7887626417393786 on epoch=25
06/13/2022 07:54:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
06/13/2022 07:54:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=26
06/13/2022 07:54:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=26
06/13/2022 07:54:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
06/13/2022 07:54:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=26
06/13/2022 07:54:36 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6085720162463044 on epoch=26
06/13/2022 07:54:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=26
06/13/2022 07:54:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
06/13/2022 07:54:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=27
06/13/2022 07:54:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=27
06/13/2022 07:54:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
06/13/2022 07:55:17 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7646134007594986 on epoch=27
06/13/2022 07:55:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=27
06/13/2022 07:55:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
06/13/2022 07:55:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=28
06/13/2022 07:55:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=28
06/13/2022 07:55:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=28
06/13/2022 07:55:55 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.8604865127268304 on epoch=28
06/13/2022 07:55:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=28
06/13/2022 07:56:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
06/13/2022 07:56:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
06/13/2022 07:56:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=29
06/13/2022 07:56:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=29
06/13/2022 07:56:35 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7233126401018038 on epoch=29
06/13/2022 07:56:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
06/13/2022 07:56:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=29
06/13/2022 07:56:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=29
06/13/2022 07:56:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=30
06/13/2022 07:56:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=30
06/13/2022 07:57:15 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8486190853533562 on epoch=30
06/13/2022 07:57:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=30
06/13/2022 07:57:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=30
06/13/2022 07:57:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
06/13/2022 07:57:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
06/13/2022 07:57:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=31
06/13/2022 07:57:54 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7561168300777887 on epoch=31
06/13/2022 07:57:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
06/13/2022 07:57:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=31
06/13/2022 07:58:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=31
06/13/2022 07:58:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
06/13/2022 07:58:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=32
06/13/2022 07:58:33 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7514369320425482 on epoch=32
06/13/2022 07:58:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=32
06/13/2022 07:58:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
06/13/2022 07:58:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
06/13/2022 07:58:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=32
06/13/2022 07:58:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
06/13/2022 07:59:11 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.5389725068735092 on epoch=33
06/13/2022 07:59:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
06/13/2022 07:59:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=33
06/13/2022 07:59:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=33
06/13/2022 07:59:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
06/13/2022 07:59:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=33
06/13/2022 07:59:49 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.762133525939021 on epoch=33
06/13/2022 07:59:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
06/13/2022 07:59:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=34
06/13/2022 07:59:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=34
06/13/2022 07:59:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=34
06/13/2022 08:00:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=34
06/13/2022 08:00:28 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8585502249005554 on epoch=34
06/13/2022 08:00:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
06/13/2022 08:00:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=35
06/13/2022 08:00:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=35
06/13/2022 08:00:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=35
06/13/2022 08:00:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=35
06/13/2022 08:01:05 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7056778309848648 on epoch=35
06/13/2022 08:01:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
06/13/2022 08:01:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
06/13/2022 08:01:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
06/13/2022 08:01:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=36
06/13/2022 08:01:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
06/13/2022 08:01:45 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7589275228006174 on epoch=36
06/13/2022 08:01:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=36
06/13/2022 08:01:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
06/13/2022 08:01:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
06/13/2022 08:01:56 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=37
06/13/2022 08:01:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
06/13/2022 08:02:22 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7225026535951224 on epoch=37
06/13/2022 08:02:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
06/13/2022 08:02:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
06/13/2022 08:02:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
06/13/2022 08:02:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=38
06/13/2022 08:02:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=38
06/13/2022 08:03:00 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.735408509114426 on epoch=38
06/13/2022 08:03:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
06/13/2022 08:03:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
06/13/2022 08:03:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
06/13/2022 08:03:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
06/13/2022 08:03:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=39
06/13/2022 08:03:37 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6973139469234537 on epoch=39
06/13/2022 08:03:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=39
06/13/2022 08:03:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
06/13/2022 08:03:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=39
06/13/2022 08:03:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
06/13/2022 08:03:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
06/13/2022 08:04:15 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8568064339896877 on epoch=40
06/13/2022 08:04:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 08:04:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
06/13/2022 08:04:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
06/13/2022 08:04:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=40
06/13/2022 08:04:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=41
06/13/2022 08:04:53 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6829405322292658 on epoch=41
06/13/2022 08:04:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=41
06/13/2022 08:04:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
06/13/2022 08:05:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
06/13/2022 08:05:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 08:05:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=41
06/13/2022 08:05:31 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8097379741717335 on epoch=41
06/13/2022 08:05:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
06/13/2022 08:05:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=42
06/13/2022 08:05:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
06/13/2022 08:05:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=42
06/13/2022 08:05:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=42
06/13/2022 08:06:08 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8565971684883787 on epoch=42
06/13/2022 08:06:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=43
06/13/2022 08:06:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=43
06/13/2022 08:06:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
06/13/2022 08:06:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=43
06/13/2022 08:06:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
06/13/2022 08:06:46 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7016807057350629 on epoch=43
06/13/2022 08:06:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
06/13/2022 08:06:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
06/13/2022 08:06:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=44
06/13/2022 08:06:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
06/13/2022 08:06:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
06/13/2022 08:07:24 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7509330337326079 on epoch=44
06/13/2022 08:07:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
06/13/2022 08:07:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
06/13/2022 08:07:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
06/13/2022 08:07:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=45
06/13/2022 08:07:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=45
06/13/2022 08:08:01 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7672489048258094 on epoch=45
06/13/2022 08:08:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
06/13/2022 08:08:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
06/13/2022 08:08:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 08:08:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=46
06/13/2022 08:08:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
06/13/2022 08:08:39 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8616790035265425 on epoch=46
06/13/2022 08:08:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=46
06/13/2022 08:08:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=46
06/13/2022 08:08:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
06/13/2022 08:08:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=47
06/13/2022 08:08:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
06/13/2022 08:09:17 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8671089978141682 on epoch=47
06/13/2022 08:09:17 - INFO - __main__ - Saving model with best Classification-F1: 0.863290947549006 -> 0.8671089978141682 on epoch=47, global_step=2650
06/13/2022 08:09:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 08:09:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
06/13/2022 08:09:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
06/13/2022 08:09:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
06/13/2022 08:09:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=48
06/13/2022 08:09:54 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9218400082816125 on epoch=48
06/13/2022 08:09:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8671089978141682 -> 0.9218400082816125 on epoch=48, global_step=2700
06/13/2022 08:09:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
06/13/2022 08:09:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=48
06/13/2022 08:10:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
06/13/2022 08:10:04 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
06/13/2022 08:10:07 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=49
06/13/2022 08:10:31 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.921356159996995 on epoch=49
06/13/2022 08:10:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
06/13/2022 08:10:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
06/13/2022 08:10:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
06/13/2022 08:10:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=49
06/13/2022 08:10:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=49
06/13/2022 08:11:09 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9244746205416183 on epoch=49
06/13/2022 08:11:09 - INFO - __main__ - Saving model with best Classification-F1: 0.9218400082816125 -> 0.9244746205416183 on epoch=49, global_step=2800
06/13/2022 08:11:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
06/13/2022 08:11:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
06/13/2022 08:11:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=50
06/13/2022 08:11:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
06/13/2022 08:11:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
06/13/2022 08:11:47 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9203689393731944 on epoch=50
06/13/2022 08:11:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
06/13/2022 08:11:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=51
06/13/2022 08:11:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
06/13/2022 08:11:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
06/13/2022 08:12:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 08:12:25 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9208236832889601 on epoch=51
06/13/2022 08:12:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
06/13/2022 08:12:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
06/13/2022 08:12:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=52
06/13/2022 08:12:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
06/13/2022 08:12:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 08:13:03 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9208243652198514 on epoch=52
06/13/2022 08:13:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
06/13/2022 08:13:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
06/13/2022 08:13:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
06/13/2022 08:13:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=53
06/13/2022 08:13:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=53
06/13/2022 08:13:18 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:13:18 - INFO - __main__ - Printing 3 examples
06/13/2022 08:13:18 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 08:13:18 - INFO - __main__ - ['Plant']
06/13/2022 08:13:18 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 08:13:18 - INFO - __main__ - ['Plant']
06/13/2022 08:13:18 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 08:13:18 - INFO - __main__ - ['Plant']
06/13/2022 08:13:18 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:13:18 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:13:19 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 08:13:19 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:13:19 - INFO - __main__ - Printing 3 examples
06/13/2022 08:13:19 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 08:13:19 - INFO - __main__ - ['Plant']
06/13/2022 08:13:19 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 08:13:19 - INFO - __main__ - ['Plant']
06/13/2022 08:13:19 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 08:13:19 - INFO - __main__ - ['Plant']
06/13/2022 08:13:19 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:13:20 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:13:20 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 08:13:36 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:13:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:13:37 - INFO - __main__ - Starting training!
06/13/2022 08:13:40 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9223991713040193 on epoch=53
06/13/2022 08:13:40 - INFO - __main__ - save last model!
06/13/2022 08:13:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 08:13:41 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 08:13:41 - INFO - __main__ - Printing 3 examples
06/13/2022 08:13:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 08:13:41 - INFO - __main__ - ['Animal']
06/13/2022 08:13:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 08:13:41 - INFO - __main__ - ['Animal']
06/13/2022 08:13:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 08:13:41 - INFO - __main__ - ['Village']
06/13/2022 08:13:41 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:13:42 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:13:46 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 08:15:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.5_8_predictions.txt
06/13/2022 08:15:51 - INFO - __main__ - Classification-F1 on test data: 0.7252
06/13/2022 08:15:51 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.5, bsz=8, dev_performance=0.9244746205416183, test_performance=0.7252181985655691
06/13/2022 08:15:51 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.4, bsz=8 ...
06/13/2022 08:15:52 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:15:52 - INFO - __main__ - Printing 3 examples
06/13/2022 08:15:52 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 08:15:52 - INFO - __main__ - ['Plant']
06/13/2022 08:15:52 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 08:15:52 - INFO - __main__ - ['Plant']
06/13/2022 08:15:52 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 08:15:52 - INFO - __main__ - ['Plant']
06/13/2022 08:15:52 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:15:52 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:15:53 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 08:15:53 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:15:53 - INFO - __main__ - Printing 3 examples
06/13/2022 08:15:53 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 08:15:53 - INFO - __main__ - ['Plant']
06/13/2022 08:15:53 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 08:15:53 - INFO - __main__ - ['Plant']
06/13/2022 08:15:53 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 08:15:53 - INFO - __main__ - ['Plant']
06/13/2022 08:15:53 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:15:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:15:55 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 08:16:13 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:16:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:16:14 - INFO - __main__ - Starting training!
06/13/2022 08:16:18 - INFO - __main__ - Step 10 Global step 10 Train loss 4.34 on epoch=0
06/13/2022 08:16:21 - INFO - __main__ - Step 20 Global step 20 Train loss 2.87 on epoch=0
06/13/2022 08:16:23 - INFO - __main__ - Step 30 Global step 30 Train loss 2.27 on epoch=0
06/13/2022 08:16:26 - INFO - __main__ - Step 40 Global step 40 Train loss 1.74 on epoch=0
06/13/2022 08:16:29 - INFO - __main__ - Step 50 Global step 50 Train loss 1.53 on epoch=0
06/13/2022 08:16:53 - INFO - __main__ - Global step 50 Train loss 2.55 Classification-F1 0.2656617839516679 on epoch=0
06/13/2022 08:16:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2656617839516679 on epoch=0, global_step=50
06/13/2022 08:16:56 - INFO - __main__ - Step 60 Global step 60 Train loss 0.95 on epoch=1
06/13/2022 08:16:59 - INFO - __main__ - Step 70 Global step 70 Train loss 0.92 on epoch=1
06/13/2022 08:17:01 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=1
06/13/2022 08:17:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.73 on epoch=1
06/13/2022 08:17:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=1
06/13/2022 08:17:32 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.5347040152671336 on epoch=1
06/13/2022 08:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.2656617839516679 -> 0.5347040152671336 on epoch=1, global_step=100
06/13/2022 08:17:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=1
06/13/2022 08:17:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.50 on epoch=2
06/13/2022 08:17:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.65 on epoch=2
06/13/2022 08:17:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=2
06/13/2022 08:17:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=2
06/13/2022 08:18:12 - INFO - __main__ - Global step 150 Train loss 0.61 Classification-F1 0.4317894044691347 on epoch=2
06/13/2022 08:18:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=2
06/13/2022 08:18:17 - INFO - __main__ - Step 170 Global step 170 Train loss 0.45 on epoch=3
06/13/2022 08:18:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.45 on epoch=3
06/13/2022 08:18:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=3
06/13/2022 08:18:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=3
06/13/2022 08:18:57 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.4808312629091832 on epoch=3
06/13/2022 08:19:00 - INFO - __main__ - Step 210 Global step 210 Train loss 0.46 on epoch=3
06/13/2022 08:19:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=3
06/13/2022 08:19:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.35 on epoch=4
06/13/2022 08:19:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.35 on epoch=4
06/13/2022 08:19:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.42 on epoch=4
06/13/2022 08:19:40 - INFO - __main__ - Global step 250 Train loss 0.42 Classification-F1 0.574980171613562 on epoch=4
06/13/2022 08:19:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5347040152671336 -> 0.574980171613562 on epoch=4, global_step=250
06/13/2022 08:19:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=4
06/13/2022 08:19:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=4
06/13/2022 08:19:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=4
06/13/2022 08:19:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=5
06/13/2022 08:19:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=5
06/13/2022 08:20:22 - INFO - __main__ - Global step 300 Train loss 0.32 Classification-F1 0.6993971979920828 on epoch=5
06/13/2022 08:20:22 - INFO - __main__ - Saving model with best Classification-F1: 0.574980171613562 -> 0.6993971979920828 on epoch=5, global_step=300
06/13/2022 08:20:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.26 on epoch=5
06/13/2022 08:20:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=5
06/13/2022 08:20:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.26 on epoch=5
06/13/2022 08:20:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.18 on epoch=6
06/13/2022 08:20:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=6
06/13/2022 08:21:09 - INFO - __main__ - Global step 350 Train loss 0.24 Classification-F1 0.8957132668071814 on epoch=6
06/13/2022 08:21:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6993971979920828 -> 0.8957132668071814 on epoch=6, global_step=350
06/13/2022 08:21:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.22 on epoch=6
06/13/2022 08:21:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=6
06/13/2022 08:21:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=6
06/13/2022 08:21:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=6
06/13/2022 08:21:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.15 on epoch=7
06/13/2022 08:21:50 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.8393385239811038 on epoch=7
06/13/2022 08:21:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.19 on epoch=7
06/13/2022 08:21:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=7
06/13/2022 08:21:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=7
06/13/2022 08:22:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=7
06/13/2022 08:22:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.14 on epoch=8
06/13/2022 08:22:33 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.9822439900812195 on epoch=8
06/13/2022 08:22:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8957132668071814 -> 0.9822439900812195 on epoch=8, global_step=450
06/13/2022 08:22:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=8
06/13/2022 08:22:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=8
06/13/2022 08:22:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=8
06/13/2022 08:22:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=8
06/13/2022 08:22:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=8
06/13/2022 08:23:18 - INFO - __main__ - Global step 500 Train loss 0.16 Classification-F1 0.7621759216730144 on epoch=8
06/13/2022 08:23:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=9
06/13/2022 08:23:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=9
06/13/2022 08:23:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=9
06/13/2022 08:23:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=9
06/13/2022 08:23:32 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=9
06/13/2022 08:24:05 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.8423013019088048 on epoch=9
06/13/2022 08:24:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=9
06/13/2022 08:24:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=10
06/13/2022 08:24:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=10
06/13/2022 08:24:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=10
06/13/2022 08:24:18 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=10
06/13/2022 08:24:52 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.8924152302889217 on epoch=10
06/13/2022 08:24:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=10
06/13/2022 08:24:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=11
06/13/2022 08:25:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=11
06/13/2022 08:25:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
06/13/2022 08:25:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=11
06/13/2022 08:25:38 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.9755178608518372 on epoch=11
06/13/2022 08:25:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=11
06/13/2022 08:25:43 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=11
06/13/2022 08:25:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=12
06/13/2022 08:25:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=12
06/13/2022 08:25:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=12
06/13/2022 08:26:23 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.7972840508361202 on epoch=12
06/13/2022 08:26:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=12
06/13/2022 08:26:28 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=12
06/13/2022 08:26:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=13
06/13/2022 08:26:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=13
06/13/2022 08:26:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=13
06/13/2022 08:27:06 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.9754429716612408 on epoch=13
06/13/2022 08:27:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=13
06/13/2022 08:27:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=13
06/13/2022 08:27:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=13
06/13/2022 08:27:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=14
06/13/2022 08:27:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=14
06/13/2022 08:27:49 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.8559725700230612 on epoch=14
06/13/2022 08:27:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=14
06/13/2022 08:27:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=14
06/13/2022 08:27:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=14
06/13/2022 08:28:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=14
06/13/2022 08:28:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=15
06/13/2022 08:28:34 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.909641474735605 on epoch=15
06/13/2022 08:28:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=15
06/13/2022 08:28:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=15
06/13/2022 08:28:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=15
06/13/2022 08:28:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=15
06/13/2022 08:28:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=16
06/13/2022 08:29:18 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.8357793580717279 on epoch=16
06/13/2022 08:29:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=16
06/13/2022 08:29:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=16
06/13/2022 08:29:26 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=16
06/13/2022 08:29:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=16
06/13/2022 08:29:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=16
06/13/2022 08:30:01 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.9218551608724278 on epoch=16
06/13/2022 08:30:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=17
06/13/2022 08:30:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=17
06/13/2022 08:30:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=17
06/13/2022 08:30:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=17
06/13/2022 08:30:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=17
06/13/2022 08:30:45 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.85928912528697 on epoch=17
06/13/2022 08:30:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=18
06/13/2022 08:30:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=18
06/13/2022 08:30:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=18
06/13/2022 08:30:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=18
06/13/2022 08:30:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=18
06/13/2022 08:31:27 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9164124880992894 on epoch=18
06/13/2022 08:31:29 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
06/13/2022 08:31:32 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=19
06/13/2022 08:31:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=19
06/13/2022 08:31:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=19
06/13/2022 08:31:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=19
06/13/2022 08:32:09 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9118832629330682 on epoch=19
06/13/2022 08:32:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=19
06/13/2022 08:32:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=19
06/13/2022 08:32:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=20
06/13/2022 08:32:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=20
06/13/2022 08:32:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=20
06/13/2022 08:32:50 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9153461653240785 on epoch=20
06/13/2022 08:32:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=20
06/13/2022 08:32:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=20
06/13/2022 08:32:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=21
06/13/2022 08:33:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=21
06/13/2022 08:33:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
06/13/2022 08:33:31 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.9170364780714118 on epoch=21
06/13/2022 08:33:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=21
06/13/2022 08:33:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=21
06/13/2022 08:33:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=21
06/13/2022 08:33:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=22
06/13/2022 08:33:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=22
06/13/2022 08:34:13 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7464575839969957 on epoch=22
06/13/2022 08:34:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=22
06/13/2022 08:34:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=22
06/13/2022 08:34:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=22
06/13/2022 08:34:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
06/13/2022 08:34:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
06/13/2022 08:34:52 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7118630586706205 on epoch=23
06/13/2022 08:34:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=23
06/13/2022 08:34:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=23
06/13/2022 08:35:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=23
06/13/2022 08:35:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=23
06/13/2022 08:35:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=24
06/13/2022 08:35:35 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9161807436779291 on epoch=24
06/13/2022 08:35:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=24
06/13/2022 08:35:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
06/13/2022 08:35:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=24
06/13/2022 08:35:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=24
06/13/2022 08:35:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=24
06/13/2022 08:36:16 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9037347912157091 on epoch=24
06/13/2022 08:36:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=25
06/13/2022 08:36:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=25
06/13/2022 08:36:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=25
06/13/2022 08:36:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=25
06/13/2022 08:36:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=25
06/13/2022 08:36:54 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7818430344876778 on epoch=25
06/13/2022 08:36:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=26
06/13/2022 08:36:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
06/13/2022 08:37:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=26
06/13/2022 08:37:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=26
06/13/2022 08:37:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=26
06/13/2022 08:37:33 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.5431842015993052 on epoch=26
06/13/2022 08:37:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=26
06/13/2022 08:37:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
06/13/2022 08:37:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=27
06/13/2022 08:37:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=27
06/13/2022 08:37:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
06/13/2022 08:38:13 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7367139203992782 on epoch=27
06/13/2022 08:38:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=27
06/13/2022 08:38:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=28
06/13/2022 08:38:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
06/13/2022 08:38:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=28
06/13/2022 08:38:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=28
06/13/2022 08:38:53 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.9102756715740604 on epoch=28
06/13/2022 08:38:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=28
06/13/2022 08:38:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
06/13/2022 08:39:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
06/13/2022 08:39:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=29
06/13/2022 08:39:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=29
06/13/2022 08:39:34 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9149586609886562 on epoch=29
06/13/2022 08:39:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=29
06/13/2022 08:39:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=29
06/13/2022 08:39:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=29
06/13/2022 08:39:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
06/13/2022 08:39:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=30
06/13/2022 08:40:15 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.916652578731475 on epoch=30
06/13/2022 08:40:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=30
06/13/2022 08:40:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=30
06/13/2022 08:40:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=30
06/13/2022 08:40:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=31
06/13/2022 08:40:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
06/13/2022 08:40:54 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8073297426823253 on epoch=31
06/13/2022 08:40:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
06/13/2022 08:41:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=31
06/13/2022 08:41:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=31
06/13/2022 08:41:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=31
06/13/2022 08:41:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=32
06/13/2022 08:41:34 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7505331382548328 on epoch=32
06/13/2022 08:41:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
06/13/2022 08:41:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
06/13/2022 08:41:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=32
06/13/2022 08:41:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
06/13/2022 08:41:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
06/13/2022 08:42:13 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7244585725804227 on epoch=33
06/13/2022 08:42:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=33
06/13/2022 08:42:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=33
06/13/2022 08:42:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=33
06/13/2022 08:42:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
06/13/2022 08:42:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=33
06/13/2022 08:42:52 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6969610547854547 on epoch=33
06/13/2022 08:42:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=34
06/13/2022 08:42:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
06/13/2022 08:43:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
06/13/2022 08:43:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
06/13/2022 08:43:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
06/13/2022 08:43:32 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7392053628220772 on epoch=34
06/13/2022 08:43:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
06/13/2022 08:43:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=35
06/13/2022 08:43:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
06/13/2022 08:43:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
06/13/2022 08:43:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=35
06/13/2022 08:44:11 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7445610967017271 on epoch=35
06/13/2022 08:44:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
06/13/2022 08:44:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=36
06/13/2022 08:44:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
06/13/2022 08:44:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=36
06/13/2022 08:44:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=36
06/13/2022 08:44:49 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9177033232926032 on epoch=36
06/13/2022 08:44:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
06/13/2022 08:44:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=36
06/13/2022 08:44:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=37
06/13/2022 08:45:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=37
06/13/2022 08:45:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=37
06/13/2022 08:45:30 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9197716838815081 on epoch=37
06/13/2022 08:45:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
06/13/2022 08:45:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
06/13/2022 08:45:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=38
06/13/2022 08:45:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=38
06/13/2022 08:45:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
06/13/2022 08:46:09 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8559950752898295 on epoch=38
06/13/2022 08:46:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
06/13/2022 08:46:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=38
06/13/2022 08:46:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=38
06/13/2022 08:46:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=39
06/13/2022 08:46:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
06/13/2022 08:46:48 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8566274678907906 on epoch=39
06/13/2022 08:46:50 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
06/13/2022 08:46:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
06/13/2022 08:46:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
06/13/2022 08:46:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
06/13/2022 08:47:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
06/13/2022 08:47:27 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.855828090196169 on epoch=40
06/13/2022 08:47:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=40
06/13/2022 08:47:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
06/13/2022 08:47:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=40
06/13/2022 08:47:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
06/13/2022 08:47:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 08:48:05 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.722690448429126 on epoch=41
06/13/2022 08:48:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=41
06/13/2022 08:48:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=41
06/13/2022 08:48:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
06/13/2022 08:48:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=41
06/13/2022 08:48:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
06/13/2022 08:48:44 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8510679257491898 on epoch=41
06/13/2022 08:48:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
06/13/2022 08:48:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
06/13/2022 08:48:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 08:48:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=42
06/13/2022 08:48:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
06/13/2022 08:49:24 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8540854712725061 on epoch=42
06/13/2022 08:49:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
06/13/2022 08:49:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=43
06/13/2022 08:49:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 08:49:35 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
06/13/2022 08:49:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
06/13/2022 08:50:03 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8478745822593243 on epoch=43
06/13/2022 08:50:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
06/13/2022 08:50:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
06/13/2022 08:50:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
06/13/2022 08:50:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 08:50:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
06/13/2022 08:50:43 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8955160841581636 on epoch=44
06/13/2022 08:50:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
06/13/2022 08:50:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=44
06/13/2022 08:50:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 08:50:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=45
06/13/2022 08:50:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
06/13/2022 08:51:25 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8662698224942834 on epoch=45
06/13/2022 08:51:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
06/13/2022 08:51:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=45
06/13/2022 08:51:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=46
06/13/2022 08:51:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=46
06/13/2022 08:51:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
06/13/2022 08:52:05 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6358023924656991 on epoch=46
06/13/2022 08:52:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
06/13/2022 08:52:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
06/13/2022 08:52:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
06/13/2022 08:52:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
06/13/2022 08:52:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=47
06/13/2022 08:52:48 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6778514952078505 on epoch=47
06/13/2022 08:52:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 08:52:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
06/13/2022 08:52:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=47
06/13/2022 08:52:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
06/13/2022 08:53:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
06/13/2022 08:53:31 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6457610413656009 on epoch=48
06/13/2022 08:53:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
06/13/2022 08:53:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
06/13/2022 08:53:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
06/13/2022 08:53:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
06/13/2022 08:53:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
06/13/2022 08:54:11 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.5061924293391543 on epoch=49
06/13/2022 08:54:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
06/13/2022 08:54:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=49
06/13/2022 08:54:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=49
06/13/2022 08:54:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=49
06/13/2022 08:54:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 08:54:51 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.5609142192678519 on epoch=49
06/13/2022 08:54:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=50
06/13/2022 08:54:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
06/13/2022 08:54:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=50
06/13/2022 08:55:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=50
06/13/2022 08:55:04 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
06/13/2022 08:55:32 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.758465213415202 on epoch=50
06/13/2022 08:55:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
06/13/2022 08:55:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
06/13/2022 08:55:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
06/13/2022 08:55:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
06/13/2022 08:55:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
06/13/2022 08:56:10 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.6034974877039768 on epoch=51
06/13/2022 08:56:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
06/13/2022 08:56:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
06/13/2022 08:56:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
06/13/2022 08:56:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
06/13/2022 08:56:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=52
06/13/2022 08:56:49 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7231289904118562 on epoch=52
06/13/2022 08:56:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=52
06/13/2022 08:56:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
06/13/2022 08:56:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
06/13/2022 08:57:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
06/13/2022 08:57:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 08:57:04 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:57:04 - INFO - __main__ - Printing 3 examples
06/13/2022 08:57:04 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 08:57:04 - INFO - __main__ - ['Plant']
06/13/2022 08:57:04 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 08:57:04 - INFO - __main__ - ['Plant']
06/13/2022 08:57:04 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 08:57:04 - INFO - __main__ - ['Plant']
06/13/2022 08:57:04 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:57:04 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:57:05 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 08:57:05 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:57:05 - INFO - __main__ - Printing 3 examples
06/13/2022 08:57:05 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 08:57:05 - INFO - __main__ - ['Plant']
06/13/2022 08:57:05 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 08:57:05 - INFO - __main__ - ['Plant']
06/13/2022 08:57:05 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 08:57:05 - INFO - __main__ - ['Plant']
06/13/2022 08:57:05 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:57:06 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:57:07 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 08:57:25 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 08:57:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 08:57:26 - INFO - __main__ - Starting training!
06/13/2022 08:57:29 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6528089338845511 on epoch=53
06/13/2022 08:57:29 - INFO - __main__ - save last model!
06/13/2022 08:57:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 08:57:29 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 08:57:29 - INFO - __main__ - Printing 3 examples
06/13/2022 08:57:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 08:57:29 - INFO - __main__ - ['Animal']
06/13/2022 08:57:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 08:57:29 - INFO - __main__ - ['Animal']
06/13/2022 08:57:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 08:57:29 - INFO - __main__ - ['Village']
06/13/2022 08:57:29 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:57:31 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:57:34 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 08:59:45 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.4_8_predictions.txt
06/13/2022 08:59:45 - INFO - __main__ - Classification-F1 on test data: 0.4715
06/13/2022 08:59:46 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.4, bsz=8, dev_performance=0.9822439900812195, test_performance=0.4715056052225758
06/13/2022 08:59:46 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.3, bsz=8 ...
06/13/2022 08:59:46 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:59:46 - INFO - __main__ - Printing 3 examples
06/13/2022 08:59:46 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 08:59:46 - INFO - __main__ - ['Plant']
06/13/2022 08:59:46 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 08:59:46 - INFO - __main__ - ['Plant']
06/13/2022 08:59:46 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 08:59:46 - INFO - __main__ - ['Plant']
06/13/2022 08:59:46 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:59:47 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:59:48 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 08:59:48 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 08:59:48 - INFO - __main__ - Printing 3 examples
06/13/2022 08:59:48 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 08:59:48 - INFO - __main__ - ['Plant']
06/13/2022 08:59:48 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 08:59:48 - INFO - __main__ - ['Plant']
06/13/2022 08:59:48 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 08:59:48 - INFO - __main__ - ['Plant']
06/13/2022 08:59:48 - INFO - __main__ - Tokenizing Input ...
06/13/2022 08:59:48 - INFO - __main__ - Tokenizing Output ...
06/13/2022 08:59:49 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 09:00:05 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:00:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:00:05 - INFO - __main__ - Starting training!
06/13/2022 09:00:09 - INFO - __main__ - Step 10 Global step 10 Train loss 4.71 on epoch=0
06/13/2022 09:00:12 - INFO - __main__ - Step 20 Global step 20 Train loss 3.19 on epoch=0
06/13/2022 09:00:14 - INFO - __main__ - Step 30 Global step 30 Train loss 2.58 on epoch=0
06/13/2022 09:00:17 - INFO - __main__ - Step 40 Global step 40 Train loss 1.72 on epoch=0
06/13/2022 09:00:19 - INFO - __main__ - Step 50 Global step 50 Train loss 1.66 on epoch=0
06/13/2022 09:00:41 - INFO - __main__ - Global step 50 Train loss 2.77 Classification-F1 0.167708700304093 on epoch=0
06/13/2022 09:00:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.167708700304093 on epoch=0, global_step=50
06/13/2022 09:00:44 - INFO - __main__ - Step 60 Global step 60 Train loss 1.23 on epoch=1
06/13/2022 09:00:46 - INFO - __main__ - Step 70 Global step 70 Train loss 1.08 on epoch=1
06/13/2022 09:00:49 - INFO - __main__ - Step 80 Global step 80 Train loss 1.08 on epoch=1
06/13/2022 09:00:51 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=1
06/13/2022 09:00:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=1
06/13/2022 09:01:18 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.38599965510396217 on epoch=1
06/13/2022 09:01:18 - INFO - __main__ - Saving model with best Classification-F1: 0.167708700304093 -> 0.38599965510396217 on epoch=1, global_step=100
06/13/2022 09:01:20 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=1
06/13/2022 09:01:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.77 on epoch=2
06/13/2022 09:01:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=2
06/13/2022 09:01:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=2
06/13/2022 09:01:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.66 on epoch=2
06/13/2022 09:01:55 - INFO - __main__ - Global step 150 Train loss 0.76 Classification-F1 0.38083457420700123 on epoch=2
06/13/2022 09:01:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=2
06/13/2022 09:02:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.55 on epoch=3
06/13/2022 09:02:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.46 on epoch=3
06/13/2022 09:02:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.56 on epoch=3
06/13/2022 09:02:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=3
06/13/2022 09:02:36 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.6278302830869801 on epoch=3
06/13/2022 09:02:36 - INFO - __main__ - Saving model with best Classification-F1: 0.38599965510396217 -> 0.6278302830869801 on epoch=3, global_step=200
06/13/2022 09:02:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=3
06/13/2022 09:02:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=3
06/13/2022 09:02:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.43 on epoch=4
06/13/2022 09:02:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=4
06/13/2022 09:02:49 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=4
06/13/2022 09:03:16 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.5934380019159283 on epoch=4
06/13/2022 09:03:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=4
06/13/2022 09:03:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=4
06/13/2022 09:03:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=4
06/13/2022 09:03:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=5
06/13/2022 09:03:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=5
06/13/2022 09:03:58 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.5195960688164123 on epoch=5
06/13/2022 09:04:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.31 on epoch=5
06/13/2022 09:04:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.24 on epoch=5
06/13/2022 09:04:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=5
06/13/2022 09:04:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=6
06/13/2022 09:04:11 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=6
06/13/2022 09:04:39 - INFO - __main__ - Global step 350 Train loss 0.29 Classification-F1 0.5044694932531929 on epoch=6
06/13/2022 09:04:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=6
06/13/2022 09:04:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=6
06/13/2022 09:04:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=6
06/13/2022 09:04:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=6
06/13/2022 09:04:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=7
06/13/2022 09:05:20 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.6045984340909916 on epoch=7
06/13/2022 09:05:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.20 on epoch=7
06/13/2022 09:05:25 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=7
06/13/2022 09:05:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=7
06/13/2022 09:05:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=7
06/13/2022 09:05:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=8
06/13/2022 09:06:02 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.6318308674676539 on epoch=8
06/13/2022 09:06:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6278302830869801 -> 0.6318308674676539 on epoch=8, global_step=450
06/13/2022 09:06:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=8
06/13/2022 09:06:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=8
06/13/2022 09:06:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=8
06/13/2022 09:06:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=8
06/13/2022 09:06:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=8
06/13/2022 09:06:46 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.6908661401091042 on epoch=8
06/13/2022 09:06:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6318308674676539 -> 0.6908661401091042 on epoch=8, global_step=500
06/13/2022 09:06:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=9
06/13/2022 09:06:51 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=9
06/13/2022 09:06:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=9
06/13/2022 09:06:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=9
06/13/2022 09:06:59 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=9
06/13/2022 09:07:28 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.6265450382306252 on epoch=9
06/13/2022 09:07:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=9
06/13/2022 09:07:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=10
06/13/2022 09:07:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=10
06/13/2022 09:07:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=10
06/13/2022 09:07:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=10
06/13/2022 09:08:11 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.716323285026425 on epoch=10
06/13/2022 09:08:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6908661401091042 -> 0.716323285026425 on epoch=10, global_step=600
06/13/2022 09:08:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=10
06/13/2022 09:08:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=11
06/13/2022 09:08:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=11
06/13/2022 09:08:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=11
06/13/2022 09:08:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=11
06/13/2022 09:08:52 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7112353342604609 on epoch=11
06/13/2022 09:08:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=11
06/13/2022 09:08:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=11
06/13/2022 09:09:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=12
06/13/2022 09:09:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=12
06/13/2022 09:09:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=12
06/13/2022 09:09:33 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.6654083595857789 on epoch=12
06/13/2022 09:09:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=12
06/13/2022 09:09:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=12
06/13/2022 09:09:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=13
06/13/2022 09:09:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=13
06/13/2022 09:09:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=13
06/13/2022 09:10:12 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7327051122633733 on epoch=13
06/13/2022 09:10:12 - INFO - __main__ - Saving model with best Classification-F1: 0.716323285026425 -> 0.7327051122633733 on epoch=13, global_step=750
06/13/2022 09:10:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=13
06/13/2022 09:10:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=13
06/13/2022 09:10:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=13
06/13/2022 09:10:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=14
06/13/2022 09:10:25 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=14
06/13/2022 09:10:55 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.8248518051671706 on epoch=14
06/13/2022 09:10:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7327051122633733 -> 0.8248518051671706 on epoch=14, global_step=800
06/13/2022 09:10:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=14
06/13/2022 09:11:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=14
06/13/2022 09:11:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=14
06/13/2022 09:11:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=14
06/13/2022 09:11:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=15
06/13/2022 09:11:35 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.7462472233802122 on epoch=15
06/13/2022 09:11:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=15
06/13/2022 09:11:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=15
06/13/2022 09:11:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=15
06/13/2022 09:11:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=15
06/13/2022 09:11:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=16
06/13/2022 09:12:18 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6471389739389386 on epoch=16
06/13/2022 09:12:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=16
06/13/2022 09:12:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=16
06/13/2022 09:12:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=16
06/13/2022 09:12:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=16
06/13/2022 09:12:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
06/13/2022 09:13:02 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.9140823235385285 on epoch=16
06/13/2022 09:13:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8248518051671706 -> 0.9140823235385285 on epoch=16, global_step=950
06/13/2022 09:13:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=17
06/13/2022 09:13:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=17
06/13/2022 09:13:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=17
06/13/2022 09:13:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=17
06/13/2022 09:13:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=17
06/13/2022 09:13:46 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.790746563565788 on epoch=17
06/13/2022 09:13:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=18
06/13/2022 09:13:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=18
06/13/2022 09:13:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=18
06/13/2022 09:13:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=18
06/13/2022 09:13:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=18
06/13/2022 09:14:28 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8550266725134683 on epoch=18
06/13/2022 09:14:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=18
06/13/2022 09:14:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=19
06/13/2022 09:14:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=19
06/13/2022 09:14:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=19
06/13/2022 09:14:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=19
06/13/2022 09:15:10 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.8555650070869808 on epoch=19
06/13/2022 09:15:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=19
06/13/2022 09:15:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=19
06/13/2022 09:15:17 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=20
06/13/2022 09:15:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=20
06/13/2022 09:15:22 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=20
06/13/2022 09:15:53 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.9144875565539808 on epoch=20
06/13/2022 09:15:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9140823235385285 -> 0.9144875565539808 on epoch=20, global_step=1150
06/13/2022 09:15:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=20
06/13/2022 09:15:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=20
06/13/2022 09:16:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=21
06/13/2022 09:16:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=21
06/13/2022 09:16:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
06/13/2022 09:16:35 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.9183164364259356 on epoch=21
06/13/2022 09:16:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9144875565539808 -> 0.9183164364259356 on epoch=21, global_step=1200
06/13/2022 09:16:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
06/13/2022 09:16:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=21
06/13/2022 09:16:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=21
06/13/2022 09:16:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=22
06/13/2022 09:16:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=22
06/13/2022 09:17:19 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.9767175072004063 on epoch=22
06/13/2022 09:17:19 - INFO - __main__ - Saving model with best Classification-F1: 0.9183164364259356 -> 0.9767175072004063 on epoch=22, global_step=1250
06/13/2022 09:17:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=22
06/13/2022 09:17:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=22
06/13/2022 09:17:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
06/13/2022 09:17:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
06/13/2022 09:17:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
06/13/2022 09:18:00 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.920314369100553 on epoch=23
06/13/2022 09:18:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=23
06/13/2022 09:18:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=23
06/13/2022 09:18:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=23
06/13/2022 09:18:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=23
06/13/2022 09:18:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
06/13/2022 09:18:40 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.8066817672012839 on epoch=24
06/13/2022 09:18:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=24
06/13/2022 09:18:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=24
06/13/2022 09:18:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=24
06/13/2022 09:18:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=24
06/13/2022 09:18:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=24
06/13/2022 09:19:22 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.850698711226098 on epoch=24
06/13/2022 09:19:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=25
06/13/2022 09:19:27 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=25
06/13/2022 09:19:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=25
06/13/2022 09:19:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=25
06/13/2022 09:19:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=25
06/13/2022 09:20:03 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8508705081776109 on epoch=25
06/13/2022 09:20:05 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=26
06/13/2022 09:20:08 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=26
06/13/2022 09:20:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=26
06/13/2022 09:20:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=26
06/13/2022 09:20:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=26
06/13/2022 09:20:45 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.9192724537467674 on epoch=26
06/13/2022 09:20:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=26
06/13/2022 09:20:50 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=27
06/13/2022 09:20:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=27
06/13/2022 09:20:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
06/13/2022 09:20:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
06/13/2022 09:21:28 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.9854967278457339 on epoch=27
06/13/2022 09:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.9767175072004063 -> 0.9854967278457339 on epoch=27, global_step=1550
06/13/2022 09:21:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=27
06/13/2022 09:21:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=28
06/13/2022 09:21:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
06/13/2022 09:21:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
06/13/2022 09:21:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=28
06/13/2022 09:22:08 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9866308521683932 on epoch=28
06/13/2022 09:22:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9854967278457339 -> 0.9866308521683932 on epoch=28, global_step=1600
06/13/2022 09:22:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=28
06/13/2022 09:22:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
06/13/2022 09:22:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
06/13/2022 09:22:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=29
06/13/2022 09:22:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=29
06/13/2022 09:22:49 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.984431666653535 on epoch=29
06/13/2022 09:22:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
06/13/2022 09:22:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=29
06/13/2022 09:22:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
06/13/2022 09:22:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=30
06/13/2022 09:23:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=30
06/13/2022 09:23:29 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9866491068887281 on epoch=30
06/13/2022 09:23:29 - INFO - __main__ - Saving model with best Classification-F1: 0.9866308521683932 -> 0.9866491068887281 on epoch=30, global_step=1700
06/13/2022 09:23:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
06/13/2022 09:23:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=30
06/13/2022 09:23:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=30
06/13/2022 09:23:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
06/13/2022 09:23:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=31
06/13/2022 09:24:11 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9844534385073688 on epoch=31
06/13/2022 09:24:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
06/13/2022 09:24:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
06/13/2022 09:24:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=31
06/13/2022 09:24:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
06/13/2022 09:24:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=32
06/13/2022 09:24:53 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.805613591686561 on epoch=32
06/13/2022 09:24:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
06/13/2022 09:24:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=32
06/13/2022 09:25:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
06/13/2022 09:25:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
06/13/2022 09:25:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
06/13/2022 09:25:34 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9855128851563808 on epoch=33
06/13/2022 09:25:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
06/13/2022 09:25:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=33
06/13/2022 09:25:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
06/13/2022 09:25:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
06/13/2022 09:25:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=33
06/13/2022 09:26:14 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9854883428352442 on epoch=33
06/13/2022 09:26:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=34
06/13/2022 09:26:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=34
06/13/2022 09:26:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
06/13/2022 09:26:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
06/13/2022 09:26:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
06/13/2022 09:26:53 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9182225512205376 on epoch=34
06/13/2022 09:26:55 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
06/13/2022 09:26:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
06/13/2022 09:27:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
06/13/2022 09:27:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
06/13/2022 09:27:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=35
06/13/2022 09:27:31 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8642162756157299 on epoch=35
06/13/2022 09:27:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=35
06/13/2022 09:27:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=36
06/13/2022 09:27:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
06/13/2022 09:27:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
06/13/2022 09:27:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
06/13/2022 09:28:12 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9129567373902335 on epoch=36
06/13/2022 09:28:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
06/13/2022 09:28:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=36
06/13/2022 09:28:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
06/13/2022 09:28:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=37
06/13/2022 09:28:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
06/13/2022 09:28:50 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9888544339009657 on epoch=37
06/13/2022 09:28:50 - INFO - __main__ - Saving model with best Classification-F1: 0.9866491068887281 -> 0.9888544339009657 on epoch=37, global_step=2100
06/13/2022 09:28:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
06/13/2022 09:28:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
06/13/2022 09:28:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=38
06/13/2022 09:29:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
06/13/2022 09:29:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
06/13/2022 09:29:29 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.80856551490787 on epoch=38
06/13/2022 09:29:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
06/13/2022 09:29:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=38
06/13/2022 09:29:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
06/13/2022 09:29:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
06/13/2022 09:29:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
06/13/2022 09:30:06 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7346950788871638 on epoch=39
06/13/2022 09:30:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
06/13/2022 09:30:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
06/13/2022 09:30:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=39
06/13/2022 09:30:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=39
06/13/2022 09:30:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=40
06/13/2022 09:30:45 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7533615569629176 on epoch=40
06/13/2022 09:30:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 09:30:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
06/13/2022 09:30:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
06/13/2022 09:30:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
06/13/2022 09:30:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
06/13/2022 09:31:23 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8588032959549947 on epoch=41
06/13/2022 09:31:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
06/13/2022 09:31:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=41
06/13/2022 09:31:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
06/13/2022 09:31:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=41
06/13/2022 09:31:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
06/13/2022 09:32:01 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7576884266398357 on epoch=41
06/13/2022 09:32:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
06/13/2022 09:32:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
06/13/2022 09:32:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
06/13/2022 09:32:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=42
06/13/2022 09:32:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
06/13/2022 09:32:38 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7178799377984684 on epoch=42
06/13/2022 09:32:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
06/13/2022 09:32:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=43
06/13/2022 09:32:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
06/13/2022 09:32:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=43
06/13/2022 09:32:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
06/13/2022 09:33:14 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7052035026837314 on epoch=43
06/13/2022 09:33:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=43
06/13/2022 09:33:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
06/13/2022 09:33:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=44
06/13/2022 09:33:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=44
06/13/2022 09:33:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
06/13/2022 09:33:53 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7620878397008745 on epoch=44
06/13/2022 09:33:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
06/13/2022 09:33:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=44
06/13/2022 09:34:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 09:34:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 09:34:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
06/13/2022 09:34:30 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8636375039043814 on epoch=45
06/13/2022 09:34:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=45
06/13/2022 09:34:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=45
06/13/2022 09:34:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
06/13/2022 09:34:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=46
06/13/2022 09:34:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
06/13/2022 09:35:09 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.81035071772601 on epoch=46
06/13/2022 09:35:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=46
06/13/2022 09:35:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
06/13/2022 09:35:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.12 on epoch=46
06/13/2022 09:35:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
06/13/2022 09:35:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
06/13/2022 09:35:47 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.9234325087066114 on epoch=47
06/13/2022 09:35:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
06/13/2022 09:35:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
06/13/2022 09:35:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
06/13/2022 09:35:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
06/13/2022 09:36:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=48
06/13/2022 09:36:25 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7612798556804576 on epoch=48
06/13/2022 09:36:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
06/13/2022 09:36:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=48
06/13/2022 09:36:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
06/13/2022 09:36:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=48
06/13/2022 09:36:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
06/13/2022 09:37:03 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9910880506670949 on epoch=49
06/13/2022 09:37:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9888544339009657 -> 0.9910880506670949 on epoch=49, global_step=2750
06/13/2022 09:37:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
06/13/2022 09:37:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
06/13/2022 09:37:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
06/13/2022 09:37:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
06/13/2022 09:37:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
06/13/2022 09:37:40 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8642106509942071 on epoch=49
06/13/2022 09:37:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
06/13/2022 09:37:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
06/13/2022 09:37:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
06/13/2022 09:37:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
06/13/2022 09:37:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
06/13/2022 09:38:18 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7129006674579655 on epoch=50
06/13/2022 09:38:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 09:38:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
06/13/2022 09:38:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
06/13/2022 09:38:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
06/13/2022 09:38:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
06/13/2022 09:38:55 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9207984050070663 on epoch=51
06/13/2022 09:38:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
06/13/2022 09:39:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
06/13/2022 09:39:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
06/13/2022 09:39:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
06/13/2022 09:39:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=52
06/13/2022 09:39:33 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8652174403959791 on epoch=52
06/13/2022 09:39:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
06/13/2022 09:39:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=53
06/13/2022 09:39:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
06/13/2022 09:39:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
06/13/2022 09:39:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
06/13/2022 09:39:47 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 09:39:47 - INFO - __main__ - Printing 3 examples
06/13/2022 09:39:47 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 09:39:47 - INFO - __main__ - ['Plant']
06/13/2022 09:39:47 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 09:39:47 - INFO - __main__ - ['Plant']
06/13/2022 09:39:47 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 09:39:47 - INFO - __main__ - ['Plant']
06/13/2022 09:39:47 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:39:47 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:39:48 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 09:39:48 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 09:39:48 - INFO - __main__ - Printing 3 examples
06/13/2022 09:39:48 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 09:39:48 - INFO - __main__ - ['Plant']
06/13/2022 09:39:48 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 09:39:48 - INFO - __main__ - ['Plant']
06/13/2022 09:39:48 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 09:39:48 - INFO - __main__ - ['Plant']
06/13/2022 09:39:48 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:39:49 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:39:50 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 09:40:08 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:40:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:40:09 - INFO - __main__ - Starting training!
06/13/2022 09:40:11 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.987747404306381 on epoch=53
06/13/2022 09:40:11 - INFO - __main__ - save last model!
06/13/2022 09:40:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 09:40:11 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 09:40:11 - INFO - __main__ - Printing 3 examples
06/13/2022 09:40:11 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 09:40:11 - INFO - __main__ - ['Animal']
06/13/2022 09:40:11 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 09:40:11 - INFO - __main__ - ['Animal']
06/13/2022 09:40:11 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 09:40:11 - INFO - __main__ - ['Village']
06/13/2022 09:40:11 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:40:13 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:40:17 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 09:42:24 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.3_8_predictions.txt
06/13/2022 09:42:24 - INFO - __main__ - Classification-F1 on test data: 0.7252
06/13/2022 09:42:25 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.3, bsz=8, dev_performance=0.9910880506670949, test_performance=0.7252440325253602
06/13/2022 09:42:25 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.2, bsz=8 ...
06/13/2022 09:42:26 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 09:42:26 - INFO - __main__ - Printing 3 examples
06/13/2022 09:42:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/13/2022 09:42:26 - INFO - __main__ - ['Plant']
06/13/2022 09:42:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/13/2022 09:42:26 - INFO - __main__ - ['Plant']
06/13/2022 09:42:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/13/2022 09:42:26 - INFO - __main__ - ['Plant']
06/13/2022 09:42:26 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:42:26 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:42:27 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 09:42:27 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 09:42:27 - INFO - __main__ - Printing 3 examples
06/13/2022 09:42:27 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
06/13/2022 09:42:27 - INFO - __main__ - ['Plant']
06/13/2022 09:42:27 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
06/13/2022 09:42:27 - INFO - __main__ - ['Plant']
06/13/2022 09:42:27 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
06/13/2022 09:42:27 - INFO - __main__ - ['Plant']
06/13/2022 09:42:27 - INFO - __main__ - Tokenizing Input ...
06/13/2022 09:42:28 - INFO - __main__ - Tokenizing Output ...
06/13/2022 09:42:29 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 09:42:44 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 09:42:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 09:42:45 - INFO - __main__ - Starting training!
06/13/2022 09:42:48 - INFO - __main__ - Step 10 Global step 10 Train loss 5.04 on epoch=0
06/13/2022 09:42:51 - INFO - __main__ - Step 20 Global step 20 Train loss 3.57 on epoch=0
06/13/2022 09:42:53 - INFO - __main__ - Step 30 Global step 30 Train loss 3.01 on epoch=0
06/13/2022 09:42:56 - INFO - __main__ - Step 40 Global step 40 Train loss 2.38 on epoch=0
06/13/2022 09:42:58 - INFO - __main__ - Step 50 Global step 50 Train loss 2.30 on epoch=0
06/13/2022 09:43:21 - INFO - __main__ - Global step 50 Train loss 3.26 Classification-F1 0.05926025860791183 on epoch=0
06/13/2022 09:43:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05926025860791183 on epoch=0, global_step=50
06/13/2022 09:43:24 - INFO - __main__ - Step 60 Global step 60 Train loss 1.54 on epoch=1
06/13/2022 09:43:27 - INFO - __main__ - Step 70 Global step 70 Train loss 1.49 on epoch=1
06/13/2022 09:43:29 - INFO - __main__ - Step 80 Global step 80 Train loss 1.44 on epoch=1
06/13/2022 09:43:32 - INFO - __main__ - Step 90 Global step 90 Train loss 1.21 on epoch=1
06/13/2022 09:43:34 - INFO - __main__ - Step 100 Global step 100 Train loss 1.05 on epoch=1
06/13/2022 09:43:58 - INFO - __main__ - Global step 100 Train loss 1.35 Classification-F1 0.21834909283014364 on epoch=1
06/13/2022 09:43:58 - INFO - __main__ - Saving model with best Classification-F1: 0.05926025860791183 -> 0.21834909283014364 on epoch=1, global_step=100
06/13/2022 09:44:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=1
06/13/2022 09:44:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.76 on epoch=2
06/13/2022 09:44:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=2
06/13/2022 09:44:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.86 on epoch=2
06/13/2022 09:44:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=2
06/13/2022 09:44:35 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.45968031714308394 on epoch=2
06/13/2022 09:44:35 - INFO - __main__ - Saving model with best Classification-F1: 0.21834909283014364 -> 0.45968031714308394 on epoch=2, global_step=150
06/13/2022 09:44:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.79 on epoch=2
06/13/2022 09:44:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=3
06/13/2022 09:44:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.66 on epoch=3
06/13/2022 09:44:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=3
06/13/2022 09:44:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.74 on epoch=3
06/13/2022 09:45:16 - INFO - __main__ - Global step 200 Train loss 0.67 Classification-F1 0.46032795915629293 on epoch=3
06/13/2022 09:45:16 - INFO - __main__ - Saving model with best Classification-F1: 0.45968031714308394 -> 0.46032795915629293 on epoch=3, global_step=200
06/13/2022 09:45:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=3
06/13/2022 09:45:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=3
06/13/2022 09:45:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=4
06/13/2022 09:45:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.61 on epoch=4
06/13/2022 09:45:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.54 on epoch=4
06/13/2022 09:45:56 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.6069346304773389 on epoch=4
06/13/2022 09:45:56 - INFO - __main__ - Saving model with best Classification-F1: 0.46032795915629293 -> 0.6069346304773389 on epoch=4, global_step=250
06/13/2022 09:45:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=4
06/13/2022 09:46:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=4
06/13/2022 09:46:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=4
06/13/2022 09:46:07 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=5
06/13/2022 09:46:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=5
06/13/2022 09:46:38 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.5741941713542412 on epoch=5
06/13/2022 09:46:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.50 on epoch=5
06/13/2022 09:46:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=5
06/13/2022 09:46:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=5
06/13/2022 09:46:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=6
06/13/2022 09:46:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=6
06/13/2022 09:47:20 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6589383867391123 on epoch=6
06/13/2022 09:47:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6069346304773389 -> 0.6589383867391123 on epoch=6, global_step=350
06/13/2022 09:47:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=6
06/13/2022 09:47:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=6
06/13/2022 09:47:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=6
06/13/2022 09:47:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=6
06/13/2022 09:47:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=7
06/13/2022 09:48:04 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.6069584602370124 on epoch=7
06/13/2022 09:48:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=7
06/13/2022 09:48:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=7
06/13/2022 09:48:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=7
06/13/2022 09:48:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=7
06/13/2022 09:48:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=8
06/13/2022 09:48:46 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.6757895174064927 on epoch=8
06/13/2022 09:48:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6589383867391123 -> 0.6757895174064927 on epoch=8, global_step=450
06/13/2022 09:48:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=8
06/13/2022 09:48:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=8
06/13/2022 09:48:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=8
06/13/2022 09:48:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=8
06/13/2022 09:48:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=8
06/13/2022 09:49:30 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.7791845113375387 on epoch=8
06/13/2022 09:49:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6757895174064927 -> 0.7791845113375387 on epoch=8, global_step=500
06/13/2022 09:49:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=9
06/13/2022 09:49:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=9
06/13/2022 09:49:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=9
06/13/2022 09:49:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=9
06/13/2022 09:49:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=9
06/13/2022 09:50:10 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.6895060576934665 on epoch=9
06/13/2022 09:50:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=9
06/13/2022 09:50:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=10
06/13/2022 09:50:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=10
06/13/2022 09:50:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=10
06/13/2022 09:50:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=10
06/13/2022 09:50:52 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.7623647710889176 on epoch=10
06/13/2022 09:50:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=10
06/13/2022 09:50:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=11
06/13/2022 09:51:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=11
06/13/2022 09:51:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=11
06/13/2022 09:51:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=11
06/13/2022 09:51:37 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7053989136905814 on epoch=11
06/13/2022 09:51:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=11
06/13/2022 09:51:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=11
06/13/2022 09:51:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=12
06/13/2022 09:51:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=12
06/13/2022 09:51:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=12
06/13/2022 09:52:22 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.6314526197113873 on epoch=12
06/13/2022 09:52:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=12
06/13/2022 09:52:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=12
06/13/2022 09:52:30 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=13
06/13/2022 09:52:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=13
06/13/2022 09:52:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=13
06/13/2022 09:53:07 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.7485511997928205 on epoch=13
06/13/2022 09:53:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=13
06/13/2022 09:53:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=13
06/13/2022 09:53:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=13
06/13/2022 09:53:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=14
06/13/2022 09:53:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=14
06/13/2022 09:53:50 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.6817023331130247 on epoch=14
06/13/2022 09:53:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=14
06/13/2022 09:53:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=14
06/13/2022 09:53:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=14
06/13/2022 09:54:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=14
06/13/2022 09:54:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=15
06/13/2022 09:54:32 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.48413358336413415 on epoch=15
06/13/2022 09:54:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=15
06/13/2022 09:54:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=15
06/13/2022 09:54:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=15
06/13/2022 09:54:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=15
06/13/2022 09:54:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=16
06/13/2022 09:55:15 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.7095437476158343 on epoch=16
06/13/2022 09:55:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=16
06/13/2022 09:55:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=16
06/13/2022 09:55:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=16
06/13/2022 09:55:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=16
06/13/2022 09:55:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=16
06/13/2022 09:55:58 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7570879095382045 on epoch=16
06/13/2022 09:56:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=17
06/13/2022 09:56:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=17
06/13/2022 09:56:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=17
06/13/2022 09:56:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=17
06/13/2022 09:56:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=17
06/13/2022 09:56:40 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6436823102851172 on epoch=17
06/13/2022 09:56:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=18
06/13/2022 09:56:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=18
06/13/2022 09:56:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=18
06/13/2022 09:56:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=18
06/13/2022 09:56:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=18
06/13/2022 09:57:22 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6984897037668357 on epoch=18
06/13/2022 09:57:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=18
06/13/2022 09:57:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=19
06/13/2022 09:57:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=19
06/13/2022 09:57:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=19
06/13/2022 09:57:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=19
06/13/2022 09:58:03 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.7965712804106931 on epoch=19
06/13/2022 09:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7791845113375387 -> 0.7965712804106931 on epoch=19, global_step=1100
06/13/2022 09:58:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=19
06/13/2022 09:58:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=19
06/13/2022 09:58:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=20
06/13/2022 09:58:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=20
06/13/2022 09:58:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=20
06/13/2022 09:58:45 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7377203774627812 on epoch=20
06/13/2022 09:58:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=20
06/13/2022 09:58:50 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=20
06/13/2022 09:58:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=21
06/13/2022 09:58:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=21
06/13/2022 09:58:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
06/13/2022 09:59:26 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7948417649114305 on epoch=21
06/13/2022 09:59:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=21
06/13/2022 09:59:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=21
06/13/2022 09:59:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=21
06/13/2022 09:59:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=22
06/13/2022 09:59:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=22
06/13/2022 10:00:07 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.643022651222236 on epoch=22
06/13/2022 10:00:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=22
06/13/2022 10:00:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=22
06/13/2022 10:00:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
06/13/2022 10:00:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
06/13/2022 10:00:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
06/13/2022 10:00:47 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7537850227720369 on epoch=23
06/13/2022 10:00:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=23
06/13/2022 10:00:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=23
06/13/2022 10:00:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=23
06/13/2022 10:00:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=23
06/13/2022 10:01:00 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.17 on epoch=24
06/13/2022 10:01:31 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7828378979314344 on epoch=24
06/13/2022 10:01:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=24
06/13/2022 10:01:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=24
06/13/2022 10:01:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=24
06/13/2022 10:01:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
06/13/2022 10:01:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=24
06/13/2022 10:02:14 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7630164181106727 on epoch=24
06/13/2022 10:02:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
06/13/2022 10:02:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=25
06/13/2022 10:02:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=25
06/13/2022 10:02:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=25
06/13/2022 10:02:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=25
06/13/2022 10:02:55 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7484584649881815 on epoch=25
06/13/2022 10:02:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=26
06/13/2022 10:03:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=26
06/13/2022 10:03:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
06/13/2022 10:03:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
06/13/2022 10:03:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=26
06/13/2022 10:03:36 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.856502493979314 on epoch=26
06/13/2022 10:03:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7965712804106931 -> 0.856502493979314 on epoch=26, global_step=1500
06/13/2022 10:03:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=26
06/13/2022 10:03:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=27
06/13/2022 10:03:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=27
06/13/2022 10:03:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=27
06/13/2022 10:03:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
06/13/2022 10:04:17 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8598320017834913 on epoch=27
06/13/2022 10:04:17 - INFO - __main__ - Saving model with best Classification-F1: 0.856502493979314 -> 0.8598320017834913 on epoch=27, global_step=1550
06/13/2022 10:04:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=27
06/13/2022 10:04:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
06/13/2022 10:04:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=28
06/13/2022 10:04:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
06/13/2022 10:04:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=28
06/13/2022 10:04:56 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7638983696673223 on epoch=28
06/13/2022 10:04:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
06/13/2022 10:05:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=28
06/13/2022 10:05:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
06/13/2022 10:05:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=29
06/13/2022 10:05:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
06/13/2022 10:05:36 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8613190156366275 on epoch=29
06/13/2022 10:05:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8598320017834913 -> 0.8613190156366275 on epoch=29, global_step=1650
06/13/2022 10:05:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
06/13/2022 10:05:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=29
06/13/2022 10:05:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=29
06/13/2022 10:05:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=30
06/13/2022 10:05:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=30
06/13/2022 10:06:18 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8579507449552166 on epoch=30
06/13/2022 10:06:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
06/13/2022 10:06:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=30
06/13/2022 10:06:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=30
06/13/2022 10:06:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=31
06/13/2022 10:06:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
06/13/2022 10:07:02 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8022386254464747 on epoch=31
06/13/2022 10:07:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=31
06/13/2022 10:07:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
06/13/2022 10:07:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=31
06/13/2022 10:07:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=31
06/13/2022 10:07:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=32
06/13/2022 10:07:42 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6196388865094228 on epoch=32
06/13/2022 10:07:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
06/13/2022 10:07:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
06/13/2022 10:07:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
06/13/2022 10:07:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=32
06/13/2022 10:07:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
06/13/2022 10:08:24 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9223883213049268 on epoch=33
06/13/2022 10:08:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8613190156366275 -> 0.9223883213049268 on epoch=33, global_step=1850
06/13/2022 10:08:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=33
06/13/2022 10:08:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=33
06/13/2022 10:08:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=33
06/13/2022 10:08:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
06/13/2022 10:08:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
06/13/2022 10:09:04 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9191798156350665 on epoch=33
06/13/2022 10:09:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
06/13/2022 10:09:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
06/13/2022 10:09:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
06/13/2022 10:09:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=34
06/13/2022 10:09:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
06/13/2022 10:09:45 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.754235555513716 on epoch=34
06/13/2022 10:09:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
06/13/2022 10:09:50 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
06/13/2022 10:09:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
06/13/2022 10:09:55 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=35
06/13/2022 10:09:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=35
06/13/2022 10:10:25 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8027668231307742 on epoch=35
06/13/2022 10:10:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=35
06/13/2022 10:10:31 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=36
06/13/2022 10:10:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=36
06/13/2022 10:10:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=36
06/13/2022 10:10:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
06/13/2022 10:11:06 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.8577523083068308 on epoch=36
06/13/2022 10:11:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=36
06/13/2022 10:11:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=36
06/13/2022 10:11:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
06/13/2022 10:11:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
06/13/2022 10:11:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=37
06/13/2022 10:11:46 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9140565873542065 on epoch=37
06/13/2022 10:11:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=37
06/13/2022 10:11:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=37
06/13/2022 10:11:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=38
06/13/2022 10:11:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=38
06/13/2022 10:11:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=38
06/13/2022 10:12:31 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.9855317286274545 on epoch=38
06/13/2022 10:12:31 - INFO - __main__ - Saving model with best Classification-F1: 0.9223883213049268 -> 0.9855317286274545 on epoch=38, global_step=2150
06/13/2022 10:12:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=38
06/13/2022 10:12:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=38
06/13/2022 10:12:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=38
06/13/2022 10:12:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
06/13/2022 10:12:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=39
06/13/2022 10:13:12 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9834311204573882 on epoch=39
06/13/2022 10:13:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=39
06/13/2022 10:13:18 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=39
06/13/2022 10:13:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
06/13/2022 10:13:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
06/13/2022 10:13:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=40
06/13/2022 10:13:53 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9866388789886907 on epoch=40
06/13/2022 10:13:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9855317286274545 -> 0.9866388789886907 on epoch=40, global_step=2250
06/13/2022 10:13:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
06/13/2022 10:13:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
06/13/2022 10:14:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
06/13/2022 10:14:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
06/13/2022 10:14:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=41
06/13/2022 10:14:34 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9833071662278117 on epoch=41
06/13/2022 10:14:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=41
06/13/2022 10:14:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
06/13/2022 10:14:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
06/13/2022 10:14:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 10:14:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
06/13/2022 10:15:16 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9855239938219904 on epoch=41
06/13/2022 10:15:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=42
06/13/2022 10:15:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=42
06/13/2022 10:15:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=42
06/13/2022 10:15:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
06/13/2022 10:15:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=42
06/13/2022 10:15:58 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.9810670636047096 on epoch=42
06/13/2022 10:16:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=43
06/13/2022 10:16:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
06/13/2022 10:16:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 10:16:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=43
06/13/2022 10:16:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
06/13/2022 10:16:40 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9213798797804704 on epoch=43
06/13/2022 10:16:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=43
06/13/2022 10:16:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
06/13/2022 10:16:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=44
06/13/2022 10:16:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
06/13/2022 10:16:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
06/13/2022 10:17:22 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9854874817882884 on epoch=44
06/13/2022 10:17:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
06/13/2022 10:17:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=44
06/13/2022 10:17:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
06/13/2022 10:17:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 10:17:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=45
06/13/2022 10:18:05 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9843864594160195 on epoch=45
06/13/2022 10:18:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=45
06/13/2022 10:18:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=45
06/13/2022 10:18:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 10:18:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=46
06/13/2022 10:18:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=46
06/13/2022 10:18:47 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7205484238692289 on epoch=46
06/13/2022 10:18:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=46
06/13/2022 10:18:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
06/13/2022 10:18:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=46
06/13/2022 10:18:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
06/13/2022 10:19:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
06/13/2022 10:19:29 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9192805200128905 on epoch=47
06/13/2022 10:19:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
06/13/2022 10:19:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=47
06/13/2022 10:19:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
06/13/2022 10:19:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
06/13/2022 10:19:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=48
06/13/2022 10:20:11 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9192442831127834 on epoch=48
06/13/2022 10:20:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=48
06/13/2022 10:20:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
06/13/2022 10:20:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
06/13/2022 10:20:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=48
06/13/2022 10:20:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
06/13/2022 10:20:52 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9866228980650646 on epoch=49
06/13/2022 10:20:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
06/13/2022 10:20:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
06/13/2022 10:21:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
06/13/2022 10:21:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
06/13/2022 10:21:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
06/13/2022 10:21:34 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9899547471732626 on epoch=49
06/13/2022 10:21:34 - INFO - __main__ - Saving model with best Classification-F1: 0.9866388789886907 -> 0.9899547471732626 on epoch=49, global_step=2800
06/13/2022 10:21:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
06/13/2022 10:21:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
06/13/2022 10:21:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
06/13/2022 10:21:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
06/13/2022 10:21:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=50
06/13/2022 10:22:13 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8048266669475078 on epoch=50
06/13/2022 10:22:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
06/13/2022 10:22:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
06/13/2022 10:22:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
06/13/2022 10:22:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=51
06/13/2022 10:22:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 10:22:53 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7103815718853451 on epoch=51
06/13/2022 10:22:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.08 on epoch=51
06/13/2022 10:22:58 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
06/13/2022 10:23:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
06/13/2022 10:23:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
06/13/2022 10:23:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
06/13/2022 10:23:33 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9866108193431788 on epoch=52
06/13/2022 10:23:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
06/13/2022 10:23:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=53
06/13/2022 10:23:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=53
06/13/2022 10:23:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
06/13/2022 10:23:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 10:23:47 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 10:23:47 - INFO - __main__ - Printing 3 examples
06/13/2022 10:23:47 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 10:23:47 - INFO - __main__ - ['Company']
06/13/2022 10:23:47 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 10:23:47 - INFO - __main__ - ['Company']
06/13/2022 10:23:47 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 10:23:47 - INFO - __main__ - ['Company']
06/13/2022 10:23:47 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:23:48 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:23:49 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 10:23:49 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 10:23:49 - INFO - __main__ - Printing 3 examples
06/13/2022 10:23:49 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 10:23:49 - INFO - __main__ - ['Company']
06/13/2022 10:23:49 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 10:23:49 - INFO - __main__ - ['Company']
06/13/2022 10:23:49 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 10:23:49 - INFO - __main__ - ['Company']
06/13/2022 10:23:49 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:23:49 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:23:50 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 10:24:09 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:24:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:24:09 - INFO - __main__ - Starting training!
06/13/2022 10:24:13 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9244902126181428 on epoch=53
06/13/2022 10:24:13 - INFO - __main__ - save last model!
06/13/2022 10:24:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 10:24:13 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 10:24:13 - INFO - __main__ - Printing 3 examples
06/13/2022 10:24:13 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 10:24:13 - INFO - __main__ - ['Animal']
06/13/2022 10:24:13 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 10:24:13 - INFO - __main__ - ['Animal']
06/13/2022 10:24:13 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 10:24:13 - INFO - __main__ - ['Village']
06/13/2022 10:24:13 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:24:15 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:24:19 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 10:26:30 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.2_8_predictions.txt
06/13/2022 10:26:30 - INFO - __main__ - Classification-F1 on test data: 0.7658
06/13/2022 10:26:31 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.2, bsz=8, dev_performance=0.9899547471732626, test_performance=0.7658416319278589
06/13/2022 10:26:31 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.5, bsz=8 ...
06/13/2022 10:26:32 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 10:26:32 - INFO - __main__ - Printing 3 examples
06/13/2022 10:26:32 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 10:26:32 - INFO - __main__ - ['Company']
06/13/2022 10:26:32 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 10:26:32 - INFO - __main__ - ['Company']
06/13/2022 10:26:32 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 10:26:32 - INFO - __main__ - ['Company']
06/13/2022 10:26:32 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:26:32 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:26:33 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 10:26:33 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 10:26:33 - INFO - __main__ - Printing 3 examples
06/13/2022 10:26:33 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 10:26:33 - INFO - __main__ - ['Company']
06/13/2022 10:26:33 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 10:26:33 - INFO - __main__ - ['Company']
06/13/2022 10:26:33 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 10:26:33 - INFO - __main__ - ['Company']
06/13/2022 10:26:33 - INFO - __main__ - Tokenizing Input ...
06/13/2022 10:26:34 - INFO - __main__ - Tokenizing Output ...
06/13/2022 10:26:35 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 10:26:50 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 10:26:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 10:26:50 - INFO - __main__ - Starting training!
06/13/2022 10:26:54 - INFO - __main__ - Step 10 Global step 10 Train loss 4.33 on epoch=0
06/13/2022 10:26:57 - INFO - __main__ - Step 20 Global step 20 Train loss 2.57 on epoch=0
06/13/2022 10:26:59 - INFO - __main__ - Step 30 Global step 30 Train loss 1.73 on epoch=0
06/13/2022 10:27:02 - INFO - __main__ - Step 40 Global step 40 Train loss 1.35 on epoch=0
06/13/2022 10:27:04 - INFO - __main__ - Step 50 Global step 50 Train loss 1.28 on epoch=0
06/13/2022 10:27:30 - INFO - __main__ - Global step 50 Train loss 2.25 Classification-F1 0.18316642023986396 on epoch=0
06/13/2022 10:27:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18316642023986396 on epoch=0, global_step=50
06/13/2022 10:27:33 - INFO - __main__ - Step 60 Global step 60 Train loss 0.92 on epoch=1
06/13/2022 10:27:35 - INFO - __main__ - Step 70 Global step 70 Train loss 0.88 on epoch=1
06/13/2022 10:27:38 - INFO - __main__ - Step 80 Global step 80 Train loss 0.69 on epoch=1
06/13/2022 10:27:40 - INFO - __main__ - Step 90 Global step 90 Train loss 0.70 on epoch=1
06/13/2022 10:27:43 - INFO - __main__ - Step 100 Global step 100 Train loss 0.61 on epoch=1
06/13/2022 10:28:09 - INFO - __main__ - Global step 100 Train loss 0.76 Classification-F1 0.31356982019682295 on epoch=1
06/13/2022 10:28:09 - INFO - __main__ - Saving model with best Classification-F1: 0.18316642023986396 -> 0.31356982019682295 on epoch=1, global_step=100
06/13/2022 10:28:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.63 on epoch=1
06/13/2022 10:28:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.48 on epoch=2
06/13/2022 10:28:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.52 on epoch=2
06/13/2022 10:28:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.44 on epoch=2
06/13/2022 10:28:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.52 on epoch=2
06/13/2022 10:28:48 - INFO - __main__ - Global step 150 Train loss 0.52 Classification-F1 0.5003434662153939 on epoch=2
06/13/2022 10:28:48 - INFO - __main__ - Saving model with best Classification-F1: 0.31356982019682295 -> 0.5003434662153939 on epoch=2, global_step=150
06/13/2022 10:28:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.57 on epoch=2
06/13/2022 10:28:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=3
06/13/2022 10:28:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.45 on epoch=3
06/13/2022 10:28:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.56 on epoch=3
06/13/2022 10:29:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.44 on epoch=3
06/13/2022 10:29:28 - INFO - __main__ - Global step 200 Train loss 0.50 Classification-F1 0.6887720449902922 on epoch=3
06/13/2022 10:29:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5003434662153939 -> 0.6887720449902922 on epoch=3, global_step=200
06/13/2022 10:29:31 - INFO - __main__ - Step 210 Global step 210 Train loss 0.35 on epoch=3
06/13/2022 10:29:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.34 on epoch=3
06/13/2022 10:29:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.37 on epoch=4
06/13/2022 10:29:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=4
06/13/2022 10:29:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=4
06/13/2022 10:30:09 - INFO - __main__ - Global step 250 Train loss 0.37 Classification-F1 0.6176152141674882 on epoch=4
06/13/2022 10:30:11 - INFO - __main__ - Step 260 Global step 260 Train loss 0.33 on epoch=4
06/13/2022 10:30:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=4
06/13/2022 10:30:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=4
06/13/2022 10:30:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=5
06/13/2022 10:30:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=5
06/13/2022 10:30:50 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.64342076701011 on epoch=5
06/13/2022 10:30:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=5
06/13/2022 10:30:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=5
06/13/2022 10:30:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=5
06/13/2022 10:31:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.23 on epoch=6
06/13/2022 10:31:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=6
06/13/2022 10:31:30 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.5224356446558507 on epoch=6
06/13/2022 10:31:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.27 on epoch=6
06/13/2022 10:31:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=6
06/13/2022 10:31:37 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=6
06/13/2022 10:31:40 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=6
06/13/2022 10:31:42 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=7
06/13/2022 10:32:11 - INFO - __main__ - Global step 400 Train loss 0.25 Classification-F1 0.6723479991958077 on epoch=7
06/13/2022 10:32:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=7
06/13/2022 10:32:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.13 on epoch=7
06/13/2022 10:32:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=7
06/13/2022 10:32:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=7
06/13/2022 10:32:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=8
06/13/2022 10:32:52 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.7135473542415811 on epoch=8
06/13/2022 10:32:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6887720449902922 -> 0.7135473542415811 on epoch=8, global_step=450
06/13/2022 10:32:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=8
06/13/2022 10:32:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=8
06/13/2022 10:32:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=8
06/13/2022 10:33:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=8
06/13/2022 10:33:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=8
06/13/2022 10:33:32 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.645462785270254 on epoch=8
06/13/2022 10:33:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=9
06/13/2022 10:33:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=9
06/13/2022 10:33:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=9
06/13/2022 10:33:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=9
06/13/2022 10:33:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=9
06/13/2022 10:34:14 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.7267118336031181 on epoch=9
06/13/2022 10:34:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7135473542415811 -> 0.7267118336031181 on epoch=9, global_step=550
06/13/2022 10:34:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=9
06/13/2022 10:34:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=10
06/13/2022 10:34:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=10
06/13/2022 10:34:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=10
06/13/2022 10:34:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=10
06/13/2022 10:34:52 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.5940172730612733 on epoch=10
06/13/2022 10:34:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=10
06/13/2022 10:34:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=11
06/13/2022 10:35:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=11
06/13/2022 10:35:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=11
06/13/2022 10:35:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=11
06/13/2022 10:35:33 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.736785613576791 on epoch=11
06/13/2022 10:35:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7267118336031181 -> 0.736785613576791 on epoch=11, global_step=650
06/13/2022 10:35:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=11
06/13/2022 10:35:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=11
06/13/2022 10:35:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=12
06/13/2022 10:35:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=12
06/13/2022 10:35:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=12
06/13/2022 10:36:13 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7934998824545505 on epoch=12
06/13/2022 10:36:13 - INFO - __main__ - Saving model with best Classification-F1: 0.736785613576791 -> 0.7934998824545505 on epoch=12, global_step=700
06/13/2022 10:36:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=12
06/13/2022 10:36:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=12
06/13/2022 10:36:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=13
06/13/2022 10:36:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=13
06/13/2022 10:36:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=13
06/13/2022 10:36:53 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6653740732191827 on epoch=13
06/13/2022 10:36:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=13
06/13/2022 10:36:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=13
06/13/2022 10:37:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=13
06/13/2022 10:37:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=14
06/13/2022 10:37:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=14
06/13/2022 10:37:33 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7720111830175707 on epoch=14
06/13/2022 10:37:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=14
06/13/2022 10:37:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=14
06/13/2022 10:37:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=14
06/13/2022 10:37:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=14
06/13/2022 10:37:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=15
06/13/2022 10:38:14 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.9139411882166146 on epoch=15
06/13/2022 10:38:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7934998824545505 -> 0.9139411882166146 on epoch=15, global_step=850
06/13/2022 10:38:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=15
06/13/2022 10:38:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=15
06/13/2022 10:38:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=15
06/13/2022 10:38:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=15
06/13/2022 10:38:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=16
06/13/2022 10:38:56 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.9764430885289875 on epoch=16
06/13/2022 10:38:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9139411882166146 -> 0.9764430885289875 on epoch=16, global_step=900
06/13/2022 10:38:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=16
06/13/2022 10:39:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
06/13/2022 10:39:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=16
06/13/2022 10:39:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=16
06/13/2022 10:39:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=16
06/13/2022 10:39:37 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7009514978356051 on epoch=16
06/13/2022 10:39:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=17
06/13/2022 10:39:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=17
06/13/2022 10:39:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=17
06/13/2022 10:39:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=17
06/13/2022 10:39:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=17
06/13/2022 10:40:18 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7205101552704062 on epoch=17
06/13/2022 10:40:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=18
06/13/2022 10:40:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=18
06/13/2022 10:40:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=18
06/13/2022 10:40:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=18
06/13/2022 10:40:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=18
06/13/2022 10:40:58 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6600288018493516 on epoch=18
06/13/2022 10:41:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
06/13/2022 10:41:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=19
06/13/2022 10:41:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=19
06/13/2022 10:41:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=19
06/13/2022 10:41:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=19
06/13/2022 10:41:37 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.7972639061231813 on epoch=19
06/13/2022 10:41:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=19
06/13/2022 10:41:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=19
06/13/2022 10:41:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
06/13/2022 10:41:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=20
06/13/2022 10:41:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=20
06/13/2022 10:42:17 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.8537176042257631 on epoch=20
06/13/2022 10:42:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=20
06/13/2022 10:42:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=20
06/13/2022 10:42:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=21
06/13/2022 10:42:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=21
06/13/2022 10:42:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=21
06/13/2022 10:42:56 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6420096439108264 on epoch=21
06/13/2022 10:42:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
06/13/2022 10:43:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=21
06/13/2022 10:43:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=21
06/13/2022 10:43:06 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=22
06/13/2022 10:43:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=22
06/13/2022 10:43:36 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6372087041112876 on epoch=22
06/13/2022 10:43:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=22
06/13/2022 10:43:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=22
06/13/2022 10:43:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=22
06/13/2022 10:43:46 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=23
06/13/2022 10:43:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
06/13/2022 10:44:16 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.793766806463387 on epoch=23
06/13/2022 10:44:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=23
06/13/2022 10:44:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=23
06/13/2022 10:44:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=23
06/13/2022 10:44:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=23
06/13/2022 10:44:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
06/13/2022 10:44:57 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8527320862516541 on epoch=24
06/13/2022 10:45:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=24
06/13/2022 10:45:02 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
06/13/2022 10:45:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
06/13/2022 10:45:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=24
06/13/2022 10:45:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=24
06/13/2022 10:45:36 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9118696476041724 on epoch=24
06/13/2022 10:45:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=25
06/13/2022 10:45:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=25
06/13/2022 10:45:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=25
06/13/2022 10:45:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=25
06/13/2022 10:45:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=25
06/13/2022 10:46:14 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9786824667811836 on epoch=25
06/13/2022 10:46:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9764430885289875 -> 0.9786824667811836 on epoch=25, global_step=1450
06/13/2022 10:46:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
06/13/2022 10:46:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=26
06/13/2022 10:46:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=26
06/13/2022 10:46:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=26
06/13/2022 10:46:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=26
06/13/2022 10:46:53 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7165339910344212 on epoch=26
06/13/2022 10:46:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=26
06/13/2022 10:46:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=27
06/13/2022 10:47:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=27
06/13/2022 10:47:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=27
06/13/2022 10:47:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=27
06/13/2022 10:47:32 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.979916565885436 on epoch=27
06/13/2022 10:47:32 - INFO - __main__ - Saving model with best Classification-F1: 0.9786824667811836 -> 0.979916565885436 on epoch=27, global_step=1550
06/13/2022 10:47:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=27
06/13/2022 10:47:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=28
06/13/2022 10:47:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
06/13/2022 10:47:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
06/13/2022 10:47:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=28
06/13/2022 10:48:10 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7566653424507114 on epoch=28
06/13/2022 10:48:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
06/13/2022 10:48:15 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=28
06/13/2022 10:48:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=29
06/13/2022 10:48:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=29
06/13/2022 10:48:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
06/13/2022 10:48:48 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7550985328805333 on epoch=29
06/13/2022 10:48:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=29
06/13/2022 10:48:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=29
06/13/2022 10:48:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
06/13/2022 10:48:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=30
06/13/2022 10:49:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
06/13/2022 10:49:25 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7961046621194744 on epoch=30
06/13/2022 10:49:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=30
06/13/2022 10:49:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=30
06/13/2022 10:49:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=30
06/13/2022 10:49:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=31
06/13/2022 10:49:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
06/13/2022 10:50:04 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8497758840182501 on epoch=31
06/13/2022 10:50:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
06/13/2022 10:50:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
06/13/2022 10:50:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=31
06/13/2022 10:50:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
06/13/2022 10:50:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=32
06/13/2022 10:50:41 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.748627753371738 on epoch=32
06/13/2022 10:50:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=32
06/13/2022 10:50:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
06/13/2022 10:50:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
06/13/2022 10:50:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
06/13/2022 10:50:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=33
06/13/2022 10:51:18 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7870884639033351 on epoch=33
06/13/2022 10:51:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=33
06/13/2022 10:51:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=33
06/13/2022 10:51:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
06/13/2022 10:51:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=33
06/13/2022 10:51:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=33
06/13/2022 10:51:56 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8027117356213352 on epoch=33
06/13/2022 10:51:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
06/13/2022 10:52:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=34
06/13/2022 10:52:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=34
06/13/2022 10:52:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=34
06/13/2022 10:52:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
06/13/2022 10:52:34 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9109834383220163 on epoch=34
06/13/2022 10:52:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
06/13/2022 10:52:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=35
06/13/2022 10:52:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
06/13/2022 10:52:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
06/13/2022 10:52:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
06/13/2022 10:53:13 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8562955046330859 on epoch=35
06/13/2022 10:53:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=35
06/13/2022 10:53:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
06/13/2022 10:53:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=36
06/13/2022 10:53:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
06/13/2022 10:53:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
06/13/2022 10:53:49 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.846335232119757 on epoch=36
06/13/2022 10:53:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
06/13/2022 10:53:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=36
06/13/2022 10:53:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=37
06/13/2022 10:54:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
06/13/2022 10:54:02 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
06/13/2022 10:54:26 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.909765268570965 on epoch=37
06/13/2022 10:54:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
06/13/2022 10:54:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=37
06/13/2022 10:54:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=38
06/13/2022 10:54:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=38
06/13/2022 10:54:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=38
06/13/2022 10:55:04 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9170410472103758 on epoch=38
06/13/2022 10:55:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
06/13/2022 10:55:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=38
06/13/2022 10:55:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
06/13/2022 10:55:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
06/13/2022 10:55:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
06/13/2022 10:55:42 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9132905494834221 on epoch=39
06/13/2022 10:55:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
06/13/2022 10:55:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=39
06/13/2022 10:55:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=39
06/13/2022 10:55:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
06/13/2022 10:55:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=40
06/13/2022 10:56:21 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8086967451645171 on epoch=40
06/13/2022 10:56:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 10:56:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
06/13/2022 10:56:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
06/13/2022 10:56:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
06/13/2022 10:56:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 10:57:00 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8045192447233797 on epoch=41
06/13/2022 10:57:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=41
06/13/2022 10:57:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=41
06/13/2022 10:57:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
06/13/2022 10:57:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=41
06/13/2022 10:57:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
06/13/2022 10:57:40 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8513752358695248 on epoch=41
06/13/2022 10:57:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=42
06/13/2022 10:57:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
06/13/2022 10:57:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
06/13/2022 10:57:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=42
06/13/2022 10:57:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=42
06/13/2022 10:58:17 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9139717863415756 on epoch=42
06/13/2022 10:58:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
06/13/2022 10:58:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
06/13/2022 10:58:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 10:58:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
06/13/2022 10:58:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
06/13/2022 10:58:54 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9809646536084983 on epoch=43
06/13/2022 10:58:54 - INFO - __main__ - Saving model with best Classification-F1: 0.979916565885436 -> 0.9809646536084983 on epoch=43, global_step=2450
06/13/2022 10:58:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=43
06/13/2022 10:58:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
06/13/2022 10:59:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=44
06/13/2022 10:59:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
06/13/2022 10:59:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
06/13/2022 10:59:30 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9122686641389353 on epoch=44
06/13/2022 10:59:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=44
06/13/2022 10:59:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
06/13/2022 10:59:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
06/13/2022 10:59:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 10:59:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
06/13/2022 11:00:07 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8883486531487857 on epoch=45
06/13/2022 11:00:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=45
06/13/2022 11:00:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
06/13/2022 11:00:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=46
06/13/2022 11:00:17 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
06/13/2022 11:00:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=46
06/13/2022 11:00:43 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.9075271138627125 on epoch=46
06/13/2022 11:00:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=46
06/13/2022 11:00:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
06/13/2022 11:00:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
06/13/2022 11:00:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
06/13/2022 11:00:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=47
06/13/2022 11:01:20 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8563425299155895 on epoch=47
06/13/2022 11:01:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=47
06/13/2022 11:01:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
06/13/2022 11:01:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=47
06/13/2022 11:01:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
06/13/2022 11:01:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=48
06/13/2022 11:01:58 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9112317723719449 on epoch=48
06/13/2022 11:02:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=48
06/13/2022 11:02:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=48
06/13/2022 11:02:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
06/13/2022 11:02:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
06/13/2022 11:02:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
06/13/2022 11:02:34 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7540711434165899 on epoch=49
06/13/2022 11:02:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=49
06/13/2022 11:02:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=49
06/13/2022 11:02:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
06/13/2022 11:02:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
06/13/2022 11:02:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 11:03:11 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.8394177129817073 on epoch=49
06/13/2022 11:03:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
06/13/2022 11:03:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
06/13/2022 11:03:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
06/13/2022 11:03:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
06/13/2022 11:03:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
06/13/2022 11:03:49 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7547604501721287 on epoch=50
06/13/2022 11:03:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
06/13/2022 11:03:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=51
06/13/2022 11:03:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
06/13/2022 11:03:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=51
06/13/2022 11:04:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=51
06/13/2022 11:04:26 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.855182604857756 on epoch=51
06/13/2022 11:04:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
06/13/2022 11:04:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
06/13/2022 11:04:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=52
06/13/2022 11:04:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
06/13/2022 11:04:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 11:05:03 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7537842262063438 on epoch=52
06/13/2022 11:05:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
06/13/2022 11:05:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
06/13/2022 11:05:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
06/13/2022 11:05:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
06/13/2022 11:05:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=53
06/13/2022 11:05:17 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:05:17 - INFO - __main__ - Printing 3 examples
06/13/2022 11:05:17 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 11:05:17 - INFO - __main__ - ['Company']
06/13/2022 11:05:17 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 11:05:17 - INFO - __main__ - ['Company']
06/13/2022 11:05:17 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 11:05:17 - INFO - __main__ - ['Company']
06/13/2022 11:05:17 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:05:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:05:18 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 11:05:18 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:05:18 - INFO - __main__ - Printing 3 examples
06/13/2022 11:05:18 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 11:05:18 - INFO - __main__ - ['Company']
06/13/2022 11:05:18 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 11:05:18 - INFO - __main__ - ['Company']
06/13/2022 11:05:18 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 11:05:18 - INFO - __main__ - ['Company']
06/13/2022 11:05:18 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:05:19 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:05:20 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 11:05:35 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:05:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:05:36 - INFO - __main__ - Starting training!
06/13/2022 11:05:39 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.895400671854209 on epoch=53
06/13/2022 11:05:39 - INFO - __main__ - save last model!
06/13/2022 11:05:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 11:05:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 11:05:39 - INFO - __main__ - Printing 3 examples
06/13/2022 11:05:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 11:05:39 - INFO - __main__ - ['Animal']
06/13/2022 11:05:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 11:05:39 - INFO - __main__ - ['Animal']
06/13/2022 11:05:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 11:05:39 - INFO - __main__ - ['Village']
06/13/2022 11:05:39 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:05:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:05:45 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 11:07:51 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.5_8_predictions.txt
06/13/2022 11:07:51 - INFO - __main__ - Classification-F1 on test data: 0.7502
06/13/2022 11:07:51 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.5, bsz=8, dev_performance=0.9809646536084983, test_performance=0.7501699553771866
06/13/2022 11:07:51 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.4, bsz=8 ...
06/13/2022 11:07:52 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:07:52 - INFO - __main__ - Printing 3 examples
06/13/2022 11:07:52 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 11:07:52 - INFO - __main__ - ['Company']
06/13/2022 11:07:52 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 11:07:52 - INFO - __main__ - ['Company']
06/13/2022 11:07:52 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 11:07:52 - INFO - __main__ - ['Company']
06/13/2022 11:07:52 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:07:53 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:07:54 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 11:07:54 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:07:54 - INFO - __main__ - Printing 3 examples
06/13/2022 11:07:54 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 11:07:54 - INFO - __main__ - ['Company']
06/13/2022 11:07:54 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 11:07:54 - INFO - __main__ - ['Company']
06/13/2022 11:07:54 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 11:07:54 - INFO - __main__ - ['Company']
06/13/2022 11:07:54 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:07:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:07:55 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 11:08:11 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:08:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:08:11 - INFO - __main__ - Starting training!
06/13/2022 11:08:15 - INFO - __main__ - Step 10 Global step 10 Train loss 4.81 on epoch=0
06/13/2022 11:08:17 - INFO - __main__ - Step 20 Global step 20 Train loss 2.95 on epoch=0
06/13/2022 11:08:20 - INFO - __main__ - Step 30 Global step 30 Train loss 2.14 on epoch=0
06/13/2022 11:08:22 - INFO - __main__ - Step 40 Global step 40 Train loss 1.59 on epoch=0
06/13/2022 11:08:25 - INFO - __main__ - Step 50 Global step 50 Train loss 1.43 on epoch=0
06/13/2022 11:08:48 - INFO - __main__ - Global step 50 Train loss 2.58 Classification-F1 0.10455370717638562 on epoch=0
06/13/2022 11:08:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10455370717638562 on epoch=0, global_step=50
06/13/2022 11:08:51 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=1
06/13/2022 11:08:53 - INFO - __main__ - Step 70 Global step 70 Train loss 0.95 on epoch=1
06/13/2022 11:08:56 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=1
06/13/2022 11:08:58 - INFO - __main__ - Step 90 Global step 90 Train loss 0.84 on epoch=1
06/13/2022 11:09:01 - INFO - __main__ - Step 100 Global step 100 Train loss 0.60 on epoch=1
06/13/2022 11:09:27 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.37439014745681437 on epoch=1
06/13/2022 11:09:27 - INFO - __main__ - Saving model with best Classification-F1: 0.10455370717638562 -> 0.37439014745681437 on epoch=1, global_step=100
06/13/2022 11:09:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.69 on epoch=1
06/13/2022 11:09:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.62 on epoch=2
06/13/2022 11:09:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.59 on epoch=2
06/13/2022 11:09:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=2
06/13/2022 11:09:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.53 on epoch=2
06/13/2022 11:10:05 - INFO - __main__ - Global step 150 Train loss 0.60 Classification-F1 0.5450437047189725 on epoch=2
06/13/2022 11:10:05 - INFO - __main__ - Saving model with best Classification-F1: 0.37439014745681437 -> 0.5450437047189725 on epoch=2, global_step=150
06/13/2022 11:10:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.50 on epoch=2
06/13/2022 11:10:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=3
06/13/2022 11:10:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=3
06/13/2022 11:10:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.51 on epoch=3
06/13/2022 11:10:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.38 on epoch=3
06/13/2022 11:10:47 - INFO - __main__ - Global step 200 Train loss 0.47 Classification-F1 0.4532705134678207 on epoch=3
06/13/2022 11:10:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=3
06/13/2022 11:10:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.33 on epoch=3
06/13/2022 11:10:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=4
06/13/2022 11:10:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=4
06/13/2022 11:11:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=4
06/13/2022 11:11:28 - INFO - __main__ - Global step 250 Train loss 0.37 Classification-F1 0.641645295040902 on epoch=4
06/13/2022 11:11:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5450437047189725 -> 0.641645295040902 on epoch=4, global_step=250
06/13/2022 11:11:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.28 on epoch=4
06/13/2022 11:11:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=4
06/13/2022 11:11:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.20 on epoch=4
06/13/2022 11:11:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=5
06/13/2022 11:11:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=5
06/13/2022 11:12:13 - INFO - __main__ - Global step 300 Train loss 0.30 Classification-F1 0.6988108692047033 on epoch=5
06/13/2022 11:12:13 - INFO - __main__ - Saving model with best Classification-F1: 0.641645295040902 -> 0.6988108692047033 on epoch=5, global_step=300
06/13/2022 11:12:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=5
06/13/2022 11:12:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=5
06/13/2022 11:12:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=5
06/13/2022 11:12:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=6
06/13/2022 11:12:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=6
06/13/2022 11:12:55 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.6120652576505102 on epoch=6
06/13/2022 11:12:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=6
06/13/2022 11:13:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=6
06/13/2022 11:13:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=6
06/13/2022 11:13:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=6
06/13/2022 11:13:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=7
06/13/2022 11:13:34 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.4770536140897975 on epoch=7
06/13/2022 11:13:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=7
06/13/2022 11:13:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.12 on epoch=7
06/13/2022 11:13:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=7
06/13/2022 11:13:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=7
06/13/2022 11:13:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=8
06/13/2022 11:14:20 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.8289787338101915 on epoch=8
06/13/2022 11:14:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6988108692047033 -> 0.8289787338101915 on epoch=8, global_step=450
06/13/2022 11:14:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.18 on epoch=8
06/13/2022 11:14:25 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=8
06/13/2022 11:14:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=8
06/13/2022 11:14:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=8
06/13/2022 11:14:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=8
06/13/2022 11:15:02 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7463738755602187 on epoch=8
06/13/2022 11:15:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=9
06/13/2022 11:15:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=9
06/13/2022 11:15:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=9
06/13/2022 11:15:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=9
06/13/2022 11:15:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=9
06/13/2022 11:15:46 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.83620122573316 on epoch=9
06/13/2022 11:15:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8289787338101915 -> 0.83620122573316 on epoch=9, global_step=550
06/13/2022 11:15:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=9
06/13/2022 11:15:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=10
06/13/2022 11:15:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=10
06/13/2022 11:15:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=10
06/13/2022 11:15:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.13 on epoch=10
06/13/2022 11:16:27 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7428238563151832 on epoch=10
06/13/2022 11:16:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=10
06/13/2022 11:16:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=11
06/13/2022 11:16:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=11
06/13/2022 11:16:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=11
06/13/2022 11:16:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=11
06/13/2022 11:17:08 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.7894917381239412 on epoch=11
06/13/2022 11:17:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=11
06/13/2022 11:17:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=11
06/13/2022 11:17:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=12
06/13/2022 11:17:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=12
06/13/2022 11:17:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=12
06/13/2022 11:17:52 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.7179606479472941 on epoch=12
06/13/2022 11:17:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=12
06/13/2022 11:17:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=12
06/13/2022 11:18:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=13
06/13/2022 11:18:02 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=13
06/13/2022 11:18:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=13
06/13/2022 11:18:36 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.7026154266574369 on epoch=13
06/13/2022 11:18:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=13
06/13/2022 11:18:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=13
06/13/2022 11:18:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=13
06/13/2022 11:18:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=14
06/13/2022 11:18:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=14
06/13/2022 11:19:20 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.9652527601466677 on epoch=14
06/13/2022 11:19:20 - INFO - __main__ - Saving model with best Classification-F1: 0.83620122573316 -> 0.9652527601466677 on epoch=14, global_step=800
06/13/2022 11:19:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=14
06/13/2022 11:19:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=14
06/13/2022 11:19:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=14
06/13/2022 11:19:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=14
06/13/2022 11:19:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=15
06/13/2022 11:20:02 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7831699413544898 on epoch=15
06/13/2022 11:20:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=15
06/13/2022 11:20:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=15
06/13/2022 11:20:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=15
06/13/2022 11:20:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=15
06/13/2022 11:20:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=16
06/13/2022 11:20:43 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7994677669769651 on epoch=16
06/13/2022 11:20:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=16
06/13/2022 11:20:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
06/13/2022 11:20:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=16
06/13/2022 11:20:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=16
06/13/2022 11:20:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=16
06/13/2022 11:21:25 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.757243051933789 on epoch=16
06/13/2022 11:21:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=17
06/13/2022 11:21:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=17
06/13/2022 11:21:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=17
06/13/2022 11:21:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=17
06/13/2022 11:21:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=17
06/13/2022 11:22:08 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.8446219025203228 on epoch=17
06/13/2022 11:22:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=18
06/13/2022 11:22:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=18
06/13/2022 11:22:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=18
06/13/2022 11:22:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=18
06/13/2022 11:22:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=18
06/13/2022 11:22:48 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.9109284851696865 on epoch=18
06/13/2022 11:22:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=18
06/13/2022 11:22:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=19
06/13/2022 11:22:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=19
06/13/2022 11:22:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=19
06/13/2022 11:23:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=19
06/13/2022 11:23:29 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.9018909633562099 on epoch=19
06/13/2022 11:23:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=19
06/13/2022 11:23:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=19
06/13/2022 11:23:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=20
06/13/2022 11:23:39 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=20
06/13/2022 11:23:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=20
06/13/2022 11:24:06 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.9091549838448725 on epoch=20
06/13/2022 11:24:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=20
06/13/2022 11:24:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
06/13/2022 11:24:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=21
06/13/2022 11:24:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=21
06/13/2022 11:24:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=21
06/13/2022 11:24:45 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.906630420116852 on epoch=21
06/13/2022 11:24:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=21
06/13/2022 11:24:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=21
06/13/2022 11:24:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=21
06/13/2022 11:24:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=22
06/13/2022 11:24:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=22
06/13/2022 11:25:24 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7963239431962342 on epoch=22
06/13/2022 11:25:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=22
06/13/2022 11:25:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=22
06/13/2022 11:25:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=22
06/13/2022 11:25:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
06/13/2022 11:25:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=23
06/13/2022 11:26:04 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.9098405243255155 on epoch=23
06/13/2022 11:26:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=23
06/13/2022 11:26:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=23
06/13/2022 11:26:12 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=23
06/13/2022 11:26:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=23
06/13/2022 11:26:17 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=24
06/13/2022 11:26:42 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.9708242331989521 on epoch=24
06/13/2022 11:26:42 - INFO - __main__ - Saving model with best Classification-F1: 0.9652527601466677 -> 0.9708242331989521 on epoch=24, global_step=1350
06/13/2022 11:26:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=24
06/13/2022 11:26:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
06/13/2022 11:26:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=24
06/13/2022 11:26:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=24
06/13/2022 11:26:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=24
06/13/2022 11:27:21 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.9149957093253105 on epoch=24
06/13/2022 11:27:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=25
06/13/2022 11:27:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=25
06/13/2022 11:27:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=25
06/13/2022 11:27:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
06/13/2022 11:27:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=25
06/13/2022 11:27:59 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.848644863834841 on epoch=25
06/13/2022 11:28:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
06/13/2022 11:28:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
06/13/2022 11:28:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=26
06/13/2022 11:28:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
06/13/2022 11:28:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=26
06/13/2022 11:28:37 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.9763529756050533 on epoch=26
06/13/2022 11:28:37 - INFO - __main__ - Saving model with best Classification-F1: 0.9708242331989521 -> 0.9763529756050533 on epoch=26, global_step=1500
06/13/2022 11:28:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=26
06/13/2022 11:28:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=27
06/13/2022 11:28:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
06/13/2022 11:28:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=27
06/13/2022 11:28:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
06/13/2022 11:29:14 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9134643468423458 on epoch=27
06/13/2022 11:29:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
06/13/2022 11:29:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=28
06/13/2022 11:29:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=28
06/13/2022 11:29:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
06/13/2022 11:29:27 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=28
06/13/2022 11:29:52 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8528733929755827 on epoch=28
06/13/2022 11:29:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=28
06/13/2022 11:29:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=28
06/13/2022 11:29:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
06/13/2022 11:30:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=29
06/13/2022 11:30:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=29
06/13/2022 11:30:29 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.9842715817632757 on epoch=29
06/13/2022 11:30:29 - INFO - __main__ - Saving model with best Classification-F1: 0.9763529756050533 -> 0.9842715817632757 on epoch=29, global_step=1650
06/13/2022 11:30:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=29
06/13/2022 11:30:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=29
06/13/2022 11:30:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
06/13/2022 11:30:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=30
06/13/2022 11:30:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=30
06/13/2022 11:31:07 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9097692135389289 on epoch=30
06/13/2022 11:31:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=30
06/13/2022 11:31:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=30
06/13/2022 11:31:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=30
06/13/2022 11:31:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
06/13/2022 11:31:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=31
06/13/2022 11:31:44 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8062018426101458 on epoch=31
06/13/2022 11:31:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
06/13/2022 11:31:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=31
06/13/2022 11:31:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=31
06/13/2022 11:31:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
06/13/2022 11:31:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=32
06/13/2022 11:32:22 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8050117448979409 on epoch=32
06/13/2022 11:32:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
06/13/2022 11:32:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=32
06/13/2022 11:32:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
06/13/2022 11:32:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=32
06/13/2022 11:32:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
06/13/2022 11:33:01 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8531461499881323 on epoch=33
06/13/2022 11:33:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
06/13/2022 11:33:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=33
06/13/2022 11:33:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
06/13/2022 11:33:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=33
06/13/2022 11:33:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=33
06/13/2022 11:33:38 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7081520735827816 on epoch=33
06/13/2022 11:33:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
06/13/2022 11:33:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=34
06/13/2022 11:33:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
06/13/2022 11:33:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
06/13/2022 11:33:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=34
06/13/2022 11:34:18 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9023506740258473 on epoch=34
06/13/2022 11:34:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
06/13/2022 11:34:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=35
06/13/2022 11:34:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
06/13/2022 11:34:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=35
06/13/2022 11:34:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=35
06/13/2022 11:34:56 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9797649998580232 on epoch=35
06/13/2022 11:34:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
06/13/2022 11:35:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
06/13/2022 11:35:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=36
06/13/2022 11:35:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=36
06/13/2022 11:35:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
06/13/2022 11:35:42 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9097456593816104 on epoch=36
06/13/2022 11:35:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
06/13/2022 11:35:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=36
06/13/2022 11:35:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
06/13/2022 11:35:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=37
06/13/2022 11:35:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=37
06/13/2022 11:36:23 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.91074589788567 on epoch=37
06/13/2022 11:36:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
06/13/2022 11:36:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
06/13/2022 11:36:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=38
06/13/2022 11:36:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=38
06/13/2022 11:36:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=38
06/13/2022 11:37:01 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8577692356053355 on epoch=38
06/13/2022 11:37:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
06/13/2022 11:37:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
06/13/2022 11:37:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
06/13/2022 11:37:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=39
06/13/2022 11:37:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
06/13/2022 11:37:38 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7895388919495273 on epoch=39
06/13/2022 11:37:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=39
06/13/2022 11:37:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=39
06/13/2022 11:37:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
06/13/2022 11:37:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
06/13/2022 11:37:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
06/13/2022 11:38:15 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8523513155455547 on epoch=40
06/13/2022 11:38:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 11:38:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
06/13/2022 11:38:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
06/13/2022 11:38:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
06/13/2022 11:38:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
06/13/2022 11:38:52 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7985438471810852 on epoch=41
06/13/2022 11:38:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=41
06/13/2022 11:38:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=41
06/13/2022 11:38:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
06/13/2022 11:39:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
06/13/2022 11:39:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
06/13/2022 11:39:28 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8544505719226538 on epoch=41
06/13/2022 11:39:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
06/13/2022 11:39:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=42
06/13/2022 11:39:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=42
06/13/2022 11:39:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=42
06/13/2022 11:39:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=42
06/13/2022 11:40:04 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9175899576655482 on epoch=42
06/13/2022 11:40:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
06/13/2022 11:40:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=43
06/13/2022 11:40:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
06/13/2022 11:40:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
06/13/2022 11:40:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
06/13/2022 11:40:41 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9160159056705568 on epoch=43
06/13/2022 11:40:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=43
06/13/2022 11:40:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
06/13/2022 11:40:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=44
06/13/2022 11:40:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 11:40:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
06/13/2022 11:41:17 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9831443521816231 on epoch=44
06/13/2022 11:41:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
06/13/2022 11:41:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=44
06/13/2022 11:41:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 11:41:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=45
06/13/2022 11:41:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=45
06/13/2022 11:41:53 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7471299210543273 on epoch=45
06/13/2022 11:41:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=45
06/13/2022 11:41:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
06/13/2022 11:42:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 11:42:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=46
06/13/2022 11:42:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
06/13/2022 11:42:30 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.5768361569379808 on epoch=46
06/13/2022 11:42:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
06/13/2022 11:42:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=46
06/13/2022 11:42:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
06/13/2022 11:42:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=47
06/13/2022 11:42:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
06/13/2022 11:43:06 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6054164104390559 on epoch=47
06/13/2022 11:43:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 11:43:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=47
06/13/2022 11:43:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
06/13/2022 11:43:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=48
06/13/2022 11:43:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
06/13/2022 11:43:42 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8384893885835342 on epoch=48
06/13/2022 11:43:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=48
06/13/2022 11:43:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
06/13/2022 11:43:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
06/13/2022 11:43:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
06/13/2022 11:43:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=49
06/13/2022 11:44:18 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6318024851290561 on epoch=49
06/13/2022 11:44:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
06/13/2022 11:44:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
06/13/2022 11:44:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
06/13/2022 11:44:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
06/13/2022 11:44:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 11:44:54 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7381803086553662 on epoch=49
06/13/2022 11:44:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=50
06/13/2022 11:44:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
06/13/2022 11:45:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
06/13/2022 11:45:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
06/13/2022 11:45:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
06/13/2022 11:45:32 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8552221936898012 on epoch=50
06/13/2022 11:45:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=51
06/13/2022 11:45:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
06/13/2022 11:45:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=51
06/13/2022 11:45:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
06/13/2022 11:45:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=51
06/13/2022 11:46:08 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8057353429293365 on epoch=51
06/13/2022 11:46:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
06/13/2022 11:46:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=52
06/13/2022 11:46:15 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
06/13/2022 11:46:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
06/13/2022 11:46:20 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
06/13/2022 11:46:43 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7549404432193566 on epoch=52
06/13/2022 11:46:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
06/13/2022 11:46:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=53
06/13/2022 11:46:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
06/13/2022 11:46:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
06/13/2022 11:46:56 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=53
06/13/2022 11:46:58 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:46:58 - INFO - __main__ - Printing 3 examples
06/13/2022 11:46:58 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 11:46:58 - INFO - __main__ - ['Company']
06/13/2022 11:46:58 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 11:46:58 - INFO - __main__ - ['Company']
06/13/2022 11:46:58 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 11:46:58 - INFO - __main__ - ['Company']
06/13/2022 11:46:58 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:46:58 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:46:59 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 11:46:59 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:46:59 - INFO - __main__ - Printing 3 examples
06/13/2022 11:46:59 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 11:46:59 - INFO - __main__ - ['Company']
06/13/2022 11:46:59 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 11:46:59 - INFO - __main__ - ['Company']
06/13/2022 11:46:59 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 11:46:59 - INFO - __main__ - ['Company']
06/13/2022 11:46:59 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:47:00 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:47:01 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 11:47:16 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:47:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:47:17 - INFO - __main__ - Starting training!
06/13/2022 11:47:19 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7620301786080954 on epoch=53
06/13/2022 11:47:19 - INFO - __main__ - save last model!
06/13/2022 11:47:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 11:47:19 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 11:47:19 - INFO - __main__ - Printing 3 examples
06/13/2022 11:47:19 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 11:47:19 - INFO - __main__ - ['Animal']
06/13/2022 11:47:19 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 11:47:19 - INFO - __main__ - ['Animal']
06/13/2022 11:47:19 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 11:47:19 - INFO - __main__ - ['Village']
06/13/2022 11:47:19 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:47:21 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:47:25 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 11:49:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.4_8_predictions.txt
06/13/2022 11:49:26 - INFO - __main__ - Classification-F1 on test data: 0.6216
06/13/2022 11:49:27 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.4, bsz=8, dev_performance=0.9842715817632757, test_performance=0.6215732330904095
06/13/2022 11:49:27 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.3, bsz=8 ...
06/13/2022 11:49:28 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:49:28 - INFO - __main__ - Printing 3 examples
06/13/2022 11:49:28 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 11:49:28 - INFO - __main__ - ['Company']
06/13/2022 11:49:28 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 11:49:28 - INFO - __main__ - ['Company']
06/13/2022 11:49:28 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 11:49:28 - INFO - __main__ - ['Company']
06/13/2022 11:49:28 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:49:28 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:49:29 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 11:49:29 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 11:49:29 - INFO - __main__ - Printing 3 examples
06/13/2022 11:49:29 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 11:49:29 - INFO - __main__ - ['Company']
06/13/2022 11:49:29 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 11:49:29 - INFO - __main__ - ['Company']
06/13/2022 11:49:29 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 11:49:29 - INFO - __main__ - ['Company']
06/13/2022 11:49:29 - INFO - __main__ - Tokenizing Input ...
06/13/2022 11:49:30 - INFO - __main__ - Tokenizing Output ...
06/13/2022 11:49:31 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 11:49:46 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 11:49:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 11:49:47 - INFO - __main__ - Starting training!
06/13/2022 11:49:50 - INFO - __main__ - Step 10 Global step 10 Train loss 5.13 on epoch=0
06/13/2022 11:49:53 - INFO - __main__ - Step 20 Global step 20 Train loss 3.41 on epoch=0
06/13/2022 11:49:55 - INFO - __main__ - Step 30 Global step 30 Train loss 2.42 on epoch=0
06/13/2022 11:49:58 - INFO - __main__ - Step 40 Global step 40 Train loss 1.99 on epoch=0
06/13/2022 11:50:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.73 on epoch=0
06/13/2022 11:50:23 - INFO - __main__ - Global step 50 Train loss 2.94 Classification-F1 0.10152814177846023 on epoch=0
06/13/2022 11:50:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10152814177846023 on epoch=0, global_step=50
06/13/2022 11:50:25 - INFO - __main__ - Step 60 Global step 60 Train loss 1.30 on epoch=1
06/13/2022 11:50:28 - INFO - __main__ - Step 70 Global step 70 Train loss 1.11 on epoch=1
06/13/2022 11:50:31 - INFO - __main__ - Step 80 Global step 80 Train loss 1.04 on epoch=1
06/13/2022 11:50:33 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=1
06/13/2022 11:50:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=1
06/13/2022 11:51:01 - INFO - __main__ - Global step 100 Train loss 1.03 Classification-F1 0.3824436635529458 on epoch=1
06/13/2022 11:51:01 - INFO - __main__ - Saving model with best Classification-F1: 0.10152814177846023 -> 0.3824436635529458 on epoch=1, global_step=100
06/13/2022 11:51:03 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=1
06/13/2022 11:51:06 - INFO - __main__ - Step 120 Global step 120 Train loss 0.70 on epoch=2
06/13/2022 11:51:08 - INFO - __main__ - Step 130 Global step 130 Train loss 0.71 on epoch=2
06/13/2022 11:51:11 - INFO - __main__ - Step 140 Global step 140 Train loss 0.54 on epoch=2
06/13/2022 11:51:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.68 on epoch=2
06/13/2022 11:51:40 - INFO - __main__ - Global step 150 Train loss 0.68 Classification-F1 0.6138283653322759 on epoch=2
06/13/2022 11:51:40 - INFO - __main__ - Saving model with best Classification-F1: 0.3824436635529458 -> 0.6138283653322759 on epoch=2, global_step=150
06/13/2022 11:51:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=2
06/13/2022 11:51:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.53 on epoch=3
06/13/2022 11:51:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=3
06/13/2022 11:51:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.45 on epoch=3
06/13/2022 11:51:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=3
06/13/2022 11:52:20 - INFO - __main__ - Global step 200 Train loss 0.51 Classification-F1 0.5362570651843703 on epoch=3
06/13/2022 11:52:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=3
06/13/2022 11:52:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=3
06/13/2022 11:52:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=4
06/13/2022 11:52:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=4
06/13/2022 11:52:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=4
06/13/2022 11:53:01 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.5698376581583081 on epoch=4
06/13/2022 11:53:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=4
06/13/2022 11:53:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=4
06/13/2022 11:53:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=4
06/13/2022 11:53:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=5
06/13/2022 11:53:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=5
06/13/2022 11:53:43 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.6465505222675911 on epoch=5
06/13/2022 11:53:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6138283653322759 -> 0.6465505222675911 on epoch=5, global_step=300
06/13/2022 11:53:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.28 on epoch=5
06/13/2022 11:53:48 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=5
06/13/2022 11:53:50 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=5
06/13/2022 11:53:53 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=6
06/13/2022 11:53:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=6
06/13/2022 11:54:23 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.4959466488073844 on epoch=6
06/13/2022 11:54:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=6
06/13/2022 11:54:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=6
06/13/2022 11:54:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=6
06/13/2022 11:54:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=6
06/13/2022 11:54:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=7
06/13/2022 11:55:05 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.8379745245704924 on epoch=7
06/13/2022 11:55:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6465505222675911 -> 0.8379745245704924 on epoch=7, global_step=400
06/13/2022 11:55:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=7
06/13/2022 11:55:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.21 on epoch=7
06/13/2022 11:55:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=7
06/13/2022 11:55:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=7
06/13/2022 11:55:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=8
06/13/2022 11:55:46 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.7285895415800611 on epoch=8
06/13/2022 11:55:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=8
06/13/2022 11:55:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=8
06/13/2022 11:55:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=8
06/13/2022 11:55:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=8
06/13/2022 11:55:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=8
06/13/2022 11:56:29 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.7451693288084653 on epoch=8
06/13/2022 11:56:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=9
06/13/2022 11:56:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=9
06/13/2022 11:56:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=9
06/13/2022 11:56:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=9
06/13/2022 11:56:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=9
06/13/2022 11:57:13 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.7006793484348532 on epoch=9
06/13/2022 11:57:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=9
06/13/2022 11:57:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=10
06/13/2022 11:57:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=10
06/13/2022 11:57:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=10
06/13/2022 11:57:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=10
06/13/2022 11:57:54 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.7720927072808061 on epoch=10
06/13/2022 11:57:57 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=10
06/13/2022 11:57:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=11
06/13/2022 11:58:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=11
06/13/2022 11:58:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=11
06/13/2022 11:58:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=11
06/13/2022 11:58:37 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.720337937961803 on epoch=11
06/13/2022 11:58:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=11
06/13/2022 11:58:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=11
06/13/2022 11:58:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=12
06/13/2022 11:58:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=12
06/13/2022 11:58:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=12
06/13/2022 11:59:19 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7260215708586101 on epoch=12
06/13/2022 11:59:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=12
06/13/2022 11:59:24 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
06/13/2022 11:59:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=13
06/13/2022 11:59:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=13
06/13/2022 11:59:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=13
06/13/2022 12:00:00 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6706558513641776 on epoch=13
06/13/2022 12:00:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=13
06/13/2022 12:00:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=13
06/13/2022 12:00:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=13
06/13/2022 12:00:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=14
06/13/2022 12:00:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=14
06/13/2022 12:00:42 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7470775749424132 on epoch=14
06/13/2022 12:00:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=14
06/13/2022 12:00:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=14
06/13/2022 12:00:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=14
06/13/2022 12:00:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=14
06/13/2022 12:00:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=15
06/13/2022 12:01:25 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7242590189980179 on epoch=15
06/13/2022 12:01:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=15
06/13/2022 12:01:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=15
06/13/2022 12:01:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=15
06/13/2022 12:01:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=15
06/13/2022 12:01:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=16
06/13/2022 12:02:05 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7223701151899081 on epoch=16
06/13/2022 12:02:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=16
06/13/2022 12:02:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=16
06/13/2022 12:02:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=16
06/13/2022 12:02:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
06/13/2022 12:02:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
06/13/2022 12:02:46 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.8008436892422482 on epoch=16
06/13/2022 12:02:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=17
06/13/2022 12:02:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=17
06/13/2022 12:02:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=17
06/13/2022 12:02:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=17
06/13/2022 12:02:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=17
06/13/2022 12:03:27 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.6405130272340203 on epoch=17
06/13/2022 12:03:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=18
06/13/2022 12:03:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=18
06/13/2022 12:03:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=18
06/13/2022 12:03:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=18
06/13/2022 12:03:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=18
06/13/2022 12:04:05 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7827780061939741 on epoch=18
06/13/2022 12:04:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=18
06/13/2022 12:04:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=19
06/13/2022 12:04:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=19
06/13/2022 12:04:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=19
06/13/2022 12:04:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=19
06/13/2022 12:04:44 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8391747007935855 on epoch=19
06/13/2022 12:04:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8379745245704924 -> 0.8391747007935855 on epoch=19, global_step=1100
06/13/2022 12:04:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=19
06/13/2022 12:04:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=19
06/13/2022 12:04:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=20
06/13/2022 12:04:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=20
06/13/2022 12:04:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=20
06/13/2022 12:05:24 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.8360108507095797 on epoch=20
06/13/2022 12:05:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=20
06/13/2022 12:05:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=20
06/13/2022 12:05:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=21
06/13/2022 12:05:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=21
06/13/2022 12:05:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=21
06/13/2022 12:06:02 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8048200531251114 on epoch=21
06/13/2022 12:06:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=21
06/13/2022 12:06:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=21
06/13/2022 12:06:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=21
06/13/2022 12:06:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=22
06/13/2022 12:06:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=22
06/13/2022 12:06:39 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7493609914526438 on epoch=22
06/13/2022 12:06:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=22
06/13/2022 12:06:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=22
06/13/2022 12:06:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=22
06/13/2022 12:06:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=23
06/13/2022 12:06:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=23
06/13/2022 12:07:18 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.8509073382237016 on epoch=23
06/13/2022 12:07:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8391747007935855 -> 0.8509073382237016 on epoch=23, global_step=1300
06/13/2022 12:07:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=23
06/13/2022 12:07:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=23
06/13/2022 12:07:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=23
06/13/2022 12:07:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=23
06/13/2022 12:07:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=24
06/13/2022 12:07:58 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.783219516387937 on epoch=24
06/13/2022 12:08:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=24
06/13/2022 12:08:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=24
06/13/2022 12:08:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=24
06/13/2022 12:08:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=24
06/13/2022 12:08:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=24
06/13/2022 12:08:35 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.8423163455690909 on epoch=24
06/13/2022 12:08:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=25
06/13/2022 12:08:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=25
06/13/2022 12:08:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=25
06/13/2022 12:08:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=25
06/13/2022 12:08:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=25
06/13/2022 12:09:14 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7922823998384534 on epoch=25
06/13/2022 12:09:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
06/13/2022 12:09:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
06/13/2022 12:09:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=26
06/13/2022 12:09:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
06/13/2022 12:09:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
06/13/2022 12:09:52 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.8012658562554361 on epoch=26
06/13/2022 12:09:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=26
06/13/2022 12:09:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=27
06/13/2022 12:10:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=27
06/13/2022 12:10:02 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
06/13/2022 12:10:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=27
06/13/2022 12:10:31 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7411084451706428 on epoch=27
06/13/2022 12:10:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=27
06/13/2022 12:10:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=28
06/13/2022 12:10:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
06/13/2022 12:10:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
06/13/2022 12:10:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=28
06/13/2022 12:11:09 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7417060609161967 on epoch=28
06/13/2022 12:11:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=28
06/13/2022 12:11:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=28
06/13/2022 12:11:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=29
06/13/2022 12:11:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=29
06/13/2022 12:11:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
06/13/2022 12:11:48 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6767933354509358 on epoch=29
06/13/2022 12:11:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=29
06/13/2022 12:11:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=29
06/13/2022 12:11:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=29
06/13/2022 12:11:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
06/13/2022 12:12:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=30
06/13/2022 12:12:26 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7598504595256111 on epoch=30
06/13/2022 12:12:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
06/13/2022 12:12:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
06/13/2022 12:12:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
06/13/2022 12:12:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=31
06/13/2022 12:12:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=31
06/13/2022 12:13:04 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8546465550770903 on epoch=31
06/13/2022 12:13:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8509073382237016 -> 0.8546465550770903 on epoch=31, global_step=1750
06/13/2022 12:13:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=31
06/13/2022 12:13:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=31
06/13/2022 12:13:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=31
06/13/2022 12:13:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
06/13/2022 12:13:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=32
06/13/2022 12:13:41 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7597474259571445 on epoch=32
06/13/2022 12:13:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=32
06/13/2022 12:13:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
06/13/2022 12:13:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
06/13/2022 12:13:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
06/13/2022 12:13:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=33
06/13/2022 12:14:18 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.8557948294511959 on epoch=33
06/13/2022 12:14:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8546465550770903 -> 0.8557948294511959 on epoch=33, global_step=1850
06/13/2022 12:14:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
06/13/2022 12:14:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=33
06/13/2022 12:14:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=33
06/13/2022 12:14:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=33
06/13/2022 12:14:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
06/13/2022 12:14:58 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8371172567589615 on epoch=33
06/13/2022 12:15:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=34
06/13/2022 12:15:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
06/13/2022 12:15:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
06/13/2022 12:15:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=34
06/13/2022 12:15:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=34
06/13/2022 12:15:35 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.8269728496509016 on epoch=34
06/13/2022 12:15:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
06/13/2022 12:15:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
06/13/2022 12:15:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
06/13/2022 12:15:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=35
06/13/2022 12:15:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=35
06/13/2022 12:16:13 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8365249465322113 on epoch=35
06/13/2022 12:16:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
06/13/2022 12:16:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=36
06/13/2022 12:16:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
06/13/2022 12:16:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
06/13/2022 12:16:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
06/13/2022 12:16:51 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7435216658057592 on epoch=36
06/13/2022 12:16:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
06/13/2022 12:16:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
06/13/2022 12:16:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=37
06/13/2022 12:17:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=37
06/13/2022 12:17:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
06/13/2022 12:17:29 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8568229198735945 on epoch=37
06/13/2022 12:17:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8557948294511959 -> 0.8568229198735945 on epoch=37, global_step=2100
06/13/2022 12:17:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
06/13/2022 12:17:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
06/13/2022 12:17:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=38
06/13/2022 12:17:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=38
06/13/2022 12:17:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=38
06/13/2022 12:18:08 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8029418779608094 on epoch=38
06/13/2022 12:18:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=38
06/13/2022 12:18:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=38
06/13/2022 12:18:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
06/13/2022 12:18:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=39
06/13/2022 12:18:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=39
06/13/2022 12:18:44 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.669142690722086 on epoch=39
06/13/2022 12:18:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
06/13/2022 12:18:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=39
06/13/2022 12:18:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
06/13/2022 12:18:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
06/13/2022 12:18:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=40
06/13/2022 12:19:22 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7052411263373275 on epoch=40
06/13/2022 12:19:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 12:19:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=40
06/13/2022 12:19:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
06/13/2022 12:19:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
06/13/2022 12:19:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
06/13/2022 12:19:58 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6730198010015799 on epoch=41
06/13/2022 12:20:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
06/13/2022 12:20:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=41
06/13/2022 12:20:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
06/13/2022 12:20:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 12:20:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=41
06/13/2022 12:20:35 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6945199308919427 on epoch=41
06/13/2022 12:20:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=42
06/13/2022 12:20:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=42
06/13/2022 12:20:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 12:20:45 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=42
06/13/2022 12:20:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=42
06/13/2022 12:21:13 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7908523662153194 on epoch=42
06/13/2022 12:21:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=43
06/13/2022 12:21:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
06/13/2022 12:21:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
06/13/2022 12:21:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
06/13/2022 12:21:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
06/13/2022 12:21:52 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7494451905589218 on epoch=43
06/13/2022 12:21:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=43
06/13/2022 12:21:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
06/13/2022 12:21:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
06/13/2022 12:22:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 12:22:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
06/13/2022 12:22:28 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7928547918376607 on epoch=44
06/13/2022 12:22:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
06/13/2022 12:22:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
06/13/2022 12:22:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
06/13/2022 12:22:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=45
06/13/2022 12:22:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=45
06/13/2022 12:23:05 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7958596702877196 on epoch=45
06/13/2022 12:23:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
06/13/2022 12:23:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=45
06/13/2022 12:23:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 12:23:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
06/13/2022 12:23:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
06/13/2022 12:23:41 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7519747933224759 on epoch=46
06/13/2022 12:23:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
06/13/2022 12:23:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=46
06/13/2022 12:23:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
06/13/2022 12:23:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=47
06/13/2022 12:23:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
06/13/2022 12:24:17 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8003292485962215 on epoch=47
06/13/2022 12:24:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 12:24:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
06/13/2022 12:24:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
06/13/2022 12:24:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=48
06/13/2022 12:24:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
06/13/2022 12:24:55 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7538039276824571 on epoch=48
06/13/2022 12:24:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
06/13/2022 12:25:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
06/13/2022 12:25:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
06/13/2022 12:25:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=48
06/13/2022 12:25:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
06/13/2022 12:25:34 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8081812514322009 on epoch=49
06/13/2022 12:25:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
06/13/2022 12:25:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
06/13/2022 12:25:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
06/13/2022 12:25:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
06/13/2022 12:25:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
06/13/2022 12:26:10 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8497976395532791 on epoch=49
06/13/2022 12:26:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=50
06/13/2022 12:26:15 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
06/13/2022 12:26:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=50
06/13/2022 12:26:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
06/13/2022 12:26:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=50
06/13/2022 12:26:47 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7990503337495929 on epoch=50
06/13/2022 12:26:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 12:26:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
06/13/2022 12:26:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
06/13/2022 12:26:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
06/13/2022 12:27:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 12:27:23 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8496513101751008 on epoch=51
06/13/2022 12:27:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=51
06/13/2022 12:27:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
06/13/2022 12:27:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
06/13/2022 12:27:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
06/13/2022 12:27:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 12:28:00 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8533028773275996 on epoch=52
06/13/2022 12:28:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
06/13/2022 12:28:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
06/13/2022 12:28:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
06/13/2022 12:28:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
06/13/2022 12:28:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
06/13/2022 12:28:15 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 12:28:15 - INFO - __main__ - Printing 3 examples
06/13/2022 12:28:15 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 12:28:15 - INFO - __main__ - ['Company']
06/13/2022 12:28:15 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 12:28:15 - INFO - __main__ - ['Company']
06/13/2022 12:28:15 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 12:28:15 - INFO - __main__ - ['Company']
06/13/2022 12:28:15 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:28:15 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:28:16 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 12:28:16 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 12:28:16 - INFO - __main__ - Printing 3 examples
06/13/2022 12:28:16 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 12:28:16 - INFO - __main__ - ['Company']
06/13/2022 12:28:16 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 12:28:16 - INFO - __main__ - ['Company']
06/13/2022 12:28:16 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 12:28:16 - INFO - __main__ - ['Company']
06/13/2022 12:28:16 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:28:17 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:28:17 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 12:28:33 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 12:28:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 12:28:34 - INFO - __main__ - Starting training!
06/13/2022 12:28:39 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9143762583949115 on epoch=53
06/13/2022 12:28:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8568229198735945 -> 0.9143762583949115 on epoch=53, global_step=3000
06/13/2022 12:28:39 - INFO - __main__ - save last model!
06/13/2022 12:28:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 12:28:39 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 12:28:39 - INFO - __main__ - Printing 3 examples
06/13/2022 12:28:39 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 12:28:39 - INFO - __main__ - ['Animal']
06/13/2022 12:28:39 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 12:28:39 - INFO - __main__ - ['Animal']
06/13/2022 12:28:39 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 12:28:39 - INFO - __main__ - ['Village']
06/13/2022 12:28:39 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:28:41 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:28:45 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 12:30:52 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.3_8_predictions.txt
06/13/2022 12:30:52 - INFO - __main__ - Classification-F1 on test data: 0.6846
06/13/2022 12:30:53 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.3, bsz=8, dev_performance=0.9143762583949115, test_performance=0.6845689156833825
06/13/2022 12:30:53 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.2, bsz=8 ...
06/13/2022 12:30:54 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 12:30:54 - INFO - __main__ - Printing 3 examples
06/13/2022 12:30:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/13/2022 12:30:54 - INFO - __main__ - ['Company']
06/13/2022 12:30:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/13/2022 12:30:54 - INFO - __main__ - ['Company']
06/13/2022 12:30:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/13/2022 12:30:54 - INFO - __main__ - ['Company']
06/13/2022 12:30:54 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:30:54 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:30:55 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 12:30:55 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 12:30:55 - INFO - __main__ - Printing 3 examples
06/13/2022 12:30:55 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
06/13/2022 12:30:55 - INFO - __main__ - ['Company']
06/13/2022 12:30:55 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
06/13/2022 12:30:55 - INFO - __main__ - ['Company']
06/13/2022 12:30:55 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
06/13/2022 12:30:55 - INFO - __main__ - ['Company']
06/13/2022 12:30:55 - INFO - __main__ - Tokenizing Input ...
06/13/2022 12:30:55 - INFO - __main__ - Tokenizing Output ...
06/13/2022 12:30:56 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 12:31:12 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 12:31:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 12:31:12 - INFO - __main__ - Starting training!
06/13/2022 12:31:16 - INFO - __main__ - Step 10 Global step 10 Train loss 5.14 on epoch=0
06/13/2022 12:31:18 - INFO - __main__ - Step 20 Global step 20 Train loss 3.74 on epoch=0
06/13/2022 12:31:21 - INFO - __main__ - Step 30 Global step 30 Train loss 2.84 on epoch=0
06/13/2022 12:31:24 - INFO - __main__ - Step 40 Global step 40 Train loss 2.51 on epoch=0
06/13/2022 12:31:26 - INFO - __main__ - Step 50 Global step 50 Train loss 2.32 on epoch=0
06/13/2022 12:31:48 - INFO - __main__ - Global step 50 Train loss 3.31 Classification-F1 0.04624408556058986 on epoch=0
06/13/2022 12:31:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04624408556058986 on epoch=0, global_step=50
06/13/2022 12:31:51 - INFO - __main__ - Step 60 Global step 60 Train loss 1.68 on epoch=1
06/13/2022 12:31:53 - INFO - __main__ - Step 70 Global step 70 Train loss 1.40 on epoch=1
06/13/2022 12:31:56 - INFO - __main__ - Step 80 Global step 80 Train loss 1.23 on epoch=1
06/13/2022 12:31:58 - INFO - __main__ - Step 90 Global step 90 Train loss 1.25 on epoch=1
06/13/2022 12:32:01 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=1
06/13/2022 12:32:26 - INFO - __main__ - Global step 100 Train loss 1.31 Classification-F1 0.22803820997835222 on epoch=1
06/13/2022 12:32:26 - INFO - __main__ - Saving model with best Classification-F1: 0.04624408556058986 -> 0.22803820997835222 on epoch=1, global_step=100
06/13/2022 12:32:29 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=1
06/13/2022 12:32:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.94 on epoch=2
06/13/2022 12:32:34 - INFO - __main__ - Step 130 Global step 130 Train loss 0.92 on epoch=2
06/13/2022 12:32:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=2
06/13/2022 12:32:39 - INFO - __main__ - Step 150 Global step 150 Train loss 0.77 on epoch=2
06/13/2022 12:33:05 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.37585983490473585 on epoch=2
06/13/2022 12:33:05 - INFO - __main__ - Saving model with best Classification-F1: 0.22803820997835222 -> 0.37585983490473585 on epoch=2, global_step=150
06/13/2022 12:33:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=2
06/13/2022 12:33:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.75 on epoch=3
06/13/2022 12:33:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.67 on epoch=3
06/13/2022 12:33:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.67 on epoch=3
06/13/2022 12:33:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.58 on epoch=3
06/13/2022 12:33:45 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.5030983735428165 on epoch=3
06/13/2022 12:33:45 - INFO - __main__ - Saving model with best Classification-F1: 0.37585983490473585 -> 0.5030983735428165 on epoch=3, global_step=200
06/13/2022 12:33:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=3
06/13/2022 12:33:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=3
06/13/2022 12:33:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.57 on epoch=4
06/13/2022 12:33:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=4
06/13/2022 12:33:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=4
06/13/2022 12:34:24 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.5613786216318302 on epoch=4
06/13/2022 12:34:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5030983735428165 -> 0.5613786216318302 on epoch=4, global_step=250
06/13/2022 12:34:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=4
06/13/2022 12:34:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=4
06/13/2022 12:34:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.44 on epoch=4
06/13/2022 12:34:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=5
06/13/2022 12:34:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=5
06/13/2022 12:35:05 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.5380872600290986 on epoch=5
06/13/2022 12:35:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=5
06/13/2022 12:35:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=5
06/13/2022 12:35:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=5
06/13/2022 12:35:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.40 on epoch=6
06/13/2022 12:35:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=6
06/13/2022 12:35:45 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.5926226326837736 on epoch=6
06/13/2022 12:35:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5613786216318302 -> 0.5926226326837736 on epoch=6, global_step=350
06/13/2022 12:35:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=6
06/13/2022 12:35:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=6
06/13/2022 12:35:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=6
06/13/2022 12:35:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=6
06/13/2022 12:35:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=7
06/13/2022 12:36:26 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.6948990005127822 on epoch=7
06/13/2022 12:36:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5926226326837736 -> 0.6948990005127822 on epoch=7, global_step=400
06/13/2022 12:36:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=7
06/13/2022 12:36:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=7
06/13/2022 12:36:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=7
06/13/2022 12:36:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=7
06/13/2022 12:36:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=8
06/13/2022 12:37:08 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.6786812268755038 on epoch=8
06/13/2022 12:37:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=8
06/13/2022 12:37:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=8
06/13/2022 12:37:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=8
06/13/2022 12:37:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=8
06/13/2022 12:37:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=8
06/13/2022 12:37:49 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.6668103120107401 on epoch=8
06/13/2022 12:37:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=9
06/13/2022 12:37:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=9
06/13/2022 12:37:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=9
06/13/2022 12:37:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=9
06/13/2022 12:38:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=9
06/13/2022 12:38:30 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7451415973312757 on epoch=9
06/13/2022 12:38:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6948990005127822 -> 0.7451415973312757 on epoch=9, global_step=550
06/13/2022 12:38:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=9
06/13/2022 12:38:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=10
06/13/2022 12:38:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=10
06/13/2022 12:38:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=10
06/13/2022 12:38:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=10
06/13/2022 12:39:10 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.7492674748506608 on epoch=10
06/13/2022 12:39:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7451415973312757 -> 0.7492674748506608 on epoch=10, global_step=600
06/13/2022 12:39:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=10
06/13/2022 12:39:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=11
06/13/2022 12:39:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=11
06/13/2022 12:39:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=11
06/13/2022 12:39:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=11
06/13/2022 12:39:51 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7879761031915933 on epoch=11
06/13/2022 12:39:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7492674748506608 -> 0.7879761031915933 on epoch=11, global_step=650
06/13/2022 12:39:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=11
06/13/2022 12:39:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=11
06/13/2022 12:39:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=12
06/13/2022 12:40:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=12
06/13/2022 12:40:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=12
06/13/2022 12:40:33 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.7252573085949596 on epoch=12
06/13/2022 12:40:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=12
06/13/2022 12:40:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=12
06/13/2022 12:40:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=13
06/13/2022 12:40:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=13
06/13/2022 12:40:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.29 on epoch=13
06/13/2022 12:41:16 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.8307314951681629 on epoch=13
06/13/2022 12:41:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7879761031915933 -> 0.8307314951681629 on epoch=13, global_step=750
06/13/2022 12:41:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=13
06/13/2022 12:41:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=13
06/13/2022 12:41:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=13
06/13/2022 12:41:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=14
06/13/2022 12:41:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=14
06/13/2022 12:41:57 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.7619493790597671 on epoch=14
06/13/2022 12:42:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=14
06/13/2022 12:42:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=14
06/13/2022 12:42:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=14
06/13/2022 12:42:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=14
06/13/2022 12:42:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=15
06/13/2022 12:42:39 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.8292417234212301 on epoch=15
06/13/2022 12:42:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=15
06/13/2022 12:42:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=15
06/13/2022 12:42:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=15
06/13/2022 12:42:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=15
06/13/2022 12:42:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=16
06/13/2022 12:43:22 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.6464826421425689 on epoch=16
06/13/2022 12:43:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=16
06/13/2022 12:43:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=16
06/13/2022 12:43:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=16
06/13/2022 12:43:32 - INFO - __main__ - Step 940 Global step 940 Train loss 0.18 on epoch=16
06/13/2022 12:43:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=16
06/13/2022 12:44:04 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.7409829255812703 on epoch=16
06/13/2022 12:44:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=17
06/13/2022 12:44:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=17
06/13/2022 12:44:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=17
06/13/2022 12:44:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=17
06/13/2022 12:44:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=17
06/13/2022 12:44:45 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.7940593068187128 on epoch=17
06/13/2022 12:44:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=18
06/13/2022 12:44:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=18
06/13/2022 12:44:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=18
06/13/2022 12:44:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=18
06/13/2022 12:44:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=18
06/13/2022 12:45:26 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.761482263556928 on epoch=18
06/13/2022 12:45:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=18
06/13/2022 12:45:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=19
06/13/2022 12:45:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=19
06/13/2022 12:45:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=19
06/13/2022 12:45:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=19
06/13/2022 12:46:06 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.7638666889140087 on epoch=19
06/13/2022 12:46:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.18 on epoch=19
06/13/2022 12:46:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=19
06/13/2022 12:46:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=20
06/13/2022 12:46:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=20
06/13/2022 12:46:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=20
06/13/2022 12:46:47 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6615424591087802 on epoch=20
06/13/2022 12:46:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=20
06/13/2022 12:46:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=20
06/13/2022 12:46:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=21
06/13/2022 12:46:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=21
06/13/2022 12:46:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=21
06/13/2022 12:47:27 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7634737138179257 on epoch=21
06/13/2022 12:47:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=21
06/13/2022 12:47:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=21
06/13/2022 12:47:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=21
06/13/2022 12:47:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=22
06/13/2022 12:47:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=22
06/13/2022 12:48:10 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.9004677259770894 on epoch=22
06/13/2022 12:48:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8307314951681629 -> 0.9004677259770894 on epoch=22, global_step=1250
06/13/2022 12:48:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=22
06/13/2022 12:48:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=22
06/13/2022 12:48:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
06/13/2022 12:48:20 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=23
06/13/2022 12:48:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=23
06/13/2022 12:48:52 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.8321396724552167 on epoch=23
06/13/2022 12:48:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=23
06/13/2022 12:48:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=23
06/13/2022 12:49:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=23
06/13/2022 12:49:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=23
06/13/2022 12:49:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=24
06/13/2022 12:49:34 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.751357242561203 on epoch=24
06/13/2022 12:49:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=24
06/13/2022 12:49:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=24
06/13/2022 12:49:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=24
06/13/2022 12:49:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=24
06/13/2022 12:49:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=24
06/13/2022 12:50:16 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6809567669135398 on epoch=24
06/13/2022 12:50:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=25
06/13/2022 12:50:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=25
06/13/2022 12:50:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=25
06/13/2022 12:50:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=25
06/13/2022 12:50:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=25
06/13/2022 12:50:58 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.8035956741556533 on epoch=25
06/13/2022 12:51:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=26
06/13/2022 12:51:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=26
06/13/2022 12:51:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=26
06/13/2022 12:51:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
06/13/2022 12:51:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=26
06/13/2022 12:51:38 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.7128605032634769 on epoch=26
06/13/2022 12:51:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=26
06/13/2022 12:51:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=27
06/13/2022 12:51:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=27
06/13/2022 12:51:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=27
06/13/2022 12:51:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=27
06/13/2022 12:52:18 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7453796717034622 on epoch=27
06/13/2022 12:52:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=27
06/13/2022 12:52:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=28
06/13/2022 12:52:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
06/13/2022 12:52:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=28
06/13/2022 12:52:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=28
06/13/2022 12:52:59 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.846367110812392 on epoch=28
06/13/2022 12:53:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=28
06/13/2022 12:53:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=28
06/13/2022 12:53:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=29
06/13/2022 12:53:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=29
06/13/2022 12:53:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
06/13/2022 12:53:38 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.9764020469843953 on epoch=29
06/13/2022 12:53:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9004677259770894 -> 0.9764020469843953 on epoch=29, global_step=1650
06/13/2022 12:53:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
06/13/2022 12:53:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=29
06/13/2022 12:53:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
06/13/2022 12:53:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=30
06/13/2022 12:53:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=30
06/13/2022 12:54:19 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9128558022736254 on epoch=30
06/13/2022 12:54:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=30
06/13/2022 12:54:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=30
06/13/2022 12:54:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=30
06/13/2022 12:54:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
06/13/2022 12:54:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=31
06/13/2022 12:55:01 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8527650242534148 on epoch=31
06/13/2022 12:55:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=31
06/13/2022 12:55:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=31
06/13/2022 12:55:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
06/13/2022 12:55:11 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=31
06/13/2022 12:55:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=32
06/13/2022 12:55:41 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.854193750229949 on epoch=32
06/13/2022 12:55:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=32
06/13/2022 12:55:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=32
06/13/2022 12:55:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=32
06/13/2022 12:55:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=32
06/13/2022 12:55:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=33
06/13/2022 12:56:24 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.9076643362267127 on epoch=33
06/13/2022 12:56:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
06/13/2022 12:56:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.13 on epoch=33
06/13/2022 12:56:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
06/13/2022 12:56:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=33
06/13/2022 12:56:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
06/13/2022 12:57:05 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7458382429800875 on epoch=33
06/13/2022 12:57:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
06/13/2022 12:57:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=34
06/13/2022 12:57:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=34
06/13/2022 12:57:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
06/13/2022 12:57:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=34
06/13/2022 12:57:46 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7554454136634906 on epoch=34
06/13/2022 12:57:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
06/13/2022 12:57:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=35
06/13/2022 12:57:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=35
06/13/2022 12:57:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=35
06/13/2022 12:57:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
06/13/2022 12:58:25 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8441737418733797 on epoch=35
06/13/2022 12:58:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
06/13/2022 12:58:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=36
06/13/2022 12:58:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
06/13/2022 12:58:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=36
06/13/2022 12:58:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
06/13/2022 12:59:06 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.6980857394998209 on epoch=36
06/13/2022 12:59:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
06/13/2022 12:59:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
06/13/2022 12:59:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=37
06/13/2022 12:59:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=37
06/13/2022 12:59:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=37
06/13/2022 12:59:46 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8038990846341455 on epoch=37
06/13/2022 12:59:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
06/13/2022 12:59:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
06/13/2022 12:59:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=38
06/13/2022 12:59:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
06/13/2022 12:59:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=38
06/13/2022 13:00:25 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7483556951325957 on epoch=38
06/13/2022 13:00:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
06/13/2022 13:00:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=38
06/13/2022 13:00:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
06/13/2022 13:00:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
06/13/2022 13:00:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=39
06/13/2022 13:01:04 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7485627419373461 on epoch=39
06/13/2022 13:01:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=39
06/13/2022 13:01:09 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
06/13/2022 13:01:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=39
06/13/2022 13:01:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=39
06/13/2022 13:01:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
06/13/2022 13:01:46 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.80132391743175 on epoch=40
06/13/2022 13:01:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=40
06/13/2022 13:01:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
06/13/2022 13:01:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=40
06/13/2022 13:01:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
06/13/2022 13:01:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
06/13/2022 13:02:26 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8460809007321632 on epoch=41
06/13/2022 13:02:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=41
06/13/2022 13:02:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=41
06/13/2022 13:02:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
06/13/2022 13:02:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
06/13/2022 13:02:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=41
06/13/2022 13:03:08 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8512384487972707 on epoch=41
06/13/2022 13:03:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
06/13/2022 13:03:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=42
06/13/2022 13:03:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 13:03:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
06/13/2022 13:03:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
06/13/2022 13:03:49 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8507375069842567 on epoch=42
06/13/2022 13:03:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
06/13/2022 13:03:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=43
06/13/2022 13:03:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=43
06/13/2022 13:03:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
06/13/2022 13:04:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
06/13/2022 13:04:29 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8558225160804558 on epoch=43
06/13/2022 13:04:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
06/13/2022 13:04:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
06/13/2022 13:04:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=44
06/13/2022 13:04:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
06/13/2022 13:04:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=44
06/13/2022 13:05:08 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8523942693635506 on epoch=44
06/13/2022 13:05:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=44
06/13/2022 13:05:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
06/13/2022 13:05:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=45
06/13/2022 13:05:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
06/13/2022 13:05:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=45
06/13/2022 13:05:47 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7115282711141601 on epoch=45
06/13/2022 13:05:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
06/13/2022 13:05:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
06/13/2022 13:05:55 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=46
06/13/2022 13:05:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
06/13/2022 13:06:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
06/13/2022 13:06:27 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8476806891185608 on epoch=46
06/13/2022 13:06:30 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=46
06/13/2022 13:06:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
06/13/2022 13:06:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
06/13/2022 13:06:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=47
06/13/2022 13:06:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
06/13/2022 13:07:06 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8071456869042307 on epoch=47
06/13/2022 13:07:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=47
06/13/2022 13:07:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
06/13/2022 13:07:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=47
06/13/2022 13:07:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=48
06/13/2022 13:07:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
06/13/2022 13:07:45 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8021110224923341 on epoch=48
06/13/2022 13:07:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=48
06/13/2022 13:07:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=48
06/13/2022 13:07:52 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
06/13/2022 13:07:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
06/13/2022 13:07:57 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
06/13/2022 13:08:25 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.85129498975467 on epoch=49
06/13/2022 13:08:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=49
06/13/2022 13:08:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
06/13/2022 13:08:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
06/13/2022 13:08:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
06/13/2022 13:08:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
06/13/2022 13:09:05 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7521537511612203 on epoch=49
06/13/2022 13:09:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
06/13/2022 13:09:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=50
06/13/2022 13:09:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
06/13/2022 13:09:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
06/13/2022 13:09:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
06/13/2022 13:09:44 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7501575965143097 on epoch=50
06/13/2022 13:09:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 13:09:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
06/13/2022 13:09:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
06/13/2022 13:09:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
06/13/2022 13:09:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
06/13/2022 13:10:24 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7527883130305135 on epoch=51
06/13/2022 13:10:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
06/13/2022 13:10:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
06/13/2022 13:10:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
06/13/2022 13:10:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
06/13/2022 13:10:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
06/13/2022 13:11:03 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8449086659078493 on epoch=52
06/13/2022 13:11:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
06/13/2022 13:11:09 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
06/13/2022 13:11:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
06/13/2022 13:11:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
06/13/2022 13:11:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
06/13/2022 13:11:18 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:11:18 - INFO - __main__ - Printing 3 examples
06/13/2022 13:11:18 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 13:11:18 - INFO - __main__ - ['Film']
06/13/2022 13:11:18 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 13:11:18 - INFO - __main__ - ['Film']
06/13/2022 13:11:18 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 13:11:18 - INFO - __main__ - ['Film']
06/13/2022 13:11:18 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:11:18 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:11:19 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 13:11:19 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:11:19 - INFO - __main__ - Printing 3 examples
06/13/2022 13:11:19 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 13:11:19 - INFO - __main__ - ['Film']
06/13/2022 13:11:19 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 13:11:19 - INFO - __main__ - ['Film']
06/13/2022 13:11:19 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 13:11:19 - INFO - __main__ - ['Film']
06/13/2022 13:11:19 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:11:20 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:11:21 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 13:11:39 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 13:11:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 13:11:40 - INFO - __main__ - Starting training!
06/13/2022 13:11:43 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8021525372944965 on epoch=53
06/13/2022 13:11:43 - INFO - __main__ - save last model!
06/13/2022 13:11:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 13:11:43 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 13:11:43 - INFO - __main__ - Printing 3 examples
06/13/2022 13:11:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 13:11:43 - INFO - __main__ - ['Animal']
06/13/2022 13:11:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 13:11:43 - INFO - __main__ - ['Animal']
06/13/2022 13:11:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 13:11:43 - INFO - __main__ - ['Village']
06/13/2022 13:11:43 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:11:45 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:11:48 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 13:13:56 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.2_8_predictions.txt
06/13/2022 13:13:56 - INFO - __main__ - Classification-F1 on test data: 0.7214
06/13/2022 13:13:56 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.2, bsz=8, dev_performance=0.9764020469843953, test_performance=0.7214321077299723
06/13/2022 13:13:56 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.5, bsz=8 ...
06/13/2022 13:13:57 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:13:57 - INFO - __main__ - Printing 3 examples
06/13/2022 13:13:57 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 13:13:57 - INFO - __main__ - ['Film']
06/13/2022 13:13:57 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 13:13:57 - INFO - __main__ - ['Film']
06/13/2022 13:13:57 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 13:13:57 - INFO - __main__ - ['Film']
06/13/2022 13:13:57 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:13:58 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:13:59 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 13:13:59 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:13:59 - INFO - __main__ - Printing 3 examples
06/13/2022 13:13:59 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 13:13:59 - INFO - __main__ - ['Film']
06/13/2022 13:13:59 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 13:13:59 - INFO - __main__ - ['Film']
06/13/2022 13:13:59 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 13:13:59 - INFO - __main__ - ['Film']
06/13/2022 13:13:59 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:13:59 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:14:00 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 13:14:16 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 13:14:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 13:14:16 - INFO - __main__ - Starting training!
06/13/2022 13:14:19 - INFO - __main__ - Step 10 Global step 10 Train loss 4.31 on epoch=0
06/13/2022 13:14:22 - INFO - __main__ - Step 20 Global step 20 Train loss 2.77 on epoch=0
06/13/2022 13:14:25 - INFO - __main__ - Step 30 Global step 30 Train loss 1.73 on epoch=0
06/13/2022 13:14:27 - INFO - __main__ - Step 40 Global step 40 Train loss 1.18 on epoch=0
06/13/2022 13:14:30 - INFO - __main__ - Step 50 Global step 50 Train loss 1.09 on epoch=0
06/13/2022 13:14:56 - INFO - __main__ - Global step 50 Train loss 2.22 Classification-F1 0.20030326774930277 on epoch=0
06/13/2022 13:14:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.20030326774930277 on epoch=0, global_step=50
06/13/2022 13:14:59 - INFO - __main__ - Step 60 Global step 60 Train loss 0.84 on epoch=1
06/13/2022 13:15:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.80 on epoch=1
06/13/2022 13:15:04 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=1
06/13/2022 13:15:07 - INFO - __main__ - Step 90 Global step 90 Train loss 0.72 on epoch=1
06/13/2022 13:15:09 - INFO - __main__ - Step 100 Global step 100 Train loss 0.59 on epoch=1
06/13/2022 13:15:35 - INFO - __main__ - Global step 100 Train loss 0.77 Classification-F1 0.4540015678292488 on epoch=1
06/13/2022 13:15:35 - INFO - __main__ - Saving model with best Classification-F1: 0.20030326774930277 -> 0.4540015678292488 on epoch=1, global_step=100
06/13/2022 13:15:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.57 on epoch=1
06/13/2022 13:15:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.50 on epoch=2
06/13/2022 13:15:43 - INFO - __main__ - Step 130 Global step 130 Train loss 0.58 on epoch=2
06/13/2022 13:15:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.52 on epoch=2
06/13/2022 13:15:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.48 on epoch=2
06/13/2022 13:16:15 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.42334342766436434 on epoch=2
06/13/2022 13:16:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.51 on epoch=2
06/13/2022 13:16:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.37 on epoch=3
06/13/2022 13:16:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.43 on epoch=3
06/13/2022 13:16:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=3
06/13/2022 13:16:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=3
06/13/2022 13:16:55 - INFO - __main__ - Global step 200 Train loss 0.43 Classification-F1 0.44456264496361714 on epoch=3
06/13/2022 13:16:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.42 on epoch=3
06/13/2022 13:17:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.32 on epoch=3
06/13/2022 13:17:03 - INFO - __main__ - Step 230 Global step 230 Train loss 0.26 on epoch=4
06/13/2022 13:17:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.32 on epoch=4
06/13/2022 13:17:08 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=4
06/13/2022 13:17:41 - INFO - __main__ - Global step 250 Train loss 0.32 Classification-F1 0.805217551166548 on epoch=4
06/13/2022 13:17:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4540015678292488 -> 0.805217551166548 on epoch=4, global_step=250
06/13/2022 13:17:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.30 on epoch=4
06/13/2022 13:17:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.21 on epoch=4
06/13/2022 13:17:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.23 on epoch=4
06/13/2022 13:17:52 - INFO - __main__ - Step 290 Global step 290 Train loss 0.23 on epoch=5
06/13/2022 13:17:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=5
06/13/2022 13:18:26 - INFO - __main__ - Global step 300 Train loss 0.25 Classification-F1 0.65084427572703 on epoch=5
06/13/2022 13:18:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=5
06/13/2022 13:18:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.23 on epoch=5
06/13/2022 13:18:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.17 on epoch=5
06/13/2022 13:18:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.14 on epoch=6
06/13/2022 13:18:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=6
06/13/2022 13:19:05 - INFO - __main__ - Global step 350 Train loss 0.20 Classification-F1 0.629584256889319 on epoch=6
06/13/2022 13:19:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=6
06/13/2022 13:19:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.16 on epoch=6
06/13/2022 13:19:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.21 on epoch=6
06/13/2022 13:19:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=6
06/13/2022 13:19:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.16 on epoch=7
06/13/2022 13:19:46 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.8302973858616838 on epoch=7
06/13/2022 13:19:46 - INFO - __main__ - Saving model with best Classification-F1: 0.805217551166548 -> 0.8302973858616838 on epoch=7, global_step=400
06/13/2022 13:19:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=7
06/13/2022 13:19:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=7
06/13/2022 13:19:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.14 on epoch=7
06/13/2022 13:19:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.26 on epoch=7
06/13/2022 13:19:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.13 on epoch=8
06/13/2022 13:20:26 - INFO - __main__ - Global step 450 Train loss 0.19 Classification-F1 0.6088669054680145 on epoch=8
06/13/2022 13:20:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=8
06/13/2022 13:20:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=8
06/13/2022 13:20:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=8
06/13/2022 13:20:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.13 on epoch=8
06/13/2022 13:20:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=8
06/13/2022 13:21:08 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.791070942497502 on epoch=8
06/13/2022 13:21:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=9
06/13/2022 13:21:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=9
06/13/2022 13:21:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=9
06/13/2022 13:21:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=9
06/13/2022 13:21:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=9
06/13/2022 13:21:52 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.9120874530568809 on epoch=9
06/13/2022 13:21:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8302973858616838 -> 0.9120874530568809 on epoch=9, global_step=550
06/13/2022 13:21:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=9
06/13/2022 13:21:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=10
06/13/2022 13:22:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=10
06/13/2022 13:22:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=10
06/13/2022 13:22:05 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=10
06/13/2022 13:22:36 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.9118231259108095 on epoch=10
06/13/2022 13:22:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=10
06/13/2022 13:22:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=11
06/13/2022 13:22:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=11
06/13/2022 13:22:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=11
06/13/2022 13:22:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=11
06/13/2022 13:23:16 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.6600626992330156 on epoch=11
06/13/2022 13:23:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=11
06/13/2022 13:23:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=11
06/13/2022 13:23:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=12
06/13/2022 13:23:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=12
06/13/2022 13:23:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=12
06/13/2022 13:23:54 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.7047973665009566 on epoch=12
06/13/2022 13:23:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=12
06/13/2022 13:23:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=12
06/13/2022 13:24:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=13
06/13/2022 13:24:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=13
06/13/2022 13:24:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=13
06/13/2022 13:24:36 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.9076926780405238 on epoch=13
06/13/2022 13:24:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=13
06/13/2022 13:24:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=13
06/13/2022 13:24:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=13
06/13/2022 13:24:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=14
06/13/2022 13:24:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=14
06/13/2022 13:25:20 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.982178647913809 on epoch=14
06/13/2022 13:25:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9120874530568809 -> 0.982178647913809 on epoch=14, global_step=800
06/13/2022 13:25:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=14
06/13/2022 13:25:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=14
06/13/2022 13:25:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=14
06/13/2022 13:25:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=14
06/13/2022 13:25:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=15
06/13/2022 13:26:00 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.8585414376835219 on epoch=15
06/13/2022 13:26:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=15
06/13/2022 13:26:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=15
06/13/2022 13:26:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=15
06/13/2022 13:26:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=15
06/13/2022 13:26:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=16
06/13/2022 13:26:42 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.8540154000910417 on epoch=16
06/13/2022 13:26:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=16
06/13/2022 13:26:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=16
06/13/2022 13:26:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=16
06/13/2022 13:26:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=16
06/13/2022 13:26:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=16
06/13/2022 13:27:21 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.859238350086623 on epoch=16
06/13/2022 13:27:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=17
06/13/2022 13:27:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=17
06/13/2022 13:27:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=17
06/13/2022 13:27:32 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=17
06/13/2022 13:27:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=17
06/13/2022 13:28:02 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.8057055331841197 on epoch=17
06/13/2022 13:28:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=18
06/13/2022 13:28:08 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=18
06/13/2022 13:28:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=18
06/13/2022 13:28:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=18
06/13/2022 13:28:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=18
06/13/2022 13:28:42 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9218576995947212 on epoch=18
06/13/2022 13:28:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=18
06/13/2022 13:28:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=19
06/13/2022 13:28:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=19
06/13/2022 13:28:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=19
06/13/2022 13:28:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=19
06/13/2022 13:29:22 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8104800517032992 on epoch=19
06/13/2022 13:29:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=19
06/13/2022 13:29:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=19
06/13/2022 13:29:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=20
06/13/2022 13:29:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=20
06/13/2022 13:29:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=20
06/13/2022 13:30:02 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.8578064049390411 on epoch=20
06/13/2022 13:30:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=20
06/13/2022 13:30:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=20
06/13/2022 13:30:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=21
06/13/2022 13:30:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=21
06/13/2022 13:30:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=21
06/13/2022 13:30:39 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8618029444891755 on epoch=21
06/13/2022 13:30:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=21
06/13/2022 13:30:45 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
06/13/2022 13:30:47 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=21
06/13/2022 13:30:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
06/13/2022 13:30:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=22
06/13/2022 13:31:18 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8632257288277247 on epoch=22
06/13/2022 13:31:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=22
06/13/2022 13:31:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=22
06/13/2022 13:31:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=22
06/13/2022 13:31:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=23
06/13/2022 13:31:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=23
06/13/2022 13:31:56 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7610405023229341 on epoch=23
06/13/2022 13:31:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=23
06/13/2022 13:32:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=23
06/13/2022 13:32:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=23
06/13/2022 13:32:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=23
06/13/2022 13:32:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=24
06/13/2022 13:32:32 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.9176814311819076 on epoch=24
06/13/2022 13:32:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=24
06/13/2022 13:32:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=24
06/13/2022 13:32:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=24
06/13/2022 13:32:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
06/13/2022 13:32:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=24
06/13/2022 13:33:11 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.8642415933700511 on epoch=24
06/13/2022 13:33:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
06/13/2022 13:33:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=25
06/13/2022 13:33:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=25
06/13/2022 13:33:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
06/13/2022 13:33:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=25
06/13/2022 13:33:50 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8607628439680143 on epoch=25
06/13/2022 13:33:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
06/13/2022 13:33:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=26
06/13/2022 13:33:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=26
06/13/2022 13:34:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=26
06/13/2022 13:34:03 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=26
06/13/2022 13:34:27 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8581096321542334 on epoch=26
06/13/2022 13:34:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=26
06/13/2022 13:34:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=27
06/13/2022 13:34:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=27
06/13/2022 13:34:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=27
06/13/2022 13:34:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=27
06/13/2022 13:35:04 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.922890961158925 on epoch=27
06/13/2022 13:35:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=27
06/13/2022 13:35:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=28
06/13/2022 13:35:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=28
06/13/2022 13:35:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=28
06/13/2022 13:35:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=28
06/13/2022 13:35:42 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8073550622824229 on epoch=28
06/13/2022 13:35:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=28
06/13/2022 13:35:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=28
06/13/2022 13:35:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
06/13/2022 13:35:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=29
06/13/2022 13:35:55 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=29
06/13/2022 13:36:20 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8622185134743332 on epoch=29
06/13/2022 13:36:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=29
06/13/2022 13:36:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=29
06/13/2022 13:36:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=29
06/13/2022 13:36:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=30
06/13/2022 13:36:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
06/13/2022 13:36:58 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7238316992043895 on epoch=30
06/13/2022 13:37:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=30
06/13/2022 13:37:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=30
06/13/2022 13:37:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=30
06/13/2022 13:37:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=31
06/13/2022 13:37:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=31
06/13/2022 13:37:34 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9186821597840791 on epoch=31
06/13/2022 13:37:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=31
06/13/2022 13:37:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=31
06/13/2022 13:37:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=31
06/13/2022 13:37:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=31
06/13/2022 13:37:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=32
06/13/2022 13:38:11 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.8652398181397856 on epoch=32
06/13/2022 13:38:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=32
06/13/2022 13:38:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
06/13/2022 13:38:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=32
06/13/2022 13:38:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
06/13/2022 13:38:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
06/13/2022 13:38:48 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9888390813430298 on epoch=33
06/13/2022 13:38:48 - INFO - __main__ - Saving model with best Classification-F1: 0.982178647913809 -> 0.9888390813430298 on epoch=33, global_step=1850
06/13/2022 13:38:50 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
06/13/2022 13:38:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=33
06/13/2022 13:38:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=33
06/13/2022 13:38:58 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=33
06/13/2022 13:39:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
06/13/2022 13:39:25 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9202899416232779 on epoch=33
06/13/2022 13:39:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=34
06/13/2022 13:39:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=34
06/13/2022 13:39:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
06/13/2022 13:39:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=34
06/13/2022 13:39:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=34
06/13/2022 13:40:02 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9202977590122343 on epoch=34
06/13/2022 13:40:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=34
06/13/2022 13:40:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=35
06/13/2022 13:40:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=35
06/13/2022 13:40:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
06/13/2022 13:40:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=35
06/13/2022 13:40:39 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8599989602173096 on epoch=35
06/13/2022 13:40:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
06/13/2022 13:40:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=36
06/13/2022 13:40:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=36
06/13/2022 13:40:49 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=36
06/13/2022 13:40:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=36
06/13/2022 13:41:18 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.9888362190472073 on epoch=36
06/13/2022 13:41:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=36
06/13/2022 13:41:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
06/13/2022 13:41:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
06/13/2022 13:41:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=37
06/13/2022 13:41:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=37
06/13/2022 13:41:55 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.85911195803441 on epoch=37
06/13/2022 13:41:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
06/13/2022 13:42:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=37
06/13/2022 13:42:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=38
06/13/2022 13:42:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=38
06/13/2022 13:42:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=38
06/13/2022 13:42:32 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.921854764468288 on epoch=38
06/13/2022 13:42:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
06/13/2022 13:42:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
06/13/2022 13:42:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
06/13/2022 13:42:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=39
06/13/2022 13:42:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
06/13/2022 13:43:10 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9854154771799933 on epoch=39
06/13/2022 13:43:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=39
06/13/2022 13:43:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=39
06/13/2022 13:43:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
06/13/2022 13:43:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
06/13/2022 13:43:22 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
06/13/2022 13:43:47 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9843189102381693 on epoch=40
06/13/2022 13:43:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=40
06/13/2022 13:43:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=40
06/13/2022 13:43:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=40
06/13/2022 13:43:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=40
06/13/2022 13:44:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=41
06/13/2022 13:44:24 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9888456884483616 on epoch=41
06/13/2022 13:44:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9888390813430298 -> 0.9888456884483616 on epoch=41, global_step=2300
06/13/2022 13:44:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=41
06/13/2022 13:44:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=41
06/13/2022 13:44:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=41
06/13/2022 13:44:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=41
06/13/2022 13:44:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=41
06/13/2022 13:45:01 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9161283951462734 on epoch=41
06/13/2022 13:45:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
06/13/2022 13:45:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=42
06/13/2022 13:45:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
06/13/2022 13:45:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
06/13/2022 13:45:14 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
06/13/2022 13:45:38 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.919220763028834 on epoch=42
06/13/2022 13:45:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
06/13/2022 13:45:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
06/13/2022 13:45:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
06/13/2022 13:45:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=43
06/13/2022 13:45:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
06/13/2022 13:46:14 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9186715781135077 on epoch=43
06/13/2022 13:46:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
06/13/2022 13:46:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
06/13/2022 13:46:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=44
06/13/2022 13:46:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=44
06/13/2022 13:46:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
06/13/2022 13:46:51 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.859659906659952 on epoch=44
06/13/2022 13:46:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
06/13/2022 13:46:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
06/13/2022 13:46:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=45
06/13/2022 13:47:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=45
06/13/2022 13:47:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
06/13/2022 13:47:27 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8036264181358451 on epoch=45
06/13/2022 13:47:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
06/13/2022 13:47:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=45
06/13/2022 13:47:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
06/13/2022 13:47:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=46
06/13/2022 13:47:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
06/13/2022 13:48:04 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8593556232902382 on epoch=46
06/13/2022 13:48:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=46
06/13/2022 13:48:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
06/13/2022 13:48:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=46
06/13/2022 13:48:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
06/13/2022 13:48:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=47
06/13/2022 13:48:41 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9223902666795453 on epoch=47
06/13/2022 13:48:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
06/13/2022 13:48:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
06/13/2022 13:48:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=47
06/13/2022 13:48:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=48
06/13/2022 13:48:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
06/13/2022 13:49:18 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9207631392725013 on epoch=48
06/13/2022 13:49:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
06/13/2022 13:49:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
06/13/2022 13:49:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=48
06/13/2022 13:49:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=48
06/13/2022 13:49:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
06/13/2022 13:49:55 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8479005753589444 on epoch=49
06/13/2022 13:49:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=49
06/13/2022 13:50:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=49
06/13/2022 13:50:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=49
06/13/2022 13:50:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
06/13/2022 13:50:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 13:50:31 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.854506969739333 on epoch=49
06/13/2022 13:50:34 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
06/13/2022 13:50:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
06/13/2022 13:50:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
06/13/2022 13:50:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=50
06/13/2022 13:50:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
06/13/2022 13:51:08 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8636944592915907 on epoch=50
06/13/2022 13:51:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 13:51:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
06/13/2022 13:51:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
06/13/2022 13:51:19 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
06/13/2022 13:51:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 13:51:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9899549484003453 on epoch=51
06/13/2022 13:51:45 - INFO - __main__ - Saving model with best Classification-F1: 0.9888456884483616 -> 0.9899549484003453 on epoch=51, global_step=2900
06/13/2022 13:51:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
06/13/2022 13:51:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=52
06/13/2022 13:51:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
06/13/2022 13:51:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
06/13/2022 13:51:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=52
06/13/2022 13:52:22 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9200623545435622 on epoch=52
06/13/2022 13:52:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
06/13/2022 13:52:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=53
06/13/2022 13:52:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
06/13/2022 13:52:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
06/13/2022 13:52:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 13:52:36 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:52:36 - INFO - __main__ - Printing 3 examples
06/13/2022 13:52:36 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 13:52:36 - INFO - __main__ - ['Film']
06/13/2022 13:52:36 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 13:52:36 - INFO - __main__ - ['Film']
06/13/2022 13:52:36 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 13:52:36 - INFO - __main__ - ['Film']
06/13/2022 13:52:36 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:52:36 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:52:37 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 13:52:37 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:52:37 - INFO - __main__ - Printing 3 examples
06/13/2022 13:52:37 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 13:52:37 - INFO - __main__ - ['Film']
06/13/2022 13:52:37 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 13:52:37 - INFO - __main__ - ['Film']
06/13/2022 13:52:37 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 13:52:37 - INFO - __main__ - ['Film']
06/13/2022 13:52:37 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:52:38 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:52:38 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 13:52:54 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 13:52:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 13:52:55 - INFO - __main__ - Starting training!
06/13/2022 13:52:57 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8610977509079534 on epoch=53
06/13/2022 13:52:57 - INFO - __main__ - save last model!
06/13/2022 13:52:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 13:52:57 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 13:52:57 - INFO - __main__ - Printing 3 examples
06/13/2022 13:52:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 13:52:57 - INFO - __main__ - ['Animal']
06/13/2022 13:52:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 13:52:57 - INFO - __main__ - ['Animal']
06/13/2022 13:52:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 13:52:57 - INFO - __main__ - ['Village']
06/13/2022 13:52:57 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:52:59 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:53:03 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 13:55:09 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.5_8_predictions.txt
06/13/2022 13:55:09 - INFO - __main__ - Classification-F1 on test data: 0.6530
06/13/2022 13:55:09 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.5, bsz=8, dev_performance=0.9899549484003453, test_performance=0.65303527702215
06/13/2022 13:55:09 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.4, bsz=8 ...
06/13/2022 13:55:10 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:55:10 - INFO - __main__ - Printing 3 examples
06/13/2022 13:55:10 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 13:55:10 - INFO - __main__ - ['Film']
06/13/2022 13:55:10 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 13:55:10 - INFO - __main__ - ['Film']
06/13/2022 13:55:10 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 13:55:10 - INFO - __main__ - ['Film']
06/13/2022 13:55:10 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:55:11 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:55:12 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 13:55:12 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 13:55:12 - INFO - __main__ - Printing 3 examples
06/13/2022 13:55:12 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 13:55:12 - INFO - __main__ - ['Film']
06/13/2022 13:55:12 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 13:55:12 - INFO - __main__ - ['Film']
06/13/2022 13:55:12 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 13:55:12 - INFO - __main__ - ['Film']
06/13/2022 13:55:12 - INFO - __main__ - Tokenizing Input ...
06/13/2022 13:55:12 - INFO - __main__ - Tokenizing Output ...
06/13/2022 13:55:13 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 13:55:28 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 13:55:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 13:55:29 - INFO - __main__ - Starting training!
06/13/2022 13:55:32 - INFO - __main__ - Step 10 Global step 10 Train loss 4.47 on epoch=0
06/13/2022 13:55:35 - INFO - __main__ - Step 20 Global step 20 Train loss 3.05 on epoch=0
06/13/2022 13:55:38 - INFO - __main__ - Step 30 Global step 30 Train loss 2.14 on epoch=0
06/13/2022 13:55:40 - INFO - __main__ - Step 40 Global step 40 Train loss 1.60 on epoch=0
06/13/2022 13:55:43 - INFO - __main__ - Step 50 Global step 50 Train loss 1.31 on epoch=0
06/13/2022 13:56:11 - INFO - __main__ - Global step 50 Train loss 2.51 Classification-F1 0.11382585432283547 on epoch=0
06/13/2022 13:56:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11382585432283547 on epoch=0, global_step=50
06/13/2022 13:56:14 - INFO - __main__ - Step 60 Global step 60 Train loss 1.01 on epoch=1
06/13/2022 13:56:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.85 on epoch=1
06/13/2022 13:56:19 - INFO - __main__ - Step 80 Global step 80 Train loss 0.87 on epoch=1
06/13/2022 13:56:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=1
06/13/2022 13:56:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.77 on epoch=1
06/13/2022 13:56:51 - INFO - __main__ - Global step 100 Train loss 0.85 Classification-F1 0.4044446062836939 on epoch=1
06/13/2022 13:56:51 - INFO - __main__ - Saving model with best Classification-F1: 0.11382585432283547 -> 0.4044446062836939 on epoch=1, global_step=100
06/13/2022 13:56:54 - INFO - __main__ - Step 110 Global step 110 Train loss 0.59 on epoch=1
06/13/2022 13:56:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.58 on epoch=2
06/13/2022 13:56:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.50 on epoch=2
06/13/2022 13:57:01 - INFO - __main__ - Step 140 Global step 140 Train loss 0.49 on epoch=2
06/13/2022 13:57:04 - INFO - __main__ - Step 150 Global step 150 Train loss 0.50 on epoch=2
06/13/2022 13:57:32 - INFO - __main__ - Global step 150 Train loss 0.53 Classification-F1 0.4870606552629653 on epoch=2
06/13/2022 13:57:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4044446062836939 -> 0.4870606552629653 on epoch=2, global_step=150
06/13/2022 13:57:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.49 on epoch=2
06/13/2022 13:57:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.53 on epoch=3
06/13/2022 13:57:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=3
06/13/2022 13:57:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.46 on epoch=3
06/13/2022 13:57:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.42 on epoch=3
06/13/2022 13:58:14 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.5282923931026652 on epoch=3
06/13/2022 13:58:14 - INFO - __main__ - Saving model with best Classification-F1: 0.4870606552629653 -> 0.5282923931026652 on epoch=3, global_step=200
06/13/2022 13:58:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=3
06/13/2022 13:58:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.29 on epoch=3
06/13/2022 13:58:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.34 on epoch=4
06/13/2022 13:58:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.33 on epoch=4
06/13/2022 13:58:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.34 on epoch=4
06/13/2022 13:58:55 - INFO - __main__ - Global step 250 Train loss 0.33 Classification-F1 0.6193389349773274 on epoch=4
06/13/2022 13:58:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5282923931026652 -> 0.6193389349773274 on epoch=4, global_step=250
06/13/2022 13:58:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.35 on epoch=4
06/13/2022 13:59:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=4
06/13/2022 13:59:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=4
06/13/2022 13:59:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=5
06/13/2022 13:59:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=5
06/13/2022 13:59:39 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.5399039764073025 on epoch=5
06/13/2022 13:59:42 - INFO - __main__ - Step 310 Global step 310 Train loss 0.29 on epoch=5
06/13/2022 13:59:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=5
06/13/2022 13:59:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=5
06/13/2022 13:59:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=6
06/13/2022 13:59:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.21 on epoch=6
06/13/2022 14:00:20 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.44073865650077604 on epoch=6
06/13/2022 14:00:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=6
06/13/2022 14:00:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=6
06/13/2022 14:00:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=6
06/13/2022 14:00:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=6
06/13/2022 14:00:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.18 on epoch=7
06/13/2022 14:00:59 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.3889381682460026 on epoch=7
06/13/2022 14:01:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=7
06/13/2022 14:01:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=7
06/13/2022 14:01:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=7
06/13/2022 14:01:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=7
06/13/2022 14:01:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=8
06/13/2022 14:01:38 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.5041241982452047 on epoch=8
06/13/2022 14:01:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.14 on epoch=8
06/13/2022 14:01:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=8
06/13/2022 14:01:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.18 on epoch=8
06/13/2022 14:01:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=8
06/13/2022 14:01:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=8
06/13/2022 14:02:20 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.6536355617271686 on epoch=8
06/13/2022 14:02:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6193389349773274 -> 0.6536355617271686 on epoch=8, global_step=500
06/13/2022 14:02:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=9
06/13/2022 14:02:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=9
06/13/2022 14:02:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=9
06/13/2022 14:02:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=9
06/13/2022 14:02:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=9
06/13/2022 14:03:00 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.5465340309606171 on epoch=9
06/13/2022 14:03:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=9
06/13/2022 14:03:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=10
06/13/2022 14:03:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=10
06/13/2022 14:03:10 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=10
06/13/2022 14:03:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=10
06/13/2022 14:03:40 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.6912250142029799 on epoch=10
06/13/2022 14:03:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6536355617271686 -> 0.6912250142029799 on epoch=10, global_step=600
06/13/2022 14:03:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=10
06/13/2022 14:03:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=11
06/13/2022 14:03:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=11
06/13/2022 14:03:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=11
06/13/2022 14:03:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=11
06/13/2022 14:04:23 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.907068621862794 on epoch=11
06/13/2022 14:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6912250142029799 -> 0.907068621862794 on epoch=11, global_step=650
06/13/2022 14:04:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=11
06/13/2022 14:04:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=11
06/13/2022 14:04:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=12
06/13/2022 14:04:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=12
06/13/2022 14:04:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=12
06/13/2022 14:05:03 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.8441646228253394 on epoch=12
06/13/2022 14:05:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.07 on epoch=12
06/13/2022 14:05:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
06/13/2022 14:05:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=13
06/13/2022 14:05:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=13
06/13/2022 14:05:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=13
06/13/2022 14:05:41 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7160048496123763 on epoch=13
06/13/2022 14:05:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=13
06/13/2022 14:05:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=13
06/13/2022 14:05:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=13
06/13/2022 14:05:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=14
06/13/2022 14:05:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=14
06/13/2022 14:06:19 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.7599451500407803 on epoch=14
06/13/2022 14:06:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=14
06/13/2022 14:06:25 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=14
06/13/2022 14:06:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=14
06/13/2022 14:06:30 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=14
06/13/2022 14:06:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=15
06/13/2022 14:06:56 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.916669917246277 on epoch=15
06/13/2022 14:06:56 - INFO - __main__ - Saving model with best Classification-F1: 0.907068621862794 -> 0.916669917246277 on epoch=15, global_step=850
06/13/2022 14:06:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=15
06/13/2022 14:07:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=15
06/13/2022 14:07:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=15
06/13/2022 14:07:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=15
06/13/2022 14:07:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=16
06/13/2022 14:07:34 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.863287522412125 on epoch=16
06/13/2022 14:07:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=16
06/13/2022 14:07:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
06/13/2022 14:07:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=16
06/13/2022 14:07:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=16
06/13/2022 14:07:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=16
06/13/2022 14:08:13 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.7526397980198877 on epoch=16
06/13/2022 14:08:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=17
06/13/2022 14:08:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=17
06/13/2022 14:08:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=17
06/13/2022 14:08:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=17
06/13/2022 14:08:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=17
06/13/2022 14:08:51 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.8010318196506084 on epoch=17
06/13/2022 14:08:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=18
06/13/2022 14:08:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=18
06/13/2022 14:08:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=18
06/13/2022 14:09:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=18
06/13/2022 14:09:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=18
06/13/2022 14:09:29 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.7522159807063152 on epoch=18
06/13/2022 14:09:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=18
06/13/2022 14:09:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=19
06/13/2022 14:09:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=19
06/13/2022 14:09:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=19
06/13/2022 14:09:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=19
06/13/2022 14:10:08 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.806509012225615 on epoch=19
06/13/2022 14:10:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=19
06/13/2022 14:10:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=19
06/13/2022 14:10:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=20
06/13/2022 14:10:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=20
06/13/2022 14:10:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=20
06/13/2022 14:10:44 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6629544805861244 on epoch=20
06/13/2022 14:10:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=20
06/13/2022 14:10:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
06/13/2022 14:10:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=21
06/13/2022 14:10:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=21
06/13/2022 14:10:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
06/13/2022 14:11:21 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.9866819642650944 on epoch=21
06/13/2022 14:11:21 - INFO - __main__ - Saving model with best Classification-F1: 0.916669917246277 -> 0.9866819642650944 on epoch=21, global_step=1200
06/13/2022 14:11:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=21
06/13/2022 14:11:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
06/13/2022 14:11:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=21
06/13/2022 14:11:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
06/13/2022 14:11:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=22
06/13/2022 14:11:57 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.6325259687688796 on epoch=22
06/13/2022 14:12:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=22
06/13/2022 14:12:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=22
06/13/2022 14:12:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=22
06/13/2022 14:12:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
06/13/2022 14:12:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=23
06/13/2022 14:12:34 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7224928093797146 on epoch=23
06/13/2022 14:12:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=23
06/13/2022 14:12:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=23
06/13/2022 14:12:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
06/13/2022 14:12:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=23
06/13/2022 14:12:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=24
06/13/2022 14:13:11 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.5844063350999819 on epoch=24
06/13/2022 14:13:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=24
06/13/2022 14:13:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=24
06/13/2022 14:13:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=24
06/13/2022 14:13:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=24
06/13/2022 14:13:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=24
06/13/2022 14:13:48 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.8622797538958542 on epoch=24
06/13/2022 14:13:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=25
06/13/2022 14:13:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=25
06/13/2022 14:13:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=25
06/13/2022 14:13:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=25
06/13/2022 14:14:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=25
06/13/2022 14:14:25 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8098505521707574 on epoch=25
06/13/2022 14:14:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=26
06/13/2022 14:14:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=26
06/13/2022 14:14:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=26
06/13/2022 14:14:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=26
06/13/2022 14:14:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
06/13/2022 14:15:02 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8628009418337177 on epoch=26
06/13/2022 14:15:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=26
06/13/2022 14:15:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=27
06/13/2022 14:15:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
06/13/2022 14:15:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=27
06/13/2022 14:15:15 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=27
06/13/2022 14:15:38 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9076204180652323 on epoch=27
06/13/2022 14:15:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=27
06/13/2022 14:15:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
06/13/2022 14:15:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
06/13/2022 14:15:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
06/13/2022 14:15:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=28
06/13/2022 14:16:14 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8603025662395651 on epoch=28
06/13/2022 14:16:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=28
06/13/2022 14:16:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
06/13/2022 14:16:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
06/13/2022 14:16:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=29
06/13/2022 14:16:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=29
06/13/2022 14:16:50 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9202972799908032 on epoch=29
06/13/2022 14:16:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
06/13/2022 14:16:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=29
06/13/2022 14:16:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=29
06/13/2022 14:17:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=30
06/13/2022 14:17:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=30
06/13/2022 14:17:26 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.987713881331694 on epoch=30
06/13/2022 14:17:26 - INFO - __main__ - Saving model with best Classification-F1: 0.9866819642650944 -> 0.987713881331694 on epoch=30, global_step=1700
06/13/2022 14:17:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=30
06/13/2022 14:17:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=30
06/13/2022 14:17:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=30
06/13/2022 14:17:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
06/13/2022 14:17:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=31
06/13/2022 14:18:02 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9213496841237868 on epoch=31
06/13/2022 14:18:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=31
06/13/2022 14:18:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=31
06/13/2022 14:18:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
06/13/2022 14:18:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=31
06/13/2022 14:18:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
06/13/2022 14:18:38 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9192878862712226 on epoch=32
06/13/2022 14:18:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=32
06/13/2022 14:18:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=32
06/13/2022 14:18:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
06/13/2022 14:18:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
06/13/2022 14:18:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
06/13/2022 14:19:14 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9182464831132842 on epoch=33
06/13/2022 14:19:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=33
06/13/2022 14:19:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=33
06/13/2022 14:19:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=33
06/13/2022 14:19:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
06/13/2022 14:19:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=33
06/13/2022 14:19:50 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9877228055432025 on epoch=33
06/13/2022 14:19:50 - INFO - __main__ - Saving model with best Classification-F1: 0.987713881331694 -> 0.9877228055432025 on epoch=33, global_step=1900
06/13/2022 14:19:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=34
06/13/2022 14:19:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
06/13/2022 14:19:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
06/13/2022 14:20:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=34
06/13/2022 14:20:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=34
06/13/2022 14:20:25 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.918273260900527 on epoch=34
06/13/2022 14:20:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=34
06/13/2022 14:20:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=35
06/13/2022 14:20:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=35
06/13/2022 14:20:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
06/13/2022 14:20:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=35
06/13/2022 14:21:02 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9208640551658085 on epoch=35
06/13/2022 14:21:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=35
06/13/2022 14:21:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
06/13/2022 14:21:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=36
06/13/2022 14:21:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
06/13/2022 14:21:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=36
06/13/2022 14:21:40 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9866055758112174 on epoch=36
06/13/2022 14:21:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
06/13/2022 14:21:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
06/13/2022 14:21:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=37
06/13/2022 14:21:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=37
06/13/2022 14:21:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
06/13/2022 14:22:19 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.9843377295202494 on epoch=37
06/13/2022 14:22:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=37
06/13/2022 14:22:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=37
06/13/2022 14:22:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
06/13/2022 14:22:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
06/13/2022 14:22:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
06/13/2022 14:22:56 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.919256240853018 on epoch=38
06/13/2022 14:22:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
06/13/2022 14:23:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
06/13/2022 14:23:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=38
06/13/2022 14:23:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=39
06/13/2022 14:23:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
06/13/2022 14:23:38 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9810866884986418 on epoch=39
06/13/2022 14:23:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=39
06/13/2022 14:23:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=39
06/13/2022 14:23:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=39
06/13/2022 14:23:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
06/13/2022 14:23:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
06/13/2022 14:24:15 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9202910349626839 on epoch=40
06/13/2022 14:24:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
06/13/2022 14:24:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
06/13/2022 14:24:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=40
06/13/2022 14:24:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=40
06/13/2022 14:24:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 14:24:51 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9888650364925314 on epoch=41
06/13/2022 14:24:51 - INFO - __main__ - Saving model with best Classification-F1: 0.9877228055432025 -> 0.9888650364925314 on epoch=41, global_step=2300
06/13/2022 14:24:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
06/13/2022 14:24:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=41
06/13/2022 14:24:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
06/13/2022 14:25:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
06/13/2022 14:25:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
06/13/2022 14:25:27 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9866403870484756 on epoch=41
06/13/2022 14:25:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
06/13/2022 14:25:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
06/13/2022 14:25:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 14:25:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=42
06/13/2022 14:25:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
06/13/2022 14:26:04 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9171947779217547 on epoch=42
06/13/2022 14:26:07 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
06/13/2022 14:26:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=43
06/13/2022 14:26:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=43
06/13/2022 14:26:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
06/13/2022 14:26:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
06/13/2022 14:26:40 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.862317928617599 on epoch=43
06/13/2022 14:26:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=43
06/13/2022 14:26:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
06/13/2022 14:26:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=44
06/13/2022 14:26:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=44
06/13/2022 14:26:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
06/13/2022 14:27:17 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9833000319076104 on epoch=44
06/13/2022 14:27:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=44
06/13/2022 14:27:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=44
06/13/2022 14:27:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 14:27:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
06/13/2022 14:27:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=45
06/13/2022 14:27:52 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8618190531416131 on epoch=45
06/13/2022 14:27:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
06/13/2022 14:27:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=45
06/13/2022 14:28:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=46
06/13/2022 14:28:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
06/13/2022 14:28:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
06/13/2022 14:28:28 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.923957821648263 on epoch=46
06/13/2022 14:28:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
06/13/2022 14:28:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=46
06/13/2022 14:28:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
06/13/2022 14:28:38 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
06/13/2022 14:28:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
06/13/2022 14:29:05 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8608067462245372 on epoch=47
06/13/2022 14:29:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
06/13/2022 14:29:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
06/13/2022 14:29:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
06/13/2022 14:29:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
06/13/2022 14:29:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.09 on epoch=48
06/13/2022 14:29:43 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.987744923518788 on epoch=48
06/13/2022 14:29:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=48
06/13/2022 14:29:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
06/13/2022 14:29:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
06/13/2022 14:29:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=48
06/13/2022 14:29:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=49
06/13/2022 14:30:18 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9832890729207968 on epoch=49
06/13/2022 14:30:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
06/13/2022 14:30:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
06/13/2022 14:30:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
06/13/2022 14:30:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
06/13/2022 14:30:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
06/13/2022 14:30:54 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9855065352208242 on epoch=49
06/13/2022 14:30:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
06/13/2022 14:30:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
06/13/2022 14:31:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
06/13/2022 14:31:05 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
06/13/2022 14:31:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
06/13/2022 14:31:32 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9854461681440567 on epoch=50
06/13/2022 14:31:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
06/13/2022 14:31:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=51
06/13/2022 14:31:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
06/13/2022 14:31:42 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=51
06/13/2022 14:31:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
06/13/2022 14:32:10 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9866408021791487 on epoch=51
06/13/2022 14:32:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
06/13/2022 14:32:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=52
06/13/2022 14:32:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=52
06/13/2022 14:32:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
06/13/2022 14:32:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=52
06/13/2022 14:32:47 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9877488969402081 on epoch=52
06/13/2022 14:32:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=52
06/13/2022 14:32:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
06/13/2022 14:32:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=53
06/13/2022 14:32:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
06/13/2022 14:33:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 14:33:01 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 14:33:01 - INFO - __main__ - Printing 3 examples
06/13/2022 14:33:01 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 14:33:01 - INFO - __main__ - ['Film']
06/13/2022 14:33:01 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 14:33:01 - INFO - __main__ - ['Film']
06/13/2022 14:33:01 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 14:33:01 - INFO - __main__ - ['Film']
06/13/2022 14:33:01 - INFO - __main__ - Tokenizing Input ...
06/13/2022 14:33:02 - INFO - __main__ - Tokenizing Output ...
06/13/2022 14:33:02 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 14:33:02 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 14:33:02 - INFO - __main__ - Printing 3 examples
06/13/2022 14:33:02 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 14:33:02 - INFO - __main__ - ['Film']
06/13/2022 14:33:02 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 14:33:02 - INFO - __main__ - ['Film']
06/13/2022 14:33:02 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 14:33:03 - INFO - __main__ - ['Film']
06/13/2022 14:33:03 - INFO - __main__ - Tokenizing Input ...
06/13/2022 14:33:03 - INFO - __main__ - Tokenizing Output ...
06/13/2022 14:33:04 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 14:33:19 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 14:33:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 14:33:20 - INFO - __main__ - Starting training!
06/13/2022 14:33:22 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9877403133474595 on epoch=53
06/13/2022 14:33:22 - INFO - __main__ - save last model!
06/13/2022 14:33:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 14:33:22 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 14:33:22 - INFO - __main__ - Printing 3 examples
06/13/2022 14:33:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 14:33:22 - INFO - __main__ - ['Animal']
06/13/2022 14:33:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 14:33:22 - INFO - __main__ - ['Animal']
06/13/2022 14:33:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 14:33:22 - INFO - __main__ - ['Village']
06/13/2022 14:33:22 - INFO - __main__ - Tokenizing Input ...
06/13/2022 14:33:24 - INFO - __main__ - Tokenizing Output ...
06/13/2022 14:33:28 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 14:35:33 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.4_8_predictions.txt
06/13/2022 14:35:33 - INFO - __main__ - Classification-F1 on test data: 0.7654
06/13/2022 14:35:33 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.4, bsz=8, dev_performance=0.9888650364925314, test_performance=0.7653873600812159
06/13/2022 14:35:33 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.3, bsz=8 ...
06/13/2022 14:35:34 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 14:35:34 - INFO - __main__ - Printing 3 examples
06/13/2022 14:35:34 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 14:35:34 - INFO - __main__ - ['Film']
06/13/2022 14:35:34 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 14:35:34 - INFO - __main__ - ['Film']
06/13/2022 14:35:34 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 14:35:34 - INFO - __main__ - ['Film']
06/13/2022 14:35:34 - INFO - __main__ - Tokenizing Input ...
06/13/2022 14:35:35 - INFO - __main__ - Tokenizing Output ...
06/13/2022 14:35:35 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 14:35:35 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 14:35:35 - INFO - __main__ - Printing 3 examples
06/13/2022 14:35:35 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 14:35:35 - INFO - __main__ - ['Film']
06/13/2022 14:35:35 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 14:35:35 - INFO - __main__ - ['Film']
06/13/2022 14:35:35 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 14:35:35 - INFO - __main__ - ['Film']
06/13/2022 14:35:35 - INFO - __main__ - Tokenizing Input ...
06/13/2022 14:35:36 - INFO - __main__ - Tokenizing Output ...
06/13/2022 14:35:37 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 14:35:52 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 14:35:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 14:35:53 - INFO - __main__ - Starting training!
06/13/2022 14:35:56 - INFO - __main__ - Step 10 Global step 10 Train loss 4.59 on epoch=0
06/13/2022 14:35:58 - INFO - __main__ - Step 20 Global step 20 Train loss 3.39 on epoch=0
06/13/2022 14:36:01 - INFO - __main__ - Step 30 Global step 30 Train loss 3.48 on epoch=0
06/13/2022 14:36:04 - INFO - __main__ - Step 40 Global step 40 Train loss 2.44 on epoch=0
06/13/2022 14:36:06 - INFO - __main__ - Step 50 Global step 50 Train loss 2.50 on epoch=0
06/13/2022 14:36:28 - INFO - __main__ - Global step 50 Train loss 3.28 Classification-F1 0.041673976800890966 on epoch=0
06/13/2022 14:36:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.041673976800890966 on epoch=0, global_step=50
06/13/2022 14:36:30 - INFO - __main__ - Step 60 Global step 60 Train loss 1.99 on epoch=1
06/13/2022 14:36:33 - INFO - __main__ - Step 70 Global step 70 Train loss 1.90 on epoch=1
06/13/2022 14:36:35 - INFO - __main__ - Step 80 Global step 80 Train loss 1.88 on epoch=1
06/13/2022 14:36:38 - INFO - __main__ - Step 90 Global step 90 Train loss 1.69 on epoch=1
06/13/2022 14:36:40 - INFO - __main__ - Step 100 Global step 100 Train loss 1.38 on epoch=1
06/13/2022 14:37:03 - INFO - __main__ - Global step 100 Train loss 1.77 Classification-F1 0.1812975157058917 on epoch=1
06/13/2022 14:37:03 - INFO - __main__ - Saving model with best Classification-F1: 0.041673976800890966 -> 0.1812975157058917 on epoch=1, global_step=100
06/13/2022 14:37:05 - INFO - __main__ - Step 110 Global step 110 Train loss 1.26 on epoch=1
06/13/2022 14:37:08 - INFO - __main__ - Step 120 Global step 120 Train loss 1.16 on epoch=2
06/13/2022 14:37:10 - INFO - __main__ - Step 130 Global step 130 Train loss 1.01 on epoch=2
06/13/2022 14:37:13 - INFO - __main__ - Step 140 Global step 140 Train loss 0.96 on epoch=2
06/13/2022 14:37:15 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=2
06/13/2022 14:37:41 - INFO - __main__ - Global step 150 Train loss 1.05 Classification-F1 0.3392095548343828 on epoch=2
06/13/2022 14:37:41 - INFO - __main__ - Saving model with best Classification-F1: 0.1812975157058917 -> 0.3392095548343828 on epoch=2, global_step=150
06/13/2022 14:37:43 - INFO - __main__ - Step 160 Global step 160 Train loss 0.86 on epoch=2
06/13/2022 14:37:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.84 on epoch=3
06/13/2022 14:37:48 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=3
06/13/2022 14:37:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=3
06/13/2022 14:37:53 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=3
06/13/2022 14:38:25 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.38995881875764254 on epoch=3
06/13/2022 14:38:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3392095548343828 -> 0.38995881875764254 on epoch=3, global_step=200
06/13/2022 14:38:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=3
06/13/2022 14:38:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=3
06/13/2022 14:38:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=4
06/13/2022 14:38:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=4
06/13/2022 14:38:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=4
06/13/2022 14:39:11 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.5215976126461219 on epoch=4
06/13/2022 14:39:11 - INFO - __main__ - Saving model with best Classification-F1: 0.38995881875764254 -> 0.5215976126461219 on epoch=4, global_step=250
06/13/2022 14:39:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=4
06/13/2022 14:39:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=4
06/13/2022 14:39:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=4
06/13/2022 14:39:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=5
06/13/2022 14:39:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=5
06/13/2022 14:39:53 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.4042134659514842 on epoch=5
06/13/2022 14:39:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=5
06/13/2022 14:39:58 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=5
06/13/2022 14:40:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=5
06/13/2022 14:40:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=6
06/13/2022 14:40:05 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=6
06/13/2022 14:40:37 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.6502695861033763 on epoch=6
06/13/2022 14:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5215976126461219 -> 0.6502695861033763 on epoch=6, global_step=350
06/13/2022 14:40:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=6
06/13/2022 14:40:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=6
06/13/2022 14:40:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=6
06/13/2022 14:40:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.38 on epoch=6
06/13/2022 14:40:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=7
06/13/2022 14:41:16 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.5933329833881954 on epoch=7
06/13/2022 14:41:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=7
06/13/2022 14:41:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=7
06/13/2022 14:41:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=7
06/13/2022 14:41:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=7
06/13/2022 14:41:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=8
06/13/2022 14:41:54 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.6360411052444125 on epoch=8
06/13/2022 14:41:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=8
06/13/2022 14:41:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=8
06/13/2022 14:42:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=8
06/13/2022 14:42:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=8
06/13/2022 14:42:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=8
06/13/2022 14:42:38 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.8738702392617037 on epoch=8
06/13/2022 14:42:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6502695861033763 -> 0.8738702392617037 on epoch=8, global_step=500
06/13/2022 14:42:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=9
06/13/2022 14:42:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=9
06/13/2022 14:42:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=9
06/13/2022 14:42:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=9
06/13/2022 14:42:50 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=9
06/13/2022 14:43:19 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.8119182111626229 on epoch=9
06/13/2022 14:43:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=9
06/13/2022 14:43:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=10
06/13/2022 14:43:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=10
06/13/2022 14:43:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=10
06/13/2022 14:43:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=10
06/13/2022 14:44:03 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7382675935053583 on epoch=10
06/13/2022 14:44:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=10
06/13/2022 14:44:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=11
06/13/2022 14:44:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=11
06/13/2022 14:44:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=11
06/13/2022 14:44:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=11
06/13/2022 14:44:45 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.7363710704453754 on epoch=11
06/13/2022 14:44:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=11
06/13/2022 14:44:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=11
06/13/2022 14:44:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=12
06/13/2022 14:44:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=12
06/13/2022 14:44:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=12
06/13/2022 14:45:27 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.7810411312850607 on epoch=12
06/13/2022 14:45:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=12
06/13/2022 14:45:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
06/13/2022 14:45:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=13
06/13/2022 14:45:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=13
06/13/2022 14:45:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=13
06/13/2022 14:46:09 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.732464179384518 on epoch=13
06/13/2022 14:46:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=13
06/13/2022 14:46:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=13
06/13/2022 14:46:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=13
06/13/2022 14:46:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=14
06/13/2022 14:46:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=14
06/13/2022 14:46:49 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.727826855050441 on epoch=14
06/13/2022 14:46:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=14
06/13/2022 14:46:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=14
06/13/2022 14:46:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=14
06/13/2022 14:46:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=14
06/13/2022 14:47:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=15
06/13/2022 14:47:28 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7412374000746009 on epoch=15
06/13/2022 14:47:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=15
06/13/2022 14:47:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=15
06/13/2022 14:47:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=15
06/13/2022 14:47:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=15
06/13/2022 14:47:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=16
06/13/2022 14:48:05 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7434618235476447 on epoch=16
06/13/2022 14:48:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=16
06/13/2022 14:48:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=16
06/13/2022 14:48:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=16
06/13/2022 14:48:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
06/13/2022 14:48:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=16
06/13/2022 14:48:43 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.6974551034733389 on epoch=16
06/13/2022 14:48:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=17
06/13/2022 14:48:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=17
06/13/2022 14:48:50 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=17
06/13/2022 14:48:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=17
06/13/2022 14:48:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=17
06/13/2022 14:49:20 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7871041233131162 on epoch=17
06/13/2022 14:49:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=18
06/13/2022 14:49:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=18
06/13/2022 14:49:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=18
06/13/2022 14:49:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=18
06/13/2022 14:49:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=18
06/13/2022 14:49:58 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.7491063169585894 on epoch=18
06/13/2022 14:50:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=18
06/13/2022 14:50:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=19
06/13/2022 14:50:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=19
06/13/2022 14:50:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=19
06/13/2022 14:50:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=19
06/13/2022 14:50:36 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.6985921174379105 on epoch=19
06/13/2022 14:50:38 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=19
06/13/2022 14:50:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=19
06/13/2022 14:50:43 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=20
06/13/2022 14:50:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=20
06/13/2022 14:50:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=20
06/13/2022 14:51:13 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7471275398201727 on epoch=20
06/13/2022 14:51:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=20
06/13/2022 14:51:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=20
06/13/2022 14:51:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=21
06/13/2022 14:51:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=21
06/13/2022 14:51:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=21
06/13/2022 14:51:50 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7790151740156057 on epoch=21
06/13/2022 14:51:53 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=21
06/13/2022 14:51:55 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
06/13/2022 14:51:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=21
06/13/2022 14:52:00 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
06/13/2022 14:52:03 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=22
06/13/2022 14:52:29 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7647430333812761 on epoch=22
06/13/2022 14:52:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=22
06/13/2022 14:52:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=22
06/13/2022 14:52:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=22
06/13/2022 14:52:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=23
06/13/2022 14:52:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
06/13/2022 14:53:05 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7422850627323965 on epoch=23
06/13/2022 14:53:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=23
06/13/2022 14:53:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=23
06/13/2022 14:53:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=23
06/13/2022 14:53:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=23
06/13/2022 14:53:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=24
06/13/2022 14:53:42 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7582530759181849 on epoch=24
06/13/2022 14:53:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=24
06/13/2022 14:53:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=24
06/13/2022 14:53:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=24
06/13/2022 14:53:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
06/13/2022 14:53:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=24
06/13/2022 14:54:18 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.7770488082821719 on epoch=24
06/13/2022 14:54:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
06/13/2022 14:54:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=25
06/13/2022 14:54:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
06/13/2022 14:54:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=25
06/13/2022 14:54:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=25
06/13/2022 14:54:55 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.8228998323414607 on epoch=25
06/13/2022 14:54:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=26
06/13/2022 14:55:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=26
06/13/2022 14:55:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=26
06/13/2022 14:55:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=26
06/13/2022 14:55:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=26
06/13/2022 14:55:32 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.8390509753712134 on epoch=26
06/13/2022 14:55:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=26
06/13/2022 14:55:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=27
06/13/2022 14:55:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=27
06/13/2022 14:55:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=27
06/13/2022 14:55:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=27
06/13/2022 14:56:09 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7772083949962535 on epoch=27
06/13/2022 14:56:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=27
06/13/2022 14:56:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
06/13/2022 14:56:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
06/13/2022 14:56:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=28
06/13/2022 14:56:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=28
06/13/2022 14:56:46 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7613659653547733 on epoch=28
06/13/2022 14:56:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=28
06/13/2022 14:56:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=28
06/13/2022 14:56:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=29
06/13/2022 14:56:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=29
06/13/2022 14:56:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
06/13/2022 14:57:22 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7700962757187554 on epoch=29
06/13/2022 14:57:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
06/13/2022 14:57:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=29
06/13/2022 14:57:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
06/13/2022 14:57:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=30
06/13/2022 14:57:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=30
06/13/2022 14:57:58 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7829738846877495 on epoch=30
06/13/2022 14:58:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=30
06/13/2022 14:58:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=30
06/13/2022 14:58:05 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
06/13/2022 14:58:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
06/13/2022 14:58:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=31
06/13/2022 14:58:34 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7629971080456542 on epoch=31
06/13/2022 14:58:36 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
06/13/2022 14:58:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
06/13/2022 14:58:41 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=31
06/13/2022 14:58:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=31
06/13/2022 14:58:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=32
06/13/2022 14:59:09 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7961157804470708 on epoch=32
06/13/2022 14:59:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=32
06/13/2022 14:59:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=32
06/13/2022 14:59:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
06/13/2022 14:59:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=32
06/13/2022 14:59:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
06/13/2022 14:59:45 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9072556437399778 on epoch=33
06/13/2022 14:59:45 - INFO - __main__ - Saving model with best Classification-F1: 0.8738702392617037 -> 0.9072556437399778 on epoch=33, global_step=1850
06/13/2022 14:59:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
06/13/2022 14:59:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.18 on epoch=33
06/13/2022 14:59:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
06/13/2022 14:59:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=33
06/13/2022 14:59:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
06/13/2022 15:00:21 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.9187219074430815 on epoch=33
06/13/2022 15:00:21 - INFO - __main__ - Saving model with best Classification-F1: 0.9072556437399778 -> 0.9187219074430815 on epoch=33, global_step=1900
06/13/2022 15:00:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
06/13/2022 15:00:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=34
06/13/2022 15:00:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
06/13/2022 15:00:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
06/13/2022 15:00:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=34
06/13/2022 15:00:57 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9187788162805137 on epoch=34
06/13/2022 15:00:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9187219074430815 -> 0.9187788162805137 on epoch=34, global_step=1950
06/13/2022 15:00:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
06/13/2022 15:01:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=35
06/13/2022 15:01:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
06/13/2022 15:01:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=35
06/13/2022 15:01:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
06/13/2022 15:01:33 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.920337669206226 on epoch=35
06/13/2022 15:01:33 - INFO - __main__ - Saving model with best Classification-F1: 0.9187788162805137 -> 0.920337669206226 on epoch=35, global_step=2000
06/13/2022 15:01:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
06/13/2022 15:01:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=36
06/13/2022 15:01:41 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=36
06/13/2022 15:01:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
06/13/2022 15:01:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
06/13/2022 15:02:09 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8607865862896908 on epoch=36
06/13/2022 15:02:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=36
06/13/2022 15:02:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=36
06/13/2022 15:02:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=37
06/13/2022 15:02:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=37
06/13/2022 15:02:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=37
06/13/2022 15:02:46 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.802377150276296 on epoch=37
06/13/2022 15:02:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
06/13/2022 15:02:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
06/13/2022 15:02:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=38
06/13/2022 15:02:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=38
06/13/2022 15:02:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=38
06/13/2022 15:03:23 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7545077249673874 on epoch=38
06/13/2022 15:03:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
06/13/2022 15:03:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
06/13/2022 15:03:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
06/13/2022 15:03:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
06/13/2022 15:03:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=39
06/13/2022 15:04:00 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.987765596691961 on epoch=39
06/13/2022 15:04:01 - INFO - __main__ - Saving model with best Classification-F1: 0.920337669206226 -> 0.987765596691961 on epoch=39, global_step=2200
06/13/2022 15:04:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=39
06/13/2022 15:04:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
06/13/2022 15:04:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=39
06/13/2022 15:04:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=39
06/13/2022 15:04:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=40
06/13/2022 15:04:37 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7613094683789154 on epoch=40
06/13/2022 15:04:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=40
06/13/2022 15:04:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
06/13/2022 15:04:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=40
06/13/2022 15:04:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=40
06/13/2022 15:04:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
06/13/2022 15:05:13 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.9034183530115227 on epoch=41
06/13/2022 15:05:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=41
06/13/2022 15:05:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=41
06/13/2022 15:05:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
06/13/2022 15:05:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=41
06/13/2022 15:05:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
06/13/2022 15:05:49 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.914075374480353 on epoch=41
06/13/2022 15:05:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
06/13/2022 15:05:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
06/13/2022 15:05:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=42
06/13/2022 15:05:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=42
06/13/2022 15:06:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=42
06/13/2022 15:06:26 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8568880787947475 on epoch=42
06/13/2022 15:06:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
06/13/2022 15:06:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
06/13/2022 15:06:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 15:06:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
06/13/2022 15:06:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
06/13/2022 15:07:02 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9162235526075518 on epoch=43
06/13/2022 15:07:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
06/13/2022 15:07:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
06/13/2022 15:07:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=44
06/13/2022 15:07:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
06/13/2022 15:07:15 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
06/13/2022 15:07:39 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9203146533447306 on epoch=44
06/13/2022 15:07:41 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
06/13/2022 15:07:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
06/13/2022 15:07:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 15:07:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
06/13/2022 15:07:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
06/13/2022 15:08:15 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9833401255608403 on epoch=45
06/13/2022 15:08:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=45
06/13/2022 15:08:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=45
06/13/2022 15:08:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
06/13/2022 15:08:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=46
06/13/2022 15:08:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=46
06/13/2022 15:08:52 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9182766793527036 on epoch=46
06/13/2022 15:08:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
06/13/2022 15:08:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=46
06/13/2022 15:08:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
06/13/2022 15:09:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
06/13/2022 15:09:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
06/13/2022 15:09:29 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.984370969612903 on epoch=47
06/13/2022 15:09:31 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
06/13/2022 15:09:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
06/13/2022 15:09:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=47
06/13/2022 15:09:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
06/13/2022 15:09:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
06/13/2022 15:10:05 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.9877396320101247 on epoch=48
06/13/2022 15:10:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
06/13/2022 15:10:10 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
06/13/2022 15:10:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
06/13/2022 15:10:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
06/13/2022 15:10:18 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
06/13/2022 15:10:42 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9193030715777813 on epoch=49
06/13/2022 15:10:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
06/13/2022 15:10:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
06/13/2022 15:10:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
06/13/2022 15:10:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.11 on epoch=49
06/13/2022 15:10:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
06/13/2022 15:11:18 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9182637957747828 on epoch=49
06/13/2022 15:11:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=50
06/13/2022 15:11:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
06/13/2022 15:11:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=50
06/13/2022 15:11:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=50
06/13/2022 15:11:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=50
06/13/2022 15:11:55 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.9192475269750494 on epoch=50
06/13/2022 15:11:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
06/13/2022 15:12:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=51
06/13/2022 15:12:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
06/13/2022 15:12:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
06/13/2022 15:12:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 15:12:30 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8562868525100782 on epoch=51
06/13/2022 15:12:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
06/13/2022 15:12:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
06/13/2022 15:12:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.11 on epoch=52
06/13/2022 15:12:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
06/13/2022 15:12:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
06/13/2022 15:13:06 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8559294490648208 on epoch=52
06/13/2022 15:13:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=52
06/13/2022 15:13:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
06/13/2022 15:13:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
06/13/2022 15:13:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=53
06/13/2022 15:13:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
06/13/2022 15:13:21 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 15:13:21 - INFO - __main__ - Printing 3 examples
06/13/2022 15:13:21 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 15:13:21 - INFO - __main__ - ['Film']
06/13/2022 15:13:21 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 15:13:21 - INFO - __main__ - ['Film']
06/13/2022 15:13:21 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 15:13:21 - INFO - __main__ - ['Film']
06/13/2022 15:13:21 - INFO - __main__ - Tokenizing Input ...
06/13/2022 15:13:21 - INFO - __main__ - Tokenizing Output ...
06/13/2022 15:13:22 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 15:13:22 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 15:13:22 - INFO - __main__ - Printing 3 examples
06/13/2022 15:13:22 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 15:13:22 - INFO - __main__ - ['Film']
06/13/2022 15:13:22 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 15:13:22 - INFO - __main__ - ['Film']
06/13/2022 15:13:22 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 15:13:22 - INFO - __main__ - ['Film']
06/13/2022 15:13:22 - INFO - __main__ - Tokenizing Input ...
06/13/2022 15:13:23 - INFO - __main__ - Tokenizing Output ...
06/13/2022 15:13:23 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 15:13:39 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 15:13:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 15:13:40 - INFO - __main__ - Starting training!
06/13/2022 15:13:43 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7565306053111286 on epoch=53
06/13/2022 15:13:43 - INFO - __main__ - save last model!
06/13/2022 15:13:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 15:13:43 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 15:13:43 - INFO - __main__ - Printing 3 examples
06/13/2022 15:13:43 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 15:13:43 - INFO - __main__ - ['Animal']
06/13/2022 15:13:43 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 15:13:43 - INFO - __main__ - ['Animal']
06/13/2022 15:13:43 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 15:13:43 - INFO - __main__ - ['Village']
06/13/2022 15:13:43 - INFO - __main__ - Tokenizing Input ...
06/13/2022 15:13:45 - INFO - __main__ - Tokenizing Output ...
06/13/2022 15:13:49 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 15:16:03 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.3_8_predictions.txt
06/13/2022 15:16:03 - INFO - __main__ - Classification-F1 on test data: 0.6818
06/13/2022 15:16:03 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.3, bsz=8, dev_performance=0.987765596691961, test_performance=0.6817736050728952
06/13/2022 15:16:03 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.2, bsz=8 ...
06/13/2022 15:16:04 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 15:16:04 - INFO - __main__ - Printing 3 examples
06/13/2022 15:16:04 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/13/2022 15:16:04 - INFO - __main__ - ['Film']
06/13/2022 15:16:04 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/13/2022 15:16:04 - INFO - __main__ - ['Film']
06/13/2022 15:16:04 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/13/2022 15:16:04 - INFO - __main__ - ['Film']
06/13/2022 15:16:04 - INFO - __main__ - Tokenizing Input ...
06/13/2022 15:16:05 - INFO - __main__ - Tokenizing Output ...
06/13/2022 15:16:06 - INFO - __main__ - Loaded 896 examples from train data
06/13/2022 15:16:06 - INFO - __main__ - Start tokenizing ... 896 instances
06/13/2022 15:16:06 - INFO - __main__ - Printing 3 examples
06/13/2022 15:16:06 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
06/13/2022 15:16:06 - INFO - __main__ - ['Film']
06/13/2022 15:16:06 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
06/13/2022 15:16:06 - INFO - __main__ - ['Film']
06/13/2022 15:16:06 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
06/13/2022 15:16:06 - INFO - __main__ - ['Film']
06/13/2022 15:16:06 - INFO - __main__ - Tokenizing Input ...
06/13/2022 15:16:06 - INFO - __main__ - Tokenizing Output ...
06/13/2022 15:16:07 - INFO - __main__ - Loaded 896 examples from dev data
06/13/2022 15:16:23 - INFO - __main__ - load prompt embedding from ckpt
06/13/2022 15:16:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/13/2022 15:16:23 - INFO - __main__ - Starting training!
06/13/2022 15:16:26 - INFO - __main__ - Step 10 Global step 10 Train loss 5.13 on epoch=0
06/13/2022 15:16:29 - INFO - __main__ - Step 20 Global step 20 Train loss 3.73 on epoch=0
06/13/2022 15:16:32 - INFO - __main__ - Step 30 Global step 30 Train loss 3.13 on epoch=0
06/13/2022 15:16:34 - INFO - __main__ - Step 40 Global step 40 Train loss 2.25 on epoch=0
06/13/2022 15:16:37 - INFO - __main__ - Step 50 Global step 50 Train loss 2.06 on epoch=0
06/13/2022 15:16:59 - INFO - __main__ - Global step 50 Train loss 3.26 Classification-F1 0.04978857327816976 on epoch=0
06/13/2022 15:16:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04978857327816976 on epoch=0, global_step=50
06/13/2022 15:17:02 - INFO - __main__ - Step 60 Global step 60 Train loss 1.70 on epoch=1
06/13/2022 15:17:05 - INFO - __main__ - Step 70 Global step 70 Train loss 1.51 on epoch=1
06/13/2022 15:17:07 - INFO - __main__ - Step 80 Global step 80 Train loss 1.31 on epoch=1
06/13/2022 15:17:10 - INFO - __main__ - Step 90 Global step 90 Train loss 1.18 on epoch=1
06/13/2022 15:17:12 - INFO - __main__ - Step 100 Global step 100 Train loss 1.15 on epoch=1
06/13/2022 15:17:37 - INFO - __main__ - Global step 100 Train loss 1.37 Classification-F1 0.3014969213315786 on epoch=1
06/13/2022 15:17:37 - INFO - __main__ - Saving model with best Classification-F1: 0.04978857327816976 -> 0.3014969213315786 on epoch=1, global_step=100
06/13/2022 15:17:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.02 on epoch=1
06/13/2022 15:17:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.82 on epoch=2
06/13/2022 15:17:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=2
06/13/2022 15:17:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=2
06/13/2022 15:17:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=2
06/13/2022 15:18:15 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.41604513563044704 on epoch=2
06/13/2022 15:18:15 - INFO - __main__ - Saving model with best Classification-F1: 0.3014969213315786 -> 0.41604513563044704 on epoch=2, global_step=150
06/13/2022 15:18:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=2
06/13/2022 15:18:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=3
06/13/2022 15:18:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.62 on epoch=3
06/13/2022 15:18:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=3
06/13/2022 15:18:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=3
06/13/2022 15:18:56 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.48488146576056296 on epoch=3
06/13/2022 15:18:56 - INFO - __main__ - Saving model with best Classification-F1: 0.41604513563044704 -> 0.48488146576056296 on epoch=3, global_step=200
06/13/2022 15:18:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.50 on epoch=3
06/13/2022 15:19:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=3
06/13/2022 15:19:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=4
06/13/2022 15:19:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=4
06/13/2022 15:19:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=4
06/13/2022 15:19:35 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.6174863913657745 on epoch=4
06/13/2022 15:19:35 - INFO - __main__ - Saving model with best Classification-F1: 0.48488146576056296 -> 0.6174863913657745 on epoch=4, global_step=250
06/13/2022 15:19:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=4
06/13/2022 15:19:40 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=4
06/13/2022 15:19:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=4
06/13/2022 15:19:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=5
06/13/2022 15:19:48 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=5
06/13/2022 15:20:15 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.4953439356265131 on epoch=5
06/13/2022 15:20:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=5
06/13/2022 15:20:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=5
06/13/2022 15:20:22 - INFO - __main__ - Step 330 Global step 330 Train loss 0.31 on epoch=5
06/13/2022 15:20:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=6
06/13/2022 15:20:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=6
06/13/2022 15:20:55 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.5040346929369011 on epoch=6
06/13/2022 15:20:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=6
06/13/2022 15:21:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=6
06/13/2022 15:21:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=6
06/13/2022 15:21:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.34 on epoch=6
06/13/2022 15:21:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=7
06/13/2022 15:21:36 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.660348055607471 on epoch=7
06/13/2022 15:21:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6174863913657745 -> 0.660348055607471 on epoch=7, global_step=400
06/13/2022 15:21:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=7
06/13/2022 15:21:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=7
06/13/2022 15:21:43 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=7
06/13/2022 15:21:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=7
06/13/2022 15:21:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=8
06/13/2022 15:22:16 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.6594877230674295 on epoch=8
06/13/2022 15:22:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=8
06/13/2022 15:22:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=8
06/13/2022 15:22:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=8
06/13/2022 15:22:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=8
06/13/2022 15:22:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=8
06/13/2022 15:22:59 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.6867849596081118 on epoch=8
06/13/2022 15:22:59 - INFO - __main__ - Saving model with best Classification-F1: 0.660348055607471 -> 0.6867849596081118 on epoch=8, global_step=500
06/13/2022 15:23:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=9
06/13/2022 15:23:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=9
06/13/2022 15:23:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=9
06/13/2022 15:23:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=9
06/13/2022 15:23:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=9
06/13/2022 15:23:41 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.5507032693199073 on epoch=9
06/13/2022 15:23:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=9
06/13/2022 15:23:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=10
06/13/2022 15:23:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=10
06/13/2022 15:23:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=10
06/13/2022 15:23:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=10
06/13/2022 15:24:26 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.6975894096645152 on epoch=10
06/13/2022 15:24:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6867849596081118 -> 0.6975894096645152 on epoch=10, global_step=600
06/13/2022 15:24:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=10
06/13/2022 15:24:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=11
06/13/2022 15:24:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=11
06/13/2022 15:24:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=11
06/13/2022 15:24:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=11
06/13/2022 15:25:11 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6832412641753166 on epoch=11
06/13/2022 15:25:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=11
06/13/2022 15:25:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=11
06/13/2022 15:25:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=12
06/13/2022 15:25:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=12
06/13/2022 15:25:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.23 on epoch=12
06/13/2022 15:25:54 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.7486915330049384 on epoch=12
06/13/2022 15:25:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6975894096645152 -> 0.7486915330049384 on epoch=12, global_step=700
06/13/2022 15:25:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=12
06/13/2022 15:25:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=12
06/13/2022 15:26:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=13
06/13/2022 15:26:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=13
06/13/2022 15:26:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=13
06/13/2022 15:26:39 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.7596428201646367 on epoch=13
06/13/2022 15:26:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7486915330049384 -> 0.7596428201646367 on epoch=13, global_step=750
06/13/2022 15:26:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=13
06/13/2022 15:26:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=13
06/13/2022 15:26:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=13
06/13/2022 15:26:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=14
06/13/2022 15:26:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=14
06/13/2022 15:27:24 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.8009167621692841 on epoch=14
06/13/2022 15:27:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7596428201646367 -> 0.8009167621692841 on epoch=14, global_step=800
06/13/2022 15:27:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=14
06/13/2022 15:27:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=14
06/13/2022 15:27:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=14
06/13/2022 15:27:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=14
06/13/2022 15:27:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=15
06/13/2022 15:28:07 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.7764203001335698 on epoch=15
06/13/2022 15:28:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=15
06/13/2022 15:28:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=15
06/13/2022 15:28:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=15
06/13/2022 15:28:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=15
06/13/2022 15:28:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=16
06/13/2022 15:28:50 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.7146645573918853 on epoch=16
06/13/2022 15:28:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=16
06/13/2022 15:28:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=16
06/13/2022 15:28:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=16
06/13/2022 15:29:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=16
06/13/2022 15:29:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=16
06/13/2022 15:29:32 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7109156797067258 on epoch=16
06/13/2022 15:29:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=17
06/13/2022 15:29:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=17
06/13/2022 15:29:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=17
06/13/2022 15:29:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=17
06/13/2022 15:29:45 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=17
06/13/2022 15:30:16 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7062871822799245 on epoch=17
06/13/2022 15:30:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=18
06/13/2022 15:30:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=18
06/13/2022 15:30:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=18
06/13/2022 15:30:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=18
06/13/2022 15:30:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=18
06/13/2022 15:30:59 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.8402790703343244 on epoch=18
06/13/2022 15:30:59 - INFO - __main__ - Saving model with best Classification-F1: 0.8009167621692841 -> 0.8402790703343244 on epoch=18, global_step=1050
06/13/2022 15:31:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=18
06/13/2022 15:31:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=19
06/13/2022 15:31:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=19
06/13/2022 15:31:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=19
06/13/2022 15:31:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=19
06/13/2022 15:31:42 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.700608498821546 on epoch=19
06/13/2022 15:31:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=19
06/13/2022 15:31:47 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=19
06/13/2022 15:31:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=20
06/13/2022 15:31:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=20
06/13/2022 15:31:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=20
06/13/2022 15:32:26 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.8086467899568206 on epoch=20
06/13/2022 15:32:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=20
06/13/2022 15:32:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=20
06/13/2022 15:32:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=21
06/13/2022 15:32:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=21
06/13/2022 15:32:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=21
06/13/2022 15:33:08 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.8505710073120742 on epoch=21
06/13/2022 15:33:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8402790703343244 -> 0.8505710073120742 on epoch=21, global_step=1200
06/13/2022 15:33:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=21
06/13/2022 15:33:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=21
06/13/2022 15:33:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=21
06/13/2022 15:33:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
06/13/2022 15:33:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=22
06/13/2022 15:33:52 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.831257504643855 on epoch=22
06/13/2022 15:33:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=22
06/13/2022 15:33:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=22
06/13/2022 15:33:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=22
06/13/2022 15:34:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=23
06/13/2022 15:34:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=23
06/13/2022 15:34:34 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.8700239944446432 on epoch=23
06/13/2022 15:34:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8505710073120742 -> 0.8700239944446432 on epoch=23, global_step=1300
06/13/2022 15:34:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=23
06/13/2022 15:34:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=23
06/13/2022 15:34:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=23
06/13/2022 15:34:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=23
06/13/2022 15:34:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
06/13/2022 15:35:16 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7833676724770702 on epoch=24
06/13/2022 15:35:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=24
06/13/2022 15:35:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=24
06/13/2022 15:35:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=24
06/13/2022 15:35:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=24
06/13/2022 15:35:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=24
06/13/2022 15:35:59 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8036836128621483 on epoch=24
06/13/2022 15:36:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=25
06/13/2022 15:36:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=25
06/13/2022 15:36:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=25
06/13/2022 15:36:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=25
06/13/2022 15:36:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=25
06/13/2022 15:36:44 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.8094963146131121 on epoch=25
06/13/2022 15:36:46 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=26
06/13/2022 15:36:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=26
06/13/2022 15:36:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=26
06/13/2022 15:36:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=26
06/13/2022 15:36:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
06/13/2022 15:37:27 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8489051845992841 on epoch=26
06/13/2022 15:37:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=26
06/13/2022 15:37:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=27
06/13/2022 15:37:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=27
06/13/2022 15:37:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
06/13/2022 15:37:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
06/13/2022 15:38:11 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6971885888140138 on epoch=27
06/13/2022 15:38:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=27
06/13/2022 15:38:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
06/13/2022 15:38:19 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=28
06/13/2022 15:38:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=28
06/13/2022 15:38:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=28
06/13/2022 15:38:53 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.8060703129807109 on epoch=28
06/13/2022 15:38:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
06/13/2022 15:38:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=28
06/13/2022 15:39:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=29
06/13/2022 15:39:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=29
06/13/2022 15:39:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
06/13/2022 15:39:35 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.914722693116356 on epoch=29
06/13/2022 15:39:35 - INFO - __main__ - Saving model with best Classification-F1: 0.8700239944446432 -> 0.914722693116356 on epoch=29, global_step=1650
06/13/2022 15:39:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
06/13/2022 15:39:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=29
06/13/2022 15:39:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
06/13/2022 15:39:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=30
06/13/2022 15:39:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=30
06/13/2022 15:40:17 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.8467898281082842 on epoch=30
06/13/2022 15:40:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=30
06/13/2022 15:40:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=30
06/13/2022 15:40:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=30
06/13/2022 15:40:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=31
06/13/2022 15:40:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=31
06/13/2022 15:40:58 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8040988089696843 on epoch=31
06/13/2022 15:41:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=31
06/13/2022 15:41:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=31
06/13/2022 15:41:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=31
06/13/2022 15:41:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=31
06/13/2022 15:41:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
06/13/2022 15:41:38 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7642637120062996 on epoch=32
06/13/2022 15:41:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=32
06/13/2022 15:41:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=32
06/13/2022 15:41:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
06/13/2022 15:41:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=32
06/13/2022 15:41:51 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
06/13/2022 15:42:19 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.8395040463243821 on epoch=33
06/13/2022 15:42:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=33
06/13/2022 15:42:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.17 on epoch=33
06/13/2022 15:42:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=33
06/13/2022 15:42:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=33
06/13/2022 15:42:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=33
06/13/2022 15:43:00 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.843368487952701 on epoch=33
06/13/2022 15:43:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
06/13/2022 15:43:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=34
06/13/2022 15:43:08 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=34
06/13/2022 15:43:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=34
06/13/2022 15:43:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=34
06/13/2022 15:43:41 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7484921068852173 on epoch=34
06/13/2022 15:43:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=34
06/13/2022 15:43:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
06/13/2022 15:43:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
06/13/2022 15:43:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
06/13/2022 15:43:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=35
06/13/2022 15:44:21 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.6897426134097014 on epoch=35
06/13/2022 15:44:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=35
06/13/2022 15:44:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=36
06/13/2022 15:44:29 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
06/13/2022 15:44:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
06/13/2022 15:44:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
06/13/2022 15:45:01 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7315150680341886 on epoch=36
06/13/2022 15:45:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
06/13/2022 15:45:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
06/13/2022 15:45:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
06/13/2022 15:45:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=37
06/13/2022 15:45:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=37
06/13/2022 15:45:43 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6862987371689918 on epoch=37
06/13/2022 15:45:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=37
06/13/2022 15:45:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=37
06/13/2022 15:45:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
06/13/2022 15:45:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=38
06/13/2022 15:45:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=38
06/13/2022 15:46:22 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7919866132072068 on epoch=38
06/13/2022 15:46:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
06/13/2022 15:46:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=38
06/13/2022 15:46:30 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=38
06/13/2022 15:46:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
06/13/2022 15:46:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
06/13/2022 15:47:03 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7392991701682494 on epoch=39
06/13/2022 15:47:06 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
06/13/2022 15:47:08 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=39
06/13/2022 15:47:11 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=39
06/13/2022 15:47:13 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=39
06/13/2022 15:47:16 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
06/13/2022 15:47:44 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7407950035217994 on epoch=40
06/13/2022 15:47:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
06/13/2022 15:47:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=40
06/13/2022 15:47:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=40
06/13/2022 15:47:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
06/13/2022 15:47:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
06/13/2022 15:48:21 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7030273128238356 on epoch=41
06/13/2022 15:48:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=41
06/13/2022 15:48:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=41
06/13/2022 15:48:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=41
06/13/2022 15:48:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=41
06/13/2022 15:48:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
06/13/2022 15:48:59 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7285033197477544 on epoch=41
06/13/2022 15:49:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=42
06/13/2022 15:49:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=42
06/13/2022 15:49:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
06/13/2022 15:49:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=42
06/13/2022 15:49:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
06/13/2022 15:49:37 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.649844506320055 on epoch=42
06/13/2022 15:49:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=43
06/13/2022 15:49:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=43
06/13/2022 15:49:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
06/13/2022 15:49:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
06/13/2022 15:49:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=43
06/13/2022 15:50:17 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7942115049821943 on epoch=43
06/13/2022 15:50:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
06/13/2022 15:50:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
06/13/2022 15:50:24 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=44
06/13/2022 15:50:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
06/13/2022 15:50:29 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
06/13/2022 15:50:56 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8478462036091474 on epoch=44
06/13/2022 15:50:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=44
06/13/2022 15:51:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=44
06/13/2022 15:51:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
06/13/2022 15:51:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
06/13/2022 15:51:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=45
06/13/2022 15:51:35 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7357594832963074 on epoch=45
06/13/2022 15:51:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=45
06/13/2022 15:51:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=45
06/13/2022 15:51:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=46
06/13/2022 15:51:46 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=46
06/13/2022 15:51:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
06/13/2022 15:52:15 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.672263400580616 on epoch=46
06/13/2022 15:52:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=46
06/13/2022 15:52:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
06/13/2022 15:52:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=46
06/13/2022 15:52:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=47
06/13/2022 15:52:28 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
06/13/2022 15:52:54 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7563368871740491 on epoch=47
06/13/2022 15:52:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=47
06/13/2022 15:52:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
06/13/2022 15:53:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
06/13/2022 15:53:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
06/13/2022 15:53:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
06/13/2022 15:53:33 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.755144329907433 on epoch=48
06/13/2022 15:53:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
06/13/2022 15:53:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
06/13/2022 15:53:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
06/13/2022 15:53:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
06/13/2022 15:53:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
06/13/2022 15:54:12 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7727558323926454 on epoch=49
06/13/2022 15:54:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=49
06/13/2022 15:54:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
06/13/2022 15:54:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
06/13/2022 15:54:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=49
06/13/2022 15:54:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
06/13/2022 15:54:50 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8431909089888581 on epoch=49
06/13/2022 15:54:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
06/13/2022 15:54:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.11 on epoch=50
06/13/2022 15:54:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
06/13/2022 15:55:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
06/13/2022 15:55:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
06/13/2022 15:55:28 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7943818283535005 on epoch=50
06/13/2022 15:55:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
06/13/2022 15:55:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
06/13/2022 15:55:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
06/13/2022 15:55:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=51
06/13/2022 15:55:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
06/13/2022 15:56:07 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7938248547932593 on epoch=51
06/13/2022 15:56:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
06/13/2022 15:56:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
06/13/2022 15:56:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
06/13/2022 15:56:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
06/13/2022 15:56:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
06/13/2022 15:56:45 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7411829413330974 on epoch=52
06/13/2022 15:56:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=52
06/13/2022 15:56:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
06/13/2022 15:56:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
06/13/2022 15:56:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
06/13/2022 15:56:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=53
06/13/2022 15:57:25 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8536548977065778 on epoch=53
06/13/2022 15:57:25 - INFO - __main__ - save last model!
06/13/2022 15:57:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/13/2022 15:57:25 - INFO - __main__ - Start tokenizing ... 3500 instances
06/13/2022 15:57:25 - INFO - __main__ - Printing 3 examples
06/13/2022 15:57:25 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/13/2022 15:57:25 - INFO - __main__ - ['Animal']
06/13/2022 15:57:25 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/13/2022 15:57:25 - INFO - __main__ - ['Animal']
06/13/2022 15:57:25 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/13/2022 15:57:25 - INFO - __main__ - ['Village']
06/13/2022 15:57:25 - INFO - __main__ - Tokenizing Input ...
06/13/2022 15:57:27 - INFO - __main__ - Tokenizing Output ...
06/13/2022 15:57:31 - INFO - __main__ - Loaded 3500 examples from test data
06/13/2022 15:59:42 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.2_8_predictions.txt
06/13/2022 15:59:43 - INFO - __main__ - Classification-F1 on test data: 0.7602
06/13/2022 15:59:43 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.2, bsz=8, dev_performance=0.914722693116356, test_performance=0.760168811960075
